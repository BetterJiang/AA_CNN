IntroductionWelcometotheNAACLHLTWorkshoponSemi-supervisedLearningforNaturalLanguageProcessing!Willsemi-supervisedlearning(SSL)becomethenextde-factostandardforbuildingnaturallanguageprocessing(NLP)systems,justassupervisedlearninghastransformedtheeldinthelastdecade?Orwillitremainasaniceideathatdoesntalwaysworkinpractice?Semi-supervisedlearninghasbecomeanimportanttopicduetothepromisethathigh-qualitylabeleddataandabundantunlabeleddata,ifleveragedappropriately,canachievesuperiorperformanceatlowercost.Asresearchersinsemi-supervisedlearningreachcriticalmass,webelieveitistimetotakeastepbackandthinkbroadlyaboutwhetherwecandiscovergeneralinsightsfromthevarioustechniquesdevelopedfordifferentNLPtasks.ThegoalofthisworkshopistohelpbuildacommunityofSSL-NLPresearchersandfosterdiscussionsaboutinsights,speculations,andresults(bothpositiveandnegative)thatmayotherwisenotappearinatechnicalpaperatamajorconference.Inourcall-for-paper,weposedsomeopenquestions:1.ProblemStructure:WhatarethedifferentclassesofNLPproblemstructures(e.g.sequences,trees,N-bestlists)andwhatalgorithmsarebestsuitedforeachclass?Forinstance,cangraph-basedalgorithmsbesuccessfullyappliedtosequence-to-sequenceproblemslikemachinetranslation,orareself-trainingandfeature-basedmethodstheonlyreasonablechoicesfortheseproblems?2.BackgroundKnowledge:WhatkindsofNLP-specicbackgroundknowledgecanweexploittoaidsemi-supervisedlearning?Recentlearningparadigmssuchasconstraint-drivenlearningandprototypelearningtakeadvantageofourdomainknowledgeaboutparticularNLPtasks;theyrepresentamoveawayfrompurelydata-agnosticmethodsandaregoodexamplesofhowlinguisticintuitioncandrivealgorithmdevelopment.3.Scalability:NLPdata-setsareoftenlarge.Whatarethescalabilitychallengesandsolutionsforapplyingexistingsemi-supervisedlearningalgorithmstoNLPdata?4.EvaluationandNegativeResults:Whatcanwelearnfromnegativeresults?Canwemakeaneducatedguessastowhensemi-supervisedlearningmightoutperformsupervisedorunsupervisedlearningbasedonwhatweknowabouttheNLPproblem?5.ToUseorNotToUse:Shouldsemi-supervisedlearningonlybeemployedinlow-resourcelanguages/tasks(i.e.littlelabeleddata,muchunlabeleddata),orshouldweexpectgainseveninhigh-resourcescenarios(i.e.expectingsemi-supervisedlearningtoimproveonasupervisedsystemthatisalreadymorethan95%accurate)?Wereceived17submissionsandselected10papersafterarigorousreviewprocess.Thesepaperscoveravarietyoftasks,rangingfrominformationextractiontospeechrecognition.Someintroducenewtechniques,whileotherscomparedexistingmethodsunderavarietyofsituations.Wearepleasedtopresentthesepapersinthisvolume.OurworkshopwillbekickedoffwithakeynotetalkbyJasonEisner(JohnsHopkinsUniversity).Weiv

willendwithapaneldiscussiononthefutureofSSL-NLP,whichwillfeatureinvitedpositionpapersfromseveralprominentresearchers.(Someareincludedinthisvolume;otherswillbeonlineattheworkshopwebsite:http://sites.google.com/site/sslnlp/).Weareespeciallygratefultotheprogramcommitteefortheirhardworkandthepresentersfortheirexcellentpapers.Wewouldalsoliketothankthefollowingpeoplefortheirmanyhelpandsupport:HalDaume,SajibDasgupta,JasonEisner,NizarHabash,MarkHasegawa-Johnson,AndrewMcCallum,VincentNg,AnoopSarkar,EricRingger,andJerryZhu.Bestregards,QinIrisWang,KevinDuh,DekangLinSSL-NLPWorkshopOrganizers26April2009v

Organizers:QinIrisWang,AT&TKevinDuh,UniversityofWashingtonDekangLin,GoogleResearchProgramCommittee:StevenAbney(UniversityofMichigan,USA)YaseminAltun(MaxPlanckInstituteforBiologicalCybernetics,Germany)TimBaldwin(UniversityofMelbourne,Australia)ShaneBergsma(UniversityofAlberta,Canada)AntalvandenBosch(TilburgUniversity,TheNetherlands)JohnBlitzer(UCBerkeley,USA)Ming-WeiChang(UIUC,USA)WalterDaelemans(UniversityofAntwerp,Belgium)HalDaumeIII(UniversityofUtah,USA)KevinGimpel(CarnegieMellonUniversity,USA)AndrewGoldberg(UniversityofWisconsin,USA)LiangHuang(GoogleResearch,USA)RieJohnson[formerly,Ando](RJResearchConsulting)KatrinKirchhoff(UniversityofWashington,USA)PercyLiang(UCBerkeley,USA)GaryGeunbaeLee(POSTECH,Korea)Gina-AnneLevow(UniversityofChicago,USA)GideonMann(Google,USA)DavidMcClotsky(BrownUniversity,USA)RayMooney(UTAustin,USA)HweeTouNg(NationalUniversityofSingapore,Singapore)VincentNg(UTDallas,USA)MilesOsborne(UniversityofEdinburgh,UK)MariOstendorf(UniversityofWashington,USA)ChrisPinchak(UniversityofAlberta,Canada)DragomirRadev(UniversityofMichigan,USA)DanRoth(UIUC,USA)AnoopSarkar(SimonFraserUniversity,Canada)DaleSchuurmans(UniversityofAlberta,Canada)AkiraShimazu(JAIST,Japan)JunSuzuki(NTT,Japan)YeeWhyeTeh(UniversityCollegeLondon,UK)KristinaToutanova(MicrosoftResearch,USA)JasonWeston(NEC,USA)TongZhang(RutgersUniversity,USA)vi

MingZhou(MicrosoftResearchAsia,China)Xiaojin(Jerry)Zhu(UniversityofWisconsin,USA)InvitedSpeaker:JasonEisner,JohnsHopkinsUniversityTable of Contents

Coupling Semi-Supervised Learning of Categories and Relations

Andrew Carlson, Justin Betteridge, Estevam Rafael Hruschka Junior and Tom M. Mitchell . . . . . 1

Surrogate Learning - From Feature Independence to Semi-Supervised Classication

Sriharsha Veeramachaneni and Ravi Kumar Kondadadi . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10

Keepin It Real: Semi-Supervised Learning with Realistic Tuning

Andrew B. Goldberg and Xiaojin Zhu . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19

Is Unlabeled Data Suitable for Multiclass SVM-based Web Page Classication?

Arkaitz Zubiaga, Vctor Fresno and Raquel Martnez . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28

A Comparison of Structural Correspondence Learning and Self-training for Discriminative Parse Se-
lection

Barbara Plank . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37

Latent Dirichlet Allocation with Topic-in-Set Knowledge

David Andrzejewski and Xiaojin Zhu . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43

An Analysis of Bootstrapping for the Recognition of Temporal Expressions

Jordi Poveda, Mihai Surdeanu and Jordi Turmo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49

A Simple Semi-supervised Algorithm For Named Entity Recognition

Wenhui Liao and Sriharsha Veeramachaneni . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58

Can One Language Bootstrap the Other: A Case Study on Event Extraction

Zheng Chen and Heng Ji . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66

On Semi-Supervised Learning of Gaussian Mixture Models for Phonetic Classication

Jui-Ting Huang and Mark Hasegawa-Johnson . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75

Discriminative Models for Semi-Supervised Natural Language Learning

Sajib Dasgupta and Vincent Ng . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84

vii

Conference Program

Thursday, June 4, 2009

8:309:00

Coffee Service

9:009:10

Opening Remarks

9:1010:10

Invited Talk by Jason Eisner

10:1010:30 Coupling Semi-Supervised Learning of Categories and Relations

Andrew Carlson, Justin Betteridge, Estevam Rafael Hruschka Junior and Tom M.
Mitchell

10:3011:00 Morning Break

11:0011:20

Surrogate Learning - From Feature Independence to Semi-Supervised Classication
Sriharsha Veeramachaneni and Ravi Kumar Kondadadi

11:2511:45 Keepin It Real: Semi-Supervised Learning with Realistic Tuning

Andrew B. Goldberg and Xiaojin Zhu

11:5012:10

Is Unlabeled Data Suitable for Multiclass SVM-based Web Page Classication?
Arkaitz Zubiaga, Vctor Fresno and Raquel Martnez

12:1512:35

A Comparison of Structural Correspondence Learning and Self-training for Dis-
criminative Parse Selection
Barbara Plank

12:352:00

Lunch Break

2:002:20

2:252:45

2:503:10

Latent Dirichlet Allocation with Topic-in-Set Knowledge
David Andrzejewski and Xiaojin Zhu

An Analysis of Bootstrapping for the Recognition of Temporal Expressions
Jordi Poveda, Mihai Surdeanu and Jordi Turmo

A Simple Semi-supervised Algorithm For Named Entity Recognition
Wenhui Liao and Sriharsha Veeramachaneni

ix

Thursday, June 4, 2009 (continued)

3:153:35

Can One Language Bootstrap the Other: A Case Study on Event Extraction
Zheng Chen and Heng Ji

3:354:00

Afternoon Break

4:004:20

On Semi-Supervised Learning of Gaussian Mixture Models for Phonetic Classication
Jui-Ting Huang and Mark Hasegawa-Johnson

4:255:25

Panel Discusstion

Discriminative Models for Semi-Supervised Natural Language Learning
Sajib Dasgupta and Vincent Ng

5:255:40

Workshop Wrap-up

x

Proceedings of the NAACL HLT Workshop on Semi-supervised Learning for Natural Language Processing, pages 19,

Boulder, Colorado, June 2009. c(cid:13)2009 Association for Computational Linguistics

1

CouplingSemi-SupervisedLearningofCategoriesandRelationsAndrewCarlson1,JustinBetteridge1,EstevamR.HruschkaJr.1,2andTomM.Mitchell11SchoolofComputerScienceCarnegieMellonUniversityPittsburgh,PA15213{acarlson,jbetter,tom.mitchell}@cs.cmu.edu2FederalUniversityofSaoCarlosSaoCarlos,SP-Brazilestevam@dc.ufscar.brAbstractWeconsidersemi-supervisedlearningofinformationextractionmethods,especiallyforextractinginstancesofnouncategories(e.g.,athlete,team)andrelations(e.g.,playsForTeam(athlete,team)).Semi-supervisedapproachesusingasmallnumberoflabeledexamplestogetherwithmanyun-labeledexamplesareoftenunreliableastheyfrequentlyproduceaninternallyconsistent,butneverthelessincorrectsetofextractions.Weproposethatthisproblemcanbeover-comebysimultaneouslylearningclassiersformanydifferentcategoriesandrelationsinthepresenceofanontologydeningconstraintsthatcouplethetrainingoftheseclassiers.Experimentalresultsshowthatsimultaneouslylearningacoupledcollectionofclassiersfor30categoriesandrelationsresultsinmuchmoreaccurateextractionsthantrainingclassiersindividually.1IntroductionAgreatwealthofknowledgeisexpressedonthewebinnaturallanguage.Translatingthisintoastruc-turedknowledgebasecontainingfactsaboutenti-ties(e.g.,Disney)andrelationsbetweenthoseen-tities(e.g.CompanyIndustry(Disney,entertain-ment))wouldbeofgreatusetomanyapplications.Althoughfullysupervisedmethodsforlearningtoextractsuchfactsfromtextworkwell,thecostofcollectingmanylabeledexamplesofeachtypeofknowledgetobeextractedisimpractical.Re-searchershavealsoexploredsemi-supervisedlearn-ingmethodsthatrelyprimarilyonunlabeleddata,Figure1:Weshowthatsignicantimprovementsinac-curacyresultfromcouplingthetrainingofinformationextractorsformanyinter-relatedcategoriesandrelations(B),comparedwiththesimplerbutmuchmoredifculttaskoflearningasingleinformationextractor(A).buttheseapproachestendtosufferfromthefactthattheyfaceanunder-constrainedlearningtask,result-inginextractionsthatareofteninaccurate.Wepresentanapproachtosemi-supervisedlearn-ingthatyieldsmoreaccurateresultsbycouplingthetrainingofmanyinformationextractors.Theintu-itionbehindourapproach(summarizedinFigure1)isthatsemi-supervisedtrainingofasingletypeofextractorsuchascoachismuchmoredifcultthansimultaneouslytrainingmanyextractorsthatcoveravarietyofinter-relatedentityandrelationtypes.Inparticular,priorknowledgeabouttherelation-shipsbetweenthesedifferententitiesandrelations(e.g.,thatcoach(x)impliesperson(x)andnotsport(x))allowsunlabeleddatatobecomeamuchmoreusefulconstraintduringtraining.Althoughpreviousworkhascoupledthelearningofmultiplecategories,orusedstaticcategoryrec-ognizerstocheckargumentsforlearnedrelationex-2

tractors,ourworkistherstweknowoftocouplethesimultaneoussemi-supervisedtrainingofmulti-plecategoriesandrelations.Ourexperimentsshowthatthiscouplingresultsinmoreaccurateextrac-tions.Basedonourresultsreportedhere,wehy-pothesizethatsignicantaccuracyimprovementsininformationextractionwillbepossiblebycouplingthetrainingofhundredsorthousandsofextractors.2ProblemStatementItwillbehelpfultorstexplainouruseofcommonterms.Anontologyisacollectionofunaryandbi-narypredicates,alsocalledcategoriesandrelations,respectively.1Aninstanceofacategory,oracate-goryinstance,isanounphrase;aninstanceofarela-tion,orarelationinstance,isapairofnounphrases.Instancescanbepositiveornegativewithrespecttoaspecicpredicate,meaningthatthepredicateholdsordoesnotholdforthatparticularinstance.Apromotedinstanceisaninstancewhichouralgo-rithmbelievestobeapositiveinstanceofsomepred-icate.Alsoassociatedwithbothcategoriesandrela-tionsarepatterns:stringsoftokenswithplacehold-ers(e.g.,gameagainstarg1andarg1,headcoachofarg2).Apromotedpatternisapatternbelievedtobeahigh-probabilityindicatorforsomepredicate.Thechallengeaddressedbythisworkistolearnextractorstoautomaticallypopulatethecategoriesandrelationsofaspeciedontologywithhigh-condenceinstances,startingfromafewseedpos-itiveinstancesandpatternsforeachpredicateandalargecorpusofsentencesannotatedwithpart-of-speech(POS)tags.Wefocusonextractingfactsthatarestatedmultipletimesinthecorpus,whichwecanassessprobabilisticallyusingcorpusstatistics.Wedonotresolvestringstoreal-worldentitiestheproblemsofsynonymresolutionanddisambiguationofstringsthatcanrefertomultipleentitiesareleftforfuturework.3RelatedWorkWorkonmultitasklearninghasdemonstratedthatsupervisedlearningofmultiplerelatedfunctionstogethercanyieldhigheraccuracythanlearningthefunctionsseparately(Thrun,1996;Caruana,1997).Semi-supervisedmultitasklearninghasbeenshown1Wedonotconsiderpredicatesofhigherarityinthiswork.toincreaseaccuracywhentasksarerelated,allow-ingonetouseapriorthatencouragessimilarpa-rameters(Liuetal.,2008).Ourworkalsoinvolvessemi-supervisedtrainingofmultiplecoupledfunc-tions,butdiffersinthatweassumeexplicitpriorknowledgeoftheprecisewayinwhichourmulti-plefunctionsarerelated(e.g.,thatthevaluesofthefunctionsappliedtothesameinputaremutuallyex-clusive,orthatoneimpliestheother).Inthispaper,wefocusonabootstrappingmethodforsemi-supervisedlearning.Bootstrap-pingapproachesstartwithasmallnumberofla-beledseedexamples,usethoseseedexamplestotrainaninitialmodel,thenusethismodeltola-belsomeoftheunlabeleddata.Themodelisthenretrained,usingtheoriginalseedexamplesplustheself-labeledexamples.Thisprocessiterates,graduallyexpandingtheamountoflabeleddata.Suchapproacheshaveshownpromiseinapplica-tionssuchaswebpageclassication(BlumandMitchell,1998),namedentityclassication(CollinsandSinger,1999),parsing(McCloskyetal.,2006),andmachinetranslation(Uefng,2006).Bootstrappingapproachestoinformationextrac-tioncanyieldimpressiveresultswithlittleinitialhumaneffort(Brin,1998;AgichteinandGravano,2000;RavichandranandHovy,2002;Pascaetal.,2006).However,aftermanyiterations,theyusu-allysufferfromsemanticdrift,whereerrorsinlabel-ingaccumulateandthelearnedconceptdriftsfromwhatwasintended(Curranetal.,2007).Couplingthelearningofpredicatesbyusingpositiveexam-plesofonepredicateasnegativeexamplesforoth-ershasbeenshowntohelplimitthisdrift(RiloffandJones,1999;Yangarber,2003).Additionally,ensur-ingthatrelationargumentsareofcertain,expectedtypescanhelpmitigatethepromotionofincorrectinstances(Pascaetal.,2006;RosenfeldandFeld-man,2007).Ourworkbuildsontheseideastocou-plethesimultaneousbootstrappedtrainingofmulti-plecategoriesandmultiplerelations.Ourapproachtoinformationextractionisbasedonusinghighprecisioncontextualpatterns(e.g.,ismayorofarg1suggeststhatarg1isacity).Anearlypattern-basedapproachtoinformationextractionac-quiredisarelationsfromtextusinggenericcon-textualpatterns(Hearst,1992).ThisapproachwaslaterscaleduptothewebbyEtzionietal.(2005).3

Otherresearchexploresthetaskofopeninforma-tionextraction,wherethepredicatestobelearnedarenotspeciedinadvance(ShinyamaandSekine,2006;Bankoetal.,2007),butemergeinsteadfromanalysisofthedata.Incontrast,ourapproachre-liesstronglyonknowledgeintheontologyaboutthepredicatestobelearned,andrelationshipsamongthem,inordertoachievehighaccuracy.Changetal.(2007)presentaframeworkforlearningthatoptimizesthedatalikelihoodplusconstraint-basedpenaltytermsthancapturepriorknowledge,anddemonstrateitwithsemi-supervisedlearningofsegmentationmodels.Constraintsthatcapturedomainknowledgeguidebootstraplearn-ingofastructuredmodelbypenalizingordisallow-ingviolationsofthoseconstraints.Whilesimilarinspirit,ourworkdiffersinthatweconsiderlearningmanymodels,ratherthanonestructuredmodel,andthatweareconsideramuchlargerscaleapplicationinadifferentdomain.4Approach4.1CouplingofPredicatesAsmentionedabove,ourapproachhingesontheno-tionofcouplingthelearningofmultiplefunctionsinordertoconstrainthesemi-supervisedlearningproblemweface.Oursystemlearnsfourdifferenttypesoffunctions.Foreachcategoryc:1.fc,inst:NP(C)[0,1]2.fc,patt:PattC(C)[0,1]andforeachrelationr:1.fr,inst:NP(C)NP(C)[0,1]2.fr,patt:PattR(C)[0,1]whereCistheinputcorpus,NP(C)isthesetofvalidnounphrasesinC,PattC(C)isthesetofvalidcategorypatternsinC,andPattR(C)isthesetofvalidrelationpatternsinC.Validnounphrases,categorypatterns,andrelationpatternsaredenedinSection4.2.2.Thelearningofthesefunctionsiscoupledintwoways:1.Sharingamongsame-aritypredicatesaccordingtologicalrelations2.Relationargumenttype-checkingThesemethodsofcouplingaremadepossiblebypriorknowledgeintheinputontology,beyondthelistsofcategoriesandrelationsmentionedabove.Weprovidegeneraldescriptionsofthesemethodsofcouplinginthenextsections,whilethedetailsaregiveninsection4.2.4.1.1Sharingamongsame-aritypredicatesEachpredicatePintheontologyhasalistofothersame-aritypredicateswithwhichPismutuallyexclusive,wheremutuallyExclusive(P,P0)(P(arg1)P0(arg1))(P0(arg1)P(arg1)),andsimilarlyforrelations.Thesemu-tuallyexclusiverelationshipsareusedtocarryoutthefollowingsimplebutcrucialcoupling:ifpredi-cateAismutuallyexclusivewithpredicateB,Aspositiveinstancesandpatternsbecomenegativein-stancesandnegativepatternsforB.Forexample,ifcity,havinganinstanceBostonandapatternmayorofarg1,ismutuallyexclusivewithscien-tist,thenBostonandmayorofarg1willbecomeanegativeinstanceandanegativepatternrespec-tivelyforscientist.Suchnegativeinstancesandpatternsprovidenegativeevidencetoconstrainthebootstrappingprocessandforestalldivergence.Somecategoriesaredeclaredtobeasubsetofoneoftheothercategoriesbeingpopulated,wheresubset(P,P0)P(arg1)P0(arg1),(e.g.,ath-leteisasubsetofperson).Thispriorknowledgeisusedtoshareinstancesandpatternsofthesubcat-egory(e.g.,athlete)aspositiveinstancesandpat-ternsforthesuper-category(e.g.,person).4.1.2Relationargumenttype-checkingThelasttypeofpriorknowledgeweusetocouplethelearningoffunctionsistypecheckinginforma-tionwhichcouplesthelearningofrelationswithcat-egories.Forexample,theargumentsoftheceoOfrelationaredeclaredtobeofthecategoriespersonandcompany.Ourapproachdoesnotpromoteapairofnounphrasesasaninstanceofarelationun-lessthetwonounphrasesareclassiedasbelongingtothecorrectargumenttypes.Additionally,whenarelationinstanceispromoted,theargumentsbecomepromotedinstancesoftheirrespectivecategories.4.2AlgorithmDescriptionInthissection,wedescribeouralgorithm,CBL(CoupledBootstrapLearner),indetail.TheinputstoCBLarealargecorpusofPOS-taggedsentencesandaninitialontologywithpre-4

Algorithm1:CBLAlgorithmInput:AnontologyO,andtextcorpusCOutput:Trustedinstances/patternsforeachpredicateSHAREinitialinstances/patternsamongpredicates;fori=1,2,...,doforeachpredicatepOdoEXTRACTcandidateinstances/patterns;FILTERcandidates;TRAINinstance/patternclassiers;ASSESScandidatesusingclassiers;PROMOTEhighest-condencecandidates;endSHAREpromoteditemsamongpredicates;enddenedcategories,relations,mutuallyexclusivere-lationshipsbetweensame-aritypredicates,subsetre-lationshipsbetweensomecategories,seedinstancesforallpredicates,andseedpatternsforthecate-gories.Categoriesintheinputontologyalsohaveaagindicatingwhetherinstancesmustbepropernouns,commonnouns,orwhethertheycanbeei-ther(e.g.,instancesofcityarepropernouns).Algorithm1givesasummaryoftheCBLalgo-rithm.First,seedinstancesandpatternsaresharedamongpredicatesusingtheavailablemutualexclu-sion,subset,andtype-checkingrelations.Then,foranindenitenumberofiterations,CBLexpandsthesetsofpromotedinstancesandpatternsforeachpredicate,asdetailedbelow.CBLwasdesignedtoallowlearningmanypred-icatessimultaneouslyfromalargesampleoftextfromtheweb.Ineachiterationofthealgorithm,theinformationneededfromthetextcorpusisgatheredintwopassesthroughthecorpususingtheMapRe-duceframework(DeanandGhemawat,2008).Thisallowsustocompleteaniterationofthesystemin1hourusingacorpuscontainingmillionsofwebpages(seeSection5.3fordetailsonthecorpus).4.2.1SharingAtthestartofexecution,seedinstancesandpat-ternsaresharedamongpredicatesaccordingtothemutualexclusion,subset,andtype-checkingcon-straints.Newlypromotedinstancesandpatternsaresharedattheendofeachiteration.4.2.2CandidateExtractionCBLndsnewcandidateinstancesbyusingnewlypromotedpatternstoextractthenounphrasesthatco-occurwiththosepatternsinthetextcorpus.Tokeepthesizeofthissetmanageable,CBLlim-itsthenumberofnewcandidateinstancesforeachpredicateto1000byselectingtheonesthatoccurwiththemostnewlypromotedpatterns.Ananalo-gousprocedureisusedtoextractcandidatepatterns.CandidateextractionisperformedforallpredicatesinasinglepassthroughthecorpususingtheMapRe-duceframework.Thecandidateextractionprocedurehasdeni-tionsforvalidinstancesandpatternsthatlimitex-tractiontoinstancesthatlooklikenounphrasesandpatternsthatarelikelytobeinformative.Hereweprovidebriefdescriptionsofthosedenitions.CategoryInstancesIntheplaceholderofacate-gorypattern,CBLlooksforanounphrase.Itusespart-of-speechtagstosegmentnounphrases,ignor-ingdeterminers.Propernounscontainingprepo-sitionsaresegmentedusingareimplementationoftheLexalgorithm(Downeyetal.,2007).Cate-goryinstancesareonlyextractediftheyobeytheproper/commonnounspecicationofthecategory.CategoryPatternsIfapromotedcategoryin-stanceisfoundinasentence,CBLextractsthepre-cedingwordsasacandidatepatterniftheyareverbsfollowedbyasequenceofadjectives,prepositions,ordeterminers(e.g.,beingacquiredbyarg1)ornounsandadjectivesfollowedbyasequenceofad-jectives,prepositions,ordeterminers(e.g.,formerCEOofarg1).CBLextractsthewordsfollowingtheinstanceasacandidatepatterniftheyareverbsfollowedoption-allybyanounphrase(e.g.,arg1brokethehomerunrecord),orverbsfollowedbyapreposition(e.g.,arg1saidthat).RelationInstancesIfapromotedrelationpattern(e.g.,arg1ismayorofarg2)isfound,acandi-daterelationinstanceisextractedifbothplacehold-ersarevalidnounphrases,andiftheyobeytheproper/commonspecicationsfortheircategories.RelationPatternsIfbothargumentsfromapro-motedrelationinstancearefoundinasentencethen5

theinterveningsequenceofwordsisextractedasacandidaterelationpatternifitcontainsnomorethan5tokens,hasacontentword,hasanuncapitalizedword,andhasatleastonenon-noun.4.2.3CandidateFilteringCandidateinstancesandpatternsarelteredtomaintainhighprecision,andtoavoidextremelyspe-cicpatterns.Aninstanceisonlyconsideredforas-sessmentifitco-occurswithatleasttwopromotedpatternsinthetextcorpus,andifitsco-occurrencecountwithallpromotedpatternsisatleastthreetimesgreaterthanitsco-occurrencecountwithneg-ativepatterns.Candidatepatternsarelteredinthesamemannerusinginstances.Allco-occurrencecountsneededbythelteringstepareobtainedwithanadditionalpassthroughthecorpususingMapReduce.Thisimplementa-tionismuchmoreefcientthanonethatreliesonwebsearchqueries.CBLtypicallyrequiresco-occurrencecountsofatleast10,000instanceswithanyofatleast10,000patterns,whichwouldrequire100millionhitcountqueries.4.2.4CandidateAssessmentNext,foreachpredicateCBLtrainsadiscretizedNaveBayesclassiertoclassifythecandidatein-stances.Itsfeaturesincludepointwisemutualinfor-mation(PMI)scores(Turney,2001)ofthecandidateinstancewitheachofthepositiveandnegativepat-ternsassociatedwiththeclass.Thecurrentsetsofpromotedandnegativeinstancesareusedastrainingexamplesfortheclassier.Attributesarediscretizedbasedoninformationgain(FayyadandIrani,1993).Patternsareassessedusinganestimateofthepre-cisionofeachpatternp:Precision(p)=PiIcount(i,p)count(p)whereIisthesetofpromotedinstancesforthepredicatecurrentlybeingconsidered,count(i,p)istheco-occurrencecountofinstanceiwithpatternp,andcount(p)isthehitcountofthepatternp.Thisisapessimisticestimatebecauseitassumesthattherestoftheoccurrencesofpatternparenotwithpos-itiveexamplesofthepredicate.Wealsopenalizeextremelyrarepatternsbythresholdingthedenomi-natorusingthe25thpercentilecandidatepatternhitcount(McDowellandCafarella,2006).Alloftheco-occurrencecountsneededfortheas-sessmentsteparecollectedinthesameMapReducepassasthoserequiredforlteringcandidates.4.2.5CandidatePromotionCBLthenranksthecandidatesaccordingtotheirassessmentscoresandpromotesatmost100in-stancesand5patternsforeachpredicate.5ExperimentalEvaluationWedesignedourexperimentalevaluationtotrytoanswerthefollowingquestions:CanCBLiteratemanytimesandstillachievehighprecision?Howhelpfularethetypesofcouplingthatweemploy?Canweextendexistingsemanticresources?5.1CongurationsoftheAlgorithmWeranouralgorithminthreecongurations:Full:ThealgorithmasdescribedinSection4.2.NoSharingAmongSame-ArityPredicates(NS):Thiscongurationcouplespredicatesonlyus-ingtype-checkingconstraints.Itusesthefullalgorithm,exceptthatpredicatesofthesamear-itydonotsharepromotedinstancesandpatternswitheachother.Seedinstancesandpatternsareshared,though,soeachpredicatehasasmall,xedpoolofnegativeevidence.NoCategory/Relationcoupling(NCR):Thiscongurationcouplespredicatesusingmutualexclusionandsubsetconstraints,butnottype-checking.Itusesthefullalgorithm,exceptthatrelationinstanceargumentsarenotl-teredorassessedusingtheirspeciedcategories,andargumentsofpromotedrelationsarenotsharedaspromotedinstancesofcategories.Theonlytype-checkinginformationusedisthecom-mon/propernounspecicationsofargumentsforlteringoutimplausibleinstances.5.2InitialontologyOurontologycontainedcategoriesandrelationsre-latedtotwodomains:companiesandsports.Ex-tracategorieswereaddedtoprovidenegativeevi-dencetothedomain-relatedcategories:hobbyforeconomicsector;actor,politician,andscien-tistforathleteandcoach;andboardgameforsport.Table1listseachpredicateintheleftmostcolumn.Categorieswerestartedwith1020seed6

5iterations10iterations15iterationsPredicateFullNSNCRFullNSNCRFullNSNCRActor93100100939710010097100Athlete1001001001009310010073100BoardGame937693892793893093City10010010010097100100100100Coach1006373975343974747Company10010010097909710090100Country604060304327402340EconomicSector776373576767506340Hobby676367404057202330Person979790979397939793Politician939397735390905387Product9787909087100979077ProductType939390707397778067Scientist10090979763979360100Sport10090100936783972790SportsTeam1009710097701009050100CategoryAverage928489827084836379Acquired(Company,Company)777780678047706347CeoOf(Person,Company)9787100908797908083CoachesTeam(Coach,SportsTeam)1001001001001009710010090CompetesIn(Company,Econ.Sector)9797801009367976360CompetesWith(Company,Company)938060777037706043HasOfcesIn(Company,City)979340939027935730HasOperationsIn(Company,Country)10095501009740908313HeadquarteredIn(Company,City)77902070772770607LocatedIn(City,Country)906757635043735030PlaysFor(Athlete,SportsTeam)1001000100977100430PlaysSport(Athlete,Sport)100100279380101004030TeamPlaysSport(SportsTeam,Sport)100100771009780938367Produces(Company,Product)918390839367938057HasType(Product,ProductType)736317336733405727RelationAverage928857848448846642All928674837668846462Table1:Precision(%)foreachpredicate.Resultsarepresentedafter5,10,and15iterations,fortheFull,NoSharing(NS),andNoCategory/RelationCoupling(NCR)congurationsofCBL.NotethatweexpectFullandNCRtoperformsimilarlyforcategories,butforFulltooutperformNCRonrelationsandforFulltooutperformNSonbothcategoriesandrelations.7

instancesand5seedpatterns.Theseedinstanceswerespeciedbyahuman,andtheseedpatternswerederivedfromthegenericpatternsofHearstforeachpredicate(Hearst,1992).Relationswerestartedwithsimilarnumbersofseedinstances,andnoseedpatterns(itislessobvioushowtogener-ategoodseedpatternsfromrelationnames).Mostpredicatesweredeclaredasmutuallyexclusivewithmostothers,exceptforspecialcases(e.g.,hobbyandsport;universityandsportsteam;andhasofcesinandheadquarteredin).5.3CorpusOurtextcorpuswasfroma200-millionpagewebcrawl.WeparsedtheHTML,lteredoutnon-Englishpagesusingastopwordratiothreshold,thenlteredoutwebspamandadultcontentusingabadwordlist.Thepageswerethensegmentedintosen-tences,tokenized,andtaggedwithparts-of-speechusingtheOpenNLPpackage.Finally,welteredthesentencestoeliminatethosethatwerelikelytobenoisyandnotusefulforlearning(e.g.,sentenceswithoutaverb,withoutanylowercasewords,withtoomanywordsthatwereallcapitalletters).Thisyieldedacorpusofroughly514-millionsentences.5.4ExperimentalProcedureWeraneachcongurationfor15iterations.Toeval-uatetheprecisionofpromotedinstances,wesam-pled30instancesfromthepromotedsetforeachpredicateineachcongurationafter5,10,and15it-erations,pooledtogetherthesamplesforeachpred-icate,andthenjudgedtheircorrectness.Thejudgedidnotknowwhichrunaninstancewassampledfrom.Weestimatedtheprecisionofthepromotedinstancesfromeachrunafter5,10,and15itera-tionsasthenumberofcorrectpromotedinstancesdividedbythenumbersampled.Whilesamplesof30instancesdonotproducetightcondenceinter-valsaroundindividualestimates,theyaresufcientfortestingfortheeffectsinwhichweareinterested.5.5ResultsTable1showstheprecisionofeachofthethreeal-gorithmcongurationsforeachcategoryandrela-tionafter5,10,and15iterations.Asisapparentinthistable,fullycoupledtraining(Full)outper-formstrainingwhencouplingisremovedbetweencategoriesandrelations(NCR),andalsowhencou-plingisremovedamongpredicatesofthesamear-ity(NS).Theneteffectissubstantial,asisappar-entfromthebottomrowofTable1,whichshowsthattheprecisionofFulloutperformsNSby6%andNCRby18%aftertherst5iterations,andbyanevenlarger20%and22%after15iterations.Thisincreasinggapinprecisionasiterationsincreasere-ectstheabilityofcoupledlearningtoconstrainthesystemtoreducetheotherwisecommondriftasso-ciatedwithself-trainedclassiers.UsingStudentspairedt-test,wefoundthatforcategories,thedifferenceinperformancebetweenFullandNSisstatisticallysignicantafter5,10,and15iterations(p-value<0.05).2NosignicantdifferencewasfoundbetweenFullandNCRforcat-egories,butthisisnotasurprise,becauseNCRstillusesmutuallyexclusiveandsubsetconstraints.ThesametestndsthatthedifferencesbetweenFullandNSaresignicantforrelationsafter15iterations,andthedifferencesbetweenFullandNCRaresig-nicantafter5,10,and15iterationsforrelations.Theworst-performingcategoriesafter15itera-tionsofFullarecountry,economicsector,andhobby.TheFullcongurationofCBLpromoted1637instancesforcountry,farmorethanthenum-berofcorrectanswers.ManyofthesearegeneralgeographicregionslikeBayeldPeninsulaandBalticRepublics.Inthehobbycase,promotingpatternslikethetypesofarg1ledtothecategorydriftingintoagenerallistofpluralcommonnouns.EconomicsectordriftedintoacademiceldslikeBehavioralScienceandPoliticalSciences.Weexpectthatthelearningofthesecategorieswouldbesignicantlybetteriftherewereevenmorecat-egoriesbeinglearnedtoprovideadditionalnegativeevidenceduringthelteringandassessmentstepsofthealgorithm.Atthisstageofdevelopment,obtaininghighre-callisnotaprioritybecauseourintentistocreateacontinuouslyrunningandcontinuouslyimprovingsystem;itisourhopethathighrecallwillcomewithtime.However,toveryroughlyconveythecom-pletenessofthecurrentresultsweshowinTable2theaveragenumberofinstancespromotedforcate-2Ourselectionofthepairedt-testwasmotivatedbytheworkofSmuckeretal.(2007),buttheWilcoxonsignedranktestgivesthesameresults.8

CategoriesRelationsCongurationInstancesPrec.InstancesPrec.Full9708319184NS13376330766NCR9167945842Table2:Averagenumbersofpromotedcategoryandre-lationinstancesandestimatesoftheirprecisionforeachcongurationofCBLafter15iterations.Figure2:ExtractedfactsfortwocompaniesdiscoveredbyCBLFull.Thesetwocompanieswereextractedbythelearnedcompanyextractor,andtherelationsshownwereextractedbylearnedrelationextractors.goriesandrelationsforeachofthethreecongura-tionsofCBLafter15iterations.Forcategories,notsharingexamplesresultsinfewernegativeexamplesduringthelteringandassessmentsteps.Thisyieldsmorepromotedinstancesonaverage.Forrelations,notusingtypecheckingyieldshigherrelativerecall,butatamuchlowerlevelofprecision.Figure2givesoneviewofthetypeofinformationextractedbythecollectionoflearnedcategoryandrelationclassiers.NotetheinitialseedexamplesprovidedtoCBLdidnotincludeinformationabouteithercompanyoranyoftheserelationinstances.35.6ComparisontoanExistingDatabaseToestimatethecapacityofouralgorithmtocon-tributeadditionalfactstopubliclyavailableseman-ticresources,wecomparedthecompletelistsofin-stancespromotedduringtheFull15iterationrunforcertaincategoriestocorrespondinglistsintheFreebasedatabase(MetawebTechnologies,2009).Excludingthecategoriesthatdidnothaveadi-rectlycorrespondingFreebaselist,wecomputedforeachcategory:Precision|CBLInstances||Matches|,wherePrecisionistheestimatedpre-cisionfromourrandomsampleof30instances,|CBLInstances|isthetotalnumberofinstancespromotedforthatcategory,and|Matches|isthe3Seehttp://rtw.ml.cmu.edu/sslnlp09forre-sultsfromafullrunofthesystem.Est.CBLFreebaseEst.NewCategoryPrec.InstancesMatchesInstancesActor10052246557Athlete1001175463BoardGame8918610City10017991665134Company1001937995942Econ.Sector501541137634Politician9096274792Product97125901221SportsTeam90414139234Sport97613134461Table3:Estimatednumbersofnewinstances(correctinstancespromotedbyCBLintheFull15iterationrunwhichdonothaveamatchinFreebase)andthevaluesusedincalculatingthem.numberofpromotedinstancesthathadanexactmatchinFreebase.Whileexactmatchesmayunder-estimatethenumberofmatches,itshouldbenotedthatratherthanmakedenitiveclaims,ourintenthereissimplytogiveroughestimates,whichareshowninTable3.Theseapproximatenumbersin-dicateapotentialtouseCBLtoextendexistingse-manticresourceslikeFreebase.6ConclusionWehavepresentedamethodofcouplingthesemi-supervisedlearningofcategoriesandrelationsanddemonstratedempiricallythatthecouplingforestallstheproblemofsemanticdriftassociatedwithboot-straplearningmethods.Wesuspectthatlearningadditionalpredicatessimultaneouslywillyieldevenmoreaccuratelearning.Anapproximatecompari-sonwithanexistingrepositoryofsemanticknowl-edge,Freebase,suggeststhatourmethodscancon-tributenewfactstoexistingresources.AcknowledgmentsThisworkissupportedinpartbyDARPA,Google,aYahoo!FellowshiptoAndrewCarlson,andtheBrazilianresearchagencyCNPq.WealsogratefullyacknowledgeJamieCallanformakingavailablehiscollectionofwebpages,Yahoo!foruseoftheirM45computingcluster,andtheanonymousreviewersfortheircomments.9

