Constructing Informative Priors using Transfer Learning

Rajat Raina
Andrew Y. Ng
Daphne Koller
Computer Science Department, Stanford University, CA 94305 USA

rajatr@cs.stanford.edu

ang@cs.stanford.edu

koller@cs.stanford.edu

Abstract

Many applications of supervised learning re-
quire good generalization from limited la-
beled data. In the Bayesian setting, we can
try to achieve this goal by using an informa-
tive prior over the parameters, one that en-
codes useful domain knowledge. Focusing on
logistic regression, we present an algorithm
for automatically constructing a multivariate
Gaussian prior with a full covariance matrix
for a given supervised learning task. This
prior relaxes a commonly used but overly
simplistic independence assumption, and al-
lows parameters to be dependent. The algo-
rithm uses other “similar” learning problems
to estimate the covariance of pairs of indi-
vidual parameters. We then use a semideﬁ-
nite program to combine these estimates and
learn a good prior for the current learning
task. We apply our methods to binary text
classiﬁcation, and demonstrate a 20 to 40%
test error reduction over a commonly used
prior.

1. Introduction

Classical supervised learning algorithms ﬁnd good
classiﬁers for a given learning task using labeled input-
output pairs. When labeled data is limited and expen-
sive to obtain, an attractive alternative is to use other
data sources to improve performance. For example,
semi-supervised learning uses unlabeled data for the
given learning task.
In this paper, we use transfer learning (Baxter, 1997;
Thrun, 1996; Caruana, 1997) to improve performance
on the learning task at hand. Transfer learning
utilizes labeled data from other “similar” learning
tasks. It is inspired by the observation that humans

Appearing in Proceedings of the 23 rd International Con-
ference on Machine Learning, Pittsburgh, PA, 2006. Copy-
right 2006 by the author(s)/owner(s).

do not receive tasks in isolation, but instead receive
a sequence of learning tasks over their lifetimes.
It
appears intuitive that learning a sequence of related
tasks should be easier than learning each of those
tasks in isolation. For example, the visual system
might ﬁnd it easier to recognize a guava if it already
knows how to recognize apples and oranges; it might
be easier to learn French if one already knows English
and Latin. Humans can probably discover some un-
derlying structure in each of these domains, and can
thus learn new but similar tasks quickly and easily.
With this inspiration, we present a transfer learning al-
gorithm that constructs an informative Bayesian prior
for a given learning task. The prior encodes useful do-
main knowledge by capturing underlying dependencies
between the parameters. The next section gives a brief
overview of our approach.

2. Overview

For conciseness and clarity, in this paper we focus on
binary text classiﬁcation, even though our model can
also be applied straightforwardly to other multiclass
classiﬁcation problems. To motivate our algorithm,
let us ﬁrst consider the traditional supervised learning
setting for binary text classiﬁcation.
In this setting, each input X is a text document and
is assigned to a unique output label from the set
{0, 1}. A vocabulary of words W = {w1, w2, . . . , w|W|}
is given, and we assume every input document X
is represented as a “bag-of-words” vector X =
(X1, X2, . . . , X|W|) ∈ {0, 1}|W|, where Xi
is 1 if
word wi occurs in document X and 0 otherwise. A la-
beled training set M = {(x(i), y(i))}m
i=1 is given, and
the task is to predict the label y for a test document x.
A linear classiﬁer for this setting can be deﬁned
using a parameter vector θ = (θ1, θ2, . . . , θ|W|) ∈
R|W|. For example, logistic regression makes predic-
tions according to the rule P (Y = 1|X = x, θ) =

1/(cid:0)1 + exp(−θT x)(cid:1). Each parameter θi thus corre-

sponds to a word wi in the input vocabulary. Us-

Constructing Informative Priors using Transfer Learning

target problem as well. We show that we can use such
cues from auxiliary problems to eﬃciently construct a
covariance matrix that also makes useful predictions
for previously unseen words.
In the sequal, we will ﬁrst describe a method
for estimating a single covariance entry (such as
Cov(θmoon, θrocket)) using auxiliary problems; then,
we show how these individual estimates can be eﬃ-
ciently put together to obtain a complete covariance
matrix Σ for the target problem.

3. Estimating the Covariance between

Word Parameters

`M (θ) = Pm

ing the given training set M , the (discriminative) log-
likelihood of a parameter setting θ can be computed as
i=1 log P (Y = y(i)|X = x(i), θ). To avoid
overﬁtting, usually one assumes a multivariate Gaus-
sian prior N (0, σ2I) on the parameter vector θ (Nigam
et al., 1999), and then ﬁnds the maximum-a-posteriori
(MAP) estimate θMAP by maximizing the (penalized)
log-likelihood of the training set M :

θMAP = arg maxθ(cid:18)`M (θ) −

1
2σ2 ||θ||2

2(cid:19) (1)

When training data is extremely scarce (m << |W|),
the parameter values learnt in this way often produce
poor performance on unseen test data. This is to
be expected from a learning theoretic viewpoint—the
prior distribution is only weakly informative as it as-
sumes that the parameters θi are independent of each
other and have equal prior variance.
However, many classiﬁcation problems naturally dis-
play rich structure in their features. Text documents,
for example, generally use many words drawn from a
small set of topics. Thus, the occurrence of a word
such as moon in a document with label y might make
it more likely that words “similar” to moon (such as
rocket or astronaut) will occur in other documents
with the same label y. Further, there might be sys-
tematic trends making rare words more or less infor-
mative about a document label than common words.
We aim to model these dependencies by placing a more
informative prior over the parameters.
In particu-
lar, we will construct a Gaussian prior N (0, Σ) where
Σ ∈ R|W|×|W| is a (non-diagonal) covariance matrix.
The oﬀ-diagonal entries of the matrix capture depen-
dencies between parameters; further, unequal values
on the diagonal allow the parameters to have diﬀerent
prior variance. For our example, if the prior covariance
between the parameters for moon and rocket is highly
positive, we can infer that rocket supports the label y
even without observing this directly in training data.
As a result, the algorithm can now correctly classify
test documents containing words such as rocket that
may not have occurred in the training set.
In this paper, we present an algorithm for learning
the covariance matrix Σ using other labeled text clas-
siﬁcation problems, which we shall call the auxiliary
learning problems. The original problem (i.e., the one
we ultimately want to perform well on) will henceforth
be called the target problem. For our running exam-
ple, suppose that we observe from auxiliary problems
that the parameters for words moon and rocket are
positively correlated (i.e., in any auxiliary problem,
they typically support the same label when they occur
in a document). On average, these correlations are
likely to provide good guesses for correlations in the

i and Θ∗

i Θ∗

i ] = E[Θ∗

moon and Θ∗

Suppose we want to compute the prior covariance be-
tween the parameters θi and θj of the target problem,
corresponding to words wi and wj in its vocabulary.
Consider building a classiﬁer for an auxiliary problem
C using a random vocabulary that includes words wi
and wj. For this vocabulary, assume that we know
the optimal values for the parameters θi and θj—i.e.,
the values that produce the highest expected log-
likelihood on test data for C. Let these optimal values
be given by the random variables Θ∗
j , where
the randomness is over the choice of the random vo-
cabulary. The covariance of these random variables is
given by E[Θ∗
j ], since the class labels are symmetric
and so E[Θ∗
j ] = 0. We will use this covariance
as a surrogate for the desired prior covariance, and
will estimate the former using labeled data for C. For
our earlier example, Θ∗
rocket might have
similar values for most vocabularies, and thus their
covariance E[Θ∗
rocket] will be highly positive.
Concretely, we estimate the covariance Cov(θi, θj) us-
ing Algorithm 1. The algorithm computes a Monte
Carlo estimate for the expectation in E[Θ∗
j ] by av-
eraging over several vocabularies of a ﬁxed size K > 2.
Since the optimal parameters Θ∗
j are not
known even for the auxiliary problem C, we also sam-
ple several training sets for each vocabulary. This pro-
duces several subproblems, each with a particular vo-
cabulary and training set. For each subproblem, we
use logistic regression with a weak prior to learn the
parameters. With a small vocabulary size (K = 5,
say) the learned parameters should be close to opti-
mal. The sample covariance of these parameters over
all subproblems gives an estimate for E[Θ∗
The procedure described thus far has a drawback. The
expectation in E[Θ∗
j ] should be over the random
choice of vocabulary only; the above procedure, how-
ever, also includes variance due to the random choice
of the training set. It can be shown, for example, that
when we compute variances by this procedure (i = j),
the estimated variance always overestimates the true

i and Θ∗

i Θ∗

i Θ∗
j ].

moonΘ∗

i Θ∗

Constructing Informative Priors using Transfer Learning

variance. To correct for the randomness due to the
choice of the training set, we apply a bootstrap cor-
rection (Efron, 1979) to the above sample covariance.
This correction term subtracts out an estimate for the
covariance due to the choice of training set.

Algorithm 1 Estimate single covariance
Input: Words wi and wj, auxiliary problem C, vo-

cabulary size K.

Return: Estimate ˆΣij for the covariance Cov(θi, θj).

Fix V = number of vocabularies to sample.
Fix T = number of training sets to sample.
for v = 1 to V do

Sample vocabulary V of size K, with wi, wj ∈ V.
for t = 1 to T do

Sample training set T from labeled data for C.
θ(v,t) ← Parameter vector learnt using logistic
regression with vocabulary V on training set T .

end for

end for

− ¯θ(v)

¯θ(v) ← (1/T )Pt θ(v,t)
C (v) ← (1/T )Pt(θ(v,t)
U ← (1/V T )Pv,t θ(v,t)
return ˆΣij = U − (1/V )Pv C (v)

θ(v,t)
j

i

)(θ(v,t)

j

− ¯θ(v)

j

)

i

i

(Sample covariance)

(Bootstrap)

With this algorithm, each estimate can be computed
using O(V T ) calls to a logistic regression routine in the
inner loop; small values of V and T are found to be
suﬃcient (V = T = 4 in our experiments). A similar
algorithm can also be used to estimate the variance
Var(θi) corresponding to a word wi.
As a sanity check for this procedure, we performed
the following experiment: we constructed 10 binary
text classiﬁcation problems using the 20 newsgroups
dataset (Lang, 1995), as described later in Section 5.
We isolated a random target problem (“Motorcycles”
vs. “MS-Windows”), and used the other 9 problems
as auxiliary problems. Table 1 shows the word pairs
from this target problem’s vocabulary whose covari-
ance was found to be the most positive or most nega-
tive when estimated using the auxiliary problems. The
word pairs with the highest positive covariance seem
to be related to similar topics; some of the word pairs
with the most negative covariance also capture some
useful distinctions between the two classes. These re-
lations between words were uncovered without looking
at any labels for the target problem.

4. Constructing the Covariance Matrix

We could try to construct the desired covariance ma-
trix Σ by computing covariance estimates for all word
pairs and putting them together in a matrix. However,
this would pose two major problems:

Table 1. Word pairs from the classiﬁcation problem “Mo-
torcycles” vs. “MS-Windows” estimated to have the most
positive (left) or most negative (right) bootstrap-corrected
parameter covariance using auxiliary learning problems.

Most positive covariance Most negative covariance
insurance mile
mile
rear
mile
honda
brake
gear
printer
meg
wheel
brake
seat
bmw
desktop
ram

wave
air
wave
air
ground
object
battery mouse
low
server

mouse
resource
menu
server
server
ram

1. It may not be feasible to get covariance esti-
mates for all word pairs using the above algo-
rithm. There might be previously unseen words—
if a word pair has never been seen in any auxil-
iary problem data, Algorithm 1 cannot produce
meaningful estimates for the parameter covari-
ance. Further, the total number of covariance es-
timates needed would grow quadratically with the
size of the vocabulary. For large vocabularies, this
becomes computationally impractical.

2. A valid covariance matrix must be positive
semideﬁnite (PSD). However, our covariance esti-
mates will invariably have noise, and might arise
from diﬀerent auxiliary problems;
the matrix
formed by these estimates need not be PSD.

4.1. Learning Individual Covariances

To address the ﬁrst problem, instead of learning the
entries themselves, we propose to learn general trans-
formations that generate these entries. In particular,
we model covariance between a pair of parameters as
a function of features of the corresponding word pair.
For example, a feature of a word pair might check if
these words are synonyms—if they are, there might
be a high covariance between their parameters. Given
such features, we can estimate a small fraction of the
covariances directly using the auxiliary learning prob-
lems, and then learn a general transformation of the
features that allows us to approximate all the missing
entries in the covariance matrix. As we show later in
the results section, a small number of simple features
are suﬃcient to ensure good performance.
More formally, suppose we extract a feature vector
Fij ∈ RS for each matrix position (i, j), such that ev-
ery element of Fij is a feature of the word pair (wi, wj)
and the vocabulary W. For example, a particular el-
ement of Fij might be 1 if wi and wj are synonyms,
and 0 otherwise. We then approximate each entry in

Constructing Informative Priors using Transfer Learning

the covariance matrix as a linear function of the corre-
sponding feature vector—i.e., given a suitable param-
eter vector ψ ∈ RS, we construct a candidate matrix
ˆΣ by computing its (i, j)th element as follows:

ˆΣij = ψT Fij

(2)

now present
Deﬁne

an
the

If synonyms generally have parameters with highly
positive covariance, we would want features such as
the “synonym-check” feature to have a highly positive
corresponding weight in the parameter vector ψ. The
features we used are described in Section 4.4.
learn-
We
algorithm for
|
ing ψ.
Cov(θi, θj) was directly estimated},
eij
be the value of the covariance estimate for position
(i, j) ∈ G. Given these “desired” values eij for some
entries in the covariance matrix, ψ might be learnt as
a small supervised learning task—we could pick ψ so
that the values ˆΣij generated using Equation (2) are
as “close” as possible to the available desired values
eij. For example, linear regression would minimize
the following squared-error criterion:

set G = {(i, j)
and let

min

ψ X(i,j)∈G

(eij − ψT Fij)2

(3)

Once ψ has been chosen, the candidate matrix ˆΣ can
be ﬁlled in using Equation (2).

4.2. Learning a Positive Semideﬁnite Matrix

The above method may learn useful patterns, but the
ﬁnal matrix ˆΣ may still not be PSD. We could project
ˆΣ onto the PSD cone to obtain the closest valid covari-
ance matrix; however, ˆΣ often turns out to be highly
indeﬁnite, and so the projected matrix is “far” from
the matrix ˆΣ originally learnt through the parameters
ψ. This makes the earlier method of learning ψ unsat-
isfactory, since the ﬁnal PSD projection is oblivious to
any underlying preferences and might “unlearn” some
of the patterns learnt through the parameters ψ.
It turns out that this sequential procedure (i.e., ﬁrst
learn ψ, then ﬁnd closest PSD matrix) is unnecessary.
We can learn good values for ψ while also consider-
ing the ﬁnal PSD constraint. If Σ is the ﬁnal covari-
ance matrix produced, we make the PSD constraint ex-
plicit by posing the following joint optimization prob-
lem over variables ψ and Σ:

min

ψ,Σ X(i,j)∈G

(eij − ψT Fij)2 + λXi,j

(Σij − ψT Fij)2

(4)

s.t. Σ (cid:23) 0

where Σij denotes the (i, j)th element of matrix Σ.
The objective function provides a trade-oﬀ between

two diﬀerent goals. The ﬁrst term encourages ψ to
better approximate the available covariance estimates
eij, as in Equation (3); the second term encourages ψ
to generate a matrix close to a PSD matrix Σ. The
positive number λ controls the relative importance as-
signed to these two terms. For example, in the limit
of λ → 0, this becomes equivalent to the previous se-
quential method.
Importantly, the optimization problem in (4) is convex
jointly in ψ and Σ, and thus possesses a unique global
optimum over these variables. In fact, the problem can
be written as a semideﬁnite program (SDP), and can
be solved directly using standard SDP solvers.
However, an even more scalable method for optimiza-
tion can be derived using alternating minimization
over the variables ψ and Σ. This procedure consists
of two alternating steps, repeated until convergence.
First, keep Σ ﬁxed and optimize the objective function
in (4) only over ψ; this problem reduces to a QP
similar to (3) and can be solved with a fast QP solver.
Then, ﬁx ψ and optimize the objective only over Σ;
this problem reduces to minimizing only the second
term in the objective, subject to the PSD constraint.
This is a particularly simple SDP—it involves project-
ing the matrix formed by ψT Fij onto the PSD cone,
which can be done eﬃciently by ﬁnding its eigen-
decomposition and taking only the components with
nonnegative eigenvalues. All of these steps can be per-
formed eﬃciently for large problems. This alternating
optimization method is guaranteed to converge to the
global minimum since the objective function is convex.

4.3. Algorithm Details

The matrix Σ generated using the SDP (4) nicely cap-
tures the relative magnitudes of the covariances, but
does not adequately capture their absolute scale. This
is to be expected because the covariance entries were
estimated on auxiliary problems with a ﬁxed small vo-
cabulary size (K = 5 in our case), whereas the tar-
get problem generally uses a diﬀerent, larger vocabu-
lary size where the parameters might have diﬀerently
scaled magnitudes. We thus allow a single scaling pa-
rameter q, and use qΣ as the ﬁnal covariance matrix
in the prior. The ﬁnal results are fairly insensitive to
the exact value of this scaling parameter, as long as it
has the right order of magnitude. In practice, simply
hard-coding a single (training set size speciﬁc) value
of q for all problems leads to only minor diﬀerences in
the ﬁnal results. We will later describe a method to
learn q from auxiliary data.
Algorithm 2 summarizes the complete method for es-
timating a covariance matrix for a target problem.

Constructing Informative Priors using Transfer Learning

Table 2. List of feature functions used. The left half shows features for a single word wi, for the diagonal entries of
the covariance matrix. The right half shows features for a word pair (wi, wj), for the oﬀ-diagonal entries. Σnemp is a
normalized empirical co-occurrence matrix, estimated from a large English corpus. Σlowrank = minA ||A − Σnemp||F , where
the minimization is over all W × W matrices of rank at most W/5. Σlowrank can be eﬃciently computed using an SVD.

Constant (always 1)
(i, i)th element of Σr
(i, i)th element of Σlowrank
Raw frequency of occurrence
Log transformed frequency of occurrence Distributional similarity score computed by Infomap

Constant (always 1)
(i, j)th element of Σr
(i, j)th element of Σlowrank
Raw frequency of co-occurrence, log transform

for r = 1, 2, 3

nemp

for r = 2, 3

nemp

Check if words are synonyms or hypernyms using WordNet

Algorithm 2 Estimate covariance matrix
Input: Target vocabulary W, set of auxiliary prob-

lems C.

Return: Covariance matrix Σ for a Gaussian prior.

Fix S = number of covariance entries to estimate
directly using auxiliary problems.
Initialize G = {}.
for s = 1 to S do

Pick a word pair wi, wj from vocabulary W, such
that wi, wj ∈ some auxiliary problem C ∈ C.
G ← G ∪ (i, j).
eij ← Cov estimate using C for (θi, θj). (Alg. 1)

end for
Compute all feature vectors Fij (1 ≤ i, j ≤ |W|).
ΣSDP ← Optimal Σ for SDP (4).
Pick scaling parameter q (or set to default value).
return Σ = qΣSDP

4.4. Features Used

We used two diﬀerent parameters ψ1 and ψ2 to con-
struct the diagonal and oﬀ-diagonal entries of the co-
variance matrix; this is natural as diﬀerent features are
useful in these two cases. The joint optimization prob-
lem (4) can be used with minor changes. The features
used for diagonal and oﬀ-diagonal entries are listed
in Table 2. Most features used a normalized empirical
word co-occurence matrix derived from a large English
corpus:
if the empirical word co-occurence matrix is
Σemp, we used the matrix Σnemp = D−1/2ΣempD−1/2
where D is a diagonal matrix of the same size as Σemp
with each diagonal entry containing the correspond-
ing row-sum from Σemp.1 We used higher powers of
this co-occurence matrix and low-rank approximations
to it, as they might capture higher-order word corre-
lations beyond simple co-occurence (e.g., astronaut
co-occurs often with moon, which co-occurs often with
cosmonaut; but astronaut and cosmonaut might co-
occur very rarely). To provide basic linguistic fea-

1This matrix is often called the normalized Laplacian

in spectral graph theory (Chung, 1997; Ng et al., 2002).

tures, we used a distributional similarity score com-
puted by Infomap (http://infomap.stanford.edu)
and checked if the words are related as synonyms or
hypernyms in WordNet (Miller, 1995).

5. Data and Methods

We used the standard 20 newsgroups dataset (Lang,
1995). This dataset contains documents from 20
document classes, each derived from postings to a
separate newsgroup. The text data was preprocessed
by stemming and removing stopwords. The news-
group classes were randomly paired to construct 10
binary classiﬁcation problems. The vocabulary for
each of these classiﬁcation problems was constructed
by picking the 250 most frequent words from each
constituent newsgroup.
To construct a transfer
learning setup, we conducted the following hold-out
experiment using these 10 classiﬁcation problems:
each of the 10 problems was in turn treated as the
target problem, and the remaining 9 were considered
auxiliary problems; in each case, covariance estimates
were generated from the auxiliary problems using
Algorithm 1 and were used to solve the SDP for the
held-out target problem.2 This produced a covariance
matrix ΣP,SDP for every held-out problem P . A scal-
ing parameter was chosen, and the test error on P was
then evaluated with the learnt prior using training sets
of diﬀerent sizes drawn from the labeled data for P .
For the sake of reproducibility, we describe the proce-
dure used to pick q in the remainder of this section.
Note that cross-validation on the target problem is not
a practical procedure to pick q here, as it would not
work well with very limited training data. The de-
scription below involves several details and the reader
can skip to the next section without loss of continuity.

2For each target problem, we used the auxiliary prob-
lems to estimate about 75% of the diagonal entries and 20%
of the oﬀ-diagonal entries. About 25% of the words in each
target vocabulary do not occur in any auxiliary problem,
and are “novel.” For the QP, we used the SeDuMi (http://
sedumi.mcmaster.ca) and Yalmip (http://control.ee.
ethz.ch/~joloef/yalmip.php) packages for Matlab.

Constructing Informative Priors using Transfer Learning

For our hold-out experiment, we estimate q using the
auxiliary problems. In general, suppose we have access
to a set of auxiliary problems A to estimate the scaling
parameter for target problem P with a ﬁxed training
set size m, and that a covariance matrix ΣC,SDP has
already been computed by solving the SDP (4) for ev-
ery C ∈ A. For any single auxiliary problem C ∈ A,
we deﬁne a “goodness” function gC(q) for scaling pa-
rameter q as EM,T `T (θMAP(q, M )), where the expecta-
tion is over the random choice of labeled test example
T = (x, y) and labeled training set M of size m drawn
from the labeled data for C; `T (·) is the log-likelihood
function as in Section 2; and θMAP(q, M ) is the MAP
estimate for θ using training set M and the prior
N (0, qΣC,SDP). The expectation can be computed by
averaging over several training sets and test examples
from the labeled data for C, solving a MAP problem
for each sampled training set. Then, for target prob-
lem P , we can deﬁne the overall goodness GP,A(q) of

scaling parameter q as GP,A(q) = PC∈A gC(q). With

this deﬁnition, we pick q = qFINAL for target problem
P as a local maximum of this overall goodness func-
tion GP,A(·) by performing a local search using multi-
plicative coordinate-ascent. Then, the prior covariance
matrix actually used for problem P is qFINALΣP,SDP.
Note that ΣC,SDP must be computed above for all
C ∈ A without using any labeled data for P , as we are
constructing the prior for P itself. Thus, we compute
ΣC,SDP for C ∈ A using covariance estimates from
all available problems except P (i.e., all problems in
A − {C}). For the whole hold-out process, it is suﬃ-
cient to precompute 100 diﬀerent covariance matrices:
one each for each problem leaving out estimates from
none or one of the other problems. In this way, no la-
beled data for the target problem is used for estimating
q. Later, we also present results using the same ﬁxed
value of q for a large number of target problems.

6. Experiments

We compare our algorithm against a baseline that uses
a uniform diagonal prior; for fairness, we also allow a
scaling parameter on this baseline prior, and choose
it by adapting the exact procedure that was used to
choose the scaling parameter for the SDP-generated
covariance matrices. To verify the advantage of us-
ing a non-diagonal covariance matrix, we also solved
Equation (4) constraining Σ to be diagonal.
Figure 1(a-j) shows our test error results.
The
SDP-generated matrices produce lower average test
error than baseline over the full range of training set
sizes; they reduced error by 20-40% over the baseline
and continue to be better than baseline even for a
training set of 100 documents. The SDP-generated

diagonal covariance matrix performs only marginally
better than baseline, showing that the oﬀ-diagonal
entries capture crucial dependencies.
To graphically examine the ﬁnal covariance matrices,
we performed the following experiment: For each
classiﬁcation task, we used all the available training
data to estimate the 50 “most informative” words per
class. We picked the words with the highest weighted
pointwise mutual information (WPMI) with each class
label.3 For example, for the classiﬁcation problem
“Motorcycles” vs. “MS-Windows”, words such as
bike, ride and bmw were chosen for the “Motorcy-
cles” class, while words such as version, file and
program were chosen for the “MS-Windows” class.
From the full covariance matrix, we extracted the
rows and columns corresponding to these words only,
and formed a matrix so that all words picked from a
class are together. Figure 1(k) shows this matrix, with
brighter positions representing higher values. A rough
block structure is evident, with words informative of
the same class being assigned higher positive covari-
ance on average. This demonstrates that the learnt
prior is able to discover good word dependencies.
Several authors have noted that transfer learning can
sometimes lower performance on the target problem
(e.g., Caruana, 1997). Negative transfer was not ob-
served on the 20 newsgroups dataset. We expect per-
formance to depend strongly on the “relatedness” of
the auxiliary problems to the target problem. Ta-
ble 3 lists the classiﬁcation problems that achieved the
highest or lowest boost in performance due to trans-
fer learning (as measured by percentage test error re-
duction over the diagonal covariance baseline). The
two classiﬁcation problems that achieved least transfer
(bottom two rows) present ambiguity somewhat dif-
ferent from that in the auxiliary problems—for exam-
ple, the parameters for the words code and computer
are positively correlated in the general 20 newsgroups
dataset, but should probably have negative prior co-
variance for the task “Cryptography” vs. “Graphics.”
Finally, we tested transfer to an entirely diﬀerent
dataset. We created 50 random text classiﬁcation
problems using webpages under the DMOZ Open Di-
rectory Project hierarchy,4 with 10 problems each from
the Arts, Business, Health, Recreation and Sports cat-

3The WPMI between word wi and label k is deﬁned as:

P (wi occurs, label is k)
P (wi occurs)P (label is k)

P (wi occurs, label is k) log2
where the probabilities are over the choice of a random
document from the dataset. Note that maximizing mutual
information between the involved random variables would
not give label-speciﬁc words; maximizing pointwise mutual
information alone would be similarly unsatisfactory as it
would generally prefer very rare words.

4http://dmoz.org

Constructing Informative Priors using Transfer Learning

Motorcycles  vs  MS−Windows  

Baseball  vs  Politics.misc  

Religion  vs  Politics.guns  

r
o
r
r
e
 
t
s
e
T

r
o
r
r
e
 
t
s
e
T

r
o
r
r
e
 
t
s
e
T

r
o
r
r
e
 
t
s
e
T

0.4

0.3

0.2

0.1

0

0.4

0.3

0.2

0.1

0

0.4

0.3

0.2

0.1

0

0.4

0.3

0.2

0.1

0

 2 

 2 

 2 

 2 

r
o
r
r
e
 
t
s
e
T

r
o
r
r
e
 
t
s
e
T

r
o
r
r
e
 
t
s
e
T

0.4

0.3

0.2

0.1

0

0.4

0.3

0.2

0.1

0

0.4

0.3

0.2

0.1

0

 2 

 2 

 2 

 4 

 6 

 10

 20

Size of training set

 50

100

(a)

Atheism  vs  Autos           

 4 

 6 

 10

 20

Size of training set

 50

100

(d)

Christian  vs  Hockey        

 4 

 6 

 10

 20

Size of training set

 50

100

 4 

 6 

 10

 20

Size of training set

 50

100

(b)

IBM.hardware  vs  Forsale    

 4 

 6 

 10

 20

Size of training set

 50

100

(e)

Space  vs  MAC.hardware      

 4 

 6 

 10

 20

Size of training set

 50

100

r
o
r
r
e
 
t
s
e
T

r
o
r
r
e
 
t
s
e
T

r
o
r
r
e
 
t
s
e
T

0.4

0.3

0.2

0.1

0

0.4

0.3

0.2

0.1

0

0.4

0.3

0.2

0.1

0

 2 

 2 

 2 

 4 

 6 

 10

 20

Size of training set

 50

100

(c)

Politics.mideast  vs  Sci.med

 4 

 6 

 10

 20

Size of training set

 50

100

(f)

Windows.x  vs  Electronics   

 4 

 6 

 10

 20

Size of training set

 50

100

(g)

Sci.crypt  vs  Comp.graphics 

(h)

(i)

Webpage classification

r
o
r
r
e
 
t
s
e
t
 
e
g
a
r
e
v
A

0.35

0.3

0.25

0.2

0.15

0.1

10%

19%

15%

12%

15%

  Health  

  Sports   Recreation  Business 

   Arts   

 50

100

 4 

 6 

 10

 20

Size of training set

(j)

(k)

(l)

Figure 1. (a-j) 20 newsgroups results. Training set size is plotted on a log-scale. Each plot shows test error for a target
problem for varying training set size. Blue circles are for our SDP-based method, green triangles for SDP with the
diagonal covariance constraint, red stars for the baseline diagonal prior. [Colors where available.] (k) Graphical depiction
of an SDP-generated covariance matrix.[See text.] (l) Performance on a DMOZ webpage classiﬁcation task using the 20
newsgroups dataset as auxiliary data. Each group represents the average over 10 problems from a DMOZ subcategory;
the subcategories are sorted from left to right in increasing order of fraction of direct covariance estimates used. (E.g.,
Health:1.1%, Arts:2.8%.) The black bars represent average test error for the uniform diagonal covariance baseline; the gray
bars are for the SDP-generated covariance matrices. The avg % error reduction over baseline is listed per subcategory.

Constructing Informative Priors using Transfer Learning

Table 3. Classiﬁcation tasks achieving the most (top two
rows) and least (bottom two rows) boost in performance
because of the transfer learning setup.

Most transfer

Least transfer

Christian vs. Hockey
Atheism vs. Autos
IBM.hardware vs. Forsale
Sci.crypt vs. Comp.graphics

egories. For each classiﬁcation problem, we used a
vocabulary of 400 words and a training set of 10 doc-
uments. Using the 20 newsgroups dataset as auxiliary
data, we estimated only 1-3% of all covariance entries
using Algorithm 1, and solved the SDP (4) to ﬁll in
the covariance matrix. We ﬁxed the scaling parame-
ter q to the average value from the earlier experiments
(q = 3). Figure 1(l) shows the test error for problems
within each subcategory, averaged over the 10 prob-
lems and several training sets for each problem. The
full covariance matrix reduces test error substantially
over the baseline; the error reduction is higher when
more covariance estimates are used.

7. Related Work

The initial foundations for transfer learning were laid
by Thrun (1996), Caruana (1997) and Baxter (1997),
among others. Several authors have since provided
theoretical
justiﬁcation for transfer learning (Ben-
David & Schuller, 2003; Ando & Zhang, 2005).
In this paper, we have presented an algorithm for
constructing the covariance matrix for an informative
Gaussian prior. The algorithm uses other “similar”
learning problems to learn a good underlying map-
ping from word pair features to word parameter co-
variances. Ando & Zhang (2005) use a diﬀerent setup
to learn the properties of good classiﬁers from multiple
learning tasks.
A diﬀerent hierarchical Bayesian viewpoint might as-
sume that the auxiliary learning problems arise from
the same prior distribution as the target problem. In
that setting, the prior covariance matrix is a hyperpa-
rameter in the model, and can be learnt using auxiliary
learning problems. To deal with novel words, such a
method could pose a generative model using hyper-
parameters (similar to our ψ parameters), and learn
them instead. Several authors have used hierarchical
Bayesian modeling to propose multi-task learning al-
gorithms. For example, Lawrence & Platt (2004) and
Yu et al. (2005) use multiple learning problems to learn
the parameters of a Gaussian process.
The proposed algorithm shows promising transfer
learning results using a small number of auxiliary prob-

lems. It is possible to transfer “knowledge” from news-
group data to webpage data; this opens the possibility
of training a single generic covariance matrix for fre-
quently used English words, and then reusing it on
a broad class of English text classiﬁcation problems.
Also, while our experiments have focused on text data,
similar models can be used in other classiﬁcation set-
tings where correlations between individual parame-
ters are likely, and can be usefully predicted by ob-
servable features of the parameters.

Acknowledgments

We give warm thanks to Chuong Do for providing
the DMOZ data, and Penka Markova for useful com-
ments. This work was supported by the DARPA trans-
fer learning program under contract number FA8750-
05-2-0249.

References

Ando, R. K., & Zhang, T. (2005). A framework for
learning predictive structures from multiple tasks
and unlabeled data. Journal of Machine Learning
Research, 6, 1817–1853.

Baxter, J. (1997). A bayesian/information theoretic
model of learning to learn via multiple task sam-
pling. Machine Learning, 28, 7–39.

Ben-David, S., & Schuller, R. (2003). Exploiting task

relatedness for multiple task learning. COLT.

Caruana, R. (1997). Multitask learning. Machine

Learning, 28, 41–75.

Chung, F. (1997). Spectral graph theory. Regional
Conference Series in Mathematics, American Math-
ematical Society, 92, 1–212.

Efron, B. (1979). Bootstrap methods: Another look
at the jackknife. In The Annals of Statistics, vol. 7,
1–26.

Lang, K. (1995). Newsweeder:

learning to ﬁlter net-

news. ICML.

Lawrence, N. D., & Platt, J. C. (2004). Learning to
learn with the informative vector machine. ICML.

Miller, G. A. (1995). Wordnet: A lexical database for

English. Commun. ACM, 38, 39–41.

Ng, A. Y., Jordan, M., & Weiss, Y. (2002). On spectral

clustering: Analysis and an algorithm. NIPS.

Nigam, K., Laﬀerty, J., & McCallum, A. (1999). Us-
ing maximum entropy for text classiﬁcation.
IJ-
CAI Workshop on Machine Learning for Informa-
tion Filtering.

Thrun, S. (1996). Is learning the n-th thing any easier

than learning the ﬁrst? NIPS.

Yu, K., Tresp, V., & Schwaighofer, A. (2005). Learning

gaussian processes from multiple tasks. ICML.

