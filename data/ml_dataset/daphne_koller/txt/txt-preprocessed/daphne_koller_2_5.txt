Abstract

in

methods

such as like

and further

the special

networks,

and are the

is observed
over

algorithms

simulation

to posterior

probabilities

characteristics

often give fast, accurate

trials  diverge  further

networks
stochastic

simulation
In essence,

simulation
observed

that standard
very poorly.

we present
that use the evidence

Stochastic
lihood weighting
approximations
probabilistic
of choice for very large networks.
Unfor
of dy
tunately,
namic probabilistic
(DPNs),
which
temporal
are used to represent
pro
algo
cesses,  mean
rithms perform
the
simulation
from reality
as the process
time. In this  paper,
algorithms
at
each time step to push the set of trials
back
towards
reality.
dence reversal"
slice of the DPN so that the evidence  nodes
for the slice  become  ancestors
variables.
vival of the fittest"
ulates"
ing a stochastic
by the likelihood
to each trial.
of each algorithm
with likelihood
on the original  network,
the benefits
the ER and SOF
methods.
to maintain
number of time steps in the simulation.

The ER/SOF combination
of the

We compare the performance

of the state
called

The second algorithm,

and also investigate

(ER) restructures
each time

error independent

reproduction

the set of trials

of combining

rate weighted

at each time step us

(SOF), "repop

weighting

sampling

bounded

appears

"sur

of the evidence  according

The first  algorithm,  "evi

1  Introduction

networks

1989; Nicholson

Dynamic probabilistic
Kanazawa,
1992) are a species
stochastic
a section  of

the network

temporal

of belief

called

and Brady, 1992; Kjaerulff,
network

designed

to model
They do so by using
a time slice to repre-

processes.1

or DPNs (Dean and

1 Alternative

terms include
networks.

temporal

belief

dynamic belief

networks
and

The

structure

of a sequence

time slice

of the evolving

probability
tables

t are connected

to nodes in time slice

process.
where nodes

temporal
of time slices

sent a snapshot
DPN consists
within
t  + 1 as well as to other nodes within slice t. Figure
shows the coarse
ditional
model, which describes
a state evolution
tion probabilities
between
which describes
a given state.
in each slice do not vary over
eters therefore
the network.

and a sensor m odel,
that can result
from
that the CPTs
time. The same param
in every time slice in

1
DPN. The con

of a generic
(CPTs) for a DPN include

the observations

will be duplicated

Typically,

one assumes

the transi

states,

STATE EVOLUTION MODEl.

SENSOR MODEL.

Figure 1: Generic
network.
and sensor

In an actual

variables

structure
network,

in each time slice.

of a dynamic

probabilistic

there may be many state

When deci

possible

They can be used

They can be used

a partially

observable

system-for

of the observed

decision-making

future evolutions
into the future.

ex
and Brady used a DPN to track mov

DPNs serve a number of purposes.
for monitoring
ample, Nicholson
ing robots using light beam sensors.
to project
system by adding slices
sion nodes are added, they enable approximately
tional
and Shachter,
surveillance
autonomous
per, we concentrate
i.e., maintaining
possible
states
decision
pends on this distribution
is also an essential
makers.

(Huang et al., 1994) and for controlling
vehicle

(Forbes et al., 1995). In this  pa
on the use ofDPNs for monitoring,

environment
1965), monitoring

1990). We have used them for freeway

current
in any partially

observable
(Astrom,

of the world. Since the  correct

distribution

a probability

with a limited

of embedded

component

decision

horizon

(Tatman

over the

ra

de

an

Exact clustering

algorithms

for DPNs are described by

Stochastic

simulation

algorithms for

dynamic probabilistic

networks 347

procedure LIKELIHOOD-

WEIGHTING{)

loop for i =  1 . . .  N

w., t--1.0

loop for t :::: 0 . . .  T

Instantiate Et
loop for i =  1 . . .  N

Add sample of Xt to s;
Ws; t--Ws; X  Likelihood(Et
Add w., to score for sampled values of Xt

I s;)

Figure 2: The Likelihood

Weighting algorithm.

is fairly

the difficulty.

to the state evolu

evolved according

trajec
to the sample distribution.

face. Suppose that the state evolution  model
weak-for example, it models the motion as a random
walk-but that the sensor is fairly accurate with a very
small Gaussian error. Figure 3 illustrates
The samples are
tion model, spreading out randomly over the surface,
whereas the object moves along some particular
tory that is unrelated
The
weighting
process will assign extremely low weights to
almost all of the samples because they disagree with
the sensor  observations.
will be dominated by a very small number of sam
ples that are closest to the true state, so the effective
number of samples diminishes
results in large estimation
spite the fact that the sensors
with
almost no error! In the case of traffic surveillance,
have discovered
of likelihood
weighting  results
imaginary traffic scenes that bear almost no relation
to what is actually happening on the road.

in a large number of more or less

that a naive application

rapidly over time.  This

errors. All this occurs de

can track the object

The estimated distribution

we

for CG distribu

are included,

requirements

our applications,

and Wermuth, 1989). Hence, exact

are not available.
the use of stochastic

we have found
approach is too expensive
and that
are not needed. Furthermore,
when
DPNs seldom con

Kjaerulff (1992).  In
that the clustering
exact probabilities
continuous
variables
form to the structural
tions (Lauritzen
algorithms
vestigated
which often provide fast approximations
quired probabilities
combinations
of discrete
In the context of DPNs, stochastic simulation
meth
ods attempt to  approximate
the current state using a collection
alities,"
environment.

for
of "simulated
re
one possible evolution
of the

each describing

and continuous

We have therefore  in
algorithms,
simulation
to the re

and can be used with arbitrary

the joint distribution

distributions.

the network, beginning with the root

The simplest simulation algorithm is logic sam
pling (Henrion, 1988). Logic sampling stochastically
instantiates
nodes and using the appropriate
tions  to
Because logic sampling discards trials whenever a vari
able instantiation
it
is likely to be ineffective
where evidence is observed throughout the temporal
sequence.2

distribu
conditional
through the network.

conflicts with observed  evidence,

extend the instantiation

in DPN-based monitoring

of interest

each trial

weighting

on variables

weighting

with evidence,

it assigns to the ob

by the probability
Probabilities

(LW) (Fung and Chang, 1989;
Likelihood
Shachter and Peot, 1989) attempts to overcome this
general problem with logic sampling. Rather than dis
carding trials that conflict
is weighted
served evidence.
by taking a weighted average of
can then be calculated
of trials. It can
the values generated in the population
be shown that likelihood
produces an unbi
ased estimate of the required probabilities.
The LW
algorithm,
which we have adapted for the purposes of
maintaining
beliefs in a DPN as evidence arrives over
time, is shown in Figure 2. We use the notation Et to
for time slice t, and Xt
denote the evidence variables
to denote the  state
variables
for time slice t. N is the
number of samples to be generated, s; is the ith sam
ple, w8, is its weight, and Tis the number of time steps
for which the simulation
denotes the product of the individual
abilities
for the evidence in E given the sampled values
for their parents in s. At each time slice, the current
belief for Xt is calculated
as the normalized score
the whole  sample
set.
The use of likelihood
problems that require special treatment.
is that a straightforward
simu
application
lations that simply ignore the observed evidence and
therefore
simple example:  tracking  a

become increasingly

moving dot on a 2-D sur-

conditional
prob

irrelevant.

The difficulty

generates

weighting

Consider a

from

in DPNs reveals  some

the other hand, logic sampling is extremely
effec
because no evidence is observed in fu

tive for projection,
ture slices.

is to be run. Likelihood(Ejs)

problem. An object

Figure 3: A simple 2-D monitoring
starts in the centre of the disc and follows the path shown
by the solid line. Sensor observations
The small circles
ples generated
ing. Snapshots for t = 2 and t = 7 are shown.

of sam
show a snapshot of the population
of likelihood
weight

by a naive application

are shown by crosses.

to reposition

we need  algorithms

that use the current sen
the sample population

Clearly,
sor  values
to reality rather than allowing them to evolve as if
no sensor values were available.
a simple method (evidence
the DPN so that likelihood
effect. Section 3 describes
of the fittest)

reversaQ
weighting has the desired
a related method (survival

that uses the likelihood

for restructuring

Section 2 describes

weights to prefer-

closer

348 Kanazawa, Koller, and Russell

propagate

entially
how this can be combined
tion 4 describes
techniques

with naive LW.

the most likely

samples,

and shows

an experimental

with evidence

Sec
comparison

reversal.
of these

position

readings

observed
sensor
model in the conditional
the new samples.

will dominate

of the object because  the

accurate

the weak state evolution
for generating

distribution

2  Evidence reversal

3  Survival of the fittest

are a constrained  resource,

in a

the prob

contains

The samples

of sampling

simulation

off into totally

This explains

are quite effective

but is not directly

joint distribution

problem (where evidence

We can force the evidence

the appeal of logic sampling

and Luby, 1993). The same argu

with the naive application

applicable
is obtained

al
no
if the network

is at the root nodes,
in the rest of the network

can also be viewed as one of resource
allo
and
in the state space to try to "fit" the
as well as possible.

It has long been known that stochastic
gorithms
evidence  (Dagum
ment can be used to show that if all the evidence
approximating
network
abilities
tractable.
for projection,
monitoring
every time slice).
the root  nodes
the arcs using  Shachter's
DPN results
doing this to ann-slice
blowup.
selected
In the specific
of the fact that each sample,
ables in time slice t - 1, d-separates
slices  from
the arcs within slice t, so that the evidence
the state at t - 1 become the parents
timet. This is shown in schematic

The problem
algorithms
cation.
should be allocated
actual
that have wandered
is computationally
should not be propagated,
enough to the estimation
The idea of survival-of-the-fittest
forward
preferentially
that have high likelihood
The SOF process
but generates
a weighted
t -1, where the weight is given by the likelihood
evidence
to the use of fitness-related
gorithms
randomized
and Vazirani,

at time t. This idea is closely
al
method used in

case of DPNs, we can take advantage
once it instantiates

in an exponential
we can do some judiciously

at t and
of the state at
form in Figure 4.

As a compromise,
arc reversals

(SOF) sampling
in time those samples

and the sample-repositioning

at time
for the
related

the state at timet. We then simply reverse

keeps a fixed number of samples,

the sample population
for time slice
t by

since they do not contribute
of the desired

simply by reversing  all

transformations,

"go with the winners"

random selection

by Fung and Chang.

for the observed

propagation

from the samples

all preceding

as suggested

to the
for

algorithms

of any network

evidence.

propagate

vari
time

in genetic

observed

as a slice

Samples

(Aldous

1994).

(1986)

to be at

can also be understood
Rather than us

but

is to

imaginary scenarios

probabilities.

..

process.
an approximation
over the entire (multi

to the

we only use them to propagate
over the
joint probability

distribution

the be

one time slice to the next. More precisely,
samples

at time t - 1 are an approxima

state at time t -1. We can then use
point for
belief state
at the next time slice.
to its weight,

That is, we sample
as  defined

as our starting

by our

weighting

likelihood

to provide
distribution

The SOF approach
by-slice
ing the samples
joint probability
network,
slice)
lief state-the
state-from
the weighted
tion to the belief
that approximate
the sampling
each state according
current
are in turn weighted using
provide
Note that the probability
time t is given just by the likelihood
at timet, and not by the accumulated
evidence
case in standard
the sample population
flects
of preferential
Figure

samples.
the evidence
of the belief
of sampling

up to and including
likelihood

an approximation

up to timet -1 through

propagation.

(likelihood

the evidence

weighted)

5.

These samples
at time t ,  and
state at time t.
a given state at
for the evidence
likelihood

for all
time t (as would be the

weighting).

This is because

at timet -1 in SOF already re

The algorithm

the process
is shown in

over likeli

provides

in general,

but does not take advan

some improvement

SOF clearly
hood weighting
tage of the sensor values in quite the same way as
SOF
ER. In the context
will multiply
the samples
so that almost the entire
sonable"
entire surface.
However,

of "rea
and will never spread out over the
will spread out

closest
population

of the 2-D tracking

the samples

problem,

consists

samples

to the actual track

Figure 4: Schematic diagram of the evidence reversal
transformation

for DBNs.

is then as follows.

The process
we have some number k of fully specified
with their weights.

For each time slice,

states

along

1. Reverse

the arcs from evidence

to state at timet;

the state variables
of the evidence

at timet.

at time t - 1 are now parents

2. Use the evidence

at timet to adjust

the weights

of

at timet -1, as in standard

likelihood

the samples
weighting.

3. Propagate

each sample at timet-1 through
the

state-evolution

modified
idence at timet (as obtained
time slice).

model which uses the ev

in the arc-reversed

is a parent of the current

evidence

therefore,

In ER, the current
state;
ing the samples
ular, in the 2-D tracking
all the samples

example
will stay closely

it can influence
to the state variables

of extend
at t. In partic

the process

shown in Figure 3,
around the

clustered

Stochastic

simulation

algorithms

for dynamic probabilistic networks

349

procedure SOF()

loop for t  =  0 . . .  T

Instantiate Et
loop for i =  1  . . .  N

Add sample of Xt to s;
w., +--Likelihood(Et
Add w., to score for sampled values of Xt

I s;)

Repopulate sample set by randomized

selection

weighted by w.,

25 samples -+----
100 samples -----
1000 samples 

0.8 0000 samples -

0.6

0.4

0.2

Figure

5: The Survival-of-the-Fittest

algorithm.

0----

0  5 10 15 20 25 30 35 40 45 50

Time step

provided

by ER

to the uncertainty

of how accurate

in the state
the sensor

the advantages

by an amount  related
evolution model,
regardless
model is. Fortunately,
and SOF can be combined
simply by applying
That is, rather
ples at step 3 in the ER algorithm,
technique
That is, we sample  from
step 2 of the ER algorithm,
through

than propagating

into an ER/SOF hybrid,

SOF to the ER sampling
process.
all the slice-t
-1 sam
we use the SOF

the distribution
in
and then propagate

obtained
those

to focus on the ones that are most likely.

the modified state-evolution

model.

Figure 6: Performance
of LW: Graph showing
absolute error in the marginal probabilities
variables
randomly generated evidence cases.

of a time slice as  a function of t, averaged over 50

the average
of the state

range. It does, however,
time. It is possible
as t -t
oo,  but we have not yet run those experiments.

that the error asymptotes

show a slow increase
over

4  Empirical results

 "'


ideas presented

 <

has the
1.3 The

used in our experiments

as the network shown

in Figure

the problem

of sample population

on some simple experiments
the intuitive

we report
out to confirm

In this section,
we carried
above. The network
same topology
aim is to investigate
divergence
mitigate
solute
variables
x-axis measures

the problem.

over time, and to show that ER and SOF
ab

We measure the average
probabilities

of the state

error in the marginal

of a time slice as a function oft-that
environment.

time in the simulated

is, the

0.08

0.06

0.04

O.o2

5 10 15 20 25 30 35 40 45 50

Time step

Figure 7: Performance
absolute error in the marginal probabilities
variables
randomly generated evidence cases.

of ER: Graph showing the average
of the state

of a time slice as a function oft, averaged over 50

evidence.

show that LW fails dramatically

clearly

sets  of

The problem

generated

error behaviour

for LW over 50
av

Figure 6 shows  the
time steps for 25, 100, 1000, and 10000 samples,
eraged over 50 randomly
The results
even on this very simple network.
as any given sample is propagated
or later it will sample a state value that makes the
(for each state value in
observed
our network,
in not
). After sufficiently
possible
ples end up  with weight
error of 1.0. Thus, after 39 steps with 25 samples,
the samples
ing the number of samples
by a small number of steps.

one of the four observation
values
all the sam
0, at which point we assign an

are extinguished

impossible

many steps,

evidence

over time, sooner

is that

all

in all 50 cases. Multiply
only delays the inevitable

Figure 7 shows the corresponding
ER. Note  that
10. Thus, the  error

well within

remains

the scale of the y-axis is increased

error behaviour

for
by

the acceptable

3We are  currently

working to generate similar experi

mental data for our traffic surveillance

networks.

respectively.

8, 9, and 10 show the performance
of SOF and
with ER, for 25, 100, and 1000
show that SOF is

Figures
ER/SOF, compared
samples
an effective
over time. Although
higher error than ER, as one would expect,
bination
steps and shows no sign of diverging
at all.

The results
for maintaining

of ER and SOF shows low error for all time

mechanism

the com

SOF on its own shows somewhat

bounded error

of ER, SOF,

absolute

of the number of samples

11 shows the performance

Finally, Figure
and ER/SOF as a function
for the range 50 to 1000 samples.
the average
ties of the state variable
that SOF seems to benefit much less from additional
samples
Currently,
not sufficiently advanced

of the algorithm
this phenomenon.

than ER-in fact, the curve is almost flat.

analysis
to explain

at t =  50. The graphs show

error in the marginal

our theoretical

The graph gives

probabili

is

350 Kanazawa, Koller, and Russell

0.2

0.18

0.16

 0.14
  0.12
! 0.1
..
0.08
>
<  0.06
0.04

ER
SOF ---
ERJSOF 

0.08

ER
SOF ----
ERJSOF   

+----+---+---+---+------+---+---+- - -+---+--+---+---+-- ....... --+---+- --

1\

r.

'  j \l i\/\1'
,., , \ I 'v."\J  
IV\ I   \  I \!.

l

0.06

0.04

0.02

--.

a---e

0.02

0

0

5  10 15 20 25 30 35 40 45 50

Time step

B--.g ... B& S&-DB-9-BG PO-El'

Time step

0 L-----------
0  I 00  200 300 400 500 600 700 800 900 1000

the average
of the state variables

Figure 8: Performance
showing
bilities
of t, averaged
for 25 samples.

over 50 randomly

absolute

of ER, SOF, and ER/SOF: Graph
proba

error in the marginal
of a time slice

generated

evidence

cases,

of the number fo samples:

Figure 11: Performance
function
erage absolute
state variables
domly generated

error in the marginal
for time slice
evidence

cases.

as  a function

Graph showing the
probabilities

av

of the
over 50 ran

t =  50, averaged

of ER, SOF, and ER/SOF as  a

0.2

0.18

0.16
15  0.14
  0.12

 0.1
.g  0.08
.. >
<  0.06
0.04

0.02

0

0

ER
SOF ---
ERJSOF 

5  10 15 20 25  30 35 40  45 50

Time step

Figure 9: Performance
showing
bilities
of t, averaged
for 100 samples.

the average
of the state variables
over 50 randomly

absolute

of ER, SOF, and ER/SOF: Graph
proba

error in the marginal
of a time slice

generated

evidence

cases,

as  a function

0.2

0.18

0.16

ER
SOF ----
ERJSOF 

 0.14
  0.12
1\
 0.1
*  '
i \
'     ,If\,
I
 ) <; f \ -t.  ;  \ : \r)  
i '  i'  ..  :  :  i .  I. / \..-...;_
.g  0.08
I
.. >
<  0.06
/'\;  'i  ' v  \i 4
f  v
I
0.04

t.  {\, ,' '  ,,  
I
f
t \ !
  \J

0.02

0

0

...

5  10 15 20 25 30 35 40 45 50

Time step

10: Performance
the average

of ER, SOF, and ER/SOF: Graph
proba

absolute

marginal

error  in  the
of a time slice

as  a function

of the state variables
over 50 randomly

Figure
showing
bilities
oft, averaged
for 1000 samples.

generated

evidence

cases,

5  Conclusion and further work

two very simple and intuitive

im

that make the likelihood

weighting
tech

for dynamic  probabilistic

networks.
our intuitions.

confirm

results
In
for SOF and ER/SOF seems to be

We have presented
provements
nique effective
Early experimental
particular,
independent
lation.
applications
ence continues

the error

of the number of time steps in the simu

This is an absolute

requirement

for monitoring

such as traffic surveillance,

where  infer

over many days of real time.

is

the theoret

of the algorithms.

The most obvious
do they
are unbiased:

Further work needs to be done to establish
ical properties
sue is whether these approaches
converge
to the right answer as the number of samples
grows to infinity.
ER is clearly
just an application
of likelihood
fied network
It seems fairly
to show that SOF (and therefore
to the correct  values
standard
probabilistic

in the large-sample
techniques.

unbiased,
weighting

because
it
to a modi

structure.

limit using

ER/SOF) converge

straightforward

the improvement
in those  cases  where  the

for specific  net

error

the algorithms'

such as that shown in Figure

gives us a lot of information

1. Under
DPNs
for general
of ER

behaviour
Intuitively,

the expected
of sample size for LW, ER, SOF, and

We would also like to investigate
as a function
ER/SOF. This should be fairly  simple
work structures
standing
is more difficult.
and SOF is more pronounced
evidence
At one extreme,
rate, ER will be completely
sample.
will also depend on the behavior
model. If this is fairly
it appears
SOF will also do well. At the other extreme,
if the
sensor model is just noise,
seems to
provide
the improvement
tities

of these algorithms

(in terms of relative

well-behaved,

as (1) the distance

an advantage

The behavior

using such quan

if the sensor

approach

neither

that

over LW. We hope to analyze

about the state.

model is completely accu
accurate

with only a single

of SOF in these circumstances

of the state-evolution

entropy)

Stochastic

simulation

algorithms

for dynamic probabilistic

networks 351

at time t and at

distribution

by considering

SOF is a technique

the belief-state

between
(in terms
timet+ 1, and (2) the amount of information
of entropy) obtained
the sensors.
Finally,
trary networks,
to see if it provides
for general
algorithm
be a useful

networks.
known for very large networks,
development.

than LW
results
the best
this would

that can be applied

consistently

is currently

Since  LW

better

to arbi

not just DPNs. It would be interesting

