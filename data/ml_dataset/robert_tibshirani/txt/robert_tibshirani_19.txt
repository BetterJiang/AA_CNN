STATISTICSINMEDICINE,VOL.16,385—395(1997)THELASSOMETHODFORVARIABLESELECTIONINTHECOXMODELROBERTTIBSHIRANIDepartmentofPreventiveMedicineandBiostatisticsandDepartmentofStatistics,UniversityofToronto,Toronto,Ontario,CanadaM5S1A8SUMMARYIproposeanewmethodforvariableselectionandshrinkageinCox’sproportionalhazardsmodel.Myproposalminimizesthelogpartiallikelihoodsubjecttothesumoftheabsolutevaluesoftheparametersbeingboundedbyaconstant.Becauseofthenatureofthisconstraint,itshrinkscoeﬃcientsandproducessomecoeﬃcientsthatareexactlyzero.Asaresultitreducestheestimationvariancewhileprovidinganinterpretableﬁnalmodel.Themethodisavariationofthe‘lasso’proposalofTibshirani,designedforthelinearregressioncontext.Simulationsindicatethatthelassocanbemoreaccuratethanstepwiseselectioninthissetting.1.INTRODUCTIONConsidertheusualsurvivaldatasetup.Thedateavailableareoftheform(y,x,♥),2,(y,,x,,♥,),thesurvivaltimeyGbeingcompleteif♥G"1andrightcensoredif♥G"0,withxGdenotingtheusualvectorofpredictors(x,x,2,xN)fortheithindividual.Denotethedistinctfailuretimesbyt(2(tI,therebeingdGfailuresattimetG.Theproportional-hazardsmodelforsurvivaldata,alsoknownastheCoxmodel,assumesthat♮(t"x)"♮(t)exp	HxH♢H(1)where♮(t"x)isthehazardattimetgivenpredictorvaluesx"(x,2,xN),and♮(t)isanarbitrarybaselinehazardfunction.Oneusuallyestimatestheparameter♢"(♢,♢,2,♢N)2intheproportional-hazardsmodel(1)withoutspeciﬁcationof♮(t)throughmaximizationofthethepartiallikelihood¸(♢)"PZ"exp(♢2xjP)+	j3RPexp(♢2xH),.(2)Inequation(2)Disthesetofindicesofthefailures,RPisthesetofindicesoftheindividualsatriskattimetP!0,andjPistheindexofthefailureattimetP.Assumeforsimplicitythattherearenotiedfailuretimes;suitablemodiﬁcationsofthepartiallikelihoodexistforthecaseofties.Assumealsothatthecensoringisnon-informative,sothattheconstructionofthepartiallikelihoodisjustiﬁed.CCC0277—6715/97/040385—11ReceivedMarch19951997byJohnWiley&Sons,Ltd.RevisedDecember1995Denotethelogpartiallikelihoodbyl(♢)"log¸(♢),andassumethatthexGHarestandardizedsothat	GxGH/N"0,	GxGH/N"1.InthispaperIproposetoestimate♢viathecriterion♢K"argminl(♢),subjectto	"♢H")s(3)wheres'0isauser-speciﬁedparameter.Inthelinearregressionsetting,Tibshiraniproposedminimizationoftheresidualsumofsquares,subjecttoaconstraintoftheform	"♢H")sandcalledtheresultingprocedurethe‘lasso’for‘LeastAbsoluteShrinkageandSelectionOperator’.HereIusetheterm‘lasso’forthepresentproposalaswell.Suppose♢KMHarethemaximizersofthepartiallikelihood(2).Thenifs*	"♢KMH",thesolutionsto(3)aretheusualpartiallikelihoodestimates.Ifs(	"♢KMH",however,thenthesolutionsto(3)areshrunkentowardszero.Anattractivefeatureoftheparticularconstraint	"♢H")sisthatquiteoftensomeofthesolutioncoeﬃcientsareexactlyzero.Thismakesforamoreinterpretableﬁnalmodel.Ontheotherhand,thesmoothformoftheconstraintshouldprovideamorestableﬁnalmodelthanthatgivenbystepwiseorbestsubsetselection.Intheregressionsetting,Tibshiraniconﬁrmedthisinsimulationstudies.Incontrast,theridgeregressionapproach(usedmainlyinthelinearmodelsetting)shrinkscoeﬃcientsbutdoesnotgivecoeﬃcientsthatareexactlyzero.Notethatlikemodelselection,thelassoisatoolforachievingparsimony;inactualityanexactzerocoeﬃcientisunlikelytooccur.Thenextsectiongivesanalgorithmforobtainingthelassoestimates.Section3containstworealdataexamples.AutomaticestimationoftheconstraintparametersappearsinSection4,andinSection5Ireportasimulationstudythatcomparesthelassotostepwiseselection.Section6discussesestimationofstandarderrors,whileSection7containssomediscussion,includingabriefsummaryofotherapproachestomodelselection.2.COMPUTATIONOFTHEESTIMATESTibshiranigavetwoalgorithmsforthelassoprocedureintheleastsquaresregressionsetting,basedonquadraticprogrammingtechniques.Thealgorithmsareiterativeandinvolverepeatedsolutionofleastsquaresproblems.Typicallyoneneedsbetweenpand2piterations,wherepisthenumberofregressorvariables.Thestrategyforsolving(3)istoexpresstheusualNewton—Raphsonupdateasaniterativereweightedleastsquares(IRLS)step,andthenreplacetheweightedleastsquaresstepbyaconstrainedweightedleastsquaresprocedure.IfXdenotesthedesignmatrixofregressorvariablesand♪"X♢,deﬁneu"*l/*♪,A"!*l/*♪♪2andz"♪#A\u(detailedexpressionsforu,AandzappearinHastieandTibshirani,Chapter8,pp.213—214).Thenaone-termTaylorseriesexpansionforl(♢)hastheform(z!♪)2A(z!♪).(4)Hencetosolvetheoriginalproblem(3),weusethefollowingprocedure:1.Fixsandinitialize♢K"0.2.Compute♪,u,Aandzbasedonthecurrentvalueof♢K.3.Minimize(z!X♢)2A(z!X♢)subjectto	"♢G")s.4.Repeatsteps2and3until♢Kdoesnotchange.Theminimizationinstep3isdonethroughaquadraticprogrammingprocedure,asdescribedinTibshirani.Notethatifoneusedinsteadanunconstrainedminimizationinstep3,thisprocedure386R.TIBSHIRANIwouldbeequivalenttotheusualNewton—Raphsonalgorithmformaximizingthepartiallikelihood(HastieandTibshirani,Chapter8,p.212).OnediﬃcultywiththeaboveprocedureisthatAisafullmatrixandhenceitrequirescomputationofO(N)elements.Onecanavoidthis,howeverby,replacingAwithadiagonalmatrixDthathasthesamediagonalelementsasA.AsarguedinHastieandTibshirani(Chapter8,pp.212—213),thediagonalelementsofAarelargerthantheoﬀ-diagonalelementsandhencethemodiﬁedalgorithmshouldbehavesimilarlytotheoriginalone.ThereisnointerceptintheCoxmodelandhencetheminimizationinstep3doesnotrequireanintercept.Ihavefoundhoweverthatinclusionofaninterceptdramaticallyimprovestheconvergenceoftheprocedure.Thisispurelyacomputationalissue;itmakesnodiﬀerenceintheﬁnalmodel,astheinterceptisabsorbedintothebaselinehazard.Ifthelogpartiallikelihoodisboundedin♢forthegivendataset,thenforﬁxedsasolutionto(3)existssincetheregion	"♢H")siscompact.However,thesolutionmaynotbeunique.Forexample,iftworegressorsvariablesXandXareidenticallyequal,thenif♢'0,forany♤in[0,♢]thelinearcombinationX♤#(♢!♤)Xhasexactlythesamevalueforthelandtheconstraint"♤"#"♢!♤".Notethatthisisduetothelinearityoftheconstraint;inridgestylepenalizationinvolvingthesquaredcoeﬃcients,thisdoesnotoccur.3.EXAMPLES3.1.LungcancerdataThedatainthisexamplecomefromtheVeteran’sAdministrationlungcancertrial,listedinKalbﬂeischandPrentice,pp.223—224.Thetimevariableissurvivalindays,andtheregressorsare:1.Treatment1"standard,2"test.2.Celltype1"squamous,2"smallcell,3"adeno,4"large.3.Karnofskyscore.4.Monthsfromdiagnosis.5.Ageinyears.6.Priortherapy0"no,10"yes.Forsimplicity,andbecausethecategoriesexhibitincreasingrisk,Ihaveleftcelltypeasanumericalvariable.AstandardproportionalhazardsanalysisshowsthattheKarnofskyscoreisextremelyimportant,whilecelltypeisalsostronglysigniﬁcant.Theotherregressorsshowmoderateeﬀects.Figure1showstheestimatedcoeﬃcientsfromthelassoﬁtasafunctionofthestandardizedconstraintparameteru"s/	"♢KMH"(where♢MHaretheunconstrainedpartiallikelihoodestimates).Karnofskyscoreisclearlythedominanteﬀectwithtreatmentandcelltypealsoshowingmoderateinﬂuence.Theverticalbrokenlineisdrawnat0·45,whichisthevalueofuchosenbygeneralizedcross-validation(GCV,seeSection4).Themodelselectedbygeneralizedcross-validationhasanon-zerocoeﬃcientonlyforKarnofskyscore,withacoeﬃcientof!0·47,correspondingtoarelativeriskof0·63.Itstandarderroris0·085,computedbythetechniquediscussedinSection6.BackwardstepwiseselectioninthestandardCoxmodelyieldsthesamesinglevariablemodel,butwithacoeﬃcientof!0·67(0·10)orarelativerisk0·51.Thestepwisemethodreferstobackward—forwardstepwiseselectionasimplementedinScottEmerson’sSlanguagefunction‘coxrgrss’withthedefaultP-valuestoenterandremoveof0·05and0·10,respectively.IalsoappliedSchwarz’scriterions(alsoknownasBIC)tothesedata;thishastheTHELASSOMETHODFORVARIABLESELECTIONINTHECOXMODEL387Figure1.Coeﬃcientestimatesforlungcancerexample,asafunctionofthestandardizedconstraintparameteru"s/	"♢KMH"formminuslogpartiallikelihoodplusklognwherekisthenumberofregressorsinthemodelconsideredandnisthesamplesize.Searchingoverallsubsets,themodelthatminimizesSchwarz’scriterionagaincontainedonlytheKarnofskyscore.3.2.LiverdataThedatainthisexampleandthefollowing(edited)descriptionwereprovidedbyHarringtonandFleming.‘Primarybiliarycirrhosis(PBC)oftheliverisararebutfatalchronicliverdiseaseofunknowncause,withaprevalenceofabout50-cases-per-millionpopulation.Theprimarypathologiceventappearstobethedestructionofinterlobularbileducts,whichmaybemediatedbyimmunologicmechanisms.388R.TIBSHIRANIThefollowingbrieﬂydescribesdatacollectedfortheMayoClinictrialinPBCoftheliverconductedbetweenJanuary1974andMay1984comparingthedrugD-penicillamine(DPCA)withaplacebo.Theﬁrst312casesparticipatedintherandomizedtrialofD-penicillamineversusplacebo,andcontainlargelycompletedata.Anadditional112casesdidnotparticipateintheclinicaltrial,butconsentedtohavebasicmeasurementsrecordedandtobefollowedforsurvival.Sixofthosecaseswerelosttofollow-upshortlyafterdiagnosis,sotherearedatahereonanadditional106casesaswellasthe312randomizedparticipants.’Idiscardedobservationswithmissingvalues,leaving276observations.Thevariablesinthedatasetare:NCasenumber.½Thenumberofdaysbetweenregistrationandtheearlierofdeathorstudyanalysistimein1986.♥1if½istimetodeath,0iftimetocensoring.XTreatmentcode,1"D-pencillamine,2"placebo.XAgeinyears.Fortheﬁrst312cases,agewascalculatedbydividingthenumberofdaysbetweenbirthandstudyregistrationby365.XSex,0"male,1"female.XPresenceofascites,0"no,1"yes.XPresenceofhepatomegaly,0"no,1"yes.XPresenceofspiders,0"no,1"yes.XPresenceofoedema,0"no,0·5"yesbutrespondedtodiuretictreatment,1"yes,didnotrespondtotreatment.XSerumbilirubin,inmg/dl.XSerumcholesterol,inmg/dl.XAlbumin,ing/dl.XUrinecopper,in♯g/day.XAlkalinephosphatase,inU/litre.XSGOT,inU/ml.XTriglycerides,inmg/dl.XPlateletcount;codedvalueisnumberofplateletspercubicmlofblooddividedby1000.XProthrombinetime,inseconds.XHistologicstateofdisease,graded1,2,3or4.SomeresultsappearinTableI.Thestepwisemethodreferstobackward—forwardstepwiseselectionasimplementedinScottEmerson’sSlanguagefunction‘coxrgrss’withthedefaultP-valuestoenterandremoveof0·05and0·10respectively.CoxrgrssisavailablefromtheStatlibarchive(ftpsitelib.stat.cmu.edu).Thisgaveamodelwitheightvariables,allhavinglargeZ-scores.TheGCVproceduregaveuL"0·56forthestandardizedlassoparameterandtheresultingmodelfromthelassolookssimilartothestepwisemodel,withmostoftheeﬀectsshrunkentowardszero.WhilethestepwiseprocedureofteninﬂatestheZscoresofchosenvariablesrelativetothefullmodelﬁt,thelassoseemstoshrinkthemtowardszero.IcomputedstandarderrorsforthelassoestimatesusingthemethodgiveninSection6.4.ESTIMATIONOFTHECONSTRAINTPARAMETERsInsomesituationsitisdesirabletohaveanautomaticmethodforchoosingsbasedonthedata.Suchaprocedureisanalogoustoanautomaticsubsetselectionproceduresuchasforward,backwardorallsubsetsregression.THELASSOMETHODFORVARIABLESELECTIONINTHECOXMODEL389TableI.ResultsforliverdataexampleVariablesFullStepwiseLassoCoeﬃcientSEZ-scoreCoeﬃcientSEZ-scoreCoeﬃcientSEZ-score1!0·060·11!0·58———0·000·000·0020·300·122·490·330·113·080·170·091·893!0·120·10!1·17———!0·010·03!0·3140·020·100·23———0·040·070·6350·010·130·10———0·000·000·0060·050·110·42———0·020·050·4070·270·112·560·220·092·370·180·111·7180·370·123·140·390·094·390·350·122·9790·120·101·11———0·000·010·2810!0·300·12!2·40!0·290·11!2·63!0·220·10!2·27110·220·102·130·250·092·900·210·111·98120·000·080·03———0·000·000·00130·230·112·080·250·102·420·090·081·0414!0·060·09!0·75———0·000·000·00150·080·110·76———0·000·000·00160·230·112·190·230·102·250·090·090·97170·390·152·590·370·122·970·210·092·28Myproposalistominimizeanapproximategeneralizedcross-validation(GCV)statistic(Wahba).Toconstructthisstatistic,weneedalinearapproximationtothelassoestimate.Wewritetheconstraint	"♢H")sas	♢H/"♢H")s.ThislatterconstraintisequivalenttoaddingaLagrangianpenalty♮	♢H/"♢H"tothelogpartiallikelihood,with♮*0dependingons.Intuitively,theseareequivalentsincetheybothleadtoabalancebetweenﬁt,asmeasuredbythelogpartiallikelihood,andthevalueof♮	♢H/"♢H".Usingstandardmatrixmanipulations,wemaywritetheconstrainedsolution♢Iinstep3intheform♢I"(X2DX#♮W)\X2Dz(5)W"diag(WH),WG"1/"♢IH"if"♢IH"'0and0otherwise.(Thisexpressiondoesnotgiveanumericallyeﬀectivewayofcomputingthelassoestimate,butitisusefulforassessingthecomplexityoftheﬁt.)Thereforewemayapproximatethenumberofeﬀectiveparametersintheconstrainedﬁt♢Ibyp(s)"tr[X(X2DX#♮W\)\X2D].LettinglQbethelog-partiallikelihoodfortheconstrainedﬁtwithconstraints,weconstructtheGCV-stylestatisticGCV(s)"1N!lQN[1!p(s)/N].(6)Intuitively,theGCVcriterioninﬂatesthenegativelogpartiallikelihoodbyafactorthatinvolvesp(s),theeﬀectivenumberofparameters.Largervaluesofp(s)causemoreinﬂation(penalization)ofthenegativelogpartiallikelihood.SeeWahbafordetailsofgeneralizedcross-validation;onecouldalsouseanAkaike-stylecriterion,asinAkaike.Figure2showstheGCVplotforthelungcancerexample,asafunctionofthestandardizedconstraintparameter.Theminimumoccursnearu"0·45.390R.TIBSHIRANIFigure2.GCVplotforlungcancerexample.Thegeneralizedcross-validationscoreisplottedagainstthestandardizedconstraintparameteru"s/	"♢KMH"5.ASIMULATIONSTUDY5.1.AfewlargeeﬀectsInthisexamplewesimulated50datasetseachwith50observations,fromtheexponentialhazardmodel♮(t"x)"exp(♢2x)where♢"(!0·35,!0·35,0,0,0,!0·35,0,0,0)2.ThexGwereeachmarginallystandardnormal,andthecorrelationbetweenxGandxHwas♵"i!j"with♵"0·5.Thisgavemoderatetostrongeﬀectsforthethreeregressorswithnon-zerocoeﬃcients.Letting	bethepopulationcovariancematrixoftheregressors,TableIIshowsthemedianofthemeansquarederrors(♢K!♢)2	(♢K!♢)over50simulationsfromthismodel.Asbefore,thestepwisemethodreferstobackward—forwardstepwiseselectionasimplementedinScottEmerson’sSlanguagefunction‘coxrgrss’withthedefaultP-valuestoenterandremoveof0·05and0·10,respectively.Thelassoclearlyoutperformsstepwiseselection,andpicksapproximatelythecorrectnumberofzerocoeﬃcients.Figure3showsboxplotsofthecoeﬃcientsfromeachofthethreemethods.Thelassodoesabetterjobofisolatingthenon-zerocoeﬃcientsandshrinkstheotherssubstantially.5.2.ManysmalleﬀectsHereweusedthesamemodelasintheprevioussection,butwith♢H"0·1∀H.Thisresultedinanoccasionaleﬀectsigniﬁcantatthe0·05level,asmeasuredbythefullCoxmodelﬁt.TableIIIshowstheresults.Thelassooutperformsthefullandstepwisemodelsbyshrinkingthecoeﬃcientsalmostallofthewaytozero.THELASSOMETHODFORVARIABLESELECTIONINTHECOXMODEL391TableII.Resultsforexample3(afewlargeeﬀects).Meansquarederrors(MSE)over50simulationsMethodMedianMSE(standarderrors)AveragenumbersofzerocoeﬃcientsNull0·44(—)9·0Fullmodel0·82(0·13)0·0Stepwise0·63(0·12)5·6Lasso0·26(0·07)6·7Figure3.Boxplotofcoeﬃcientsfromﬁrstsimulationstudy(afewlargecoeﬃcients)392R.TIBSHIRANITableIII.Resultsforsecondsimulationstudy(manysmalleﬀects).Meansquarederrors(MSE)over50simulationsMethodMedianMSE(standarderrors)AveragenumbersofzerocoeﬃcientsNull0·15(—)9·0Fullmodel0·57(0·04)0·0Stepwise0·53(0·04)5·5Lasso0·15(0·00)7·8TableIV.EstimatedandactualstandarderrorsforsimulatedexampleVariableu"0·7u"0·3MeancoeﬃcientMeanSEYActualSEMeancoeﬃcientMeanSEYActualSE1!0·550·170·19!0·300·130·162!0·580·180·24!0·350·150·173!0·010·090·16!0·020·020·0640·010·070·100·000·000·0150·000·070·13!0·010·010·056!0·500·160·20!0·230·120·127!0·050·090·15!0·010·010·0380·000·090·150·000·010·029!0·010·060·110·000·000·016.STANDARDERRORSWecanuseapproximation(5)toyieldanapproximatemethodforobtainingstandarderrorsforthelassoestimates.Inthenotationofequation(5),wecanshowusingstandardpartiallikelihoodtheorythatthevarianceofzisapproximatelyD\.LettingMdenotethematrixthatmultiplieszinequation(5),thenthevarianceof♢K"MzisapproximatelyMD\M2.Hencewecanobtaintheapproximatestandarderrorsof♢KfromthesquarerootofthediagonalofMD\M2.Toinvestigatetheaccuracyofthisprocedure,Isimulated50datasetsfromtheexampleofSection5.1.Theregressorvariablesweregeneratedonceandﬁxedforthe50simulations.TableIVshowstheresults.Intheleftpartofthetablethestandardizedconstraintparameterwasﬁxedat0·7;intherighthalf,itwas0·3.Ineachhalf,theﬁrstcolumnshowsthemeancoeﬃcientoverthe50simulations,thesecondcolumngivesthemeanofthestandarderrorestimate,andthethirdcolumnshowstheactualstandarderrorofthecoeﬃcientsoverthe50simulations.Notethatontheaveragethestandarderrorformulagivesareasonableestimateforthelargeeﬀects(variables1,2,6).Forthesmalleﬀects,ittendstounderestimatethestandarderror,butnotsomuch(exceptinoneinstance)astoaﬀectthattheperceivedsigniﬁcanceofthevariable.Thustheapproximatestandarderrorsappearreliable,exceptwhentheestimatedcoeﬃcientitselfisverysmall.Notealsothatthesamplingdistributionoftheestimatestendstobeskewed,especiallyforsmallvaluesoftheconstraintparameter(seeFigure3),sothiswilldegradetheaccuracyofnormalconﬁdencelimits.THELASSOMETHODFORVARIABLESELECTIONINTHECOXMODEL3937.DISCUSSIONThelassotechniqueforvariableselectionintheCoxmodelseemsaworthycompetitortostepwiseselection.Itislessvariablethanthestepwiseapproachandstillyieldsinterpretablemodels.Inpracticethelassoshouldbeusedinconjunctionwithothermodelbuildingtools.Inparticular,inourexampleswehaveassumedthatlinearityisreasonableforallofthepredictors.Thismaynotbeagoodassumptionanditshouldbecheckedinarealdataanalysis.Similarly,arefereepointedoutthattheproportionalhazardsassumptionisunreasonableofcelltypeandKarnofskyscoreintheﬁrstexample,andthisshouldbechecked;Ihavenotattemptedtoprovidethoroughanalysesinmyexamples.Thelassomethodrequiresinitialstandardizationoftheregressors,sothatthepenalizationschemeisfairtoallregressors.Forcategoricalregressors,onecodestheregressorwithdummyvariablesandthenstandardizesthedummyvariables.Aspointedoutbyareferee,however,therelativescalingbetweencontinuousandcategoricalvariablesinthisschemecanbesomewhatarbitrary.Insomeproblemstheremightbeeﬀectsthattheanalystdoesnotwanttoshrinkatall.Suchanexampleisatreatmentfactorknowntobeeﬀectiveapriori,withinterestlyinginmoreaccurateadjustmentforothercovariates.Insuchaninstance,onesimplyomitsthecorresponding♢Hfromtheconstraint,andonesolvestheproblembyasimplemodiﬁcationoftheoptimizationprocedurediscussedearlier.Therearesomeotherrecentlyproposedapproachestomodelselection.TheBayesianapproachhasbeendevelopedbyMichellandBeauchampandGeorgeandMcCulloch.TheyuseahierarchicalBayesmodel;thesecondauthorsapplytheGibbssamplertosimulatealargecollectionofsubsetmodelsfromtheposteriordistribution.SauerbreiandSchumacherproposeabootstrap-basedapproachtomodelselection.Therearesomewaystoextendthiswork.Thispaperhasfocusedonﬁxedcovariates,butonecanincorporatetime-dependentcovariateswithoutanynewdiﬃculty.Adaptationofthelassotechniquetothematchedcasecontrolmodelsisalsofairlystraightforward.ACKNOWLEDGEMENTSIwishtothankMichaelLeBlancforprovidingFlemingandHarrington’sliverdata,andMartinSchumacherandtworefereesforhelpfulcomments.ThisworkwassupportedbyagrantfromtheNaturalSciencesandEngineeringResearchCouncilofCanada.REFERENCES1.Cox,D.‘Regressionmodelsandlifetables(withdiscussion)’,JournaloftheRoyalStatisticalSociety,SeriesB,74,187—220(1972).2.Tibshirani,R.‘Regressionshrinkageandselectionviathelasso’,JournaloftheRoyalStatisticalSociety,SeriesB,(1995).3.Hastie,T.andTibshirani,R.GeneralizedAdditiveModels,ChapmanandHall,1990.4.Kalbﬂeisch,J.andPrentice,R.¹heStatisticalAnalysisofFailure¹imeData,Wiley,NewYork,1980.5.Schwarz,G.‘Estimatingthedimensionofamodel’,AnnalsofStatistics,6,461—464(1978).6.Wahba‘Splinebases,regularization,andgeneralizedcross-validationforsolvingapproximationproblemswithlargequantitiesofnoisydata’,inProceedingsoftheInternationalConferenceonApproximationtheoryinhonourofGeorgeLorenz,AcademicPress,Austin,Texas,1980.394R.TIBSHIRANI7.Akaike,H.‘Informationtheoryandanextensionofthemaximumlikelihoodprinciple’,inSecondInternationalSymposiumonInformationTheory,1973pp.267—281.8.Mitchell,T.andBeauchamp,J.‘Bayesianvariableselectioninlinearregression’,JournaloftheAmericanStatisticalAssociation,83,1023—1036(1988).9.George,E.andMcCulloch,R.‘VariableselectionviaGibbssampling’,JournaloftheAmericanStatisticalAssociation,88,884—889(1993).10.Sauerbrei,W.andSchumacher,M.‘Abootstrapresamplingprocedureformodelbuilding:applicationtothecoxregressionmodel’,StatisticsinMedicine,11,2093—2109(1992)..THELASSOMETHODFORVARIABLESELECTIONINTHECOXMODEL395