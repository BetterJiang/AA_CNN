Introduction

Consider an observed sequence z1, . . . , zN . In a state space model for Z1, . . . , ZN , the distribution
of the Zis is dened using a latent (hidden) Markov process X1, . . . , XN . We can describe such a
model in terms of a distribution for the rst hidden state, p(x1), transition probabilities between
hidden states, p(xi|xi1), and emission probabilities, p(zi|xi), with these distributions dependent
on some unknown parameters .

1

While the state space model framework is very general, only two state space models, Hidden
Markov Models (HMMs) and linear Gaussian models have ecient, exact inference algorithms.
The forward-backward algorithm for HMMs and the Kalman lter for linear Gaussian models
allow us to perform ecient inference of the latent process, which in turn allows us to perform
ecient parameter inference, using an algorithm such as Expectation-Maximizaton for maximum
likelihood inference, or various MCMC methods for Bayesian inference. No such exact and ecient
algorithms exist for models with a continuous state space with non-linear state dynamics, non-
Gaussian transition distributions, or non-Gaussian emission distributions, such as the Ricker
model we consider later in this paper.

In cases where we can write down a likelihood function for the model parameters conditional
on latent and observed variables, it is possible to perform Bayesian inference for the parameters
and the latent variables by making use of sampling methods such as MCMC. For example, one
can perform inference for the latent variables and the parameters by alternately updating them
according to their joint posterior.

Sampling of the latent state sequence x = (x1, . . . , xN ) is dicult for state space models when
the state space process has strong dependencies  for example, when the transitions between
states are nearly deterministic. To see why, suppose we sample from (x1, . . . , xN|z1, . . . , zN )
using Gibbs sampling, which samples the latent variables one at a time, conditional on values of
other latent variables, the observed data, and the model parameters. In the presence of strong
dependencies within the state sequence, the conditional distribution of a latent variable will be
highly concentrated, and we will only be able to change it slightly at each variable update,
even when the marginal distribution of this latent variable, given z1, . . . , zN , is relatively diuse.
Consequently, exploration of the space of latent sequences will be slow.

The embedded HMM method of (Neal (2003), Neal, et al. (2004)) addresses this problem by
updating the entire latent sequence at once. The idea is to temporarily reduce the state space
of the model, which may be countably innite or continuous, to a nite collection of randomly
generated pool states at each time point. If the transitions between states are Markov, this
reduced model is an HMM, for which we can use the forward-backward algorithm to eciently
sample a sequence with values in the pools at each time point. Pool states are chosen from a
distribution that assigns positive probability to all possible state values, allowing us to explore the
entire space of latent sequences in accordance with their exact distribution. Neal (2003) showed
that when there are strong dependencies in the state sequence, the embedded HMM method
performs better than conventional Metropolis methods at sampling latent state sequences.

In our paper, we rst look at an MCMC method which combines embedded HMM updates of
the hidden state sequence with random-walk Metropolis updates of the parameters. We call this
method the single-sequence method. We next reformulate the embedded HMM method as an
ensemble MCMC method. Ensemble MCMC allows multiple candidate points to be considered
simultaneously when a proposal is made. This allows us to consider an extension of the embedded
HMM method for inference of the model parameters when they are unknown. We refer to this
extension as the ensemble embedded HMM method. We then introduce and describe a staged
method, which makes ensemble MCMC more ecient by rejecting poor proposals at low com-
putational cost after looking at a part of the observed sequence. We use the single-sequence,

2

ensemble, and ensemble with staging methods to perform Bayesian inference in the Ricker model
of population dynamics, comparing the performance of these new methods to each other, and to
a simple Metropolis sampler.

2 Ensemble MCMC

We rst describe Ensemble MCMC, introduced by Neal (2010) as a general MCMC method,
before describing its application to inference in state space models.

Ensemble MCMC is based on the framework of MCMC using a temporary mapping. Suppose
we want to sample from a distribution  on X . This can be done using a Markov chain with
transition probablity from x to x(cid:48) given by T (x(cid:48)|x), for which  is an invariant distribution 

that is, T must satisfy(cid:82) (x)T (x(cid:48)|x)dx = (x(cid:48)). The temporary mapping strategy denes T as

a composition of three stochastic mappings. The current state x is stochastically mapped to a
state y  Y using the mapping T (y|x). Here, the space Y need not be the same as the space X .
The state y is then updated to y(cid:48) using the mapping T (y(cid:48)|y), and nally a state x(cid:48) is obtained
using the mapping T (x(cid:48)|y(cid:48)). In this approach, we may choose whatever mappings we want, so
long as the overall transition T leaves  invariant. In particular, if  is a density for y, T will
leave  invariant if the following conditions hold.

(cid:90)
(cid:90)
(cid:90)

(x) T (y|x)dx = (y)
(y) T (y(cid:48)|y)dy = (y(cid:48))
(y(cid:48)) T (x(cid:48)|y(cid:48))dy(cid:48) = (x(cid:48))

(1)

(2)

(3)

In the ensemble method, we take Y = X K, with y = (x(1), . . . , x(K)) referred to as an ensem-
ble, with K being the number of ensemble elements. The three mappings are then constructed
as follows. Consider an ensemble base measure over ensembles (x(1), . . . , x(K)) with density
(x(1), . . . , x(K)), and with marginal densities k(x(k)) for each of the k = 1, . . . , K ensemble
elements. We dene T as

K(cid:88)

k=1

T (x(1), . . . , x(K)|x) =

1
K

k|k(x(k)|x)x(x(k))

(4)

Here, x is a distribution that places a point mass at x, x(k) is all of x(1), . . . , x(K) except x(k),
and k|k(x(k)|x(k)) = (x(1), . . . , x(K))/k(x(k)) is the conditional density of all ensemble elements
except the k-th, given the value x(k) for the k-th.

This mapping can be interpreted as follows. First, we select an integer k, from a uniform
distribution on {1, . . . , K}. Then, we set the ensemble element x(k) to x, the current state.
Finally, we generate the remaining elements of the ensemble using the conditional density k|k.

3

The ensemble density  is determined by  and T , and is given explicitly as

(x(1), . . . , x(K)) =

(x) T (x(1), . . . , x(K)|x)dx

(cid:90)

= (x(1), . . . , x(K))

1
K

(x(k))
k(x(k))

(5)

K(cid:88)

k=1

T can be any update (or sequence of updates) that leaves  invariant. For example, T could
be a Metropolis update for y, with a proposal drawn from some symmetrical proposal density.
Finally, T maps from y(cid:48) to x(cid:48) by randomly setting x(cid:48) to x(k) with k chosen from {1, . . . , K} with
probabilities proportional to (x(k))/k(x(k)).

The mappings descibed above satisfy the necessary properties to make them a valid update,
in the sense of preserving the stationary distribution . The proof can be found in Neal (2010).

3 Embedded HMM MCMC as an

Ensemble MCMC method

The embedded HMM method briey described in the introduction was not initially introduced as
an ensemble MCMC method, but it can be reformulated as one. We assume here that we are inter-
ested in sampling from the posterior distribution of the state sequences, (x1, . . . , xN|z1, . . . , zN ),
when the parameters of the model are known. Suppose the current state sequence is x =
(x1, . . . , xN ). We want to update this state sequence in a way that leaves  invariant.

The rst step of the embedded HMM method is to temporarily reduce the state space to a
nite number of possible states at each time, turning our model into an HMM. This is done by,
for each time i, generating a set of L pool states, Pi = {x[1]
i }, as follows. We rst set
to xi, the value of the current state sequence at time i. The remaining L  1
the pool state x[1]
i
pool states x[l]
i , for l > 1 are generated by sampling independently from some pool distribution
with density i. The collections of pool states at dierent times are selected independently of
each other. The total number of sequences we can then construct using these pool states, by
choosing one state from the pool at each time, is K = LN .

, . . . , x[L]

i

The second step of the embedded HMM method is to choose a state sequence composed of

pool states, with the probability of such a state sequence, x, being proportional to

(6)

(7)

q(x|z1, . . . , zN )  p(x1)

p(xi|xi1)

i=2

i=1

We can dene (zi|xi) = p(zi|xi)/i(xi), and rewrite (6) as

q(x|z1, . . . , zN )  p(x1)

p(xi|xi1)

(cid:20)p(zi|xi)

(cid:21)

N(cid:89)

i(xi)

N(cid:89)

i=1

(zi|xi)

N(cid:89)

N(cid:89)

i=2

4

We now note that the distribution (7) takes the same form as the distribution over hidden state
sequences for an HMM in which each xi  Pi  the initial state distribution is proportional
to p(x1), the transition probabilities are proportional to p(xi|xi1), and the (zi|xi) have the
same role as emission probabilities. This allows us to use the well-known forward-backward
algorithms for HMMs (reviewed by Scott (2002)) to eciently sample hidden state sequences
composed of pool states. To sample a sequence with the embedded HMM method, we rst
compute the forward probabilities. Then, using a stochastic backwards pass, we select a
state sequence composed of pool states. (We can alternately compute backward probabilities and
then do a stochastic forward pass). We emphasize that having an ecient algorithm to sample
state sequences is crucial for the embedded HMM method. The number of possible sequences we
can compose from the pool states, LN , can be very large, and so naive sampling methods would
be impractical.

In detail, for xi  Pi, the forward probabilities i(xi) are computed using a recursion that
goes forward in time, starting from i = 1. We start by computing 1(x1) = p(x1)(z1|x1). Then,
for 1 < i  N , the forward probabilities i(x) are given by the recursion

i(xi) = (zi|xi)

p(xi|x[l]

i1)i1(x[l]

i1),

for x  Pi

(8)

l=1

The stochastic backwards recursion samples a state sequence, one state at a time, beginning with
the state at time N . First, we sample xN from the pool PN with probabilities proportional to
N (xN ). Then, going backwards in time for i from N  1 to 1, we sample xi from the pool Pi
with probabilities proportional to p(xi+1|xi)i(xi), where xi+1 is the variable just sampled at time
i + 1. Both of these recursions are commonly implemented using logarithms of probabilities to
avoid numerical underow.

Let us now reformulate the embedded HMM method as an ensemble MCMC method. The
step of choosing the pool states can be thought of as performing a mapping T which takes a single
hidden state sequence x and maps it to an ensemble of K state sequences y = (x(1), . . . , x(K)),
with x = x(k) for some k chosen uniformly from {1, . . . , K}.
(However, we note that in this
context, the order in the ensemble does not matter.)

L(cid:88)

Since the randomly chosen pool states are independent under i at each time, and across
time as well, the density of an ensemble of hidden state sequences in the ensemble base measure,
, is dened through a product of i(x[l]
i )s over the pool states and over time, and is non-zero
for ensembles consisting of all sequences composed from the chosen set of pool states. The
corresponding marginal density of a hidden state sequence x(k) in the ensemble base measure is

k(x(k)) =

i(x(k)
i )

(9)

i=1

Together,  and k dene the conditional distribution k|k, which is used to dene T . The
mapping T is taken to be a null mapping that keeps the ensemble xed at its current value,
and the mapping T to a single state sequence is performed by selecting a sequence x(k) from the
ensemble with probabilities given by (7), in the same way as in the embedded HMM method.

5

N(cid:89)

4 The single-sequence embedded HMM MCMC method

Let us assume that the parameters  of our model are unknown, and that we want to sample
from the joint posterior distribution of state sequences x = (x1, . . . , xN ) and parameters  =
(1, . . . , P ), with density (x, |z1, . . . , zN ). One way of doing this is by alternating embedded
HMM updates of the state sequence with Metropolis updates of the parameters. Doing updates in
this manner makes use of an ensemble to sample state sequences more eciently in the presence of
strong dependencies. However, this method only takes into account a single hidden state sequence
when updating the parameters.

The update for the sequence is identical to that in the embedded HMM method, with initial,
transition and emission densities dependent on the current value of . In our case, we only consider
simple random-walk Metropolis updates for , updating all of the variables simultaneously.

Evaluating the likelihood conditional on x and z, as needed for Metropolis parameter updates,
is computationally inexpensive relative to updates of the state sequence, which take time pro-
portional to L2. It may be benecial to perform several Metropolis parameter updates for every
update of the state sequence, since this will not greatly increase the overall computational cost,
and allows us to obtain samples with lower autocorrelation time.

5 An ensemble extension of the embedded HMM method

When performing parameter updates, we can look at all possible state sequences composed of
pool states by using an ensemble ((x(1), ), . . . , (x(K), )) that includes a parameter value , the
same for each element of the ensemble. The update T could change both  and x(k), but in the
method we will consider here, we only change .

To see why updating  with an ensemble of sequences might be more ecient than updating
 given a single sequence, consider a Metropolis proposal in ensemble space, which proposes
to change  for all of the ensemble elements, from  to . Such an update can be accepted
whenever there are some elements (x(k), ) in the proposed ensemble that make the ensemble
density ((x(1), ), . . . , (x(K), )) relatively large. That is, it is possible to accept a move in
ensemble space with a high probability as long as some elements of the proposed ensemble, with
the new , lie in a region of high posterior density. This is at least as likely to happen as having
a proposed  together with a single state sequence x lie in a region of high posterior density.

Using ensembles makes sense when the ensemble density  can be computed in an ecient
manner, in less than K times as long as it takes to compute p(x, |z1, . . . , zN ) for a single hidden
state sequence x. Otherwise, one could make K independent proposals to change x, which would
have approximately the same computational cost as a single ensemble update, and likely be a
more ecient way to sample x. In the application here, K = LN is enormous for typical values
of N when L  2, while computation of  takes time proportional only to N L2.

In detail, to compute the ensemble density, we need to sum q(x(k), |z1, . . . , zN ) over all en-
semble elements (x(k), ), that is, over all hidden sequences which are composed of the pool states

6

at each time. The forward algorithm described above makes it possible to compute the ensemble
density eciently by summing the probabilities at the end of the forward recursion N (xN ) over
all xN  PN . That is

K(cid:88)

L(cid:88)

((x(1), ), . . . , (x(K), ))  ()

where () is the prior density of .

q(x(k), |z1, . . . , zN ) = ()

N (x[l]
N )

(10)

k=1

l=1

The ensemble extension of the embedded HMM method can be thought of as using an approx-
imation to the marginal posterior of  when updating , since summing the posterior density over
a large collection of hidden sequences approximates integrating over all such sequences. Larger
updates of  may be possible with an ensemble because the marginal posterior of , given the
data, is more diuse than the conditional distribution of  given a xed state sequence and the
data. Note that since the ensemble of sequences is periodically changed, when new pool states
are chosen, the ensemble method is a proper MCMC method that converges to the exact joint
posterior, even though the set of sequences using pool states is restricted at each MCMC iteration.

The ensemble method is more computationally expensive than the single-sequence method
 it requires two forward passes to evaluate the ensemble density for two values of  and one
backward pass to sample a hidden state sequence, whereas the single-sequence method requires
only a single forward pass to compute the probabilities for every sequence in our ensemble, and
a single backward pass to select a sequence.

Some of this additional computational cost can be oset by reusing the same pool states to do
multiple updates of . Once we have chosen a collection of pool states, and performed a forward
pass to compute the ensemble density at the current value of , we can remember it. Proposing
an update of  to  requires us to compute the ensemble density at  using a forward pass.
Now, if this proposal is rejected, we can reuse the stored value of the ensemble density  when we
make another proposal using the same collection of pool states. If this proposal is accepted, we
can remember the ensemble density at the accepted value. Keeping the pool xed, and saving the
current value of the ensemble density therefore allows us to perform M ensemble updates with
M + 1 forward passes, as opposed to 2M if we used a new pool for each update.

With a large number of pool states, reusing the pool states for two or more updates has only a
small impact on performance, since with any large collection of pool states we essentially integrate
over the state space. However, pool states must still be updated occasionally, to ensure that the
method samples from the exact joint posterior.

6 Staged ensemble MCMC sampling

Having to compute the ensemble density given the entire observed sequence for every proposal,
even those that are obviously poor, is a source of ineciency in the ensemble method. If poor
proposals can be eliminated at a low computational cost, the ensemble method could be made
more ecient. We could then aord to make our proposals larger, accepting occasional large
proposals while rejecting others at little cost.

7

We propose to do this by performing staged updates. First, we choose a part of the observed
sequence that we believe is representative of the whole sequence. Then, we propose to update 
to a  found using an ensemble update that only uses the part of the sequence we have chosen. If
the proposal found by this rst stage update is accepted, we perform a second stage ensemble
update given the entire sequence, with  as the proposal. If the proposal at the rst stage is
rejected, we do not perform a second stage update, and add the current value of  to our sequence
of sampled values. This can be viewed as a second stage update where the proposal is the current
state  to do such an update, no computations need be performed.

Suppose that 1 is the ensemble density given the chosen part of the observed sequence,
and q(|) is the proposal density for constructing the rst stage update. Then the acceptance
probability for the rst stage update is given by

(cid:18)

min

1,

1((x(1), ), . . . , (x(K), ))q(|)
1((x(1), ), . . . , (x(K), ))q(|)

(cid:19)

If  is the ensemble density given the entire sequence, the acceptance probability for the second
stage update is given by

((x(1), ), . . . , (x(K), )) min

min

1,

((x(1), ), . . . , (x(K), )) min

(cid:18)
(cid:18)

1, 1((x(1),),...,(x(K),))q(|)
1((x(1),),...,(x(K),))q(|)
1, 1((x(1),),...,(x(K),))q(|)
1((x(1),),...,(x(K),))q(|)

(11)

(12)

(cid:19)
(cid:19) (cid:33)

(cid:33)

(cid:32)

(cid:32)

Regardless of whether 1((x(1), ), . . . , (x(K), ))q(|) < 1((x(1), ), . . . , (x(K), ))q(|) or
vice versa, the above ratio simplies to

min

1,

((x(1), ), . . . , (x(K), ))1((x(1), ), . . . , (x(K), ))q(|)
((x(1), ), . . . , (x(K), ))1((x(1), ), . . . , (x(K), ))q(|)

(13)

Choosing a part of the observed sequence for the rst stage update can be aided by looking at the
acceptance rates at the rst and second stages. We need the moves accepted at the rst stage to
also be accepted at a suciently high rate at the second stage, but we want the acceptance rate at
the rst stage to be low so the method will have an advantage over the ensemble method in terms
of computational eciency. We can also look at the false negatives for diagnostic purposes, that
is, how many proposals rejected at the rst step would have been accepted had we looked at the
entire sequence when deciding whether to accept.

We are free to select any portion of the observed sequence to use for the rst stage. We will
look here at using a partial sequence for the rst stage consisting of observations starting at n1
and going until the end, at time N . This is appropriate for our example later in the paper, where
we only have observations past a certain point in time.

For this scenario, to perform a rst stage update, we need to perform a backward pass. As
we perform a backward pass to do the rst stage proposal, we save the vector of backward
probabilities. Then, if the rst stage update is accepted, we start the recursion for the full
sequence using these saved backward probabilities, and compute the ensemble density given the

8

entire sequence, avoiding recomputation of backward probabilities for the portion of the sequence
used for the rst stage.

To compute the backward probabilities i(xi), we perform a backward recursion, starting at

time N . We rst set N (xN ) to 1 for all xN  PN . We then compute, for n1  i < N

i(xi) =

p(x[l]

i+1)(zi+1|x[l]
i+1)

L(cid:88)

l=1

i+1|xi)i+1(x[l]
L(cid:88)

We compute the rst stage ensemble density 1 as follows

(14)

(15)

L(cid:88)

1((x(1), ), . . . , (x(K), )) = ()

p(x[l]

n1)p(yn1|x[l]

n1)n1(x[l]
n1)

l=1

We do not know p(xn1), but we can choose a substitute for it (which aects only performance,
not correctness). One possibility is a uniform distrubution over the pool states at n1, which is
what we will use in our example below.

The ensemble density for the full sequence can be obtained by performing the backward

recursion up to the beginning of the sequence, and then computing

((x(1), ), . . . , (x(K), )) = ()

p(x[l]

1 )p(y1|x[l]

1 )1(x[l]
1 )

(16)

l=1

To see how much computation time is saved with staged updates, we measure computation
time in terms of the time it takes to do a backward (or equivalently, forward) pass  generally,
the most computationally expensive operation in ensemble MCMC  counting a backward pass
to time n1 as a partial backward pass.

Let us suppose that the acceptance rate for stage 1 updates is a1. An ensemble update that
uses the full sequence requires us to perform two backwards passes if we update the pool at every
iteration, whereas a staged ensemble update will require us to perform

N  n1
N  1

n1  1
N  1

1 +

+ a1

(17)
backward passes on average (counting a pass back only to n1 as (N  n1)/(N  1) passes). The
rst term in the above formula represents the full backward pass for the initial value of  that is
always needed  either for a second stage update, or for mapping to a new set of pool states.
The second term represents the partial backward pass we need to perform to complete the rst
stage proposal. The third term accounts for having to compute the remainder of a backwards
pass if we accept the rst stage proposal  hence it is weighted by the rst stage acceptance
rate.

We can again save computation time by updating the pool less frequently. Suppose we decide
to update the pool every M iterations. Without staging, the ensemble method would require a

9

total of M + 1 forward (or equivalently, backward) passes. With staged updates, the expected
number of backward passes we would need to perform is

n1  1
N  1
as can be seen by generalizing the expression above to M > 1.

N  n1
N  1

1 + M

+ M a1

(18)

7 Constructing pools of states

An important aspect of these embedded HMM methods is the selection of pool states at each
time, which determines the mapping T from a single state sequence to an ensemble. In this paper,
we will only consider sampling pool states independently from some distribution with density i
(though dependent pool states are considered in (Neal, 2003).

One choice of i is the conditional density of xi given zi, based on some pseudo-prior distri-
bution  for xi  that is, i(xi)  (xi)p(zi|xi). This distribution approximates, to some extent,
the marginal posterior of xi given all observations. We hope that such a pool distribution will
produce sequences in our ensemble which have a high posterior density, and as a result make
sampling more ecient.

To motivate how we might go about choosing , consider the following. Suppose we sample
values of  from the model prior, and then sample hidden state sequences, given the sampled
values of . We can then think of  as a distribution that is consistent with this distribution of
hidden state sequences, which is in turn consistent with the model prior. In this paper, we choose
 heuristically, setting it to what we believe to be reasonable, and not in violation of the model
prior.

Note that the choice of  aects only sampling eciency, not correctness (as long as it is
non-zero for all possible xi). However, when we choose pool states in the ensemble method, we
cannot use current values of , since this would make an ensemble update non-reversible. This
restriction does not apply to the single-sequence method since in this case T is null.

8 Performance comparisons on a

population dynamics model

We test the performance of the proposed methods on the Ricker population dynamics model,
described by Wood (2003). This model assumes that a population of size Ni (modeled as a
real number) evolves as Ni+1 = rNi exp(Ni + ei), with ei independent with a Normal(0, 2)
distribution, with N0 = 1. We dont observe this process directly, but rather we observe Yis
whose distribution is Poisson(Ni). The goal is to infer  = (r, , ). This is considered to be a
fairly complex inference scenario, as evidenced by the application of recently developed inference
methods such as Approximate Bayesian Computation (ABC) to this model.
(See Fearnhead,

10

Prangle (2012) for more on the ABC approach.) This model can be viewed as a non-linear state
space model, with Ni as our state variable.

MCMC inference in this model can be inecient for two reasons. First, when the value of 2
in the current MCMC iteration is small, consecutive Nis are highly dependent, so the distribution
of each Ni, conditional on the remaining Nis and the data, is highly concentrated, making it hard
to eciently sample state sequences one state at a time. An MCMC method based on embedding
an HMM into the state space, either the single-sequence method or the ensemble method, can
potentially make state sequence sampling more ecient, by sampling whole sequences at once.
The second reason is that the distribution of , given a single sequence of Nis and the data, can
be concentrated as well, so we may not be able to eciently explore the posterior distribution of 
by alternately sampling  and the Nis. By considering an ensemble of sequences, we may be able
to propose and accept larger changes to . This is because the posterior distribution of  summed
over an ensemble of state sequences is less concentrated than it is given a single sequence.

To test our MCMC methods, we consider a scenario similar to those considered by Wood
(2010) and Fearnhead and Prangle (2012). The parameters of the Ricker model we use are
r = exp(3.8),  = 0.15,  = 2. We generated 100 points from the Ricker model, with yi only
observed from time 51 on, mimicking a situation where we do not observe a population right from
its inception.

We put a Uniform(0, 10) prior on log(r), a Uniform(0, 100) prior on , and a Uniform[log(0.1), 0]
prior on log(). Instead of Ni, we use Mi = log(Ni) as our state variables, since we found that
doing this makes MCMC sampling more ecient. With these state variables, our model can be
written as

M1  N (log(r) + log()  1, 2)

Mi|Mi1  N (log(r) + Mi1  exp(Mi1)/, 2),
i = 51, . . . , 100

Yi|Mi  Poisson(exp(Mi)),

i = 2, . . . , 100

(19)
(20)
(21)

Furthermore, the MCMC state uses the logarithms of the parameters, (log(r), log(), log()).

For parameter updates in the MCMC methods compared below, we used independent normal
proposals for each parameter, centered at the current parameter values, proposing updates to
all parameters at once. To choose appropriate proposal standard deviations, we did a number
of runs of the single sequence and the ensemble methods, and used these trial runs to estimate
the marginal standard deviations of the logarithm of each parameter. We got standard deviation
estimates of 0.14 for log(r), 0.36 for log(), and 0.065 for log(). We then scaled each estimated
marginal standard deviation by the same factor, and used the scaled estimates as the proposal
standard deviations for the corresponding parameters. The maximum scaling we used was 2,
since beyond this our proposals would often lie outside the high probability region of the marginal
posterior density.

We rst tried a simple Metropolis sampler on this problem. This sampler updates the latent
states one at a time, using Metropolis updates to sample from the full conditional density of each

11

state Mt, given by

p(m1|y51, . . . , y100, m1)  p(m1)p(m2|m1)
p(mi|y51, . . . , y100, mi)  p(mi|mi1)p(mi+1|mi),
p(mi|y51, . . . , y100, mi)  p(mi|mi1)p(yi|mi)p(mi+1|mi),

2  i  50

p(m100|y51, . . . , y100, m100)  p(m100|m99)p(y100|m100)

51  i  99

(22)
(23)
(24)
(25)

We started the Metropolis sampler with parameters set to prior means, and the hidden states to
randomly chosen values from the pool distributions we used for the embedded HMM methods
below. After we perform a pass over the latent variables, and update each one in turn, we perform
a Metropolis update of the parameters, using a scaling of 0.25 for the proposal density.

The latent states are updated sequentially, starting from 1 and going up to 100. When
updating each latent variable Mi, we use a Normal proposal distribution centered at the current
value of the latent variable, with the following proposal standard deviations. When we do not
observe yi, or yi = 0, we use the current value of  from the state times 0.5. When we observe

yi > 0, we use a proposal standard deviation of 1/(cid:112)1/2 + yi (with  from the state). This choice

can be motivated as follows. An estimate of precision for Mi given Mi1 is 1/2. Furthermore,
Yi is Poisson(Ni), so that Var(Ni)  yi and Var(log(Ni)) = Var(Mi)  1/yi. So an estimate
for the precision of Mi given yi is yi. We combine these estimates of precisions to get a proposal
standard deviation for the latent variables in the case when yi > 0.

We ran the Metropolis sampler for 6, 000, 000 iterations from ve dierent starting points.
The acceptance rate for parameter updates was between about 10% and 20%, depending on the
initial starting value. The acceptance rate for latent variable updates was between 11% and 84%,
depending on the run and the particular latent variable being sampled.

We found that the simple Metropolis sampler does not perform well on this problem. This
is most evident for sampling . The Metropolis sampler appears to explore dierent regions of
the posterior for  when it is started from dierent initial hidden state sequences. That is, the
Metropolis sampler can get stuck in various regions of the posterior for extended periods of time.
An example of the behaviour of the Metropolis sampler be seen on Figure 1. The autocorrelations
for the parameters are so high that accurately estimating them would require a much longer run.

This suggests that more sophisticated MCMC methods are necessary for this problem. We
next looked at the single-sequence method, the ensemble method, and the staged ensemble
method.

All embedded MCMC-based samplers require us to choose pool states for each time i. For
the is where no yis are observed, we choose our pool states by sampling values of exp(Mi) from
a pseudo-prior  for the Poisson mean exp(Mi)  a Gamma(k, ) distribution with k = 0.15 and
 = 50  and then taking logarithms of the sampled values. For the is where we observe yis we
choose our pool states by sampling values of exp(Mi) from the conditional density of exp(Mi)|yi
with  as the pseudo-prior. Since Yi|Mi is Poisson(exp(Mi)), the conditional density of exp(Mi)|yi
has a Gamma(k + yi, /(1 + )) distribution.

It should be noted that since we choose our pool states by sampling exp(Mi)s, but our model
is written in terms of Mi, the pool density i must take this into account. In particular, when yi

12

Figure 1: An example run of the simple Metropolis method.

Figure 2: An example ensemble method run, with 120 pool states and proposal scaling 1.4.

13

03,000,0006,000,000101100101102103iteration  rsigmaphi050,000100,000101100101102103iteration  rsigmaphiis unobserved, we have

i(mi) =

1

(k)k exp(kmi  exp(mi)/),  < mi < 

(26)

and when yi is observed we replace k with k + yi and  with /(1 + ). We use the same way of
choosing the pool states for all three methods we consider.

The staged ensemble MCMC method also requires us to choose a portion of the sequence to
use for the rst stage update. On the basis of several trial runs, we chose to use the last 20 points,
i.e. n1 = 81.

As we mentioned earlier, when likelihood evaluations are computationally inexpensive relative
to sequence updates, we can do multiple parameter updates for each update of the hidden state
sequence, without incurring a large increase in computation time. For the single-sequence method,
we do ten Metropolis updates of the parameters for each update of the hidden state sequence. For
the ensemble method, we do ve updates of the parameters for each update of the ensemble. For
staged ensemble MCMC, we do ten parameter updates for each update of the ensemble. These
choices were based on numerous trial runs.

We thin each of the single-sequence runs by a factor of ten when computing autocorrelation
times  hence the time per iteration for the single-sequence method is the time it takes to do a
single update of the hidden sequence and ten Metropolis updates. We do not thin the ensemble
and staged ensemble runs.

To compare the performance of the embedded HMM methods, and to tune each method, we
looked at the autocorrelation time,  , of the sequence of parameter samples, for each parameter.
The autocorrelation time can be thought of as the number of samples we need to draw using our
Markov chain to get the equivalent of one independent point (Neal (1993)). It is dened as

 = 1 + 2

k

(27)

(cid:88)

k=1

K(cid:88)

where k is the autocorrelation at lag k for a function of state that is of interest. Here, k =
k/0, where k is the estimated autocovariance at lag k. We estimate each k by estimating
autocovariances using each of the ve runs, using the overall mean from the ve runs, and then
averaging the resulting autocovariance estimates. We then estimate  by

 = 1 + 2

k

(28)

Here, the truncation point K is where the remaining ks are nearly zero.

k=1

For our comparisons to have practical validity, we need to multiply each estimate of autocor-
relation time estimate by the time it takes to perform a single iteration. A method that produces
samples with a lower autocorrelation time is often more computationally expensive than a method
that produces samples with a higher autocorrelation time, and if the dierence in computation
time is suciently large, the computationally cheaper method might be more ecient. Compu-
tation times per iteration were obtained with a program written in MATLAB on a Linux system
with an Intel Xeon X5680 3.33 GHz CPU.

14

Method

Pool
states Scaling

Acc.
Rate

Single-

sequence

Ensemble

Staged

Ensemble

10

20

40

60

80
40

60

80

120

180
40

60

80

120

180

Iter-
ations
400,000

400,000

0.25

12%

200,000

200,000

200,000
100,000

100,000

100,000

100,000

13%

11%

16%

14%

12%

100,000
30, 15% 100,000

27, 18% 100,000

30, 25% 100,000

25, 29% 100,000

23, 32% 100,000

0.6

1

1

1.4

1.8
1

1.4

1.4

1.8

2

Time /
iteration

r

ACT





0.09

0.17

0.31

0.47

0.61
0.23

0.34

0.47

0.76

1.26
0.10

0.14

0.21

0.29

0.45

4345

2362

7272

779

427

329

294
496

187

107

52

35
692

291

187

75

48

1875

1849

187

155

134
335

115

55

41

27
689

373

104

59

44

1317

879

869
897

167

90

45

29
1201

303

195

70

52

ACT  time

r
654


213

391

132

132

155

179
114

64

50

40

44
69

41

39

22

22

319

58

73

82
77

39

26

31

34
69

52

22

17

20

314

408

413

530
206

57

42

34

37
120

42

41

20

23

Table 1: Comparison of autocorrelation times.

For each number of pool states considered, we started the samplers from ve dierent initial
states. Like with the Metropolis method, the parameters were initialized to prior means, and the
hidden sequence was initialized to states randomly chosen from pool distribution at each time.
When estimating autocorrelations, we discarded the rst 10% of samples of each run as burn-in.

An example ensemble run is shown in Figure 2. Comparing with Figure 1, one can see that the
ensemble run has an enormously lower autocorrelation time. Autocorrelation time estimates for
the various ensemble methods, along with computation times, proposal scaling, and acceptance
rates, are presented in Table 1. For the staged ensemble method, the acceptance rates are shown
for the rst stage and second stage. We also estimated the parameters of the model by averaging
estimates of the posterior means from each of the ve runs for the single-sequence method with
40 pool states, the ensemble method with 120 pool states, and the staged ensemble method with
120 pool states. The results are presented in Table 2. The estimates using the three dierent
methods do not dier signicantly.

Method

Single-Sequence

Ensemble

Staged Ensemble

r

44.46 ( 0.09)
44.65 ( 0.09)
44.57 ( 0.04)



0.2074 ( 0.0012)
0.2089 ( 0.0009)
0.2089 ( 0.0010)



1.9921 ( 0.0032)
1.9853 ( 0.0013)
1.9878 ( 0.0015)

Table 2: Estimates of posterior means, with standard errors of posterior means shown in brackets.

15

From these results, one can see that for our Ricker model example, the single-sequence method
is less ecient than the ensemble method, when both methods are well-tuned and computation
time is taken into account. We also found that the the staged ensemble method allows us to
further improve performance of the ensemble method. In detail, depending on the parameter one
looks at, the best tuned ensemble method without staging (with 120 pool states) is between 1.9
and 12.0 times better than the best tuned single-sequence method (with 40 pool states). The
best tuned ensemble method with staging (120 pool states) is between 3.4 and 20.4 times better
than the best single-squence method.

The large drop in autocorrelation time for  for the single-sequence method between 20 and
40 pool states is due to poor mixing in one of the ve runs. To conrm whether this systematic,
we did ve more runs of the single sequence method, from another set of starting values, and
found that the same problem is again present in one of the ve runs. This is inidicative of a risk
of poor mixing when using the single-sequence sampler with a small number of pool states. We
did not observe similar problems for larger numbers of pool states.

The results in Table 1 show that performance improvement is greatest for the parameter .
One reason for this may be that the posterior distribution of  given a sequence is signicantly
more concentrated than the marginal posterior distribution of . Since for a suciently large
number of pool states, the posterior distribution given an ensemble approximates the marginal
posterior distribution, the posterior distribution of  given an ensemble will become relatively
more diuse than the posterior distributions of r and . This leads to a larger relative performance
improvement when sampling values of .

Evidence of this can be seen on Figure 3. To produce it, we took the hidden state sequence and
parameter values from the end of one of our ensemble runs, and performed Metropolis updates
for the parameters, while keeping the hidden state sequence xed. We also took the same hidden
state sequence and parameter values, mapped the hidden sequence to an ensemble of sequences
by generating a collection of pool states (we used 120) and peformed Metropolis updates of the
parameter part of the ensemble, keeping the pool states xed. We drew 50, 000 samples given a
single xed sequence and 2, 000 samples given an ensemble.

Figure 3: An illustration to aid explanation of relative performance. Note that the xed sequence
dots are smaller, to better illustrate the dierence in the spread between the xed sequence and
two other distributions.

16

20304050607080900.10.20.30.40.50.60.70.8rsigma20304050607080901.51.61.71.81.922.12.22.32.42.5rphi  marginalfixed ensemblefixed sequence0.10.20.30.40.50.60.70.81.51.61.71.81.922.12.22.32.42.5sigmaphiVisually, we can see that the posterior of  given a single sequence is signicantly more
concentrated than the marginal posterior, and the posterior given a xed ensemble of sequences.
Comparing the standard deviations of the posterior of  given a xed sequence, and the marginal
posterior of , we nd that the marginal posterior of  has a standard deviation about 21 times
larger than the posterior of  given a single sequence. The marginal posteriors for r and  have
a posterior standard deviation larger by a factor of 5.2 and 6.0. The standard deviation of the
posterior given our xed ensemble of sequences is greater for  by a factor of 11, and by factors
of 4.3 and 3.2 for r and . This is consisent with our explanation above.

We note that the actual timings of the runs are dierent from what one may expect.

In
theory, the computation time should scale as nL2, where L is the number of pool states and n
is the number of observations. However, the implementation we use, in MATLAB, implements
the forward pass as a nested loop over n and over L, with another inner loop over L vectorized.
MATLAB is an interpreted language with slow loops, and vectorizing loops generally leads to
vast performance improvements. For the numbers of pool states we use, the computational cost
of the vector operation corresponding to the inner loop over L is very low compared to that of the
outer loop over L. As a result, the total computational cost scales approximately linearly with
L, in the range of values of L we considered. An implementation in a dierent language might
lead to dierent optimal pool state settings.

The original examples of Wood and Fearnhead and Prangle used  = 10 instead of  = 2.
We found that for  = 10, the ensemble method still performs better than the single sequence
method, when computation time is taken into account, though the dierence in performance is
not as large. When  is larger, the observations yi are larger on average as well. As a result,
the data is more informative about the values of the hidden state variables, and the marginal
posteriors of the model parameters are more concentrated. As a result of this, though we would
still expect the ensemble method to improve performance, we would not expect the improvement
to be as large as when  = 2.

Finally, we would like to note that if the single-sequence method is implemented already, im-
plementing the ensemble method is very simple, since all that is needed is an additional call of the
forward pass function and summing of the nal forward probabilities. So, the performance gains
from using an ensemble for parameter updates can be obtained with little additional programming
eort.

9 Conclusion

We found that both the embedded HMM MCMC method and its ensemble extension perform
signicantly better than the ordinary Metropolis method for doing Bayesian inference in the
Ricker model. This suggests that it would be promising to investigate other state space models
with non-linear state dynamics, and see if it is possible to use the embedded HMM methods we
described to perform inference in these models.

Our results also show that using staged proposals further improves the performance of the
ensemble method. It would be worthwhile to look at other scenarios where this technique might

17

be applied.

Most importantly, however, our results suggest that looking at multiple hidden state sequences
at once can make parameter sampling in state space models noticeably more ecient, and so
indicate a direction for further research in the development of MCMC methods for non-linear,
non-Gaussian state space models.

Acknowledgements

This research was supported by the Natural Sciences and Engineering Research Council of
Canada. A. S. is in part funded by an NSERC Postgraduate Scholarship. R. N. holds a Canada
Research Chair in Statistics and Machine Learning.

