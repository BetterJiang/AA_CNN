we propose a non - linear generative model for human motion data that uses an undirected model with binary latent variables and real - valued visible variables that represent joint angles .
the latent and visible variables at each time step re - ceive directed connections from the visible variables at the last few time - steps .
such an architecture makes on - line inference efcient and allows us to use a sim - ple approximate learning procedure .
after training , the model nds a single set of parameters that simultaneously capture several different kinds of motion .
we demonstrate the power of our approach by synthesizing various motion sequences and by performing on - line lling in of data lost during motion capture .
recent advances in motion capture technology have fueled interest in the analysis and synthesis of complex human motion for animation and tracking .
models based on the physics of masses and springs have produced some impressive results by using sophisticated energy - based learning methods ( 123 ) to estimate physical parameters from motion capture data ( 123 ) .
but if we want to generate realistic human motion , we need to model all the complexities of the real dynamics and this is so difcult to do analytically that learning is likely to be essential .
the simplest way to generate new motion sequences based on data is to concatenate parts of training sequences ( 123 ) .
another method is to transform motion in the training data to new sequences by learning to adjusting its style or other characteristics ( 123 , 123 , 123 ) .
in this paper we focus on model driven analysis and synthesis but avoid the complexities involved in imposing physics - based constraints , relying instead on a pure learning approach in which all the knowledge in the model comes from the data .
data from modern motion capture systems is high - dimensional and contains complex non - linear relationships between the components of the observation vector , which usually represent joint angles with respect to some skeletal structure .
hidden markov models cannot model such data efciently because they rely on a single , discrete k - state multinomial to represent the history of the time series .
to model n bits of information about the past history they require 123n hidden states .
to avoid this exponential explosion , we need a model with distributed ( i . e .
componential ) hidden state that has a representational capacity which is linear in the number of components .
linear dynamical systems satisfy this requirement , but they cannot model the complex non - linear dynamics created by the non - linear properties of muscles , contact forces of the foot on the ground and myriad other factors .
123 an energy - based model for vectors of real - values
in general , using distributed binary representations for hidden state in directed models of time series makes inference difcult .
if , however , we use a restricted boltzmann machine ( rbm ) to model the probability distribution of the observation vector at each time frame , the posterior over latent variables factorizes completely , making inference easy .
typically , rbms use binary logistic units for both the visible data and hidden variables , but in our application the data ( comprised of joint angles ) is continuous .
we thus use a modied rbm in which the visible units are linear , real - valued variables that have gaussian noise ( 123 , 123 ) .
the graphical model has a layer of visible units v and a layer of hidden units h; there are undirected connections between layers but no connections within a layer .
for any setting of the hidden units , the distribution of each visible unit is dened by a parabolic log likelihood function that makes extreme values very improbable : 123
log p ( v , h ) = x
hjwij + const ,
where i is the standard deviation of the gaussian noise for visible unit i .
( in practice , we rescale our data to have zero mean and unit variance .
we have found that xing i at 123 makes the learning work well even though we would expect a good model to predict the data with much higher precision ) .
the main advantage of using this undirected , energy - based model rather than a directed belief net is that inference is very easy because the hidden units become conditionally independent when the states of the visible units are observed .
the conditional distributions ( assuming i = 123 ) are :
p ( hj = 123|v ) = f ( bj + x
p ( vi|h ) = n ( ci + x
hjwij , 123 ) ,
where f ( ) is the logistic function , n ( , v ) is a gaussian , bj and ci are the biases of hidden unit j and visible unit i respectively , and wij is the symmetric weight between them .
maximum likelihood learning is slow in an rbm but learning still works well if we approximately follow the gradient of another function called the contrastive divergence ( 123 ) .
the learning rule is :
wij hvihjidata hvihjirecon ,
where the rst expectation ( over hidden unit activations ) is with respect to the data distribution and the second expectation is with respect to the distribution of reconstructed data .
the reconstructions are generated by starting a markov chain at the data distribution , updating all the hidden units in parallel by sampling ( eq .
123 ) and then updating all the visible units in parallel by sampling ( eq .
for both expectations , the states of the hidden units are conditional on the states of the visible units , not vice versa .
the learning rule for the hidden biases is just a simplied version of eq
bj hhj idata hhjirecon .
123 the conditional rbm model
the rbm we have described above models static frames of data , but does not incorporate any tem - poral information .
we can model temporal dependencies by treating the visible variables in the previous time slice as additional xed inputs ( 123 ) .
fortunately , this does not complicate inference .
we add two types of directed connections ( figure 123 ) : autoregressive connections from the past n congurations ( time steps ) of the visible units to the current visible conguration , and connections from the past m visibles to the current hidden conguration .
the addition of these directed con - nections turns the rbm into a conditional rbm ( crbm ) .
in our experiments , we have chosen n = m = 123
these are , however , tunable parameters and need not be the same for both types of directed connections .
to simplify discussion , we will assume n = m and refer to n as the order of
123for any setting of the parameters , the gradient of the quadratic log likelihood will always overwhelm the gradient due to the weighted input from the binary hidden units provided the value vi of a visible unit is far enough from its bias , ci .
figure 123 : in a trained model , probabilities of each feature being on conditional on the data at the visible units .
shown is a 123 - hidden unit model , and a sequence which contains ( in order ) walking , sitting / standing ( three times ) , walking , crouching , and running .
rows represent features , columns represent sequential frames .
inference in the crbm is no more difcult than in the standard rbm .
given the data at time t , t 123 , .
, t n , the hidden units at time t are conditionally independent .
we can still use contrastive divergence for training the crbm .
the only change is that when we update the visible and hidden units , we implement the directed con - nections by treating data from previous time steps as a dynamically changing bias .
the contrastive divergence learning rule for hidden biases is given in eq .
123 and the equivalent learning rule for the tem - poral connections that determine the dynamically changing hidden unit biases is :
is the log - linear parameter ( weight ) connecting visible unit i at time t q to hidden unit j for q = 123 . n .
similarly , the learning rule for the autoregressive connections that determine the dynamically changing visible unit biases is :
i irecon ( cid : 123 ) .
is the weight from visible unit k at time t q to visible
the autoregressive weights can model short - term temporal structure very well , leaving the hidden units to model longer - term , higher level structure .
during training , the states of the hidden units are deter - mined by both the input they receive from the observed data and the input they receive from the previous time slices .
the learning rule for w remains the same as a standard rbm , but has a different ef - fect because the states of the hidden units are now inuenced by the previous visible units .
we do not attempt to model the rst n frames of each sequence .
t - 123 t - 123 t
figure 123 : architecture of our model ( in our experi - ments , we use three previous
while learning a model of motion , we do not need to proceed sequentially through the training data sequences .
the updates are only conditional on the past n time steps , not the entire sequence .
as long as we isolate chunks of frames ( the size depending on the order of the directed connections ) , these can be mixed and formed into mini - batches .
to speed up the learning , we assemble these chunks of frames into balanced mini - batches of size 123
we randomly assign chunks to different mini - batches so that the chunks in each mini - batch are as uncorrelated as possible .
to save computer memory , time frames are not actually replicated in mini - batches; we simply use indexing to simulate the chunking of frames .
our training procedure relies on several approximations , most of which are chosen based on ex - perience training similar networks .
while training the crbm , we replaced vi in eq .
123 and eq .
123 by its expected value and we also used the expected value of vi when computing the probability of activation of the hidden units .
however , to compute the one - step reconstructions of the data , we used stochastically chosen binary values of the hidden units .
this prevents the hidden activities from transmitting an unbounded amount of information from the data to the reconstruction ( 123 ) .
while updating the directed visible - to - hidden connections ( eq .
123 ) and the symmetric undirected connections ( eq .
123 ) we used the stochastically chosen binary values of the hidden units in the rst term ( under the data ) , but replaced hj by its expected value in the second term ( under the reconstruc - tion ) .
we took this approach because the reconstruction of the data depends on the binary choices made when selecting hidden state .
thus when we infer the hiddens from the reconstructed data , the probabilities are highly correlated with the binary hidden states inferred from the data .
on the other hand , we stop after one reconstruction , so the binary choice of hiddens from the reconstruction doesnt correlate with any other terms , and there is no point including this extra noise .
lastly , we note that the ne - tuning procedure as a whole is making a crude approximation in addition to the one made by contrastive divergence .
the inference step , conditional on past visible states , is approximate because it ignores the future ( it does not do smoothing ) .
because of the directed connections , exact inference within the model should include both a forward and backward pass through each sequence ( we currently perform only a forward pass ) .
we have avoided a backward pass because missing values create problems in undirected models , so it is hard to perform learning efciently using the full posterior .
compared with an hmm , the lack of smoothing is a loss , but this is more than offset by the exponential gain in representational power .
123 data gathering and preprocessing
we used data from the cmu graphics lab motion capture database as well as from ( 123 ) ( see acknowledgments ) .
the processed data consists of 123d joint angles derived from 123 ( cmu ) or 123 ( mit ) markers plus a root ( coccyx , near the base of the back ) orientation and displacement .
for both datasets , the original data was captured at 123hz; we have downsampled it to 123hz .
six of the joint angle dimensions in the original cmu data had constant values , so they were elim - inated .
each of the remaining joint angles had between one and three degrees of freedom .
all of the joint angles and the root orientation were converted from euler angles to the exponential map parameterization ( 123 ) .
this was done to avoid gimbal lock and discontinuities .
( the mit data was already expressed in exponential map form and did not need to be converted . )
we treated the root specially because it encodes a transformation with respect to a xed global coordinate system .
in order to respect physics , we wanted our nal representation to be invariant to ground - plane translation and to rotation about the gravitational vertical .
we represented each ground - plane translation by an incremental forwards vector and an incremental sideways vector relative to the direction the person was currently facing , but we represented height non - incrementally by the distance above the ground plane .
we represented orientation around the gravitational vertical by the incremental change , but we represented the other two rotational degrees of freedom by the absolute pitch and roll relative to the direction the person was currently facing .
the nal dimensionality of our data vectors was 123 ( for the cmu data ) and 123 ( for the mit data ) .
note that we eliminated exponential map dimensions that were constant zero ( corresponding to joints with a single degree of freedom ) .
as mentioned in sec .
123 , each component of the data was normalized to have zero mean and unit variance .
one advantage of our model is the fact that the data does not need to be heavily preprocessed or dimensionality reduced .
brand and hertzmann ( 123 ) apply pca to reduce noise and dimensionality .
the autoregressive connections in our model can be thought of as doing a kind of whitening of the data .
urtasun et al .
( 123 ) manually segment data into cycles and sample at regular time intervals using quaternion spherical interpolation .
dimensionality reduction becomes problematic when a wider range of motions is to be modeled .
after training our model using the updates described above , we can demonstrate in several ways what it has learned about the structure of human motion .
perhaps the most direct demonstration , which exploits the fact that it is a probability density model of sequences , is to use the model to generate de - novo a number of synthetic motion sequences .
video les of these sequences are avail - able on the website mentioned in the abstract; these motions have not been retouched by hand in any motion editing software .
note that we also do not have to keep a reservoir of training data sequences around for generation - we only need the weights of the model and a few valid frames for
causal generation from a learned model can be done on - line with no smoothing , just like the learning procedure .
the visible units at the last few time steps determine the effective biases of the visible and hidden units at the current time step .
we always keep the previous visible states xed and perform alternating gibbs sampling to obtain a joint sample from the conditional rbm .
this picks new hidden and visible states that are compatible with each other and with the recent ( visible ) history .
generation requires initialization with n time steps of the visible units , which implicitly determine the mode of motion in which the synthetic sequence will start .
we used randomly drawn consecutive frames from the training data as an initial conguration .
123 generation of walking and running sequences from a single model
in our rst demonstration , we train a single model on data containing both walking and running motions; we then use the learned model to generate both types of motion , depending on how it is initialized .
we trained123 on 123 sequences of walking and 123 sequences of jogging ( from subject 123 in the cmu database ) .
after downsampling to 123hz , the training data consisted of 123 frames .
figure 123 : after training , the same model can generate walking ( top ) and running ( bottom ) motion ( see videos on the website ) .
each skele - ton is 123 frames apart .
figure 123 shows a walking sequence and a running sequence generated by the same model , using al - ternating gibbs sampling ( with the probability of hidden units being on conditional on the current and previous three visible vectors ) .
since the training data does not contain any transitions between walking and running ( and vice - versa ) , the model will continue to generate walking or running mo - tions depending on where it is initialized .
123 learning transitions between various styles
in our second demonstration , we show that our model is capable of learning not only several homo - geneous motion styles but also the transitions between them , when the training data itself contains
123a 123 hidden - unit crbm was trained for 123 passes through the training data , using a third - order model ( for directed connections ) .
weight updates were made after each mini - batch of size 123
the order of the sequences was randomly permuted such that walking and running sequences were distributed throughout the
examples of such transitions .
we trained on 123 sequences ( from the mit database , le jog123 m ) con - taining long examples of running and jogging , as well as a few transitions between the two styles .
after downsampling to 123hz , this provided us with 123 frames .
training was done as before , ex - cept that after the model was trained , an identical 123 hidden - unit model was trained on top of the rst model ( see sec .
the resulting two - level model was used to generate data .
a video available on the website demonstrates our models ability to stochastically transition between various motion styles during a single generated sequence .
123 introducing transitions using noise
in our third demonstration , we show how transitions between motion styles can be generated even when such transitions are absent in the data .
we use the same model and data as described in sec .
123 , where we have learned on separate sequences of walking and running .
to generate , we use the same sampling procedure as before , except that at each time we stochastically choose the hidden states ( given the current and previous three visible vectors ) we add a small amount of gaussian noise to the hidden state biases .
this encourages the model to explore more of the hidden state space without deviating too far the current motion .
applying this noisy sampling approach , we see that the generated motion occasionally transitions between learned styles .
these transitions appear natural ( see the video on the website ) .
123 filling in missing data
due to the nature of the motion capture process , which can be adversely affected by lighting and environmental effects , as well as noise during recording , motion capture data often contains missing or unusable data .
some markers may disappear ( dropout ) for long periods of time due to sen - sor failure or occlusion .
the majority of motion editing software packages contain interpolation methods to ll in missing data , but this leaves the data unnaturally smooth .
these methods also rely on the starting and end points of the missing data , so if a marker goes missing until the end of a sequence , nave interpolation will not work .
such methods often only use the past and future data from the single missing marker to ll in that markers missing values , but since joint angles are highly correlated , substantial information about the placement of one marker could be gained from the others .
our trained model has the ability to easily ll in such missing data , regardless of where the dropouts occur in a sequence .
due to its approximate inference method which does not rely on a backward pass through the sequence , it also has the ability to ll in such missing data on - line .
filling in missing data with our model is very similar to generation .
we simply clamp the known data to the visible units , initialize the missing data to something reasonable ( for example , the value at the previous frame ) , and alternate between stochastically updating the hidden and visible units , with the known visible states held xed .
to demonstrate lling in , we trained a model exactly as described in sec .
123 except that one walking and one running sequence were left out of the training data to be used as test data .
for each of these walking and running test sequences , we erased two different sets of joint angles , starting halfway through the test sequence .
these sets were the joints in ( 123 ) the left leg , and ( 123 ) the entire upper body .
as seen in the video les on the website , the quality of the lled - in data is excellent and is hardly distinguishable from the original ground truth of the test sequence .
figure 123 demonstrates the models ability to predict the three angles of rotation of the left hip .
for the walking sequence ( of length 123 frames ) , we compared our models performance to nearest neighbor interpolation , a simple method where for each frame , the values on known dimensions are compared to each example in the training set to nd the closest match ( measured by euclidean dis - tance in the normalized angle space ) .
the unknown dimensions are then lled in using the matched example .
as reconstruction from our model is stochastic , we repeated the experiment 123 times and report the mean .
for the missing leg , mean squared reconstruction error per joint using our model was 123 , measured in normalized joint angle space , and summed over the 123 frames of interest .
using nearest neighbor interpolation , the error was greater : 123 .
for the missing upper body , mean squared reconstruction error per joint using our model was 123 .
using nearest neighbor interpolation , again the error was greater : 123 .
figure 123 : the model successfully lls in missing data using only the previous values of the joint angles ( through the temporal connections ) and the current angles of other joints ( through the rbm connections ) .
shown are two of the three angles of rotation for the left hip joint ( the plot of the third is similar to the rst ) .
the original data is shown on a solid line , the models prediction is shown on a dashed line , and the results of nearest neighbor interpolation are shown on a dotted line ( see a video on the website ) .
123 higher level models
once we have trained the model , we can add layers like in a deep belief network ( 123 ) .
the previous layer crbm is kept , and the sequence of hidden state vectors , while driven by the data , is treated as a new kind of fully observed data .
the next level crbm has the same architecture as the rst ( though we can alter the number of its units ) and is trained in the exact same way .
upper levels of the network can then model higher - order structure .
this greedy procedure is justied using a variational bound ( 123 ) .
a two - level model is shown in figure 123
we can also consider two special cases of the higher - level model .
if we keep only the visible layer , and its n - th order directed connections , we have a standard ar ( n ) model with gaussian noise .
if we take the two - hidden layer model and delete the rst - level autoregressive connections , as well as both sets of visible - to - hidden directed connections , we have a simplied model that can be trained in 123 stages : rst learning a static ( iid ) model of pairs or triples of time frames , then using the inferred hidden states to train a fully - observed sigmoid belief net that captures the temporal structure of the hidden states .
t - 123 t - 123 t
figure 123 : higher -
we have introduced a generative model for human motion based on the idea that local constraints and global dynamics can be learned efciently by a conditional restricted boltzmann machine .
once trained , our models are able to efciently capture complex non - linearities in the data without sophisticated pre - processing or dimensionality reduction .
the model has been designed with human motion in mind , but should lend itself well to other high - dimensional time series .
in relatively low - dimensional or unstructured data ( for example if we were to model a single isolated joint ) a single - layer model might be expected to have difculty since such cyclic time series contain several subsequences which are locally very similar but occur in different phases of the overall cycle .
it would be possible to preserve the global phase information by using a much higher order model , but for higher dimensional data such as full body motion capture this is unnecessary because the whole conguration of joint angles and angular velocities never has any phase ambiguity .
so the single - layer version of our model actually performs much better on higher - dimensional data .
models with more hidden layers are able to implicitly model longer - term temporal information , and thus will mitigate this effect .
we have demonstrated that our model can effectively learn different styles of motion , as well as the transitions between these styles .
this differentiates our approach from pca - based approaches which only accurately model cyclic motion , and additionally must build separate models for each type of motion .
the ability of the model to transition smoothly , however , is dependent on having sufcient examples of such transitions in the training data .
we plan to train on larger datasets en - compassing such transitions between various styles of motion .
if we augment the data with some static skeletal and identity parameters ( in essence mapping a persons unique identity to a set of fea - tures ) , we should be able to use the same generative model for many different people , and generalize individual characteristics from one type of motion to another .
finally , our model is not limited to a single source of data .
in the future , we hope to integrate low - level vision data captured at the same time as motion; we could then learn the correlations between the vision stream and the joint angles .
the rst data set used in this project was obtained from mocap . cs . cmu . edu .
this database was created with funding from nsf eia - 123
the second data set used in this project was obtained from http : / / people . csail . mit . edu / ehsu / work / sig123stf / .
for matlab playback of motion and generation of videos , we have used neil lawrences motion capture toolbox
