motivated by navigation and tracking applications within sensor networks , we consider the prob -
lem of performing kalman ltering with intermittent observations .
when data travel along unreliable
communication channels in a large , wireless , multi - hop sensor network , the effect of communication
delays and loss of information in the control loop cannot be neglected .
we address this problem starting
from the discrete kalman ltering formulation , and modelling the arrival of the observation as a random
process .
we study the statistical convergence properties of the estimation error covariance , showing the
existence of a critical value for the arrival rate of the observations , beyond which a transition to an
unbounded state error covariance occurs .
we also give upper and lower bounds on this expected state
this research is partially supported by darpa under grant f123 - 123 - c - 123
advances in vlsi and mems technology have boosted the development of micro sensor
integrated systems .
such systems combine computing , storage , radio technology , and energy
source on a single chip ( 123 ) ( 123 ) .
when distributed over a wide area , networks of sensors can
perform a variety of tasks that range from environmental monitoring and military surveillance ,
to navigation and control of a moving vehicle ( 123 ) ( 123 ) ( 123 ) .
a common feature of these systems
is the presence of signicant communication delays and data loss across the network .
from the
point of view of control theory , signicant delay is equivalent to loss , as data needs to arrive
to its destination in time to be used for control .
in short , communication and control become
tightly coupled such that the two issues cannot be addressed independently .
consider , for example , the problem of navigating a vehicle based on the estimate from a sensor
web of its current position and velocity .
the measurements underlying this estimate can be lost
or delayed due to the unreliability of the wireless links .
what is the amount of data loss that the
control loop can tolerate to reliably perform the navigation task ? can communication protocols
be designed to satisfy this constraint ? at berkeley , we have faced these kind of questions in
building sensor networks for pursuit evasion games as part of the network of embedded systems
technology ( nest ) project ( 123 ) .
practical advances in the design of these systems are described
in ( 123 ) .
the goal of this paper is to examine some control - theoretic implications of using sensor
networks for control .
these require a generalization of classical control techniques that explicitly
take into account the stochastic nature of the communication channel .
in our setting , the sensor network provides observed data that are used to estimate the state of a
controlled system , and this estimate is then used for control .
we study the effect of data losses due
to the unreliability of the network links .
we generalize the most ubiquitous recursive estimation
technique in controlthe discrete kalman lter ( 123 ) modelling the arrival of an observation
as a random process whose parameters are related to the characteristics of the communication
channel , see figure 123
we characterize the statistical convergence of the expected estimation
error covariance in this setting .
the classical theory relies on several assumptions that guarantee convergence of the kalman
overview of the system .
we study the statistical convergence of the expected estimation error covariance of the discrete
kalman lter , where the observation , travelling over an unreliable communication channel , can be lost at each time step with probability 123 .
consider the following discrete time linear dynamical system :
xt+123 = axt + wt
yt = cxt + vt ,
where xt ( cid : 123 ) n is the state vector , yt ( cid : 123 ) m the output vector , wt ( cid : 123 ) p and vt ( cid : 123 ) m are gaussian random vectors with zero mean and covariance matrices q 123 and r > 123 , respectively .
wt is independent of ws for s < t .
assume that the initial state , x123 , is also a gaussian vector of zero mean and covariance 123
under the hypothesis of stabilizability of the pair ( a , q ) and detectability of the pair ( a , c ) , the estimation error covariance of the kalman lter converges
to a unique value from any initial condition ( 123 ) .
these assumptions have been relaxed in various ways ( 123 ) .
extended kalman ltering attempts
to cope with nonlinearities in the model; particle ltering is also appropriate for nonlinear
systemkalman filtermz - 123mz - 123+++ - 123
models and additionally does not require the noise model to be gaussian .
recently , more
general observation processes have been studied .
in particular , in ( 123 ) , ( 123 ) the case in which
observations are randomly spaced in time according to a poisson process has been studied , where
the underlying dynamics evolve in continuous time .
these authors showed the existence of a
lower bound on the arrival rate of the observations below which it is possible to maintain the
estimation error covariance below a xed value , with high probability .
the results were restricted
to scalar siso systems .
we approach a similar problem within the framework of discrete time , and provide results
for general n - dimensional mimo systems .
in particular , we consider a discrete - time system in
which the arrival of an observation is a bernoulli process with parameter 123 < < 123 , and ,
rather than asking for the estimation error covariance to be bounded with high probability , we
study the asymptotic behavior ( in time ) of its average .
our main contribution is to show that ,
depending on the eigenvalues of the matrix a , and on the structure of the matrix c , there exists
a critical value c , such that if the probability of arrival of an observation at time t is > c , then the expectation of the estimation error covariance is always nite ( provided that the usual stabilizability and detectability hypotheses are satised ) .
if c , then the expectation of the estimation error covariance tends to innity .
we give explicit upper and lower bounds on c , and show that they are tight in some special cases .
philosophically this result can be seen as another manifestation of the well known uncertainty
threshold principle ( 123 ) , ( 123 ) .
this principle states that optimum long - range control of a dy -
namical system with uncertainty parameters is possible if and only if the uncertainty does not
exceed a given threshold .
the uncertainty is modelled as white noise scalar sequences acting
on the system and control matrices .
in our case , the result is for optimal estimation , rather than
optimal control , and the uncertainty is due to the random arrival of the observation , with the
randomness arising from losses in the network .
studies on ltering with intermittent observations can be tracked back to nahi ( 123 ) and hadidi
more recently , this problem has been studied using jump linear systems ( jls ) ( 123 )
are stochastic hybrid systems characterized by linear dynamics and discrete regime transitions
modelled as markov chains .
in the work of costa et al .
( 123 ) and nilsson et al .
( 123 ) , ( 123 ) , the
kalman lter with missing observations is modelled as a jls switching between two discrete
regimes : an open loop conguration and a closed loop one .
following this approach , these authors
obtain convergence criteria for the expected estimation error covariance .
however , they restrict
their formulation to the steady state case , where the kalman gain is constant , and they do not
assume to know the switching sequence .
the resulting process is wide sense stationary ( 123 ) , and
this makes the exact computation of the transition probability and state error covariance possible .
other work on optimal , constant gain ltering was done by wang et al .
( 123 ) , who included the
presence of system parameters uncertainty besides missing observations , and smith et al
who considered multiple lters fusion .
instead , we consider the general case of time varying
kalman gain .
in presence of missing observations , this lter has a smaller linear minimum mean
square error ( lmmse ) than its static counterpart , as it is detailed in section ii .
the general case of time - varying kalman lter with intermittent observations was also studied
by fortmann et al .
( 123 ) , who derived stochastic equations for the state covariance error .
however ,
they do not statistically characterize its convergence and provide only numerical evidence of the
transition to instability , leaving a formal characterization of this as an open problem , which is
addressed in this paper .
a somewhat different formulation was considered in ( 123 ) , where the
observations arrival have a bounded delay .
finally , we point out that our analysis can also be viewed as an instance of expectation -
maximization ( em ) theory .
em is a general framework for doing maximum likelihood esti -
mation in missing - data models ( 123 ) .
lauritzen ( 123 ) shows how em can be used for general
graphical models .
in our case , however , the graph structure is a function of the missing data , as
there is one graph for each pattern of missing data .
the paper is organized as follows .
in section ii we formalize the problem of kalman ltering
with intermittent observations .
in section iii we provide upper and lower bounds on the expected
estimation error covariance of the kalman lter , and nd the conditions on the observation arrival
probability for which the upper bound converges to a xed point , and for which the lower
bound diverges .
section iv describes some special cases and gives an intuitive understanding of
the results .
in section v we compare our approach to previous ones ( 123 ) based on jump linear
systems .
finally , in section vi , we state our conclusions and give directions for future work .
problem formulation
consider the canonical state estimation problem .
we dene the arrival of the observation at
time t as a binary random variable t , with probability distribution pt ( 123 ) = t , and with t
independent of s if t ( cid : 123 ) = s .
the output noise vt is dened in the following way :
n ( 123 , r )
n ( 123 , 123i )
: t = 123
: t = 123 ,
for some 123 .
therefore , the variance of the observation at time t is r if t is 123 , and 123i otherwise .
in reality the absence of observation corresponds to the limiting case of .
our approach is to re - derive the kalman lter equations using a dummy observation with a given variance when the real observation does not arrive , and then take the limit as .
first let us dene :
= e ( xt|yt , t ) = e ( ( xt x ) ( xt x ) ( cid : 123 ) |yt , t ) = e ( xt+123|yt , t+123 ) = e ( ( xt+123 xt+123 ) ( xt+123 xt+123 ) ( cid : 123 ) |yt , t+123 ) = e ( yt+123|yt , t+123 ) ,
= ( y123 , .
, yt ) ( cid : 123 ) and t
= ( 123 , .
, t ) ( cid : 123 ) .
using the dirac delta
where we have dened the vectors yt ( ) we have :
e ( ( yt+123 yt+123|t ) ( xt+123 xt+123|t ) ( cid : 123 ) |yt , t+123 ) = cpt+123|t
e ( ( yt+123 yt+123|t ) ( yt+123 yt+123|t ) ( cid : 123 ) |yt , t+123 ) = cpt+123|tc ( cid : 123 ) + ( t+123 123 ) r + ( t+123 ) 123i ,
and it follows that the random variables xt+123 and yt+123 , conditioned on the output yt and on the arrivals t+123 , are jointly gaussian with mean
e ( xt+123 , yt+123|yt , t+123 ) =
cov ( xt+123 , yt+123|yt , t+123 ) =
cpt+123|t cpt+123|tc ( cid : 123 ) + ( t+123 123 ) r + ( t+123 ) 123i
hence , the kalman lter equations are modied as follows :
xt+123|t = axt|t pt+123|t = apt|ta ( cid : 123 ) + q
xt+123|t+123 = xt+123|t + pt+123|tc ( cid : 123 ) ( cpt+123|tc ( cid : 123 ) + ( t+123 123 ) r + ( t+123 ) 123i ) 123 ( yt+123 c xt+123|t ) pt+123|t+123 = pt+123|t pt+123|tc ( cid : 123 ) ( cpt+123|tc ( cid : 123 ) + ( t+123 123 ) r + ( t+123 ) 123i ) 123cpt+123|t .
taking the limit as , the update equations ( 123 ) and ( 123 ) can be rewritten as follows :
xt+123|t+123 = xt+123|t + t+123pt+123|tc ( cid : 123 ) ( cpt+123|tc ( cid : 123 ) + r ) 123 ( yt+123 c xt+123|t ) pt+123|t+123 = pt+123|t t+123pt+123|tc ( cid : 123 ) ( cpt+123|tc ( cid : 123 ) + r ) 123cpt+123|t .
note that performing this limit corresponds exactly to propagating the previous state when
there is no observation update available at time t .
we also point out the main difference from
the standard kalman lter formulation : both xt+123|t+123 and pt+123|t+123 are now random variables , being a function of t+123 , which is itself random .
it is important to stress that equations ( 123 ) - ( 123 ) give the minimum state error variance lter
given the observations ( yt ) and their arrival sequence ( t ) , i . e .
t = e ( xt|yn , .
, y123; n , .
as a consequence , the lter proposed in this paper is neces - sarily time - varying and stochastic since it depends on the arrival sequence .
the lters that have
been proposed so far using jls theory ( 123 ) ( 123 ) give the minimum state error variance lters assuming that only the observations ( yt ) are available , i . e .
xjls t = e ( xt|yn , .
therefore , the lter given by equations ( 123 ) - ( 123 ) gives a better performance than its jls counterparts , since
it exploits additional information regarding the arrival sequence .
given the new formulation , we now study the riccati equation of the state error covariance
matrix in the specic case when the arrival process of the observation is time - independent , i . e .
t = for all time .
this will allow us to provide deterministic upper and lower bounds on its expectation .
we then characterize the convergence of these upper and lower bounds , as a
function of the arrival probability of the observation .
convergence conditions and transition to instability
it is easy to verify that the modied kalman lter formulation in equations ( 123 ) and ( 123 ) can
be rewritten as follows :
pt+123 = apta ( cid : 123 ) + q t aptc ( cid : 123 ) ( cptc ( cid : 123 ) + r ) 123cpta ( cid : 123 ) ,
where we use the simplied notation pt = pt|t123
since the sequence ( t ) modied kalman lter iteration is stochastic and cannot be determined off - line .
therefore , only
is random , the
statistical properties can be deduced .
in this section we show the existence of a critical value
c for the arrival probability of the observation update , such that for > c the mean state covariance e ( pt ) is bounded for all initial conditions , and for c the mean state covariance diverges for some initial condition .
we also nd a lower bound , and upper bound , for the critical probability c , i . e . , c .
the lower bound is expressed in closed form; the upper bound is the solution of a linear matrix inequality ( lmi ) .
in some special cases the two bounds
coincide , giving a tight estimate .
finally , we present numerical algorithms to compute a lower bound s , and upper bound v , for limt e ( pt ) , when it is bounded .
first , we dene the modied algebraic riccati equation ( mare ) for the kalman lter with
intermittent observations as follows ,
g ( x ) = axa ( cid : 123 ) + q axc ( cid : 123 ) ( cxc ( cid : 123 ) + r ) 123cxa ( cid : 123 ) .
our results derive from two principal facts : the rst is that concavity of the modied algebraic
riccati equation for our lter with intermittent observations allows use of jensens inequality to
nd an upper bound on the mean state covariance; the second is that all the operators we use to
estimate upper and lower bounds are monotonically increasing , therefore if a xed point exists ,
it is also stable .
we formally state all main results in form of theorems .
omitted proofs appear in the appendix .
the rst theorem expresses convergence properties of the mare .
theorem 123
consider the operator ( k , x ) = ( 123 ) ( axa ( cid : 123 ) + q ) + ( f xf ( cid : 123 ) + v ) , where f = a + kc , v = q + krk ( cid : 123 ) .
suppose there exists a matrix k and a positive denite matrix p such that
p > 123 and
p > ( k , p )
( a ) for any initial condition p123 123 , the mare converges , and the limit is independent of the initial condition :
t pt = lim
( p123 ) = p
( b ) p is the unique positive semidenite xed point of the mare .
the next theorem states the existence of a sharp transition .
theorem 123
if ( a , q 123 a c ( 123 , 123 ) such that
123 ) is controllable , ( a , c ) is detectable , and a is unstable , then there exists
t e ( pt ) = + for 123 c and some initial condition p123 123 e ( pt ) mp123 t for c < 123 and any initial condition p123 123
where mp123 > 123 depends on the initial condition p123 123
the next theorem gives upper and lower bounds for the critical probability c .
theorem 123
= arginf ( s | s = ( 123 ) a sa ( cid : 123 ) + q ) = 123 123 = arginf ( ( k , x ) | x > ( k , x ) ) where = maxi |i| and i are the eigenvalues of a
finally , the following theorem gives an estimate of the limit of the mean covariance matrix
e ( pt ) , when this is bounded .
theorem 123
assume that ( a , q 123
123 ) is controllable , ( a , c ) is detectable and > , where is
dened in theorem 123
123 st e ( pt ) vt
123we use the notation limt at = + when the sequence at 123 is not bounded; i . e . , there is no matrix m 123 such
that at m , t .
where limt st = s and limt vt = v , where s and v are solution of the respective algebraic equations s = ( 123 ) a sa ( cid : 123 ) + q and v = g ( v )
the previous theorems give lower and upper bounds for both the critical probability c and for the mean error covariance e ( pt ) .
the lower bound is expressed in closed form .
we now resort to numerical algorithms for the computation of the remaining bounds , s and v .
the computation of the upper bound can be reformulated as the iteration of an lmi feasibility
problem .
to establish this we need the following theorem :
theorem 123
if ( a , q 123
123 ) is controllable and ( a , c ) is detectable , then the following statements
( a ) x such that ( b ) k , x > 123 ( c ) z and 123 < y i such that
x > g ( x )
x > ( k , x )
( y , z ) =
( a ( cid : 123 ) y + c ( cid : 123 ) z ( cid : 123 ) )
( y a + zc )
123 y a
( a ) = ( b ) if x > g ( x ) exists , then x > 123 by lemma 123 ( g ) .
let k = k x .
then x > g ( x ) = ( k , x ) which proves the statement .
( b ) = ( a ) clearly x > ( k , x ) g ( x ) which proves the statement .
( b ) ( c ) let f = a + kc , then :
x > ( 123 ) axa ( cid : 123 ) + f xf ( cid : 123 ) + q + krk ( cid : 123 )
is equivalent to
where we used the schur complement decomposition and the fact that x ( 123 ) axa ( cid : 123 ) f xf ( cid : 123 ) + q + krk ( cid : 123 ) q > 123
using one more time the schur complement decomposition on the rst element of the matrix we obtain
x ( 123 ) axa ( cid : 123 )
this is equivalent to
x123 123 123
x123 123 123
let us consider the change of variable y = x123 > 123 and z = x123k , in which case the previous lmi is equivalent to :
123 y a
( y , z ) =
( y a + zc )
( a ( cid : 123 ) y + c ( cid : 123 ) z ( cid : 123 ) )
since ( y , k ) = ( y , k ) , then y can be restricted to y i , which completes the theorem .
combining theorems 123 and 123 we immediately have the following corollary
corollary 123
the upper bound is given by the solution of the following optimization problem ,
= argmin ( y , z ) > 123 ,
123 y i .
this is a quasi - convex optimization problem in the variables ( , y , z ) and the solution can
be obtained by iterating lmi feasibility problems and using bisection for the variable .
the lower bound s for the mean covariance matrix can be easily obtained via standard lyapunov equation solvers .
the upper bound v can be found by iterating the mare or by solving a semidenite programming ( sdp ) problem as shown in the following .
theorem 123
if > , then the matrix v = g ( v ) is given by :
( a ) v = limt vt; vt+123 = gvt where v123 123
t race ( v )
av a ( cid : 123 ) v
cv a ( cid : 123 ) cv c ( cid : 123 ) + r
( a ) it follows directly from theorem 123
( b ) it can be obtained by using the schur complement decomposition on the equation v g ( v ) .
clearly the solution v = g ( v ) belongs to the feasible set of the optimization problem .
we now show that the solution of the optimization problem is the xed point of the mare .
suppose it is not , i . e . , v solves the optimization problem but v ( cid : 123 ) = g ( v ) .
since v is a feasible v .
however , this implies that t race ( v ) < point of the optimization problem , then v < g ( v ) = v ) , which contradicts the hypothesis of optimality of matrix v .
therefore v = g ( v )
and this concludes the theorem .
special cases and examples
in this section we present some special cases in which upper and lower bounds on the critical value c coincide and give some examples .
from theorem 123 , it follows that if there exists a k such that f is the zero matrix , then the convergence condition of the mare is for > c = 123 123 / 123 , where = maxi |i| , and i are the eigenvalues of a .
c is invertible .
in this case a choice of k = ac123 makes f = 123
note that the scalar case also falls under this category .
figure ( 123 ) shows a plot of the steady state of the upper
and lower bounds versus in the scalar case .
the discrete time lti system used in this simulation has a = 123 , c = 123 , with vt and wt having zero mean and variance r = 123 and q = 123 , respectively .
for this system we have c = 123 .
the transition clearly appears in the gure , where we see that the steady state value of both upper and lower bound tends
to innity as approaches c .
the dashed line shows the lower bound , the solid line the upper bound , and the dash - dot line shows the asymptote .
a has a single unstable eigenvalue .
in this case , regardless of the dimension of c ( and
as long as the pair ( a , c ) is detectable ) , we can use kalman decomposition to bring to
zero the unstable part of f and thereby obtain tight bounds .
figure ( 123 ) shows a plot for
example of transition to instability in the scalar case .
the dashed line shows the asymptotic value of the lower bound ( s ) , the solid line the asymptotic value of the upper bound ( v ) , and the dash - dot line shows the asymptote ( c ) .
the system a =
with vt and wt having zero mean and variance r = 123 and q = 123 i123x123 , respectively .
this time , the asymptotic value for trace of upper and lower bound is plotted versus .
once again c = 123 .
in general f cannot always be made zero and we have shown that while a lower bound on
c can be written in closed form , an upper bound on c is the result of a lmi .
figure ( 123 ) shows an example where upper and lower bounds have different convergence conditions .
the system
used for this simulation is a = with vt and wt having zero mean and variance r = 123 and q = 123 i123x123 , respectively .
finally , in figure ( 123 ) we report results of another experiment , plotting the state estimation error
for the scalar system used above at two similar values of , one being below and one above the critical value .
we note a dramatic change in the error at c 123 .
the gure on the left shows
123 . 123 . 123 . 123 . 123s , vspecial case : c is invertiblevsc 123
example of transition to instability with a single unstable eigenvalue in the mimo case .
the dashed line shows the asymptotic value of the trace of lower bound ( s ) , the solid line the asymptotic value of trace of the upper bound ( v ) , and the dash - dot line shows the asymptote ( c ) .
transition to instability in the general case , with arbitrary a and c .
in this case lower and upper bounds do not have
the same asymptote .
123 . 123 . 123 . 123 . 123 . 123 . 123 . 123x 123special case : one unstable eigenvaluetr ( v ) tr ( s ) tr ( s ) , tr ( v ) c 123 . 123 . 123 . 123 . 123x 123general casetr ( v ) tr ( s ) tr ( s ) , tr ( v ) 123
estimation error for below ( left ) and above ( right ) the critical value
the estimation error with = 123 .
the gure on the right shows the estimation error for the same
system evolution with = 123 .
in the rst case the estimation error grows dramatically , making
it practically useless for control purposes .
in the second case , a small increase in reduces the
estimation error by approximately three orders of magnitude .
static versus dynamic kalman gain
in this section we compare the performance of ltering with static and dynamic gain for
a scalar discrete system .
for the static estimator we follow the jump linear system approach
of ( 123 ) .
the scalar static estimator case has been also worked out in ( 123 ) .
consider the dynamic state estimator
t + tk d
t ( yt yt ) t+123 = axd t = aptc ( cid : 123 ) ( cptc ( cid : 123 ) + r ) 123 pt+123 = apta ( cid : 123 ) + q taptc ( cid : 123 ) ( cptc ( cid : 123 ) + r ) 123cpta ( cid : 123 )
123x 123tkestimation error : = 123tk estimation error : = 123 where the kalman gain k d
is time - varying .
also consider the static state estimator
t+123 = axd
t + tks ( yt yt )
where the estimator gain ks is constant .
if no data arrives , i . e .
t = 123 , both estimators simply propagate the state estimate of the previous time - step .
the performance of the dynamic state estimator ( 123 ) has been analyzed in the previous
sections .
the performance of static state estimator ( 123 ) , instead , can be readily obtained using t+123 , we obtain the dynamics
jump linear system theory ( 123 ) ( 123 ) .
to do so , let us consider the estimator error es of the estimation error :
substituting equations ( 123 ) for xt+123 and ( 123 ) for xs
t+123 = ( a tksc ) es
t + vt + tkswt .
using the same notation of chapter 123 in nilsson ( 123 ) , where he considers the general system :
zk+123 = ( rk ) zk + ( rk ) ek ,
the system ( 123 ) can be seen as jump linear system switching between two states rk ( 123 , 123 )
( 123 ) = a ksc
( 123 ) = ( 123 ks )
( 123 ) = a
( 123 ) = ( 123 123 ) ,
k ) = re , the transition probability matrix q and the steady
where the noise covariance e ( eke ( cid : 123 ) state probability distribution are given by :
following the methodology proposed in nilsson ( 123 ) is possible to show that the system above is mean square stable , i . e .
limt e ( ( es
t ) = 123 if and only if the transition probability is
if the system is mean square stable , the steady state error covariance p s = limt e ( es
123 ( a ksc ) 123 ( 123 ) a123 .
q + k 123
t ) ( cid : 123 ) ) is
calculations to obtain equations ( 123 ) and ( 123 ) are tedious but straightforward , therefore they
it is immediately evident that the critical transition probability s of the estimator ( 123 ) using a static gain is always greater then the critical transition probability c of the estimator ( 123 ) which adopts a dynamic gain , in fact
and the two probabilities are equal only when ks = a
a natural choice for the static estimator gain ks is the steady state kalman gain kss of the closed loop system ( r = 123 ) , which is always different from a c .
for the scalar system considered in the previous section , where a = 123 , c = 123 , q = 123 , r = 123 , this is given by kss = 123 , c = 123 .
in the special case while the gain for largest mean square stability range is ks = a when the arrival probability is known , another natural choice for the estimator gain k is obtained by substituting the error covariance solution of p = g ( p ) into the equation for the kalman lter gain k = a p c ( cid : 123 ) ( c p c ( cid : 123 ) + r ) 123
for example , assuming = 123 , then p = 123 and k = 123 .
figure 123 shows all of these cases , comparing them with the upper bound on the state error covariance v of the dynamic estimator ( 123 ) that can be computed as indicated in theorem 123
the steady state error covariance of the static predictor for the three different gains is always greater then our upper bound v .
this is not surprising , since the dynamic estimator is optimal over all possible estimators as shown in section ii .
note that the static predictor with
static gain k ( designed for = 123 ) achieves the same state error covariance predicted by our upper bound for the optimal dynamic lter when = 123 .
however , the empirical error state
covariance is on average better then the static lter , as shown in figure 123
this is to be expected ,
since the solution of mare gives only an upper bound of the true expected state covariance of
the time - varying lter .
moreover , it is worth stressing that if the arrival probability is different
from the one used to design the static gain , the performance of the static lter will degrade
considerably , while the time - varying lter will still perform optimally and does not require
knowledge of .
from this example , it seems that the upper bound for the dynamic estimator v gives en estimate of the minimum steady state covariance that can be achieved with a static estimator for any given arrival probability if the static gain ks is chosen optimally .
then the mare could be used to nd the minimum steady state covariance and then the corresponding
error covariance bound v for dynamic predictor obtained from our theory and steady state error covariance for three natural static predictors obtained from jls theory .
steady state modied kalman gain , thus providing an useful tool for optimal static estimator
design .
future work will explore this possibility .
in this paper we have presented an analysis of kalman ltering in the setting of intermittent
observations .
we have shown how the expected estimation error covariance depends on the
tradeoff between loss probability and the system dynamics .
such a result is useful to the system
designer who must assess the relationship between the dynamics of the system whose state is
to be estimated and the reliability of the communication channel through which that system is
our motivating application is a distributed sensor network that collects observations and sends
them to one or more central units that are responsible for estimation and control .
for example ,
in a pursuit evasion game in which mobile pursuers perform their control actions based on the
current estimate of the positions of both pursuers and evaders , the sensing capability of each
pursuer is generally limited , and an embedded sensor network is essential for providing a larger
123 . 123 . 123 . 123 . 123state error covariance pvkk=a / ckss 123
empirical state error covariance of our time - varying lter and the linear mimimum mean square error estimator
( lmmsee ) ( 123 ) obtained by using the optimal static kalman gain k .
the curves are obtained by averaging 123 monte
carlo simulations for t = 123 , .
, 123 , with the values of the input noise ( vt , wt ) and the arrival sequence t generated randomly .
both lters were compared under the same conditions .
overall view of the terrain .
the results that we have presented here can aid the designer of the
sensor network in the choice of the number and disposition of the sensors .
this application also suggests a number of interesting directions for further work .
for example ,
although we have assumed independent bernoulli probabilities for the observation events , in the
sensor network there will generally be temporal and spatial sources of variability that lead to
correlations among these events .
while it is possible to compute posterior state estimates in such
a setting , it would be of interest to see if a priori bounds of the kind that we have obtained here
can be obtained in this case .
similarly , in many situations there may be correlations between
the states and the observation events; for example , such correlations will arise in the pursuit
evasion game when the evaders move near the boundaries of the sensor network .
finally , the
sensor network setting also suggests the use of smoothing algorithms in addition to the ltering
algorithms that have been our focus here .
in particular , we may be willing to tolerate a small
amount of additional delay to wait for the arrival of a sensor measurement , if that measurement
is expected to provide a signicant reduction in uncertainty .
thus we would expect that the
123 . 123 . 123timeempirical state error covarince ( r . m . s . ) 123timevarying filterlmmse filter ( k ) 123
tradeoff that we have studied here between loss probability and the system dynamics should
also be modulated in interesting ways by the delay due to smoothing .
we also remark that the assumption of modelling the arrival of observations as a bernoulli
process can be clearly improved upon .
for example , one can imagine situations where some
of the sensing is done locally and therefore measurements are available at all sampling times ,
while measurements taken at distant locations are available at irregular intervals .
this would
translate in different dropping rates for different channels .
we have focused to providing a basic
result upon which more sophisticated models can be built and analyzed .
the authors are grateful to the anonymous reviewer for the comments that helped improving
the quality of the manuscript .
appendix a
in order to give complete proofs of our main theorems , we need to prove some preliminary
lemmas .
the rst one shows some useful properties of the mare .
lemma 123
let the operator
( k , x ) = ( 123 ) ( axa ( cid : 123 ) + q ) + ( f xf ( cid : 123 ) + v ) v = q + krk ( cid : 123 ) .
assume x s = ( s rnn|s 123 ) , r > 123 , q 123 ,
where f = a + kc , and ( a , q 123
123 ) is controllable .
then the following facts are true :
123 , g ( x ) = ( kx , x )
( a ) with kx = axc ( cid : 123 ) ( cxc ( cid : 123 ) + r ) ( b ) g ( x ) = mink ( k , x ) ( k , x ) k ( c ) if x y , then g ( x ) g ( y ) ( d ) if 123 123 then g123 ( x ) g123 ( x ) ( e ) if ( 123 , 123 ) , then g ( x + ( 123 ) y ) g ( x ) + ( 123 ) g ( y ) ( f ) g ( x ) ( 123 ) axa ( cid : 123 ) + q ( g ) if x g ( x ) , then x > 123 ( h ) if x is a random variable , then ( 123 ) ae ( x ) a ( cid : 123 ) + q e ( g ( x ) ) g ( e ( x ) )
( a ) dene fx = a + kxc , and observe that
fxxc ( cid : 123 ) + kxr = ( a + kxc ) xc ( cid : 123 ) + kxr = axc ( cid : 123 ) + kx ( cxc ( cid : 123 ) + r ) = 123
next , we have
g ( x ) = ( 123 ) ( axa ( cid : 123 ) + q ) + ( axa ( cid : 123 ) + q axc ( cid : 123 ) ( cxc ( cid : 123 ) + r )
= ( 123 ) ( axa ( cid : 123 ) + q ) + ( axa ( cid : 123 ) + q + kxcxa ( cid : 123 ) ) = ( 123 ) ( axa ( cid : 123 ) + q ) + ( fxxa ( cid : 123 ) + q ) = ( 123 ) ( axa ( cid : 123 ) + q ) + ( fxxa ( cid : 123 ) + q ) + ( fxxc ( cid : 123 ) + kxr ) k ( cid : 123 )
= ( kx , x )
( b ) let ( k , x ) = ( a + kc ) x ( a + kc ) ( cid : 123 ) + krk ( cid : 123 ) + q .
note that
argmink ( k , x ) = argminkf xf ( cid : 123 ) + v = argmink ( x , k ) .
since x , r 123 , ( k , x ) is quadratic and convex in the variable k , therefore the minimizer can be found by solving ( k , x )
k = 123 , which gives :
123 ( a + kc ) xc ( cid : 123 ) + 123kr = 123 = k = axc ( cid : 123 ) ( cxc ( cid : 123 ) + r )
since the minimizer corresponds to kx dened above , the fact follows from fact ( 123 )
( c ) note that ( k , x ) is afne in x .
suppose x y
g ( x ) = ( kx , x ) ( ky , x ) ( ky , y ) = g ( y ) .
this completes the proof .
( d ) note that axc ( cid : 123 ) ( cxc ( cid : 123 ) + r ) 123cxa 123
g123 ( x ) = axa ( cid : 123 ) + q 123 axc ( cid : 123 ) ( cxc ( cid : 123 ) + r ) 123cxa
axa ( cid : 123 ) + q 123 axc ( cid : 123 ) ( cxc ( cid : 123 ) + r ) 123cxa = g123 ( x )
( e ) let z = x + ( 123 ) y where ( 123 , 123 ) .
then we have
g ( z ) = ( kz , z )
= ( a + kz c ) x ( a + kz c ) ( cid : 123 ) + ( 123 ) ( a + kz c ) y ( a + kz c ) ( cid : 123 ) +
+ ( + 123 ) ( kz r k ( cid : 123 )
z + q ) = ( kz , x ) + ( 123 ) ( kz , y ) ( kx , x ) + ( 123 ) ( ky , y ) = g ( x ) + ( 123 ) g ( y ) .
( f ) note that fxxf ( cid : 123 )
x 123 and krk ( cid : 123 ) 123 for all k and x .
then g123 ( x ) = ( kx , x ) = ( 123 ) ( axa ( cid : 123 ) + q ) + ( fxxf ( cid : 123 )
x + kxrk ( cid : 123 )
x + q )
( 123 ) ( axa ( cid : 123 ) + q ) + q = ( 123 ) axa ( cid : 123 ) + q .
( g ) from fact ( f ) follows that x g123 ( x ) ( 123 ) a xa ( cid : 123 ) + q .
let x such that x = ( 123 ) a xa ( cid : 123 ) + q .
such x must clearly exist .
therefore x x ( 123 ) a ( x x ) a ( cid : 123 ) 123
moreover the matrix x solves the lyapunov equation x = a x a ( cid : 123 ) + q where a = since ( a , q 123
123 ) is detectable , it follows that x > 123 and so x > 123 , which proves the fact .
( h ) using fact ( f ) and linearity of expectation we have
e ( g ( x ) ) e ( ( 123 ) axa ( cid : 123 ) + q ) = ( 123 ) ae ( x ) a ( cid : 123 ) + q ,
fact ( e ) implies that the operator g ( ) is concave , therefore by jensens inequality we have
lemma 123
let xt+123 = h ( xt ) and yt+123 = h ( yt ) .
if h ( x ) is a monotonically increasing function
x123 x123 xt+123 xt , t 123 x123 x123 xt+123 xt , t 123 x123 y123 xt yt ,
proof : this lemma can be readily proved by induction .
it is true for t = 123 , since x123 x123 by denition .
now assume that xt+123 xt , then xt+123 = h ( xt+123 ) h ( xt+123 ) = xt+123 because of monotonicity of h ( ) .
the proof for the other two cases is analogous .
it is important to note that while in the scalar case x r either h ( x ) x or h ( x ) x; in the matrix case x rnn , it is not generally true that either h ( x ) x or h ( x ) x .
this is the source of the major technical difculty for the proof of convergence of sequences in higher dimensions .
in this case convergence of a sequence ( xt ) other sequences , ( yt ) these two sequences converge to the same point .
is obtained by nding two that bound xt , i . e . , yt xt zt , t , and then by showing that
the next two lemmas show that when the mare has a solution p , this solution is also stable , i . e . , every sequence based on the difference riccati equation pt+123 = g ( pt ) converges to p for all initial positive semidenite conditions p 123
lemma 123
dene the linear operator
l ( y ) = ( 123 ) ( ay a ( cid : 123 ) ) + ( f y f ( cid : 123 ) )
suppose there exists y > 123 such that y > l ( y ) .
( a ) for all w 123 ,
( b ) let u 123 and consider the linear system
klk ( w ) = 123
yk+123 = l ( yk ) + u initialized at y123
then , the sequence yk is bounded .
proof : ( a ) first observe that 123 l ( y ) for all 123 y .
also , x y implies l ( x ) l ( y ) .
choose 123 r < 123 such that l ( y ) < ry .
choose 123 m such that w my
123 lk ( w ) mlk ( y ) < mrky
the assertion follows when we take the limit r , on noticing that 123 r < 123
( b ) the solution of the linear iteration is
yk = lk ( y123 ) +
proving the claim .
lemma 123
consider the operator ( k , x ) dened in equation ( 123 ) .
suppose there exists a
matrix k and a positive denite matrix p such that
p > 123 and p > ( k , p ) .
then , for any p123 , the sequence pt = gt p123 such that
( p123 ) is bounded , i . e .
there exists mp123 123 dependent of
pt m for all
proof : first dene the matrices f = a + kc and consider the linear operator
l ( y ) = ( 123 ) ( ay a ( cid : 123 ) ) + ( f y f
p > ( k , p ) = l ( p ) + q + krk
( cid : 123 ) l ( p ) .
thus , l meets the condition of lemma 123
finally , using fact ( b ) in lemma 123 we have
pt+123 = g ( pt ) ( k , pt ) = lpt + q + krk
= l ( pt ) + u .
since u = krk
+ q 123 , using lemma 123 , we conclude that the sequence pt is bounded .
we are now ready to give proofs for theorems 123 - 123
proof of theorem 123
( a ) we rst show that the modied riccati difference equation initialized at q123 = 123 converges .
let qk = gk
note that 123 = q123 q123
it follows from lemma 123 ( c ) that
q123 = g ( q123 ) g ( q123 ) = q123
a simple inductive argument establishes that
123 = q123 q123 q123 mq123
here , we have used lemma 123 to bound the trajectory .
we now have a monotone non - decreasing
sequence of matrices bounded above .
it is a simple matter to show that the sequence converges ,
also , we see that p is a xed point of the modied riccati iteration :
k qk = p .
p = g ( p ) ,
which establishes that it is a positive semi - denite solution of the mare .
next , we show that the riccati iteration initialized at r123 p also converges , and to the same
limit p .
first dene the matrices
k = ap c ( cid : 123 ) ( cid : 123 )
cp c ( cid : 123 ) + r
, f = a + kc
and consider the linear operator
l ( y ) = ( 123 ) ( ay a ( cid : 123 ) ) + ( f y f
p = g ( p ) = l ( p ) + q + krk
> l ( p ) .
thus , l meets the condition of lemma 123
consequently , for all y 123 ,
now suppose r123 p
lk ( y ) = 123
r123 = g ( r123 ) g ( p ) = p .
a simple inductive argument establishes that
rk p for all k .
123 ( rk+123 p ) = g ( rk ) g ( p )
= ( krk , rk ) ( kp , p ) ( kp , rk ) ( kp , p ) = ( 123 ) a ( rk p ) a ( cid : 123 ) + fp ( rk p ) f ( cid : 123 ) = l ( rk p ) .
then , 123 limk ( rk+123 p ) 123 , proving the claim .
we now establish that the riccati iteration converges to p for all initial conditions p123 123
dene q123 = 123 and r123 = p123 + p .
consider three riccati iterations , initialized at q123 , p123 , and r123
note that
q123 p123 r123
it then follows from lemma 123 that
qk pk rk
for all k .
we have already established that the riccati equations pk and rk converge to p .
as a result ,
k pk lim
k qk lim
p = lim
k rk = p ,
proving the claim .
( b ) finally , we establish that the mare has a unique positive semi - denite solution .
to this end , consider p = g ( p ) and the riccati iteration initialized at p123 = p .
this yields the constant
p , p ,
however , we have shown that every riccati iteration converges to p .
thus p = p .
proof of theorem 123
first we note that the two cases expressed by the theorem are indeed possible .
if = 123 the
modied riccati difference equation reduces to the standard riccati difference equation , which
is known to converge to a xed point , under the theorems hypotheses .
hence , the covariance matrix is always bounded in this case , for any initial condition p123 123
if = 123 then we reduce to open loop prediction , and if the matrix a is unstable , then the covariance matrix diverges for some initial condition p123 123
next , we show the existence of a single point of transition between the two cases .
fix a 123 < 123 123 such that e123 ( pt ) is bounded for any initial condition p123 123
then , for any 123 123 e123 ( pt ) is also bounded for all p123 123
in fact we have
e123 ( pt+123 ) = e123 ( apta ( cid : 123 ) + q t+123aptc ( cid : 123 ) ( cptc ( cid : 123 ) + r ) 123cpta )
= e ( apta ( cid : 123 ) + q 123aptc ( cid : 123 ) ( cptc ( cid : 123 ) + r ) 123cpta )
where we exploited fact ( d ) of lemma 123 to write the above inequality .
we can now choose
c = ( inf : > e ( pt ) is bounded , for all p123 123 ) ,
completing the proof .
proof of theorem 123
dene the lyapunov operator m ( x ) = ax a ( cid : 123 ) +q where a =
123 ) is control - 123 ) is controllable .
therefore , it is well known that s = m ( s ) has a unique strictly 123 maxi |i ( a ) | < 123 , 123 .
if maxi |i ( a ) | 123 it is also a well known fact that there 123 ) is
lable , also ( a , q 123 positive denite solution s > 123 if and only if maxi |i ( a ) | < 123 , i . e .
from which follows = 123 123 is no positive semidenite xed point to the lyapunov equation s = m ( s ) , since ( a , q 123
if ( a , q 123
let us consider the difference equation st+123 = m ( st ) , s123 = 123
it is clear that s123 = 123 q = s123
since the operator m ( ) is monotonic increasing , by lemma 123 it follows that the is monotonically increasing , i . e .
st+123 st for all t .
if < this sequence does not converge to a nite matrix s , otherwise by continuity of the operator m we would have s = m ( s ) , which is not possible .
since it is easy to show that a monotonically increasing sequence st that does not converge is also unbounded , then we have
let us consider now the mean covariance matrix e ( pt ) initialized at e ( p123 ) 123
clearly
123 = s123 e ( p123 ) .
moreover it is also true
t st = .
st e ( pt ) = st+123 = ( 123 ) asta ( cid : 123 ) + q ( 123 ) ae ( pt ) a ( cid : 123 ) + q e ( g ( pt ) ) = e ( pt+123 ) ,
where we used fact ( h ) from lemma 123
by induction , it is easy to show that
st e ( pt ) t , e ( p123 ) 123 = lim
t e ( pt ) lim
t st = .
this implies that for any initial condition e ( pt ) is unbounded for any < , therefore c , which proves the rst part of the theorem .
now consider the sequence vt+123 = g ( vt ) , v123 = e ( p123 ) 123
clearly
e ( pt ) vt = e ( pt+123 ) = e ( g ( pt ) ) g ( e ( pt ) ) ( g ( vt ) ) = vt+123 ,
where we used facts ( c ) and ( h ) from lemma 123
then a simple induction argument shows that vt e ( pt ) for all t .
let us consider the case > , therefore there exists x such that x g ( x ) .
by lemma 123 ( g ) x > 123 , therefore all hypotheses of lemma 123 are satised , which
e ( pt ) vt mv123 t .
this shows that c and concludes the proof of the theorem .
proof of theorem 123
let consider the sequences st+123 = ( 123 ) asta ( cid : 123 ) + q , s123 = 123 and vt+123 = g ( vt ) , v123 =
e ( p123 ) 123
using the same induction arguments in theorem 123 it is easy to show that
st e ( pt ) vt t .
from theorem 123 follows that limt vt = v , where v = gv .
as shown before the sequence st is monotonically increasing .
also it is bounded since st vt m .
therefore limt st = s , and by continuity s = ( 123 ) a sa ( cid : 123 ) + q , which is a lyapunov equation .
since 123 a is stable and ( a , q 123 123 ) is controllable , then the solution of the lyapunov equation is strictly positive denite , i . e .
adding all the results together we get
123 < s = lim
t vt = v ,
t st lim
t e ( pt ) lim
which concludes the proof .
