an introduction to mcmc for machine learning
department of mathematics , statistics group , university of bristol , university walk , bristol bs123 123tw , uk
nando de freitas department of computer science , university of british columbia , 123 main mall , vancouver , bc v123t 123z123 , canada
department of electrical and electronic engineering , university of melbourne , parkville , victoria 123 , australia
michael i .
jordan departments of computer science and statistics , university of california at berkeley , 123 soda hall , berkeley , ca 123 - 123 , usa
abstract .
this purpose of this introductory paper is threefold .
first , it introduces the monte carlo method with emphasis on probabilistic machine learning .
second , it reviews the main building blocks of modern markov chain monte carlo simulation , thereby providing and introduction to the remaining papers of this special issue .
lastly , it discusses new interesting research horizons .
keywords : markov chain monte carlo , mcmc , sampling , stochastic algorithms
a recent survey places the metropolis algorithm among the ten algorithms that have had the greatest inuence on the development and practice of science and engineering in the 123th century ( beichl & sullivan , 123 ) .
this algorithm is an instance of a large class of sampling algorithms , known as markov chain monte carlo ( mcmc ) .
these algorithms have played a signicant role in statistics , econometrics , physics and computing science over the last two decades .
there are several high - dimensional problems , such as computing the volume of a convex body in d dimensions , for which mcmc simulation is the only known general approach for providing a solution within a reasonable time ( polynomial in d ) ( dyer , frieze , & kannan , 123; jerrum & sinclair , 123 ) .
while convalescing from an illness in 123 , stan ulam was playing solitaire .
it , then , occurred to him to try to compute the chances that a particular solitaire laid out with 123 cards would come out successfully ( eckhard , 123 ) .
after attempting exhaustive combinatorial calculations , he decided to go for the more practical approach of laying out several solitaires at random and then observing and counting the number of successful plays .
this idea of selecting a statistical sample to approximate a hard combinatorial problem by a much simpler problem is at the heart of modern monte carlo simulation .
andrieu et al .
stan ulam soon realised that computers could be used in this fashion to answer ques - tions of neutron diffusion and mathematical physics .
he contacted john von neumann , who understood the great potential of this idea .
over the next few years , ulam and von neumann developed many monte carlo algorithms , including importance sampling and rejection sampling .
enrico fermi in the 123s also used monte carlo in the calculation of neutron diffusion , and later designed the fermiac , a monte carlo mechanical device that performed calculations ( anderson , 123 ) .
in the 123s nick metropolis , a young physicist , designed new controls for the state - of - the - art computer ( eniac ) with klari von neumann , johns wife .
he was fascinated with monte carlo methods and this new computing device .
soon he designed an improved computer , which he named the maniac in the hope that computer scientists would stop using acronyms .
during the time he spent working on the computing machines , many mathematicians and physicists ( fermi , von neumann , ulam , teller , richtmyer , bethe , feynman , & gamow ) would go to him with their work problems .
eventually in 123 , he published the rst public document on monte carlo simulation with stan ulam ( metropolis & ulam , 123 ) .
this paper introduces , among other ideas , monte carlo particle methods , which form the basis of modern sequential monte carlo methods such as bootstrap lters , condensation , and survival of the ttest algorithms ( doucet , de freitas , & gordon , 123 ) .
soon after , he proposed the metropolis algorithm with the tellers and the rosenbluths ( metropolis et al . , 123 ) .
many papers on monte carlo simulation appeared in the physics literature after 123
from an inference perspective , the most signicant contribution was the generalisation of the metropolis algorithm by hastings in 123
hastings and his student peskun showed that metropolis and the more general metropolis - hastings algorithms are particular instances of a large family of algorithms , which also includes the boltzmann algorithm ( hastings , 123; peskun , 123 ) .
they studied the optimality of these algorithms and introduced the formulation of the metropolis - hastings algorithm that we adopt in this paper .
in the 123s , two important mcmc papers appeared in the elds of computer vision and articial in - telligence ( geman & geman , 123; pearl , 123 ) .
despite the existence of a few mcmc publications in the statistics literature at this time , it is generally accepted that it was only in 123 that mcmc made the rst signicant impact in statistics ( gelfand & smith , 123 ) .
in the neural networks literature , the publication of neal ( 123 ) was particularly inuential .
in the introduction to this special issue , we focus on describing algorithms that we feel are the main building blocks in modern mcmc programs .
we should emphasize that in order to obtain the best results out of this class of algorithms , it is important that we do not treat them as black boxes , but instead try to incorporate as much domain specic knowledge as possible into their design .
mcmc algorithms typically require the design of proposal mechanisms to generate candidate hypotheses .
many existing machine learning algorithms can be adapted to become proposal mechanisms ( de freitas et al . , 123 ) .
this is often essential to obtain mcmc algorithms that converge quickly .
in addition to this , we believe that the machine learning community can contribute signicantly to the solution of many open problems in the mcmc eld .
for this purpose , we have outlined several hot research directions at the end of this paper .
finally , readers are encouraged to consult the excellent texts of chen , shao , and ibrahim ( 123 ) , gilks , richardson , and spiegelhalter ( 123 ) , liu ( 123 ) , meyn and tweedie ( 123 ) , robert and casella ( 123 ) and review papers by besag
( 123 ) , brooks ( 123 ) , diaconis and saloff - coste ( 123 ) , jerrum and sinclair ( 123 ) , neal ( 123 ) , and tierney ( 123 ) for more information on mcmc .
the remainder of this paper is organised as follows .
in part 123 , we outline the general problems and introduce simple monte carlo simulation , rejection sampling and importance sampling .
part 123 deals with the introduction of mcmc and the presentation of the most popular mcmc algorithms .
in part 123 , we describe some important research frontiers .
to make the paper more accessible , we make no notational distinction between distributions and densities until the section on reversible jump mcmc .
mcmc motivation
mcmc techniques are often applied to solve integration and optimisation problems in large dimensional spaces .
these two types of problem play a fundamental role in machine learning , physics , statistics , econometrics and decision analysis .
the following are just some 123
bayesian inference and learning .
given some unknown variables x x and data y y , the following typically intractable integration problems are central to bayesian statistics ( a ) normalisation .
to obtain the posterior p ( x | y ) given the prior p ( x ) and likelihood
p ( y | x ) , the normalising factor in bayes theorem needs to be computed
( b ) marginalisation .
given the joint posterior of ( x , z ) x z , we may often be
p ( x | y ) =
p ( y | x ) p ( x )
x p ( y | x ( cid : 123 ) ) p ( x ( cid : 123 ) ) dx ( cid : 123 ) .
p ( x | y ) =
interested in the marginal posterior p ( x , z | y ) dz .
e p ( x|y ) ( f ( x ) ) =
f ( x ) p ( x | y ) dx
( c ) expectation .
the objective of the analysis is often to obtain summary statistics of
: x rn f integrable with respect to p ( x | y ) .
for some function of interest examples of appropriate functions include the conditional mean , in which case f ( x ) = x , or the conditional covariance of x where f ( x ) = xx 123
statistical mechanics .
here , one needs to compute the partition function z of a system
with states s and hamiltonian e ( s )
where k is the boltzmanns constant and t denotes the temperature of the system .
summing over the large number of possible congurations is prohibitively expensive ( baxter , 123 ) .
note that the problems of computing the partition function and the normalising constant in statistical inference are analogous .
andrieu et al .
optimisation .
the goal of optimisation is to extract the solution that minimises some objective function from a large set of feasible solutions .
in fact , this set can be contin - uous and unbounded .
in general , it is too computationally expensive to compare all the solutions to nd out which one is optimal .
penalised likelihood model selection .
this task typically involves two steps .
first , one nds the maximum likelihood ( ml ) estimates for each model separately .
then one uses a penalisation term ( for example mdl , bic or aic ) to select one of the models .
the problem with this approach is that the initial set of models can be very large .
moreover , many of those models are of not interest and , therefore , computing resources are wasted .
although we have emphasized integration and optimisation , mcmc also plays a funda - mental role in the simulation of physical systems .
this is of great relevance in nuclear physics and computer graphics ( chenney & forsyth , 123; kalos & whitlock , 123; veach & guibas , 123 ) .
the monte carlo principle the idea of monte carlo simulation is to draw an i . i . d .
set of samples ( x ( i ) ) n i=123 from a target density p ( x ) dened on a high - dimensional space x ( e . g .
the set of possible congurations of a system , the space on which the posterior is dened , or the combinatorial set of feasible solutions ) .
these n samples can be used to approximate the target density with the following empirical point - mass function
pn ( x ) = 123
where x ( i ) ( x ) denotes the delta - dirac mass located at x ( i ) .
consequently , one can approx - imate the integrals ( or very large sums ) i ( f ) with tractable sums in ( f ) that converge as
in ( f ) = 123
n i ( f ) =
f ( x ) p ( x ) dx .
that is , the estimate in ( f ) is unbiased and by the strong law of large numbers , it will almost surely ( a . s . ) converge to i ( f ) .
if the variance ( in the univariate case for simplicity ) ( cid : 123 ) e p ( x ) ( f 123 ( x ) ) i 123 ( f ) < , then the variance of the estimator of f ( x ) satises 123 in ( f ) is equal to var ( in ( f ) ) = 123 n and a central limit theorem yields convergence in distribution of the error
n ( in ( f ) i ( f ) ) =
where = denotes convergence in distribution ( robert & casella , 123; section 123 ) .
the advantage of monte carlo integration over deterministic integration arises from the fact that the former positions the integration grid ( samples ) in regions of high probability .
the n samples can also be used to obtain a maximum of the objective function p ( x ) as
x = arg max
however , we will show later that it is possible to construct simulated annealing algorithms that allow us to sample approximately from a distribution whose support is the set of global
when p ( x ) has standard form , e . g .
gaussian , it is straightforward to sample from it using easily available routines .
however , when this is not the case , we need to introduce more sophisticated techniques based on rejection sampling , importance sampling and mcmc .
rejection sampling
we can sample from a distribution p ( x ) , which is known up to a proportionality constant , by sampling from another easy - to - sample proposal distribution q ( x ) that satises p ( x ) mq ( x ) , m < , using the accept / reject procedure describe in gure 123 ( see also gure 123 ) .
the accepted x ( i ) can be easily shown to be sampled with probability p ( x ) ( robert &
figure 123
rejection sampling algorithm .
here , u u ( 123 , 123 ) denotes the operation of sampling a uniform random variable on the interval ( 123 , 123 ) .
figure 123
rejection sampling : sample a candidate x ( i ) and a uniform variable u .
accept the candidate sample if u mq ( x ( i ) ) < p ( x ( i ) ) , otherwise reject it .
andrieu et al .
casella , 123 , p .
this simple method suffers from severe limitations .
it is not always possible to bound p ( x ) / q ( x ) with a reasonable constant m over the whole space x .
if m is too large , the acceptance probability
pr ( x accepted ) = pr
will be too small .
this makes the method impractical in high - dimensional scenarios .
importance sampling is an alternative classical solution that goes back to the 123s; see for example ( geweke , 123; rubinstein , 123 ) .
let us introduce , again , an arbitrary importance proposal distribution q ( x ) such that its support includes the support of p ( x ) .
then we can rewrite i ( f ) as follows
i ( f ) =
f ( x ) w ( x ) q ( x ) dx
q ( x ) is known as the importance weight .
consequently , if one can simulate i=123 according to q ( x ) and evaluate w ( x ( i ) ) , a possible monte carlo
where w ( x ) ( cid : 123 ) p ( x ) n i . i . d .
samples ( x ( i ) ) n estimate of i ( f ) is
i n ( f ) = n ( cid : 123 )
this estimator is unbiased and , under weak assumptions , the strong law of large num - bers applies , that is i n ( f ) n i ( f ) .
it is clear that this integration method can also be interpreted as a sampling method where the posterior density p ( x ) is approximated by
p n ( x ) = n ( cid : 123 )
and i n ( f ) is nothing but the function f ( x ) integrated with respect to the empirical measure p n ( x ) .
some proposal distributions q ( x ) will obviously be preferable to others .
an important criterion for choosing an optimal proposal distribution is to nd one that minimises the variance of the estimator i n ( f ) .
the variance of f ( x ) w ( x ) with respect to q ( x ) is given by
varq ( x ) ( f ( x ) w ( x ) ) = eq ( x ) ( f 123 ( x ) w123 ( x ) ) i 123 ( f )
the second term on the right hand side does not depend on q ( x ) and hence we only need to minimise the rst term , which according to jensens inequality has the following lower
eq ( x ) ( f 123 ( x ) w123 ( x ) ) ( cid : 123 )
eq ( x ) ( | f ( x ) |w ( x ) )
| f ( x ) | p ( x ) dx
this lower bound is attained when we adopt the following optimal importance distribution
( cid : 123 ) | f ( x ) | p ( x ) dx q ( cid : 123 ) ( x ) = | f ( x ) | p ( x )
the optimal proposal is not very useful in the sense that it is not easy to sample from | f ( x ) | p ( x ) .
however , it tells us that high sampling efciency is achieved when we focus on sampling from p ( x ) in the important regions where | f ( x ) | p ( x ) is relatively large; hence the name importance sampling .
this result implies that importance sampling estimates can be super - efcient .
that is , for a a given function f ( x ) , it is possible to nd a distribution q ( x ) that yields an estimate with a lower variance than when using a perfect monte carlo method , i . e .
with q ( x ) = p ( x ) .
this property is often exploited to evaluate the probability of rare events in communication networks ( smith , sha , & gao , 123 ) .
there the quantity of interest is a tail probability ( bit error rate ) and hence f ( x ) = ie ( x ) where ie ( x ) = 123 if x e and 123 otherwise ( see gure 123 ) .
one could estimate the bit error rate more efciently by sampling according to q ( x ) ie ( x ) p ( x ) than according to q ( x ) = p ( x ) .
that is , it is wasteful to propose candidates in regions of no utility .
in many applications , the aim is usually different in the sense that
importance sampling : one should place more importance on sampling from the state space regions that matter .
in this particular example one is interested in computing a tail probability of error ( detecting infrequent
andrieu et al .
one wants to have a good approximation of p ( x ) and not of a particular integral with respect to p ( x ) , so we often seek to have q ( x ) ( cid : 123 ) p ( x ) .
as the dimension of the x increases , it becomes harder to obtain a suitable q ( x ) from which to draw samples .
a sensible strategy is to adopt a parameterised q ( x , ) and to adapt during the simulation .
adaptive importance sampling appears to have originated in the structural safety literature ( bucher , 123 ) , and has been extensively applied in the communications literature ( al - qaq , devetsikiotis , & townsend , 123; remondo et al . , 123 ) .
this technique has also been exploited recently in the machine learning community ( de freitas et al . , 123; cheng & druzdzel , 123; ortiz & kaelbling , 123; schuurmans & southey , 123 ) .
a popular adaptive strategy involves computing the derivative of the rst term on the right hand side of eq
d ( ) = eq ( x , )
f 123 ( x ) w ( x , )
and then updating the parameters as follows
x ( i ) , t
x ( i ) , t
t+123 = t
where is a learning rate and x ( i ) q ( x , ) .
other optimisation approaches that make use of the hessian are also possible .
when the normalising constant of p ( x ) is unknown , it is still possible to apply the
importance sampling method by rewriting i ( f ) as follows :
i ( f ) =
f ( x ) w ( x ) q ( x ) dx
q ( x ) is now only known up to a normalising constant .
the monte carlo
where w ( x ) p ( x ) estimate of i ( f ) becomes
i n ( f ) = 123
where w ( x ( i ) ) is a normalised importance weight .
for n nite , i n ( f ) is biased ( ratio of two estimates ) but asymptotically , under weak assumptions , the strong law of large numbers applies , that is i n ( f ) n i ( f ) .
under additional assumptions a central limit theorem can be obtained ( geweke , 123 ) .
the estimator i n ( f ) has been shown to perform better than i n ( f ) in some setups under squared error loss ( robert & casella , 123 ) .
if one is interested in obtaining m i . i . d .
samples from p n ( x ) , then an asymptotically ( n / m ) valid method consists of resampling m times according to the discrete distri - bution p n ( x ) .
this procedure results in m samples x ( i ) with the possibility that x ( i ) = x ( j )
for i ( cid : 123 ) = j .
this method is known as sampling importance resampling ( sir ) ( rubin , 123 ) .
after resampling , the approximation of the target density is
pm ( x ) = 123
the resampling scheme introduces some additional monte carlo variation .
it is , therefore , not clear whether the sir procedure can lead to practical gains in general .
however , in the sequential monte carlo setting described in section 123 , it is essential to carry out this
we conclude this section by stating that even with adaptation , it is often impossible to obtain proposal distributions that are easy to sample from and good approximations at the same time .
for this reason , we need to introduce more sophisticated sampling algorithms based on markov chains .
mcmc algorithms mcmc is a strategy for generating samples x ( i ) while exploring the state space x using a markov chain mechanism .
this mechanism is constructed so that the chain spends more time in the most important regions .
in particular , it is constructed so that the samples x ( i ) mimic samples drawn from the target distribution p ( x ) .
( we reiterate that we use mcmc when we cannot draw samples from p ( x ) directly , but can evaluate p ( x ) up to a normalising it is intuitive to introduce markov chains on nite state spaces , where x ( i ) can only take s discrete values x ( i ) x = ( x123 , x123 , .
the stochastic process x ( i ) is called a markov
( cid : 123 ) ( cid : 123 ) x ( i123 ) , .
, x ( 123 )
( cid : 123 ) = t
( cid : 123 ) ( cid : 123 ) x ( i123 )
the chain is homogeneous if t ( cid : 123 ) t ( x ( i ) | x ( i123 ) ) remains invariant for all i , with x ( i ) t ( x ( i ) | x ( i123 ) ) = 123 for any i .
that is , the evolution of the chain in a space x depends solely on the current state of the chain and a xed transition matrix .
as an example , consider a markov chain with three states ( s = 123 ) and a transition graph
as illustrated in gure 123
the transition matrix for this example is
if the probability vector for the initial state is ( x ( 123 ) ) = ( 123 , 123 , 123 ) , it follows that ( x ( 123 ) ) t = ( 123 , 123 , 123 ) and , after several iterations ( multiplications by t ) , the product ( x ( 123 ) ) t t converges to p ( x ) = ( 123 , 123 , 123 ) .
no matter what initial distribution ( x ( 123 ) ) we use , the chain will stabilise at p ( x ) = ( 123 , 123 , 123 ) .
this stability result plays a funda - mental role in mcmc simulation .
for any starting point , the chain will convergence to the
andrieu et al .
figure 123
transition graph for the markov chain example with x = ( x123 , x123 , x123 ) .
invariant distribution p ( x ) , as long as t is a stochastic transition matrix that obeys the
irreducibility .
for any state of the markov chain , there is a positive probability of visiting all other states .
that is , the matrix t cannot be reduced to separate smaller matrices , which is also the same as stating that the transition graph is connected .
aperiodicity .
the chain should not get trapped in cycles .
a sufcient , but not necessary , condition to ensure that a particular p ( x ) is the desired invariant distribution is the following reversibility ( detailed balance ) condition
summing both sides over x ( i123 ) , gives us
( cid : 123 ) ( cid : 123 ) x ( i )
( cid : 123 ) = p
( cid : 123 ) ( cid : 123 ) x ( i123 )
x ( i ) | x ( i123 )
mcmc samplers are irreducible and aperiodic markov chains that have the target distribu - tion as the invariant distribution .
one way to design these samplers is to ensure that detailed balance is satised .
however , it is also important to design samplers that converge quickly .
indeed , most of our efforts will be devoted to increasing the convergence speed .
spectral theory gives us useful insights into the problem .
notice that p ( x ) is the left eigenvector of the matrix t with corresponding eigenvalue 123
in fact , the perron - frobenius theorem from linear algebra tells us that the remaining eigenvalues have absolute value less than 123
the second largest eigenvalue , therefore , determines the rate of convergence of the chain , and should be as small as possible .
the concepts of irreducibility , aperiodicity and invariance can be better appreciated once we realise the important role that they play in our lives .
when we search for information on
the world - wide web , we typically follow a set of links ( berners - lee et al . , 123 ) .
we can interpret the webpages and links , respectively , as the nodes and directed connections in a markov chain transition graph .
clearly , we ( say , the random walkers on the web ) want to avoid getting trapped in cycles ( aperiodicity ) and want to be able to access all the existing webpages ( irreducibility ) .
let us consider , now , the popular information retrieval algorithm used by the search engine google , namely pagerank ( page et al . , 123 ) .
pagerank requires the denition of a transition matrix with two components t = l+ e .
l is a large link matrix with rows and columns corresponding to web pages , such that the entry li , j represents the normalised number of links from web page i to web page j .
e is a uniform random matrix of small magnitude that is added to l to ensure irreducibility and aperiodicity .
that is , the addition of noise prevents us from getting trapped in loops , as it ensures that there is always some probability of jumping to anywhere on the web .
from our previous discussion , we
( l + e ) = p ( x i )
where , in this case , the invariant distribution ( eigenvector ) p ( x ) represents the rank of a webpage x .
note that it is possible to design more interesting transition matrices in this setting .
as long as one satises irreducibility and aperiodicity , one can incorporate terms into the transition matrix that favour particular webpages or that bias the search in useful
in continuous state spaces , the transition matrix t becomes an integral kernel k and
p ( x ) becomes the corresponding eigenfunction
( cid : 123 ) ( cid : 123 ) x ( i )
dx ( i ) = p
the kernel k is the conditional density of x ( i+123 ) given the value x ( i ) .
it is a mathematical representation of a markov chain algorithm .
in the following subsections we describe various of these algorithms .
the metropolis - hastings algorithm
the metropolis - hastings ( mh ) algorithm is the most popular mcmc method ( hastings , 123; metropolis et al . , 123 ) .
in later sections , we will see that most practical mcmc algorithms can be interpreted as special cases or extensions of this algorithm .
an mh step of invariant distribution p ( x ) and proposal distribution q ( x ( cid : 123 ) | x ) involves sampling a candidate value x ( cid : 123 ) given the current value x according to q ( x ( cid : 123 ) | x ) .
the markov chain then moves towards x ( cid : 123 ) with acceptance probability a ( x , x ( cid : 123 ) ) = min ( 123 , ( p ( x ) q ( x ( cid : 123 ) | 123 p ( x ( cid : 123 ) ) q ( x | x ( cid : 123 ) ) ) , otherwise it remains at x .
the pseudo - code is shown in gure 123 , while gure 123 shows the results of running the mh algorithm with a gaussian proposal distribution q ( x ( cid : 123 ) | x ( i ) ) = n ( x ( i ) , 123 ) and a bimodal target distribution p ( x ) 123 exp ( 123x 123 ) + 123 exp ( 123 ( x 123 ) 123 ) for 123 iterations .
as expected , the histogram of the samples approximates the target distribution .
andrieu et al .
figure 123
metropolis - hastings algorithm .
figure 123
target distribution and histogram of the mcmc samples at different iteration points .
the mh algorithm is very simple , but it requires careful design of the proposal distri - bution q ( x ( cid : 123 ) | x ) .
in subsequent sections , we will see that many mcmc algorithms arise by considering specic choices of this distribution .
in general , it is possible to use suboptimal inference and learning algorithms to generate data - driven proposal distributions .
the transition kernel for the mh algorithm is
( cid : 123 ) ( cid : 123 ) x ( i )
( cid : 123 ) = q
( cid : 123 ) ( cid : 123 ) x ( i )
( cid : 123 ) + x ( i )
x ( i ) , x ( i+123 )
where r ( x ( i ) ) is the term associated with rejection
( cid : 123 ) ( cid : 123 ) x ( i )
x ( i ) , x ( cid : 123 )
it is fairly easy to prove that the samples generated by mh algorithm will mimic samples drawn from the target distribution asymptotically .
by construction , kmh satises the detailed
( cid : 123 ) ( cid : 123 ) x ( i )
( cid : 123 ) = p
( cid : 123 ) ( cid : 123 ) x ( i+123 )
and , consequently , the mh algorithm admits p ( x ) as invariant distribution .
to show that the mh algorithm converges , we need to ensure that there are no cycles ( aperiodicity ) and that every state that has positive probability can be reached in a nite number of steps ( irreducibility ) .
since the algorithm always allows for rejection , it follows that it is aperiodic .
to ensure irreducibility , we simply need to make sure that the support of q ( ) includes the support of p ( ) .
under these conditions , we obtain asymptotic convergence ( tierney , 123 , theorem 123 , p .
if the space x is small ( for example , bounded in rn ) , then it is possible to use minorisation conditions to prove uniform ( geometric ) ergodicity ( meyn & tweedie , 123 ) .
it is also possible to prove geometric ergodicity using foster - lyapunov drift conditions ( meyn & tweedie , 123; roberts & tweedie , 123 ) .
the independent sampler and the metropolis algorithm are two simple instances of the mh algorithm .
in the independent sampler the proposal is independent of the current state , q ( x ( cid : 123 ) | x ( i ) ) = q ( x ( cid : 123 ) ) .
hence , the acceptance probability is
( cid : 123 ) = min
x ( i ) , x ( cid : 123 )
this algorithm is close to importance sampling , but now the samples are correlated since they result from comparing one sample to the other .
the metropolis algorithm assumes a symmetric random walk proposal q ( x ( cid : 123 ) | x ( i ) ) = q ( x ( i ) | x ( cid : 123 ) ) and , hence , the acceptance ratio
x ( i ) , x ( cid : 123 )
( cid : 123 ) = min
some properties of the mh algorithm are worth highlighting .
firstly , the normalising constant of the target distribution is not required .
we only need to know the target distribution up to a constant of proportionality .
secondly , although the pseudo - code makes use of a single chain , it is easy to simulate several independent chains in parallel .
lastly , the success or failure of the algorithm often hinges on the choice of proposal distribution .
this is illustrated in gure 123
different choices of the proposal standard deviation ( cid : 123 ) lead to very different results .
if the proposal is too narrow , only one mode of p ( x ) might be visited .
on the other hand , if it is too wide , the rejection rate can be very high , resulting in high correlations .
if all the modes are visited while the acceptance probability is high , the chain is said to mix well .
andrieu et al .
figure 123
approximations obtained using the mh algorithm with three gaussian proposal distributions of dif -
simulated annealing for global optimization
let us assume that instead of wanting to approximate p ( x ) , we want to nd its global maximum .
for example , if p ( x ) is the likelihood or posterior distribution , we often want to compute the ml and maximum a posteriori ( map ) estimates .
as mentioned earlier , we could run a markov chain of invariant distribution p ( x ) and estimate the global mode by
x = arg max
this method is inefcient because the random samples only rarely come from the vicinity of the mode .
unless the distribution has large probability mass around the mode , computing resources will be wasted exploring areas of no interest .
a more principled strategy is to adopt simulated annealing ( geman & geman , 123; kirkpatrick , gelatt , & vecchi , 123; van laarhoven & arts , 123 ) .
this technique involves simulating a non - homogeneous markov chain whose invariant distribution at iteration i is no longer equal to p ( x ) , but to
pi ( x ) p123 / ti ( x ) ,
figure 123
general simulated annealing algorithm .
figure 123
discovering the modes of the target distribution with the simulated annealing algorithm .
where ti is a decreasing cooling schedule with limi ti = 123
the reason for doing this ( x ) is a probability density that is that , under weak regularity assumptions on p ( x ) , p concentrates itself on the set of global maxima of p ( x ) .
the simulated annealing involves , therefore , just a minor modication of standard mcmc algorithms as shown in gure 123
the results of applying annealing to the example of the previous section are shown in gure 123
to obtain efcient annealed algorithms , it is again important to choose suitable proposal distributions and an appropriate cooling schedule .
many of the negative simulated annealing
andrieu et al .
results reported in the literature often stem from poor proposal distribution design .
in some complex variable and model selection scenarios arising in machine learning , one can even propose from complex reversible jump mcmc kernels ( section 123 ) within the annealing algorithm ( andrieu , de freitas , & doucet , 123a ) .
if one denes a joint distribution over the parameter and model spaces , this technique can be used to search for the best model ( according to mdl or aic criteria ) and ml parameter estimates simultaneously .
most convergence results for simulated annealing typically state that if for a given ti , the homogeneous markov transition kernel mixes quickly enough , then convergence to the set of global maxima of p ( x ) is ensured for a sequence ti = ( c ln ( i + t123 ) ) 123 , where c and t123 are problem - dependent .
most of the results have been obtained for nite spaces ( geman & geman , 123; van laarhoven & arts , 123 ) or compact continuous spaces ( haario & sacksman , 123 ) .
some results for non - compact spaces can be found in andrieu , breyer , and doucet ( 123 ) .
mixtures and cycles of mcmc kernels
a very powerful property of mcmc is that it is possible to combine several samplers into mixtures and cycles of the individual samplers ( tierney , 123 ) .
if the transition kernels k123 and k123 have invariant distribution p ( ) each , then the cycle hybrid kernel k123 k123 and the mixture hybrid kernel k123 + ( 123 ) k123 , for 123 123 , are also transition kernels with invariant distribution p ( ) .
mixtures of kernels can incorporate global proposals to explore vast regions of the state space and local proposals to discover ner details of the target distribution ( andrieu , de freitas , & doucet , 123b; andrieu & doucet , 123; robert & casella , 123 ) .
this will be useful , for example , when the target distribution has many narrow peaks .
here , a global proposal locks into the peaks while a local proposal allows one to explore the space around each peak .
for example , if we require a high - precision frequency detector , one can use the fast fourier transform ( fft ) as a global proposal and a random walk as local proposal ( andrieu & doucet , 123 ) .
similarly , in kernel regression and classication , one might want to have a global proposal that places the bases ( kernels ) at the locations of the input data and a local random walk proposal that perturbs these in order to obtain better ts ( andrieu , de freitas , & doucet , 123b ) .
however , mixtures of kernels also play a big role in many other samplers , including the reversible jump mcmc algorithm ( section 123 ) .
the pseudo - code for a typical mixture of kernels is shown in gure 123
cycles allow us to split a multivariate state vector into components ( blocks ) that can be updated separately .
typically the samplers will mix more quickly by blocking highly cor - related variables .
a block mcmc sampler , using b j to indicate the j - th block , nb to denote ) , is shown in the number of blocks and x ( i+123 ) ( b j ) ( cid : 123 ) = nb ( cid : 123 ) gure 123
the transition kernel for this algorithm is given by the following expression ( cid : 123 ) ( cid : 123 ) x ( i )
( cid : 123 ) ( x ( i+123 ) , x ( i+123 )
, x ( i+123 )
, x ( i )
, x ( i )
( cid : 123 ) ( cid : 123 ) ( cid : 123 ) x ( i )
, x ( i+123 ) ( b j )
where kmh ( j ) denotes the j - th mh algorithm in the cycle .
figure 123
typical mixture of mcmc kernels .
figure 123
cycle of mcmc kernelsblock mh algorithm .
obviously , choosing the size of the blocks poses some trade - offs .
if one samples the components of a multi - dimensional vector one - at - a - time , the chain may take a very long time to explore the target distribution .
this problem gets worse as the correlation between the components increases .
alternatively , if one samples all the components together , then the probability of accepting this large move tends to be very low .
a popular cycle of mh kernels , known as gibbs sampling ( geman & geman , 123 ) , is obtained when we adopt the full conditional distributions p ( x j | x j ) = p ( x j | x123 , .
, x j123 , x j+123 , .
, xn ) as proposal distributions ( for notational simplicity , we have replaced the index notation b j with j ) .
the following section describes it in more detail .
the gibbs sampler
suppose we have an n - dimensional vector x and the expressions for the full conditionals p ( x j | x123 , .
, x j123 , x j+123 , .
in this case , it is often advantageous to use the following
andrieu et al .
proposal distribution for j = 123 ,
( cid : 123 ) ( cid : 123 ) x ( i )
( cid : 123 ) ( cid : 123 ) x ( i ) j
= x ( i ) j if x ( cid : 123 ) j
the corresponding acceptance probability is :
x ( i ) , x ( cid : 123 )
( cid : 123 ) = min
( cid : 123 ) ( cid : 123 ) x ( cid : 123 ) ( cid : 123 ) ( cid : 123 ) x ( i ) j x ( cid : 123 ) |x ( i ) |x ( cid : 123 ) j )
p ( x ( cid : 123 ) ) p x ( cid : 123 ) j x ( i ) j
that is , the acceptance probability for each proposal is one and , hence , the deterministic scan gibbs sampler algorithm is often presented as shown in gure 123
since the gibbs sampler can be viewed as a special case of the mh algorithm , it is possible to introduce mh steps into the gibbs sampler .
that is , when the full conditionals are available and belong to the family of standard distributions ( gamma , gaussian , etc . ) , we will draw the new samples directly .
otherwise , we can draw samples with mh steps embedded within the gibbs algorithm .
for n = 123 , the gibbs sampler is also known as the data augmentation algorithm , which is closely related to the expectation maximisation ( em ) algorithm ( dempster , laird , & rubin , 123; tanner & wong , 123 ) .
directed acyclic graphs ( dags ) are one of the best known application areas for gibbs sampling ( pearl , 123 ) .
here , a large - dimensional joint distribution is factored into a directed graph that encodes the conditional independencies in the model .
in particular , if x pa ( j )
figure 123
gibbs sampler .
denotes the parent nodes of node x j , we have
( cid : 123 ) ( cid : 123 ) x j
( cid : 123 ) = p
( cid : 123 ) ( cid : 123 ) x pa ( j ) ( cid : 123 ) ( cid : 123 ) x pa ( j )
it follows that the full conditionals simplify as follows
( cid : 123 ) ( cid : 123 ) x pa ( k )
where ch ( j ) denotes the children nodes of x j .
that is , we only need to take into account the parents , the children and the childrens parents .
this set of variables is known as the markov blanket of x j .
this technique forms the basis of the popular software package for bayesian updating with gibbs sampling ( bugs ) ( gilks , thomas , & spiegelhalter , 123 ) .
sampling from the full conditionals , with the gibbs sampler , lends itself naturally to the construction of general purpose mcmc software .
it is sometimes convenient to block some of the variables to improve mixing ( jensen , kong , & kjrulff , 123; wilkinson & yeung ,
monte carlo em
the em algorithm ( baum et al . , 123; dempster , laird , & rubin , 123 ) is a standard algorithm for ml and map point estimation .
if x contains visible and hidden variables x = ( xv , xh ) , then a local maximum of the likelihood p ( xv | ) given the parameters can be found by iterating the following two steps :
e step .
compute the expected value of the complete log - likelihood function with respect
to the distribution of the hidden variables
log ( p ( xh , xv | ) ) p
( cid : 123 ) ( cid : 123 ) xv , ( old )
where ( old ) refers to the value of the parameters at the previous time step .
m step .
perform the following maximisation ( new ) = arg max q ( ) .
in many practical situations , the expectation in the e step is either a sum with an exponen - tially large number of summands or an intractable integral ( ghahramani , 123; ghahramani & jordan , 123; mcculloch , 123; pasula et al . , 123; utsugi , 123 ) ; see also dellaert et al .
( this issue ) .
a solution is to introduce mcmc to sample from p ( xh | xv , ( old ) ) and replace the expectation in the e step with a small sum over the samples , as shown in gure 123
convergence of this algorithm is discussed in sherman , ho , and dalal ( 123 ) , while levine and casella ( 123 ) is a good recent review .
to improve the convergence behaviour of em , namely to escape low local minima and saddle points , various authors have proposed stochastic approaches that rely on sampling from p ( xh | xv , ( old ) ) in the e step and then performing the m step using these samples .
andrieu et al .
figure 123
mcmc - em algorithm .
the method is known as stochastic em ( sem ) when we draw only one sample ( celeux & diebolt , 123 ) and monte carlo em ( mcem ) when several samples are drawn ( wei & tanner , 123 ) .
there are several annealed variants ( such as saem ) that become more deterministic as the number of iterations increases ( celeux & diebolt , 123 ) .
the are also very efcient algorithms for marginal map estimation ( same ) ( doucet , godsill , & robert , 123 ) .
one wishes sometimes that metropolis had succeeded in stopping the proliferation
auxiliary variable samplers
it is often easier to sample from an augmented distribution p ( x , u ) , where u is an auxiliary variable , than from p ( x ) .
then , it is possible to obtain marginal samples x ( i ) by sampling ( x ( i ) , u ( i ) ) according to p ( x , u ) and , subsequently , ignoring the samples u ( i ) .
this very useful idea was proposed in the physics literature ( swendsen & wang , 123 ) .
here , we will focus on two well - known examples of auxiliary variable methods , namely hybrid monte carlo and slice sampling .
hybrid monte carlo .
hybrid monte carlo ( hmc ) is an mcmc algorithm that incorporates information about the gradient of the target distribution to improve mixing in high dimensions .
we describe here the leapfrog hmc algorithm outlined in duane et al .
( 123 ) and neal ( 123 ) focusing on the algorithmic details and not on the statistical mechanics motivation .
assume that p ( x ) is differentiable and everywhere strictly positive .
at each iteration of the hmc algorithm , one takes a predetermined number ( l ) of deter - ministic steps using information about the gradient of p ( x ) .
to explain this in more detail , we rst need to introduce a set of auxiliary momentum variables u rnx and dene the
figure 123
hybrid monte carlo .
extended target density
p ( x , u ) = p ( x ) n ( cid : 123 )
u; 123 , inx
next , we need to introduce the nx - dimensional gradient vector ( x ) ( cid : 123 ) log p ( x ) / x and a xed step - size parameter > 123
in the hmc algorithm , we draw a new sample according to p ( x , u ) by starting with the previous value of x and generating a gaussian random variable u .
we then take l frog leaps in u and x .
the values of u and x at the last leap are the proposal candidates in the mh algorithm with target density p ( x , u ) .
marginal samples from p ( x ) are ob - tained by simply ignoring u .
given ( x ( i123 ) , u ( i123 ) ) , the algorithm proceeds as illustrated in when only one deterministic step is used , i . e .
l = 123 , one obtains the langevin algorithm , which is a discrete time approximation of a langevin diffusion process .
the langevin algorithm is a special case of mh where the candidate satises
x ( cid : 123 ) = x123 + u123 = x ( i123 ) +
with u ( cid : 123 ) n ( 123 , inx ) .
the choice of the parameters l and poses simulation tradeoffs .
large values of result in low acceptance rates , while small values require many leapfrog steps ( expensive computations of the gradient ) to move between two nearby states .
choosing l is equally problematic as we want it to be large to generate candidates far from the initial state , but this can result in many expensive computations .
hmc , therefore , requires careful tuning of the proposal distribution .
it is more efcient , in practice , to allow a different step size for each of the coordinates of x ( ishwaran , 123 ) .
andrieu et al .
the slice sampler .
the slice sampler ( damien , wakeeld , & walker , 123; higdon , 123; wakeeld , gelfand , & smith , 123 ) is a general version of the gibbs sampler .
the basic idea of the slice sampler is to introduce an auxiliary variable u r and construct an extended target distribution p ( cid : 123 ) ( x , u ) , such that
if 123 u p ( x )
p ( cid : 123 ) ( x , u ) =
it is then straightforward to check that
p ( cid : 123 ) ( x , u ) du =
du = p ( x ) .
hence , to sample from p ( x ) one can sample from p ( cid : 123 ) ( x , u ) and then ignore u .
the full conditionals are of this augmented model are
p ( u | x ) = u ( 123 , p ( x ) ) ( u ) p ( x | u ) = ua ( x )
where a = ( x; p ( x ) u ) .
if a is easy to identify then the algorithm is straightforward to implement , as shown in gure 123
it can be difcult to identify a .
it is then worth introducing several auxiliary variables
( damien , wakeeld , & walker , 123; higdon , 123 ) .
for example assume that
where the fl ( ) s are positive functions , not necessarily densities .
let us introduce l auxiliary variables ( u123 , .
, u l ) and dene
p ( cid : 123 ) ( x , u123 , .
, u l ) l ( cid : 123 )
i ( 123 , fl ( x ) ) ( ul ) .
figure 123
slice sampling : given a previous sample , we sample a uniform variable u ( i+123 ) between 123 and f ( x ( i ) ) .
one then samples x ( i+123 ) in the interval where f ( x ) u ( i+123 ) .
figure 123
slice sampler .
then one can also check that
p ( cid : 123 ) ( x , u123 , .
, u l ) du123 .
du l = p ( x ) as
i ( 123 , fl ( x ) ) ( ul ) du123 .
du l = l ( cid : 123 )
p ( cid : 123 ) ( x , u123 , .
, u l ) du123
the slice sampler to sample from p ( cid : 123 ) ( x , u123 , .
, u l ) proceeds as shown in gure 123
al - gorithmic improvements and convergence results are presented in mira ( 123 ) and neal
reversible jump mcmc
in this section , we attack the more complex problem of model selection .
typical exam - ples include estimating the number of neurons in a neural network ( andrieu , de freitas , & doucet , 123a; holmes & mallick , 123; rios insua & muller , 123 ) , the number of splines in a multivariate adaptive splines regression ( mars ) model ( holmes & denison , this issue ) , the number of sinusoids in a noisy signal ( andrieu & doucet , 123 ) , the number of lags in an autoregressive process ( troughton & godsill , 123 ) , the number of com - ponents in a mixture ( richardson & green , 123 ) , the number of levels in a change - point process ( green , 123 ) , the number of components in a mixture of factor analy - sers ( fokoue & titterington , this issue ) , the appropriate structure of a graphical model ( friedman & koller , 123; giudici & castelo , this issue ) or the best set of input variables ( lee , this issue ) .
given a family of m models ( mm; m = 123 , .
, n ) , we will focus on constructing ergodic markov chains admitting p ( m , xm ) as the invariant distribution .
for simplicity , we avoid the treatment of nonparametric model averaging techniques; see for example ( escobar & west , 123; green & richardson , 123 ) .
up to this section , we have been comparing densities in the acceptance ratio .
however , if we are carrying out model selection , then comparing the densities of objects in different dimensions has no meaning .
it is like trying to compare spheres with circles .
instead , we have to be more formal and compare distributions p ( dx ) = pr ( x dx ) under a common measure of volume .
the distribution p ( dx ) will be assumed to admit a density p ( x ) with respect to a measure of interest , e . g .
lebesgue in the continuous case : p ( dx ) = p ( x ) dx .
the acceptance ratio will now include the ratio of the densities and the ratio of the measures ( radon nikodym derivative ) .
the latter gives rise to a jacobian term .
to compare densities point - wise , we need , therefore , to map the two models to a common dimension as illustrated in gure 123
andrieu et al .
p ( x , x )
uniformly expanded density
p ( x , x )
figure 123
to compare a 123d model against a 123d model , we rst have to map the rst model so that both models have common measure ( area in this case ) .
the parameters xm xm ( e . g .
xm = rnm ) are model dependent .
hence , to nd the right model and parameters we could sample over the model indicator and the product space xm ( carlin & chib , 123 ) .
recently , green introduced a strategy that avoids this expensive search over the full product space ( green , 123 ) .
in particular one samples on a ( m ) xm .
the full target distribution dened in this much smaller union space x ( cid : 123 ) space is given by
p ( k , dx ) = m ( cid : 123 )
p ( m , dxm ) i ( m ) xm ( k , x ) .
that is , the probability of k being equal to m and x belonging to an innitesimal set centred around xm is p ( m , dxm ) .
by marginalisation , we obtain the probability of being in subspace greens method allows the sampler to jump between the different subspaces .
to ensure a common measure , it requires the extension of each pair of communicating spaces , xm and xn , to xm , n ( cid : 123 ) xm um , n and xn , m ( cid : 123 ) xn un , m .
it also requires the denition of a deterministic , differentiable , invertible dimension matching function fnm between xm , n
( xm , um , n ) = fnm ( xn , un , m ) = ( cid : 123 )
nm ( xn , un , m ) , f u
we dene fmn such that fmn ( fnm ( xn , un , m ) ) = ( xn , un , m ) .
the choice of the extended spaces , deterministic transformation fmn and proposal distributions for qnm ( | n , xn ) and qmn ( | m , xm ) is problem dependent and needs to be addressed on a case by case basis .
if the current state of the chain is ( n , xn ) , we move to ( m , xm ) by generating un , m qnm ( | n , xn ) , ensuring that we have reversibility ( xm , um , n ) = fnm ( xn , un , m ) , and ac - cepting the move according to the probability ratio
anm = min
p ( m , x ( cid : 123 )
qmn ( um , n | m , x ( cid : 123 ) qnm ( un , m | n , xn )
where x ( cid : 123 ) only continuous variables are involved in the transformation )
nm ( xn , un , m ) and j fnm is the jacobian of the transformation fnm ( when
fnm ( xm , um , n )
( xm , um , n )
q ( n | m ) q ( m | n )
to illustrate this , assume that we are concerned with sampling the locations and number k of components of a mixture .
for example we might want to estimate the locations and number of basis functions in kernel regression and classication , the number of mixture components in a nite mixture model , or the location and number of segments in a segmen - tation problem .
here , we could dene a merge move that combines two nearby components and a split move that breaks a component into two nearby ones .
the merge move involves randomly selecting a component ( 123 ) and then combining it with its closest neighbour ( 123 ) into a single component , whose new location is
= 123 + 123
the corresponding split move that guarantees reversibility , involves splitting a randomly chosen component as follows
123 = un , m 123 = + un , m
where is a simulation parameter and , for example , un , m u ( 123 , 123 ) .
note that to ensure reversibility , we only perform the merge move if ( cid : 123 ) 123 123 ( cid : 123 ) < 123
the acceptance ratio for the split move is
asplit = min
p ( k + 123 , k+123 )
where 123 / k denotes the probability of choosing , uniformly at random , one of the k compo - nents .
the jacobian is
( cid : 123 ) ( cid : 123 ) ( cid : 123 ) ( cid : 123 ) ( 123 , 123 )
( cid : 123 ) ( cid : 123 ) ( cid : 123 ) ( cid : 123 ) = 123
andrieu et al .
figure 123
generic reversible jump mcmc .
similarly , for the merge move , we have p ( k 123 , k123 )
amerge = min
where jmerge = 123 / 123
reversible jump is a mixture of mcmc kernels ( moves ) .
in addition , to the split and merge moves , we could have other moves such as birth of a component , death of a component and a simple update of the locations .
the various moves are carried out according to the mixture probabilities ( bk , dk , mk , sk , uk ) , as shown in gure 123
in fact , it is the exibility of including so many possible moves that can make reversible jump a more powerful model selection strategy than schemes based on model selection using a mixture indicator or diffusion processes using only birth and death moves ( stephens , 123 ) .
however , the problem with reversible jump mcmc is that engineering reversible moves is a very tricky ,
the mcmc frontiers
convergence and perfect sampling
determining the length of the markov chain is a difcult task .
in practice , one often dis - cards an initial set of samples ( burn - in ) to avoid starting biases .
in addition , one can ap - ply several graphical and statistical tests to assess , roughly , if the chain has stabilised ( robert & casella , 123 , ch .
in general , none of these tests provide entirely satisfactory
several theoreticians have tried to bound the mixing time; that is , the minimum number of steps required for the distribution of the markov chain k to be close to the target p ( x ) .
( here , we present a , by no means exhaustive , summary of some of the available results . ) if
we measure closeness with the total variation norm x ( t ) , where k ( t ) ( y | x ) p ( y )
x ( t ) = ( cid : 123 ) ( cid : 123 ) k ( t ) ( | x ) p ( )
( cid : 123 ) ( cid : 123 ) = 123
then the mixing time is
x ( ) = min ( t : x ( t
) for all t
k ( k f ( x ) = ( cid : 123 )
if the state space x is nite and reversibility holds true , then the transition operator
k ( y | x ) f ( y ) ) is self adjoint on l123 ( p ) .
that is ,
( cid : 123 ) k f | g ( cid : 123 ) = ( cid : 123 ) f | k g ( cid : 123 ) ,
( cid : 123 ) f | g ( cid : 123 ) = ( cid : 123 )
where f and g are real functions and we have used the bra - ket notation for the inner product
f ( x ) g ( x ) p ( x ) .
this implies that k has real eigenvalues
123 = 123 > 123 123 |x| > 123
and an orthonormal basis of real eigenfunctions fi , such that k fi = i fi .
this spectral decomposition and the cauchy - schwartz inequality allow us to obtain a bound on the total
where ( cid : 123 ) = max ( 123 , ||x|| ) ( diaconis & saloff - coste , 123; jerrum & sinclair , 123 ) .
this classical result give us a geometric convergence rate in terms of eigenvalues .
geometric bounds have also been obtained in general state spaces using the tools of regeneration and lyapunov - foster conditions ( meyn & tweedie , 123 ) .
the next logical step is to bound the second eigenvalue .
there are several inequalities ( cheeger , poincare , nash ) from differential geometry that allows us to obtain these bounds ( diaconis & saloff - coste , 123 ) .
for example , one could use cheegers inequality to obtain the following bound
123 123 123 123 123
where is the conductance of the markov chain xs , ysc p ( x ) k ( y | x )
intuitively , one can interpret this quantity as the readiness of the chain to escape from any small region s of the state space and , hence , make rapid progress towards equilibrium ( jerrum & sinclair , 123 ) .
andrieu et al .
these mathematical tools have been applied to show that simple mcmc algorithms ( mostly metropolis ) run in time that is polynomial in the dimension d of the state space , thereby escaping the exponential curse of dimensionality .
polynomial time sampling algo - rithms have been obtained in the following important scenarios :
computing the volume of a convex body in d dimensions , where d is large ( dyer , frieze ,
& kannan , 123 ) .
sampling from log - concave distributions ( applegate & kannan , 123 ) .
sampling from truncated multivariate gaussians ( kannan & li , 123 ) .
computing the permanent of a matrix ( jerrum , sinclair , & vigoda , 123 ) .
the last problem is equivalent to sampling matchings from a bipartite graph; a problem that manifests itself in many ways in machine learning ( e . g . , stereo matching and data
although the theoretical results are still far from the practice of mcmc , they will even - tually provide better guidelines on how to design and choose algorithms .
already , some results tell us , for example , that it is not wise to use the independent metropolis sampler in high dimensions ( mengersen & tweedie , 123 ) .
a remarkable recent breakthrough was the development of algorithms for perfect sam - pling .
these algorithms are guaranteed to give us an independent sample from p ( x ) under certain restrictions .
the two major players are coupling from the past ( propp & wilson , 123 ) and fills algorithm ( fill , 123 ) .
from a practical point of view , these algorithms are still limited and , in many cases , computationally inefcient .
however , some steps are being taken towards obtaining more general perfect samplers; for example perfect slice samplers ( casella et al . , 123 ) .
adaptive mcmc
if we look at the chain on the top right of gure 123 , we notice that the chain stays at each state for a long time .
this tells us that we should reduce the variance of the proposal distribution .
ideally , one would like to automate this process of choosing the proposal distribution as much as possible .
that is , one should use the information in the samples to update the parameters of the proposal distribution so as to obtain a distribution that is either closer to the target distri - bution , that ensures a suitable acceptance rate , or that minimises the variance of the estimator of interest .
however , one should not allow adaptation to take place innitely often in a naive way because this can disturb the stationary distribution .
this problem arises because by using the past information innitely often , we violate the markov property of the transition kernel .
that is , p ( x ( i ) | x ( 123 ) , x ( 123 ) , .
, x ( i123 ) ) no longer simplies to p ( x ( i ) | x ( i123 ) ) .
in particular , gelfand and sahu ( 123 ) present a pathological example , where the stationary distribution is disturbed despite the fact that each participating kernel has the same stationary distribution .
to avoid this problem , one could carry out adaptation only during an initial xed number of steps , and then use standard mcmc simulation to ensure convergence to the right distribu - tion .
two methods for doing this are presented in gelfand and sahu ( 123 ) .
the rst is based on the idea of running several chains in parallel and using sampling - importance resampling
( rubin , 123 ) to multiply the kernels that are doing well and suppress the others .
in this approach , one uses an approximation to the marginal density of the chain as proposal .
the second method simply involves monitoring the transition kernel and changing one of its com - ponents ( for example the proposal distribution ) so as to improve mixing .
a similar method that guarantees a particular acceptance rate is discussed in browne and draper ( 123 ) .
there are , however , a few adaptive mcmc methods that allow one to perform adaptation continuously without disturbing the markov property , including delayed rejection ( tierney & mira , 123 ) , parallel chains ( gilks & roberts , 123 ) and regeneration ( gilks , roberts , & sahu , 123; mykland , tierney , & yu , 123 ) .
these methods are , unfortunately , inefcient in many ways and much more research is required in this exciting area .
sequential monte carlo and particle lters
sequential monte carlo ( smc ) methods allow us to carry out on - line approximation of probability distributions using samples ( particles ) .
they are very useful in scenarios involv - ing real - time signal processing , where data arrival is inherently sequential .
furthermore , one might wish to adopt a sequential processing strategy to deal with non - stationarity in signals , so that information from the recent past is given greater weighting than information from the distant past .
computational simplicity in the form of not having to store all the data might also constitute an additional motivating factor for these methods .
in the smc setting , we assume that we have an initial distribution , a dynamic model and
p ( xt | x123 : t123 , y123 : t123 ) p ( yt | x123 : t , y123 : t123 )
for t 123 for t 123
we denote by x123 : t ( cid : 123 ) ( x123 , .
, xt ) and y123 : t ( cid : 123 ) ( y123 , .
, yt ) , respectively , the states and the ob - servations up to time t .
note that we could assume markov transitions and conditional inde - pendence to simplify the model; p ( xt | x123 : t123 , y123 : t123 ) = p ( xt | xt123 ) and p ( yt | x123 : t , y123 : t123 ) = p ( yt | xt ) .
however , this assumption is not necessary in the smc framework .
our aim is to estimate recursively in time the posterior p ( x123 : t | y123 : t ) and its associated features including the marginal distribution p ( xt | y123 : t ) , known as the ltering distribution , and the expectations
i ( ft ) = e p ( x123 : t|y123 : t ) ( ft ( x123 : t ) )
a generic smc algorithm is depicted in gure 123
given n particles ( x ( i ) time t 123 , approximately distributed according to the distribution p ( x123 : t123 | y123 : t123 ) , smc methods allow us to compute n particles ( x ( i ) i=123 approximately distributed according to the posterior p ( x123 : t|y123 : t ) , at time t .
since we cannot sample from the posterior directly , the smc update is accomplished by introducing an appropriate importance proposal dis - tribution q ( x123 : t ) from which we can obtain samples .
the samples are then appropriately
andrieu et al .
in this example , the bootstrap lter starts at time t 123 with an unweighted measure ( x ( i )
which provides an approximation of p ( xt123 | y123 : t123 ) .
for each particle we compute the importance weights using the information at time t 123
this results in the weighted measure ( x ( i ) ) , which yields an approximation p ( xt123 | y123 : t123 ) .
subsequently , the resampling step selects only the ttest particles to obtain the unweighted 123 ) , which is still an approximation of p ( xt123 | y123 : t123 ) .
finally , the sampling ( prediction ) step introduces variety , resulting in the measure ( x ( i )
123 ) , which is an approximation of p ( xt | y123 : t123 ) .
figure 123
simple smc algorithm at time t .
for ltering purposes , there is no need for storing or resampling the past trajectories .
new paths ( x ( i )
in generic smc simulation , one needs to extend the current paths ( x ( i )
i=123 using the proposal distribution q ( x123 : t|y123 : t ) given by q ( x123 : t | x123 : t123 , y123 : t ) p ( x123 : t123 | y123 : t123 ) dx123 : t123
q ( x123 : t | y123 : t ) ) =
i=123 to obtain
to make this integral tractable , we only propose to modify the particles at time t , and leave the past trajectories intact .
consequently
q ( x123 : t | y123 : t ) = p ( x123 : t123 | y123 : t123 ) q ( xt | x123 : t123 , y123 : t )
the samples from q ( ) , must be weighted by the importance weights
= p ( x123 : t123 | y123 : t ) wt = p ( x123 : t | y123 : t ) p ( x123 : t123 | y123 : t123 ) q ( x123 : t | y123 : t ) p ( yt | xt ) p ( xt | x123 : t123 , y123 : t123 )
qt ( xt | x123 : t123 , y123 : t )
p ( xt | x123 : t123 , y123 : t ) q ( xt | x123 : t123 , y123 : t )
from eq .
( 123 ) , we note that the optimal importance distribution is
q ( xt | x123 : t123 , y123 : t ) = p ( xt | x123 : t123 , y123 : t ) .
( when using this proposal , one might still encounter difculties if the ratio of the rst two terms of eq .
( 123 ) differs signicantly from 123 ( andrieu , doucet , & punskaya , 123; pitt & shephard , 123 ) . ) the optimal importance distribution can be difcult to evaluate .
one can adopt , instead , the transition prior as proposal distribution
q ( xt | x123 : t123 , y123 : t ) = p ( xt | x123 : t123 , y123 : t123 )
in which case the importance weights are given by the likelihood function
wt p ( yt | xt ) .
this simplied version of smc has appeared under many names , including condensation ( isard & blake , 123 ) , survival of the ttest ( kanazawa , koller , & russell , 123 ) and the bootstrap lter ( gordon , salmond , & smith , 123 ) .
the importance sampling framework allows us to design more principled and clever proposal distributions .
for instance , one can adopt suboptimal lters and other approximation methods that make use of the information available at time t to generate the proposal distribution ( doucet , godsill , & andrieu , 123; de freitas et al . , 123; pitt & shephard , 123; van der merwe et al . , 123 ) .
in fact , in some restricted situations , one may interpret the likelihood as a distribution in terms of the states and sample from it directly .
in doing so , the importance weights become equal to the transition prior ( fox et al . , 123 ) .
after the importance sampling step , a selection scheme associates to each particle x ( i ) a number of children , say ni n , such that i=123 ni = n .
this selection step is what
andrieu et al .
allows us to track moving target distributions efciently by choosing the ttest particles .
there are various selection schemes in the literature , but their performance varies in terms of var ( ni ) ( doucet , de freitas , & gordon , 123 ) .
an important feature of the selection routine is that its interface only depends on particle indices and weights .
that is , it can be treated as a black - box routine that does not require any knowledge of what a particle represents ( e . g . , variables , parameters , models ) .
this enables one to implement variable and model selection schemes straightforwardly .
the simplicity of the coding of complex models is , indeed , one of the major advantages of these it is also possible to introduce mcmc steps of invariant distribution p ( x123 : t | y123 : t ) on each particle ( andrieu , de freitas , & doucet , 123; gilks & berzuini , 123; maceachern , clyde , & liu , 123 ) .
the basic idea is that if the particles are distributed according to the poste - rior distribution p ( x123 : t | y123 : t ) , then applying a markov chain transition kernel k ( x ( cid : 123 ) | x123 : t ) , with invariant distribution p ( | y123 : t ) such that | y123 : t ) , still results in a set of particles distributed according to the posterior of interest .
however , the new particles might have been moved to more interesting areas of the state - space .
in fact , by applying a markov transition kernel , the total variation of the current distribution with respect to the invariant distribution can only decrease .
note that we can incorporate any of the standard mcmc methods , such as the gibbs sampler , mh algorithm and reversible jump mcmc , into the ltering framework , but we no longer require the kernel to be
| x123 : t ) p ( x123 : t | y123 : t ) = p ( x ( cid : 123 )
k ( x ( cid : 123 )
the machine learning frontier
the machine learning frontier is characterised by large dimensional models , massive datasets and many and varied applications .
massive datasets pose no problem in the smc context .
however , in batch mcmc simulation it is often not possible to load the entire dataset into memory .
a few solutions based on importance sampling have been proposed recently ( ridgeway , 123 ) , but there is still great room for innovation in this area .
despite the auspicious polynomial bounds on the mixing time , it is an arduous task to design efcient samplers in high dimensions .
the combination of sampling algorithms with either gradient optimisation or exact methods has proved to be very useful .
gradient optimisation is inherent to langevin algorithms and hybrid monte carlo .
these algorithms have been shown to work with large dimensional models such as neural networks ( neal , 123 ) and gaussian processes ( barber & williams , 123 ) .
information about derivatives of the target distribution also forms an integral part of many adaptive schemes , as discussed in section 123 .
recently , it has been argued that the combination of mcmc and variational optimisation techniques can also lead to more efcient sampling ( de freitas et al . , 123 ) .
the combination of exact inference with sampling methods within the framework of rao - blackwellisation ( casella & robert , 123 ) can also result in great improvements .
suppose we can divide the hidden variables x into two groups , u and v , such that p ( x ) = p ( v | u ) p ( u ) and , conditional on u , the conditional posterior distribution p ( v | u ) is analytically tractable .
then we can easily marginalise out v from the posterior , and only need to focus on sampling from p ( u ) , which lies in a space of reduced dimension .
that is , we sample u ( i ) p ( u ) and
then use exact inference to compute
p ( v ) = 123
by identifying troublesome variables and sampling them , the rest of the problem can often be solved easily using exact algorithms such as kalman lters , hmms or junction trees .
for example , one can apply this technique to sample variables that eliminate loops in graphical models and then compute the remaining variables with efcient analytical algo - rithms ( jensen , kong , & kjrulff , 123; wilkinson & yeung , 123 ) .
other application areas include dynamic bayesian networks ( doucet et al . , 123 ) , conditionally gaussian models ( carter & kohn , 123; de jong & shephard , 123; doucet , 123 ) and model averaging for graphical models ( friedman & koller , this issue ) .
the problem of how to automatically identify which variables should be sampled , and which can be handled analytically is still open .
an interesting development is the augmentation of high dimensional models with low dimensional articial variables .
by sampling only the articial variables , the original model decouples into simpler , more tractable submodels ( albert & chib , 123; andrieu , de freitas , & doucet , 123b; wood & kohn , 123 ) ; see also holmes and denison ( this issue ) .
this strategy allows one to map probabilistic classication problems to simpler regression
the design of efcient sampling methods most of the times hinges on awareness of the basic building blocks of mcmc ( mixtures of kernels , augmentation strategies and blocking ) and on careful design of the proposal mechanisms .
the latter requires domain specic knowledge and heuristics .
there are great opportunities for combining existing sub - optimal algorithms with mcmc in many machine learning problems .
some areas that are already beneting from sampling methods include :
computer vision .
tracking ( isard & blake , 123; ormoneit , lemieux , & fleet , 123 ) , stereo matching ( dellaert et al . , this issue ) , colour constancy ( forsyth , 123 ) , restoration of old movies ( morris , fitzgerald , & kokaram , 123 ) and segmentation ( clark & quinn , 123; kam , 123; tu & zhu , 123 ) .
web statistics .
estimating coverage of search engines , proportions belonging to specic
domains and the average size of web pages ( bar - yossef et al . , 123 ) .
speech and audio processing .
signal enhancement ( godsill & rayner , 123; vermaak
et al . , 123 ) .
probabilistic graphical models .
for example ( gilks , thomas , & spiegelhalter , 123;
wilkinson & yeung , 123 ) and several papers in this issue .
regression and classication .
neural networks and kernel machines ( andrieu , de freitas , & doucet , 123a; holmes & mallick , 123; neal , 123; muller & rios insua , 123 ) , gaussian processes ( barber & williams , 123 ) , cart ( denison , mallick , & smith , 123 ) and mars ( holmes & denison , this issue ) .
computer graphics .
light transport ( veach & guibas , 123 ) and sampling plausible
solutions to multi - body constraint problems ( chenney & forsyth , 123 ) .
andrieu et al .
data association .
vehicle matching in highway systems ( pasula et al . , 123 ) and mul -
titarget tracking ( bergman , 123 ) .
decision theory .
partially observable markov decision processes ( pomdps ) ( thrun , 123; salmond & gordon , 123 ) , abstract markov policies ( bui , venkatesh , & west , 123 ) and inuence diagrams ( bielza , muller , & rios insua , 123 ) .
first order probabilistic logic .
( pasula & russell , 123 ) .
genetics and molecular biology .
dna microarray data ( west et al . , 123 ) , cancer gene mapping ( newton & lee , 123 ) , protein alignment ( neuwald et al . , 123 ) and linkage analysis ( jensen , kong , & kjrulff , 123 ) .
robotics .
robot localisation and map building ( fox et al . , 123 ) .
classical mixture models .
mixtures of independent factor analysers ( utsugi , 123 ) and
mixtures of factor analysers ( fokoue & titterington , this issue ) .
