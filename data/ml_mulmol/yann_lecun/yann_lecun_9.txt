we assess the applicability of several popular learning methods for the problem of recognizing generic visual cat - egories with invariance to pose , lighting , and surrounding clutter .
a large dataset comprising stereo image pairs of 123 uniform - colored toys under 123 azimuths , 123 elevations , and 123 lighting conditions was collected ( for a total of 123 , 123 in - dividual images ) .
the objects were 123 instances of 123 generic categories : four - legged animals , human gures , airplanes , trucks , and cars .
five instances of each category were used for training , and the other ve for testing .
low - resolution grayscale images of the objects with various amounts of variability and surrounding clutter were used for training and testing .
nearest neighbor methods , support vector ma - chines , and convolutional networks , operating on raw pix - els or on pca - derived features were tested .
test error rates for unseen object instances placed on uniform backgrounds were around 123% for svm and 123% for convolutional nets .
on a segmentation / recognition task with highly cluttered images , svm proved impractical , while convolutional nets yielded 123 / 123% error .
a real - time version of the system was implemented that can detect and classify objects in natu - ral scenes at around 123 frames per second .
the recognition of generic object categories with invari - ance to pose , lighting , diverse backgrounds , and the pres - ence of clutter is one of the major challenges of computer vision .
while there have been attempts to detect and recog - nize objects in natural scenes using a variety of clues , such as color , texture , the detection of distinctive local features , and the use of separately acquired 123d models , very few au - thors have attacked the problem of detecting and recogniz - ing 123d objects in images primarily from the shape informa -
even fewer authors have attacked the problem of rec - ognizing generic categories , such as cars , trucks , airplanes , human gures , or four - legged animals purely from shape in - formation .
the dearth of work in this area is due in part to the difculty of the problem , and in large part to the non -
availability of a dataset with sufcient size and diversity to carry out meaningful experiments .
the rst part of this paper describes the norb dataset , a large image dataset comprising 123 , 123 stereo image pairs of 123 objects belonging to 123 generic categories ( four - legged animals , human gures , airplanes , trucks , and cars ) under 123 different elevations , 123 azimuths , and 123 lighting conditions .
the raw images were used to generate very large sets of greyscale stereo pairs where the objects appear at variable location , scale , image - plane angles , brightness , and con - trast , on top of background clutter , and distractor objects .
the second part of the paper reports results of generic shape recognition using popular image classication meth - ods operating on various input representations .
the classi - ers were trained on ve instances of each category ( for all azimuths , elevations , and lightings ) and tested on the ve remaining instances .
results of simultaneous detection and recognition with convolutional nets are also reported .
the main purpose of this paper is not to introduce new recognition methods , but rather to ( 123 ) describe the largest publicly available dataset for generic object recognition; ( 123 ) report baseline performance with standard method on this dataset; ( 123 ) explore how different classes of methods fare when the number of input variables is in the tens of thou - sands , and the number of examples in the hundreds of thou - sands; ( 123 ) compare the performance of methods based on global template matching such as k - nearest neighbors and support vector machines , and those based on local fea - ture extraction such as convolutional nets , when intra - class variabilities involve highly complex transformations ( pose and lighting ) ; ( 123 ) assess the performance of template - based methods when the size of the problem is at the upper limit of their practicality; ( 123 ) measure to what extent the vari - ous learning architectures can learn invariance to 123d pose and lighting , and can deal with the variabilities of natural images; ( 123 ) determine whether trainable classiers can take advantage of binocular inputs .
the norb dataset
many object detection and recognition systems de - scribed in the literature have ( wisely ) relied on many different non - shape related clues and various assump - tions to achieve their goal .
authors have advocated the use of color , texture , and contours for image index -
proceedings of the 123 ieee computer society conference on computer vision and pattern recognition ( cvpr123 ) 123 - 123 / 123 $123 123 ieee
ing applications ( 123 ) , the detection of distinctive local features ( 123 , 123 , 123 , 123 ) , the use of global appearance tem - plates ( 123 , 123 , 123 ) , the extraction of silhouettes and edge in - formation ( 123 , 123 , 123 , 123 , 123 ) and the use of pose - invariant feature histograms ( 123 , 123 , 123 ) .
conversely , learning - based methods operating on raw pixels or low - level local fea - tures have been quite successful for such applications as face detection ( 123 , 123 , 123 , 123 , 123 , 123 ) , but they have yet to be applied successfully to shape - based , pose - invariant ob - ject recognition .
one of the central questions addressed in this paper is how methods based on global templates and methods based on local features compare on invari - ant shape classication tasks .
in the norb dataset , the only useful and reliable clue is the shape of the object , while all the other parameters that affect the appearance are subject to variation , or are de - signed to contain no useful clue .
parameters that are subject to variation are : viewing angles ( pose ) , lighting condition , position in the image plane , scale , image - plane rotation , surrounding objects , background texture , contrast , lumi - nance , and camera settings ( gain and white balance ) .
poten - tial clues whose impact was eliminated include : color ( all images were grayscale ) , and object texture ( objects were painted with a uniform color ) .
for specic object recogni - tion tasks , the color and texture information may be help - ful , but for generic shape recognition tasks the color and texture information are distractions rather than useful clues .
the image acquisition setup was deliberately designed to reect real imaging situations .
by preserving natural vari - abilities and eliminating irrelevant clues and systematic bi - ases , our aim was to produce a benchmark in which no hid - den regularity can be used , which would unfairly advantage some methods over others .
while several datasets of object images have been made available in the past ( 123 , 123 , 123 ) , norb is considerably larger than those datasets , and offers more variability , stereo pairs , and the ability to composite the objects and their cast shadows onto diverse backgrounds .
ultimately , practical object recognition systems will have to be trained on natural images .
the value of the present approach is to allow systematic objective compar - isons shape classication methods , as well as a way of assessing their invariant properties , and the number of ex - amples required to train them .
data collection
the image acquisition system was composed of a turntable on which object were placed , two hitachi kp - d123au ccd cameras mounted on a swiveling arm , and four studio lights with bounce umbrellas .
the angle of the turntable , the elevations of the camera arm , and the inten - sity of the lights were all under computer control .
the cam - eras were 123cm away from the objects ( roughly arm length ) and 123cm apart from each other ( roughly the distance be - tween the two eyes in humans ) .
the lenses focal length was set around 123mm .
the turntable was 123cm in diame - ter and had a uniform medium gray color .
the lights were placed at various xed locations and distances around the
we collected images of 123 different toys shown in g - ure 123
the collection consists of 123 instances of 123 generic categories : four - legged animals , human gures , airplanes , trucks , and cars .
all the objects were painted with a uni - form bright green .
the uniform color ensured that all irrel - evant color and texture information was eliminated .
123 , 123 stereo pairs were collected for each object instance : 123 eleva - tions ( 123 , 123 , 123 , 123 , 123 , 123 , 123 , 123 , and 123 degrees from the horizontal ) , 123 azimuths ( from 123 to 123 ) , and 123 lighting conditions ( various on - off combinations of the four lights ) .
a total of 123 , 123 rgb images at 123 resolu - tion were collected ( 123 categories , 123 instances , 123 elevations , 123 azimuths , 123 lightings , 123 cameras ) for a total of 123gb of raw data .
note that each object instance was placed in a different initial pose , therefore 123 degree angle may mean facing left for one instance of an animal , and facing 123 degree right for another instance .
training and testing samples were generated so as to carefully remove ( or avoid ) any potential bias in the data that might make the task easier than it would be in real - istic situations .
the object masks and their cast shadows were extracted from the raw images .
a scaling factor was determined for each of the 123 object instances by comput - ing the bounding box of the union of all the object masks for all the images of that instance .
the scaling factor was chosen such that the largest dimension of the bounding box was 123 pixels .
this removed the most obvious systematic bias caused by the variety of sizes of the objects ( e . g .
most airplanes were larger than most human gures in absolute terms ) .
the segmented and normalized objects were then composited ( with their cast shadows ) in the center of var - ious 123 123 pixel background images .
in some experi - ments , the locations , scales , image - plane angle , brightness , and contrast were randomly perturbed during the composit -
experiments were conducted with four datasets gen - erated from the normalized object images .
the rst two datasets were for pure categorization experiments ( a some - what unrealistic task ) , while the last two were for simulta - neous detection / segmentation / recognition experiments .
all datasets used 123 instances of each category for train - ing and the 123 remaining instances for testing .
in the normal - ized dataset , 123 images of each instance were used : 123 ele - vations , 123 azimuths ( 123 to 123 ) , and 123 illumina - tions , for a total of 123 , 123 training samples and 123 , 123 test samples .
in the various jittered datasets , each of the 123 im - ages of each instance were used to generate additional ex - amples by randomly perturbing the position ( ( - 123 , +123 ) pix - els ) , scale ( ratio in ( 123 , 123 ) ) , image - plane angle ( ( - 123 , 123 ) de - grees ) , brightness ( ( - 123 , 123 ) shifts of gray levels ) , contrast ( ( 123 , 123 ) gain ) of the objects during the compositing pro - cess .
ten drawings of these random parameters were drawn to generate training sets , and one or two drawings to gener - ate test sets .
proceedings of the 123 ieee computer society conference on computer vision and pattern recognition ( cvpr123 ) 123 - 123 / 123 $123 123 ieee
figure 123
the 123 object instances in the norb dataset .
the left side contains the training instances and the right side the testing instances for each of the 123 categories .
in the textured and cluttered datasets , the objects were placed on randomly picked background images .
in those ex - periments , a 123 - th category was added : background images with no objects ( results are reported for this 123 - way classi - cation ) .
in the textured set , the backgrounds were placed at a xed disparity , akin to a back wall orthogonal to the camera axis at a xed distance .
in the cluttered datasets , the dispar - ities were adjusted and randomly picked so that the objects appeared placed on highly textured horizontal surfaces at small random distance from that surface .
in addition , a ran - domly picked distractor object from the training set was placed at the periphery of the image .
normalized - uniform set : 123 classes , centered , unper - turbed objects on uniform backgrounds .
123 , 123 train - ing samples , 123 , 123 testing samples .
see gure 123
jittered - uniform set : 123 classes , random perturbations , uniform backgrounds .
123 , 123 training samples ( 123 drawings ) and 123 , 123 test samples ( 123 drawing ) jittered - textured set : 123 classes ( including one back - random perturbation , natural back - ground textures at xed disparity .
123 , 123 train - ing samples ( 123 drawings ) , 123 , 123 testing samples ( 123 drawings ) .
see gure 123
jittered - cluttered set : 123 classes ( including one back - ground class ) , random perturbation , highly cluttered background images at random disparities , and ran - domly placed distractor objects around the periphery .
123 , 123 training samples ( 123 drawings ) , 123 , 123 test - ing samples ( 123 drawings ) .
see gure 123
occlusions of the central object by the distractor occur oc - casionally , as can be seen in gure 123
most experiments were performed in binocular mode ( using left and right im - ages ) , but some were performed in monocular mode .
in monocular experiments , the training set and test set were composed of all left and right images used in the corre - sponding binocular experiment .
therefore , while the num - ber of training samples was twice higher , the total amount
of training data was identical .
examples from the jittered - textured and jittered - cluttered training set are shown in g -
the following classiers were tested on raw image pairs from the normalized - uniform dataset : linear classier , k - nearest neighbor ( euclidean distance ) , pairwise support vector machines with gaussian kernels , and convolutional networks ( 123 ) .
with 123 , 123 input variables and 123 , 123 sam - ples , this dataset is at the upper limit of practicality for template - matching - based methods such as k - nn and svm ( in fact , special algorithms had to be implemented to make them practical ) .
the k - nearest neighbor and svm meth - ods were also applied to 123 - dimensional vectors of pca coefcients extracted from the 123 123 123 binocular train - ing images .
all the methods were also applied to laplacian - ltered versions of the images , but the results were uni - formly worse than with raw images and are not reported .
the convolutional network was trained and tested on the normalized - uniform dataset , as well as on the jittered - uniform and jittered - textured datasets .
the jittered training sets were much too large to be handled by the k - nn and svm methods within reasonable limits of cpu time and memory requirements .
in the following sections , we give brief descriptions of the methods employed .
all the algo - rithms were implemented with the lush environment ( 123 ) .
the svm implementation used the torch library ( 123 ) in - terfaced to lush , while the convolutional net implementa - tion used lushs gblearn123 package .
principal component analysis
computing the principal components of the dataset for the pca - based k - nn and svm was a major challenge be - cause it was impossible to manipulate ( let alone diagonal - ize ) the 123 , 123 , 123 covariance matrix ( 123 123 123
proceedings of the 123 ieee computer society conference on computer vision and pattern recognition ( cvpr123 ) 123 - 123 / 123 $123 123 ieee
figure 123
some of the 123 , 123 examples from the jittered - texturedtraining set ( top 123 rows ) , and from the jittered - clutteredtraining set ( bottom 123 rows ) .
( left camera images ) .
( xi u ) 123 , ( xi + u ) 123
squared ) .
fortunately , following ( 123 ) , we can compute the principal direction of a centered cloud of points ( xi ) by nding two cluster centroids that are symmetric with re - spect to the origin : we must nd a vector u that mini - .
a quick solution is obtained with online ( stochastic ) algorithms as discussed in ( 123 ) in the context of the k - means algorithm .
repeated ap - plications of this method , with projections on the comple - mentary space spanned by the previously obtained direc - tions , yield the rst 123 principal components in a few cpu hours .
the rst 123 components thus obtained ( the left cam - era portion ) are shown in gure 123
the rst 123 principal components were used in the experiments .
k - nearest neighbors ( with euclidean dis -
because running the k - nearest neighbors algorithm with 123 , 123 reference images in dimension 123 , 123 is pro - hibitively expensive , we precomputed the distances of a few representative images ak to all the other refer - ence images xi .
by triangular inequality , the distances be - tween a query image x and all the reference image xi is bounded below by maxk |d ( x , ak ) d ( ak , xi ) | .
these can be used to choose which distances should be com -
puted rst , and to avoid computing distances that are known to be higher than those of the currently selected ref - erence points ( 123 ) .
experiments were conducted for val - ues of k up to 123 , but the best results were obtained for k = 123
we also applied k - nn to the 123 - dimensional pca - derived feature vectors .
pairwise support vector machine ( svm )
we applied the svm method with gaussian kernels to the raw images of the normalized - uniform dataset , but failed to obtain convergence in manageable time due to the overwhelming dimension , the number of training sam - ples , and the task complexity .
we resorted to using the 123 - dimensional , pca - derived feature vectors , as well as sub - sampled , monocular versions of the images at 123 pixels and 123 resolutions .
ten svms were independently trained to classify one class versus one other class ( pairwise classiers ) .
this greatly reduces the number of samples that must be ex - amined by each svm over the more traditional approach of classifying one class versus all others .
during test - ing , the sample is sent to all 123 classiers .
each classier votes for one of its attributed categories .
the cate - gory with the largest number of votes wins .
the num - ber of support vectors per classier were between 123 and
proceedings of the 123 ieee computer society conference on computer vision and pattern recognition ( cvpr123 ) 123 - 123 / 123 $123 123 ieee
layers of trainable convolutions and spatial subsampling in - terspersed with sigmoid non - linearities to extract features of increasingly large receptive elds , increasing complex - ity , and increasing robustness to irrelevant variabilities of
a six - layer net , shown in gure 123 , was used in the exper - iments reported here .
the layers are respectively named c123 , s123 , c123 , s123 , c123 , and output .
the c letter indicates a convo - lutional layer , and the s layer a subsampling layer .
c123 has 123 feature maps and uses 123 convolution kernels .
the rst 123 maps take input from the left image , the next two from the right image , and the last 123 from both .
s123 is a 123 sub - sampling layer .
c123 has 123 feature maps that use 123 convo - lution kernels of size 123
each c123 map takes input from 123 monocular maps and 123 binocular maps on s123 , each with a different combination .
s123 is a 123 subsampling layer .
c123 has a variable number of maps ( 123 and 123 in the reported results ) that combine inputs from all map in s123 through 123 kernels .
finally the output layer takes inputs from all c123 maps .
the network has a total of 123 , 123 trainable pa - rameters .
a full propagation through the network requires
the network was trained to minimize the mean squared error with a set of target outputs .
for 123 - class recognition tasks , we used a traditional place code ( one unit active , the other inactive ) , for 123 - class detection / recognition tasks , we added a 123 - th target conguration with all output units inac - tive for the background class ( no object in the center of the
we used a stochastic version of
marquardt algorithm with diagonal approximation of the hessian ( 123 ) , for approximately 123 , 123 online updates .
no signicant over - training was observed , and no early stop - ping was performed .
for experiments with monocular age , or vice versa with equal probability .
image was duplicated into the right
results and discussion
results on the normalized - uniform and
the results are shown in table 123
to our knowledge , these are the rst systematic experiments that apply machine learning to shape - based generic object recognition with in - variance to pose and lighting .
these results are intended as a baseline for future work with the norb datasets .
the rst section of the table gives results on the normalized - uniform database , a somewhat unrealistic set - ting that assumes that objects can be isolated from their surroundings and have been size - normalized prior to recog -
the biggest surprise is that brute - force nearest neigh - bor with euclidean distance on raw pixels works at all , de - spite the complex variabilities in the data ( see lines 123 and 123 in the table ) .
naturally , the classication is horribly ex - pensive in memory and cpu time .
another important lesson is that gaussian svm becomes impractical with very large and complex datasets such as norb .
the gaussian svm architecture consists of a layer
figure 123
the average image and the rst 123 principal eigenvectors of the normalized - uniformtraining set ( only the left camera por - tions of the vectors are shown ) .
conv net 123 conv net 123
conv net 123 conv net 123 conv net 123
conv net 123
indicates raw monocular
table 123
recognition results .
raw 123x123x123 ages , pca - 123 indicates a vector of 123 pca - derived features .
norm - unif refers to the normalized - uniform dataset , jitt - unif to the jittered - uniform dataset , jitt - text to the jittered - textured dataset , and jitt - clutt to the jittered - cluttered dataset .
123 on pca - derived inputs ( roughly 123 123 ops to clas - sify one sample ) , and between 123 and 123 on 123 raw images ( roughly 123 123 ops to classify one sam - ple ) .
svms could not be trained on the jittered datasets because of the prohibitive size of the training set .
convolutional network
convolutional networks ( 123 ) have been used with great success in various image recognition applications , such as handwriting recognition and face detection .
the reader is refered to the above reference for a general discussion of convolutional nets .
convolutional nets use a succession of
proceedings of the 123 ieee computer society conference on computer vision and pattern recognition ( cvpr123 ) 123 - 123 / 123 $123 123 ieee
of template matchers , whose prototypes are a subset of the training samples ( i . e .
a gaussian bump is placed around each training sample ) , followed by a layer of linear com - binations with learned weights .
since the supervised learn - ing only takes place in the linear layer , the objective func - tion can be made convex ( quadratic with box constraints in the case of traditional svms ) .
in fact , an often - stated ad - vantage of svms is the convexity of their objective func - tion .
that property seems to be of little help in our case be - cause of the difculty of the task ( which increases the num - ber of support vectors ) , the large number of training sam - ples , and the fact that the size of the quadratic program to be solved grows with the square of the number of training samples .
we did not obtain convergence on the raw binoc - ular data after several days of cpu time using one of the fastest known implementations of svms ( from the torch package ( 123 ) ) .
experiments with reduced resolution monoc - ular images yielded decent results around 123% ( see lines 123 and 123 in table 123 ) .
working from the pca features yielded similar results ( see line 123 ) .
unfortunately , those complexity reductions were still in - sufcient to allow us experiments with the much larger jittered - textured and jittered - cluttered trainings set .
the per - formance of svms on the jittered test set after training on the unjittered training set was predictably abysmal ( 123% error on pca features and 123% on raw 123 ) pca - derived features , which has met with some success in face recognition , only brought marginal improvements over us - ing raw pixels with k - nn ( from 123 to 123% error ) , and no improvement with svm .
one should not be misled by the surprisingly good per - formance of template - based methods on the normalized - uniform dataset .
this dataset is unrealistically favorable to template - based methods because the lighting conditions are in small numbers ( 123 ) and are exactly identical in the train - ing set and the test set .
furthermore , the perfectly uniform backgrounds , perfect object registration , and perfect size normalization are not likely to be possible in realistic ob - ject recognition settings .
on the normalized - uniform set , convolutional nets reached error rates below 123% with binocular inputs ( lines 123 , and 123 ) .
the error rate was only mildly affected by jit - tering the training and test samples ( 123% versus 123% for non - jittered ) .
the size of the jittered database was too large to carry out experiments with the template - based meth - ods that would result in meaningful comparisons .
results on the jittered - textured and jittered -
the most challenging task by far was the jittered - cluttered dataset , and the less challenging jittered - textured dataset , where the classier must simultaneously de - tect and recognize objects .
the shear size and complex - ity of these datasets place them above the practical limits of template - based methods , therefore we only report re - sults with convolutional nets ( lines 123x and 123x ) .
a test error rate of 123% on the 123 classes ( 123 objects plus background ) was obtained on the jittered - textured dataset .
a large proportion of errors were objects classied as back -
table 123
confusion matrix on the test set for the binocular convolutional net on the jittered - cluttered database ( line 123 in the re - sults table ) .
each row indicates the probabil - ity that the system will classify an object of the given category into each of the 123 cate - gories .
most errors are false negatives ( ob - jects classied as junk ) , or cars being classi - ed as trucks .
ground , and cars and space shuttles classied as trucks .
a test error rate of 123% was obtained on the highly challeng - ing jittered - cluttered dataset in binocular mode .
an exam - ple of the internal state of this network is shown in gure 123
typical examples of images from the test set and the corre - sponding answers produced by the system are shown in g -
one signicant surprise is the comparatively poor perfor - mance of convolutional net on the jittered - cluttered dataset with monocular inputs ( line 123 ) : the error rate is 123% compared with 123% for binocular inputs .
this suggests that the binocular network is able to take advantage of the disparity information to help locate the outline of the object and disambiguate the segmentation / classication .
in fact , it can be observed on gure 123 that the last 123 feature maps in the rst and second layers , which take inputs from both cameras , seem to be estimating features akin to disparity .
conclusion and outlook
an important goal of this work is to point out the lim - itations of popular template - based approaches ( including svms ) for classication over very large datasets with com - plex variabilities .
our results emphasize the crucial impor - tance of trainable local feature extractors for robust and in -
a real - time portable demo system was implemented us - ing usb cameras connected to a laptop computer .
convo - lutional nets can be scanned over large images very ef - ciently ( 123 ) .
taking advantage of this property , the network is scanned over input images at multiple scales producing likelihood maps for each category .
the system can spot and recognize animals , human gures , planes , cars and trucks in natural scenes with high accuracy at a rate of several frames per second .
by presenting the input image at mul - tiple scales , the system can detect those objects over a wide range of scales .
examples of output of this system with nat - ural images are shown in gure 123
this gure was gener - ated using the monocular convolutional net trained on the jitterd - cluttered database ( line 123 on the results table )
proceedings of the 123 ieee computer society conference on computer vision and pattern recognition ( cvpr123 ) 123 - 123 / 123 $123 123 ieee
figure 123
examples of results on natural images .
the list of objects found by the monocular convo - lutional net is displayed above each sample .
though the raw performance of this network on the database was quite poor , and despite the fact that it was trained only with semi - articial data , the system can spot most objects in the scenes .
the network is applied to the image at two dif - ferent scales , and is scanned over multiple positions at the large scale .
the scores for each class at all scales and posi - tions are combined to produce an overall likelihood of nd - ing an object of the class anywhere in the image .
the list of classes whose likelihood exceeds a threshold are shown above each image in the gure .
the gray level of the la - bel word is indicative of the likelihood .
the norb dataset opens the door to large - scale exper - iments with learning - based approaches to invariant object recognition .
this is the rst installment in what promises to be a long series of works on the subject .
future work will use trainable classiers that incorporate explicit models of image formation and geometry .
acknowledgments we thank margarita osadchy , and david jacobs for useful comments .
this work was sup - ported by nsf under itr grant ccr - 123
