we present a globally convergent method for regularized risk minimization prob - lems .
our method applies to support vector estimation , regression , gaussian processes , and any other regularized risk minimization setting which leads to a convex optimization problem .
svmperf can be shown to be a special case of our approach .
in addition to the unied framework we present tight convergence bounds , which show that our algorithm converges in o ( 123 / ) steps to precision for general convex problems and in o ( log ( 123 / ) ) steps for continuously differen - tiable problems .
we demonstrate in experiments the performance of our approach .
in recent years optimization methods for convex models have seen signicant progress .
starting from the active set methods described by vapnik ( 123 ) increasingly sophisticated algorithms for solv - ing regularized risk minimization problems have been developed .
some of the most exciting recent developments are svmperf ( 123 ) and the pegasos gradient descent solver ( 123 ) .
the former computes gradients of the current solution at every step and adds those to the optimization problem .
joachims ( 123 ) prove an o ( 123 / 123 ) rate of convergence .
for pegasos shalev - shwartz et al .
( 123 ) prove an o ( 123 / ) rate of convergence , which suggests that pegasos should be much more suitable for optimization .
in this paper we extend the ideas of svmperf to general convex optimization problems and a much wider class of regularizers .
in addition to this , we present a formulation which does not require the solution of a quadratic program whilst in practice enjoying the same rate of convergence as algorithms of the svmperf family .
our error analysis shows that the rates achieved by this algorithm are considerably better than what was previously known for svmperf , namely the algorithm enjoys o ( 123 / ) convergence and o ( log ( 123 / ) ) convergence , whenever the loss is sufciently smooth .
an important feature of our algorithm is that it automatically takes advantage of smoothness in the our work builds on ( 123 ) , which describes the basic extension of svmperf to general convex prob - lems .
the current paper provides a ) signicantly improved performance bounds which match better what can be observed in practice and which apply to a wide range of regularization terms , b ) a vari - ant of the algorithm which does not require quadratic programming , yet enjoys the same fast rates of convergence , and c ) experimental data comparing the speed of our solver to pegasos and svmperf .
due to space constraints we relegate the proofs to an technical report ( 123 ) .
123 problem setting
denote by x x and y y patterns and labels respectively and let l ( x , y , w ) be a loss function which is convex in w w , where either w = rd ( linear classier ) , or w is a reproducing kernel hilbert space for kernel methods .
given a set of m training patterns ( xi , yi ) m i=123 the regularized risk
functional which many estimation methods strive to minimize can be written as
j ( w ) : = remp ( w ) + ( w ) where remp ( w ) : =
l ( xi , yi , w ) .
123 ( cid : 123 ) w ( cid : 123 ) 123 , and > 123 is a regularization term .
typically ( w ) is a smooth convex regularizer such as 123 is cheap to compute and to minimize whereas the empirical risk term remp ( w ) is computationally expensive to deal with .
for instance , in the case of intractable graphical models it requires approx - imate inference methods such as sampling or semidenite programming .
to make matters worse the number of training observations m may be huge .
we assume that the empirical risk remp ( w ) is
if j is differentiable we can use standard quasi - newtons methods like lbfgs even for large values of m ( 123 ) .
unfortunately , it is not straightforward to extend these algorithms to optimize a non - smooth objective .
in such cases one has to resort to bundle methods ( 123 ) , which are based on the following elementary observation : for con - vex functions a rst order taylor approximation is a lower bound .
so is the maximum over a set of taylor approximations .
further - more , the taylor approximation is exact at the point of expansion .
the idea is to replace remp ( w ) by these lower bounds and to opti - mize the latter in conjunction with ( w ) .
figure 123 gives geometric intuition .
in the remainder of the paper we will show that 123 ) this ex - tends a number of existing algorithms; 123 ) this method enjoys good rates of convergence; and 123 ) it works well in practice .
figure 123 : a lower bound on the convex empirical risk remp ( w ) obtained by computing three tan - gents on the entire function .
note that there is no need for remp ( w ) to decompose into individual losses in an additive fashion .
for instance , scores , such as precision@k ( 123 ) , or svm ranking scores do not satisfy this property .
likewise , estimation problems which allow for an unregularized common constant offset or adaptive margin settings using the - trick fall into this category .
the only difference is that in those cases the derivative of remp ( w ) with respect to w no more decomposes trivially into a sum of gradients .
123 bundle methods
123 subdifferential and subgradient
before we describe the bundle method , it is necessary to clarify a key technical point .
the subgradi - ent is a generalization of gradients appropriate for convex functions , including those which are not necessarily smooth .
suppose w is a point where a convex function f is nite .
then a subgradi - ent is the normal vector of any tangential supporting hyperplane of f at w .
formally is called a subgradient of f at w if , and only if ,
f ( w ( cid : 123 ) ) f ( w ) + ( cid : 123 ) w ( cid : 123 ) w , ( cid : 123 )
the set of all subgradients at a point is called the subdifferential , and is denoted by wf ( w ) .
if this set is not empty then f is said to be subdifferentiable at w .
on the other hand , if this set is a singleton then , the function is said to be differentiable at w .
123 the algorithm denote by wt w the values of w which are obtained by successive steps of our method , let at w , bt r , and set w123 = 123 , a123 = 123 , b123 = 123
then , the taylor expansion coefcients of remp ( wt ) can be written as
at+123 : = wremp ( wt ) and bt+123 : = remp ( wt ) ( cid : 123 ) at+123 , wt ( cid : 123 ) .
note that we do not require remp to be differentiable : if remp is not differentiable at wt we simply choose any element of the subdifferential as at+123
since each taylor approximation is a lower bound , we may take their maximum to obtain that remp ( w ) maxt ( cid : 123 ) at , w ( cid : 123 ) + bt .
moreover , by
algorithm 123 bundle method ( )
initialize t = 123 , w123 = 123 , a123 = 123 , b123 = 123 , and j123 ( w ) = ( w )
find minimizer wt : = argminw jt ( w ) compute gradient at+123 and offset bt+123
increment t t + 123
virtue of the fact that remp is a non - negative function we can write the following lower bounds on remp and j respectively :
rt ( w ) : = max
( cid : 123 ) at ( cid : 123 ) , w ( cid : 123 ) + bt ( cid : 123 ) and jt ( w ) : = ( w ) + rt ( w ) .
by construction rt ( cid : 123 ) rt remp and jt ( cid : 123 ) jt j for all t ( cid : 123 ) t
w : = argmin
wt : = argmin
t : = jt+123 ( wt ) jt ( wt ) , t : = min
the following lemma establishes some useful properties of t and t .
lemma 123 we have jt ( cid : 123 ) ( wt ( cid : 123 ) ) jt ( wt ) j ( w ) j ( wt ) = jt+123 ( wt ) for all t ( cid : 123 ) t .
furthermore , t is monotonically decreasing with t t+123 jt+123 ( wt+123 ) jt ( wt ) 123
also , t upper bounds the distance from optimality via t t mint ( cid : 123 ) t j ( wt ( cid : 123 ) ) j ( w ) .
123 dual problem
optimization is often considerably easier in the dual space .
in fact , we will show that we need not know ( w ) at all , instead it is sufcient to work with its fenchel - legendre dual ( ) : = supw ( cid : 123 ) w , ( cid : 123 ) ( w ) .
if is a so - called legendre function ( e . g .
123 ) the w at which the supremum is attained can be written as w = ( ) .
in the sequel we will always assume that is twice differentiable and legendre .
examples include ( ) = 123 theorem 123 let rt , denote by a = ( a123 , .
, at ) the matrix whose columns are the ( sub ) gradients , let b = ( b123 , .
the dual problem of
123 ( cid : 123 ) ( cid : 123 ) 123 or ( ) = ( cid : 123 )
( cid : 123 ) at ( cid : 123 ) , w ( cid : 123 ) + bt ( cid : 123 ) + ( w ) is
jt ( w ) : = max t ( ) : = ( 123a ) + ( cid : 123 ) b subject to 123 and ( cid : 123 ) ( cid : 123 ) 123 = 123
furthermore , the optimal wt and t are related by the dual connection wt = ( 123at ) .
123 the fenchel - legendre dual is given by ( ) = 123
recall that for ( w ) = 123 commonly used in svms and gaussian processes .
the following corollary is immediate : corollary 123 dene q : = a ( cid : 123 ) a , minimizew max ( 123 , maxt ( cid : 123 ) t ( cid : 123 ) at ( cid : 123 ) , w ( cid : 123 ) + bt ( cid : 123 ) ) +
: = ( cid : 123 ) au , av ( cid : 123 ) .
for quadratic regularization ,
123 the dual becomes
this is
123 ( cid : 123 ) q + ( cid : 123 ) b subject to 123 and ( cid : 123 ) ( cid : 123 ) 123 = 123
this means that for quadratic regularization the dual optimization problem is a quadratic program where the number of variables equals the number of gradients computed previously .
since t is typically in the order of 123s to 123s , the resulting qp is very cheap to solve .
in fact , we dont even need to know the gradients explicitly .
all that is required to dene the qp are the inner products between gradient vectors ( cid : 123 ) au , av ( cid : 123 ) .
later in this section we propose a variant which does away with the quadratic program altogether while preserving most of the appealing convergence properties of
structured estimation many estimation problems ( 123 , 123 ) can be written in terms of a piecewise linear loss function
l ( x , y , w ) = max
( cid : 123 ) ( x , y ( cid : 123 ) ) ( x , y ) , w ( cid : 123 ) + ( y , y ( cid : 123 ) )
for some suitable joint feature map , and a loss function ( y , y ( cid : 123 ) ) .
it follows from section 123 that a subdifferential of ( 123 ) is given by wl ( x , y , w ) = ( x , y ) ( x , y ) where y : = argmax
( cid : 123 ) ( x , y ( cid : 123 ) ) ( x , y ) , w ( cid : 123 ) + ( y , y ( cid : 123 ) ) .
since remp is dened as a summation of loss terms , this allows us to apply algorithm 123 directly for risk minimization : at every iteration t we nd all maximal constraint violators for each ( xi , yi ) pair and compute the composite gradient vector .
this vector is then added to the convex program we have so far .
joachims ( 123 ) pointed out this idea for the special case of ( x , y ) = y ( x ) and y ( 123 ) , that is , binary loss .
effectively , by dening a joint feature map as the sum over individual feature maps and by dening a joint loss as the sum over individual losses svmperf performs exactly the same operations as we described above .
hence , for losses of type ( 123 ) our algorithm is a direct extension of svmperf to structured estimation .
exponential families one of the advantages of our setting is that it applies to any convex loss function , as long as there is an efcient way of computing the gradient .
that is , we can use it for cases where we are interested in modeling
p ( y|x; w ) = exp ( ( cid : 123 ) ( x , y ) , w ( cid : 123 ) g ( w|x ) ) where g ( w|x ) = log
that is , g ( w|x ) is the conditional log - partition function .
this type of losses includes settings such as gaussian process classication and conditional random fields ( 123 ) .
such settings have been studied by lee et al .
( 123 ) in conjunction with an ( cid : 123 ) 123 regularizer ( w ) = ( cid : 123 ) w ( cid : 123 ) 123 for structure discovery in graphical models .
choosing l to be the negative log - likelihood it follows that
exp ( cid : 123 ) ( x , y ( cid : 123 ) ) , w ( cid : 123 ) dy ( cid : 123 )
g ( w|xi ) ( cid : 123 ) ( xi , yi ) , w ( cid : 123 ) and wremp ( w ) =
ey ( cid : 123 ) p ( y ( cid : 123 ) |xi;w ) ( ( xi , y ( cid : 123 ) ) ) ( xi , yi ) .
this means that column generation methods are therefore directly applicable to gaussian process estimation , a problem where large scale solvers were somewhat more difcult to nd .
it also shows that adding a new model becomes a matter of dening a new loss function and its corresponding gradient , rather than having to build a full solver from scratch .
123 convergence analysis
while algorithm 123 is intuitively plausible , it remains to be shown that it has good rates of conver - gence .
in fact , past results , such as those by tsochantaridis et al .
( 123 ) suggest an o ( 123 / 123 ) rate , which would make the application infeasible in practice .
we use a duality argument similar to those put forward in ( 123 , 123 ) , both of which share key tech - niques with ( 123 ) .
the crux of our proof argument lies in showing that t t+123 jt+123 ( wt+123 ) jt ( wt ) ( see theorem 123 ) is sufciently bounded away from 123
in other words , since t bounds the distance from the optimality , at every step algorithm 123 makes sufcient progress towards the op - timum .
towards this end , we rst observe that by strong duality the values of the primal and dual problems ( 123 ) and ( 123 ) are equal at optimality .
hence , any progress in jt+123 can be computed in the next , we observe that the solution of the dual problem ( 123 ) at iteration t , denoted by t , forms a feasible set of parameters for the dual problem ( 123 ) at iteration t+123 by means of the parameterization ( t , 123 ) , i . e .
by padding t with a 123
the value of the objective function in this case equals jt ( wt ) .
to obtain a lower bound on the improvement due to jt+123 ( wt+123 ) we perform a line search along ( ( 123 ) t , ) in ( 123 ) .
the constraint ( 123 , 123 ) ensures dual feasibility .
we will bound this improvement in terms of t .
note that , in general , solving the dual problem ( 123 ) results in an increase which is larger than that obtained via the line search .
the line search is employed in the analysis only for analytic tractability .
we aim to lower - bound tt+123 in terms of t and solve the resultant difference depending on j ( w ) we will be able to prove two different convergence results .
( a ) for regularizers ( w ) for which ( cid : 123 ) ( cid : 123 ) 123 ( b ) under the above conditions , if furthermore ( cid : 123 ) ( cid : 123 ) 123
( ) ( cid : 123 ) ( cid : 123 ) h we rst experience a regime of progress wj ( w ) ( cid : 123 ) ( cid : 123 ) h , i . e .
the hessian of j is
linear in t and a subsequent slowdown to improvements which are quadratic in t .
bounded , we have linear convergence throughout .
we rst derive lower bounds on the improvement jt+123 ( wt+123 ) jt ( wt ) , then the fact that for ( b ) the bounds are better .
finally we prove the convergence rates by solving the difference equation in t .
this reasoning leads to the following theorem : theorem 123 assume that ( cid : 123 ) wremp ( w ) ( cid : 123 ) g for all w w , where w is some domain of interest
containing all wt ( cid : 123 ) for t ( cid : 123 ) t .
also assume that has bounded curvature , i . e .
let ( cid : 123 ) ( cid : 123 ) 123 for all ( cid : 123 ) 123 a where 123 and ( cid : 123 ) ( cid : 123 ) 123 123 ( cid : 123 ) .
in this case we have
123 min ( 123 , t / 123g123h ) t
123 min ( 123 , t / 123g123h ) .
t t+123 t
wj ( w ) ( cid : 123 ) ( cid : 123 ) h , then we have
if t > 123g123h / if 123g123h / t h / 123
note that the error keeps on halving initially and settles for a somewhat slower rate of convergence after that , whenever the hessian of the overall risk is bounded from above .
the reason for the difference in the convergence bound for differentiable and non - differentiable losses is that in the former case the gradient of the risk converges to 123 as we approach optimality , whereas in the former case , no such guarantees hold ( e . g .
when minimizing |x| the ( sub ) gradient does not vanish at the two facts are worthwhile noting : a ) the dual of many regularizers , e . g .
squares norm , squared ( cid : 123 ) p norm , and the entropic regularizer have bounded second derivative .
see e . g .
( 123 ) for a discussion
( ) ( cid : 123 ) ( cid : 123 ) h is not unreasonable .
b ) since the improvements
and details .
thus our condition ( cid : 123 ) ( cid : 123 ) 123
decrease with the size of t we may replace t by t in both bounds and conditions without any ill effect ( the bound only gets worse ) .
applying the previous result we obtain a convergence theorem for bundle methods .
theorem 123 assume that j ( w ) 123 for all w .
under the assumptions of theorem 123 we can give the following convergence guarantee for algorithm 123
for any < 123g123h / the algorithm converges to the desired precision after
if furthermore the hessian of j ( w ) is bounded , convergence to any h / 123 takes at most the following number of steps :
max ( cid : 123 ) 123 , h 123g123h / ( cid : 123 ) +
several observations are in order : rstly , note that the number of iterations only depends logarithmi - cally on how far the initial value j ( 123 ) is away from the optimal solution .
compare this to the result of tsochantaridis et al .
( 123 ) , where the number of iterations is linear in j ( 123 ) .
secondly , we have an o ( 123 / ) dependence in the number of iterations in the non - differentiable case .
this matches the rate of shalev - shwartz et al .
in addition to that , the convergence is o ( log ( 123 / ) ) for continuously differentiable problems .
note that whenever remp ( w ) is the average over many piecewise linear functions remp ( w ) behaves essentially like a function with bounded hessian as long as we are taking large enough steps not to notice the fact that the term is actually nonsmooth .
wj ( w ) ( cid : 123 ) ( cid : 123 ) = + ( cid : 123 ) ( cid : 123 ) 123
remark 123 for ( w ) = 123
123 ( cid : 123 ) w ( cid : 123 ) 123 the dual hessian is exactly h = 123
moreover we know that
123 w ( cid : 123 ) qw the dual is ( z ) = 123
effectively the rate of convergence of the algorithm is governed by upper bounds on the primal and dual curvature of the objective function .
this acts like a condition number of the problem for 123 z ( cid : 123 ) q123z , hence the largest eigenvalues of q and q123 ( w ) = 123 would have a signicant inuence on the convergence .
in terms of the number of iterations needed for convergence is o ( 123 ) .
in practice the iteration count does increase with , albeit not as badly as predicted .
this is likely due to the fact that the empirical risk remp ( w ) is typically rather smooth and has a certain inherent curvature which acts as a natural regularizer in addition to the regularization afforded by ( w ) .
123 a linesearch variant
the convergence analysis in theorem 123 relied on a one - dimensional line search .
algorithm 123 , however , uses a more complex quadratic program to solve the problem .
since even the simple updates promise good rates of convergence it is tempting to replace the corresponding step in the bundle update .
this can lead to considerable savings in particular for smaller problems , where the time spent in the quadratic programming solver is a substantial fraction of the total runtime .
it can be shown that jt+123 ( 123 ) = t and 123 = min ( 123 , t / ( cid : 123 ) wt + at+123 ( cid : 123 ) 123
123 ( cid : 123 ) w ( cid : 123 ) 123
note that to keep matters simple , we only consider quadratic regularization ( w ) : = 123 t+123 ( ( 123 ) t , ) is a quadratic function in , regardless of the choice of remp ( w ) .
jt+123 ( ) : = j hence a line search only needs to determine rst and second derivative as done in the proof of theorem 123
( cid : 123 ) wt + at+123 ( cid : 123 ) 123
hence the optimal value of is given by this means that we may update wt+123 = ( 123 ) wt at+123
in other words , we need not store past gradients for the update .
to obtain t note that we are computing remp ( wt ) as part of the taylor relations .
in particular , the fact that w ( cid : 123 ) a = ( cid : 123 ) w ( cid : 123 ) 123 means that the only quantity we need to cache is b ( cid : 123 ) t as an auxiliary variable rt in order to compute t efciently .
experiments show that this simplied algorithm has essentially the same convergence properties .
approximation step .
finally , rt ( wt ) is given by ( cid : 123 ) w ( cid : 123 ) a + b ( cid : 123 ) t , hence it satises the same update
jt+123 ( 123 ) = 123
in this section we show experimental results that demonstrate the merits of our algorithm and its analysis .
due to space constraints , we report results of experiments with two large datasets namely astro - physics ( astro - ph ) and reuters - ccat ( reuters - ccat ) ( 123 , 123 ) .
for a fair comparison with exist - ing solvers we use the quadratic regularizer ( w ) : = in our rst experiment , we address the rate of convergence and its dependence on the value of .
in figure 123 we plot t as a function of iterations for various values of using the qp solver at every iteration to solve the dual problem ( 123 ) to optimality .
initially , we observe super - linear convergence; this is consistent with our analysis .
surprisingly , even though theory predicts sub - linear speed of convergence for non - differentiable losses like the binary hinge loss ( see ( 123 ) ) , our solver exhibits linear rates of convergence predicted only for differentiable functions ( see ( 123 ) ) .
we conjecture that the average over many piecewise linear functions , remp ( w ) , behaves essentially like a smooth function .
as predicted , the convergence speed is inversely proportional to the value of .
123 ( cid : 123 ) w ( cid : 123 ) 123 , and the binary hinge loss .
figure 123 : we plot t as a function of the number of iterations .
note the logarithmic scale in t .
left : astro - ph; right : reuters - ccat .
figure 123 : top : objective function value as a function of time .
bottom : objective function value as a function of iterations .
left : astro - ph , right : reuters - ccat .
the black line indicates the nal value of the objective function + 123 .
in our second experiment , we compare the convergence speed of two variants of the bundle method , namely , with a qp solver in the inner loop ( which essentially boils down to svmperf ) and the line search variant which we described in section 123
we contrast these solvers with pegasos ( 123 ) in the batch setting .
following ( 123 ) we set = 123 for reuters - ccat and = 123 for astro - ph .
figure 123 depicts the evolution of the primal objective function value as a function of both cpu time as well as the number of iterations .
following shalev - shwartz et al .
( 123 ) we investigate the time required by various solvers to reduce the objective value to within 123 of the optimum .
this is depicted as a black horizontal line in our plots .
as can be seen , pegasos converges to this region quickly .
nevertheless , both variants of the bundle method converge to this value even faster ( line search is slightly slower than pegasos on astro - ph , but this is not always the case for many other large datasets we tested on ) .
note that both line search and pegasos converge to within 123 precision rather quickly , but they require a large number of iterations to converge to the optimum .
123 related research
our work is closely related to shalev - shwartz and singer ( 123 ) who prove mistake bounds for online algorithms by lower bounding the progress in the dual .
although not stated explicitly , essentially the same technique of lower bounding the dual improvement was used by tsochantaridis et al .
( 123 ) to show polynomial time convergence of the svmstruct algorithm .
the main difference however is that tsochantaridis et al .
( 123 ) only work with a quadratic objective function while the framework
proposed by shalev - shwartz and singer ( 123 ) can handle arbitrary convex functions .
in both cases , a weaker analysis led to o ( 123 / 123 ) rates of convergence for nonsmooth loss functions .
on the other hand , our results establish a o ( 123 / ) rate for nonsmooth loss functions and o ( log ( 123 / ) ) rates for smooth loss functions under mild technical assumptions .
another related work is svmperf ( 123 ) which solves the svm estimation problem in linear time .
svmperf nds a solution with accuracy in o ( md / ( 123 ) ) time , where the m training patterns xi rd .
this bound was improved by shalev - shwartz et al .
( 123 ) to o ( 123 / ) for obtaining an accuracy of with condence 123 .
their algorithm , pegasos , essentially performs stochastic
( sub ) gradient descent but projects the solution back onto the l123 ball of radius 123 / .
but , as our experiments show , performing an exact line search in the dual leads to a faster decrease in the value of primal objective .
note that pegasos also can be used in an online setting .
this , however , only applies whenever the empirical risk decomposes into individual loss terms ( e . g .
it is not applicable to multivariate performance scores ) .
the third related strand of research considers gradient descent in the primal with a line search to choose the optimal step size , see e . g .
( 123 , section 123 . 123 ) .
under assumptions of smoothness and strong convexity that is , the objective function can be upper and lower bounded by quadratic func - tions it can be shown that gradient descent with line search will converge to an accuracy of in o ( log ( 123 / ) ) steps .
the problem here is the line search in the primal , since evaluating the regular - ized risk functional might be as expensive as computing its gradient , thus rendering a line search in the primal unattractive .
on the other hand , the dual objective is relatively simple to evaluate , thus making the line search in the dual , as performed by our algorithm , computationally feasible .
finally , we would like to point out connections to subgradient methods ( 123 ) .
these algorithms are designed for nonsmooth functions , and essentially choose an arbitrary element of the subgradient set to perform a gradient descent like update .
let ( cid : 123 ) jw ( w ) ( cid : 123 ) g , and b ( w , r ) denote a ball of radius r centered around the minimizer of j ( w ) .
by applying the analysis of nedich and bertsekas ( 123 ) to 123 ( cid : 123 ) w ( cid : 123 ) 123 , ratliff et al .
( 123 ) showed that sub - the regularized risk minimization problem with ( w ) : = gradient descent with a xed , but sufciently small , stepsize will converge linearly to b ( w , g / ) .
