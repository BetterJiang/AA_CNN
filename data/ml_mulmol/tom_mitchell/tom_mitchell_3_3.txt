most learning algorithms that are applied to text cat - egorization problems rely on a bag - of - words document representation , i . e . , each word occurring in the docu - ment is considered as a separate feature .
in this paper , we investigate the use of linguistic phrases as input fea - tures for text categorization problems .
these features are based on information extraction patterns that are generated and used by the autoslog - ts present experimental results on using such features as background knowledge for two machine learning algo - rithms on a classification task on the www .
the re - sults show that phrasal features can improve the pre - cision of learned theories at the expense of coverage .
most machine learning algorithms for text categoriza - tion represent documents as a bag of words .
typically , each word is treated as a separate feature .
for exam - ple , a html - document might be classified as the home page of a student if the word student occurs on the page .
however , student will also occur on many other pages on the www , including most pages of computer sci - ence departments .
on the other hand , a sentence like " i am a student of computer science at carnegie mel - lon university " is clearly indicative of a students home page .
it is worth noting that none of the words that ap - pear in this sentence are good predictors of a student home page , nor is any subset of these words , because all of them are quite common on pages related mellons school of computer science .
123 what makes a difference is the linguistic role that these words have in
conceived for information extraction ( riloff 123a ) , is able to provide a learner with features that capture some of the syntactic struc - ture of natural language text .
for the above input sen - tence , it extracts the following four features : i am <_> ,
123 in this sentence , the most predictive words for a student home page are i and am .
they are quite reliable features for the problem of discriminating between student pages and other departmental pages and , for this task , should not be removed by a stop list ( see also ( craven et al .
123a ) ) .
<_> is student , student of <_> , and student at <_> . 123 all four of them are highly indicative of student pages and at least three of them are quite unlikely to appear on other types of pages .
note that the last of these , student at <_> , does not match a contiguous piece of text , but is based on prepositional attachment to the word student .
in previous work ( e . g . ,
( riloff & lorenzen 123 ) ) , promising results on the usefulness of such phrases for tasks were obtained using simple thresholding methods to find the best classi - terms .
in this paper , we report on some exper - the utility of such iments that aimed at investigating phrases as features learning algorithms , namely the naive bayes classifier rainbow and the separate - and - conquer algorithm i ~ ipper .
the case study is performed in a
for two state - of - the - art
task on the www .
generating phrasal features
autoslog was developed as a method for automati - cally constructing domain - specific extraction patterns corpus .
as input , au - from an annotated toslog requires a set of noun phrases , formation that should be extracted from the training then uses syntactic heuristics to create linguistic patterns that can extract the desired information from the training documents ( and from un - seen documents ) .
the extracted patterns resent subject - verb or verb - direct - object ( e . g . , <subject> teaches or teaches <direct - object> ) as well as prepositional phrase attachments ( e . g . , at <noun - phrase> or teacher at <noun - phrase> ) .
see ( riloff 123b ) for a more detailed description of au -
the key difference
between autoslog and the removal of the
need for an annotated for all noun simply generates extraction phrases in the training corpus whose syntactic matches one of the heuristics .
table 123 shows three of the 123 syntactic heuristics employed in the current
123we use angle brackets <> to represent
<sub j> aux - verb noun noun prep <noun - phrase>
i am <_> <_> is student student of <_> student at <_>
table h syntactic heuristics that are used for finding phrasal features in the sentence " i am a student of com - puter science at carnegie mellon university . "
of words occurring in documents of that
class independent of their context .
by doing so , rain - bow makes the naive independence assumption .
more the probability of document d belonging to class c is estimated by multiplying the prior probability pr ( c ) of class c with the product of the probabilities pr ( wiic ) that the word wi occurs in documents of this class .
this product is then normalized by the product of the prior probabilities pr ( wi ) of all words .
that can be detected
version of autoslog - ts as well as their correspond - ing extraction patterns example sentence " i am a student of computer science at carnegie mellon university " .
note that the third twice in the same syntactic heuristic of table 123 fires sentence using two different prepositional attachments forms of the to the noun student .
also , the different verb to be are not discerned for the first however , in general words that occur in different forms will not be treated in the same way .
for example , the sentence " here are the students at our department " will not match the last extraction pattern of table 123 , because the word student occurs in plural that the plural version stu - dents at <_> occurs more frequently on departmental pages than on student home pages .
that such small differences in the use of words can make a big difference for text classification was previously observed in ( riloff 123 ) .
a set of experiments demonstrated occurrence or absence of linguistic phrases of the above form can be successfully used for recognizing relevant documents of the terrorist domain of the 123th message understanding conference ( muc - 123 ) ( riloff & lorenzen 123 ) .
it seems likely
in this paper , we explore the potential use of the generated by autoslog - ts as phrasal features for state - of - the - art in the following , we will briefly describe the learning al - gorithms and the test domain ( classifying www pages related to computer science departments ) , and then dis - cuss the results of our experiments .
features with two
the use of phrasal
the naive bayes classi - fier rainbow and the rule learning algorithm rip - per .
the data set used for our experiments is the 123 - universities dataset , which has been collected for the webkb project at carnegie mellon university .
mccallum at cmu123
it estimates a document is a member of a certain class using the
is a naive bayes classifier tasks ( mitchell 123 ) , developed by andrew
for text classi -
from http : / / www .
edu / af s / cs /
pr ( cld ) : = pr ( c )
as many of the probabilities
pr ( wi ( c ) are typi -
cally 123 ( hence their product will be 123 ) , rainbow smoothes the estimates using the technique proposed by witten & bell ( 123 ) .
a related problem - - fact that for text classification tasks many estimates of pr ( c ( d ) for the winning class tend to be close to 123 and often will be exactly 123 because of floating - point round - off errors - - is addressed by providing an option to incorporate a correction term based on kullback - leibler divergence .
this correction does not change of the documents , but provides more realistic probability estimates .
this option was used in our experiments to obtain better confidence estimates for the predictions , which we used for generating re - graphs .
a more detailed description of this smoothing technique and of rainbow can be found in ( craven et al .
123a ) .
( quinlan 123 ) ) until
ripper123 ( cohen 123 ) is an efficient , noise - tolerant rule learning algorithm based on the incremental reduced error pruning algorithm ( fiirnkranz ~ widmer 123; ffirnkranz 123 ) .
it learns single rules by greedily adding one condition at a time ( using foils informa - tion gain heuristic longer makes incorrect predictions on the growing set , a randomly chosen subset of the training set .
there - the learned rule is simplified by deleting condi - tions as long as the performance of the rule does not decrease on the remaining set of examples ( the pruning set ) .
all examples covered by the resulting rule are then removed from the training set and a new rule is learned in the same way until all examples are covered by at least one rule .
thus , ripper is a member of the fam - ily of separate - and - conquer ( or covering ) rule learning algorithms ( fiirnkranz 123 ) .
what makes ripper particularly well - suited for text categorization problems is its ability to use set - valued features ( cohen 123 ) .
for conventional machine learn - ing algorithms , a document is typically represented as a set of binary features , each encoding the presence or absence of a particular word in that document .
this results in a very inefficient encoding of the training ex - amples because much space is wasted for specifying the
project / theo - 123 i / www / naive - bayes
table 123 : class distribution
in the 123 universities data
absence of words in a document .
ripper allows to rep - resent a document as a single set - valued feature simply lists all the words occurring in the text .
con - ceptually , rippers use of such a set - valued feature is than the use of binary features in conven - learning algorithms , although ripper makes use of some optimizations .
for the remainder of this paper , we will continue to think of each word ( or phrase ) as separate binary feature .
the webkb project the goal of the webkb project ( craven et al .
123b ) is to extract a computer - understandable knowledge base from the www whose contents mirrors the contents of could be imagined for the www .
many applications such a knowledge base .
for example , it could enhance the capabilities of currently available search engines that can only answer word - occurrence queries ( e . g . , al - tavista ) or that rely on a manually constructed knowl - edge base about the contents of www pages ( e . g . , ya - hoo ) by enabling them to answer questions course x at university y ? " or " how many students are in department z ? " .
currently , a proto - type system uses an ontology of common entities computer science departments ( students , courses , projects , departments ) and relations between them ( e . g . , professor x is the instructor of course and the advisor of student z ) .
the prototype crawls the net and uses learned knowledge to classify pages of computer science departments into that ontology .
in order to furnish the crawler with some learned do - main knowledge , a set of 123 , 123 training documents was from the www pages of various computer science departments .
123 about half of the pages are a fairly exhaustive set of pages from the computer science departments of four universities : cornell , texas , wis - consin , and washington .
the remaining 123 , 123 pages are more or less randomly collected pages from various computer science departments .
the pages are manu - ally classified into the categories student , faculty , staff , course , project , department , and other .
table 123 shows the frequency distributions of these classes in the data
: / / www .
edu / afs / cs ,
the other class is a very heterogeneous class that contains pages found at these departments that are not classified as any of the six relevant classes .
note , how - that one of the assumptions made in manually classifying the pages was that each real - world entity is represented by only one page .
thus , if , e . g . , a fac - ulty member organizes his personal home page as a hypertext document containing separate pages for his research interests , his publications , his cv , and point - ers to the research projects he is involved in , only the top page that links these informations together would be used to represent him in the class faculty , while all other pages would be classified as other .
this is clearly not a perfect solution , as other people might organize the same information into a single page .
thus it can be expected to be hard to discriminate between cer - tain pages of the other class and pages of the relevant
a more detailed description of this data set and of some previous work can be found in ( craven et al .
for our experiments , all pages were stripped of their html tags , converted to lower case , and all digits were replaced with a d .
autosloc - ts was run on each doc - ument and the generated extraction patterns were en - coded as one - word tokens and put into a separate file .
we compared three different algorithm : one where each word was treated as a fea - ture , one where each phrase ( extraction pattern ) was treated as a feature , and one where both were consid - ered as features .
for the last case , corresponding files were simply appended to produce the input files rainbow , while for ripper we encoded each docu - ment with two set - valued features , one containing the words in the document , the other containing the tokens that represent the discovered phrasal features .
the algorithms were evaluated using the same proce - dure as in ( craven et al .
123b ) : each experiment con - sists of four runs , in which the pages of one of the four universities are left out in turn .
thus , each training set consists of the 123 , 123 pages from miscellaneous univer - sities plus the pages from three of the four universities .
the results of each of the four runs were combined us - ing micro - averaging , i . e . , the predictions made for the four test sets were thrown together and all evaluation measures were computed on this combined set .
the fre - quency distribution of the classes in this combined test set is shown in the second column of table 123
unless noted otherwise , ripper was used with its default options .
it should be noted that in this setting , ripper sorts the classes according to their inverse fre - quency and learns decision lists for discriminating one class against all classes ranked below it .
hence , the is treated as a default class and no rules are learned for it .
in the ex - periments with rainbow , we made use of its built - in stemming , and features
that occurred only once were
in our case the other class ,
table 123 : overall predictive accuracy
not considered .
the experiments with ripper were performed without stemming and without any form of feature subset selection .
language phrases and are classified
in terms of predictive accu - table 123 shows the results racy on the 123 test sets combined .
the results are quite diverse .
for rainbow , the use of phrases increases pre - dictive accuracy , while for ripper , the opposite is the case .
an investigation of the confusion matrices ( not shown ) shows that this is mostly due to an increase in the number of pages that are classified as other .
for example , about 123% of the pages do not contain any by default .
this decrease in the number of pages for which a commitment to one of the six relevant classes is made , in some sense , confirms that the phrasal fea - tures are much more conservative in their predictions : they tend to appear less frequently , but some of them are highly typical for certain classes .
this has a posi - tive effect on the overall accuracy , because rainbow using word - based features classifies only 123 pages as other , while the test set contains 123 pages of this class .
rainbow using phrasal features classifies examples as other without significantly classifiers precision in the six relevant classes .
this means that the majority of other pages is misclassified into one of the six relevant classes , thus producing a low overall accuracy and a low precision , as we will see in the next section .
the 123 minority classes .
rainbow
is converse for ripper , which classi - fies 123 pages as other using words , while classifying 123 pages as other when using only phrases .
hence , for ripper , whose classification accuracy is above the default accuracy ( 123% ) , predicting more examples other has a negative effect on its performance .
in the number of pages classified with the default class are also the main reason for the huge performance differences of the two algorithms .
one reason for this phenomenon might be the nature of of the other class , which is likely pages that are very similar it might well be the case that this problem imposes greater difficulties upon a linear classifier such as rainbow , whereas the rule learner ripper is better able to focus on the small differences between similar pages in different classes .
it might also be the case that in the experimental setup ( stemming ,
to pages of the relevant
to contain many
, % ~ . . . . . . . . . . . . . . . .
123 - - - - - -
figure 123 : combined precision / recall ( bottom ) and ripper ( top ) .
pruning of features that occur only once ) contributed to this effect , but it cannot be its sole cause , because no stemming was used on the phrasal features
more interesting , however , is a closer look at the pre - graphs shown in figure 123
in this graph , recall means the percentage of correctly predicted ex - amples of the six relevant classes ( not including other ) , while precision means the percentage of correct predic - tions in all predictions for examples of these classes .
for generating these graphs , we associated a confi - dence score with each prediction .
the confidence as - sociated with a predictions of rainbow is simply the
123 i am <_> 123 <_> is student 123 student in <_> 123 university of <_> 123 professor of <_> 123 <_> is professor 123 i am <_>
<_> is associate
123 manager of <_> 123 associated <_> 123 related <_> 123 affiliated <_> 123 department of <_> 123 undergraduate <_> 123 graduate <_> 123 <_> due 123 due <_> 123 fall <_>
table 123 : the best three phrases for each class and their rank in a sorted list of features in the words+phrases
student : - my ,
test accuracy ( washington ) : 123
student : - i am <_> ,
<_> is student , institute of <_> .
test accuracy ( texas ) :
student : - my ,
<_> is student ,
test accuracy ( texas ) :
estimated probability of the example being in the pre - dicted class .
ripper does not provide probability esti - mates , so we associated with each prediction of ripper a confidence value c_a_+_l_ where e ( i ) is the number training examples that are correctly ( incorrectly ) clas - sified by the rule that predicted the class for this exam - ple .
123 we chose the laplace - estimate for estimating the accuracy of a rule in order to penalize rules that cover only a few examples .
we measured the precision of the algorithms at 123% increments in recall .
a recall level of 123% is equivalent to correctly classifying about 123 of the 123 examples of the six relevant classes .
the precision at a recall level of n% was measured by first sorting the predictions for examples of the relevant classes according to their confidence score .
then we went down the list until number of correct predictions exceeded n% of the total number of examples of the relevant classes , i . e . , until we had recalled n% of the examples of these classes .
the number of correct predictions over the total number of predictions in that segment of the list is the precision score associated with that recall level .
if a recall of n% was reached within a series of predictions with identical confidence scores , we continued to process the list until the confidence score changed .
hence , in some cases , the points for the precision / recall curves are not exactly lined up at 123% increments .
~ note that these are not necessarily equivalent to the number of examples that are correctly or incorrectly classi - fied by the rule in isolation , because ripper learns decision lists .
this means that the learned rules are processed in order , and only examples that are not classified by previous rules can be classified by subsequent rules .
table 123 : the rules with highest confidence scores for words , phrases , and phrases+words respectively , with the number of correct and incorrect predictions they make on their respective training and test sets .
in both graphs , it is apparent that at lower recall
the phrasal features outperform the word - based representation .
this supports the hypothesis that some phrasal features are highly predictive for certain classes , but in general have low coverage .
this is particularly obvious in the significant decrease of the maximum re - call for ripper if it uses only phrasal features .
for the combined representation are more diverse : rainbow assigns higher weights to word - based features than to phrasal features , so that the results for the combined representation are mostly determined by the words .
table 123 illustrates this by showing the top three phrases for each class , and their rank in the list of features ordered by a weighted log - odds ratio
but even
based features determine the shape of the curve , the addition of phrasal features results in small improve - ments at all recall levels .
the situation is quite similar for ripper in the sense that only a few of the learned rules actually use the phrasal features .
however , the phrases frequently oc - cur in rules with a high confidence score and make a crucial difference at the low recall end of the graph .
table 123 shows , for each of the three representations , the rule that was assigned the highest confidence score based on its performance on the respective
it is very interesting to observe that the best rule for the word - based feature set and the best rule for the words+phrases representation are almost identical .
both require the presence of the word my and a seven - digit number ( most likely a phone number ) .
however , requires the pres - while the word - based representation ence of the words am and student , requires the presence of the phrase <_> is student .
recall that all documents containing sentence " i am a student . " match both conditions , be - cause the phrase matches all forms of the auxiliary verb to be .
looking at the accuracies of these two rules shows that the first one matches 123 examples in the entire data set , 123 of which being non - student pages , while the second rule matches only 123 examples , but all of them are of the class student .
bigrams vs .
phrases
" ph+ w ( rainbow )
the rule that was formed using only the phrasal fea - tures can be loosely interpreted as classifying all doc - uments that contain the sentence " i am a student at of <_> . " as student home pages .
while this rule is sensible and accurate , it has a much lower coverage than both other rules .
it is also interesting to note that the third rule con -
the redundant condition
the redundant condition student .
apparently , rippers information gain heuristic first preferred this condition over the more accurate phrase that contains the word , because the word feature had higher cover - age .
after it discovered that the phrase has to be added is not removed because rippers pruning algorithm only considers the removal of a final sequence of conditions from a rule / it should be remarked that it is no coincidence that all three rules are predicting the class student .
in fact , most of the improvements at the low recall end of the curves is due to respective improvements in the pre - diction of the student class .
precision / recall for this class look very similar to the graphs shown in figure 123 , while for the other five relevant classes no dra - matic improvements could be observed .
we have seen in table 123 that rainbow attributes a somewhat lower im - portance to phrasal features in the other 123 classes , and an investigation of the learned rules shows that only a few of the top - ranked rules for classes other than stu - dent actually use phrasal features .
this may be partly due to the fact that there are too few training examples for some of these classes .
we plan to further investigate this on a more balanced data set , like the 123 newsgroups data used in ( lang 123 ) .
two other interesting
ure 123 are the differences
to make in fig - in maximum recall between
is one of
between ripper and
original incremental reduced error pruning algorithm , which - - less efficiently - - considers all conditions as candidates for pruning ( ffirnkranz & widmer 123 ) .
awe have also investigated whether the student class contains a higher percentage of natural language text , but we could not empirically confirm this hypothesis ( using the crude measure number of phrases per class over number of words per class ) .
figure 123 : precision / recall and ripper ( bottom ) using phrases+words versus bi -
curves for rainbow
rainbow and ripper , and the consistent precision at the low recall end for rainbow .
the for - mer is due to fact that rainbow less pages as other , thus increasing the percentage of recalled pages in the relevant classes at the expense of precision .
we conjecture that the latter phenomenon is caused by vio - lations of the independence assumption of naive bayes , which leads to overly optimistic confidence scores for for example , if the phrase <_> is student occurs in a document , it is quite likely that at least one of the phrases student at / in / of <_> will oc - cur in the same sentence , which will unduly boost the that this document is a student home page .
while the results of the last section have shown that phrasal features can improve the precision of text clas - at the expense of recall , one can ask whether similar results could have been obtained by using se - quences of words instead of single words as features .
to this end , we have repeated some of the above ex - periments using a representation that considers single words and pairs of words ( bigrams ) as features .
the same phenomenon for rainbow , we observed the shape of the re - as with the use of phrases : curve is determined by the word - based features , but the precision is slightly higher .
the two curves at the bottom of figure 123 are the recall / precision curves for bigrams+words versus phrases+words for rainbow .
there are no notable differences small peak for the phrase representation at a recall level of 123% .
a comparison of the best bigram features ( ta - ble 123 ) to the best phrase features ( table 123 ) shows that the average rank of the top three features among the
123 home page 123 comput scienc 123 depart of 123 comput scienc 123 the depart 123 comput scienc 123 of comput 123 univ of 123 satoshi sekin 123 rice edu 123 in japanes 123 research group 123 audio latex 123 latex postscript 123 will be 123 offic hour 123 the cours
table 123 : the best three bigrams for each class and their rank in a sorted list of features
in the bigrams+words
student : - my ,
test accuracy ( washington ) : 123 123
table 123 : a highly ranked rule using bigrams with the number of correct and incorrect predictions it makes on training and test examples .
appear to be less sensible ( cf . , e . g . , classes staff and project ) .
is higher for bigrams , while they the features for
for ripper , however , the situation
the upper two curves of figure 123 , the phrase representa - tion outperforms the bigram representation at the low recall end .
looking at the rules that apply there , we find that , unlike the rules of table 123 , for the bigrams the rule with the highest confidence is not one of the 123 top - ranked rules of the student class in the respective folds of the 123 - fold cross - validation .
the rule shown in table 123 is most similar to the rules shown in table 123
it is ranked number 123 by our confidence measure .
words phrases bigrams 123 , 123 123 , 123 123 , 123
table 123 : number of features considered by rainbow
tures it uses is much smaller than the number features ripper considers .
it can be seen that , although there are slightly more different phrases than words , their numbers are in about the same order of magnitude , while the number of bigrams found in the documents is one order of magnitude larger .
our experiments have shown that the use of linguistic features can improve the precision of text categorization at the low recall end .
for the rule learning algorithm p ~ ipper , adding such features was able to boost the pre - cision by about 123% to more than 123% when recalling about 123% of the 123 test examples of a text catego - task on the www .
although phrasal features require more engineering effort ( e . g . , the syntax of both the training and the test documents has to be parsed ) , they seemingly provide a better focus for rule learn - ing algorithms .
this effect was less remarkable for the naive bayes classifier
that we used .
nevertheless , it should be noted that we were not able to improve the precision of the classifiers at high recall the reason being that the phrasal features typi - cally have a very narrow focus .
however , it should also be noted that the test domain used in our case study may not have been an ideal choice for evaluating utility of phrasal features , because significant parts of www pages do not contain natural thus , we plan to further evaluate commonly used text categorization as the 123 newsgroups dataset reuters newswire collection
( lang 123 ) and the ( cohen & singer 123 ) .
on the other hand , we are also working on further improving the classification accuracy on the 123 universi - ties data set used in this case study .
for example , all approaches used in this study performed very poorly on the project class ( precision was typically below 123% ) .
the reason for this is most likely the heterogeneous na - ture of topics that are dealt with on project pages .
we believe that this problem can be solved by looking at the information that is contained on or near the links that point to such pages and plan to investigate to those employed in further using techniques similar
it is worth to take a look at the number of different features that are considered by the learning al - gorithms ( table 123 ) .
recall that we used rainbow with stemming on words and bigrams , as well as pruning of all features that occur only once , so the number of fea -
123for example , one of the most characteristic words for the classes faculty and staff is the word " fax " , which is more likely to occur in addresses than in the natural lan - guage portion of a web - page .
is supported by a schrsdinger - ( j123 - inf ) of the austrian fonds zur support by the darpa
fsrderung der wissenschaftlichen hpkb program under contract ellen riloff acknowledges support from nsf grants iri - 123 and iri - 123
we wish to thank mark schmelzenbach for generating
the autoslog - ts data .
