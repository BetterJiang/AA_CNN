learning involves the ability to generalize from past expe - rience in order to deal with new situations that are related to this experience .
the inductive leaap needed to deal with new situations seems to be possible only under certain biases for choosing one generalization of the situation over another .
this paper denes precisely the notion of bias in generaliza - tion problems , then shows that biases are necessary for the inductive leap .
classes of justiable biases are considered , and the relationship between bias and domain - independence
we restrict the scope of this discussion to the problem of
generalizing from training instances , dened as follows :
the generalization problem
language of instances .
language of generalizations .
matching predicate for matching generalizations to in -
sets of positive and negative training instances .
generalization ( s ) consistent with the training instances .
as a concrete example of the above generalization prob - lem , consider the task addressed by winstons program for learning classes of block structures ( winston 123 ) .
here , the language of instances is the representation used to de - scribe example block structures .
the language of gener - alizations is the language in which learned concepts ( e . g . , arch , tower ) are described .
the matching predicate species whether a given generalization applies to a given instance ( e . g . , whether the inferred description of an arch is satised by a specic block structure ) .
this paper addresses a deep difculty with the general - ization problem as dened above : if consistency with the training instances is taken as the sole determiner of appro - priate generalizations , then a program can never make the inductive leap necessary to classify instances beyond those it has observed .
only if the program has other sources of in - formation , or biases for choosing one generalization over the
converted to electronic version by : roby joehanes , kansas state
figure 123 : relationships among instances and generaliza - tions ( this gure was missing from the original publication and added in 123 )
other , can it non - arbitrarily classify instances beyond those in the training set .
in this paper , we use the term bias to refer to any basis for choosing one generalization over another , other than strict consistency with the observed training instances .
what is an unbiased generalizer
if generalization is the problem of guessing the class of in - stances to which the positive training instances belong , then an unbiased generalizer is one that makes no a priori as - sumptions about which classes of instances are most likely , but bases all its choices on the observed data .
two com - mon sources of bias in existing learning systems are ( 123 ) the generalization language is not capable of expressing all pos - sible classes of instances , and ( 123 ) the generalization proce - dure that searches through the space of expressible general - izations is itself biased .
an unbiased generalization language in considering bias in the generalization language , it is use - ful to view each generalization as denoting the set of in - stances that it matches .
in gure 123 , for example , g123 and g123 are two generalizations expressible in some generaliza - tion language , and each matches a different subset of the
relative to a given langauge of instances , an unbiased generalization language is then one which allows describ - ing every possible subset of these instances .
in short , an
unbiased generalization language corresponds to the power set of the given instance language .
the impact of using a biased generalization language is clear : each subset of instances for which there is no express - ible generalization is a concept that could be presented to the program , but which the program will be unable to de - scribe and therefore unable to learn .
if it is possible to know ahead of time that certain subsets of instances are irrelevant , then it may be useful to leave these out of the generaliza - tion language , in order to simplify the learning problem .
for example , on features of the instance ( e . g . , ( winston 123 ) , ( buchanan & mitchell 123 ) ) introduce a strong bias of this kind , which reduces considerably the complexity of the gen -
the strength of the bias introduced by generalization lan - guages restricted to conjunctive constraints on features , is illustrated by a simple example .
consider an instance lan - guage of binary feature vectors containing 123 features , and a generalization language that allows constraining each fea - ture value to be 123 , 123 , or dont care .
some simple arith - metic shows that only about one out of every 123 subsets of instances is expressible in the generalization language .
this proportion worsens quickly as the number of features and the number of allowed values per feature increases .
an unbiased generalization procedure the generalization procedure searches for expressible gen - eralizations that denote sets of instances , each of which in - cludes all of the positive but none of the negative training in - stances .
of course , there may be many such generalizations .
in gure 123 , for instance , if the observed positive instacnes are contained in the intersection of the instance sets of g123 and g123 , and the observed negative instances are outside both sets , then both g123 and g123 are consistent with the observed
an unbiased generalization procedure is one which shows no preference for one expressible generalization over an - other , except on the basis of consistency with the training
following ( mitchell 123 ) , we dene the version space relative to a particular generalization language , and a given set of training instances , as the set of all expressible gen - eralizations consistent with the training instances .
then an unbiased generalization procedure must compute the version space relative to the observed training instances , and the pro - vided generalization language .
such a generalization proce - dure is described in ( mitchell 123 ) , and has been imple - mented as part of the meta - dendral program ( buchanan & mitchell 123 ) .
in order to consider the consequences of an unbiased gen - eralization procedure , it is necessary to consider how a com - puted version space can be used to classify subsequent in - stances as either positive or negative .
an unbiased classi - cation method classies the new instance as a positive in - stance if and only if every generalization in the version space matches it .
the instance is classied as a negative instance if and only if no generalization in the version space matches it .
if some , but not all , of the generalizations in the version space match the instance , then the instane cannot be clas -
sied with certainty .
the program could , however , give an estimated classication based upon the proportion of gener - alizations within the version space , that match and do not match the instance .
the futility of removing biases
for a generalization system to be unbiased for it to con - sider equally all possible subsets of instances as the possible identity of the class being learned it must employ an unbi - ased generalization language , and compute the version space relative to that language and the presented training instances .
although removing all biases from a generalization sys - tem may seem to be a desirable goal , in fact the result is nearly useless .
an unbiased learning systems ability to clas - sify new instances is no better than if it simply stored all the training instances and performed a lookup when asked to classify a subsequent instance .
to see that this is the case , consider the procedure de - scribed above for using the computed version space to clas - sify new instances .
for an unbiased generalization language , the new instance will match every generalization consistent with the observed instances if and only if it is identical to one of the observed positive instances .
similarly , to be classied as a negative instance , the new instance must be identical to one of the observed negative instances .
furthermore , any instance that has not yet appeared as a training instance will match exactly half the generalizations in the version space .
as a result , even the scheme described above for estimating the classication will fail to produce useful results .
in retrospect , it is not surprising that an unbiased gen - eralization system cannot make classications of instances other than the training instances .
an unbiased system is one whose inferences logically follow from the training in - stances , whereas classications of the new instances do not logically follow from the classications of the training in -
useful classes of biases
there is an important conclusion to the above discussion : if totally unbiased generalization systems are incapable of making the inductive leap to characteriza the new instances , then the power of a generalization system follows directly from its biases from decisions based on criteria other than consistency with the training instances .
therefore , progress toward understanding learning mechanisms depends upon understanding the sources of , and justication for , various biases .
this section classies certain kinds of biases that have been used by learning programs .
factual knowledge of the domain .
in learning gener - alizations for a particular purpose , it may be possible to limit the generalizations considered , by appealing to knowl - edge about the task domain .
the meta - dendral program ( buchanan & mitchell 123 ) forms general rules that char - acterize molecular bonds that fragment in a mass spectrom - eter .
here , general knowledge of the domain , such as dou - ble bonds rarely break , can be used to constrain the search for appropriate generalizations .
similarly , in a program that learns the rules of baseball ( soloway & riseman 123 ) ,
unbiased generalization programs that use consistency with the training instances as their only source of information , cannot outperform programs that use rote learning .
addi - tional information or biases are therefore critical to the abil - ity to classify instances that are not identical to the training instances .
this fact has signicant implications for research on machine learning .
if biases and initial knowledge are at the heart of the abil - ity to generalize beyond observed data , then efforts to study machine learning must focus on the combined use prior knowledge , biases , and observation in guiding the learning process .
it would be wise to make the biases and their use in controlling learning just as explicit as past research has made the observations and their use .
the following people have provided thoughtful comments on various drafts of this paper , and have contributed their own ideas : saul amarel , george drastal , n . s .
sridharan , and paul utgoff .
this work was supported by nih grant rr - 123 - 123 , and by an award from the rutgers research coun -
