we consider the problem of zero - shot learning , where the goal is to learn a clas - sier f : x y that must predict novel values of y that were omitted from the training set .
to achieve this , we dene the notion of a semantic output code classier ( soc ) which utilizes a knowledge base of semantic properties of y to extrapolate to novel classes .
we provide a formalism for this type of classier and study its theoretical properties in a pac framework , showing conditions un - der which the classier can accurately predict novel classes .
as a case study , we build a soc classier for a neural decoding task and show that it can often predict words that people are thinking about from functional magnetic resonance images ( fmri ) of their neural activity , even without training examples for those words .
machine learning algorithms have been successfully applied to learning classiers in many domains such as computer vision , fraud detection , and brain image analysis .
typically , classiers are trained to approximate a target function f : x y , given a set of labeled training data that includes all possible values for y , and sometimes additional unlabeled training data .
little research has been performed on zero - shot learning , where the possible values for the class variable y include values that have been omitted from the training examples .
this is an important problem setting , especially in domains where y can take on many values , and the cost of obtaining labeled examples for all values is high .
one obvious example is computer vision , where there are tens of thousands of objects which we might want a computer to recognize .
another example is in neural activity decoding , where the goal is to determine the word or object a person is thinking about by observing an image of that persons neural activity .
it is intractable to collect neural training images for every possible word in english , so to build a practical neural decoder we must have a way to extrapolate to recognizing words beyond those in the training set .
this problem is similar to the challenges of automatic speech recognition , where it is desirable to recognize words without explicitly including them during classier training .
to achieve vocabulary independence , speech recognition systems typically employ a phoneme - based recognition strategy ( waibel , 123 ) .
phonemes are the component parts which can be combined to construct the words of a language .
speech recognition systems succeed by leveraging a relatively small set of phoneme
recognizers in conjunction with a large knowledge base representing words as combinations of to apply a similar approach to neural activity decoding , we must discover how to infer the compo - nent parts of a words meaning from neural activity .
while there is no clear consensus as to how the brain encodes semantic information ( plaut , 123 ) , there are several proposed representations that might serve as a knowledge base of neural activity , thus enabling a neural decoder to recognize a large set of possible words , even when those words are omitted from a training set .
the general question this paper asks is :
given a semantic encoding of a large set of concept classes , can we build a classier to recognize classes that were omitted from the training set ? we provide a formal framework for addressing this question and a concrete example for the task of neural activity decoding .
we show it is possible to build a classier that can recognize words a person is thinking about , even without training examples for those particular words .
123 related work
the problem of zero - shot learning has received little attention in the machine learning community .
some work by larochelle et al .
( 123 ) on zero - data learning has shown the ability to predict novel classes of digits that were omitted from a training set .
in computer vision , techniques for sharing features across object classes have been investigated ( torralba & murphy , 123; bart & ullman , 123 ) but relatively little work has focused on recognizing entirely novel classes , with the exception of lampert et al .
( 123 ) predicting visual properties of new objects and farhadi et al .
( 123 ) using visual property predictions for object recognition .
in the neural imaging community , kay et al .
( 123 ) has shown the ability to decode ( from visual cortex activity ) which novel visual scenes a person is viewing from a large set of possible images , but without recognizing the image content per se .
the work most similar to our own is mitchell ( 123 ) .
they use semantic features derived from corpus statistics to generate a neural activity pattern for any noun in english .
in our work , by contrast , we focus on word decoding , where given a novel neural image , we wish to predict the word from a large set of possible words .
we also consider semantic features that are derived from human labeling in addition to corpus statistics .
further , we introduce a formalism for a zero - shot learner and provide theoretical guarantees on its ability to recognize novel classes omitted from a
123 classication with semantic knowledge
in this section we formalize the notion of a zero - shot learner that uses semantic knowledge to extrap - olate to novel classes .
while a zero - shot learner could take many forms , we present one such model that utilizes an intermediate set of features derived from a semantic knowledge base .
intuitively , our goal is to treat each class not as simply an atomic label , but instead represent it using a vector of semantic features characterizing a large number of possible classes .
our models will learn the relationship between input data and the semantic features .
they will use this learned relationship in a two step prediction procedure to recover the class label for novel input data .
given new input data , the models will predict a set of semantic features corresponding to that input , and then nd the class in the knowledge base that best matches that set of predicted features .
signicantly , this procedure will even work for input data from a novel class if that class is included in the semantic knowledge base ( i . e .
even if no input space representation is available for the class , but a feature encoding of it exists in the semantic knowledge base ) .
denition 123
semantic feature space a semantic feature space of p dimensions is a metric space in which each of the p dimensions encodes the value of a semantic property .
these properties may be categorical in nature or may contain real - valued data .
as an example , consider a semantic space for describing high - level properties of animals .
in this example , well consider a small space with only p = 123 dimensions .
each dimension encodes a is it furry ? does it have a tail ? can it breathe underwater ? is it carnivorous ? is it slow moving ? in this semantic feature space , the prototypical concept of dog might be represented as the point ( 123 , 123 , 123 , 123 , 123 ) .
denition 123
semantic knowledge base a semantic knowledge base k of m examples is a collection of pairs ( f , y ) 123 : m such that f f p is a point in a p dimensional semantic space f p and y y is a class label from a set y .
we assume a one - to - one encoding between class labels and points in the semantic feature space .
a knowledge base of animals would contain the semantic encoding and label for many animals .
denition 123
semantic output code classier a semantic output code classier h : x d y maps points from some d dimensional raw - input space x d to a label from a set y such that h is the composition of two other functions , s and l ,
h = l ( s ( ) ) : x d f p l : f p y
this model of a zero - shot classier rst maps from a d dimensional raw - input space x d into a semantic space of p dimensions f p , and then maps this semantic encoding to a class label .
for example , we may imagine some raw - input features from a digital image of a dog rst mapped into the semantic encoding of a dog described earlier , which is then mapped to the class label dog .
as a result , our class labels can be thought of as a semantic output code , similar in spirit to the error - correcting output codes of dietterich and bakiri ( 123 ) .
as part of its training input , this classier is given a set of n examples d that consists of pairs ( x , y ) 123 : n such that x x d and y y .
the classier is also given a knowledge base k of m examples that is a collection of pairs ( f , y ) 123 : m such that f f p and y y .
typically , m >> n , meaning that data in semantic space is available for many more class labels than in the raw - input a semantic output code classier can be useful when the knowledge base k covers more of the possible values for y than are covered by the input data d .
to learn the mapping s , the classier rst builds a new set of n examples ( x , f ) 123 : n by replacing each y with the respective semantic encoding f according to its knowledge base k .
the intuition behind using this two - stage process is that the classier may be able to learn the relationship between the raw - input space and the individual dimensions of the semantic feature space from a relatively small number of training examples in the input space .
when a new example is presented , the classier will make a prediction about its semantic encoding using the learned s map .
even when a new example belongs to a class that did not appear in the training set d , if the prediction produced by the s map is close to the true encoding of that class , then the l map will have a reasonable chance of recovering the correct label .
as a concrete example , if the model can predict the object has fur and a tail , it would have a good chance of recovering the class label dog , even without having seen images of dogs during training .
in short : by using a rich semantic encoding of the classes , the classier may be able to extrapolate and recognize novel classes .
123 theoretical analysis
in this section we consider theoretical properties of a semantic output code classier that determine its ability to recognize instances of novel classes .
in other words , we will address the question : under what conditions will the semantic output code classier recognize examples from classes omitted from its training set ?
in answering this question , our goal is to obtain a pac - style bound : we want to know how much error can be tolerated in the prediction of the semantic properties while still recovering the novel class with high probability .
we will then use this error bound to obtain a bound on the number of examples necessary to achieve that level of error in the rst stage of the classier .
the idea is that if the rst stage s ( ) of the classier can predict the semantic properties well , then the second stage l ( ) will have a good chance of recovering the correct label for instances from novel classes .
as a rst step towards a general theory of zero - shot learning , we will consider one instantiation of a semantic output code classier .
we will assume that semantic features are binary labels , the rst stage s ( ) is a collection of pac - learnable linear classiers ( one classier per feature ) , and the second stage l ( ) is a 123 - nearest neighbor classier using the hamming distance metric .
by making these assumptions , we can leverage existing pac theory for linear classiers as well as theory for approximate nearest neighbor search .
much of our nearest - neighbor analysis parallels the work of ciaccia and patella ( 123 ) .
we rst want to bound the amount of error we can tolerate given a prediction of semantic features .
to nd this bound , we dene f to be the distribution in semantic feature space of points from the knowledge base k .
clearly points ( classes ) in semantic space may not be equidistant from each other .
a point might be far from others , which would allow more room for error in the prediction of semantic features for this point , while maintaining the ability to recover its unique identity ( label ) .
conversely , a point close to others in semantic space will have lower tolerance of error .
in short , the tolerance for error is relative to a particular point in relation to other points in semantic space .
we next dene a prediction q to be the output of the s ( ) map applied to some raw - input example x x d .
let d ( q , q ( cid : 123 ) ) be the distance between the prediction q and some other point q ( cid : 123 ) representing a class in the semantic space .
we dene the relative distribution rq for a point q as the probability that the distance from q to q ( cid : 123 ) is less than some distance z :
this empirical distribution depends on f and is just the fraction of sampled points from f that are less than some distance z away from q .
using this distribution , we can also dene a distribution on the distance to the nearest neighbor of q , dened as q :
rq ( z ) = p ( d ( q , q ( cid : 123 ) ) z )
gq ( z ) = p ( q z )
which is given in ciaccia ( 123 ) as :
gq ( z ) = 123 ( 123 rq ( z ) ) n
where n is the number of actual points drawn from the distribution f .
now suppose that we dene q to be the distance a prediction q for raw - input example x is from the true semantic encoding of the class to which x belongs .
intuitively , the class we infer for input x is going to be the point closest to prediction q , so we want a small probability that the distance q to the true class is larger than the distance between q and its nearest neighbor , since that would mean there is a spurious neighbor closer to q in semantic space than the point representing qs true class :
p ( q q )
rearranging we can put this in terms of the distribution gq and then can solve for q :
p ( q q )
if gq ( ) were invertible , we could immediately recover the value q for a desired .
for some distributions , gq ( ) may not be a 123 - to - 123 function , so there may not be an inverse .
but gq ( ) will never decrease since it is a cumulative distribution function .
we will therefore dene a function g123 such that : g123 so using nearest neighbor for l ( ) , if q g123 q ( ) , then we will recover the correct class with at least 123 probability .
to ensure that we achieve this error bound , we need to make sure the total error of s ( ) is less than g123 .
we assume in this analysis that we have p binary semantic features and a hamming distance metric , so max denes the total
q ( ) which we dene as max
q ( ) = argmaxq
number of mistakes we can make predicting the binary features .
note with our assumptions , each semantic feature is pac - learnable using a linear classier from a d dimensional raw input space .
to simplify the analysis , we will treat each of the p semantic features as independently learned .
by the pac assumption , the true error ( i . e .
probability of the classier making a mistake ) of each of the p learned hypotheses is , then the expected number of mistakes over the p semantic features will be mistakes is given by the binomial distribution : binocdf ( max we can obtain the desired error rate for each hypothesis by utilizing the standard pac bound for vc - dimension123 ( mitchell , 123 ) .
to obtain a hypothesis with ( 123 ) probability that has true error at most = max
/ p = g123 ( ) / p , then the classier requires a number of examples mq , :
further , the probability of making at most max
if we set = max
; p , max
123log ( 123 / ) + 123 ( d + 123 ) log ( 123p / max
if each of the p classiers ( feature predictors ) is learned with this many examples , then with prob - ability ( 123 ) p , all feature predictors will achieve the desired error rate .
but note that this is only the probability of achieving p hypotheses with the desired true error rate .
the binomial cdf yields mistakes total , and the ( 123 ) term above species the the probability of making at most max probability of recovering the true class if a maximum of this many mistakes were made .
therefore , there are three probabilistic events required for the semantic output code classier to predict a novel class and the total ( joint ) probability of these events is :
p ( there are p feature predictors with true error max p ( at most max p ( recovering true class | at most max
mistakes made | there are p feature predictors with true error max
and since max
q ( ) , the total probability is given by : ( 123 ) p binocdf ( g123
q ( ) ; p , g123
q ( ) / p ) ( 123 )
in summary , given desired error parameters ( 123 ) and ( 123 ) for the two classier stages , equation 123 provides the total probability of correctly predicting a novel class .
given the value for we can compute the necessary for each feature predictor .
we are guaranteed to obtain the total probability if the feature predictors were trained with mq , raw - input examples as specied in equation 123
to our knowledge , equations 123 and 123 specify the rst formal guarantee that provides conditions under which a classier can predict novel classes .
123 case study : neural decoding of novel thoughts
in this section we empirically evaluate a semantic output code classier on a neural decoding task .
the objective is to decode novel words a person is thinking about from fmri images of the persons neural activity , without including example fmri images of those words during training .
we utilized the same fmri dataset from mitchell ( 123 ) .
this dataset contains the neural activity observed from nine human participants while viewing 123 different concrete words ( 123 examples from 123 different categories ) .
some examples include animals : bear , dog , cat , cow , horse and vehicles : truck , car , train , airplane , bicycle .
each participant was shown a word and a small line drawing of the concrete object the word represents .
the participants were asked to think about the properties of these objects for several seconds while images of their brain activity were recorded .
each image measures the neural activity at roughly 123 , 123 locations ( i . e .
voxels ) in the brain .
six fmri scans were taken for each word .
we used the same time - averaging described in mitchell ( 123 ) to create a single average brain activity pattern for each of the 123 words , for each participant .
123the vc dimension of linear classiers in d dimensions is d + 123
in the language of the semantic output code classier , this dataset represents the collection d of raw - input space examples .
we also collected two semantic knowledge bases for these 123 words .
in the rst semantic knowl - edge base , corpus123 , each word is represented as a co - occurrence vector with the 123 most frequent words from the google trillion - word - corpus123
the second semantic knowledge base , human123 , was created using the mechanical turk human computation service from amazon . com .
there were 123 semantic features collected for the 123 words , and the questions were selected to reect psychological conjectures about neural activity encoding .
for example , the questions related to size , shape , surface properties , and typical usage .
example questions include is it manmade ? and can you hold it ? .
users of the mechanical turk service answered these questions for each word on a scale of 123 to 123 ( denitely not to denitely yes ) .
in our experiments , we use multiple output linear regression to learn the s ( ) map of the semantic output code classier .
let x ( cid : 123 ) nd be a training set of fmri examples where each row is the image for a particular word and d is the number of dimensions of the fmri image .
during training , we use the voxel - stability - criterion that does not use the class labels described in mitchell ( 123 ) to reduce d from about 123 , 123 voxels to 123
let y ( cid : 123 ) np be a matrix of semantic features for those words ( obtained from the knowledge base k ) where p is the number of semantic features for that
word ( e . g .
123 for the human123 knowledge base ) .
we learn a matrix of weights ( cid : 123 ) w ( cid : 123 ) dp
this model , each output is treated independently , so we can solve all of them quickly in one matrix operation ( even with thousands of semantic features ) :
( cid : 123 ) w = ( xt x + i ) 123xt y
where i is the identity matrix and is a regularization parameter chosen automatically using the cross - validation scoring function ( hastie et al . , 123 ) 123
given a novel fmri image x , we can obtain
a prediction ( cid : 123 ) f of the semantic features for this image by multiplying the image by the weights : ( cid : 123 ) f = x ( cid : 123 ) w classier .
in other words , l ( ( cid : 123 ) f ) will take the prediction of features and return the closest point in a
for the second stage of the semantic output code classier , l ( ) , we simply use a 123 - nearest neighbor
given knowledge base according the euclidean distance ( l123 ) metric .
using the model and datasets described above , we now pose and answer three important questions .
can we build a classier to discriminate between two classes , where neither class appeared in the training set ? to answer this question , we performed a leave - two - out - cross - validation .
specically , we trained the model in equation 123 to learn the mapping between 123 fmri images and the semantic features for their respective words .
for the rst held out image , we applied the learned weight matrix to obtain a prediction of the semantic features , and then we used a 123 - nearest neighbor classier to compare the vector of predictions to the true semantic encodings of the two held - out words .
the label was chosen by selecting the word with the encoding closest to the prediction for the fmri image .
we then performed the same test using the second held - out image .
thus , for each iteration of the cross -
validation , two separate comparisons were made .
this process was repeated for all ( cid : 123 ) 123
( cid : 123 ) = 123 , 123
possible leave - two - out combinations leading to 123 , 123 total comparisons .
table 123 shows the results for two different semantic feature encodings .
we see that the human123 semantic features signicantly outperformed the corpus123 features , with mean accuracies over the nine participants of 123% and 123% respectively .
but for both feature sets , we see that it is possible to discriminate between two novel classes for each of the nine participants .
123vectors are normalized to unit length and do not include 123 stop words like a , the , is 123we compute the cross - validation score for each task and choose the parameter that minimizes the average
loss across all output tasks .
table 123 : percent accuracies for leave - two - out - cross - validation for 123 fmri participants ( labeled p123 - p123 ) .
the values represent classier percentage accuracy over 123 , 123 trials when discriminating be - tween two fmri images , both of which were omitted from the training set .
figure 123 : ten semantic features from the human123 knowledge base for the words bear and dog .
the true encoding is shown along with the predicted encoding when fmri images for bear and dog were left out of the training set .
how is the classier able to discriminate between closely related novel classes ? figure 123 shows ten semantic questions ( features ) from the human123 dataset .
the graph shows the true values along with the predicted feature values for both bear and dog when trained on the other 123 words .
we see the model is able to learn to predict many of the key features that bears and dogs have in common such as is it an animal ? as well as those that differentiate between the two , such as do you see it daily ? and can you hold it ? for both of these novel words , the features predicted from the neural data were closest to the true word .
can we decode the word from a large set of possible words ? given the success of the semantic output code classier at discriminating between the brain images for two novel words , we now consider the much harder problem of discriminating a novel word from a large set of candidate words .
to test this ability , we performed a leave - one - out - cross - validation , where we trained using equation 123 on images and semantic features for 123 words .
we then pre - dicted the features for the held - out image of the 123th word , and then performed a 123 - nearest neighbor classication in a large set of candidate words .
we tested two different word sets .
the rst was mri123 which is the collection of all 123 concrete nouns for which we collected fmri data , including the 123 training words and the single held out word .
the second set was noun123 , a collection of 123 english nouns with high familiarity , concreteness and imagineability , compiled from wilson ( 123 ) and snodgrass ( 123 ) .
for this set of words , we added the true held - out word to the set of 123 on each cross - validation iteration .
we performed this experiment using both the corpus123 and human123 feature sets .
the rank accuracy results ( over 123 cross - validation iterations ) of the four experiments are shown in figure 123
the human123 features again signicantly outperform corpus123 on both mean and median rank accuracy measures , and both feature sets perform well above chance .
on 123 of 123 total presentations of the mri123 words ( 123 presentations for each of nine participants ) , the human123 features predicted the single held - out word above all 123 other words in its training set .
while just a bit above chance level ( 123 / 123 ) , the fact that the model ever chooses the held - out word over all the training words is noteworthy since the model is undoubtedly biased towards predicting feature values similar to the words on which it was trained .
on the noun123 words , the model predicted the correct word from the set of 123 alternatives a total of 123 times for the human123 features and 123 times for the corpus123 features .
for some subjects , the model correctly picked the right
bear & dog prediction match - 123 - 123 - 123 - 123 - 123 . 123 . 123 . 123is it ananimal ? is it man - made ? do you seeit daily ? is ithelpful ? can youhold it ? would youfind it in ahouse ? do youlove it ? does itstand ontwo legs ? is it wild ? does itprovideprotection ? answerbear predictedbear targetdog targetdog predicted figure 123 : the mean and median rank accuracies across nine participants for two different semantic feature sets .
both the original 123 fmri words and a set of 123 nouns were considered .
table 123 : the top ve predicted words for a novel fmri image taken for the word in bold ( all fmri images taken from participant p123 ) .
the number in the parentheses contains the rank of the correct word selected from 123 concrete nouns in english .
word from the set of 123 more than 123% of the time .
the chance accuracy of predicting a word correctly is only 123% , meaning we would expect less than one correct prediction across all 123 as figure 123 shows , the median rank accuracies are often signicantly higher than the mean rank accuracies .
using the human123 features on the noun123 words , the median rank accuracy is above 123% for each participant while the mean is typically about 123% lower .
this is due to the fact that several words are consistently predicted poorly .
the prediction of words in the categories ani - mals , body parts , foods , tools , and vehicles typically perform well , while the words in the categories furniture , man - made items , and insects often perform poorly .
even when the correct word is not the closest match , the words that best match the predicted features are often very similar to the held - out word .
table 123 shows the top ve predicted words for eight different held - out fmri images for participant p123 ( i . e .
the 123 closest words in the set of 123 to the predicted vector of semantic features ) .
we presented a formalism for a zero - shot learning algorithm known as the semantic output code classier .
this classier can predict novel classes that were omitted from a training set by leveraging a semantic knowledge base that encodes features common to both the novel classes and the training set .
we also proved the rst formal guarantee that shows conditions under which this classier will predict novel classes .
we demonstrated this semantic output code classier on the task of neural decoding using semantic knowledge bases derived from both human labeling and corpus statistics .
we showed this classier can predict the word a person is thinking about from a recorded fmri image of that persons neural activity with accuracy much higher than chance , even when training examples for that particular word were omitted from the training set and the classier was forced to pick the word from among nearly 123 , 123 alternatives .
we have shown that training images of brain activity are not required for every word we would like a classier to recognize .
these results signicantly advance the state - of - the - art in neural decoding and are a promising step towards a large vocabulary brain - computer interface .
