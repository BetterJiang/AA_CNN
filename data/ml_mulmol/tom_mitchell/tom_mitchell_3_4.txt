ithis document has been approved
for public release and sale; its distribution is unliiited .
most research on machine learning has focused on scenarios in which a learner faces a single , isolated learning task .
the lifelong learning framework assumes instead that the learner encounters a multitude of related learning tasks over its lifetime , providing the opportunity for the transfer of this paper studies lifelong learning in the context of binary classification .
it presents the invariance approach , in which knowledge is transferred via a learned model of the invariances of the domain .
results on learning to recognize objects from color images demonstrate superior generalization capabilities if invariances are learned and used to bias ' subsequent learning .
this research is sponsored in part by the national science foundation under award iri - 123 , and by the wright laboratory , aeronautical systems center , air force materiel command , usaf , and the advanced research projects agency ( arpa ) under grant number f123 - 123 - 123 - 123
views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing official policies or endorsements , either expressed or implied , of nsf , wright laboratory or the united states government .
keywords : explanation - based neural network learning , learning invariances , lifelong learning ,
machine learning , neural networks , object recognition
standard inductive supervised learning is concerned with learning an unknown target function from a finite collection of training data .
the framework of supervised learning can be characterized as follows .
let f denote the set of all potential target functions .
for example , in a robot arm domain f might be the set of all kinematic functions for robots with three joints .
it is commonly assumed that all functions in f are defined over a single input space , denoted by i , and a single output space , denoted by 123
the learner has a set of hypotheses that it can consider , denoted by h , which might or might not be different from f .
for example , the set h could be the set of all artificial neural networks with 123 hidden units ( rumelhart et al . , 123 , or , alternatively , the set of all decision trees with depth less than 123 ( quinlan , 123
throughout this paper , let us make the simplifying assumption that all functions in f are binary classifiers , by restricting the output to 123 = ( 123 , 123 ) .
we will refer to instances that fall into class i as positive instances , and to those that fall into class 123 as negative instances .
to learn an unknown target function f* e f , the learner is given a finite collection of input -
output examples ( training examples )
which are possibly distorted by noise .
the goal of the learner is to generate a hypothesis h e h , such that the deviation
e = e prob ( i ) ! lf* ( i ) - h ( i ) 123
between the target function f* and h on future examples will be as small as possible .
here prob ( i ) is the probability distribution according to which the examples are generated .
prob is generally unknown to the learner , as is f* .
standard supervised learning focusses on learning a single target function f* , and training data is assumed to be available only for this one function .
however , if functions in f are sufficiently related , it can be helpful to have access to training examples of other functions f in f as well .
for example , consider a robot whose task is to find and fetch various objects , using its camera for object recognition .
here let f be the set of recognition functions for all objects , one for each potential target object , and the target function f* e f corresponds to some object the robot must currently learn to recognize .
x , the training set , will consist of positive and negative examples of this object .
the task of the learner is to find an h which minimizes e .
in order to do so , the robot must learn to recognize the target object invariant of rotation , translation , scaling in size , change of lighting and so on .
clearly , the more profound the learner ' s initial understanding of these invariances , the fewer training examples in x it will require for reliable learning .
because these invariances are common to all functions in f , images showing other objects can provide additional information for learning about these invariances , and hence augment the training set x .
this example illustrates the lifelong learning framework ( thrun and mitchell , 123
lifelong learning , a collection of related learning problems is encountered over the lifetime of the system .
when learning the n - th task , the leatner may therefore employ knowledge gathered in the
" * a space of possible hypotheses h " * a set of training examples x of some unknown target function f* e f , drawn
with probability distribution prob .
" * in lifelong learning : a collection of support sets y = ( xk ) , which characterize
other functions fk e f
a hypothesis h e h that minimizes 123 prob ( i ) iif* ( i ) - h ( i ) ii
table 123 : standard supervised learning and lifelong supervised learning .
previous n - 123 tasks to improve its performance .
this paper considers a particular form of lifelong learning in which the learning tasks correspond to learning boolean classifications ( concepts ) , and in which the previous experience consists of training examples of other classification functions from the same family f .
more formally , in addition to the set of training examples x for the target function f * , the learner is also provided sets of examples
xk = ( ( i , gk ( i ) ) )
( k = 123 , . . . , igi )
of other functions g = ( g , , g123 , . . . ) c f taken from the same function family f .
since this additional data supports learning f* , we shall call each xk a support set for x .
the set of all available support sets , ( xi , : k = i , . . . , igij , is denoted by y .
notice that the support sets xk are not necessarily generated according to the same probability distribution .
table i summarizes the problem definitions of standard supervised learning and the lifelong supervised learning problem considered here .
in lifelong learning , the learner is given a collection of support sets y in addition to the training set x and the hypothesis space y .
support sets can be defined for a variety of real - world learning tasks .
for example , consider a personal computer assistant whose task it is to recognize its user ' s handwriting .
f is the set of all mappings from hand - drawn curves to letter labels , one for each potential user .
for each user , i . e . , for each f e f , the assistant could start learning to recognize handwriting from scratch .
however , many characteristics will co - occur for multiple users , and one would expect a learner which incorporates examples from other users to generalize better .
a second example , to which inductive machine learning techniques have frequently been applied , is stock market prediction .
while many of the successful techniques in this domain remain unpublished , it seems to be well - accepted that stocks can be predicted better by learning from data regarding entire families of stocks , rather than learning about a single stock in isolation .
clearly , certain patterns can be found that apply to various stocks , and knowing about these regularities when training data is limited will most likely improve the prediction accuracy of a learning system .
the lifelong learning framework studied in this paper differs from standard supervised learning in that in addition to the training data x , support sets y are also provided .
this raises two
how can a learner use support sets to generalize more accurately ?
under what conditions will a learner benefit from support sets ? obviously , the more closely related the functions in f , the better .
but exactly what relation among these functions is required in order for support sets to be useful ? what happens if the functions in f are not related at all ? can support sets mislead generalization and , if so , under what conditions ?
this paper does not provide general answers to these questions .
instead , it proposes one particular approach , namely learning invariance functions , which relies on certain assumptions on the function set f .
it also presents empirical evidence that this approach to using support sets can significantly improve generalization accuracy when learning to recognize objects based on visual
123 the invariance approach
the invariance approach first learns an invariance function o from the support sets in y .
this function is then used to bias the learner as it selects a hypothesis to fit the training examples x of the target function .
let y = ( xk ) be a collection of support sets for learning f* from x .
recall our assumption that all functions in f have binary output values .
hence , each example in a support set is either positive ( i . e . , output 123 ) or negative ( i . e . , output 123 ) .
consider a target function , fk e f with k e ( i . . . , jfj ) , and a pair of examples , say i e i andj e i .
a local invariance operator " rk : i x i - -
( 123 , 123 ) is a mapping from a pair of input vectors defined as follows :
if a ( i ) = fk ( j ) = i if fk ( i ) # a ( j ) if fk ( i ) = fk ( j ) =123
basically , the local invariance operator indicates whether both instances are members of class i ( positive examples ) relative to fk .
if rk ( i , j ) = 123 , then fk is invariant with respect to i and j .
notice that positive and negative instances are not treated symmetrically in r .
the local invariance operators rk ( k = i , . . . , ifi ) define a ( global ) invariance function for f , ( 123 , 123 ) .
for two examples , i and j , ao ( i , j ) is 123 if there exists a k for
denoted by a : i x i which rk ( i , j ) = 123
likewise , a ( i , j ) is 123 if there exists a k for which rk ( i , j ) = 123 :
if 123k e l , . . . , ifi ) with tk ( i , j ) = 123 if123ke ( , . . . .
jfj ) withrk ( i , j ) =123
the invariance function behaves like an invariance operator , but it does not depend on k .
it is important to notice that the invariance function can be ill - defined .
this is the case if there exist two examples which in one target function both belong to class 123 , whereas in another they fall into
123i , j e i , k , k ' e ( 123 , . . . , ifi ) : rk ( i , j ) = i a tk , ( i , j ) = 123
in such cases the invariance mapping is ambiguous and is not even a mathematical function .
a class of functions f is said to obey the invariance property if its invariance function is non - ambiguous ' .
the invariance property is a central assumption for the invariance approach to lifelong classification learning .
the concept of invariance functions is quite powerful .
assume f holds the invariance property .
if a is known , every training instance i for an arbitrary function fk e f can be correctly classified , given there is at least one positive instance of fk available .
to see , assume ipo , e i is known to be a positive instance for fk .
then for any instance i e i , a ( i , izo ) will be 123 if and only if fk ( i ) = 123
although the invariance property imposes a restriction on the function family f , it holds true for quite a few real - world problems .
for example , a function family obeys the invariance property if all positive classes ( of all functions fk ) are disjoint .
one such function family is the family of object recognition functions defined over distinct objects .
123 learning with invariants
in the lifelong learning regime studied in this paper , a - is not given .
however , an approximation to o - can be learned .
since ao does not depend upon the specific target function f* , every support set xk e y can be used to train a ' , as long as there is at least one positive instance available in xk .
for all k e ( i , . . . , igil ) , training examples for a " are constructed from examples i , j e xk :
here rk must be defined , i . e . , at least one of the examples i and j must be positive under fk .
in the experiments described below , ao is approximated by training an artificial neural network using the backpropagation algorithm ( rumelhart et al . , 123
once o , has been learned , one way to mimic f* is to pick an arbitrary positive training instance in x , and to use o " for classification , as described above .
however , ao might not be accurate enough to classify correctly , usually because of modeling limitations , noise , or lack of training data .
in fact , the experimental results described in the next section indicate that there are better ways to employ the invariance network .
123 extracting slopes to guide generalization
the remainder of this section describes an alternative approach which employs a hybrid neural network learning algorithm for learning f* .
this algorithm is a special case of both the tangent - ' it is generally acceptable for the invariance function to be ambiguous , as long as the likelihood for generating
ambiguously classified pairs of examples is zero .
figure 123 : fitting values and slopes : let f* be the target function for which three examples ( x 123 , f* ( x123 ) ) , ( x123 , 123f* ( x123 ) ) , and ( x 123 , f* ( x 123 ) ) are known .
based on these points the learner might generate the hypothesis hi .
if the slopes are also known , the learner can do much better : h , .
prop algorithm ( simard et al . , 123 and the explanation - based neural network learning ( ebnn ) algorithm ( mitchell and thrun , 123
here we will refer to it as ebnn .
suppose we are given a training set x , and an invariance network a which has been trained using a collection of support sets y .
we are now interested in learning f* .
one could , of course , ignore the invariance network and the support sets altogether and train a neural network purely based on the training data x .
the training set x imposes a collection of constraints on the output values for the hypothesis h .
if h is represented by an artificial neural network , as is the case in the experiments reported below , the backpropagation ( bp ) algorithm can be used to fit x .
ebnn does this , but it also derives additional constraints using the invariance network .
more precisely , in addition to the value constraints in x , ebnn derives constraints on the slopes ( tangents ) for the hypothesis h .
to see how this is done , consider a training example i , taken from the training set x .
let ip , be an arbitrary positive example in x .
then , o ( i , ipo ) determines whetner i and iz ' s belong to the same class - information that is readily available , since we are given the classes of i and ip .
however , predicting the class using the invariance network also allows us to determine the output - input slopes of the invariance network .
these slopes measure the sensitivity of class membership with respect to the input features in i .
this is done by computing the partial derivative of a with respect to i at ( i , ipos ) :
jio ( i )
" - - 123 123 ( , i p
via ( i ) measures how infinitesimal changes in i will affect the classification of i .
since ar ( - , ip , ) is an approximation to f* , via ( i ) approximates the slope vif ( i ) .
consequently , instead of fitting training examples of the type ( i , f ( i ) ) , ebnn fits training examples of the type
gradient descent can be used to fit training examples of this type , as explained in ( simard et al . , 123
123 illustrates the utility of this additional slope information in function fitting .
notice if multiple positive instances are available in x , slopes can be derived for each one of
let xpos c x be the set of positive training examples in x .
let x ' = 123
for each training example ( i , f* ( 123i ) ) e xpo do :
( a ) compute via ( i ) =x 123a ( i ) ( i
xposii , e xpra
( b ) letx ' = x ' + ( i , f* ' ( i ) , vza ( i ) )
fit x ' .
s ) using the invariance network a .
table 123 : application of ebnn to learning with invariance networks .
in this case , averaged slopes are used to constrain the target function :
r ( i , i ( cid : 123 ) ~ ) ( |
here xp c x denotes the set of positive examples in x .
the application of the ebnn algorithm to learning with invariance networks is summarized in table 123
generally speaking , slope information extracted from the invariance network is a linear ap - proximation to the variances and invariances of f at a specific point in l .
along the invariant directions slopes will be approximately zero , while along others they will be large .
for example , in the object recognition domain described above , it might happen that color is an important feature for classification while brightness is not .
this is typically the case in situations with changing illumination .
in this case , the invariance network could learn to ignore brightness , and hence the slopes of its classification with respect to brightness would be approximately zero .
the slopes for color , however , would be large , given that slight color changes imply that the object would belong to a different class .
when training the classification network , slopes provide additional information about the sensitivity of the target function with respect to its input features .
hence , the invariance network can be said to bias the learning of the classification network .
however , since ebnn trains on both slopes and values simultaneously , errors in this bias ( incorrect slopes due to approximations in the learned invariance network ) can be overturned by the observed training example values in x .
123 object recognition
to illustrate the invariance network in a real - world domain , we collected a database of 123 color camera images of seven different objects , as depicted in fig .
123 ( left columns ) .
blue and white
hammer brown and black medium depending on perspective
the objects were chosen so as tc provide color and size cues helpful to their discrimination .
the background of all images consisted of plain , white cardboard .
different images of the same object varied by the relative location and orientation of the object within the image .
in 123% of all recordings , the location of the light source was also changed , producing bright reflections at random locations in various cases .
in some of the images the objects were back - lit , in which case they appeared to be black .
123 shows examples of two of the objects , the shoe and the glasses .
123 images of each object were recorded .
in all our experiments images were encoded by a 123 - dimensional vector , providing color , brightness and saturation information for a down - scaled image of size 123 by 123
examples for the down - scaled images are shown in figures 123 ( right columns ) and 123
although each object appears to be easy to recognize from the original image , in many cases we found it difficult to visually classify objects from the subsampled images .
however , subsampling was necessary to keep the networks at a reasonable size .
the set of target functions , f , was the set of functions that recognize objects , one for each object .
for example , the indicator function for the bottle , fbol . , was i , if the image showed a bottle , and 123 otherwise .
since we only presented distinct objects , all sets of positive instances were disjoint .
consequently , f obeyed the invariance property .
the set of hypotheses h was the set of all artificial neural networks with 123 input units , 123 hidden units , and i output unit , as such a network was employed to represent the target function .
the objective was to learn to recognize shoes , i . e . , f* = fsho .
five other objects , namely the bottle , the hat , the hammer , the can and the book , were used to construct the support sets v .
in order to avoid any overlap in the training set x and the support sets in y , we exclusively used pictures of a seventh object , glasses , as counterexamples for faho .
123 training the invariance network
each of the five support sets in y , xbonle , xh . , , xh . mme , xya , and xok , contained 123 images of the corresponding object ( positive examples ) and 123 randomly selected images of other objects ( negative examples ) .
when constructing training examples for the invariance network , we randomly selected a subset of 123 , 123 pairs of images , 123 of which were taking for training and 123 for cross - validation .
123% of the final training and cross - validation examples were positive examples for the invariance network ( i . e . , both images showed the same object ) , and the other 123% were negative examples .
figure 123 : objects ( left ) and corresponding network inputs ( right ) .
a hundred images of a bottle .
a hat , a hammer , a coke can , and a book were used to train and test the invariance network .
afterwards , the classification network was trained to distinguish the shoe from the glasses .
in several attempts to construct an invariance network , using a variety of network topologies with up to two hidden layers , we achieved a maximum generalization accuracy of 123% .
this result was somewhat unsatisfactory , since random guessing , by comparison , results in 123% ac - curacy .
when applied to the two remaining unseen objects , the shoe and the glasses , the best invariance network classified only 123% of all image pairs correctly .
in order to improve these results , we applied a learning technique that focusses learning by incorporating additional training information , adopted from isuddarth and kergosien , 123
( caruana , 123
their technique rests on the assumption that in addition to the ! earning task of interest , some related learning tasks , using the same input representation and the same training data ( with different target values ) , are available .
instead of training on a single task , a network is
figure 123 : images , along with the corresponding network inputs , of the objects shoe and glasses .
these examples illustrate some of the invariances in the object recognition domain .
trained on all tasks simultaneously , using an augmented output layer that provides additional output units for the additional tasks .
this technique , which is called " learning by hints " or " multi - task learning , " has been found to yield better generalization accuracies , which can be attributed to the fact that all of these tasks share the same hidden units .
if tasks are sufficiently related , it allows better hidden representations to be developed , resulting in improved generalization .
in fact , this approach establishes an alternative method for the lifelong learning problem , as discussed in sect .
in the object recognition domain , a task that is obviously related to determining whether or not two images belong to the same class is the task of actually classifying the two images .
hence , we added two sets of 123 output units to the invariance network , which were trained to determine the classification of the object shown in either image .
a local i - of - n encoding was used to encode the 123 different object classes .
hence , the augmented invariance network had i i output units , one for determining if the two images are the same or not and 123 for classifying images .
the latter 123 units , however , were used exclusively during training the invariance network , and did not play any part in subsequently applying the invariance network .
the classification accuracy of this network was significantly better than the accuracy of the single output network reported above .
after training , the augmented network managed to determine whether or not two objects belong to the same class with 123% generalization accuracy .
it also exhibited 123% classification accuracy in
the new task , the recognition of the shoe .
obviously , both accuracy rates are significantly better
than those achieved using the single output network .
123 lamning to recognize shoes
having trained the invariance network , we were now interested in training the classification network .
the network used throughout the experiments reported here consisted of 123 input units , 123 hidden units , and i output unit - no effort was made to optimize the network topology .
a total of 123 examples of images showing the shoe and the glasses were available for training and testing the shoe classification network .
the central question regarding the invariance approach is to what extent the invariance network , when used to bias the target function , improves the generalization accuracy of the classification
in order to elucidate the role of the invariance network , we trained the classification network using only two training examples : a randomly selected image of the shoe ( positive example ) , and a randomly selected image of the glasses ( negative example ) .
slopes were computed using the previously learned invariance network .
since the counterexamples to the target concept , the glasses , form a unique class of images that do not overlap with any other positive class from the support sets , slopes could also be derived using negative examples .
instead of using eq .
( i ) , slopes were extracted from the invariance net using the extended mixture :
123 i pn
here xt , , c x is the set of positive examples in x , and x , .
= x - x . o is the set of negative examples .
( 123 ) differs from eq .
( 123 ) by taking also negative examples 123 , , s into account , which is justified by the fact that images of glasses form a class disjoint from all other objects .
123 shows the average generalization curve as a function of training epochs with and without the invariance network .
the generalization accuracy here was measured over all 123 available images .
the curve shows the generalization accuracy averaged over 123 experiments , each trained using one randomly selected positive and one randomly selected negative example . 123 without using the invariance approach , the average generalization accuracy after 123 , 123 training epochs is 123% .
however , using ebnn with the invariance network increases accuracy to 123% due to the information conveyed by the invariance slopes .
this difference can be assessed in multiple ways .
in terms of residual error , backpropagation eyhibits a misclassification rate that is 123% larger than that of ebnn .
a second interpretation is to look at the performance increase .
which is defined as the difference in classification accuracy after learning and before learning , assuming that the accuracy before learning is 123% .
123 : nn ' s performance increase is 123% , which is 123 times better than backpropagation ' s 123% .
for example , if a neural network is trained using the two images of a shoe and the glasses depicted in fig .
123 , plain backpropagation classifies only 123% of the testing images correctly .
123note we used a fast learning method that adapted the amount of momentum on - line during learning .
figure 123 : training curves , with ( solid line ) and without ( dashed line ) the invariance network and ebnn , measured on an independent test set and averaged over 123 runs , after providing one positive and one negative training example .
here the generalization rate is particularly poor , since the location of thk objects differ , and backpropagation mistakenly considers location the crucial feature for object recognition .
ebnn using the invariance network produces a network that is much less sensitive to object location , resulting in a 123% generalization accuracy in this particular example .
note that the network learned by ebnn performs significantly better than the invariance network itself used as a classifier ( 123% ) .
this is because ebnn is trained on images of the shoe and the glasses , while the invariance network is not .
the importance of mixing slopes becomes clear by looking at the accuracy that is achieved when slopes are computed differently .
if slopes are only extracted by comparing an image with itself ( i . e . , both images of the invariance network are equivalent ) , the average final accuracy is 123% .
when only pairwise different images are used as input to the invariance network , the resulting accuracy is 123% .
both accuracies are significantly smaller than the 123% accuracy achieved by mixing the two .
we also tried experiments weighting the mixtures of slopes .
in one case , we used the prediction accuracy of the domain theory ( lob* ) as the weighting factor : the more accurate the invariance network for a particular training example , the stronger the weight of the corresponding slope in the mixture .
this strategy , which has been found to be useful across a variety of domains ( mitchell et al . , 123 , ( thrun , 123 resulted about equivalent performance ( 123% ) in the object recognition domain .
the reader should notice that all these results refer to the classification accuracy after 123 , 123 training epochs , using just one positive and one negative training example .
as can be seen in fig .
123 , backpropagation suffers from some over - fitting , as the accuracy drops after a peak at about 123 , 123 training epochs .
the average classification accuracy at this point in time is 123% .
however , due to lack of data , it is impossible in this domain to use early stopping methods that rely on cross validation , and it is unclear whether such methods would have improved the results for backpropagation significantly .
123a shows analogous results for training with two examples of both shoes and glasses .
here , the difference between ebnn and backpropagation is even wider .
ebnn achieves 123%
figure 123 : ( a ) averaged generalization accuracy when training on two positive and two negative training examples .
( b ) generalization accuracy for different number of training examples after 123 , 123 training epochs .
final accuracy , as opposed to 123% by plain backpropagation .
consequently , backpropagation ' s misclassification rate exceeds that of ebnn by 123% .
ebnn ' s performance increase is 123% , which is 123 times better than backpropagation ' s 123% .
results for experiments with larger training set sizes are depicted in fig .
as can be seen from this figure , the difference between the methods decreases as the number of training instances increases .
ebnn , however , continues to perform slightly better than plain backpropagation .
this matches our expectations , as the need for background knowledge decreases as the number of training examples increases .
however , the primary focus of this paper is learning when training data in x is scarce .
123 the role of the invariance network
the improved classification rates , which illustrate the successful transfer of knowledge from the support sets via the invariance network , raise the question what exactly are the invariances represented in this network .
what type information do the slopes convey ?
a plausible ( but only approximate ) measure of the importance of a feature is the magnitude of its slopes .
the larger the slopes , the larger the effect of small changes in the feature on the classification , hence the more relevant the feature .
in order to empirically assess the importance of features , average slope magnitudes were computed for all input pixels , averaged over all 123 pairs of training instances .
the largest average slope magnitude was found for color information : 123 .
in comparison , saturation slopes were , on average , only 123 ( this is 123% of the average for color slopes ) , and brightness slopes only 123 ( 123 123 % ) .
these numbers indicate that , according to the invariance network , color information was most important for classification .
to verify this hypothesis , we repeated our experiments omitting some of the image information .
more specifically , in one experiment color information was omitted , in a second saturation , and brightness in a third .
the results
invariance network classification , no ebnn 123 training example per class same , after 123 , 123 training epochs image shown in fig .
123 123 training examples per class only objects of same class used for deriving slopes only objects of different class used for deriving slopes weighting slopes by classification accuracy
table 123 : summary of the classification results listed in the paper .
all numbers are average classification rates on unseen testing data .
without invariance network with invariance network
123 123 %
confirmed our belief that color information indeed dominates classification .
it is clear that without color the generalization rates in the testing set are poor , although ebnn still generalizes better .
if saturation or brightness is omitted , however , the generalization rate is approximately equivalent to the results obtained for the full images reported above .
however , learning required significantly more training epochs in the absence of brightness information ( not shown here ) .
these and other results reported here are summarized in table 123
123 shows average slope matrices for the target category ( shoes ) with respect to the three input features , color , brightness and saturation .
grey colors indicate that the average slope for an input pixel is zero .
bright and dark colors indicate strongly positive and strongly negative slopes , respectively .
notice that these slopes are averaged over all 123 explanations used for training .
as is easily seen , average color slopes vary over the image , showing a slight positive tendency on average .
average saturation slopes are approximately zero .
brightness slopes , however , exhibit a strong negative tendency which is strongest in the center of the image .
one possible explanation for the latter observation is the following : both the shoe and the glasses are dark compared to the background .
shoes are , on average , larger than glasses , and hence fill more pixels .
in addition , in the majority of images the object was somewhere near the center of the image , whereas the border pixels showed significantly more noise .
lack of brightness in the image center is therefore a good indicator for the presence of the shoe , as is clearly reflected in the brightness slopes derived
figure 123 : slopes of the target concept ( glasses ) with respect to ( a ) color , ( b ) saturation , and ( c ) brightness .
every slope is averaged over 123 explanations .
white ( black ) color represents positive
from the invariance network .
the less obvious results for color and saturation can be attributed to the effect that optimal classifiers are non - linear in color and saturation .
in order to discriminate objects by color , for example , the network has to spot a specific interval in color space .
hence , the correct slopes can be either positive or negative depending in the particular color of a pixel , cancelling each other out in this plot .
as pointed out earlier , slopes provide first - order information , and invariances may well be hidden in higher - order derivatives .
however , both the superior performance of ebnn as well as the clear correlation of slope magnitudes and generalization accuracy show that ebnn manages to extract useful invariance information in this domain , even if these invariances defy simple
123 alternative approaches
while in this paper we have presented one particular approach to lifelong learning in the context of classification , many others are possible and several can be found in recent literature .
e learning internal representations .
other researchers report techniques to develop more appropriate hidden layer representations from multiple tasks .
for example , pratt proposed a method which transfered information by using an internal representation that was developed in earlier learning tasks ( pratt , 123
a similar technique has been proposed in ( sharkey and sharkey , 123
a second example of learning internal representations using multiple target functions is caruana ' s multi - task learning algorithm .
in his approach .
multiple , related tasks are trained simultaneously in a single neural network , forcing the networks to share hidden units .
he reports that hidden internal representations are developed which lead to improved generalization ( caruana , 123
notice that these results match our findings when training the invariance network .
all these approaches develop better internal representations of the data by considering multiple functions in f with the goal of improving generalization .
" spotting relevant features .
another approach , which bears close resemblance to learning invariances and learning representations , is to spot irrelevant features ( littlestone , 123 , ( caruana and freitag , 123 ) .
if the set of target functions f is such that - across the board - only a subset the features is relevant ( e . g . , the time of day may not matter for object recognition ) , a learning system can employ support sets to find the most relevant features .
once they are discovered , the remaining hypothesis space is smaller , which reduces the sample complexity in learning .
notice that ebnn weakens the influence of irrelevant features through zero - valued slopes ebnn .
" adapting the data .
a different approach to lifelong learning is to modify the dr the training set x or in the support sets y .
for example , imagine there is a ge ! module that can be applied to all functions in f , but it requires that data is pre each f e f requires an individual filter .
this is the case , for example , in approaches to speaker adaptation .
speaker adaptation comprises a family of techniques studied in speech recognition , in which a computer quickly adapts to the accent , voice , pitch , or speed of an individual speaker ( see ( hild and waibel , 123 for an example ) .
typically , speech is translated to a more machine - understandable speech by a user - specific module that allws quick adaptation .
speaker adaptation is an example of an approach in which training data x is adapted to fit previously learned modules .
in essence , all these approaches change the bias of the function approximator .
they differ in the way bias is represented , and in the assumption they make on the underlying function class f .
a variety of approaches aim to change the bias of an inductive function approximator in a more direct way .
for example , sutton ( sutton , 123 describes an approach that employs kalman filters to determine optimal learning rates .
atkeson ( atkeson , 123 123 proposes techniques for optimizing the distance metric in a nearest neighbor generalizer .
in ( maron and moore , 123 , an incremental method for the selection of nearest neighbor models is described .
starting with a hypothesis set h , this technique uses training data and cross - validation to gradually reduce h .
however , many of the approaches listed here have not been proposed in the context of learning more than one task .
it should be noted that the invariance approach bears some resemblance to training schemes found in the context of autonomous driving and letter recognition .
simard and colleagues ( simard et al . , 123 employed the tangent - prop algorithm for recognizing hand - printed letters .
since letter recognition should be invariant to translation and rotation , they manually provided zero - valued target slopes in the directions of these invariances , very much like those automatically generated by ebnn .
pomerleau ( pomerleau , 123 reports a similar technique that was used for training an autonomous vehicle .
based on knowledge about the relation of camera images and steering direction , he constructed additional training data that were used when training the network .
his technique can be viewed as an approximative version of simard ' s approach .
in both cases , domain knowledge was employed to incorporate invariances into neural network learning .
the invariance approach presented here differs in that a model of the invariances is constructed from training data , making it applicable in situations where the appropriate expert knowledge is not available from a human designer .
in the lifelong learning framework , the learner faces a collection of related learning tasks .
the challenge of this framework is to transfer knowledge across tasks , in order to generalize better from fewer training examples of the target function itself .
the experimental results presented in this paper prcvide clear evidence of superior general - ization in the object recognition domain , when invariances learned from related tasks are used to augment the training data for a new object recognition task .
however , the success of this invariance approach relies on several critical assumptions :
" well defined invariance functions rest on the assumption that f obeys the invariance property .
however , even if the invariance property is only approximately satisfied by f , the support sets can be used to train an invariance network .
this network will , in the ideal case , approach the expected a - value .
the object recognition domain presented above provides an example in which the invariance property may hold only approximately .
this is because different objects may look alike in the coarse - grained , noisy images , in which case they violate the
" it is also assumed that functions in f possess certain invariances which can actually be learned by the invariance network .
this fact does not follow from the invariance property .
the exact invariances that will be learned depend crucially on the input representation and function approximator used for a .
" we also assumed that the output space 123 of functions in f is binary .
however , this assumption is not essential for the invariance approach .
in principle , invariance functions may be defined for arbitrary , high - dimensional output spaces , given that a notion of difference between output vectors is available .
for example , if the function space f contains multi - , rn , the canonical vector difference dimensional real - valued functions of the type f : wm r ) establishes a local invariance tk : r123 , , operator and hence an invariance function .
this function , however , differs from a used in the binary case in that no clear class boundaries are defined , and no distinction is made between positive and negative examples .
, r with trk ( i , j ) = ifk ( i ) -
fk ( j ) i ( i , e
in the experiments reported above , all three assumptions were at least approximately fulfilled .
we conjecture that the real world offers a variety of tasks where learned invariances can boost generalization .
for example , problems such as face recognition , cursive handwriting recognition , stock market prediction and speech recognition , which possess non - trivial but important invari - ances .
for example , consider the problem of learning to recognize faces of various individuals .
here certain aspects are important for the successful recognition ( e . g . , the distance between the eyes ) , whereas others are less important ( e . g . , the direction in which the person is looking ) .
after training on a number of individuals , we conjecture that the invariance network might grasp some of these invariances , reducing the difficulty of learning faces of new individuals .
it should be noted that in this paper lifelong learning is applied to one particular class of learning problems , namely binary classification tasks .
in this context , several restrictive assumptions have
been made , most of which are adopted from standard supervised learning .
it is assumed that all functions ( and hence all instances in x and y ) are drawn from a monolithic function class f , in which all functions share the same input and output space .
moreover , 123 is restricted to be ( 123 , l ) .
in applying the invariance network , further assumptions were made on the relation of the target functions in f .
the lifelong learning framework , however , is more general .
it only specifies that a learner encounters a multitude of related learning tasks over its entire lifetime .
the task of the learner need not necessarily be classification .
for example , lifelong learning can be studied in function approximation , unsupervised learning , control learning or other learning paradigms .
it is also not required that the support sets , which contain related training data , and the training set stem from a class of functions sharing a common input and output space .
for example , control learning may benefit from training data collected in a classification domain , although the control function operates over different input and output spaces .
for example , in ( mitchell and thrun , 123 and ( thrun , 123 ) control learning is studied in a lifelong learning framework .
in control learning , the target function f* is a control function which maps percepts , denoted by s e s , to actions , denoted by a e a :
fp : s - - - - a
actions , when executed by the agent , result in some scalar penalty / reward , and the goal of learning is to maximize reward .
a popular method for learning control is reinforcement learning ( barto et al . , to appear ) , ( sutton , 123 , ( watkins and dayan , 123
reinforcement learning constructs value function that can be used to select optimal actions .
embedded in a lifelong learning framework , a control learning agent may face a variety of control learning tasks over its lifetime .
as shown in ( mitchell and thrun , 123 , learning action models , which are functions of the type
g : s - - - + s ,
can significantly reduce the amount of training required for subsequent control learning tasks .
ebnn is used to transfer knowledge across tasks , as in the invariance approach presented in this
the lifelong learning problem can also be understood as a meta - level learning problem .
consider , for example , its application to classification , as presented in this paper .
each training example at the meta - level correspondg to a whole support set xk at the base - level .
the set of support sets y = ( xk ) thus forms the set of training examples at the meta - level .
the testing set is x , which is the set of training examples for the target function f* at the base - level .
a convenient assumption to be made is that the base - level hypothesis space h is a superset of f .
then , the hypothesis space at the meta - level is a set of restrictions on h , or , in other words , a set of subsets of h .
the goal of learning on the meta - level is to reconstruct f ( or find a minimal superset of f ) as a hypothesis space for the base - level .
each training example xk reduces the meta - level hypothesis space .
if f is a candidate hypothesis in the meta - hypothesis space , one expects that in the limit h = f is the only hypothesis left at the meta - level .
since each support set characterizes a function in f , every training example at the meta - level will be a positive example of the target
concept f .
clearly , there can be no useful bias - free learning at the meta - level any more than there can be at the base - level .
however , despite the striking similarities between standard supervised learning and meta - learning , there are significant differences .
given a particular target function , f e f , the ultimate goal of learning is to minimize the prediction error for f* .
recognizing f is a secondary goal , since it is useful only in support of learning f * .
x , which establishes a single testing pattern in the meta - level , does not specify f* uniquely .
instead , it provides a potentially small and noisy set of input - output examples of f* .
in addition , examples on the meta - level may vary in length , since the number of training examples in a support set may vary .
in order to learn at the meta - level , more flexible encodings are needed than those that are typically studied in supervised learning .
the invariance network establishes one particular such encoding , which works only if the original function space f holds the invariance property .
the invariance network does not directly describe a hypothesis class - rather , it imposes shape constraints that , when incorporated into the training of the base - level recognizer , constrain its space of hypotheses .
the central question of this paper is whether learning can be made easier when the learner has already learned other related tasks .
will a system that is " trained " to learn generalize better than a novice learner ? this paper provides encouraging results in an object recognition domain .
however , most questions that arise in the context of lifelong learning still lack satisfactory , more general answers .
we expect that future research in this direction will be important to going beyond the intrinsic bounds associated with learning single isolated functions .
we thank astro teller for thoughtful comments on an earlier draft of this paper .
