human cognition rests on a unique talent for extracting generalizable knowledge from a few specic examples .
consider how a child might rst grasp the meaning of a common word , such as horse .
given several examples of horses labeled prominently by her parents , she is likely to make an inductive leap that goes far beyond the data observed .
she could now judge whether any new entity is a horse or not , and she would be mostly correct , except for the occasional donkey , deer or camel .
the ability to generalize from sparse data is crucial not only in learning word meanings , but in learning about the properties of objects , causeeffect relations , social rules , and many other domains of knowledge .
this article describes recent research that seeks to understand human inductive learning and reasoning in computational terms ( see also conceptual foundations editorial by chater , tenenbaum and yuille in this issue ) .
the goal is to build broadly applicable , quantitatively predictive models that approximate optimal in natural environments , and thereby explain why human generalization works the way it does and how it can succeed given such sparse data ( 123 , 123 ) .
our focus is theories ( 123 ) , characterizing the functional capacities of human inference rather than specic psychological processes that implement
most previous accounts of inductive generalization represent one of two approaches .
the rst focuses
corresponding author : tenenbaum , j .
( jbt@mit . edu ) .
on relatively domain - general , knowledge - independent statistical mechanisms of inference , based on similarity , association , correlation or other statistical metrics ( 123 , 123 123 ) .
this approach has led to successful mathematical models of human generalization in laboratory tasks , but fails to account for many important phenomena of learning and reasoning in complex , real - world domains , such as intuitive biology , intuitive physics or intuitive psychology .
the second approach aims to capture more of the richness of human inference , by appealing to sophisticated domain - specic knowledge representations , or intuitive theories ( 123 ) .
an intuitive theory may be thought of as a system of related concepts , together with a set of causal laws , structural constraints , or other explanatory principles , that guide inductive inference in a particular domain .
however , theory - based approaches to induction have been notoriously difcult to formalize , particularly in terms that make quantitative predictions about behavior or can be understood in terms of rational
we will argue for an alternative approach , where structured knowledge and statistical inference cooperate rather than compete , allowing us to build on the insights of both traditions .
we cast induction as a form of bayesian statistical inference over structured probabilistic models of the world .
these models can be seen as probabilistic intuitive theories ( 123 , 123 , 123 ) or schemas ( 123 , 123 ) , capturing the knowledge about a domain that enables inductive generalization from sparse data .
this approach has only become possible in recent years , as advances in articial intelligence ( 123 ) and statistics ( 123 ) have provided essential tools for formalizing intuitive theories and theory - based statistical inuence is bidirectional , as these bayesian cognitive models have led to new machine - learning algorithms with more powerful and more human - like capacities ( 123 , 123 ) .
theory - based bayesian models theory - based bayesian models of induction focus on three important questions : what is the content of probabilistic theories , how are they used to support rapid learning , and how can they themselves be learned ? the learner evaluates hypotheses h about some aspect of the world the meaning of a word , the extension of a property or category , or the presence of a hidden cause given observed data x and subject to the constraints of a
www . sciencedirect . com 123 - 123 / $ - see front matter q 123 elsevier ltd .
all rights reserved .
doi : 123 / j . tics . 123 . 123
trends in cognitive sciences vol . 123 no . 123 july 123
background theory t .
hypotheses are scored by computing posterior probabilities via bayes rule :
phjx; t z
h123ht pxjh123; tph123jt
the likelihood p ( xjh , t ) measures how well each hypothesis predicts the data , and the prior probability p ( hjt ) expresses the plausibility of the hypothesis given the learners background knowledge .
posterior probabil - ities p ( hjx , t ) are proportional to the product of these two terms , representing the learners degree of belief in each hypothesis given both the constraints of the background theory t and the observed data x ( see the technical introduction to this special issue by grifths and yuille for further background : supplementary material online ) adopting this bayesian framework is just the starting point for our cognitive models .
the challenge comes in specifying hypothesis spaces and probability distributions that support bayesian inference for a given task and domain .
in theory - based bayesian models , the domain theory plays this crucial role .
more formally , the domain theory t generates a space ht of candidate hypotheses , such as all possible meanings for a word , along with the priors p ( hjt ) and likelihoods p ( xjh , t ) .
prior probabilities and likelihoods are thus not simply statistical records of the learners previous observations , as in some bayesian analyses of perception and motor control ( 123 , 123 ) , or previous bayesian analyses of inductive reasoning ( 123 ) .
neither are they assumed to share a single universal structure across all domains , as in shepards pioneering bayesian analysis of generalization ( 123 ) .
rather , they are products of abstract systems of knowledge that go substantially beyond the learners direct experience of the world , and can take qualitatively different forms in different domains .
we will distinguish at least two different levels of knowledge in a theory ( figure 123 ) .
although intuitive theories may well be much richer than this picture suggests , we focus on the minimal aspects of theories needed to support inductive generalization .
the base level of a theory is a structured probabilistic model that denes a probability distribution over possible observables entities , properties , variables , events .
this model typically built on some kind of graph structure capturing relations between observables , such as a taxonomic hierarchy or a causal network , together with a set of numerical parameters .
the graph structure determines qualitative aspects of the probabilistic model; the numeri - cal parameters determine more ne - grained quantitative details .
at a higher level of knowledge are abstract principles that generate the class of structured models a learner may consider , such as the specication that a given domain is organized taxonomically or causally .
inference at all levels of this theory hierarchy ( figure 123 ) using theories to infer unobserved aspects of the data , learning structured models given the abstract domain principles of a theory , and learning the abstract domain principles themselves can be carried out in a unied and tractable way with hierarchical bayesian models ( 123 ) .
p ( principles |
abstract domain principles
p ( structure | principles )
structured probabilistic model
p ( data | structure )
trends in cognitive sciences
figure 123
a hierarchical bayesian framework for theory - based induction .
the learner observes data about the world ( e . g .
examples of objects that a word refers to ) and must predict other unobserved data ( e . g .
which other objects the word can refer to ) .
the learners intuitive theory generates hypotheses that can explain the observed data and that support the desired predictions .
the theory represents knowledge on at least two levels of abstraction : a structured probabilistic model generates expectations about the probability of possible data sets , while more abstract domain principles generate the space of possible structures that the learner may consider .
each level generates the hypotheses and probability distributions that support learning at the level below .
priors for abstract domain principles can come from multiple sources , including higher - level domain knowledge or domain - general conceptual resources .
the following sections describe theory - based bayesian models for several important inductive tasks , contrasting them with alternative approaches emphasizing either statistical learning or structured knowledge alone .
we begin with the task of learning words or category labels , and focus on the lowest level of inference : theory - based generalization .
then we illustrate the full hierarchical approach in two other domains , property induction and
learning names for things behavioral studies of human inductive generalization arguably began with the study of category learning ( 123 ) .
the basic experimental task presents learners with a set of objects or visual stimuli , and a verbal label ( e . g .
blicket ) that applies to a subset of the objects .
learners observe several examples of blickets , and perhaps negative examples ( non - blickets ) , and must then infer which other objects the label applies to .
these articial category - learning tasks abstract the essence of the problem children face in learning words for kinds of things , and formal models of category - learning and word - learning have developed in parallel .
they typically rely on bottom - up general - purpose statistical mechanisms , either explicitly probabilistic ( 123 , 123 ) or framed in terms of similarity or association ( 123 , 123 , 123 ) .
these models assume relatively simple notions of categories and how labels relate to categories : for instance ( 123 ) , each object belongs to a single category , and each label picks out a unique category , so each object receives exactly one label .
however , peoples representations of categories and word meanings are considerably more
trends in cognitive sciences vol . 123 no . 123 july 123
structured , reecting their intuitive domain theories .
the need for a more theory - based approach has often been pointed out ( 123 , 123 , 123 , 123 , 123 ) , but rarely pursued by
insights from both these traditions come together in a bayesian framework ( 123 ) .
in terms of equation 123 , hypotheses about the meaning of a novel label refer to subsets of objects candidate extensions for a words meaning or a category to be labeled .
abstract knowledge about category structure , word usage , and word - category mappings generates the priors and likelihoods for these hypotheses .
tenenbaum and xu ( 123 , 123 ) focus on learning names for object - kind concepts , which are typically organized into a tree - structured taxonomy with labels at various levels ( 123 , 123 ) .
accordingly , the hypothesis space of candidate word meanings consists of all subtrees in a tree - structured taxonomy of objects ( in figure 123a , subtrees correspond to basset hounds , dogs , animals , etc . ) .
other logically possible subsets of objects not corresponding to subtrees are effectively assigned zero ( or very low ) prior probability .
the prior can be further restricted to favor mappings of words onto basic - level categories ( 123 ) , or to disfavor mapping two words onto exactly the same concept
the likelihood embodies a pragmatic assumption that words will be used by a competent and cooperative speaker ( 123 ) , and that the objects labeled are a fair random sample from the set of objects that the word applies to .
these priors and likelihoods combine to explain how children generalize object labels from one or several examples .
figure 123b shows that generalization follows a gradient according to taxonomic distance , which sharpens up given multiple examples to focus on the most specic consistent taxonomic category : e . g .
basset hounds if the examples are all basset hounds , or dogs if the examples are all dogs but different kinds of dogs .
generalization along taxonomic contours derives from the tree - structured prior .
in principle , a prior could be dened over other representational structures , such as a euclidean space recovered from similarity judgments , as is common in similarity - based models ( 123 ) .
but to date , tree - structured priors have been the basis for the most accurate bayesian models of word - learning , consistent with a proposed taxonomic bias in childrens word learning ( 123 ) .
the sharpening of generalization with more examples derives from the likelihood : a single example is not highly diagnostic about the scope of the words extension ,
competent and cooperative speaker randomly sampled examples
123 basic 123 super .
figure 123
theory - based bayesian word learning .
( a ) learning words for object categories , from examples of objectlabel pairs .
objects are given unfamiliar labels to illustrate the problem faced by a child learner .
a tree - structured taxonomy of categories comprises the hypothesis space of word meanings : each node in the tree ( red dot ) is a possible extension of a word .
abstract principles constrain the structure of this hypothesis space , and generate the priors and likelihoods necessary to evaluate these hypotheses given data ( 123 ) .
( b ) comparison of the models predictions with 123 - year - old childrens patterns of generalization ( preliminary ndings from ( 123 ) ) .
for both children and the model , the probability of generalization decreases with taxonomic distance to the examples , and this gradient becomes sharper as more examples are observed .
see text for
trends in cognitive sciences
trends in cognitive sciences vol . 123 no . 123 july 123
but observing several examples drawn at random , it would be a highly suspicious coincidence for all examples to fall within a given taxonomic category ( e . g .
basset hounds ) if the word in fact had a much broader extension ( e . g .
dogs ) ,
the tendency for smaller , more specic hypotheses to be increasingly preferred over larger , more general hypotheses as more examples are observed is a general principle of bayesian learning when randomly sampled examples are assumed .
tenenbaum and grifths ( 123 ) referred to this as the size principle and showed how it could potentially explain a wide range of phenomena in category learning , generalization , and similarity judgment , which were not previously unied under a single rational - inference account .
the random - sampling assumption is not always valid , of course , and the size principle may be accordingly defeasible .
xu and tenen - baum ( unpublished data ) have found its effects are reduced or eliminated when word learners ( children or adults ) are given examples that are clearly not drawn as independent random samples .
this bayesian framework has been extended to learning other aspects of linguistic meaning , using differently structured hypothesis spaces appropriate for learning verb frames ( 123 ) , adjectives ( 123 ) , or anaphora resolution ( 123 ) .
there are also clear connec - tions to bayesian syntactic acquisition ( see chater and manning , this issue ( 123 ) ) .
these bayesian analyses have focused on learning at the bottom level of figure 123 learning about which words can refer to which entities , situations or properties .
future work should explore learning the higher - level knowledge that supports these inferences for instance , how people learn the principles that structure word - category mappings , or the relevant taxonomic tree of categories ( 123 , 123 , 123 ) .
the following section describes a closely related learning task where bayesian inferences at higher levels of figure 123 have been analyzed
reasoning about hidden properties many kinds of predicates may be true of a given entity .
some of these predicates correspond to category labels ( is a horse , is a sh ) but many correspond to properties , such as is brown , has a spleen , or can y .
property induction has been the subject of numerous behavioral experiments and formal models .
in a typical task , learners nd out that one or more categories have a novel property , and must decide how to extend the property to other categories in the domain .
for instance , subjects might be told that gorillas and lions carry a certain gene , and asked to judge how likely it is that monkeys also carry this gene ( 123 , 123 ) .
theory - based property induction the most systematic studies of property induction have used biological species and blank properties : properties like has the t123 gene that are unfamiliar but recognizably biological .
a tree - based bayesian model ( 123 ) similar to the tenenbaum and xu ( 123 ) word - learning model accounts well for judgments about blank biological properties .
the model assumes that species are organized into a
tree - structured taxonomy ( 123 ) , and that properties are generated by a mutation process over this tree ( figure 123a , left ) .
the mutation process generates a prior over candidate extensions of predicates that is more exible than traditional symbolic semantic hierarchies ( or the word - learning prior in ( 123 ) ) : properties that pick out a single subtree of the taxonomy are favored , but poly - phyletic properties ( those that arise independently in two or more subtrees ) are also allowed ( figure 123b ) .
this model approximates optimal inference for biological species and their properties , which are in fact generated by a stochastic branching process the process of evolution .
both the tree structure and some mutation - like process for generating property distributions seem to be important; bayesian models using a range of other priors have consistently correlated less well with peoples judgments
previous computational models for blank - property induction have used more generic knowledge represen - tations , such as pairwise similarities ( 123 ) or collections of features ( 123 ) .
in comparison with these models , theory - based approaches have clear advantages in explaining inferences about other kinds of predicates , where more specialized prior knowledge is involved .
qualitatively different patterns of generalization have been found for anatomical properties , behavioral properties and disease properties ( 123 , 123 , 123 ) .
to cite one classic example , given that poodles can bite through wire , it seems likely that german shepherds can bite through wire , but knowing that dobermans can bite through wire provides less support for the same conclusion about german shepherds ( 123 ) .
these inferences cannot rely on similarity , because german shepherds are more similar to dobermans than to poodles .
other inferences appear to rely on asymmetric causal relations : for example , a disease carried by salmon is more likely to be found in grizzly bears than vice
bayesian models can account for these different patterns of generalization by using different priors ( 123 ) .
in terms of figure 123 , inferences about different kinds of observable predicates are based on different kinds of structured probabilistic models , which are in turn governed by different abstract domain principles .
several examples are shown in figure 123a .
in each case , the taxonomic tree structure and the mutation process of the default model are replaced by a differently structured graph and a different kind of stochastic process over that structure .
for inferences about disease predicates ( e . g .
carries leptospirosis ) , the prior is generated by a noisy transmission process over a directed food - web network ( figure 123a , middle ) .
this prior captures the asymmetry of generalizations in this domain that a prey species is more likely to share a disease with its predators than vice versa and accurately predicts peoples inductive judg - ments about disease predicates ( figure 123c ) .
a predicate like can bite through wire or weighs more than an anvil corresponds to an unknown threshold along some known dimension ( e . g .
strength or size ) .
a linearly ordered graph can represent the relevant dimension , and judgments threshold predicates ( 123 , 123 ) can be modeled
trends in cognitive sciences vol . 123 no . 123 july 123
has the t123 gene
weighs more than an anvil
drift process + threshold
trends in cognitive sciences
figure 123
theory - based bayesian property induction .
( a ) three models for property induction : a taxonomic model ( left ) , a food - web model ( centre ) and a dimensional - threshold model ( right ) .
each model assumes that properties are generated by a different probabilistic process over a different kind of graph structure , and each model is appropriate for a different kind of property .
in the taxonomic model , properties are generated by a mutation process : there is a small probability of a property appearing at any point along any branch of the tree .
in the food - web model , properties are generated by a causal transmission process : there is a small probability of a property arising spontaneously in any species , and a high probability of transmitting that property from the species to each of its predators .
in the dimensional - threshold model , properties are generated by a random - drift process biased such that species towards one end of the dimension are increasingly likely to have the novel property .
the data level of the gure shows properties with high prior probability under each of these models : e . g .
the dimensional - threshold model favors hypotheses that include all species beyond some point in the linear order .
( b ) three possible outcomes if a property is generated by the taxonomic model , shown in order of decreasing prior probability : properties are most likely if they can be explained by a small number of mutations , and if those mutations occur on long branches .
( c ) the importance of domain theories in bayesian models of property induction is illustrated by a double dissociation in model predictions for two different kinds of properties ( preliminary ndings from ( 123 ) ) .
participants learned both a taxonomy and a food web over a set of species and were asked to make inductive judgments about either genetic or disease properties .
the bayesian taxonomic model correlated strongly with judgments for genetic properties but not disease properties , and vice versa for the bayesian food - web model .
assuming a prior generated by a random drift process over that graph ( figure 123a , right ) .
learning theories to support property induction if differently structured theories are necessary to account for inferences about different kinds of predicates , becomes even more pressing to explain how these theories could be acquired .
bayesian approaches can address this question at all levels of the theory hierarchy in figure 123 , and we illustrate by showing how the taxonomic theory might be acquired ( figure 123 ) .
first , consider the problem of learning the tree structure given raw observable data , in the form of a large collection of species - property pairs ( e . g .
lions have sharp teeth , chimps have hair , etc . ) .
there are many different ways to organize species into a tree
( figure 123a ) , but we can search for the tree that maximizes the likelihood p ( datajstructure ) for the dataset of observed properties ( 123 , 123 ) .
intuitively , the best choice allows features to vary smoothly over the tree : for example , because gorillas and monkeys share many properties , these species should be located nearby in
this approach to learning a structured probabilistic model relies crucially on abstract knowledge at the highest level in figure 123 : a taxonomic principle specifying that living kinds should be represented by a tree structure .
could such an abstract domain principle itself by acquired ? abstract knowledge of this sort is often thought to be innate ( 123 , 123 ) , perhaps because it seems so remote from the data of experience .
given an appropriate hypothesis space ,
trends in cognitive sciences vol . 123 no . 123 july 123
trends in cognitive sciences
figure 123
learning a theory for how biological properties are distributed over species .
( a ) given abstract domain knowledge that species should be organized in a taxonomic tree , with properties varying smoothly over that tree , a bayesian learner can infer the tree structure that best explains a set of observed properties .
two ways to organize animal species into a taxonomy are shown .
the preferred structure will be the tree over which observed properties vary most smoothly .
( b ) animal species may be organized according to various different structural principles , such as the three shown here .
bayesian inference in the hierarchical framework of figure 123 can select the organizing principles best supported by a set of observed properties .
however , bayesian inference can account for knowledge acquisition at any level of abstraction .
suppose that the learner has access to a repertoire of different structural forms that includes taxonomic trees as well as other basic alternatives , such as one - dimensional orders and disjoint clusters ( figure 123b ) .
choosing the best form involves a trade - off between complexity and t to the data , which can be formalized in terms of the hierarchical bayesian framework of figure 123
kemp et al .
( 123 ) showed that under this trade - off , the judged properties of biological species are better accounted for by trees than either linear orders or clusters .
in summary , the hierarchical bayesian framework of figure 123 supports a unied learning model that takes as input data a collection of species - property pairs , and subsequently discovers the taxonomic principle , discovers the best tree structure for the species in the dataset , and makes predictions about how to generalize new , sparsely observed properties .
it thus explains how the theory in figure 123a ( left ) might be discovered from raw data , and likewise could explain the origins of hypothesis spaces and inductive biases for word learning in young children discussed in the previous section .
theories can also be acquired through other processes , such as explicit instruction; for example , food - web relations are typically learned that way .
unlike similarity - based accounts of property induction , a hierarchical bayesian approach naturally accommodates explicit instructions at any level of abstraction , as children typically receive from parents or in school : for example , dolphins breath air ( at the level of observable data ) , dolphins are mammals ( at the level of structure ) , and living things can be organized into a tree ( at the level of abstract principles ) .
this approach could explain how hearing a single statement about domain structure ( e . g .
dolphins are mammals ) might lead to dramatic changes in inferences about
causal learning and reasoning the role of intuitive theories in learning and reasoning has been most prominently studied in the context of causal
cognition ( 123 , 123 , 123 , 123 ) .
for many authors , causality is central to the notion of a theory .
carey , for instance , suggests that a theory comprises a set of phenomena that are in its domain , the causal laws and other explanatory mechanisms in terms of which the phenomena are accounted for , and the concepts in terms of which the phenomena and explanatory apparatus are expressed ( ( 123 ) , p .
the hierarchical bayesian framework of figure 123 gives a unied account of inference at all these levels , suggesting how causal models can be used to predict and explain observable events , how domain - specic principles guide construction of these models , and how that abstract domain knowledge could itself
at the lowest level of the hierarchy are inferences about variables characterizing observable events .
for instance , a doctor might observe certain aspects of a patients state , such as symptoms and risk factors , and want to predict others , such as diseases or future symptoms .
these tasks have often been viewed as bottom - up statistical inferences ( 123 , 123 ) , but there is evidence to suggest that these predictions are often driven by causal knowledge ( 123 ) .
recent work has tried to explain the relevant knowledge and inferences in rational terms using the formalism of causal graphical models ( 123 , 123 ) .
these models constitute a particular kind of structured probabilistic model at the middle level of figure 123
for example , figure 123a shows a causal model that could be used to make inferences about the diseases of patients based on their symptoms and risk factors .
theory - based induction of causal structure many recent studies have examined how people learn these causal models .
again there have been both bottom - up and top - down proposals .
bottom - up approaches detect statistical cues to causal structure , such as contingency between variables ( 123 ) , normalized probabilistic contrast ( 123 ) , or partial correlations ( 123 ) .
these cues , when they can be detected reliably , allow causal structure to be learned for any kinds of variables , without substantive prior knowledge .
however , both adults and young children
trends in cognitive sciences vol . 123 no . 123 july 123
classes : ( r , d , s ) ( risks , diseases , symptoms ) causal laws : r d , d s
objects can activate machines activation requires contact machines are ( near ) deterministic
working in factory
classes : ( r , d , s ) causal laws : r d , d s
causal laws : c c
classes : ( r , d , s ) causal laws : d r , s s
trends in cognitive sciences
figure 123
theory - based bayesian causal induction .
abstract causal principles constrain the causal structures that may be learned to capture dependencies among observable variables .
( a ) abstract knowledge in a simple medical domain can be represented using a graph schema , a probabilistic generative grammar for graphs .
variables fall into three classes risk factors , diseases , and symptoms with causal inuences only from risks to diseases and diseases to symptoms .
given a newly observed correlation ( e . g .
between working in a factory and chronic chest pain ) , the graph schema generates a constrained set of hypotheses for how that data might be explained ( shown in red ) .
in the simplest hypotheses , a disease known to be caused by working in a factory might cause chest pain , or a disease known to cause chest pain might actually be produced by working in a factory .
failing these possibilities , the learner could posit a new disease x , which has chest pain as a symptom and is caused by working in a factory .
other hypotheses that may be simpler a priori but which violate the theory would never be considered , such as a direct causal link from working in a factory to chest pain , or from chest pain to working in a factory .
( b ) the abstract knowledge that supports causal learning in a simple physical system , the blicket detector ( 123 , 123 ) , can be formalized using probabilistic predicate logic ( 123 , 123 ) .
the theory includes several principles : there is some probability r that any object has the power to activate the machine; an efcacious object will activate the machine upon contact with probability near 123; activation has no other causes .
possible causal relations , given a sequence of interactions between blocks and the machine , are shown in red .
in a context in which most objects have failed to activate the machine ( r is small ) , both people and the theory - based bayesian model infer that object a probably activates the machine , whereas b and c probably do not ( 123 , 123 ) .
( c ) the innite relational model ( 123 ) supports a hierarchical bayesian approach to learning simple forms of abstract causal theories .
graph schemas with different numbers of classes and appropriately dened causal laws can be inferred to explain different kinds of causal network structures that a learner might encounter .
frequently make correct inferences about causal structure from just a handful of observations , far too few to compute contingency or correlation reliably .
these inferences must be supported by more abstract prior knowledge , such as knowledge about the kinds of causal mechanisms or structures in a domain , which has been the focus of most top - down approaches to causal learning ( 123 ) .
the theory - based bayesian framework once again provides the means to integrate bottom - up and top - down inuences .
in terms of figure 123 , p ( datajstructure ) measures the likelihood for a particular causal model how well that causal structure explains the observed pattern of events .
p ( structurejprinciples ) measures the causal models prior probability how well it ts with the learners abstract domain knowledge .
the best causal model maximizes the product of these two probabilities .
if a causal model represents the most basic kind of causal theory ( 123 , 123 ) , the abstract domain knowledge that
trends in cognitive sciences vol . 123 no . 123 july 123
allows these models to be learned can be thought of as a higher - level theory a theory for theories .
cognitive developmentalists ( 123 ) have often emphasized the import - ance of larger - scale framework theories , which constrain the specic theories a learner considers , but they have not been treated computationally .
the concept of probabilistic models for structured representations is well - developed in computational linguistics ( 123 ) , where abstract syntactic principles may be formalized in terms of probabilistic grammars that generate admissible syntactic structures in a language with varying probabilities .
several proposals for formalizing abstract causal theories have been inspired by this linguistic analogy ( 123 ) .
these causal grammars ( 123 ) share the idea of generating causal graphical models based on an ontology , which identies the types of entities in a domain and the predicates that can apply to them , and a set of causal laws , which specify the form of allowed causal relationships between predicates .
loosely speaking , the ontology generates the variables that appear in causal graphical models , and the causal laws generate the edges and associated
figure 123 sketches two examples of this approach to induction ( 123 , 123 ) .
first , consider learning a causal network relating risk factors , diseases , and symptoms , given data on patients states .
the task is greatly simplied by an ontology that divides the variables into three classes diseases , symptoms , and risk factors and causal laws dened over that ontology , specifying that direct inuences only exist between risk factors and diseases , and between diseases and symptoms .
these principles can be formalized using a kind of probabilistic graph grammar that ( 123 ) call a graph schema .
the grammar places strong constraints on the causal structures a learner must consider , and thus allows strong inferences about causal structure to be drawn from sparse data ( figure 123a ) .
second , consider recent studies exploring theory - based causal learning using simple physical systems such as the blicket detector ( 123 , 123 , 123 ) .
learners are shown a number of objects , along with a machine that activates ( lights up and makes noise ) whenever certain blocks are placed on it .
after observing several in which various combinations of objects are placed on the machine , participants are asked which objects have the hidden causal power to activate the machine .
figure 123b shows how these judgments can be modeled as theory - based bayesian inferences guided by several domain principles , such as the activation law : the machine activates if and only if it is in contact with an object that has the hidden causal power .
this theory can be cast more formally in probabilistic predicate logic ( 123 ) .
unlike bottom - up approaches to causal learning , this account naturally explains many ndings where adults and young children make correct inferences from just a few trials , even for objects that have never appeared on the machine alone ( 123 , 123 ) .
this general framework for theory - based causal induction has been used to model how people learn more complex physical systems with hidden variables and dynamic causes ( 123 ) , and how people choose optimal experiments to perform in causal learning ( 123 ) .
learning abstract causal theories the question of how abstract causal principles , or frame - work theories , might themselves be learned is a major open question in both articial intelligence and cognitive development .
for some simple kinds of framework know - ledge , such as the probabilistic graph grammars discussed above , it is possible to formulate the learning problem as a bayesian inference that can be approximated with tractable search algorithms .
the innite relational model ( irm ) ( 123 ) assumes that variables come in one or more classes , with relations between them depending on these classes .
the model can be used to infer the number of classes , which variables are in which classes , and what kinds of relationships hold between classes , directly from data ( figure 123c ) .
this approach is capable of learning the abstract principles of the disease theory shown in figure 123a , but not the richer theories based on probabi - listic predicate logic needed to explain inferences in some other systems such as the blicket detector ( figure 123b ) .
several methods for learning in probabilistic logical systems have recently been introduced in articial intelligence ( 123 , 123 ) , however , and these methods could provide the basis for more powerful models of human
the theory - based bayesian framework provides a formal means to address several fundamental questions about human cognition .
what is the content and form of human knowledge , at multiple levels of abstraction ? how can abstract domain knowledge guide learning of new concepts ? how can abstract domain knowledge be learned ? what conceptual resources must be built in innately ? how do mechanisms of statistical learning and
questions for future research how might theory - based bayesian models apply to other aspects of cognition where structured knowledge and inductive inference appear to interact , such as intuitive physics , intuitive psychology , or can bayesian models of concept learning and word learning be integrated with bayesian models of syntactic acquisition ( 123 ) to give a unied approach to language development ? how do bayesian models of inductive inference relate to probabilistic models of ( apparently ) deductive thinking , such as hypothesis testing or syllogistic reasoning ( 123 ) ? could a hierarchical bayesian approach provide insight into other functions of intuitive theories besides induction , such as analogy or like other theoretical paradigms , the bayesian approach is not meant to be falsiable in the same sense that a specic compu - tational model should be; it should be judged in terms of whether it leads to specic models with explanatory value across a range of different data sets .
what aspects of intuitive theories and theory - based inference will prove difcult to explain from a bayesian view ? how could bayesian approaches to induction considered here strictly at the level of computational theory ( 123 ) be implemented with tractable algorithms ? how can they can be reconciled with psychological processes that have sometimes looked dramatically inconsistent with bayesian principles ( 123 ) ? philosophers of science and developmental psychologists have often exchanged ideas about the structure , function , and origins of theories .
can we build hierarchical bayesian models of scientic theories analogous to our models of intuitive theories ?
trends in cognitive sciences vol . 123 no . 123 july 123
inference interact with and operate over structured symbolic knowledge ? traditionally , accounts that aim to explain a broad spectrum of human cognition have focused exclusively on either sophisticated inference processes or sophisticated knowledge represen - tations .
our view embraces both , and highlights
it is far too soon to say what a mature computational theory of inductive learning and reasoning will look like .
the real - world problems that children and adults face are still well beyond the scope of our models , and issues of algorithmic and psychological plausibility will have to be addressed ( see box 123 , and editorial where next ? in this issue ) .
yet as future work on induction unfolds , one idea should play a crucial role in any explanatory account : probabilistic inference over hierarchies of increasingly abstract , exibly structured representations of the world .
we thank the current and past members of the computational cognitive science group at mit for innumerable discussions of the work described here .
we owe particular debts to fei xu , patrick shafto , and sourabh niyogi , who have collaborated closely on the projects described here .
we acknowledge support from ntt communication sciences laboratories , mitsubishi electric research labs , the national science foundation , the james s .
mcdonnell foundation causal learning collaborative , the paul e .
newton career development chair ( j . b . t . ) , the stanford graduate fellowships ( t . l . g . ) , and the william asbjornsen albert memorial graduate fellowship ( c . k . ) .
supplementary data associated with this article can be found at doi : 123 / j . tics . 123 . 123
