in many situations human behavior approximates that of a bayesian ideal observer , suggesting that , at some level , cog - nition can be described as bayesian inference .
however , a number of ndings have highlighted an intriguing mismatch between human behavior and that predicted by bayesian infer - ence : people often appear to make judgments based on a few samples from a probability distribution , rather than the full dis - tribution .
although sample - based approximations are a com - mon implementation of bayesian inference , the very limited number of samples used by humans seems to be insufcient to approximate the required probability distributions .
here we consider this discrepancy in the broader framework of statis - tical decision theory , and ask : if people were making deci - sions based on samples , but samples were costly , how many samples should people use ? we nd that under reasonable as - sumptions about how long it takes to produce a sample , locally suboptimal decisions based on few samples are globally op - timal .
these results reconcile a large body of work showing sampling , or probability - matching , behavior with the hypoth - esis that human cognition is well described as bayesian in - ference , and suggest promising future directions for studies of keywords : computational modeling; bayesian models; pro - cess models; sampling
across a wide range of tasks , people seem to act in a man - ner consistent with optimal bayesian models ( in perception : knill & richards , 123; motor action : maloney , trommer - shauser , & landy , 123; language : chater & manning , 123; decision making : mckenzie , 123; causal judgments : grif - ths & tenenbaum , 123; and concept learning : goodman , tenenbaum , feldman , & grifths , 123 ) .
however , despite this similarity between bayesian ideal observers and human observers , two crucial problems remain unaddressed across these domains .
first , human behavior often appears to be optimal on average , but not within individual people or in - dividual trials : what are people doing on individual trails to produce optimal behavior in the long - run average ? sec - ond , bayesian inference is straight - forward when considering small laboratory tasks , but intractable for large - scale prob - lems like those that people face in the real world : how can people be carrying out generally intractable bayesian calcu - lations in real - world tasks ? here we will argue that both of these problems can be resolved by considering the algorithms that people may be using to approximate bayesian inference .
the rst problem is highlighted by an intriguing observa - tion from goodman et al .
( 123 ) about performance in cat - egorization tasks in which people see positive and negative exemplars of a category and are then asked to generalize any
joshua b .
tenenbaum ( jbt@mit . edu ) brain and cognitive science , 123 vassar st
cambridge , ma 123 usa
learned rules to new test items .
after exposure to several cat - egory exemplars people classify new test items consistently with fully bayesian inference , on average .
this average be - havior suggests that people consider many possible classica - tion rules , update their beliefs about each one , and then clas - sify new items by averaging the classication over all the pos - sible rules .
however , this perfectly bayesian behavior is only evident in the average across many observers .
each individual classies all test items in a manner consis - tent with only one or a few rules; which rules are considered varies from observer to observer according to the appropri - ate posterior probabilities ( goodman et al . , 123 ) .
thus , it seems that an individual observer acts based on just one or a few rules sampled from the posterior distribution , and the fully bayesian behavior only emerges when averaging many individuals , each with different sampled rules .
this sampling behavior is not limited to concept - learning tasks .
in many other high - level cognitive tasks , individuals patterns of response and sometimes even responses on indi - vidual trials appear to reect just a small number of samples from the posterior predictive distribution .
when predicting how long a cake will bake given that it has been in the oven for 123 minutes ( grifths & tenenbaum , 123 ) , the across - subject variance of responses is consistent with individuals guessing based on only two prior observations of cake baking times ( mozer , pashler , & homaei , 123 ) .
when making estimates of esoteric quantities in the world , multiple guesses from one individual have independent error , like samples from a proba - bility distribution ( vul & pashler , 123 ) .
in all of these cases ( and others; e . g . , xu & tenenbaum , 123; anderson , 123; sanborn & grifths , 123 ) , people seem to sample instead of computing the fully bayesian answer .
critics of the bayesian approach ( e . g . , mozer et al . , 123 ) have suggested that although many samples may adequately approximate bayesian inference , behavior based on only a few samples is fundamentally inconsistent with the hypoth - esis that human cognition is bayesian .
others highlight the second problem and argue that cognition cannot be bayesian inference because exact bayesian calculations are computa - tionally intractable ( e . g . , gigerenzer , 123 ) .
in this paper we will argue that acting based on a few sam - ples can be easily reconciled with optimal bayesian infer - ence and may be the method by which people approximate otherwise intractable bayesian calculations .
we argue that ( a ) sampling behavior can be understood in terms of sensible
sampling - based approaches to approximating intractable in - ference problems in bayesian statistics and ai; ( b ) very few samples from the bayesian posterior are often sufcient to obtain approximate predictions that are almost as good as pre - dictions computed using the full posterior; and ( c ) on conser - vative assumptions about how much time it might cost to pro - duce a sample from the posterior , making predictions based on very few samples ( even just one ) , can actually be the glob - ally optimal strategy .
bayesian inference with samples
bayesian probability theory prescribes a normative method to combine information and make inferences about the world .
however , the claim that human cognition can be described as bayesian inference does not imply that people are doing exact bayesian inference .
exact bayesian inference amounts to fully enumerating hypothesis spaces every time beliefs are updated with new data .
in any large - scale application , this is computationally intractable , so inference must be approximate .
this is the case in bayesian articial intelligence and statistics , and this must apply even more in human cognition , where the real - world inferences are vastly more complex and responses are time - sensitive .
the need for approximating bayesian in - ference leaves two important questions .
for articial intelli - gence and statistics : what kinds of approximation methods work best to approximate bayesian inference ? for cognitive science and psychology : what kinds of approximation meth - ods does the human mind use ?
in the tradition of rational analysis , or marrs computa - tional approach ( marr , 123 ) , a reasonable strategy to an - swering the psychological question begins with good answers to the engineering question .
thus , we will explore the hy - pothesis that the human mind approximates bayesian infer - ence with some version of the algorithmic strategies that have proven best in ai and statistics , on the grounds of computa - tional efciency and accuracy .
in articial intelligence and statistics , one of the most com - mon methods for implementing bayesian inference is with inference by sampling is a procedure to approximate a probability distribution by repeat - edly simulating a simpler stochastic process which produces alternatives from a hypothesis space according to their proba - bility under the distribution in question .
the result of any one such simulation is a sample .
with sufciently many samples , these calculations based on these approximations approach the exact calculations using the analytical probability distri - butions themselves123
sampling methods are typically used because they are applicable to a large range of computational
123the monte carlo theorem states that the expectation over a
probability distribution can be approximated from samples :
ep ( s ) ( f ( s ) ) ( cid : 123 ) 123
f ( si ) , when si p ( s ) .
models and are more robust to increasing dimensionality than other approximate methods .
many cognitively plausible sampling algorithms exist and some specic ones have been proposed to account for aspects of human behavior ( grifths , canini , sanborn , & navarro , 123; levy , reali , & grifths , 123; brown & steyvers , 123 ) .
for our purposes , we need only assume that a per - son has the ability to draw samples from the hypothesis space according to the posterior probability distribution .
thus , it is reasonable to suppose that people can approximate bayesian inference via a sampling algorithm , and evidence that humans make decisions by sampling is not in conict with the hypoth - esis that the computations they are carrying out are bayesian .
however , recent work suggests that people base their deci - sions on very few samples ( vul & pashler , 123; goodman et al . , 123; mozer et al . , 123 ) so few that any claims of convergence to the real probability distribution do not hold .
algorithms using only two samples ( mozer et al . , 123 ) will have properties quite different from full bayesian integration .
this leaves us with the question : how bad are decisions based on few samples ?
bayesian and sample - based agents
to address the quality of decisions based on few samples , we will consider performance of optimal ( fully bayesian ) and sample - based agents in the common scenario of choos - ing between two alternatives .
many experimental tasks in psychology are a variant of this problem : given everything learned , make a two - alternative forced - choice ( 123afc ) re - sponse .
moreover , real - world tasks often collapse onto such simple 123afc decisions , for instance : we must decide whether to drive to the airport via the bridge or the tunnel , depend - ing on which route is likely to have least trafc .
although this decision will be informed by prior experiences that pro - duced intricate cognitive representations of possible trafc ow , at one particular junction these complex representations collapse onto a prediction about a binary variable and deci - sion : should we turn left or right ?
statistical decision theory ( berger , 123 ) prescribes how information and beliefs about the world and possible rewards should be combined to dene a probability distribution over possible payoffs for each available action ( maloney , 123; kording , 123; yuille & bulthoff , 123 ) .
an agent trying to maximize payoffs over many decisions should use these normative rules to determine the expected payoff of each ac - tion , and choose the action with the greatest expected payoff123
thus , the standard for decisions in statistical decision theory is to choose the action ( a ) that will maximize expected util - ity under the posterior predictive distribution over possible world states ( s ) given prior data ( d ) , assuming that action and state uniquely determine the utility obtained :
a = argmax
123an agent might have other goals , e . g . , maximizing the mini - mum possible payoff ( i . e . , extreme risk aversion ) ; however , we will not consider situations in which such goals are likely .
if the world state is sufciently specied , 123afc decisions map onto a prediction about which of two actions ( a123 and a123 ) will have higher expected utility for instance : will we spend less time in trafc taking the bridge or the tunnel ? there - fore , choosing among two alternatives amounts to predicting the outcome of a bernoulli trial : will a123 or a123 have greater utility ? thus , p ( a = a123 ) p and p ( a = a123 ) ( 123 p ) , and we can simply parameterize these decisions in terms of the posterior predictive probability p .
for simplicity , we will consider choosing the higher - utility action a correct choice , and choosing the lower - utility action an incorrect choice .
the fully bayesian agent will choose the more likely alterna - tive , and will be correct p proportion of the time ( we assume p is between 123 and 123 , given symmetry ) .
a sample - based agent would sample possible world states , and make decisions based on those sampled world states ( sn ) :
a = argmax
so in the case of making predictions between two alterna - tives one of which may be correct , the sample - based agent should choose the action corresponding to the most frequent outcome in the set of sampled world states .
thus , a sample - based agent drawing k samples will choose a particular out - come with probability q :
q = 123 cdf (
where cdf is the binomial cumulative density function and k / 123 is rounded down to the nearest integer .
this sample - based agent will be right with probability qp+ ( 123q ) ( 123 p ) .
good decisions from few samples
figure 123 : increased error rate for the sample - based agent over the optimal agent as a function of the bernoulli trial probability and the number of samples drawn for a decision ( decisions based on 123 samples not shown ) .
so , how much worse will such 123afc decisions be if they are based on a few samples rather than the fully bayesian
inference ? bernoulli estimated that more than 123 , 123 sam - ples are required for moral certainty about the true proba - bility of a two - alternative event123 ( stigler , 123 ) .
although bernoullis calculations were based on different derivations than those which are now accepted ( stigler , 123 ) , it is un - deniable that inference based on a small number of samples differs from the fully bayesian solution and will contain greater errors , but how bad are the decisions based on this
in figure 123 we plot the difference in error rates between the sample - based and optimal agents as a function of the un - derlying probability ( p ) and number of samples ( k ) .
when p is near 123 , there is no use in obtaining any samples ( since a perfectly informed decision will be as likely to be correct as a random guess ) .
when p is 123 ( or close ) , there is much to be gained from a single sample since that one sample will indi - cate the ( nearly - deterministically correct ) answer; however , subsequent samples are of little use , since the rst one will provide all the gain there is to be had .
most of the benet of large numbers of samples occurs in interim probability values ( around 123 and lower ) .
figure 123 : ( a ) the maximum and expected increase in error for the sample - based agent compared to the optimal agent as a function of number of samples ( see text ) .
( b ) expected and maximum gain in accuracy from an additional sample as a function of the number of samples already obtained .
since the sample - based agent does not know what the true probability p may be for a particular decision we can consider the scenarios such an agent should expect : the average sce - nario ( expectation over p ) and the worst case scenario ( maxi - mization of the loss over p ) .
these are displayed in figure 123a assuming a uniform probability distribution over p .
the devi - ation from optimal performance decreases to negligible lev - els with very few samples , suggesting that the sample - based agent need not have more than a few samples to approximate ideal performance .
we can go further to assess just how much is gained ( in terms of decreased error rate ) from an additional sample ( figure 123b ) .
again , the vast majority of accuracy is gained with the rst sample , and subsequent samples do very little to improve performance .
thus , even though few samples will not provide a very ac - curate estimate of p denitely not sufcient to have moral
123bernoulli considered moral certainty to be at least 123 : 123 odds
that the true ratio will be within 123
123 of the measured ratio .
figure 123 : expected utility per decision , the number of decisions that can be made per unit time , and the expected rate of return ( utility per unit time ) as a function of the bernoulli probability and the number of samples ( with an example action / sample cost ratio of 123 ) .
certainty they are sufcient to choose an action : we do not need moral certainty to act optimally .
how many samples for a decision ?
lets take seriously the hypothesis that people make infer - ences based on samples .
if this is the case , how many sam - ples should people use before making a decision ? for in - stance , how many possible arrangements of trafc across the city should we consider before deciding whether to turn left for the tunnel or right for the bridge ? considering one such possibility requires concerted thought and effort it seems obvious that we should not pause at the intersection for sev - eral hours and enumerate all the possibilities .
it also seems likely that we shouldnt just turn left or right at random with - out any consideration .
so , how many samples should we take : how hard should we think ?
determining an optimal answer to this meta - cognitive problem requires that we specify how much a sample may cost ? to be conservative ( and for the sake of simplicity ) , we will assume that a sample can only cost time it takes some amount of time to conjure up an alternate outcome , pre - dict its value , and update a decision variable .
thus , if a given sample is free ( costs 123 time ) , then we should take innitely many samples , and make the best de - cision possible every time .
if a sample costs 123 unit of time , and the action time ( the time that it would take us to act once we have chosen to do so ) is also 123 unit of time , then we should take zero samples we should guess randomly .
to make this peculiar result intuitive , lets be concrete : if we have 123 sec - onds , and the action time is xed to be 123 second , then we can make 123 random decisions , which will be right 123% of the time , thus giving us an expected reward of $123
if taking a single sample to improve our decision will cost an additional second per decision , then if we take one sample per decision , each decision will take 123 seconds , and we could make at most 123 of them .
it is impossible for the expected reward from this strategy to be greater than guessing randomly , since even if 123% of the decisions are correct , only $123 will be gained .
moreover , since 123% accuracy based on one sample is ex - tremely unlikely ( this could only arise in a completely deter -
ministic prediction task ) , substantially less reward should be expected .
thus , if obtaining a sample takes as long as the action , and we do not get punished for an incorrect answer , we should draw zero samples per decision and make as many random decisions as we can .
more generally , we can param - eterize how much a sample costs as the ratio between the time required to make an action and the time required to ob - tain one sample ( action / sample ratio ) intuitively , a measure of how many samples it would take to double the time spent on a decision .
the expected accuracy for a sample - based agent ( previous section ) gives us the expected utility per decision as a func - tion of k ( the number of samples ) and p ( the bernoulli trial probability; figure 123a ) , and the utility function .
we consider two utility functions for the 123afc case : no punishment cor - rect : gain 123; incorrect lose 123 ) and symmetric correct : gain 123; incorrect : lose 123
given one particular action / sample time ratio , we can compute the number of decisions made per unit time ( figure 123b ) .
multiplying these two functions together yields the expected utility per unit time ( figure 123c ) .
since p is unknown to the agent , an ideal k must be cho - sen by taking the expectation over p .
this marginalization ( assuming a uniform distribution over p ) for many different action / sample time ratios is displayed in figure 123
it is clear that as samples become cheaper , one is best advised to take more of them converging to the limit of innitely many sam - ples when the samples are free ( the action / sample time ratio
in figure 123 we plot the optimal number of samples as a function of the action / sample time ratio .
remarkably , for ratios less than 123 , one is best advised to make decisions based on only one sample if the utility function is symmet - ric .
moreover , with no punishment for incorrect answers , the action / sample time ratio must be 123 or greater before taking any samples ( making a guess thats at all educated , rather than fully random ) becomes a prudent course of action .
thus , un - der some assumptions about how much it costs to think , mak - ing guesses based on very few samples ( e . g . , one ) is the best course of action : making many locally suboptimal decisions quickly is the globally optimal strategy .
figure 123 : expected utility per decision , number of decisions per unit time , and expected utility per unit time ( rate of return ) as a function of the number of samples and action / sample cost ratios .
action / sample cost ratios are logarithmically spaced between 123 ( red ) and 123 ( yellow ) .
in the last graph the solid circles indicate the optimal number of samples at that action / sample cost ratio .
( the utility function used for this gure contained no punishment for an incorrect choice and +123 for a correct choice . )
distribution .
moreover , we showed that given reasonable as - sumptions about the time it takes to produce an exact sample , a policy of making decisions based on very few samples ( even just one ) is globally optimal , maximizing long - run utility .
in this paper we considered sample - based decisions about predictions of variables that had not been previously observed predictions computed through bayesian inference over la - tent variables and structures in the world .
however , a large prior literature on probability matching ( herrnstein , 123; vulkan , 123 ) has studied a very similar phenomenon in a in probability matching , subjects predict the outcome of a trial based on the relative frequencies with which that outcome has been observed in the past .
thus , sub - jects have direct evidence of the probability that lever a or lever b should be pulled , but they do not seem to maximize; instead , they probability match and choose levers with a frequency proportional to the probability of reward .
on our account , this literal probability matching behavior amounts to making decisions based on one sample , while decisions based on more samples would correspond to luce choice de - cisions with an exponent greater than 123 ( luce , 123 ) .
probability matching to previously observed frequencies is naturally interpreted as sampling prior events from mem - ory .
this interpretation is consistent with recent work sug - gesting that people make decisions based on samples from memory .
stewart , chater , and brown ( 123 ) suggested that a policy of making decisions through binary preference judg - ments among alternatives sampled from memory can ac - count for an assortment of human judgment and decision - making errors .
similarly , schneider , oppenheimer , and detre ( 123 ) suggest that votes from sampled orientations in multi - dimensional preference space can account for violations of coherent normative utility judgments .
a promising direction for future research would be to relate models suggesting that samples are drawn from cognitive processes such as memory , to models like those we have described in our paper , in which samples are drawn from probability distributions reecting
figure 123 : the optimal number of samples as a function of the ac - tion / sample time - cost ratio for each of two utility functions ( sym - metric correct : +123 , incorrect : - 123; and no punishment for incorrect answers correct : +123 , incorrect : 123 ) .
we began with the observation that , on average , people tend to act consistently with ideal bayesian inference , integrating information to optimally build models of the world; however , locally , they appear to be systematically suboptimal , acting based on a very limited number of samples .
this has been used to argue that people are not fully bayesian ( mozer et instead , we have argued that sample - based ap - proximations are a powerful method for implementing ap - proximate bayesian inference .
although with few samples , sample - based inferences will deviate from exact bayesian inference , we showed that for two - alternative forced - choice tasks , a decision based on a very small set of samples is nearly as good as an optimal decision based on a full probability
ideal inferences about the world .
how much might a sample cost ? a relevant measure of sample cost in multiple - trial experiments is the ratio between the time it takes to make an action and go on to the next trial and the time required to draw a sample to inform a decision about that action .
ratios near 123 seem quite reasonable : most experimental trials last a few seconds , and it can arguably cost a few hundred milliseconds to consider a hypothesis .
of course , this is speculation .
however , in general , it seems to us that in most experimental tasks , the benets gained from a better decision are relatively small compared to the costs of spending a very long time thinking .
so , if thinking amounts to sampling possible alternatives before making a decision , it should not be surprising that people regularly seem to use so
we should emphasize that we are not arguing that all hu - man actions and decisions are based on very few samples .
the evidence for sampling - based decisions arises when peo - ple make a decision or a choice based on what they think is likely to be true ( which example is in the concept ? how long will this event last ? how many airports are there in the us ? ) .
in other situations people appear to integrate over the posterior , or to take many more samples , such as when peo - ple make graded inductive judgments ( how similar is a to b ? how likely is it that x has property p given that y does ? how likely do you think that f causes g ? ) .
it is interesting to consider why there may be a difference between these sorts
under reasonable two - alternative choice scenarios , people are best advised to make decisions based on few samples ( fu - ture work will extend this to n - afc and continuous choice decisions ) .
this captures a very sensible intuition : when we are deciding whether to turn left or right at an intersection , we should not enumerate every possible map of the world .
we do not need moral certainty about the probability that left or right will lead to the fastest route to our destination we just need to make a decision .
we must implicitly weigh the bene - ts of improving our decision by thinking for a longer period of time against the cost of spending more time and effort de - liberating .
intuition suggests that we do this in the real world : we think harder before deciding whether to go north or south on an interstate ( where a wrong decision can lead to a detour of many miles ) , than when we are looking for a house ( where the wrong decision will have minimal cost ) .
empirical evi - dence conrms this : when the stakes are high , people start maximizing instead of probability matching ( shanks , tun - ney , & mccarthy , 123 ) .
nonetheless , it seems that in sim - ple circumstances , deliberating is rarely the prudent course of action for the most part , making quick , locally suboptimal , decisions is the globally optimal policy : one and done .
acknowledgments .
this work was supported by onr muri ( jbt , pi : bavelier ) ; russell sage , ndseg , nsf dissertation grant ( ev ) .
