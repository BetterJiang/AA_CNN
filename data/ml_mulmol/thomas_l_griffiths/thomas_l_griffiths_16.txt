rational models of cognition typically consider the abstract computational problems
posed by the environment , assuming that people are capable of optimally solving those
problems .
this diers from more traditional formal models of cognition , which focus on
the psychological processes responsible for behavior .
a basic challenge for rational models
is thus explaining how optimal solutions can be approximated by psychological processes .
we outline a general strategy for answering this question , namely to explore the
psychological plausibility of approximation algorithms developed in computer science and
statistics .
in particular , we argue that monte carlo methods provide a source of rational
process models that connect optimal solutions to psychological processes .
we support
this argument through a detailed example , applying this approach to andersons ( 123 ,
123 ) rational model of categorization ( rmc ) , which involves a particularly challenging
computational problem .
drawing on a connection between the rmc and ideas from
nonparametric bayesian statistics , we propose two alternative algorithms for approximate
inference in this model .
the algorithms we consider include gibbs sampling , a procedure
appropriate when all stimuli are presented simultaneously , and particle lters , which
sequentially approximate the posterior distribution with a small number of samples that
are updated as new data become available .
applying these algorithms to several existing
datasets shows that a particle lter with a single particle provides a good description of
rational approximations to category learning 123
rational approximations to rational models :
alternative algorithms for category learning
rational models of cognition aim to explain human thought and behavior as an
optimal solution to the computational problems that are posed by our environment
( anderson , 123; chater & oaksford , 123; marr , 123; oaksford & chater , 123 )
approach has been used to model several aspects of cognition , including memory
( anderson , 123; shirin & steyvers , 123 ) , reasoning ( oaksford & chater , 123 ) ,
generalization ( shepard , 123; tenenbaum & griths , 123a ) , and causal induction
( anderson , 123; griths & tenenbaum , 123 ) .
however , executing optimal solutions to
these problems can be extemely computationally expensive , a point that is commonly
raised as an argument against the validity of rational models ( e . g . , gigerenzer & todd ,
123; tversky & kahneman , 123 ) .
this establishes a basic challenge for advocates of
rational models of cognition : identifying psychologically plausible mechanisms that would
allow the human mind to approximate optimal performance .
the question of how rational models of cognition can be approximated by
psychologically plausible mechanisms addresses a fundamental issue in cognitive science :
bridging levels of analysis .
rational models provide answers to questions posed at marrs
( 123 ) computational level questions about the abstract computational problems
involved in cognition .
this is a dierent kind of explanation to those provided by other
modeling approaches , which tend to operate at the level of algorithms , considering the
concrete processes that are assumed to operate in the human mind .
theories developed at
these dierent levels of analysis provide dierent kinds of explanations for human
behavior , with the computational level explaining why we do the things we do , and the
algorithmic level explaining how these things are done .
both levels of analysis contribute
to the development of a complete account of human cognition , just as our understanding
rational approximations to category learning 123
of bird ight is informed by knowing both how the shape of wings results from
aerodynamics and how those wings are articulated by muscle and bone .
despite the importance of both the computational and algorithmic level to
understanding human cognition , there has been relatively little consideration of how the
two levels might be connected .
in dierentiating these levels of analysis , marr ( 123 )
clearly stated that they were not independent , with the expectation that results yielded at
one level would provide constraints on theories at another .
however , accounts of human
cognition are typically oered at just one of these levels , oering theories of either the
abstract computational problem or the psychological processes involved .
cases where
rational and process models can be explicitly connected are rare and noteworthy , such as
the equivalence of exemplar and prototype models of categorization to dierent forms of
density estimation ( ashby & alfonso - reese , 123 ) , although recent work has begun to
explore how rational models might be converted into process models ( e . g . , kruschke ,
considering the processes by which human minds might approximate optimal
solutions to computational problems thus provides us with an opportunity not just to
address a challenge for rational models of cognition , but to consider how one might
develop a general strategy for bridging levels of analysis .
in this paper , we outline a
strategy that is applicable to rational analyses of probabilistic inference tasks .
in such
tasks , the learner needs to repeatedly update a probability distribution over hypotheses as
more information about those hypotheses becomes available .
due to the prevalence of
such tasks , our strategy provides tools that can be used to derive rational approximations
to a variety of rational models of cognition .
the key idea behind our approach is that ecient implementation of probabilistic
inference is not just a problem in cognitive science it is an issue that arises in computer
science and statistics , resulting in a number of general purpose algorithms ( for an
rational approximations to category learning 123
introduction and examples , see bishop , 123; hastie , tibshirani , & friedman , 123;
mackay , 123 ) .
these algorithms often provide asymptotic guarantees on the quality of
the approximation they provide , meaning that with sucient resources they can
approximate the optimal inference to any desired level of precision .
the existence of these
algorithms suggests a strategy for bridging levels of analysis : starting with rational
models , and then considering ecient approximations to those models as candidates for
psychological process models .
the models inspired by these algorithms will not be
rational models , but instead will be process models that are closely tied to rational
models , and typically come with guarantees of good performance as approximations a
kind of rational process model .
our emphasis in this paper will be on one class of approximation algorithms : monte
carlo algorithms , which approximate a probability distribution with a set of samples from
that distribution .
sophisticated monte carlo schemes provide methods for sampling from
complex probability distributions ( gilks , richardson , & spiegelhalter , 123 ) , and for
recursively updating a set of samples from a distribution as more data are obtained
( doucet , freitas , & gordon , 123 ) .
these algorithms provide an answer to the question of
how learners with nite memory resources might be able to maintain a distribution over a
large hypothesis space .
we introduce these algorithms in the general case , and then
provide a detailed illustration of how these algorithms can be applied to one of the rst
rational models of cognition : andersons ( 123 , 123 ) rational model of categorization .
our analysis of andersons rational model of categorization draws on a surprising
connection between this model and work on density estimation in nonparametric bayesian
statistics .
this connection allows us to identify two new algorithms that can be used in
evaluating the predictions of the model .
these two algorithms both asymptotically
approximate ideal bayesian inference , and help to separate the predictions that arise from
the underlying statistical model from those that are due to the inference algorithm
rational approximations to category learning 123
evaluate these algorithms by comparing the results to the full posterior distribution and to
human data .
the new algorithms better approximate the posterior distribution and t
human data at least as well as the original algorithm proposed by anderson .
in addition ,
we show that these new algorithms have greater psychological plausibility and provide
better ts to data that have proved challenging to bayesian models .
these results
illustrate the use of rational process models to explain how people perform probabilistic
inference , provide a tool for exploring the relationship between rational models and
human performance , and begin to bridge the gap between computational and algorithmic
levels of analysis .
the plan of the paper is as follows .
in the rst part of the paper we describe the
general approach .
we begin with a discussion of the challenges associated with performing
probabilistic inference , followed by a description of various monte carlo methods that can
be used to address these challenges , leading nally to the development of the rational
approximation framework .
in the second part of the paper , we apply the rational
approximation idea to categorization problems , using andersons rational model .
we rst
describe this model , and use its connection to nonparametric statistics to motivate new
approximate inference algorithms .
we then evaluate the psychological plausibility of these
algorithms at both a descriptive level and with comparisons to human performance in
several categorization experiments .
the challenges of probabilistic inference
the computational problems that people need to solve are often inductive problems ,
requiring an inference from limited data to underdetermined hypotheses .
for example ,
when learning about a new category of objects , people need to infer the structure of the
category from examples of its members .
this inference is inherently inductive , since the
category structure is not completely specied by the limited set of examples given to the
rational approximations to category learning 123
learner; and because of this , it is not possible to know exactly which structure is correct .
that is , the optimal solution to problems of this kind requires the learner to make
probabilistic inferences , evaluating the plausibility of dierent hypotheses in light of the
information provided by the observed data .
in the remainder of this section , we discuss
two challenges that a learner attempting to implement the ideal solution faces : reasoning
about hypotheses that are composed of large numbers of variables , and repeatedly
updating beliefs about a set of hypotheses as more information becomes available over
reasoning about large numbers of variables
one of the most fundamental challenges in performing probabilistic inference
concerns the situation when the number of hypotheses is very large .
this is typically
encountered when each hypothesis corresponds to a statement about a number of dierent
variables .
the number of hypotheses then suers from a combinatoric explosion
example , many theories of category learning assume that people assign objects to clusters .
if so , then each hypothesis is composed of many assignment variables , one per object .
likewise , in causal learning , hypotheses about causal structure can often be expressed in
terms of all of the individual causal relationships that make up a given structure , thus
requiring multiple variables .
reasoning about hypotheses comprised of large numbers of
variables poses a particular challenge , because of the combinatorial nature of the
hypothesis space : the number of hypotheses to be considered can increase exponentially in
the number of relevant variables .
the number of possible clusterings of n objects , for
example , is given by the nth bell number , with the rst ten values being 123 , 123 , 123 , 123 , 123 ,
123 , 123 , 123 , 123 , and 123
in such cases , brute force enumeration of all
hypotheses will be extremely computationally expensive , and scale badly with the number
of variables under consideration .
rational approximations to category learning 123
updating beliefs over time
when making probabilistic inferences , we rarely have all the information we need to
denitively evaluate a hypothesis .
as a result , when a learner observes a piece of data and
uses this to form beliefs , he or she generally remains somewhat uncertain about which
hypothesis is really the correct one .
when a new piece of information arrives , this
distribution needs to be updated to the new beliefs .
the consequence is that an ideal
learner needs to constantly update a probability distribution over hypotheses as more data
updating beliefs over time is computationally challenging because it requires the
learner to draw inferences every time new information becomes available .
unless the
learner uses methods that allow the ecient updating of his or her beliefs , he or she would
be required to perform the entire inference from scratch every time new information
arrives .
the cost of probabilistic inference is thus multiplied by the number of
observations that have to be processed .
as one would expect , this becomes particularly
expensive with large hypothesis spaces , such as the combinatorial spaces that result from
having hypotheses expressed over large numbers of random variables .
making
probabilistic inference computationally tractable thus requires developing strategies for
eciently updating a probability distribution over hypotheses as new data are observed .
algorithms to address the challenges
some of the challenges of probabilistic inference can be addressed by approximating
optimal solutions using algorithms based on the monte carlo principle .
this principle is
one of the most basic ideas in statistical computing : rather than performing computations
using a probability distribution , we perform those computations using a set of samples
from that distribution .
the resulting approximation becomes increasingly accurate as the
number of samples grows , and the relative costs of computing time and errors in
rational approximations to category learning 123
approximation can be used to determine how many samples should be generated
principle forms the foundation of an entire class of approximation algorithms ( motwani &
raghavan , 123 ) .
monte carlo methods provide a way to eciently approximate
probabilistic inference .
however , generating samples from posterior distributions is
typically not straightforward : generating samples from a distribution requires knowing the
form that distribution takes , which is a large part of the challenge of probabilistic
inference in the rst place .
consequently , sophisticated algorithms need to be used in
order to generate samples .
here we introduce two such algorithms at an intuitive level :
gibbs sampling and particle lters .
a parallel mathematical development of the general
algorithms is given in the appendix and toy examples of these algorithms applied to
categorization and a discussion of their psychological plausibility are given later .
gibbs sampling ( geman & geman , 123 ) is a very commonly used monte carlo
method for sampling from probability distributions .
this algorithm is initialized with a
particular set of values for each variable , often with random values .
gibbs sampling works
on the principle of sampling a single random variable at each step .
one random variable is
selected , and the value of this variable is sampled , conditioned on the values of all of the
other random variables and the data .
the process is repeated for each variable; each is
sampled conditioned on the values of all of the other variables and the data .
intuitively ,
gibbs sampling corresponds to the process of inspecting ones beliefs about each random
variable conditioned on ones beliefs about all of the other random variables , and the data .
reecting on each variable in turn provides the opportunity for changes to propagate
through the set of random variables .
a complete run through sampling all of the random
variables is an iteration and the algorithm is usually engaged for many iterations .
though the algorithm will eventually sample from the desired distribution , is starts
rational approximations to category learning 123
at a particular , often random , set of values .
the early iterations show the algorithm
converging to the desired distribution , but are not yet samples from this distribution .
these iterations are known as the burn - in and are thrown away .
an additional diculty is
that iterations following the burn - in iterations often show strong dependency from one
iteration to the next .
these iterations are then thinned , which means keeping every nth
iteration and discarding the rest .
the remaining iterations after burn - in and thinning are
used as samples from the desired distribution .
this process provides a way to generate
samples from probability distributions dened over large numbers of variables without
ever having to enumerate the entire hypothesis space , providing a tractable way to
perform probabilistic inference in these cases .
a second class of monte carlo algorithms , particle lters , are specically designed to
deal with sequential data .
particle lters are underpinned by a simpler algorithm known
as importance sampling , which is used in cases in which it is hard to sample from the
target distribution , but easy to sample from a related distribution ( known as the proposal
distribution ) .
the basic idea of importance sampling is that we generate samples from the
proposal distribution , and then assign those samples weights that correct for the dierence
from the target distribution .
samples that are more likely under the proposal than the
target distribution are assigned lower weights , since they should be over - represented in a
set of draws from the proposal distribution , and samples that are more likely under the
target than the proposal are assigned higher weights , increasing their inuence .
particle lters extend importance sampling to a sequence of probability
distributions , typically making use of the relationship between successive distributions to
use samples from one distribution to generate samples from the next ( for more details , see
doucet et al . , 123 ) .
the particle lter was originally developed for making inferences
rational approximations to category learning 123
about variables in a dynamic environment the problem of ltering is to infer the
current state of the world given a sequence of observations .
however , it also provides a
natural solution to the general problem of updating a probability distribution over time .
each particle is a sample from the posterior distribution on the previous trial , and these
samples are updated when new data become available .
rational approximations to rational models
monte carlo algorithms provide ecient schemes for approximating probabilistic
inference , and come with the asymptotic guarantee that they can produce an arbitrarily
good approximation if sucient computational resources are available .
these algorithms
thus seem like good candidates for explaining how human minds could be capable of
performing probabilistic inference , bridging the gap between the computational - level
analyses typically associated with rational models of cognition and the algorithmic level at
which psychological process models are dened .
in particular , gibbs sampling and particle
lters provide solutions to the challenges posed by probabilistic inference with large
numbers of variables and updating probability distributions over time .
part of the attraction of the monte carlo principle as the basis for developing
rational process models is that it reduces probabilistic computations to one operation :
generating samples from a probability distribution .
the notion that people might be
capable of generating samples from internalized probability distributions has previously
appeared in psychological process models of decision making ( stewart , chater , & brown ,
123 ) , estimation ( fiedler & juslin , 123 ) , and prediction ( mozer , pashler , & homaei ,
indeed , the foundational premise of the highly successful sequential sampling
framework ( ratcli , 123; p .
smith & ratcli , 123; vickers , 123 ) is that choice
behavior is fundamentally reliant on people drawing and evaluating samples from
probability distributions that in some cases derive from internally stored stimulus
rational approximations to category learning 123
representations ( lee & cummins , 123; ratcli , 123; vandekerckhove , verheyen , &
tuerlinckx , 123 ) .
taken together , these models provide support for the idea that the
basic ingredients required for monte carlo simulation are already part of the psychological
recent research has also identied correspondences between the kind of
sophisticated monte carlo methods discussed above and psychological process models .
shi , feldman , and griths ( 123 ) showed that the basic computations involved in
importance sampling are identical to those used in exemplar models ( also see shi , griths ,
feldman , & sanborn , in press ) .
exemplar models assume that people store stimuli in
memory , activating them based on their similarity to new stimuli ( e . g . , medin & schaer ,
123; nosofsky , 123 ) .
an importance sampler can be implemented by storing hypotheses
in memory , and activating them in proportion to the probability of observed data under
that hypothesis .
moreover , this interpretation of exemplars as stored hypotheses links
exemplar - based learning nicely to previous rational analyses of exemplar - based decisions
as a form of sequential analysis ( see navarro , 123; nosofsky & palmeri , 123 ) .
that is ,
the importance sampling method allows people to eciently learn and store a posterior
distribution , and the sequential analysis method allows ecient decisions to be made on
the basis of this stored representation .
this thus constitutes a natural , psychologically
plausible scheme for approximating some probabilistic computations .
several recent papers have also examined the possibility that particle lters might
be relevant to understanding how people can update probability distributions over time .
this idea was rst raised by sanborn , griths , and navarro ( 123 ) , and particle lters
have subsequently been used to explain behavioral patterns observed in several tasks .
daw and courville ( 123 ) argued that a particle lter with a small number of particles
could explain rapid transitions seen in associative learning tasks with animals .
brown and
steyvers ( 123 ) used particle lters to explain individual dierences in a change - point
rational approximations to category learning 123
detection task , where variation of the number of particles being considered captured one
dimension along which participants varied .
finally , levy , reali , and griths ( 123 )
showed that garden path eects in sentence processing could be accounted for by using a
particle lter for parsing , where the frequency with which the parser produced no valid
particles was predictive of the diculty that people had interpreting the sentence .
evaluating monte carlo algorithms as candidates for rational process models
requires exploring how the predictions of rational models of cognition vary under these
dierent approximation schemes , and examining how well these predictions correspond to
human behavior .
in the remainder of the paper , we provide a detailed investigation of the
performance of dierent approximation algorithms for andersons ( 123; 123 ) rational
model of categorization .
this model is a good candidate for such an investigation , since it
involves an extremely challenging computational problem : evaluating a posterior
distribution over all possible partitions of a set of objects into clusters .
this problem is so
challenging that andersons original presentation of the model resorted to a heuristic
solution .
we use a connection between this rational model and a model that is widely
used in bayesian statistics to specify a gibbs sampler and particle lter for this model ,
which we evaluate against a range of empirical data .
the rational model of categorization
the problem of category learning is to infer the structure of categories from a set of
stimuli labeled as belonging to those categories .
the knowledge acquired through this
process can ultimately be used to make decisions about how to categorize new stimuli .
several rational analyses of category learning have been proposed ( anderson , 123; ashby
& alfonso - reese , 123; nosofsky , 123 ) .
these analyses essentially agree on the nature of
the computational problem involved , casting category learning as a problem of density
estimation : determining the probability distributions associated with dierent category
rational approximations to category learning 123
labels .
viewing category learning in this way helps to clarify the assumptions behind the
two main classes of psychological models : exemplar models and prototype models .
exemplar models assume that a category is represented by a set of stored exemplars , and
categorizing new stimuli involves comparing these stimuli to the set of exemplars in each
category ( e . g . , medin & schaer , 123; nosofsky , 123 ) .
prototype models assume that a
category is associated with a single prototype and categorization involves comparing new
stimuli to these prototypes ( e . g . , reed , 123 ) .
these approaches to category learning
correspond to dierent strategies for density estimation used in statistics , being
nonparametric and parametric density estimation respectively ( ashby & alfonso - reese ,
andersons ( 123 , 123 ) rational analysis of categorization takes a third approach ,
modeling category learning as bayesian density estimation .
this approach encompasses
both prototype and exemplar representations , automatically selecting the number of
clusters to be used in representing a set of objects .
unfortunately , the inference for this
model is extremely complex , requiring an evaluation of every possible way of partitioning
exemplars into clusters , with the number of possible partitions growing exponentially with
the number of exemplars .
anderson proposed an approximation algorithm in which stimuli
are sequentially assigned to clusters , and assignments of stimuli are xed once they are
however , this algorithm does not provide any asymptotic guarantees for the quality
of the resulting assignments , and is extremely sensitive to the order in which stimuli are
observed , a property which is not intrinsic to the underlying statistical model .
as a result ,
evaluations of the model are tied to the particular approximation algorithm that was used .
before we consider alternative approximation algorithms for andersons model , we
need to provide a detailed specication of the model and the original algorithm .
in this
section , we rst outline the bayesian view of categorization , showing how exemplar and
prototype models are special cases of the approach , and then describe the specic
rational approximations to category learning 123
approach taken by anderson .
bayesian categorization models
rational models of categorization must solve the density estimation problem
outlined above and use this estimate to identify the category label or some other
unobserved property of an object using its observed properties ( anderson , 123; ashby &
alfonso - reese , 123; rosseel , 123 ) .
this prediction problem has a natural interpretation
as a form of bayesian inference , which we now outline .
suppose that the learner has
previously been shown a set of two stimuli and their labels , where the two stimuli are the
rst two stimuli in figure 123
we let yi refer to the category label given to the ith object in
this list ( often a nonsense syllable such as dax ) , and the mental representation of the
object is assumed to be characterized by a collection of features , denoted xi .
so for
instance if the stimulus is the rst stimulus , it could be simply described in terms of
features such as is circular , is black , and is large .
thus , if the learner is told the
rst stimulus is a dax , we would describe the trial by the pair ( xi , yi ) .
across the set of
two labelled objects , the information available to the learner can be thought of as a
collection of statements ( e . g . , the rst stimulus is a dax and the second stimulus is a
zug ) that can be formally characterized by the collection of stimulus representations
x123 = ( x123 , x123 ) , along with the labels given to each of these objects y123 = ( y123 , y123 )
generally we will refer to these already known stimuli as the rst n 123 stimuli with
representations xn 123 = ( x123 , x123 , .
xn 123 ) , and labels yn 123 = ( y123 , y123 ,
with that in mind , the problem facing the learner can be written in the following
way : on the n th trial in the experiment , he or she is shown a new stimulus xn ( e . g . , the
third stimulus in figure 123 ) , and asked what label it should be given .
if there are j
possible labels involved in the task , the problem is to determine if the n th object should
be given the jth label ( i . e . , infer that yn = j ) , on the basis of the information available ,
rational approximations to category learning 123
( xn , xn 123 , yn 123 ) .
if we apply bayes rule to this problem , we are able to see that
p ( yn = j|xn , xn 123 , yn 123 ) =
p ( xn |yn = j , xn 123 , yn 123 ) p ( yn = j|yn 123 ) y=123 p ( xn |yn = y , xn 123 , yn 123 ) p ( yn = y|yn 123 )
in this expression , p ( xn |yn = j , xn 123 , yn 123 ) denotes the estimated probability that an
element of the jth category would possess the collection of features xn observed in the
novel object , and p ( yn = j|yn 123 ) is an estimate of the prior probability that a new
object would belong to the jth category .
additionally , we have assumed that the prior
probability of an object coming from a particular category is independent of the features
of the previous objects .
thus , this expression makes clear that the probability that an
object with features xn should be given the label yn = j is related both the probability of
sampling an object with features xn from that category , and the prior probability of
choosing that category label .
category learning , then , becomes a matter of determining
these probabilities the problem known as density estimation .
one advantage to describing categorization in terms of the density estimation
problem is that both exemplar models and prototype models can be described as dierent
methods for determining the probabilities described by equation 123
specically , ashby
and alfonso - reese ( 123 ) observed that if the learner uses a simple form of nonparametric
density estimation known as kernel density estimation ( e . g . , silverman , 123 ) in order to
compute the probability p ( xn |yn = j , xn 123 , yn 123 ) , then an exemplar model of
categorization is the result .
on the other hand , they note that the learner could use a
form of parametric density estimation ( e . g . , rice , 123 ) , in which the category
distribution is assumed to have some known form , and the learners goal is to estimate the
unknown parameters of that distribution .
if the learner uses this approach , then the result
is a prototype model , with the centroid being an appropriate estimate for distributions
whose parameters characterize their mean .
to illustrate the point , figure 123 shows a
prototype model on the left , in which the category distribution is assumed to be normal
rational approximations to category learning 123
distribution centered over the prototype , and an exemplar model on the right , in which a
separate normal distribution ( the kernel ) is placed over each exemplar , and the resulting
category distribution is a mixture model .
having cast the problem in these terms , it is clear that exemplar and prototype
models are two extremes along a continuum of possible approaches to category
representation .
as illustrated in the middle panel of figure 123 , the learner might choose to
break the category up into several clusters of stimuli , denoted zn 123 , where zi = k if the
ith stimulus is assigned to the kth cluster .
each such cluster is then associated with a
simple parametric distribution , and the category distribution as a whole then becomes a
mixture model ( e . g .
rosseel , 123; vanpaemel & storms , 123 ) .
expressed in these terms ,
prototype models map naturally onto the idea of a one - cluster representation , and
exemplar models arise when there is a separate cluster for each object .
in between lies a
whole class of intermediate category representations , such as the one shown in the middle
of figure 123
in this case , the learner has divided the ve objects into two clusters , and the
resulting category distribution is a mixture of two normal distributions .
the appeal of this more general class of category representations is that it allows
people to use prototype - like models when called for , and to move to the more exible
exemplar - like models when needed .
however , by proposing category representations of
this form , we introduce a new problem : for a set of n objects how many clusters k are
appropriate to represent the categories , and how should the cluster assignments zn be
made in light of the available data ( xn , yn ) ? it is to this topic that we now turn .
a partial solution to this problem was given by anderson ( 123 ) , in the form of the
rational model of categorization ( rmc ) .
the rmc is somewhat dierent to the various
mixture models described in the previous section insofar as it treats the category labels as
rational approximations to category learning 123
being equivalent to unobserved features .
as a consequence , the rmc species a joint
distribution on features and category labels , rather than assuming that the distribution
over category labels is estimated separately and then combined with a distribution on
features for each category .
this distribution is a mixture , with
p ( xn , yn ) = " zn
p ( xn , yn |zn ) p ( zn )
where p ( zn ) is a distribution over possible partitions of the n objects into clusters .
importantly , the number of clusters k in the partition zn is not assumed to be xed in
advance , but is rather something that the learner infers from the data .
the rmc provides
an explicit form for this prior distribution , namely
( 123 c ) kcn k i=123 ( ( 123 c ) + ci )
p ( zn ) =
where c is a parameter called the coupling probability , mk is the number of objects
assigned to cluster k , and k is the total number of clusters in zn .
although this
distribution appears unwieldy , it is in fact the distribution that results from sequentially
assigning objects to clusters with probability
p ( zi = k|zi123 ) =
if mk > 123 ( i . e . , k is old )
if mk = 123 ( i . e . , k is new )
where the counts mk are accumulated over zi123
thus , each object can be assigned to an
existing cluster with probability proportional to the number of objects already assigned to
that cluster , or to a new cluster with probability determined by c .
since the prior
distribution is set up in a way that allows k to grow as more objects are encountered , the
rmc allows the learner to infer the number of clusters via the usual process of bayesian
intuitively , we can look at the prior as a rich - get - richer scheme : if a cluster already
contains many objects , then it has a higher prior probability for new objects
rational approximations to category learning 123
coupling probability is the parameter that determines the severity of this scheme
high values of the coupling parameter , then larger clusters will be favored in the prior ,
while for low values of the coupling parameter , smaller clusters will be favored
cluster sizes that actually result depend on the likelihoods as well as the prior .
the local map algorithm
when considering richer representations than prototypes and exemplars it is
necessary to have a method for learning the appropriate representation from data
equation 123 to make predictions about category labels and features requires summing over
all possible partitions zn .
this sum rapidly becomes intractable for large n , since the
number of partitions grows rapidly with the number of stimuli according to the bell
number introduced earlier .
consequently , an approximate inference algorithm is needed
and anderson ( 123 , 123 ) developed a simple inference algorithm to solve this problem .
we will refer to this algorithm as the local map algorithm , as it involves assigning each
stimulus to the cluster that has the highest posterior probability given the previous
assignments ( i . e . , the maximum a posteriori or map cluster ) .
the algorithm is a local
implementation of the map because it makes an assignment for each new stimulus as it
arrives , which does not necessarily result in the global map .
the local map algorithm approximates the sum in equation 123 with just a single
clustering of the n objects , zn .
this clustering is selected by assigning each object to a
cluster as it is observed .
at this point , the features and labels of all stimuli , along with
the cluster assignments zi123 for the previous i 123 stimuli are given .
thus , the posterior
probability that stimulus i was generated from cluster k is
p ( zi = k|zi123 , xi , xi123 , yi , yi123 )
p ( xi|zi = k , zi123 , xi123 ) p ( yi|zi = k , zi123 , yi123 ) p ( zi = k|zi123 )
where p ( zi = k|zi123 ) is given by equation 123
under the local map algorithm , xi is
rational approximations to category learning 123
assigned to the cluster k that maximizes equation 123
iterating this process results in a
single partition of a set of n objects .
to illustrate the local map algorithm , we show in figure 123 how it would be applied
it to the simple example of sequentially presented stimuli in figure 123
each stimulus is
parameterized by three binary features and the likelihood
p ( xi|zi = k , zi123 , xi123 ) p ( yi|zi = k , zi123 , yi123 ) is calculated using binomial distributions
that are independent for each feature .
these binomial likelihoods are parameterized by
the probability of the outcome , and need a prior distribution over this probability
standard prior for binomial likelihoods is the beta distribution ( see the appendix for
details ) .
for the toy example , we used a symmetric beta prior for the binomial likelihood ,
with = 123
the symmetric beta distribution with = 123 is a simple choice , because it is
equivalent to the uniform distribution .
the local map algorithm initially assigns the rst observed stimulus to its own
cluster .
when the second stimulus is observed , the algorithm generates each possible
partition : either it is assigned to the same cluster as the rst stimulus or to a new cluster .
the posterior probability of each of these partitions is calculated and the partition with
the highest posterior probability is always chosen as the representation .
after the third
stimulus is observed , the algorithm produces all possible partitions involving the third
stimulus , assuming that the clustering for the rst two stimuli remains the same
that not all possible partitions of the three stimuli are considered , because the algorithm
makes an irrevocable choice for the partition of the rst two stimuli and the possible
partitions on later trials have to be consistent with this choice .
the local map algorithm
will always produce the same nal partition for a given sequential order of the stimuli ,
assuming there are no ties in the posterior probability .
the local map algorithm approximates the complete joint distribution using only
rational approximations to category learning 123
this partition .
in eect , it assumes that
p ( xn , yn ) p ( xn , yn |zn )
where zn is produced via the procedure outlined above .
the probability that a particular
object receives a particular category label would likewise be computed using a single
the rmc species a rational model of categorization , capturing many of the ideas
embodied in other models and allowing the representation to be inferred from the data .
however , the model is still signicantly limited , because the approximate algorithm used
for assigning objects to clusters in the rmc can be a poor approximation to the posterior .
in particular , this makes it hard to discriminate the predictions that result from the
underlying statistical model from those that are a consequence of the algorithm being
in order to explore alternative approximation algorithms , we now discuss the
connections between the rmc and nonparametric bayesian statistics .
dirichlet process mixture models
one of the most interesting properties of the rmc is that it has a direct connection
to a model used in nonparametric bayesian statistics ( neal , 123 ) .
the rationale for using
nonparametric methods is that real data are not generally sampled from some neat ,
nite - dimensional family of distributions , so it is best to avoid this assumption at the
outset .
from a bayesian perspective , the nonparametric approach requires us to use priors
that include as broad a range of densities of possible , thereby allowing us to infer very
complex densities if they are warranted by data .
the most commonly used method for
placing broad priors over probability distributions is the dirichlet process ( dp; ferguson ,
the distributions indexed by the dirichlet process can be expressed as countably
rational approximations to category learning 123
innite mixtures of point masses ( sethuraman , 123 ) , making them ideally suited to act
as priors in innite mixture models ( escobar & west , 123; rasmussen , 123 ) .
when used
in this fashion , the resulting model is referred to as a dirichlet process mixture model
( dpmm; antoniak , 123; ferguson , 123; neal , 123 ) .
although a complete description of the dirichlet process is beyond the scope of this
paper ( for more details , see navarro , griths , steyvers , & lee , 123 ) , what matters for
our purposes is that the dirichlet process implies a distribution over partitions : any two
observations in the sample that were generated from the same mixture component may be
treated as members of the same cluster , allowing us to specify priors over an unbounded
number of clusters .
in the case where n observations have been made , the prior
probability that a dirichlet process will partition those observations into the clusters zn is
p ( zn ) =
i=123 ( + i )
where is the dispersion parameter of the dirichlet process .
this distribution over
partitions can be produced by a simple sequential stochastic process ( blackwell &
macqueen , 123 ) .
if observations are assigned to clusters one after another and the
probability that observation i + 123 is assigned to cluster k is
p ( zi = k|zi123 ) =
if mk > 123 ( i . e . , k is old )
if mk = 123 ( i . e . , k is new )
we obtain equation 123 for the probability of the resulting partition .
this distribution has a
number of nice properties , with one of the most important being exchangeability : the prior
probability of a partition is unaected by the order in which the observations are received
( aldous , 123 ) .
intuitively , exchangeability is similar to independence , but slightly weaker .
to make some of these ideas more concrete , figure 123 presents a visual depiction of
the relationship between the partitioning implied by the dp , the distribution over
parameters that is sampled from the dp , and the resulting mixture distribution over
rational approximations to category learning 123
stimuli that results in the dpmm .
the partitioning implied by the dpmm shows that
items are divided into discrete clusters .
each of these clusters is given a parameter drawn
from the prior distribution over parameters .
a large number of parameter draws are
shown in figure 123b .
each spike is a new parameter value and the height of the bars
depends on the number of clusters that use that parameter .
finally , combining the
parameter values with a continuous likelihood function , such as a gaussian distribution ,
gives the mixture distribution shown in figure 123c .
it should be apparent from our description of the prior distribution used in the
dpmm that it is similar in spirit to the prior distribution underlying the rmc .
in fact ,
the two are directly equivalent , a point that was rst made in the statistics literature by
neal ( 123 ) .
if we let = ( 123 c ) / c , equations 123 and 123 are equivalent , as are equations 123
thus the prior over cluster assignments used in the rmc is exactly the same as
that used in the dpmm .
anderson ( 123 , 123 ) thus independently discovered one of the
most celebrated models in nonparametric bayesian statistics , deriving this distribution
from rst principles .
alternative approximate inference algorithms
the connection between the rmc and the dpmm suggests a solution to the
shortcomings of the local map algorithm .
in this section , we draw on the extensive
literature on approximate inference for dpmms to oer two alternative algorithms for the
rmc : gibbs sampling and particle ltering .
these algorithms are less sensitive to order
and are asymptotically guaranteed to produce accurate predictions .
as discussed above , both gibbs sampling and particle lters are monte carlo
methods .
this means that they provide ways of approximating the intractable sum over
partitions numerically using a collection of samples .
specically , to compute the
probability that a particular object receives a particular category label , a monte carlo
rational approximations to category learning 123
p ( yn = j|xn , yn 123 ) = " zn
p ( yn = j|xn , yn 123 , zn ) p ( zn |xn , yn 123 )
p ( yn = j|xn , yn 123 , z ( " )
, z ( m )
n are m samples from p ( zn |xn , yn 123 ) , and the approximation becomes
exact as m .
the two algorithms dier only in how these samples are generated .
gibbs sampling is the approximate inference algorithm most commonly used with
the dpmm ( e . g . , escobar & west , 123; neal , 123 ) .
it provides a way to construct a
markov chain that converges to the posterior distribution over partitions .
the state space
of the markov chain is the set of partitions , and transitions between states are produced
by sampling the cluster assignment of each stimulus from its conditional distribution ,
given the current assignments of all other stimuli .
the clustering evolves by sequentially
sampling each zi from the distribution
p ( zi = k|zi , xi , xi , yi , yi )
p ( xi|zi = k , zi , xi ) p ( yi|zi = k , zi , yi ) p ( zi = k|zi )
where zi refers to all cluster assignments except for the ith .
equation 123 is extremely similar to equation 123 , although it gives the probability of
a cluster based on the all of the trials in the entire experiment except for the current trial ,
instead of just the previous trials .
the statistical property of exchangeability , briey
noted above , means that these probabilities are actually computed in exactly the same
way : the order of the observations can be rearranged so that any particular observation is
considered the last observation .
hence , we can use equation 123 to compute p ( zi|zi ) , with
old clusters receiving probability in proportion to their popularity , and a new cluster
rational approximations to category learning 123
being chosen with probability determined by ( or , equivalently , c ) .
the other terms
reect the probability of the features and category label of stimulus i under the partition
that results from this choice of zi , and depends on the nature of the features .
the gibbs sampling algorithm for the dpmm is straightforward ( neal , 123 ) , and
is illustrated for the simple example in figure 123
first , an initial assignment of stimuli to
clusters is chosen , with a convenient choice being all stimuli assigned to a single cluster .
unlike the local map algorithm , gibbs sampling is not a sequential algorithm; all stimuli
must be observed before it can be run .
next , we choose a single stimulus and consider all
possible reassignments of that stimulus to clusters , including not making a change in
assignments or assigning the stimulus to a new cluster .
equation 123 gives the probability
of each partition and one of the partitions is sampled based on its posterior probability ,
making this algorithm stochastic , unlike the local map .
the stochastic nature of the
algorithm is evident in the example in figure 123 , because the rst circled assignment has
lower probability than the alternatives .
the example shows two iterations of gibbs
sampling , in which each stimulus is cycled through and reassigned .
in an actual
application the algorithm would go through many iterations , with the output of one
iteration providing the input to the next .
since the probability of obtaining a particular
partition after each iteration depends only on the partition produced on the previous
iteration , this is a markov chain .
after enough iterations for the markov chain to converge , we begin to save the
partitions it produces .
the partition produced on one iteration is not independent of the
next , so the results of some iterations are discarded to approximate independence
partitions generated by the gibbs sampler can be used in the same way as samples z ( " )
equation 123
as with standard monte carlo approximations , the quality of the
approximation increases as the number of partitions in that collection increases
gibbs sampler provides an eective means of constructing the approximation in
rational approximations to category learning 123
equation 123 , and thus of making accurate predictions about the unobserved features of
there are several ways to construct a particle lter for the dpmm .
the method we
will use is most closely related to the one discussed by fearnhead ( 123 ) .
the key idea is
to treat each new observation as a new time step , with each particle being a partition
of the stimuli from the rst i trials .
unlike the local map algorithm , in which the
posterior distribution is approximated with a single partition , the particle lter uses m
partitions .
summing over these particles gives us an approximation to the posterior
distribution over partitions
p ( zi|xi , yi )
where ( z , z " ) is 123 when z = z " , and 123 otherwise .
if equation 123 is used as an
approximation to the posterior distribution over partitions zi after the rst i trials , then
we can approximate the distribution of zi+123 given the observations xi , yi in the following
p ( zi+123|zi ) p ( zi|xi , yi )
p ( zi+123|xi , yi ) = " zi
where p ( zi+123|zi ) is given by equation 123
we can then incorporate the information
conveyed by the features and label of stimulus i + 123 , arriving at the approximate posterior
p ( zi+123|xi+123 , yi+123 ) p ( xi+123|zi+123 , xi ) p ( yi+123|zi+123 , yi ) p ( zi+123|xi , yi )
p ( xi+123|zi+123 , xi ) p ( yi+123|zi+123 , yi ) p ( zi+123|z ( ! )
rational approximations to category learning 123
the result is a discrete distribution over all the previous particle assignments and all
possible assignments for the current stimulus .
drawing m samples from this distribution
provides us with our new set of particles .
the particle lter for the simple example is illustrated in figure 123
the particle
lter for the dpmm is initialized with the rst stimulus assigned to the rst cluster for all
m particles , in this case m = 123
on observing each new stimulus , the distribution in
equation 123 is calculated , based on the particles sampled in the last trial .
like the local
map , the particle lter updates the partition as each new stimulus is observed , and like
the local map , only new partitions that are consistent with the previous choices made by
the algorithm are considered .
this consistency can be seen in the potential partitions
when the third stimulus is observed in figure 123 : each descendant is consistent with the
partition choices made by its ancestor .
intuitively , the psychological processes involved in
this approximation are very similar to those involved in the local map algorithm .
people
update their beliefs incrementally , keeping the assignments of old items xed , and making
the assignments of new items conditional on these xed beliefs .
there are two key
dierences between the local map and particle lter algorithms .
the rst is that the
choice of new partitions is stochastic instead of deterministic .
the particle lter algorithm
samples new partitions based on their posterior probabilities instead of always selecting
the partition with the maximum probability .
a particle lter with m = 123 particles is
equivalent to the local map algorithm , except that the new partition is sampled instead
of deterministically selected .
the second dierence is that multiple particles means that
multiple partitions can be used instead of the single partition passed forward by the local
the m partitions are selected without regard for ancestry , allowing a partition that
was selected for the early observations to die out as the descendants of other partitions
rational approximations to category learning 123
the dierences in quality of the various approximations can be explored by a toy
example using sequential observations of the stimuli in figure 123
we compared the local
map , a particle lter with m = 123 particles , a particle lter with m = 123 particle , and
gibbs sampling to the exact posterior .
for each algorithm a symmetric beta prior in
which = 123 was used for the likelihood ( see appendix for details ) .
the local map was
run a single time , because its outcome is deterministic on a xed stimulus order
particle lters were each replicated 123 , 123 times , and the gibbs sampler was run for
123 , 123 iterations .
for the gibbs sampler , the rst 123 , 123 iterations were discarded and
every 123th iteration was taken as a sample , yielding 123 , 123 samples .
the results of this
comparison are shown in figure 123
the local map algorithm has selected a single
partition as an approximation to the exact posterior .
in this example , the partition
selected by the local map is also the map of the exact posterior distribution , but the two
will not always be equivalent .
by taking the map partition as each stimulus arrives , the
local map can be misled to choose a partition that is not the global map , if the initial
trials are not representative of the whole run of trials .
an example of this can be seen in
the experiment by anderson and matessa in a later section .
the particle lter with m = 123 particles and the gibbs sampler both produce a
posterior distribution that is nearly indistinguishable from the exact posterior
single - particle particle lter is an interesting intermediate case .
each run of the
single - particle particle lter produces a single partition , not the distribution produced by
a particle lter with m > 123 particles .
however , averaging over runs of the single - particle
particle lter gives an approximation that is much closer to the exact posterior than the
local map .
unlike the asymptotic performance of the gibbs sampler and particle lter
with innite particles , the approximation of the single - particle particle lter is slightly
biased , as can be seen in the gure .
the bias is much less than the local map because the
rational approximations to category learning 123
algorithm is stochastic , but is still present because each run of the m = 123 particle lter
cannot correct its previous assignments by resampling .
psychological plausibility of the algorithms
before turning to a quantitative comparison of the algorithms with human data it is
worth considering their psychological plausibility at a descriptive level , to see whether
they are appropriate for human cognition .
we take as a starting point andersons ( 123 ,
123 ) two desiderata for an approximate inference algorithm : that it be incremental , and
that people see objects as arising from a single cause .
these desiderata were based on
beliefs about the nature of human category learning .
in tasks in which people see objects
presented sequentially and must judge which category they arise from people need to be
able to make predictions all the time not just at particular junctures after seeing many
objects and much deliberation ( anderson , 123 , p .
123 ) , and people tend to perceive
objects as coming from specic categories ( anderson , 123 , p
in addition to these two desiderata , we are concerned with how these algorithms
might introduce new order eects into a model .
often statistical models , such as the
dpmm , are invariant to the order in which observations arrive .
however , the
approximations used in practical applications of these models tend to introduce order
eects as a side eect of limited computation .
people show eects of the order of
presentation of stimuli ( anderson , 123; medin & bettger , 123; murdock , 123 ) , and to
have a psychologically plausible algorithm , the cumulative order eects of the model and
those introduced by the approximation should match the order eects displayed by people .
in the remainder of this section we summarize the psychological plausibility of the local
map , gibbs sampling , and particle lters .
we relate these algorithms to the properties of
incrementalism , a single interpretation of how the data arise , and the order eects
introduced by the algorithms , which are summarized in table 123
rational approximations to category learning 123
anderson ( 123 , 123 ) introduced the local map algorithm to satisfy his two
desiderata for psychological plausibility .
the rst desideratum is satised because the
local map is updated incrementally .
in addition , the second desideratum is satised
because only a single partition of the stimuli into clusters is available to the algorithm in
order to make judgments about new stimuli .
however , as a result of the single
interpretation and its maximization operation , the local map algorithm is extremely
sensitive to the order in which stimuli are observed .
for example , anderson and matessa
( reported in anderson , 123 ) showed that the predictions of the local map algorithm
depended strongly on the order the stimuli were introduced in their clustering experiment .
for one type of order , the local map always predicted one partition of the stimuli , but for
the other order it always predicted a second partition .
we will explore how the local map
can be led down garden paths when we compare the algorithms quantitatively .
gibbs sampling draws samples from one random variable conditioned on all of the
rest and all of the data , thus requiring all of the data be present before inference begins .
new data cannot be incrementally added to the sampling scheme , so in order to sample
from a posterior distribution when a new piece of data arrives , gibbs sampling must start
from scratch .
this property makes the algorithm computationally wasteful if sequential
judgments are required .
for other tasks , however , gibbs sampling is more psychologically
plausbile .
in tasks in which all of the data arrive simultaneously , such as when a
researcher gives participants a set of objects to sort into groups , participants do not need
to make judgments until all of the stimuli are present .
here gibbs sampling seems
standard implementations of gibbs sampling do not provide a single interpretation
rational approximations to category learning 123
of the data .
the algorithm gathers a set of samples from a probability distribution and all
of these samples are used to infer other properties about the data , such as category labels .
however , we should note that it would be possible to implement a modied version of the
gibbs sampling algorithm that would provide a xed interpretation of the data .
instead of
keeping all of the iterations , we could create a very forgetful gibbs sampler that would
only recall the current values of the variables when making inferences .
likewise , referring
to our third property , gibbs sampling is asymptotically unbiased , meaning that generating
a huge number samples would not introduce any order eects not already present in the
statistical model .
again though , the iterations of gibbs sampling are dependent on one
another , so in the forgetful gibbs sampler we would have iteration to iteration dependence .
this iteration to iteration dependence would not be an eect of the order in which the
stimuli were presented , but instead an autocorrelation of judgments made by this model .
particle lters are designed as sequential algorithms that explicitly use incremental
updating , which clearly satises the rst property and makes this algorithm appropriate
for modeling sequential judgments .
for the second property , the answer depends on the
number of particles .
each particle is a sample from the posterior distribution , so a
single - particle particle lter will provide a single interpretation of the data .
with a
multi - particle particle lter , the interpretation becomes probabilistic .
the order eects
introduced depend on the number of particles , analogous to how the gibbs samplers order
eects depend on the number of samples .
with an innite number of particles , the particle
lter is a very faithful representation of the posterior distribution and thus does not
introduce any order eects not present in the statistical model .
however , small numbers of
particles will introduce order eects and we explore this property in detail later .
rational approximations to category learning 123
comparing the algorithms
using the local map algorithm , the rational model of categorization ( rmc;
anderson , 123 ) has successfully predicted human choices in a wide range of experimental
paradigms .
we introduced two new algorithms for the rmc in the above sections : the
gibbs sampler and the particle lter .
we have demonstrated that both of these
algorithms provide a closer approximation to the underlying model than the local map
algorithm and both share some aspects of its psychological plausibility .
in this section , we
compare the local map algorithm , a sequential updating algorithm , against the sequential
algorithm we have introduced : the particle lter .
most empirical investigations of human
categorization use a sequential trial structure , so we have focused on this comparison
compare the ts of the multi - particle particle lter , the single - particle particle lter , and
the local map algorithm to show that the particle lter provides comparable ts to the
human data and for some paradigms , the particle lter algorithm actually allows the
rmc to better predict human choices .
there are a large number of categorization paradigms on which we could compare
the algorithms we chose to compare the algorithms on several data sets for which the
local map algorithm performs well , including several cases from andersons ( 123; 123 )
original evaluation of the model .
testing our algorithm against data on which the local
map is known to perform well provides a strong test of the particle lter algorithm
examine the eect of specic instances with binary ( medin & schaer , 123 ) and
continuous parameters ( nosofsky , 123 ) , and show the algorithms predict a similar
correspondence with human data .
next we explore paradigms that have been chosen to
highlight dierences between the local map algorithm and the particle lter .
the eects
of trial order ( anderson , 123 ) , how linearly separable and non - separable categories are
learned ( j .
smith & minda , 123 ) , and the wider class of learning problems in the
shepard , hovland , and jenkins ( 123 ) task ( nosofsky , gluck , palmeri , mckinley , &
rational approximations to category learning 123
glauthier , 123 ) are employed to illustrate the advantages of using the particle lter to
approximate the rmc .
eect of specic instances
in a classic paper , medin and schaer ( 123 ) tested whether categorization
judgments were inuenced by the central tendency of a category alone .
in their
experiment 123 , the stimuli were designed so as to test whether the nearness of stimuli had
an eect above contributing to the category center .
the stimuli consisted of six training
items , each with ve binary features ( including the category label , listed last ) : 123 ,
123 , 123 , 123 , 123 , and 123
in the transfer session , the training items and
additional items were rated .
the transfer stimuli are presented in table 123 , ordered by
human category ratings .
these transfer stimuli were structured so that some were closer
to specic instances than others , while the distance to the category centers was constant .
in this experiment , an eect of specic instances was found in the ratings .
anderson ( 123 ) ran the local map algorithm for several dierent values of the
coupling parameter , but with a xed prior of = 123
the order of the training items was
randomized on each block .
low values of the coupling parameter , such as c = 123 ,
produced high correlations to human ratings ( r = 123 ) .
at such values of the coupling
parameter , the representation tends to be more exemplar - like than prototype - like , which is
consistent with an eect of specic instances .
we ran the particle lter algorithm on this
experimental design with m = 123 and m = 123 particles .
the particle lter with m = 123
particle was replicated 123 , 123 times and the m = 123 particle particle lter was replicated
123 times .
the results are shown in figure 123
using the same coupling parameter , c = 123 ,
we found good correlations for the multi - particle particle lter ( r = 123 ) and for the
single - particle particle lter ( r = 123 ) .
we also examined lower values of the coupling
parameter .
for c = 123 the local map algorithm produced nearly the same correlation ,
rational approximations to category learning 123
r = 123 , but the single - particle improved somewhat , to r = 123 , as did the particle lter
with m = 123 particles ( r = 123 ) .
prediction performance and the range of predicted probabilities both increase if the
model is trained with the same number of blocks human subjects were trained ( ten )
instead of just a single block .
across coupling parameters , the best correlation with
human ratings were high for the local map ( r = 123 ) , the particle lter with m = 123
particles ( r = 123 ) , and the particle lter with m = 123 particles ( r = 123 ) .
overall , the
results in figure 123 look accurate for all of the models , except for a serious disagreement
between the human data and model predictions for 123 , the seventh stimulus from the
human ratings for 123 diverged from the ratings of 123 and 123 , the fourth and
fth stimuli from the left .
however these three stimuli are the same distances from the
training stimuli , so the models tended to give these three stimuli the same probability of
category 123 as a result .
specic instances with continuous features
the eect of specic instances has been studied with continuous features in nosofsky
( 123 ) .
in this study , subjects were trained on 123 stimuli that varied in brightness and
saturation .
as in medin and schaer ( 123 ) , the category structure could not be learned
using only one feature .
however , in this experiment , the frequency of specic examples
was manipulated .
over the course of two experiments , subjects showed a sensitivity to the
presentation frequency of specic colors .
anderson ( 123 ) t the rmc to these data using
a likelihood function ( following gelman , carlin , stern , & rubin , 123 ) appropriate for
continuous data .
the continuous likelihood used was a gaussian distribution for each
cluster and the chosen parameters are described in the appendix .
in this simulation , the
values of the continuous dimension prior parameters were 123 = 123 and a123 = 123
the label
prior parameter was set to = 123
using these parameters , the local map algorithm had
rational approximations to category learning 123
an overall correlation between the two experiments of r = 123 with the human data .
both the single - particle particle lter and the particle lter with m = 123 particles
were run with these same parameters .
there were 123 , 123 replications of the single - particle
particle lter and 123 repetitions of the m = 123 particle particle lter .
on each
replication , the stimuli were presented in a new random order .
the overall correlation
between the human data in the two experiments and the average output of the model was
r = 123 for the single - particle particle lter and r = 123 for m = 123 particles
again , both types of particle lters perform as well as the local map algorithm .
order eects provide a strong challenge to stationary bayesian models , such as the
statistical model underlying the rmc ( kruschke , 123a , 123b ) .
a dpmm by nature does
not produce order eects , because the observations are exchangeable under the model .
however , order eects are easily found in investigations of human cognition , most saliently
in the primacy and recency eects found in free recall of a list of words ( murdock , 123 ) .
in categorization research , order eects are well established ( medin & bettger , 123 )
examine the order eects found including order sensitivity data collected by anderson and
matessa ( reported in anderson , 123 ) to support the approximation used in the rmc .
the rational model is not able to predict these order eects , but approximations to
the rational model can .
approximations only assign mass to a small portion of the
posterior space over partitions , in eect embodying only a small number of hypotheses
about how the stimuli should be clustered .
when a new trial is added to the
representation , the possible new representations are extensions of the previous
representations .
so , if a particular partition of the existing stimuli is not present among
the particles , then it will never appear when the representation has been updated .
in this
way , the approximation to the dpmm can be led down a garden path by presenting many
rational approximations to category learning 123
early trials that point toward a particular type of representation123
if the likelihood of this
type of representation is large enough , then the particles will all tend to show that
particular representation .
later trials that point toward a dierent partition of the early
trials will not be able to change the partition of the early trials .
as a result , early
examples can have a greater inuence than later trials .
in anderson and matessas experiment , subjects were presented with a set of 123
stimuli in one of two orders , shown in table 123
these stimuli were designed to either
emphasize the rst two features ( front - anchored stimuli ) or the last two features
( end - anchored stimuli ) in the rst eight trials .
subjects were trained in one of the two
orders .
following the training phase , subjects were shown the full set of stimuli on a sheet
of paper and asked to divide the stimuli into two categories of eight stimuli each .
eleven
of twenty subjects presented with the front - anchored order split the stimuli into groups
along one of the two features emphasized by the front - anchored ordering .
fourteen of
twenty subjects presented with the end - anchored order split the stimuli along the features
that were emphasized by that ordering .
overall , there was a signicant result as
twenty - ve of forty subjects ( 123% ) produced the anticipated order eect .
we compared order eects produced by the range of approximation algorithms to
the human data .
for all algorithms , c = 123 and = 123 , the values used for the local map
by anderson and matessa ( anderson , 123 ) .
the adjusted rand index ( hubert &
arabie , 123 ) , a standard measure of distance between partitions , was used to nd the
similarity of the output of the local map and particle lter to each of the four partitions
that split the stimuli along a single feature .
the single - feature - based partition that had
the highest adjusted rand index was selected as the partition for that sample .
if there
was a tie , one of the best was selected with equal probability .
in this experiment the local map algorithm predicts that participants will always
produce the anticipated ordering eect .
we ran the single - particle particle lter for 123 , 123
rational approximations to category learning 123
repetitions and the m = 123 particle particle lter for 123 repetitions in this experimental
design to compare it with the local map .
the single - particle particle lter produces the
anticipated order eect on 123% of trials , while the particle lter with m = 123 particles
produces the order eect only 123% of the time .
in this experiment , the particle lter with
a single particle is closer to the human results than either the local map algorithm or the
particle lter with a large number of particles .
the property of linear separability , in which two categories can be perfectly
discriminated using a line as a decision bound , has been used in experimental designs to
test dierent types of category representations ( medin & schwanenugel , 123; nosofsky
& zaki , 123; j .
smith & minda , 123 ) .
many models , such as prototype models ,
inherently predict that linearly separable categories are easier to learn than non - linearly
separable categories .
in contrast , models such as the rmc do not necessarily predict that
linearly separable categories are easier to learn ( anderson , 123 ) .
an interesting aspect to the study of non - linearly separable categories is exploring
how category outliers are learned .
the standard design is to select two category centers ,
with most training stimuli clustered near to the center .
a small number of outliers ,
however , are actually very close to the center of the other category .
examples of these
types of structures can be seen in table 123
in both these designs , category a consists of
binary features mainly set to zero , and category b consists of binary features mainly set
to one .
one stimulus in each category is an outlier and is a better match to the stimuli in
the other category than to the stimuli in its own category .
prototype models predicts that these outlier stimuli will always be classied in the
incorrect category , while exemplar models can predict that they will be classied fairly
accurately .
smith and minda ( 123 ) ran a series of experiments that examined the
rational approximations to category learning 123
time course of learning central and outlier members of categories .
initially outlier items
were classied as belonging to the incorrect category , but performance improved over
blocks of training trials .
figure 123 displays these average results as well as the results of
individual subjects .
the data of the individual subjects were noisy , so the training blocks
are grouped into three bins which are summarized in bar graphs .
the outlier stimuli could
either both be classied incorrectly ( labelled opposite categories ) , both classied in one
category or another , or both classied correctly .
the decrease in the number of
individuals who classify both outliers incorrectly and increase in the number who classify
both outliers correctly over blocks mirrors the average results .
smith and minda ( 123 ) proposed that the crossover of the outliers from
misclassied to classied correctly seen in the human data was the result of a shift from
prototype - like to exemplar - like processing .
these results were t with a mixture of
prototypes and exemplars .
later work with a variant of the dpmm showed the crossover
could be due to an initial prior for simple representations that is eventually overwhelmed
by the data ( griths , canini , sanborn , & navarro , 123 ) .
an alternative explanation was
proposed by nosofsky and zaki ( 123 ) , who explained the crossover as a transition from
focused attention to a single dimension to more equal weights across all dimensions
experiment 123 , nosofsky and zaki ( 123 ) demonstrated that the exemplar model
constrained to attend to a few dimensions did not t the transfer data after a few blocks
signicantly worse than the full exemplar model .
these additional data provide an
interesting counterpoint to the representational change explanation , but we are unable to
address them because of the computational complexity in tting the rmc with any
approximation algorithm if all the weights can vary independently .
here we focus on what
algorithms allow the rmc to predict a human - like crossover eect .
the rmc using the local map and single - particle particle lter algorithms were t
to both the non - linearly separable and linearly separable conditions in the rst three
rational approximations to category learning 123
experiments of j .
smith and minda ( 123 ) .
to t the models , a grid search was
performed over model parameters , using values of 123 , 123 , 123 , and 123 for the prior
parameters .
independent prior parameters were used for the physical dimensions , p ,
and for the label , l .
the coupling parameter was varied using the values 123 , 123 , 123 , 123 ,
and 123 .
each simulation was repeated 123 , 123 times with the stimuli re - randomized within
block on each simulation , which was the same randomization scheme used for the human
for all eighty settings of the parameters , the combined likelihoods over all
conditions and experiments was compared .
the single - particle particle lter produced a
higher likelihood than the local map algorithm did for each of the eighty settings
better understand how well the two approximation algorithms t the outlier stimuli , we
re - calculated the likelihoods for each parameter setting using only the outlier stimuli
the these stimuli , the single - particle particle lter produced a better t to the data on
seventy - six of the eighty parameter settings .
the best - tting parameters for the local
map were p = 123 for the physical dimensions , l = 123 for the label dimension , and
c = 123 for the coupling parameter .
for the m = 123 particle lter , the best tting
parameters were p = 123 , l = 123 , and c = 123 .
the maximum likelihood ts for the local
map and single - particle particle lter are shown in figure 123
the local map algorithm
produces a cross - over of the average of the outliers : going from both mis - classied to both
classied correctly over blocks , at least for experiments 123 and 123
however , the results of
the individual runs show that the local map does not produce crossovers on individual
runs of the algorithm .
instead , examination of the bar plots of individual runs show that
the local map crossover is an artifact of averaging .
unlike the local map , the
single - particle particle lter produces both average crossovers and individual crossovers , as
seen in the changing bar plots of individual runs .
the intuitive reason the local map algorithm does not produce human - like
rational approximations to category learning 123
crossovers for individual runs is because it becomes stuck in a pattern based on the initial
ordering of the stimuli .
to illustrate this idea , we will make the simplifying assumption
that each of the central items of category a are assigned to one cluster and all of the
central items of category b are assigned to a second cluster .
the logical possibilities for
an outlier is that it is assigned to the correct cluster , assigned to the incorrect cluster , or
assigned to its own cluster .
whatever cluster it is initially assigned to , which depends on
the parameter settings and the order of the stimuli , it will likely be assigned to the same
cluster in later blocks .
the repetition occurs because the cluster the outlier was assigned
to initially had the highest probability of generating that stimulus , and on subsequent
blocks this cluster will contain a copy of the outlier , which increases the likelihood of
assignment to this cluster .
the local map algorithm always assigned stimuli to the
maximum likelihood cluster , so that the initial assignment of the outlier is almost
perfectly predictive of its later assignment .
in fact , examining samples of 123 runs of the
local map using the best parameters on each experiments non - linearly separable
condition , the initial assignment was perfectly predictive of all later assignments .
in contrast , the stochastic assignment of the single - particle particle lter allows for
individual runs of the rmc to display crossovers .
unlike the local map , the particle lter
allows an outlier to be assigned to a less - probable cluster , depending on the relative
probability of the new cluster .
one way in which sampling can cause crossing - over is if an
outlier is initially assigned to a cluster containing the central stimuli from the other
category .
this outlier will initially be categorized incorrectly .
but in later blocks , the
outlier has the possibility of being assigned to a new cluster that contains only that
outlier .
once the outlier is assigned to a new cluster , the outlier in later blocks tends to be
assigned to the same cluster , because the new cluster contains only the outlier and thus is
a very good likelihood match .
prediction of the outliers category label will become more
accurate , because the cluster containing only the outlier will have a stronger inuence over
rational approximations to category learning 123
blocks and it predicts the correct category label .
as the assignments are stochastic , the
block on which the crossover occurs will vary over runs of the algorithm .
the prediction of
individual crossovers at variable blocks in training matches the human data .
the prediction of the single - particle particle lter stands in contrast with the
prediction of a particle lter with a very large number of particles .
each block contains a
random ordering of all of the training stimuli , so as the number of particles becomes very
large , the distribution over partitions on each run of the model after each block will be the
unlike the single - particle particle lter , a particle lter with many particles will not
be able to predict between - subject variability with the same parameters , which is an
interesting consequence of the single - particle particle lter .
the number of particles
needed to produce the same outcome on each block is actually quite large , as simulations
with m = 123 , 123 particles still showed between - run variability , so this may only be a
problem for the ideal statistical model .
learning types of category structures
a wide range of learning problems were examined in the classic experimental design
of shepard et al .
( 123 ) .
binary stimuli with three dimensions were divided into all
categories of equal size , and six interesting categorization problems emerged
problems , shown in figure 123 , were numbered by their diculty , with type i the easiest
and type vi the hardest .
in a later replication and extension of this design , nosofsky et
( 123 ) collected data on the time course of learning for these six problems , shown in
in addition to running the experiment , nosofsky et al .
( 123 ) t the rmc using the
local map algorithm to the data .
the best tting parameters were p = 123 ,
l = 123 , c = 123 , and a response mapping parameter ( used as an exponent to scale
the responses ) of 123 .
this algorithm predicted a sum squared deviation across learning
rational approximations to category learning 123
problems ( ssd ) of 123 .
attempting to replicate this result with the local map revealed
some surprising subtleties of the local map algorithm .
first , sometimes there are ties
between clusters for the cluster with the maximum probability , for which the local map
algorithm must be adjusted .
a straightforward solution is to assign the new stimulus with
equal probability to any cluster that shares the maximum probability .
a more troubling discovery is that there are clusters of the stimuli that have only
slightly less probability than the cluster with the maximum posterior probability
the best parameters of nosofsky et al .
( 123 ) , we found that the maximum ratio of the
second - best posterior probability to the maximum posterior probability could be as high
as 123 .
the behavior of the local map algorithm should be very dierent in the case of
tied probabilities and not - quite - tied probabilities , but the dierence between the two cases
can be very subtle and depend on the precision of the numbers used in the simulation
found this to be the case when using these best - tting parameters : using the double
precision numbers of matlab ( 123 bits ) and assigning ties equally to the best clusters , the
ssd of the local map at these parameters rises to 123 , and the ordering of problem
diculty on the nal block is changed .
a grid search of parameters for both the local map and particle lter algorithms
was done using the same grid as in the linear separability section with 123 repetitions per
algorithm .
a new random order for the stimuli was set for each replication , and the
randomization scheme was the same within - block randomization scheme as used in
nosofsky et al .
( 123 ) .
over the set of all parameters , the single - particle particle lter
algorithm t better than the local map algorithm on 123% of parameter settings
addition , the best t of the local map was a total ssd of 123 , while the best ssd for the
single - particle particle lter was 123 .
the best tting parameters were p = 123 ,
l = 123 , and c = 123 for the local map and p = 123 , l = 123 , and c = 123 for the
particle lter with m = 123 particles .
these results , shown in figure 123 , demonstrate that
rational approximations to category learning 123
the single - particle particle lter exceeds the performance of the local map for the
parameters we tested .
however , the brittleness of local map algorithm in this paradigm
means that there are probably very specic parameter sets that may provide a much
better match to the human data .
summary of simulations
we began with experimental paradigms on which the local map algorithm performs
well ( anderson , 123 ) , and the simulations we have performed demonstrate that the
particle lter algorithm , especially the single - particle particle lter performs as well or
better in these categorization paradigms .
for the eects of specic instances with binary
( medin & schaer , 123 ) and continuous data ( nosofsky , 123 ) , the single - particle
particle lter and the multi - particle particle lter performed about as well as the local
map algorithm .
however , in the later simulations the local map algorithm was
outperformed by the particle lter , especially by the single - particle particle lter .
for the
order eects of stimuli presentation , the local map algorithm predicts order eects that
are stronger than those displayed by human subjects .
a particle lter with m = 123
particles predicted almost no order eects , but for the single - particle particle lter the size
of the order eect was similar to the empirical average .
further advantages of the particle lter were found for newer experiments with
categories that diered in linear separability ( j .
smith & minda , 123 ) .
the statistical
model underlying the rmc predicts that outlier stimuli will initially be categorized
incorrectly , but over blocks will eventually be categorized correctly .
the local map
algorithm did not predict the crossover in individual runs with its best - tting parameters ,
and imitates it in the average data by averaging over dierent trial orders .
in contrast , the
single - particle particle lter predicts both the crossover in average data , as well as
individual variability in how quickly the outlier is learned to be classied correctly .
rational approximations to category learning 123
finally , the local map is extremely sensitive to small changes in probability , as
demonstrated with the data and model ts of nosofsky et al .
( 123 ) .
the absolute t and
even the order of errors of the six problems depended on the precision of the
representation and how ties were dealt with .
in the particle lter , the clustering of a new
example is sampled , providing a much more plausible implementation that is not sensitive
to small changes in relative probability .
bridging the gap between why human cognition might operate the way it does ( as
described by rational analysis ) and how the mind performs the operations required to do
so ( as per process models ) is a fundamental question in cognitive science .
this bridge can
be built in a number of dierent ways : by establishing isomorphisms between models
framed at these two levels ( e . g . , ashby & alfonso - reese , 123; griths et al . , 123; shi et
al . , 123 , in press ) , by describing the rational foundations of process theories ( e . g . ,
gigerenzer & brighton , 123; perfors & navarro , 123; tenenbaum & griths , 123b ) or
by building models that are able to interpolate between heuristic processes and rational
accounts ( e . g . , brown & steyvers , 123; daw & courville , 123; lee & cummins , 123;
sanborn et al . , 123 ) .
in this paper we have pursued the third option , arguing that the
monte carlo principle can provide a foundation for an entire class of rational process
models that are equivalent to rational models when given unlimited processing resources ,
but give rise to fast , simple heuristics when computational resources are scarce .
our analysis of the rational model of categorization provides a good example of
how this idea can be put to good use .
the rmc is an example of a successful bayesian
model of cognition .
it provides a reasonable explanation of how objects should be grouped
into clusters and the result of this clustering can be used to explain many categorization
experiments .
as a purely rational analysis , however , the rmc runs into diculties
rational approximations to category learning 123
because the complexity of the computational problems involved makes inference dicult ,
and the fact that the underlying statistical model cannot produce order eects .
approximation algorithms address both issues , by simplifying inferences and inducing
order eects .
however , the original local map approximation produces some order
eects that could be considered too strong , and unlike people it learns by deterministic
assignments rather than probabilistic ones .
using the monte carlo principle , however , we
are able to derive a particle ltering algorithm that retains the strengths of the local map
algorithm but xes its weaknesses .
a single - particle particle lter retains the desiderata of
anderson ( 123 ) : online updating of the representation plus a single partition of all of the
stimuli into clusters .
the only dierence of the algorithm is that it uses sampling instead
of a maximization operation in order to select new partitions .
the change to using sampling produces some important dierences .
averaging
many runs of the same order with the local map approximation produces the same result
every time .
however , averaging many runs with the same order using sampling produces a
much better approximation to the true posterior .
though each run of a single - particle
particle lter produces a potentially extreme result , the aggregate of these results
resembles the optimal solution .
this eect echoes the wisdom of the crowds : the accuracy
of the average over individuals can exceed the accuracy of the individuals ( surowiecki ,
this eect has also been found for averaging the judgments of a single individual
( vul & pashler , 123 ) .
in addition , for a task that requires learning categories that are
not linearly separable , sampling allows for the model to occasionally assign a repeated
item to a new cluster , allowing it reproduce the nding that people initially categorize an
outlier stimulus incorrectly , but slowly learn the correct response .
the single - particle
particle lter shows a real advantage on this task : not only can it produce the same
results as many particles at a lower computational cost , it produces realistic - looking
individual dierences over runs of the model .
rational approximations to category learning 123
sampling also avoids the necessity of precise representations .
it is implausible that
people would make deterministic choices based on values that are almost exactly equal ,
but this is what the local map algorithm assumes .
nearly indiscriminable choice
probabilities arise in tting the local map algorithm to learning data under a plausible
set of parameters .
in contrast , the particle lter algorithm samples , so that choices
between representations that have nearly equal probability are chosen nearly equally
this algorithm , or one that interpolates between pure sampling and pure
maximization makes for a more psychologically plausible alternative to the local map .
these results , combined with recent work that has successfully applied particle lters to a
range of problems ( brown & steyvers , 123; daw & courville , 123; levy et al . , 123; yi ,
steyvers , & lee , in press ) , lead us to believe that particle lters have the potential to be a
powerful tool for producing rational process models .
the introduction of these new algorithms also inspires the development of
intermediate cases .
it seems necessary to limit the precision of the local map algorithm
in some way to create a psychologically plausible algorithm .
one possible way to do this is
by casting the local map as a sampling algorithm .
as each new stimulus is presented , the
local map algorithm computes the posterior probability , f ( x ) , that the new stimulus
belongs to each of the existing clusters and to a new cluster .
the local map algorithm
selects the maximum of f ( x ) , which we can represent by sampling .
if we construct a new
distribution , g ( x ) f ( x ) , and set = , then sampling from g ( x ) will be equivalent to
taking the maximum value of f ( x ) .
we refer to the parameter as the distributional
scaling parameter123
the usefulness of this representation is that we can use values of
that are less than .
using smaller values of produces a soft - max rule , which greatly
changes the behavior of the algorithm when the best two clusters for a new stimulus have
nearly the same , but not exactly the same probability .
now , instead of always selecting
the highest probability cluster , the adjusted algorithm will select the top two clusters with
rational approximations to category learning 123
nearly equal probability , which is more psychologically plausible .
at the other end of the
range of the parameter , when = 123 , this representation is equivalent to a particle lter
with m = 123 particles , which selects clusters according to their posterior probability .
we should note that our simulations are not particularly constraining on the number
of particles that might best be used to t human participants .
the second desideratum for
psychological plausibility stated that there should be a single interpretation of which
cluster generated an object .
this desideratum is debatable , because it may be that people
can hold multiple hypotheses of how objects are generated .
in simulations we did not
present , we looked at a range of approximations that varied both the number of particles
and distributional scaling parameter .
our simulations were not particularly constraining
for these parameters .
for example , a 123 particles with = 123 produces order eects in the
anderson and matessa experiment that were approximately equal to that produced by the
single - particle particle lter .
we elected to test the local map to the single - particle
particle lter in most of the simulations because it provided a clean comparison between
maximization and sampling .
however , we do not draw the conclusion that a
single - particle particle lter is necessarily the way forward .
other work has successfully t
individual subject data by varying the number of particles ( brown & steyvers , 123 ) .
more generally , the monte carlo principle can be used to motivate other interesting
psychological processes .
as noted earlier , exemplar - based category learning can be
interpreted as a kind of importance sampling ( shi et al . , 123 , in press ) , and the eld of
decision - making already has many sampling - based theories ( lee & cummins , 123;
ratcli , 123; stewart et al . , 123; vickers , 123 ) , but other possibilities exist .
in the area
of problem solving which , to a large extent is dened in terms of a focus on dicult
learning problems several avenues of work seem promising .
for instance , to the extent
that incubation eects in problem solving ( s .
smith & blankenship , 123; wallas ,
123 ) relate to a loss of xation of mental set , they could be interpreted as a form of
rational approximations to category learning 123
particle rejuvenation .
similarly , while trial - and - error learning can be quite complex ( anzai
& simon , 123 ) , it is nevertheless a natural candidate for markov chain monte carlo
explanations .
more speculatively , the fact that human problem solving is not invariant to
changes in surface form ( kotovsky , hayes , & simon , 123 ) makes sense given the monte
carlo principle , insofar as reparameterization of the hypothesis space can make an
inference problem harder or easier .
rational models of cognition provide a way to understand how human behavior can
be explained in terms of optimal solutions to problems posed by the environment
promise of rational process models is that they can link the platonic world of ideal forms
and ideal learners to the less lofty reality of inexact representations and limited resources .
by linking these two levels of analysis more closely , we can build models that more
completely characterize both the why and the how of human cognition .
rational approximations to category learning 123
