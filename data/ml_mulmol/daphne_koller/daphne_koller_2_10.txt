markerless tracking of human pose is a hard yet rele - vant problem .
in this paper , we derive an efcient ltering algorithm for tracking human pose at 123 - 123 frames per sec - ond using a stream of monocular depth images .
the key idea is to combine an accurate generative modelwhich is achievable in this setting using programmable graph - ics hardwarewith a discriminative model that feeds data - driven evidence about body part locations .
in each lter iteration , we apply a form of local model - based search that exploits the nature of the kinematic chain .
as fast move - ments and occlusion can disrupt the local search , we utilize a set of discriminatively trained patch classiers to detect body parts .
we describe a novel algorithm for propagating this noisy evidence about body part locations up the kine - matic chain using the unscented transform .
the resulting distribution of body congurations allows us to reinitialize the model - based search , which in turn allows our system to robustly recover from temporary tracking drift .
we provide extensive experimental results on 123 real - world sequences using automatic ground - truth annotations from a commer - cial motion capture system .
if motion capture technology were to become conve - nient , cheap , and applicable in natural environments , then a whole range of applications would become possible , such as intuitive human - machine interaction , smart surveillance , character animation , virtual reality and motion analysis .
it is likely that many such applications will become apparent once the technology is available .
the only viable solution today , that is , marker - based hu - man motion capture , has so far mainly been used in the en - tertainment industry , largely because the need for special - purpose cameras and inconvenient markers or suits requir - ing high operation costs .
as a result , there has been much
interest in the area of markerless motion capture , and such systems are becoming more popular ( 123 ) .
in recent years , algorithms have been proposed that cap - ture full skeletal motion at near real - time frame rates; how - ever , they mostly rely on multi - view camera systems and special controlled recording conditions that limit their ap - plicability .
less expensive systems that use a narrow base - line camera system have not yet reached a similar level of maturity .
most monocular approaches so far aim at solv - ing simplied versions of the full articulated motion cap - ture problem , such as gesture disambiguation , or capture of restricted motion for certain parts of the body .
time - of - ight sensors are a technology that offers rich sensory information about a large part of the scene and , at the same time , enables a convenient , non - invasive system setup .
these sensors provide dense depth measurements at every point in the scene at high frame rates .
the range data provided allows easy segmentation of the human body and can also disambiguate poses that would otherwise have similar appearance and therefore confuse most monocular systems .
range sensors , in general , lend themselves to a faithful generative model ( as the robotics literature shows ) , because they are not sensitive to changes in lighting , shad - ows , and the variety of the problems that make it nearly impossible to generatively model intensity images .
in the future , these sensors are likely to be as cheap as webcams are today .
thus , we approach the human motion capture task using time - of - ight sensors .
despite the advantages of depth sensors , however , several hard problems have to be dealt with , including the high dimensionality of the state - space ( 123 degree - of - freedom in our case ) and the nonlinear , highly peaked likelihood function .
we propose in this paper a probabilistic ltering frame - work that employs a highly accurate generative model which is achievable in this setting using an efcient gpu implementationwith a discriminative model .
our algo - rithm was developed specically for fast operation at video frame rates , since natural communication requires a low - latency action - reaction cycle .
the presented system re -
quires 123 123ms per camera frame to estimate the joint angles of a 123 degree - of - freedom human model .
our primary contribution is a novel algorithm for combining discriminative part detections with local hill - climbing for this task .
our secondary contribution is the denition of a smooth likelihood function and a means of implementing it on readily available graphics hardware ( gpus ) efciently in order to obtain near real - time perfor - mance .
in addition to this , we constructed an extensive set of real - world test sequences with annotated ground truth , which are published openly ( 123 ) for future benchmarks .
related work
the automatic analysis of human shape and motion from sensor data has been researched considerably as moes - lund et al .
( 123 ) illustrate in their survey covering more than than 123 papers .
several learning based approaches ( 123 , 123 , 123 ) attempt to directly map image structures , silhouettes or features com - puted from them directly to poses .
while this is an inter - esting approach in general , it is not clear yet how to scale it robustly to the general problem setting in unconstrained environments due to the high dimensionality of the human pose space .
related to our approach , this line of research would t well into the data - driven component of our algo - rithm described in sec .
similarly , several papers try to detect parts of the body which they assemble into a com - plete form , termed pictorial structures .
although operating on high quality point clouds obtained from laser scans in - stead of video , rodgers et al .
( 123 ) take a similar approach that uses discriminative methods to populate the domains of discrete variables in a bayesian network .
in the multi - view vision setting , sigal et al .
( 123 ) apply a similar strategy , but use nonparameteric belief propagation for their inference method .
our approach differs in that we perform inference in the continuous domain and that we are working on tem - poral data with a noisier sensor .
our approach to body part detection employed in this work is described in ( 123 ) .
much work has also focused on sampling - based methods ( 123 , 123 , 123 ) , including partitioned sampling , which updates subsets of parameters , and hierarchical sampling , which starts at the top of the kinematic chain and proceeds down - wards .
in our approach , we adopt the idea of hierarchical search along the kinematic chain , but replace random sam - pling with deterministic sampling because it is allows in - creased efciency through precomputation .
recently there have been several attempts to track people using a time - of - ight ( tof ) camera .
grest et al .
( 123 ) apply non - linear least squares to edge maps , that are associated from frame to frame .
knoop et al .
( 123 ) use a stereo camera and a tof camera to t a cylindrical 123d body model to the data via the iterative closest point ( icp ) algorithm .
both pa - pers focus on tracking of the upper body only .
due to their
figure 123
left : the human body is modeled by a kinematic chain and a 123d surface mesh .
right : the dynamic bayesian network modeling the poses xt of the tracked person and the recorded range measurements zt .
local nature , both algorithms are susceptible to losing track when the motion is too fast .
recently , zhu et al .
( 123 ) have proposed an algorithm for upper - body tracking from one tof camera .
their algorithm is based on hand - engineered heuristics for detecting joints of the upper body and is opti - mized for upper front - facing poses .
these algorithms do not include any reinitialization component and operate through local optimization initialized from the previous frame .
the related problem of tracking using one or many video cameras has also received much attention .
the classic work by bregler et al .
( 123 ) tracks a person from a single camera using optical ow to obtain frame - to - frame cor - respondences , which are used to calculate motion deriva - tives , which are propagated up the kinematic chain .
by as - sumption , their approach is limited to motions parallel to the image plane , and it is also susceptible to losing track .
however , the central idea of propagating information from the image up the kinematic chain is one that we exploit in our algorithm , although we use the unscented transform to achieve higher quality linearization .
there is a growing trend in papers that use pro - grammable graphics hardware ( gpus ) to implement com - puter vision algorithms ( 123 ) .
the parallel nature of compu - tation on a gpu as well as their optimization for operating on images leads us to believe , that they are an ideal platform for computer vision algorithms , especially when real - time performance is paramount .
we exploit gpus to perform large numbers of likelihood evaluations efciently .
probabilistic model
the objective is to track an articulated body over time using a stream of monocular depth images .
we rst dene a probabilistic model for the variables of interest in this sec - tion and then describe how to efciently perform inference in sec
we model the body as a collection of 123 rigid body parts , which are constrained in space according to a tree - shaped kinematic chain ( skeleton ) , see the left diagram in fig .
a kinematic chain is a directed acyclic graph ( dag )
with well - dened parent - child relations .
the surface ge - ometry of the model is represented via a closed triangle mesh , which deforms with the underlying kinematic chain by means of a vertex skinning approach ( 123 ) .
we de - note the conguration of the body by xt = ( x i where each i indexes a uniquely dened body part in the chain .
the transformations xi can be represented in vari - ous ways , such as using homogeneous matrices or in vec - tor / quaternion form .
independent from the choice of rep - resentation , x i denotes the position and orientation of a specic body part relative to its parent part .
the chain is anchored to the world at the pelvis x 123 t ( which does not have a parent in the kinematic tree ) .
in our model , we allow the pelvis to freely rotate and translate .
the remaining body parts are connected to the their parent via a ball joint , which allows them to rotate in any direction , but not to translate .
we obtain the absolute orientation w i ( x ) of a body part i by multiplying the transformations of its ancestors in the kinematic chain , w i ( x ) = x 123 x parent ( i ) x i .
in order to determine the most likely state at any time , we must dene a probabilistic model .
the state at time t is the pose xt and its rst discrete - time derivative vt .
the measurement is the range scan zt .
we model our system as a dynamic bayesian network ( dbn ) , see the right dia - gram in fig .
123 , which encodes the markov independence assumption that xt and vt are independent of z123 , .
, zt123 given xt123 and vt123
this dbn requires the specication of the conditional probabilities p ( vt|vt123 ) , p ( xt|xt123 , vt ) and the mea - surement model p ( zt|xt ) .
we make the assumption that the accelerations in our system are drawn from a gaussian distribution with zero mean123
thus , vt|vt123 n ( vt123 , ) with the covariance matrix being diagonal .
we note that since x is a list of relative transformations , the velocities are also dened relatively .
that is , if k is the index of the knee , v k t encodes the change in the angle between the shin and thigh at frame t .
the covariance was specied by hand following bio - mechanical principles and the known video frame rate , although it could easily be set by an au - tomated procedure using the many available human motion
we dene p ( xt|vt , xt123 ) to be a deterministic cpd ( conditional probability distribution ) , that applies the trans - formations in vt to those in xt123
formally , x i with probability 123
t = v i
the measurement model denes the distribution on the measured range data given the state of the system .
the mea - sured range scan is denoted by z = ( zk ) m k=123 where zk gives the measured depth of the pixel at coordinate k .
an example scan is shown in fig .
we assume the conditional indepen -
123note that it is common in the tracking literature to assume random
accelerations rather than random velocities
figure 123
our sensor model for individual range measurements ap - proximates the mixture of a gaussian ( measurement noise ) and a uniform distribution ( outliers and mis - associations ) .
dence of each pixel given the state and scene geometry m ,
p ( zt|xt , m ) = y
t |xt , m ) .
to generate the zk for a specic body conguration x and model m , we transform the vertices corresponding to each part i by its corresponding transformation matrix w i ( x ) .
we then cast a ray from the focal point through pixel k and calculate the distance to the rst surface it hits , which we denote zk .
note , that this is basically a ray - tracing op - eration common place in the computer graphics rendering
given the ideal depth value , we can then apply a noise model for the given sensor .
noise models for time - of - ight sensors have been heavily explored in the robotics litera - ture .
the standard approach is to explicitly model the dif - ferent types of noise that are can occur .
in principle , one can enumerate the effects , such as gaussian noise of the sensor , the probability of a max range reading , outliers , and others .
we approximate such a cpd using the func - tion shown in fig .
let us dene smoothstep ( x ) = ( min ( x , 123 ) ) 123 ( 123 123 min ( x , 123 ) ) .
we dene
p ( |zk zk| ) exp ( smoothstep ( |zk zk| ) ) .
we chose this function because it approximates a gaussian mixed with a uniform distribution and it is a built - in func - tion in the gpu shading language .
our goal is to determine the most likely states xt and vt at time t given the map assignments of the previous frame , that is , xt123 and vt123
at each frame , we face the difcult , high dimensional optimization problem h xt , vti =
argmaxxt , vt log p ( zt|xt , vt ) +log p ( xt , vt| xt123 , vt123 ) ,
for which we describe an efcient solution in sec
as a central component of our optimization problem , the previously described measurement model p ( zt|xt , vt ) is inadequate due to its sensitivity to incorrect models m and to slight changes in the state x .
parts of the model that vio - late their silhouette in the measured image will be penalized heavily .
for instance , slightly translating an object will re - sult in all pixels at the edges evaluating an incorrect depth
value , which would be penalized heavily .
the sensor model partially accounts for this over - sensitivity through the use of a heavy - tailed distribution .
in the literature , it has frequently been observed that the true likelihood is often ill - suited for optimization , and sur - rogate likelihoods are often used ( 123 ) .
we develop a func - tion that is more robust to the mis - association that occurs during optimization .
let us rewrite this likelihood l ( x ) in terms of z ( x ) , the depth image obtained through ray - l ( x ) = pk log p ( zk|z ( x ) ) = casting applied to x .
pk log p ( zk|zk ( x ) ) .
we construct an alternate smoother
lsmooth ( x ) = x
log p ( zk|zj ( x ) ) + ( j , k )
parametrized by a penalty function .
here , ( j , k ) rep - resents a cost for choosing a different pixel index than the one predicted by ray casting .
in our case we dene ( j , k ) = , if j is not an immediate pixel neighbor of k , ( j , k ) = 123 , if j = k and set ( j , k ) to a constant in all other cases .
we chose the constant 123 according to on the following reasoning : given our sensors eld of view , the subject will be approximately two meters away in order to t completely .
at that distance , moving to a neighboring pixel results in a euclidean distance of a approximately 123 meters perpendicular to the direction the camera is facing .
near the minimum , the log likelihood of the noise model is approximately quadratic .
can be chosen to smooth the likelihood further though this could reduce accuracy .
thus , the total penalty function approximates euclidean distance for close matches .
this section dened the probabilistic state space and measurement model .
inference in this model is non - trivial due to the high - dimensional nature of the space of the kine - matic conguration space x and the associated velocity space v .
this is particularly challenging for our real - time tracking objective , where exhaustive inference is infeasible .
we now describe how to perform efcient map infer - ence at each frame .
we attack this problem in two ways : ( 123 ) a model - based component locally optimizes the like - lihood function by hill - climbing and ( 123 ) , a data - driven part processes the measurement z to reinitialize parts of the lter state when possible .
for the latter component , we derive an approximate inference procedure termed evidence propaga - tion to generate likely states which are then used to initialize the model - based algorithm .
model ( cid : 123 ) based hill climbing search ( hc )
to locally optimize the likelihood , we apply a coarse - to - ne hill - climbing procedure .
we start from the base of
t |v i
kinematic chain which includes the largest body parts , and proceed toward the limbs .
for a single dimension i of the state space , we sample a grid of values about the mean of t123 ) .
for each sample of vt , we deterministically generate the state xt from xt123
the likelihood of this state is evaluated , and the best one of the grid chosen .
the procedure can then potentially be applied to a smaller inter - val about the value chosen at the coarser level .
for example , to optimize the x axis of the pelvis , we might sample values between - 123 to 123 at intervals of 123 meters .
the bene - t of such a procedure is that it is inherently parallel .
we can send a batch of candidates to the gpu , which evalu - ates all of them and returns their costs .
we chose a deter - ministic sampling strategy over stochastic sampling because it allows more precomputation and therefore increases the speed of likelihood evaluation .
evidence propagation ( ep )
a variety of effects can cause the model - based search to fail .
one problem is that fast motion causes signicant mo - tion blur .
additionally , occlusion can cause the estimate of the state of hidden parts to drift .
additionally , the likelihood function has ridges that are difcult to navigate .
we there - fore propose a data - driven procedure that identies promis - ing locations for body parts in order to nd likely poses .
the three steps in this procedure are ( i ) to identify possi - ble body part locations from the current range image , ( ii ) to update the body conguration x given possible correspon - dences between mesh vertices and part detections and ( iii ) to determine the best subset of such correspondences .
123 . 123 body part detection
we consider the ve body parts head , left hand , right hand , left foot and right foot .
the 123d world locations of these parts according to the current conguration x of the body are denoted as pi , i ( 123 , .
note that we represent these parts by single vertices on the surface mesh of the body , such that all pi are deterministic functions of x .
the data - driven detections of body partswhich we describe in the followingare denoted as pj , j ( 123 , .
, j ) , where j n can be an arbitrary number depending on the part detector .
actual body parts as well as the detections have a class assignment ci , cj to ( head , hand , f oot ) .
we obtain the body part detections using the algorithm described in ( 123 ) .
these detections are produced by a two in the rst step extremal points on the recorded surface mesh are determined from the range mea - surement zt to form a set of distinct interest points .
dis - criminatively trained classiers are applied to patches cen - tered on the points to determine to what body part class they belong to .
if the classier is sufciently condent , the fea - ture is reported as a detection ( see ( 123 ) for details ) .
123 . 123 probabilistic inverse kinematics
we now dene a probabilistic model , visualized in fig .
123 , consisting of the variables vt , xt , vt123 , xt123 and pj .
as - suming a correspondence between body part i and detection j , we apply the observation model
pj n ( pi ( x ) , o ) .
we would now like to calculate a map estimate of xt and vt conditioned on xt123 and pj .
this is difcult because the intermediate variable pi is a heavily non - linear function of x .
in order to compute pi ( x ) we must determine the world coordinates w ( x ) , which includes the absolute orientation of each body part .
then we transform pi from its location in the mesh to its nal location in the world .
to tackle this problem , we observe that xt is a determin - istic function of vt and xt123
therefore , we can rewrite pi as a non - linear function pi ( vt , xt123 , vt123 ) .
our approach will be to linearize the function pi .
because the distribution p ( vt| vt123 ) is a linear gaussian , linearizing pi results in a linear gaussian network approximation .
map inference on this model is easy , so we can determine an estimate of argmaxp ( vt| xt123 , vt123 , pj ) .
we linearize about this esti - mate and repeat the procedure until convergence .
there are many ways to linearize pi .
we apply the un - scented transform which is used in the unscented kalman lter in a similar situation .
the basic approach is to com - pute sigma points from the prior distribution on vt , apply the non - linear function to them , and then approximate the result with a linear gaussian .
we omit the mathematical details , but it can be shown that this method provides an estimate of the distribution that is more accurate than lin - earization through calculating an analytic jacobian .
to summarize , given a known correspondence between a point in the image and a point in the mesh , we can perform approximate map inference using the algorithm just de - scribed .
the algorithm is related to existing methods for in - verse kinematics using non - linear least squares , except that it performs linearization using the unscented transform , and it admits prior distributions on the variables .
figure 123
dynamical model for the integration of body part detec -
is spurious , and if not , which specic body part it is asso - ciated with , constrained by the body part class of the detec - tion .
this results in a large number of possible combina - tions .
considering each such combination , which requires performing hill - climbing , would be far too time consuming for a real - time system .
we therefore prune detections that are near any part location in x best .
this perhaps unintuitive heuristic is based on the observation that discriminative de - tections are needed most when the hill climbing approach has lost track .
when such a loss has occurred , it is hoped the the discriminative algorithm will detect a part far from the location of any part in x best .
when the hill climbing al - gorithm is doing well , the part detections will be near their location in x best and therefore can be ignored .
we prune detections near any part in x best because the part classiers can often confuse classes .
the next step is to expand the detections into a set of concrete correspondences .
a can - didate correspondence ( ( pi , pj ) ) is created for each body part to all detections with a matching class , that is ci = cj .
for instance , a correspondence is created for the right hand to all hand detections .
at this point , we have a concrete list of possible corre - spondences from which we must choose a subset .
we ap - proach this problem in a greedy fashion .
we iterate through each possible correspondence , and apply evidence propa - gation , initialized from x best to nd a new posterior mode
update x best by local hill - climbing on the likelihood
extract part detections from zt
123 . 123 data association and inference
prune hypotheses that are already explained
we now give the entire algorithm for determining xt from xt123 and zt .
in this section , we only assume we are given a set of part detections and their estimated body part classes , ( pj , cj ) .
the algorithm begins with an initial guess x best set to xt123 , which is repeatedly improved by integrating
the algorithm begins by updating x best with the estimate from produced by hill - climbing as described in sec .
part detections are then extracted from the measurement zt .
in theory , we have to decide for each detection whether it
produce set of correspondences ( ( pi , pj ) ) by expanding hy -
loop i = 123 to n
( a ) let x be the posterior mode of evidence propagation
initialized from x best conditioned on ci
( b ) update x by local hill - climbing on likelihood ( c ) if likelihood of x > x best , set x best to xc
figure 123
tracking algorithm .
hc + ep
expectation propagation ( ep ) hill climbing ( hc ) our approach ( hc+ep )
average error of ground truth recording error reduction of our approach ( hc+ep ) w . r . t
test sequence id
figure 123
tracking results on real - world test sequences , sorted from most complex ( left ) to least complex ( right ) .
x which incorporates the current correspondence only .
ep thus allows us to make a big jump in the state space .
we then restart local hill - climbing from x to rene it .
if the nal likelihood is better than x best , x best is replaced with the pose found .
when this occurs , the candidate correspon - dence is considered to be accepted .
the only effect of this on the subsequent iterations of the algorithm is through its update of x best .
the correspondence is not incorporated during subsequent states of ep , so that subsequent , possi - bly better , correspondences can override earlier ones .
we have observed that this algorithm succesfully rejects incor - rect correspondences because the state resulting from their incorporation will be penalized by the likelihood function .
gpu - accelerated implementation
several technical details enable the efcient evaluation of more than 123 123 candidates per second on the gpu .
the main considerations are to maximize parallelism and to minimize uploading and downloading large amounts of data .
the mesh is initially simplied using quadratic edge decimation and uploaded to the gpu along with the part assignments for each vertex .
we use a custom skinning ver - tex shader that allows us to simply upload the transforma - tion matrices for the entire conguration in order to render the entire body , without transferring any other data .
an - other shader calculates the measured ray length ( since the z - buffer has limited precision ) and implements the actual cost function as described above .
because issuing opera - tions to the gpu involves a certain latency , we process a batch of candidates simultaneously .
we render a grid of candidates tiled on a single texture .
this texture is then compared against the observation in parallel for each tile .
by ensuring that the dimensions of the grid are a power of two , we can exploit the built - in functionality of the gpu to generate a mip - mapped texture .
a mip - mapped texture is one which contains versions of itself at progressively lower resolutions , each calculated by averaging pixels at higher
resolutions .
by reading a particular mip - map level , we can directly read out the average costs of each candidate , one per pixel , which is the minimum amount of data we can transfer back to the cpu .
the described algorithm was fully implemented in c++ and evaluated on real sequences .
the goal of this experi - mental evaluation is to show that
our proposed system is able to estimate the pose and conguration of a human over time using only a stream of depth images ,
proposing candidates using ep on detected body parts signicantly improves performance over just doing lo -
the smoothed energy function ( eq .
123 ) outperforms the
typically used pixel - wise energy function , and
the system runs close to real - time at 123 frames per sec -
to this end , we have created a sophisticated test data set , that allows quantitative analysis of the tracking per - formance .
the data set , which is available openly as a benchmark along with our results ( 123 ) , consists of 123 real - world depth - image sequences of varying complexity ranging from short sequences with single - limb motions to longer sequences including fast kicks , swings , self - occlusions and full - body rotations .
our denition of com - plexity , though subjective , increases with the length of the sequence , amount of occlusion , speed of motion , number of body parts moving simultaneously , and rotation about the vertical axis .
the depth image stream is collected using a swissranger sr123 time - of - flight camera , which was set to record full - frame infrared intensity images and depth at 123 fps and a resolution of 123 123 pixels , which we sub - sample to 123 123 pixels in order to take advantage of the gpu more effectively .
in addition to the stream of depth im -
absolute tracking error
average error , hc average error , hc+ep max error , hc max error , hc+ep
figure 123
a typical situation in which data - driven evidence is crucial for tracking success ( excerpt from seq .
left : three exemplary frames from the tennis sequence .
model - based search ( top row ) loses track of the tennis swing , since the arm was occluded .
our combined tracker that integrates bottom - up evidence about body parts ( bottom row ) is able to recapture the fast moving arm .
the right diagram shows the same situation in terms of actual tracking error ( see text ) .
ages , we recorded the locations of 123d markers attached to the subjects body using a commercial active marker motion capture system .
these measured marker locations serve as the ground truth in our error metric .
concretely , we con - sider the following evaluation metrics
max = maxi ||mi mi|| ,
where m is the number of visible motion - capture markers , mi are the true 123d locations and mi are the corresponding 123d locations on the estimated surface mesh of the tracked person .
through visual inspection , we found that individual marker errors ||mi mi|| of 123m or lower can be inter - preted as perfectly tracked markers , since this corresponds to the approximate accuracy of the recorded ground truth data .
on the other hand , marker errors of 123m or larger can be interpreted as tracking failures .
in order to evaluate the effectiveness of the combination of model - based and data - driven approaches , we show the results of two algorithms in addition to our proposed algo - rithm on this extensive dataset .
the algorithm labeled ep consists of our overall algorithm with local hill - climbing
removed .
it simply proposes modes determined by ep , and keeps the one with highest likelihood .
the algorithm la - beled hc consists of just the model - based hill - climbing al - gorithm alone .
we note that the mesh model for all algo - rithms was provided semi - automatically using a cyberware laser scanner .
the joint locations were determined using the scape algorithm ( 123 ) .
figure 123 shows numerical results on our data set for all three algorithms .
in the top panel , we show the errors of all algorithms .
the results show that the data - driven method in isolation ( ep ) performs far worse than the other two ap - proaches .
because of the high error of the data - driven al - gorithm alone , in the remaining plots we only consider the model - based algorithm and the combined algorithm .
in the bottom panel , we visualize the difference in error between the combined approach ( hc+ep ) and the model - based ap - proach ( hc ) .
in all the sequences , the combined approach performs best or equally well .
it is interesting to note that on the harder sequences ( left side ) , the difference in performance is more pronounced .
to analyze this in more detail , we consider a challenging excerpt from sequence 123a fast , partially occluded ten -
nis swing as visualized in the left panel in fig .
the right panel in this gure shows the trace of the error - metrics com - paring the model - based and combined algorithm on the ex - cerpt .
in the beginning , the swinging arm becomes com - pletely occluded , followed by moving swiftly forward .
the max measure ( max error in the diagram ) reveals that once the hill - climbing tracker loses track , it never recovers .
our combined approach is able to again nd the mode and con - tinue .
the left panel in fig . 123 illustrates this using three tracked frames from the sequence .
the top row illustrates that the model - based algorithm completely loses the arms , whereas our algorithm is able to nd the arm after an oc - clusion and catch the trailing edge of the tennis serve .
the gure also illustrates through green lines from the detected body parts the associations that the algorithm considered , and how this enables it to use evidence propagation to pull itself back on track .
finally , we also compared the effects of likelihood smoothing on the performance of the algorithms .
we found that the smooth likelihood improved the performance in terms of average error across all sequences and frames by about 123 percent for the model based algorithm and 123 per - cent for the combined algorithm .
the fact that it helped the combined approach more may be a result of the fact that the reinitialization is not always close enough to regain track with the non - smooth likelihood function .
in terms of efciency , both algorithms are close , though the hill - climbing approach is more efcient .
the model - based algorithm ran at about 123 frames per second , whereas the combined algorithm ran at 123 frames per second .
conclusions and future work
the ambitious goal of accurate real - time tracking of hu - mans and other articulated bodies is one that has enticed researchers for many years due to the large number of use - ful applications .
with the hybrid , gpu - accelerated ltering approach introduced in this paper , we believe to have made a large step forward , but there remain more challenges to overcome .
some examples include cluttered scenes , track - ing more than one person at a time , improving the speed fur - ther , and fully automatic model initialization .
moreover , it would be interesting to integrate traditional imaging modal - ities such as color cameras or to apply the developed tech - nology to stereo vision setups .
acknowledgments .
this work was supported by nsf ( iss 123 ) , muri ( n123 ) , and the boeing company .
