this paper addresses the problem of tracking and diagnosing complex systems with mixtures of discrete and continuous variables .
this problem is a difcult one , particularly when the system dynamics are nondeterministic , not all aspects of the system are directly observed , and the sensors are subject to noise .
in this paper , we propose a new approach to this task , based on the framework of hybrid dynamic bayesian networks ( dbn ) .
these models contain both continuous vari - ables representing the state of the system and discrete vari - ables representing discrete changes such as failures; they can model a variety of faults , including burst faults , measurement errors , and gradual drifts .
we present a novel algorithm for tracking in hybrid dbns , that deals with the challenges posed by this difcult problem .
we demonstrate how the resulting algorithm can be used to detect faults in a complex system .
the complexity and sophistication of the current genera - tion of industrial processes , and the growing need for au - tonomous agents that control physical systems , motivate the need for robust online monitoring and diagnosis of complex hybrid systems ( e . g . , ( isermann 123 ) and ( mcilraith et al .
123 ) ) .
we want to monitor the state of the system , reliably detect abnormal behavior , and diagnose the failure .
sev - eral approaches have been used for dealing with this prob - lem , but each has its limitations .
the traditional model - based schemes for diagnosis and control suffer from com - putational intractability and numerical convergence prob - lems .
the qualitative reasoning mechanisms that dominate this work in the ai community mitigate some of these prob - lems; however , the lack of precision in the representation , and the ambiguities introduced by the reasoning framework can lead them to perform poorly when applied to complex system with continuous dynamics ( hamscher , console , & de kleer ( eds . ) 123 ) .
in this paper , we propose a different approach to this prob - lem , where we model a complex hybrid system as a dynamic bayesian network ( dbn ) .
this model implicitly denes a probability distribution over projected trajectories of the sys - tem state over time .
in this sense , it is similar to the very successful kalman lter ( kalman 123 ) .
for systems with linear dynamics and gaussian noise , the kalman lter pro - vides an excellent means for tracking system state .
unfortu - nately , real - life systems are rife with nonlinearities , many of
copyright c 123 , american association for articial intelli - gence ( www . aaai . org ) .
all rights reserved .
which are expressed as discrete failure modes that can pro - duce discontinuous jumps in system behavior .
hybrid dbns accommodate a much greater range of problems , including nonlinear dynamics and discrete failure modes that inuence system evolution .
they can directly represent the noise asso - ciated with the system evolution and measurements , as well as the probabilities of faults and their effects .
we rst show that many interesting aspects of diagnostic models can be represented in the dbn framework .
in par - ticular , we show that they allow a natural encoding of the representation of higher - order system dynamics used in the temporal causal graph ( tcg ) framework of mosterman and biswas ( 123 ) .
in fact , a tcg can be used to provide the skeleton for an appropriate dbn model .
we also show that many interesting types of failures can be modeled naturally in the dbn , including burst faults , parameter drift , and mea -
there are several advantages to the use of general proba - bilistic models , such as dbns , for fault detection and diag - nosis .
a dbn is complete model of the system .
using this model , the state of the system , including its failure modes , is tracked by maintaining a probability distribution over possi - ble system states given all of the measurements so far .
this belief state distribution is an exact representation of our best possible beliefs given all of the available evidence .
cludes within it the likelihood of different types of failures , as well as a distribution over the relevant system parameters .
in principle , many of the issues that have challenged tradi - tional approaches to diagnosis ranking possible failures , handling of multiple simultaneous failures , and robustness to parameter drift can be addressed within a probabilistic
of course , the inference task that is required for main - taining this belief state is a difcult one .
unlike the case of a simple kalman lter , tracking such systems is generally in - tractable since the number of modes of these systems grows exponentially over time .
we present a novel algorithm that tames this intractability using a combination of several dif - ferent techniques .
we show that this algorithm succeeds in tracking a very difcult scenario on a fairly large system ( one involving ve tanks ) .
we believe that our approach will scale well to substantially more complex systems .
diagnosis of hybrid systems to ground our discussion , we will focus on the diagnosis task for a class of problems typical of chemical manufac -
figure 123 : the two - tank system .
f indicates ow; p indicates pressure; r indicates resistance .
turing processes , which involve the transport of materials ( mostly uids ) into and between tanks .
such domains are well - represented using bond graph formalism ( rosenberg & karnopp 123 ) , where the dynamic behavior of the system is dened by uid pressures and uid ow - rates .
consider , for example , a simple two - tank model , shown in figure 123 ( a ) .
the model represents a system with two tanks that can hold uids , an inlet pipe into tank 123 , two outlet pipes , and a con - necting pipe between the tanks .
the storage tanks are ca - pacitive elements and the connecting pipes are resistive el - ements .
this system is a second order system with natural
the temporal causal graph ( tcg ) framework of ( moster - man & biswas 123 ) is a topological representation that captures local dynamic relations between variables , and pro - vides a more explicit representation of the relation between system parameters and the behavior variables .
the tcg for the two - tank example is shown in figure 123 ( b ) .
here , the variables are the pressure and ow - rate variables associated with the tanks and the pipes in the system .
causal edges in a tcg are labeled with component parameter values and temporal information derived from the characteristics of the related components .
resistive and junction components in - troduce algebraic relations among the system variables , and therefore , dene instantaneous temporal relations such as a direct or inverse proportionality between the variables ( de - noted by ) .
on the other hand , energy storage elements , like capacitive and inductive elements , introduce integral re - lations between system variables ( labeled with a dt ) .
for example , capacitive relations from the ow - rate variable to the pressure variable are labeled with a dt; this implies a temporal relation , i . e . , the ow - rate affects the derivative of the corresponding pressure variable .
many systems have the property that they behave nearly deterministically in the absence of a fault .
the deterministic trajectory of the system is often called its nominal trajectory .
in such cases , faults are sometimes dened implicitly as any abrupt change in a parameter that causes a deviation from
the nominal trajectory .
since the temporal causal graph de - nes a set of qualitative constraints on the system it can be used to predict the effects of sudden discontinuous changes in parameters , e . g . , burst faults .
by contrast , tcgs gener - ally are not used identify parameter drift failures , which are the result of gradual changes in system parameters that ac - cumulate over time .
dynamic bayesian networks a dynamic bayesian network ( dbn ) is a temporal stochas - tic model for a dynamic system .
it assumes that the system state can be represented by a set of variables , denoted z .
each of these variables zi can be real - valued or discrete .
we use dt zt to denote the discrete variables in the state .
we partition the continuous variables into two sub - sets : the subset y z are variables that are measurements , i . e . , their value is known to us; the remaining subset x are
the system is modeled as evolving in discrete time steps .
thus , each system variable z has an instantiation z t for each time slice t .
a dbn is a compact graphical represen - tation for the two - time - slice conditional probability distri - bution p zt+ j zt .
it encompasses both the transition model and the observation model .
more formally , a dbn is a directed acyclic graph , whose nodes are random vari - ables in two consecutive time slices : zt and zt+ .
the edges in the graph represent the direct dependence of a time t + variable z t+ each such node is annotated with a conditional probability distribution ( cpd ) , that denes the local probability model p z t+ .
the dbn model is a compact rep - resentation for the two - time - slice distribution via the chain .
we note that the transition probabilities for any variable are deter - mined completely by the value of the variables in the current and previous time step .
this markov assumption requires us to model explicitly any variables , such as failures , that in - duce long - term correlations on the system state .
we return to this issue below .
rule : p zt+ j zt = qi p z t+
on its immediate causes parz t+
j parz t+
j parz t+
for the diagnostic tasks that we focus on , we can restrict attention to a very natural subclass of hybrid dbns the conditional linear gaussian ( clg ) models .
here , we we require that discrete nodes cannot have continuous parents .
we also require that the cpd for a continuous variable be a conditional linear gaussian .
roughly speaking , in a linear gaussian dependence , the node is a linear function of its par - ents with gaussian noise , where the parameters of the linear dependence can depend on the discrete parents .
more pre - cisely , if a node x has continuous parents y; : : : ; yk and discrete parents u , we parameterize its cpd using param - eters au;; : : : ; au;k and u for every instantiation u to the discrete parents u .
then p x j y; u is a gaussian distri -
i= au;iyi and variance
bution with a mean au; +pk
it is important to note that , without discrete variables in the network , this type of dbn denes standard linear gaus - sian dynamics .
hence , in this case , the dbn is simply a graphical representation of the standard dynamics used in a kalman lter , albeit one that makes certain independence
figure 123 : the two - tank dbn .
assumptions explicit .
in the presence of discrete parents , the model represents a mixture of linear models , with the mix - tures determined by the discrete variables .
dbns for diagnosis our goal is to represent a diagnostic system , of the type de - scribed above , as a dbn .
it turns out that we can use a tcg for a system as a blueprint for the skeleton of the dbn .
we can think of a tcg as a schema for a system of equations describing the continuous system dynamics .
we distinguish two types of arcs in a tcg : temporal arcs are annotated with a dt , whereas non - temporal arcs are not .
for any variable x with no incoming temporal arcs , the tcg expresses an instantaneous constraint on x as a function of its predeces - sors .
for a variable x with at least one incoming temporal arc , the tcg expresses a temporal constraint .
we generate a dbn structure from a tcg as follows : for each node xi in the temporal causal graph , we create x t and x t+ to denote the state of the variable at two consec - utive time points .
( in practice , we will merge nodes that are connected by equality constraints in the tcg . ) let xj be a node in the tcg which is a direct predecessor of xi .
if the arc from xj to xi is non - temporal , we add an arc from x t i and an arc fromx t+ to x t .
if the arc is temporal , .
this process sufces we add an arc only from x t to generate the structure for a dbn that models the nominal behavior the system .
to x t+ j to x t+
we then want to add variables that model our observations and represent the failure modes of the system .
our frame - work accommodates for a wide variety of failure modes .
in our presentation , we focus on three important types : burst failures , measurement failures and parameter drift failures .
to accommodate these , we need to make two important ad - ditions to the tcg induced dbn .
since any parameter that
can change must be modeled in the dbn , we add nodes to model the resistance variables .
in our implementation , these were conductances and not resistances , since we preferred to use a multiplicative model .
we also need to add nodes corresponding to presence of burst failures and the presence of measurement failures .
figure 123 shows a dbn created by this process .
the nodes ft and ft simply add incoming ows and this function has been subsumed by the cpds for p and p .
the nodes la - beled with m correspond to our measurements of the ow parameters in the system and the discrete nodes labeled with e indicate the presence of measurement failures .
for exam - ple , we dene the cpd of m to be a normal distribution around f with small variance when e is false , but with a much larger variance when the e is true .
the r variables model the conductances in the system .
these have discrete parents , d , that indicate the presence of faults .
unlike the measurement fault variables , these fault variables have par - ents in the previous dbn time slice .
this is necessary to model persistent events such as drifts .
each conductance fault variable takes on four values : stable , fault , buildup and leak .
when the system is stable , the cpd of the correspond - ing r has low noise .
when a fault occurs , there is a sharp increase in the variance of the corresponding r .
the two drift faults produce a small drift , dened as a percentage of the parameters previous value .
we need the temporal con - nection between the d nodes to reect the fact that drifts persist; once a buildup starts in a pipe it tends to continue .
in this section , we propose an inference procedure for fault diagnosis and detection in models represented as dbns .
as we have mentioned , we can view dbns as a structured representation and extension of traditional kalman lters .
we therefore build our algorithm starting from the classi - cal kalman lter algorithm .
typical extensions to this algo - rithm maintain multiple candidate hypotheses about the state of the system .
at each time step they update a set of candi - date hypotheses and prune out unlikely ones based upon evi - dence .
if the correct hypothesis remains in the candidate set , these algorithms will track the state of the system correctly .
the problem with this type of approach is that it is very difcult to determine which hypotheses to keep for com - plex systems : there are too many possible new hypotheses at each time , and the information needed to prune away bad hypotheses often is not manifested until several time steps after the hypotheses are generated .
we present a novel ap - proach that collapses similar hypotheses into a single hy - pothesis , then present a novel approximate smoothing algo - rithm that we use to improve our ability to effectively reduce the number of hypotheses .
this approach allows us to deal with complex failure modes and sequences involving many failures .
but it does not scale to complex systems that in - volve many possible failures in different components .
we address this problem by combining our techniques with a decomposition method based on the algorithm of boyen and koller ( 123 ) that allows the tracking of very large systems .
tracking and smoothing our dynamic bayesian network represents the complete state of the system at each time step; it includes variables for the various aspects of the continuous state of the system such as pressures or conductances , as well as discrete vari - ables representing possible failures .
this complete model allows us to reduce the problems of fault detection and di - agnosis to the task of tracking ( or ltering ) a stochastic dy - namic system .
the tracking problem is dened as follows .
as the system evolves , we get observations y; y; : : : .
at time t , our most informed evaluation of the state of the sys - tem is our posterior distribution p zt j y; : : : ; yt about the current system state given all of our observations so far .
we call this posterior distribution our time t belief state , and denote it using t .
the probability of a discrete fault vari - able in this belief state takes into consideration all of the evidence up to the present to determine the probability that this fault has occurred .
in principle , tracking is a very easy task , which can be
accomplished by the following propagation formula : t+zt+=p yt+ j zt+z tztp zt+ j ztdzt where is a normalizing constant .
this process is known as a forward pass .
forward tracking gives the best estimate of the likelihood of a fault given the evidence so far .
it cannot , however , deal with cases where a fault is momentary , but whose direct ef - fects are unobservable so that its effects become visible to our sensor only later on .
the reason is that , at the time that the evidence indicates the presence of a previous failure , there is no longer a variable in the belief state that represents the occurrence of that failure .
there is a variable denoting this event at an earlier time slice , but the forward pass only maintains beliefs about variables in the current time step .
to explicitly discover faults of this type , we need to also reason backwards in time , from our current evidence to the time slice where the fault took place .
this process is known as smoothing .
given evidence y; : : : ; yt+ , we compute p zt j y; : : : ; yt; : : : ; yt+ .
the smoothing process in - volves a backward pass where evidence from t + is trans - mitted backwards over the intervening time slices , updating each of them .
we omit details for lack of space .
one case of enormous practical importance is the case of linear systems .
these systems are fully continuous , with linear gaussian cpds .
in this case , zt+ is a linear function of zt and yt+ is a linear function of zt+ , both with some added gaussian noise .
in this case , the belief state can be represented exactly as a multivariate gaussian distribution over zt .
this is the basis for an elegant tracking algorithm called the kalman lter ( kalman 123 ) which maintains this belief state in closed form as the system evolves .
unfortunately , often we cannot apply the kalman lter di - rectly to real - life problems , since many real - life systems are not linear systems .
the continuous relationships be - tween variables are often nonlinear and the failure modes
of the system are often discrete , introducing discontinuous changes in system parameters .
when the system is nonlin - ear , the belief state is no longer a multivariate gaussian , and rarely has a compact closed form representation .
consider our simple two - tank model .
here , we have a product of two random variables : the ow f is the product of the pressure p and the conductance r .
a standard solu - tion to this type of problem is to approximate the nonlinear dynamics with linear dynamics , and then use a standard lin - ear gaussian model .
thus , we try to get the best approxima - tion for the rst and second moments , and ignore the rest .
the classical method of linearizing is called the extended kalman filter ( bar - shalom & fortmann 123 ) ; it approxi - mates the nonlinear function using its second order taylor in our case , the nonlinear function is a product , which is fairly simple , thus we can compute its rst and second order moments in closed form .
a far more problematic type of nonlinearity is caused by discrete state changes that inuence the continuous system dynamics .
for example , a fault might drastically change the conditional mean or variance of a continuous variable such as the conductance .
this type of situation is represented in our model via the dependence of the continuous variables x on the discrete fault variables d .
this type of model creates substantial difculties for a tracking algorithm .
to understand the difculties , let d; : : : ; dt be some particular instantiation of the discrete variables at time ; : : : ; t .
given this instantiation , the dy - namics of the continuous variables are , once again , linear gaussian .
hence , the time t belief state , conditioned on d; : : : ; dt , is a multivariate gaussian over xt .
the dif - culty is that we have one such gaussian for every single in - stantiation d; : : : ; dt .
thus , in order to do exact tracking , we need to maintain a separate hypothesis for every combi - nation of the discrete variables at all times .
the number of such hypotheses grows exponentially with the length of the sequence , which is clearly unacceptable .
a classical tracking algorithm which deals with this prob - lem is described in ( bar - shalom & fortmann 123 ) .
the main idea is to maintain our belief state as a smaller set of hypotheses , each of which corresponds to a single mul - tivariate gaussian .
the algorithm , applied to our setting , is as follows .
it is convenient to introduce the random vari - able h t , each of whose values corresponds to one hypoth - esis .
the distribution of h t corresponds to the likelihood of the hypothesis .
when the algorithm does the forward pass , it considers all the combinations of values of h t and dt+ .
the result is a mixture with k jdj components .
each of these new hypotheses is conditioned on the new measurements yt+ , and using bayesian conditioning we adjust both the mixture weights and the parameters of the multivariate gaussians .
the algorithm them prunes the hy - potheses that have low probability , and selects only the most likely ones to be part of the time t + belief state .
i our setting , we also wish to maintain values for the per - sistent discrete state variables , since the state of the system at time t + depends on these values at time t .
we therefore represent the belief state using a simple graphical model of the form dt h t ! xt .
formally , we represent our time
t belief state t as a mixture tht of k hypotheses , each of which is associated with a single multivariate gaussian txt j ht and a discrete distribution tdt j ht
the deciency of this algorithm is that it selects some hy - potheses exactly , while entirely ignoring others .
cases , the hypotheses that are maintained all correspond to scenarios that are all close to nominal behavior , and are therefore qualitatively quite similar .
by contrast , the pruned hypotheses often correspond to a priori unlikely faults , that can lead to very different behaviors .
we therefore propose a new approach where similar hypotheses are collapsed .
like the pruning algorithm , we start by performing the forward propagation step , dening a set of possible hypothe - ses h t; dt+; let ~ h t+ be random variable whose values correspond to this larger set of k jdj hypotheses .
next , the measurements are introduced , and the result is a mixture distribution t+ over h t; dt+ and xt+ .
our task is to generate the t + hypotheses from this mixture .
we dene a new set of mixture components h t+ , each of which aggregates several of the values of ~ h t+ .
the algo - rithm thereby denes a collapsing matrix that is essentially a deterministic cpd p h t+ j h t; dt+ .
this collapsing matrix is used to dene the belief state t+ , as a weighted average of the mixture components :
t+h t+ = x ~ h t+
p h t+ j ~ h t+ t+ ~ h t+
t+dt+ j h t+ = x ~ h t+
p ~ h t+ j h t+ t+dt+ j ~ h t+
finally , we dene t+xt+ j h t; dt+ to be the closest gaussian approximation ( i . e . , the gaussian that has the same mean and covariances as the mixture ) to
p ~ h t+ p ~ h t+ j h t+p xt+ j ~ h t+ .
the main remaining question is the choice of which hy - potheses to collapse .
we use a greedy approach , that takes into consideration both the likelihood of the different hy - potheses and their similarity to each other .
we sort the dif - ferent hypotheses by their likelihood . 123 then , starting from the most likely hypothesis , we nd the closest hypothesis to it , and merge the two .
note that the merged hypothe - sis will have higher probability , so will remain at the top of the list .
when there are no hypotheses that are close enough , we move to the next most likely hypothesis in our list .
when we have lled our quota of hypotheses , we col - lapse all the remaining hypotheses into one , regardless of how close they are .
as our distance measure , we use the sum of the two relative entropies ( kl - distances ) ( cover & thomas 123 ) between the gaussians associated with the hypotheses .
we note that we deliberately do not use the weights in determining the distance between hypotheses; otherwise , we would invariably collapse unlikely hypotheses into likely ones , even if they are qualitatively very different .
123to reduce cpu time in our implementation , we rst removed all hypotheses with extremely low probability ( ( cid : 123 ) ) , and then use the merging approach to collapse the rest .
both hypothesis collapsing and pruning are myopic meth - ods; they only use evidence observed up to time t .
as dis - cussed above , the effects of some failures have a delay , so a failure at time t may not manifest itself in evidence up to time t .
since a priori failure probabilities are typically quite low , failures could have very weak support in our be - lief state .
thus , by the time the data necessary to diagnose the failure are available , the failure track may be lost .
the obvious solution to the problem is to pick the likely hypothe - ses based not only on past and present evidence but also on future evidence; i . e . , we want to use weights obtained after some amount of smoothing .
however , smoothing requires that we rst propagate a belief state forward in time , and this is the very problem we are trying to solve .
we break this cycle by using a slightly different method of collapsing hypotheses .
instead of sorting the hypotheses by likelihoods we always collapse the two most similar gaussians until our mixture is small enough .
this may lead to a more aggres - sive collapsing since we do not have a bound on the maximal kl - distance between two gaussians that we collapse .
we can afford to be more aggressive here since we will not use the results of smoothing to update our continuous variables , but only to guide our hypothesis reduction method .
it remains to show how we do the backward propagation process required for smoothing .
the primary difculty is the correct handling of the continuous part of our belief state approximation .
the reason is that after collapsing a mixture of gaussians , updating the distribution of each component based only on evidence relative to the result of the collapse is a non - trivial problem .
fortunately , we are primarily inter - ested in getting a more informed posterior for the hypothesis variable , since our main goal is simply to identify the most likely hypotheses .
the continuous parts will typically track correctly if we identify the correct hypotheses .
therefore , we execute smoothing only for the discrete variables .
the process is now easy; assume that we use a looka - head window of time slices ( thus , the last observation we get to see is t + + ) .
the backward message to time step t + is simply the probability of yt++; : : : ; yt++ given h t+ .
this message denes a posterior distribution over h t+ , which can be computed using standard methods .
we now use our collapsing matrix to compute the effect of this new information on dt+l and h t+l ( cid : 123 ) .
in particular , the probabilities of all the components which were collapsed into some ht+ are multiplied by the change in the probabil - ity of ht+ .
this is also intuitively appealing since all the collapsed components were similar , we should change their probabilities by the same factor .
the result is a message to time step t + ( cid : 123 ) , which is propagated in the same way .
when the process terminates at time step t , we have the probability p h t j y; : : : ; yt++ , which we can then use to better guide which hypotheses to eliminate , as well as our collapsing algorithm .
we note , however , that the results of smoothing should be used only for guiding the approxima - tion .
in order to avoid double - counting evidence , it is very important to continue our tracking using our unsmoothed hypothesis weights th t .
one of the underlying assumptions of the algorithm is that it is feasible to enumerate all the possible instantiations of the discrete variables dt .
unfortunately , for non - trivial sys - tems , this assumption is often unrealistic .
the number of possible instantiations of the discrete variables dt grows exponentially with the number of discrete variables in the system .
to deal with this problem , we take an approach introduced for discrete systems in ( boyen & koller 123 ) .
the crucial idea is to make use of the fact that large systems are typically composed of subsystems , and that , while the subsystems are correlated , the interaction between them is often not so strong .
therefore , it might be reasonable to ap - proximate our beliefs about the system using separate beliefs about the subsystems , i . e . , using a belief state where they are independent .
note that this approximation is very different from one that ignores the interactions between the subsys - tems .
as we do the propagation , the state of one subsystem can inuence the state of another; but we then decouple the correlations resulting from this interaction when we main - tain our beliefs about the current system state .
more precisely , we partition the system variables into n disjoint sets , corresponding to the different subsystems .
let di and xi be the discrete and continuous variables in sub - system i , respectively .
as for the case of a single system , we represent the belief state for each subsystem i as a mixture , represented using a hypothesis variable hi .
we also asso - ciate with each subsystem a set of observation variables yi , which are the ones that are most relevant to the subsystem .
i over each subsystem i .
since subsystem i may be inuenced directly by some other subsystems , we cannot perform the inference completely in isolation inside subsystem i .
instead , we consider the ex - tended subsystem which includes subsystem i , and all the variables from other subsystems which inuence it .
our goal is to get a belief state t
given our belief state representation , it is possible to de - scribe the distribution over the extended subsystem as a mix - ture of gaussians .
as in the single subsystem case , we can introduce evidence which changes our probability distribu - tion over discrete variables as well as over continuous vari - ables .
note that different extended subsystems may over - lap , and after introducing different measurements into these subsystems we may have a different distribution over the shared variables .
we synchronize these probabilities using a message - passing algorithm called calibration ( lauritzen & spiegelhalter 123 ) .
as in backward propagation , we only update the discrete variables , not the continuous ones .
as a result of this phase , all the discrete variables are updated using all the measurement information .
this is important , as outside evidence can be important in determining the likeli - hood of the different hypotheses .
it is also possible to modify the smoothing algorithm to use the decomposed representation of the belief state .
the collapsing is done independently in every subsystem using the same algorithm ( and giving a collapsing matrix for every subsystem ) .
the backward messages are used to update the hypothesis variables of each one of the subsystems .
the in - formation can be propagated backwards with the collapsing matrices .
the only difference is that after this propagation ,
figure 123 : five tank system and results
we need to calibrate the discrete variables of the subsystems , just like in the forward pass .
we tested our algorithm on a system which contains ve wa - ter tanks , shown in figure 123
the system contains six con - ductances and ve pressures , which are all free parameters , but only three measurements , making it a challenging sys - tem to track .
in addition , the system contains the three types of failures described in section : drifts , bursts and measure - ment errors , each occurring with probability : .
thus , at every time step every conductance has 123 possible failure modes ( stable , fault , buildup , leak ) and each measurement has 123 possible failure modes .
counting all the possible fail - ures at time t + and the persistent failures from time t , the system has possible failure modes at any point in time , eliminating any hope of using inference without some decomposition of the system .
in our experiments we decomposed the system into ve subsystems , since decompositions into less subsystems de - manded too much memory .
each tank was considered to be a subsystem ( see figure 123 ) .
we tracked ve hypotheses per subsystem , with a lookahead of two steps when doing smoothing .
we tested our algorithm on a complicated se - at t = , r starts to experience a negative drift .
at t = , we introduce two simultaneous measurement
errors in the measurements of f and fo .
at t = , r bursts , and then returns to a steady state .
at t = r starts a negative drift .
at t = r bursts and then returns to normal .
at t = r bursts .
the graph in figure 123 shows the results of tracking r ,
r and r .
initially , at t = the effect of the drift in r was negligible .
the corresponding hypothesis had a prob - ability of : , but after smoothing the probability went up to : .
as a result our algorithm considered this a likely hypothesis , and kept it in the belief state .
at t = the probability of a negative drift went from : to : af - ter smoothing .
at this point our algorithm correctly detected the negative drift , and maintained a very high probability for this event until t = .
at this point , before smoothing , our algorithm considered two hypotheses : a burst in r ( prob - ability ) or the persistence of the negative drift and a measurement failure ( probability ) .
smoothing raised the probability of a burst ( the correct hypothesis ) to .
the actual values of r were tracked with high accuracy .
the measurement of f made the tracking of r a rel - atively simple problem .
things are much more complicated for r .
not only is there no direct measurement of f , there is no measurement at all in subsystem 123 ! therefore , tracking r is a real challenge .
due to lack of space we omit the actual numbers , but in this run our algorithm de - tected the drift as soon as it began .
( in other runs the de - tection was sometimes delayed by 123 steps . ) it is also in - teresting to see the behavior of r during the burst .
our algorithm detected the burst , but since no evidence is used in subsystem 123 it could not track the true value of the burst correctly .
we plan to address this problem in future work by propagating continuous information between the subsys - tems as well as discrete information .
for the measurements failures at t = , our algorithm behaved in almost the same way for the two measurements , so we report on m only .
before smoothing , our algorithm considered two hypotheses a burst in r ( probability : ) or a measurement fault and a persistent negative drift in r ( probability : ) .
after smoothing the probability of the correct hypothesis went up to almost .
we feel that these results demonstrate the power of our al - gorithm , and its ability to correctly diagnose and track even a complex system with a small number of measurements .
conclusions and future work
in this paper , we presented a new approach for monitoring and diagnosis of hybrid systems .
we model these systems as dbns , thus reducing the problem of diagnosis to the prob - lem of tracking .
it is not a surprise that tracking hybrid sys - tems is also a difcult problem .
in this paper we focus on a special class of hybrid systems : ones that given some par - ticular assignment to the discrete variables have linear dy - namics ( or can be linearized with a satisfactory precision ) .
furthermore , we focus on systems that are composed of sev - eral weakly interacting subsystems .
we believe that many real - life physical systems belong to this class of systems .
we present a novel tracking algorithm for this class of systems .
first , we collapse similar hypotheses instead of just choosing the most likely ones .
this technique allows us to use a bounded window look - ahead into the future .
we use future observations to assist us in determining which hy - potheses are the likely candidates and should be kept relative unchanged , and which are less likely and can be collapsed more aggressively .
our nal contribution is introducing a
way to avoid the exponential blowup , caused by many dis - crete variables within a time slice .
we do this by reasoning separately about the different subsystems , while still propa - gating correlations between them .
our initial experiments with this approach are very en - couraging .
we have tested it on a very large system ( one with different discrete states per time slice ) , with a par - ticularly difcult scenario .
our algorithm found most of the faults , showing that it can be used to provide reliable track - ing and diagnosis even for very hard problems .
of course , we plan to conduct further experiments in other domains .
we are currently working on extending the calibration al - gorithm to allow us to propagate information between sub - systems not only for the discrete variables but for continu - ous variables as well .
we believe that this new feature will signicantly improve our tracking capabilities , especially on long sequences with many events .
we are also looking for ways to extend the algorithm be - yond the family of conditional linear systems ( or systems which can be approximated as such ) .
in particular , we hope to be able to handle discrete children of continuous parents and highly non - linear evidence models .
finally , we hope to apply our algorithm on real - life ap - plications and not just on synthetic data .
we are exploring possible applications in the diagnosis domain , such as mon - itoring the performance of an engine , as well as application in other domains , such as visual tracking .
acknowledgments .
this research was supported by an onr young investigator award grant number n123 - 123 - 123 - 123 and by aro under the muri program , integrated approach to intelligent systems , grant number daah123 - 123 - 123 - 123 , and by the terman foundation .
