summary .
we propose a method ( the `gap statistic ' ) for estimating the number of clusters ( groups ) in a set of data .
the technique uses the output of any clustering algorithm ( e . g .
k - means or hierarchical ) , comparing the change in within - cluster dispersion with that expected under an appropriate reference null distribution .
some theory is developed for the proposal and a simulation study shows that the gap statistic usually outperforms other methods that have been proposed in the
keywords : clustering; groups; hierarchy; k - means; uniform distribution
cluster analysis is an important tool for `unsupervised ' learning the problem of nding groups in data without the help of a response variable .
a major challenge in cluster analysis is the estimation of the optimal number of `clusters ' .
123 ( b ) shows a typical plot of an error measure wk ( the within - cluster dispersion dened below ) for a clustering procedure versus the number of clusters k employed : the error measure wk decreases monotonically as the number of clusters k increases , but from some k onwards the decrease attens markedly .
statistical folklore has it that the location of such an `elbow ' indicates the appropriate number of clusters .
the goal of this paper is to provide a statistical procedure to formalize that heuristic .
for recent studies of the elbow phenomenon , see sugar ( 123 ) and sugar et al .
( 123 ) .
a comprehensive survey of methods for estimating the number of clusters is given in milligan and cooper ( 123 ) , whereas gordon ( 123 ) discusses the best performers .
some of these methods are described in sections 123 and 123 , where they are compared with our method .
in this paper we propose the `gap ' method for estimating the number of clusters .
it is designed to be applicable to virtually any clustering method .
for simplicity , the theoretical part of our analysis will focus on the widely used k - means clustering procedure .
the gap statistic our data fxijg , i 123 , 123 , .
. , n , j 123 , 123 , .
. , p , consist of p features measured on n inde - pendent observations .
let dii 123 denote the distance between observations i and i 123
the most common choice for dii123 is the squared euclidean distance j xij xi 123j123
the indices of observations in cluster r , and nr jcrj
suppose that we have clustered the data into k clusters c123 , c123 , .
. , ck , with cr denoting
address for correspondence : robert tibshirani , department of health research and policy and department of
statistics , stanford university , stanford , ca 123 , usa .
& 123 royal statistical society
tibshirani , g .
walther and t .
hastie
results for the two - cluster example : ( a ) data; ( b ) within sum of squares function wk ; ( c ) functions log ( wk ) ( o ) and ^e *nflog ( wk ) g ( e ) ; ( d ) gap curve
be the sum of the pairwise distances for all points in cluster r , and set
so , if the distance d is the squared euclidean distance , then wk is the pooled within - cluster sum of squares around the cluster means ( the factor 123 makes this work exactly ) .
the sample size n is suppressed in this notation .
the idea of our approach is to standardize the graph of logwk by comparing it with its expectation under an appropriate null reference distribution of the data .
( the importance of the choice of an appropriate null model is demonstrated in gordon ( 123 ) . ) our estimate of the optimal number of clusters is then the value of k for which logwk falls the farthest below this reference curve .
hence we dene
gapnk e*nflogwkg logwk ,
where e*n denotes expectation under a sample of size n from the reference distribution .
our estimate ^k will be the value maximizing gapnk after we take the sampling distribution into
account .
note that this estimate is very general , applicable to any clustering method and distance measure dii123
as a motivation for the gap statistic , consider clustering n uniform data points in p dimensions , with k centres .
then , assuming that the centres align themselves in an equally spaced fashion , the expectation of logwk is approximately
log pn=123 123=p logk constant .
if the data actually have k well - separated clusters , we expect logwk to decrease faster than its expected rate 123=p logk for k 123 k .
when k > k , we are essentially adding an ( unnecessary ) cluster centre in the middle of an approximately uniform cloud and simple algebra shows that logwk should decrease more slowly than its expected rate .
hence the gap statistic should be largest when k k .
as a further motivation , note that , in the case of a special gaussian mixture model , logwk has an interpretation as a log - likelihood; see scott and symons ( 123 ) .
to develop the gap statistic into an operational procedure , we need to nd an appropriate reference distribution and to assess the sampling distribution of the gap statistic .
the reference distribution
in our framework we assume a null model of a single component , and we reject it in favour of a k - component model ( k > 123 ) , if the strongest evidence for any such k warrants it , i . e .
we wish to screen the evidence over all k > 123 simultaneously .
this approach of guarding against erroneous rejection of the one - component model is similar to that of roeder ( 123 ) .
a component ( cluster ) of the distribution can be appropriately modelled by a log - concave distribution , i . e .
by a density of the form expf xg , where is a concave function ( unless the distribution is degenerate ) .
standard examples are of course the normal distribution ( with kxk123 and the uniform distribution with convex support .
in walther ( 123 ) it is shown there that it is impossible to set condence intervals ( even one sided ) for the number of modes in a multivariate distribution , a crucial aspect for the goal of this paper .
thus we model the components as log - concave densities instead of the often - used unimodal densi - ties .
we denote by s p the set of such single - component distributions ( or random variables )
to see how to nd an appropriate reference distribution , consider for a moment the
population version corresponding to the gap statistic in the case of k - means clustering :
where msexk emin123ak k x k123 , with the k - point set ak rp chosen to minim - ize this quantity , is the population version corresponding to wk .
we subtracted off the logarithms of the variances to make g123 123
so we are looking for a least favourable single - component reference distribution on x * such that gk 123 123 for all x 123 s p and all k 123 123
the rst theorem shows that in the univariate case such a reference distribution is given by the uniform distribution u u123 , 123
theorem 123
let p 123
then for all k 123 123
tibshirani , g .
walther and t .
hastie
in other words , among all unimodal distributions , the uniform distribution is the most
likely to produce spurious clusters by the gap test .
note that the above problem is invariant under changes in location and scale , thus allowing us to restrict attention to the uniform distribution supported on the unit interval .
calculations show that mseuk=mseu123 123=k123
so there is a formal similarity to a proposal by krzanowski and lai ( 123 ) , following marriott ( 123 ) , who suggested to estimate k by comparing successive differences of wkk123=p .
note , however , that their procedure is not dened for the important single - component case k 123
even more importantly , such an approach will generally fail in a multivariate situation .
theorem 123
if p > 123 then no distribution u 123 s p can satisfy equation ( 123 ) unless its support is degenerate to a subset of a line .
note that the assertion of the last theorem is not contingent on our denition s p of a single - component model .
the same conclusion would apply if we based it on , say , unimodal densities instead .
simple calculations show that employing a reference distribution with degenerate support will result in an ineffectual procedure .
thus the upshot of the theorem is that in a multivariate situation we will not be able to choose a generally applicable and useful reference distribution : the geometry of the particular null distribution matters .
an obvious solution would be to generate reference data from the maximum likelihood estimate ( mle ) in s p .
this is the nonparametric mle of the density under the restriction of being log - concave .
this mle can be shown to exist , as opposed to the mle of a unimodal distribution .
in one dimension , this mle can be computed with the help of the iterative convex minorant algorithm ( see walther ( 123 ) ) .
however , we do not know how to compute the mle in higher dimensions , but the next section shows how the insights gained from theorems 123 and 123 can be used to construct a simple and effective reference distribution .
the computational implementation of the gap statistic
the lesson of theorem 123 was that the multivariate variance structure matters .
our idea is to exploit the shape information in the principal components instead of the more complicated structure provided by the mle .
we consider two choices for the reference distribution :
( a ) generate each reference feature uniformly over the range of the observed values for that
( b ) generate the reference features from a uniform distribution over a box aligned with the principal components of the data .
in detail , if x is our n p data matrix , assume that the columns have mean 123 and compute the singular value decomposition x udv t .
we transform via x123 xv and then draw uniform features z123 over the ranges of the columns of x123 , as in method ( a ) above .
finally we back - transform via z z123v t to give reference data z .
method ( a ) has the advantage of simplicity .
method ( b ) takes into account the shape of the data distribution and makes the procedure rotationally invariant , as long as the clustering method itself is invariant .
in each case , we estimate e*nflogwkg by an average of b copies logw *k , each of which is computed from a monte carlo sample x *123 , .
. , x *n drawn from our reference distribution .
finally , we need to assess the sampling distribution of the gap statistic .
let sd ( k ) denote the standard deviation of the b monte carlo replicates logw *k .
accounting additionally for the simulation error in e*nflogwkg results in the quantity
123 123=b sdk .
using this we choose the cluster size ^k to be the smallest k such that gapk 123 gapk 123 sk123
this `123 - standard - error ' style of rule is used elsewhere ( e . g .
breiman et al .
( 123 ) ) .
in the simulation studies later in this paper and in other real data examples , we have found empirically that it works well .
a more rened approach would employ a multiplier to the sk for better control of the rejection of the null model .
computation of the gap statistic proceeds as follows .
step 123 : cluster the observed data , varying the total number of clusters from k 123 , 123 , .
. , k , giving within - dispersion measures wk , k 123 , 123 , .
step 123 : generate b reference data sets , using the uniform prescription ( a ) or ( b ) above , and cluster each one giving within - dispersion measures w *kb , b 123 , 123 , .
. , b , k 123 , 123 , .
compute the ( estimated ) gap statistic
step 123 : let l 123=b b logw *kb , compute the standard deviation
logw *kb logwk .
flogw *kb lg123=123
and dene sk sdk
123 123=b .
finally choose the number of clusters via
^k smallest k such that gapk 123 gapk 123 sk123
123 shows an example using k - means clustering .
the data ( fig .
123 ( a ) ) fall in two distinct clusters .
the within sum of squares function wk is displayed in fig .
the functions logwk and ^e*nflogwkg are shown in fig .
123 ( c ) , with the gap curve displayed in fig .
123 ( d ) , with 123 standard error bars .
the gap curve has a clear maximum at ^k 123
123 examines the behaviour of the gap estimate with unclustered data .
the raw data are 123 observations uniformly distributed over the unit square .
the observed and expected curves are very close , and the gap estimate is ^k 123
example : application to hierarchical clustering and dna microarray data in this example our data are a 123 123 matrix of gene expression measurements .
each row represents a gene , and each column a human tumour .
the data are taken from ross et al .
( 123 ) and are available at http : / / www - genome . stanford . edu / nci123
the columns have a label ( cancer type ) , but this label was not used in the clustering .
we applied hierarchical ( agglomerative ) clustering to the columns , using squared error and average linkage , and obtained the dendrogram in fig .
not surprisingly , many cancers of the same type are clustered together .
for more on the utility of hierarchical clustering for microarray data , see ross et al .
( 123 ) .
the results for the gap statistic are shown in fig .
the estimated number of clusters is 123
the corresponding cut of the dendrogram is indicated by the dotted line in fig .
however ,
tibshirani , g .
walther and t .
hastie
results for the uniform data example : ( a ) data; ( b ) within sum of squares function wk ; ( c ) functions log ( wk ) ( o ) and ^e *nflog ( wk ) g ( e ) ; ( d ) gap curve
the gap function starts to rise again after six clusters , suggesting that there are two well - separated clusters and more less separated ones .
the derivation for the gap test assumes that there are well - separated uniform clusters .
in cases where there are smaller subclusters within larger well - separated clusters , it can exhibit non - monotone behaviour .
hence it is important to examine the entire gap curve rather than simply to nd the position of its
other approaches
many methods have been proposed for estimating the number of clusters : a good summary is given by gordon ( 123 ) .
he divides the approaches into global and local methods .
the former evaluate some measure over the entire data set and optimize it as a function of the number of clusters .
the latter consider individual pairs of clusters and test whether they should be amalgamated .
hence the gap method is a global procedure .
according to gordon , most global methods have the disadvantage that they are undened for one cluster and hence offer no indication whether the data should be clustered at all .
a very recent proposal is given by cuevas et al .
( 123 ) ; however , this relies on a high dimensional density estimate , which may suffer from the curse of dimensionality .
dendrogram from the deoxyribonucleic acid ( dna ) microarray data : the dotted line cuts the tree , leaving two clusters as suggested by the gap statistic
the dna microarray data
( a ) logarithmic observed ( o ) and expected ( e ) within sum of squares curves and ( b ) the gap statistic for
milligan and cooper ( 123 ) carried out a comprehensive simulation comparison of 123 different procedures .
among the global methods performing the best was the index due to calinski and harabasz ( 123 ) :
chk bk=k 123
where bk and wk are the between - and within - cluster sums of squares , with k clusters .
the idea is to maximize chk over the number of clusters k .
ch123 is not dened; even if it
tibshirani , g .
walther and t .
hastie
were modied by replacing k 123 with k , its value at 123 would be 123
since chk > 123 for k > 123 , the maximum would never occur at k 123
as mentioned earlier , krzanowski and lai ( 123 ) proposed the quantity wkk123=p as a criterion for choosing the number of clusters .
this followed a proposal by marriott ( 123 ) , who used the determinant , rather than the trace , of the within sum of squares matrix .
the actual proposal of krzanowski and lai ( 123 ) dened
diffk k 123=pwk123 k123=pwk
and chose k to maximize the quantity
this is similar to maximizing wk k123=p , but krzanowski and lai ( 123 ) argued that it may have better properties .
note that klk is not dened for k 123 and hence cannot be used for testing one cluster versus more than one .
hartigan ( 123 ) proposed the statistic
wk 123 123
n k 123
the idea is to start with k 123 and to add a cluster as long as hk is sufciently large .
one can use an approximate f - distribution cut - off; instead hartigan suggested that a cluster be added if hk > 123
hence the estimated number of clusters is the smallest k 123 123 such that hk 123 123
this estimate is dened for k 123 and can potentially discriminate between one versus more than one cluster .
kaufman and rousseeuw ( 123 ) proposed the silhouette statistic , for assessing clusters and estimating the optimal number .
for observation i , let ai be the average distance to other points in its cluster , and bi the average distance to points in the nearest cluster besides its own nearest is dened by the cluster minimizing this average distance .
then the silhouette statistic is dened by
si bi ai
a point is well clustered if si is large .
kaufman and rousseeuw ( 123 ) proposed to choose the optimal number of clusters ^k as the value maximizing the average si over the data set .
note that si is not dened for the k 123 cluster .
maxfai , big .
we generated data sets in ve different scenarios :
( a ) null ( single - cluster ) data in 123 dimensions 123 data points uniformly distributed over
( b ) three clusters in two dimensions the clusters are standard normal variables with ( 123 ,
the unit square in 123 dimensions; 123 , 123 ) observations , centred at ( 123 , 123 ) , ( 123 , 123 ) and ( 123 , 123 ) ; ( c ) four clusters in three dimensions each cluster was randomly chosen to have 123 or 123 standard normal observations , with centres randomly chosen as n123 , 123i ( any simu - lation with clusters having a minimum distance less than 123 units between them was
( d ) four clusters in 123 dimensions each cluster was randomly chosen to have 123 or 123 standard normal observations , with centres randomly chosen as n123 , 123 : 123i ( any simulation with clusters having a minimum distance less than 123 units between them was discarded; in this and the previous scenario , the settings are such that about half of the random realizations were discarded ) ; ( e ) two elongated clusters in three dimensions each cluster is generated as follows .
set x123 x123 x123 t with t taking 123 equally spaced values from 123 : 123 to 123 and then gaussian noise with standard deviation 123 is added to each feature .
cluster 123 is generated in the same way , except that the value 123 is added to each feature at the end .
the result is two elongated clusters , stretching out along the main diagonal of a three -
123 realizations were generated from each setting .
in the non - null settings , the clusters have no overlap , so there is no confusion over the denition of the `true ' number of clusters .
we applied six different methods for estimating the number of clusters : ch , kl , hartigan and silhouette are given by equations ( 123 ) , ( 123 ) , ( 123 ) and ( 123 ) respectively .
gap / unif is the gap method with a uniform reference distribution over the range of each observed feature; gap / pc uses the uniform reference in the principal component orientation .
the results are given in table 123
the gap estimate using the uniform reference does well except in the last problem , where the oblong shape of the data adversely affects it .
the gap / pc method , using a uniform reference in the principal components orientation , is the clear winner overall .
the other methods do quite well , except in the null setting where the gap estimate is the only one to show a reasonable performance .
of course it might be possible to modify any of the methods to handle the null ( single - cluster ) case : one possibility would be to simulate their null distribution under uniform data , in a manner similar to the gap estimate .
overlapping classes
the simulation studies suggest that the gap estimate is good at identifying well - separated clusters .
when data are not well separated , the notion of a cluster is not any more well dened in the literature .
in this section , we did a small experiment to assess how the gap method responds to non - separated data .
each simulated data set consists of 123 observations from each of two bivariate normal populations , with means 123 , 123 and , 123 , and identity covariance .
for each sample we computed the gap estimate of the number of clusters and also recorded the proportion of data points from the rst population that were closer to the second population mean , or vice versa .
we call this the amount of `overlap ' .
this was done for 123 values of running from 123 to 123 , with 123 simulations done for each value of .
the results are shown in fig .
roughly speaking , if the overlap proportion is p , then the probability of selecting one cluster is also about p .
the problem of estimating the number of clusters in a data set is difcult , underlined by the fact that there is no clear denition of a `cluster ' .
hence , in data that are not clearly separated into groups , different people might have different opinions about the number of distinct clusters .
in this paper , we have focused on well - separated clusters and have proposed the gap statistic for estimating the number of groups .
when used with a uniform reference
tibshirani , g .
walther and t .
hastie
table 123
results of the simulation study (
estimates of the following numbers of clusters ^k :
null model in 123 dimensions
random 123 - cluster model in 123 dimensions
random 123 - cluster model in 123 dimensions
123 elongated clusters
( numbers are counts out of 123 trials .
some rows do not add up to 123 because the number of clusters chosen was greater than 123
zcolumn corresponding to the correct number of clusters .
distribution in the principal component orientation , it outperforms other proposed methods from the literature in our simulations .
the simpler uniform reference ( over the range of the data ) works well except when the data lie near a subspace .
the dna microarray example shows the importance of graphing the gap statistic , rather than simply extracting the estimated maximum .
with real data the gap curve can have many local maxima , and these themselves can be informative .
there are many avenues for further research .
one is a consideration of other possibilities for the reference distribution : for example , we could proceed sequentially .
having found k clusters , we could generate reference data from k separate uniform distributions , over the support of each of the k estimated data clusters .
as before , a principal component orientation would probably produce better results .
the gap method can also be used with adaptive
gap method for overlapping data : the proportion of times that the method chose one cluster , as a function of the proportion of points in the overlap region between the two subpopulations
versions of k - means clustering ( see for example diday and govaert ( 123 ) ) , which may be better at nding elongated clusters than the standard version .
similarly , it may be applicable to model - based clustering ( fraley and raftery , 123 ) .
a referee raised the interesting question of how to carry out the gap test when the dimension p of the data is unknown and only pairwise dissimilarities are available .
one possibility would be to use multidimensional scaling to map the data into a low dimensional space while preserving the dissimilarities , and then to proceed in this space as described in the paper .
however , a more direct method would be preferable and we leave this as an open
it would be especially useful to develop methods for an efcient simulation of reference data from the log - concave mle .
the use of this distribution in the gap method could then be compared with the uniform reference distribution .
tibshirani was partially supported by national institutes of health grant 123 r123 ca123 and national science foundation grant dms - 123
hastie was partially supported by grant dms - 123 from the national science foundation and grant roi - ca - 123 - 123 from the national institutes of health .
appendix a : proofs
=k for 123 123 j 123 k shows that mseuk 123 efmin j
proof of theorem 123 setting j : j 123 mseuk=mseu123 123 123=k123
thus it is enough to prove
px 123 ii varii
u j123g 123=123k123 , whence
for every partition i123 , .
. , ik of the support of x .
here we write x dpx=px 123 i px 123 i
tibshirani , g .
walther and t .
hastie
for the conditional variance of x given x 123 i .
by standard arguments ( e . g .
convolution with a gaussian kernel and using ibragimov ' s convolution result; see theorem 123 in dharmadhikari and joag - dev ( 123 ) ) , it is enough to consider a non - degenerate cumulative density function f of x that has a density f which is logarithmically concave and differentiable in the interior of its support and so does not vanish there
fff123tg f 123ff123tg
but dlogf fxg=dx is non - increasing as f is logarithmically concave .
together with the fact that f123t is non - decreasing , it follows that fff123g has a non - increasing derivative and hence is concave on 123 , 123
y x123 fx f y dx dy
ff123v f123ug123 du dv
by symmetry and the fundamental theorem of calculus .
the change of variable z v u gives
proceeding likewise with varii
x we obtain
fff 123tg dt
where we set si : j123i fij , i 123 ,
using the concavity of fff123g and holder ' s inequality it can be shown that the above expression is
not smaller than
fii du dz
proving inequality ( 123 ) .
by equation ( 123 ) ,
proof of theorem 123 if x is uniformly distributed on u123 , k 123 , p123 , then msex123 fk123 p 123g=123 , and taking j j 123=123 , =123 , .
. , =123 , 123 123 j 123 k , shows that msexk 123 eminj kx jk123 f123 p 123g=123
so fmsexk=msex123g 123 123=k123 ,
even if we were to consider only x 123 s p with non - degenerate support .
123 123 i 123 p , must be in s 123 by theorem 123 in dharmadhikari and joag - dev ( 123 )
however , suppose that u 123 s p satises mseuk=mseu123 123=k123
each of the marginals ui of u ,
for all i by theorem 123 ,
123 123 k123 mseui
k 123 mseuk
for all k > 123
123 123 k123 pp
k 123 mseuk ,
and hence mseuk=mseu123 123=k123 can only hold if we have equality in expressions ( 123 ) and ( 123 ) .
to avoid technicalities we shall only give the main arguments for the remainder of the proof .
proceeding similarly as in the proof of theorem 123 we conclude from equality in expression ( 123 ) that the ui must have a uniform distribution , with the optimal centres i j , 123 123 j 123 k , equally spaced .
let li be the length of the support of ui .
we then check that expression ( 123 ) can hold with equality only if with probability 123 the centre i j closest to ui has the same index j for all marginals i .
but the set of u 123 rp i123 li=k ! 123 as k ! 123
hence , by for which the latter statement holds has lebesgue measure k p prekopa ' s theorem ( theorem 123 in dharmadhikari and joag - dev ( 123 ) ) , the support of u must be degenerate and contained in a linear subspace of rp .
repeating this argument at most p 123 times proves the theorem .
