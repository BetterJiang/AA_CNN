inexpensive rgb - d cameras that give an rgb image together with depth data have become widely available .
in this paper , we use this data to build 123d point clouds of full indoor scenes such as an ofce and address the task of semantic la - beling of these 123d point clouds .
we propose a graphical model that captures var - ious features and contextual relations , including the local visual appearance and shape cues , object co - occurence relationships and geometric relationships .
with a large number of object classes and relations , the models parsimony becomes im - portant and we address that by using multiple types of edge potentials .
the model admits efcient approximate inference , and we train it using a maximum - margin learning approach .
in our experiments over a total of 123 123d scenes of homes and ofces ( composed from about 123 views , having 123 segments labeled with 123 object classes ) , we get a performance of 123% in labeling 123 object classes for ofces , and 123% in labeling 123 object classes for home scenes .
finally , we applied these algorithms successfully on a mobile robot for the task of nding objects in large cluttered rooms . 123
inexpensive rgb - d sensors that augment an rgb image with depth data have recently become widely available .
at the same time , years of research on slam ( simultaneous localization and mapping ) now make it possible to reliably merge multiple rgb - d images into a single point cloud , easily providing an approximate 123d model of a complete indoor scene ( e . g . , a room ) .
in this paper , we explore how this move from part - of - scene 123d images to full - scene 123d point clouds can improve the richness of models for object labeling .
in the past , a signicant amount of work has been done in semantic labeling of 123d images .
however , a lot of valuable information about the shape and geometric layout of objects is lost when a 123d image is formed from the corresponding 123d world .
a classier that has access to a full 123d model , can access important geometric properties in addition to the local shape and appearance of an object .
for example , many objects occur in characteristic relative geometric congurations ( e . g . , a monitor is almost always on a table ) , and many objects consist of visually distinct parts that occur in a certain relative conguration .
more generally , a 123d model makes it easy to reason about a variety of properties , which are based on 123d distances , volume and local convexity .
some recent works attempt to rst infer the geometric layout from 123d images for improving the object detection ( 123 , 123 , 123 ) .
however , such a geometric layout is not accurate enough to give signicant improvement .
other recent work ( 123 ) considers labeling a scene using a single 123d view ( i . e . , a 123d representation ) .
in our work , we rst use slam in order to compose multiple views from a microsoft kinect rgb - d sensor together into one 123d point cloud , providing each rgb pixel with an absolute 123d location in the scene .
we then ( over - ) segment the scene and predict semantic labels for each segment ( see fig .
we predict not only coarse classes like in ( 123 , 123 ) ( i . e . ,
123this work was rst presented at ( 123 ) .
indicates equal contribution .
figure 123 : ofce scene ( top ) and home ( bottom ) scene with the corresponding label coloring above the images .
the left - most is the original point cloud , the middle is the ground truth labeling and the right most is the point cloud with predicted labels .
wall , ground , ceiling , building ) , but also label individual objects ( e . g . , printer , keyboard , mouse ) .
furthermore , we model rich relational information beyond an associative coupling of labels ( 123 ) .
in this paper , we propose and evaluate the rst model and learning algorithm for scene understand - ing that exploits rich relational information derived from the full - scene 123d point cloud for object in particular , we propose a graphical model that naturally captures the geometric re - lationships of a 123d scene .
each 123d segment is associated with a node , and pairwise potentials model the relationships between segments ( e . g . , co - planarity , convexity , visual similarity , object co - occurrences and proximity ) .
the model admits efcient approximate inference ( 123 ) , and we show that it can be trained using a maximum - margin approach ( 123 , 123 , 123 ) that globally minimizes an upper bound on the training loss .
we model both associative and non - associative coupling of labels .
with a large number of object classes , the models parsimony becomes important .
some features are better indicators of label similarity , while other features are better indicators of non - associative relations such as geometric arrangement ( e . g . , on - top - of , in - front - of ) .
we therefore in - troduce parsimony in the model by using appropriate clique potentials rather than using general clique potentials .
our model is highly exible and our software is available as a ros package at : to empirically evaluate our model and algorithms , we perform several experiments over a total of 123 scenes of two types : ofces and homes .
these scenes were built from about 123 views from the kinect sensor , and they are also available for public use .
we consider labeling each segment ( from a total of about 123 segments per scene ) into 123 classes ( 123 for ofces and 123 for homes , with 123 classes in common ) .
our experiments show that our method , which captures several local cues and contextual properties , achieves an overall performance of 123% on ofce scenes and 123% on home scenes .
we also consider the problem of labeling 123d segments with multiple attributes meaningful to robotics context ( such as small objects that can be manipulated , furniture , etc . ) .
finally , we successfully applied these algorithms on mobile robots for the task of nding objects in cluttered ofce scenes .
123 related work there is a huge body of work in the area of scene understanding and object recognition from 123d im - ages .
previous works focus on several different aspects : designing good local features such as hog ( histogram - of - gradients ) ( 123 ) and bag of words ( 123 ) , and designing good global ( context ) features such as gist features ( 123 ) .
however , these approaches do not consider the relative arrangement of the parts of the object or of multiple objects with respect to each other .
a number of works propose models that explicitly capture the relations between different parts of the object e . g . , pedro et al . s part - based models ( 123 ) , and between different objects in 123d images ( 123 , 123 ) .
however , a lot of valu - able information about the shape and geometric layout of objects is lost when a 123d image is formed from the corresponding 123d world .
in some recent works , 123d layout or depths have been used for improving object detection ( e . g . , ( 123 , 123 , 123 , 123 , 123 , 123 , 123 , 123 ) ) .
here a rough 123d scene geometry ( e . g . , main surfaces in the scene ) is inferred from a single 123d image or a stereo video stream , respec - tively .
however , the estimated geometry is not accurate enough to give signicant improvements .
with 123d data , we can more precisely determine the shape , size and geometric orientation of the objects , and several other properties and therefore capture much stronger context .
the recent availability of synchronized videos of both color and depth obtained from rgb - d ( kinect - style ) depth cameras , shifted the focus to making use of both visual as well as shape features for object detection ( 123 , 123 , 123 , 123 , 123 ) and 123d segmentation ( e . g . , ( 123 ) ) .
these methods demonstrate
that augmenting visual features with 123d information can enhance object detection in cluttered , real - world environments .
however , these works do not make use of the contextual relationships between various objects which have been shown to be useful for tasks such as object detection and scene understanding in 123d images .
our goal is to perform semantic labeling of indoor scenes by modeling and learning several contextual relationships .
there is also some recent work in labeling outdoor scenes obtained from lidar data into a few ge - ometric classes ( e . g . , ground , building , trees , vegetation , etc . ) .
( 123 , 123 ) capture context by designing node features and ( 123 ) do so by stacking layers of classiers; however these methods do not model the correlation between the labels .
some of these works model some contextual relationships in the learning model itself .
for example , ( 123 , 123 ) use associative markov networks in order to favor similar labels for nodes in the cliques .
however , many relative features between objects are not associative in nature .
for example , the relationship on top of does not hold in between two ground segments , i . e . , a ground segment cannot be on top of another ground segment .
therefore , using an associa - tive markov network is very restrictive for our problem .
all of these works ( 123 , 123 , 123 , 123 , 123 ) were designed for outdoor scenes with lidar data ( without rgb values ) and therefore would not apply directly to rgb - d data in indoor environments .
furthermore , these methods only consider very few geometric classes ( between three to ve classes ) in outdoor environments , whereas we consider a large number of object classes for labeling the indoor rgb - d data .
the most related work to ours is ( 123 ) , where they label the planar patches in a point - cloud of an indoor scene with four geometric labels ( walls , oors , ceilings , clutter ) .
they use a crf to model geometrical relationships such as orthogonal , parallel , adjacent , and coplanar .
the learning method for estimating the parameters was based on maximizing the pseudo - likelihood resulting in a sub - optimal learning algorithm .
in comparison , our basic representation is a 123d segment ( as compared to planar patches ) and we consider a much larger number of classes ( beyond just the geometric classes ) .
we also capture a much richer set of relationships between pairs of objects , and use a principled max - margin learning method to learn the parameters of our model .
we now outline our approach , including the model , its inference methods , and the learning algo - rithm .
our input is multiple kinect rgb - d images of a scene ( i . e . , a room ) stitched into a single 123d point cloud using rgbdslam . 123 each such point cloud is then over - segmented based on smooth - ness ( i . e . , difference in the local surface normals ) and continuity of surfaces ( i . e . , distance between the points ) .
these segments are the atomic units in our model .
our goal is to label each of them .
before getting into the technical details of the model , the following outlines the properties we aim to capture in our model : visual appearance .
the reasonable success of object detection in 123d images shows that visual appearance is a good indicator for labeling scenes .
we therefore model the local color , texture , gradients of intensities , etc .
for predicting the labels .
in addition , we also model the property that if nearby segments are similar in visual appearance , they are more likely to belong to the same object .
local shape and geometry .
objects have characteristic shapesfor example , a table is horizontal , a monitor is vertical , a keyboard is uneven , and a sofa is usually smoothly curved .
furthermore , parts of an object often form a convex shape .
we compute 123d shape features to capture this .
geometrical context .
many sets of objects occur in characteristic relative geometric congurations .
for example , a monitor is always on - top - of a table , chairs are usually found near tables , a keyboard is in - front - of a monitor .
this means that our model needs to capture non - associative relationships ( i . e . , that neighboring segments differ in their labels in specic patterns ) .
note the examples given above are just illustrative .
for any particular practical application , there will likely be other properties that could also be included .
as demonstrated in the following section , our model is exible enough to include a wide range of features .
123 model formulation we model the three - dimensional structure of a scene using a model isomorphic to a markov ran - dom field with log - linear node and pairwise edge potentials .
given a segmented point cloud x = ( x123 , . . . , xn ) consisting of segments xi , we aim to predict a labeling y = ( y123 , . . . , yn ) for the segments .
each segment label yi is itself a vector of k binary class labels yi = ( y123 i , . . . , yk with each yk i ( 123 , 123 ) indicating whether a segment i is a member of class k .
note that multiple yk can be 123 for each segment ( e . g . , a segment can be both a chair and a movable object ) .
we use
figure 123 : illustration of a few features .
( left ) features n123 and e123
segment i is infront of segment j if ( middle ) two connected segment i and j are form a convex shape if ( ri rj ) .
ni 123 and rhi < rhj .
( rj ri ) .
( right ) illustrating feature e123
such multi - labelings in our attribute experiments where each segment can have multiple attributes , but not in segment labeling experiments where each segment can have only one label ) .
for a segmented point cloud x , the prediction y is computed as the argmax of a discriminant function fw ( x , y ) that is parameterized by a vector of weights w .
y = argmax
the discriminant function captures the dependencies between segment labels as dened by an undi - rected graph ( v , e ) of vertices v = ( 123 , . . . , n ) and edges e v v .
we describe in section 123 how this graph is derived from the spatial proximity of the segments .
given ( v , e ) , we dene the fol - lowing discriminant function based on individual segment features n ( i ) and edge features t ( i , j ) as further described below .
fw ( y , x ) = ( cid : 123 ) iv
n n ( i ) ( cid : 123 ) + ( cid : 123 ) ( i , j ) e ( cid : 123 ) ttt ( cid : 123 ) ( l , k ) tt
the node feature map n ( i ) describes segment i through a vector of features , and there is one weight vector for each of the k classes .
examples of such features are the ones capturing local visual appearance , shape and geometry .
the edge feature maps t ( i , j ) describe the relationship between segments i and j .
examples of edge features are the ones capturing similarity in visual appearance and geometric context . 123 there may be multiple types t of edge feature maps t ( i , j ) , and each type has a graph over the k classes with edges tt .
if tt contains an edge between classes is used to model the dependencies between l and k , then this feature map and a weight vector wlk classes l and k .
if the edge is not present in tt , then t ( i , j ) is not used .
we say that a type t of edge features is modeled by an associative edge potential if tt = ( ( k , k ) |k = 123 . k ) .
and it is modeled by an non - associative edge potential if tt = ( ( l , k ) |l , k = 123 . k ) .
finally , it is modeled by an object - associative edge potential if tt = ( ( l , k ) |object , in our experiments we distinguished between two types of edge feature mapsobject - associative features oa ( i , j ) used between classes that are parts of the same object ( e . g . , chair base , chair back and chair back rest ) , and non - associative features na ( i , j ) that are used between any pair of classes .
examples of features in the object - associative feature map oa ( i , j ) include similarity in appearance , co - planarity , and convexityi . e . , features that indicate whether two adjacent segments belong to the same class or object .
a key reason for distinguishing between object - associative and non - associate features is parsimony of the model .
in this parsimo - nious model ( referred to as svm mrf parsimon ) , we model object associative features using object - associative edge potentials and non - associative features as non - associative edge potentials .
as not all edge features are non - associative , we avoid learning weight vectors for relationships which do not exist .
note that |tna| >> |toa| since , in practice , the number of parts of an objects is much less than k .
due to this , the model we learn with both type of edge features will have much lesser number of parameters compared to a model learnt with all edge features as non - associative features .
table 123 summarizes the features used in our experiments .
i123 , i123 and i123 are the 123 eigen - values of the scatter matrix computed from the points of segment i in decreasing order .
ci is the centroid of segment i .
ri is the ray vector to the centroid of segment i from the position camera in which it was captured .
rhi is the projection of ri on horizontal plane .
ni is the unit normal of segment i which points towards the camera ( ri . ni < 123 ) .
the node features n ( i ) consist of visual appearance features based on histogram of hsv values and the histogram of gradients ( hog ) , as well as local shape and geometry features that capture properties such as how planar a segment is , its absolute
123even though it is not represented in the notation , note that both the node feature map n ( i ) and the edge
feature maps t ( i , j ) can compute their features based on the full x , not just xi and xj .
nodefeaturesforsegmenti . descriptioncountvisualappearance123n123histogramofhsvcolorvalues123n123averagehsvcolorvalues123n123averageofhogfeaturesoftheblocksinim - agespannedbythepointsofasegment123localshapeandgeometry123n123linearness ( i123 - i123 ) , planarness ( i123 - i123 ) 123n123scatter : i123n123verticalcomponentofthenormal : niz123n123verticalpositionofcentroid : ciz123n123vert . andhor . extentofboundingbox123n123dist . fromthesceneboundary ( fig . 123 ) 123edgefeaturesfor ( segmenti , segmentj ) . descriptioncountvisualappearance ( associative ) 123e123differenceofavghsvcolorvalues123localshapeandgeometry ( associative ) 123e123coplanarityandconvexity ( fig . 123 ) 123geometriccontext ( non - associative ) 123e123horizontaldistanceb / wcentroids . 123e123verticaldisplacementb / wcentroids : ( cizcjz ) 123e123anglebetweennormals ( dotproduct ) : ninj123e123diff . inanglewithvert . : cos123 ( niz ) - cos123 ( njz ) 123e123dist . betweenclosestpoints : minusi , vsjd ( u , v ) ( fig . 123 ) 123e123rel . positionfromcamera ( infrontof / behind ) . ( fig . 123 ) 123table123 : nodeandedgefeatures . locationaboveground , anditsshape . somefeaturescapturespatiallocationofanobjectinthescene ( e . g . , n123 ) . weconnecttwosegments ( nodes ) iandjbyanedgeifthereexistsapointinsegmentiandapointinsegmentjwhicharelessthancontextrangedistanceapart . thiscapturestheclosestdistancebetweentwosegments ( ascomparedtocentroiddistancebetweenthesegments ) westudytheeffectofcontextrangemoreinsection123theedgefeaturest ( i , j ) ( table123 - right ) consistofassociativefeatures ( e123 - e123 ) basedonvisualappearanceandlocalshape , aswellasnon - associativefeatures ( e123 - e123 ) thatcapturethetendenciesoftwoobjectstooccurincertaincongurations . notethatourfeaturesareinsensitivetohorizontaltranslationandrotationofthecamera . however , ourfeaturesplacealotofemphasisontheverticaldirectionbecausegravityinuencestheshapeandrelativepositionsofobjectstoalargeextent . ijcamrhidbidbjrhj123 . 123computingpredictionssolvingtheargmaxineq . ( 123 ) forthediscriminantfunctionineq . ( 123 ) isnphard . however , itsequivalentformulationasthefollowingmixed - integerprogramhasalinearrelaxationwithseveraldesirableproperties . y=argmaxymaxzivkk=123ykiwknn ( i ) + ( i , j ) ettt ( l , k ) ttzlkijwlktt ( i , j ) ( 123 ) i , j , l , k : zlkijyli , zlkijykj , yli+ykjzlkij+123 , zlkij , yli ( 123 , 123 ) ( 123 ) notethattheproductsyliykjhavebeenreplacedbyauxiliaryvariableszlkij . relaxingthevariableszlkijandylitotheinterval ( 123 , 123 ) leadstoalinearprogramthatcanbeshowntoalwayshavehalf - integralsolutions ( i . e . ylionlytakevalues ( 123 , 123 , 123 ) atthesolution ) ( 123 ) . furthermore , thisrelaxationcanalsobesolvedasaquadraticpseudo - booleanoptimizationproblemusingagraph - cutmethod ( 123 ) , whichisordersofmagnitudefasterthanusingageneralpurposelpsolver ( i . e . , 123secforlabelingatypicalsceneinourexperiments ) . therefore , werefertothesolutionofthisrelaxationasycut . therelaxationsolutionycuthasaninterestingpropertycalledpersistence ( 123 , 123 ) . persistencesaysthatanysegmentforwhichthevalueofyliisintegralinycut ( i . e . doesnottakevalue123 ) islabeledjustlikeitwouldbeintheoptimalmixed - integersolution . 123nodefeaturesforsegmenti . descriptioncountvisualappearance123n123histogramofhsvcolorvalues123n123averagehsvcolorvalues123n123averageofhogfeaturesoftheblocksinim - agespannedbythepointsofasegment123localshapeandgeometry123n123linearness ( i123 - i123 ) , planarness ( i123 - i123 ) 123n123scatter : i123n123verticalcomponentofthenormal : niz123n123verticalpositionofcentroid : ciz123n123vert . andhor . extentofboundingbox123n123dist . fromthesceneboundary ( fig . 123 ) 123edgefeaturesfor ( segmenti , segmentj ) . descriptioncountvisualappearance ( associative ) 123e123differenceofavghsvcolorvalues123localshapeandgeometry ( associative ) 123e123coplanarityandconvexity ( fig . 123 ) 123geometriccontext ( non - associative ) 123e123horizontaldistanceb / wcentroids . 123e123verticaldisplacementb / wcentroids : ( cizcjz ) 123e123anglebetweennormals ( dotproduct ) : ninj123e123diff . inanglewithvert . : cos123 ( niz ) - cos123 ( njz ) 123e123dist . betweenclosestpoints : minusi , vsjd ( u , v ) ( fig . 123 ) 123e123rel . positionfromcamera ( infrontof / behind ) . ( fig . 123 ) 123table123 : nodeandedgefeatures . locationaboveground , anditsshape . somefeaturescapturespatiallocationofanobjectinthescene ( e . g . , n123 ) . weconnecttwosegments ( nodes ) iandjbyanedgeifthereexistsapointinsegmentiandapointinsegmentjwhicharelessthancontextrangedistanceapart . thiscapturestheclosestdistancebetweentwosegments ( ascomparedtocentroiddistancebetweenthesegments ) westudytheeffectofcontextrangemoreinsection123theedgefeaturest ( i , j ) ( table123 - right ) consistofassociativefeatures ( e123 - e123 ) basedonvisualappearanceandlocalshape , aswellasnon - associativefeatures ( e123 - e123 ) thatcapturethetendenciesoftwoobjectstooccurincertaincongurations . notethatourfeaturesareinsensitivetohorizontaltranslationandrotationofthecamera . however , ourfeaturesplacealotofemphasisontheverticaldirectionbecausegravityinuencestheshapeandrelativepositionsofobjectstoalargeextent . camrirjninj123 . 123computingpredictionssolvingtheargmaxineq . ( 123 ) forthediscriminantfunctionineq . ( 123 ) isnphard . however , itsequivalentformulationasthefollowingmixed - integerprogramhasalinearrelaxationwithseveraldesirableproperties . y=argmaxymaxzivkk=123ykiwknn ( i ) + ( i , j ) ettt ( l , k ) ttzlkijwlktt ( i , j ) ( 123 ) i , j , l , k : zlkijyli , zlkijykj , yli+ykjzlkij+123 , zlkij , yli ( 123 , 123 ) ( 123 ) notethattheproductsyliykjhavebeenreplacedbyauxiliaryvariableszlkij . relaxingthevariableszlkijandylitotheinterval ( 123 , 123 ) leadstoalinearprogramthatcanbeshowntoalwayshavehalf - integralsolutions ( i . e . ylionlytakevalues ( 123 , 123 , 123 ) atthesolution ) ( 123 ) . furthermore , thisrelaxationcanalsobesolvedasaquadraticpseudo - booleanoptimizationproblemusingagraph - cutmethod ( 123 ) , whichisordersofmagnitudefasterthanusingageneralpurposelpsolver ( i . e . , 123secforlabelingatypicalsceneinourexperiments ) . therefore , werefertothesolutionofthisrelaxationasycut . therelaxationsolutionycuthasaninterestingpropertycalledpersistence ( 123 , 123 ) . persistencesaysthatanysegmentforwhichthevalueofyliisintegralinycut ( i . e . doesnottakevalue123 ) islabeledjustlikeitwouldbeintheoptimalmixed - integersolution . sinceeverysegmentinourexperimentsisinexactlyoneclass , wealsoconsiderthelinearrelaxationfromabovewiththeadditionalconstrainti : kj=123yji=123thisproblemcannolongerbesolvedviagraphcutsandisnothalf - integral . werefertoitssolutionasylp . computingylpfora123nodefeaturesforsegmenti . descriptioncountvisualappearance123n123histogramofhsvcolorvalues123n123averagehsvcolorvalues123n123averageofhogfeaturesoftheblocksinim - agespannedbythepointsofasegment123localshapeandgeometry123n123linearness ( i123 - i123 ) , planarness ( i123 - i123 ) 123n123scatter : i123n123verticalcomponentofthenormal : niz123n123verticalpositionofcentroid : ciz123n123vert . andhor . extentofboundingbox123n123dist . fromthesceneboundary ( fig . 123 ) 123edgefeaturesfor ( segmenti , segmentj ) . descriptioncountvisualappearance ( associative ) 123e123differenceofavghsvcolorvalues123localshapeandgeometry ( associative ) 123e123coplanarityandconvexity ( fig . 123 ) 123geometriccontext ( non - associative ) 123e123horizontaldistanceb / wcentroids . 123e123verticaldisplacementb / wcentroids : ( cizcjz ) 123e123anglebetweennormals ( dotproduct ) : ninj123e123diff . inanglewithvert . : cos123 ( niz ) - cos123 ( njz ) 123e123dist . betweenclosestpoints : minusi , vsjd ( u , v ) ( fig . 123 ) 123e123rel . positionfromcamera ( infrontof / behind ) . ( fig . 123 ) 123table123 : nodeandedgefeatures . locationaboveground , anditsshape . somefeaturescapturespatiallocationofanobjectinthescene ( e . g . , n123 ) . weconnecttwosegments ( nodes ) iandjbyanedgeifthereexistsapointinsegmentiandapointinsegmentjwhicharelessthancontextrangedistanceapart . thiscapturestheclosestdistancebetweentwosegments ( ascomparedtocentroiddistancebetweenthesegments ) westudytheeffectofcontextrangemoreinsection123theedgefeaturest ( i , j ) ( table123 - right ) consistofassociativefeatures ( e123 - e123 ) basedonvisualappearanceandlocalshape , aswellasnon - associativefeatures ( e123 - e123 ) thatcapturethetendenciesoftwoobjectstooccurincertaincongurations . notethatourfeaturesareinsensitivetohorizontaltranslationandrotationofthecamera . however , ourfeaturesplacealotofemphasisontheverticaldirectionbecausegravityinuencestheshapeandrelativepositionsofobjectstoalargeextent . idminijj123 . 123computingpredictionssolvingtheargmaxineq . ( 123 ) forthediscriminantfunctionineq . ( 123 ) isnphard . however , itsequivalentformulationasthefollowingmixed - integerprogramhasalinearrelaxationwithseveraldesirableproperties . y=argmaxymaxzivkk=123ykiwknn ( i ) + ( i , j ) ettt ( l , k ) ttzlkijwlktt ( i , j ) ( 123 ) i , j , l , k : zlkijyli , zlkijykj , yli+ykjzlkij+123 , zlkij , yli ( 123 , 123 ) ( 123 ) notethattheproductsyliykjhavebeenreplacedbyauxiliaryvariableszlkij . relaxingthevariableszlkijandylitotheinterval ( 123 , 123 ) leadstoalinearprogramthatcanbeshowntoalwayshavehalf - integralsolutions ( i . e . ylionlytakevalues ( 123 , 123 , 123 ) atthesolution ) ( 123 ) . furthermore , thisrelaxationcanalsobesolvedasaquadraticpseudo - booleanoptimizationproblemusingagraph - cutmethod ( 123 ) , whichisordersofmagnitudefasterthanusingageneralpurposelpsolver ( i . e . , 123secforlabelingatypicalsceneinourexperiments ) . therefore , werefertothesolutionofthisrelaxationasycut . therelaxationsolutionycuthasaninterestingpropertycalledpersistence ( 123 , 123 ) . persistencesaysthatanysegmentforwhichthevalueofyliisintegralinycut ( i . e . doesnottakevalue123 ) islabeledjustlikeitwouldbeintheoptimalmixed - integersolution . sinceeverysegmentinourexperimentsisinexactlyoneclass , wealsoconsiderthelinearrelaxationfromabovewiththeadditionalconstrainti : kj=123yji=123thisproblemcannolongerbesolvedviagraphcutsandisnothalf - integral . werefertoitssolutionasylp . computingylpforascenetakes123minutesonaverage123finally , wecanalsocomputetheexactmixedintegersolutionincludingtheadditionalconstrainti : kj=123yji=123usingageneral - purposemipsolver123wesetatimelimitof123minutesforthemipsolver . thistakes123minutesonaverageforascene . allruntimesareforsinglecpuimplementationsusing123classes . 123http : / / www . tnley . net / software / pyglpk / readme . html123 node features for segment i .
histogram of hsv color values n123
average hsv color values n123
average of hog features of the blocks in im - age spanned by the points of a segment local shape and geometry n123
linearness ( i123 - i123 ) , planarness ( i123 - i123 ) n123
scatter : i123 n123
vertical component of the normal : niz n123
vertical position of centroid : ciz n123
and hor .
extent of bounding box n123
from the scene boundary ( fig
edge features for ( segment i , segment j ) .
visual appearance ( associative ) e123
difference of avg hsv color values local shape and geometry ( associative ) e123
coplanarity and convexity ( fig .
123 ) geometric context ( non - associative ) e123
horizontal distance b / w centroids .
vertical displacement b / w centroids : ( ciz cjz ) e123
angle between normals ( dot product ) : ni nj e123
in angle with vert . : cos123 ( niz ) - cos123 ( njz ) minusi , vsj d ( u , v ) ( fig .
position from camera ( in front of / behind )
table 123 : node and edge features .
location above ground , and its shape .
some features capture spatial location of an object in the scene we connect two segments ( nodes ) i and j by an edge if there exists a point in segment i and a point in segment j which are less than context range distance apart .
this captures the closest distance between two segments ( as compared to centroid distance between the segments ) we study the effect of context range more in section 123
the edge features t ( i , j ) ( table 123 - right ) consist of associative features ( e123 - e123 ) based on visual appearance and local shape , as well as non - associative features ( e123 - e123 ) that capture the tendencies of two objects to occur in certain congurations .
note that our features are insensitive to horizontal translation and rotation of the camera .
however , our features place a lot of emphasis on the vertical direction because gravity inuences the shape and relative positions of objects to a large extent .
123 . 123 computing predictions solving the argmax in eq .
( 123 ) for the discriminant function in eq .
( 123 ) is np hard .
however , its equivalent formulation as the following mixed - integer program has a linear relaxation with several
ij , yl
y = argmax
i , j , l , k : zlk j have been replaced by auxiliary variables zlk
n n ( i ) ( cid : 123 ) + ( cid : 123 ) ( i , j ) e ( cid : 123 ) ttt ( cid : 123 ) ( l , k ) tt
i + yk
ij + 123 ,
i ( 123 , 123 )
relaxing the variables zlk note that the products yl i to the interval ( 123 , 123 ) leads to a linear program that can be shown to always have half - integral solutions ( i . e .
yl i only take values ( 123 , 123 , 123 ) at the solution ) ( 123 ) .
furthermore , this relaxation can also be solved as a quadratic pseudo - boolean optimization problem using a graph - cut method ( 123 ) , which is orders of magnitude faster than using a general purpose lp solver ( i . e . , 123 sec for labeling a typical scene in our experiments ) .
therefore , we refer to the solution of this relaxation as ycut .
the relaxation solution ycut has an interesting property called persistence ( 123 , 123 ) .
persistence says that any segment for which the value of yl i is integral in ycut ( i . e .
does not take value 123 ) is labeled just like it would be in the optimal mixed - integer solution .
since every segment in our experiments is in exactly one class , we also consider the linear relaxation i = 123
this problem can no longer be solved via graph cuts and is not half - integral .
we refer to its solution as ylp .
computing ylp for a scene takes 123 minutes on average123
finally , we can also compute the exact mixed integer solution i = 123 using a general - purpose mip solver123
we set a time limit of 123 minutes for the mip solver .
this takes 123 minutes on average for a scene .
all runtimes are for single cpu implementations using 123 classes .
when using this algorithm in practice on new scenes ( e . g . , during our robotic experiments ) , objects other than the 123 objects we modeled might be present ( e . g . , coffee - mugs ) .
so we relax the constraint i 123
this increases precision greatly at the cost of some drop in
from above with the additional constraint i : ( cid : 123 ) k including the additional constraint i : ( cid : 123 ) k
recall .
also , this relaxed mip takes lesser time to solve .
123 . 123 learning algorithm we take a large - margin approach to learning the parameter vector w of eq .
( 123 ) from labeled training examples ( x123 , y123 ) , . . . , ( xn , yn ) ( 123 , 123 , 123 ) .
compared to conditional random field training ( 123 )
i = 123 to i : ( cid : 123 ) k
using maximum likelihood , this has the advantage that the partition function normalizing eq .
( 123 ) does not need to be computed , and that the training problem can be formulated as a convex program for which efcient algorithms exist .
our method optimizes a regularized upper bound on the training error
where yj is the optimal solution of eq .
( 123 ) and ( y , y ) = ( cid : 123 ) n
to simplify notation , note that eq .
( 123 ) can be equivalently written as wt ( x , y ) by appropriately stacking the ij is consistent with eq .
( 123 ) given y .
training can then be formulated as the following convex quadratic program ( 123 ) :
n and wlk
into w and the yk
i n ( k ) and zlk
ij t ( l , k ) into ( x , y ) , where each zlk
wt w + c
y123 , . . . , yn ( 123 , 123 , 123 ) nk :
( ( xi , yi ) ( xi , yi ) ) ( yi , yi )
while the number of constraints in this quadratic program is exponential in n , n , and k , it can nevertheless be solved efciently using the cutting - plane algorithm for training structural svms ( 123 ) .
the algorithm maintains a working set of constraints , and it can be shown to provide an - accurate solution after adding at most o ( r123c / ) constraints ( ignoring log terms ) .
the algorithm merely need access to an efcient method for computing
yi = argmax
y ( 123 , 123 , 123 ) nk ( cid : 123 ) wt ( xi , y ) + ( yi , y ) ( cid : 123 ) .
due to the structure of ( . , . ) , this problem is identical to the relaxed prediction problem in eqs .
( 123 ) - ( 123 ) and can be solved efciently using graph cuts .
since our training problem is an overgenerating formulation as dened in ( 123 ) , the value of at the solution is an upper bound on the training error in eq .
furthermore , ( 123 ) observed empirically that the relaxed prediction ycut after training w via eq .
( 123 ) is typically largely integral , meaning that most labels yk i of the relaxed solution are the same as the optimal mixed - integer solution due to persistence .
we made the same observation in our experiments as well .
we consider labeling object segments in full 123d scene ( as compared to 123d data from a single view ) .
for this purpose , we collected data of 123 ofce and 123 home scenes ( composed from about 123 views ) .
each scene was reconstructed from about 123 - 123 rgb - d views from a kinect sensor and contains about one million colored points .
we rst over - segment the 123d scene ( as described earlier ) to obtain the atomic units of our rep - resentation .
for training , we manually labeled the segments , and we selected the labels which were present in a minimum of 123 scenes in the dataset .
specically , the ofce labels are : ( wall , oor , tabletop , tabledrawer , tableleg , chairbackrest , chairbase , chairback , monitor , printerfront , printerside keyboard , cputop , cpufront , cpuside , book , paper ) , and the home labels are : ( wall , oor , tabletop , tabledrawer , tableleg , chairbackrest , chairbase , sofabase , sofaarm , sofaback - rest , bed , bedside , quilt , pillow , shelfrack , laptop , book ) .
this gave us a total of 123 labeled segments in the ofce scenes and 123 segments in the home scenes .
often one object may be di - vided into multiple segments because of over - segmentation .
we have made this data available at : table 123 shows the results , performed using 123 - fold cross - validation and averaging performance across the folds for the models trained separately on home and ofce datasets .
we use both the macro and micro averaging to aggregate precision and recall over various classes .
since our algorithm can only predict one label for each segment , micro precision and recall are same as the percentage of correctly classied segments .
macro precision and recall are respectively the averages of precision and recall for all classes .
the optimal c value is determined separately for each of the algorithms figure 123 shows the original point cloud , ground - truth and predicted labels for one ofce ( top ) and one home scene ( bottom ) .
we see that on majority of the classes we are able to predict the correct
table 123 : learning experiment statistics .
the table shows average micro precision / recall , and average macro precision and recall for home and ofce scenes .
p / r precision recall
image+shape & context image+shape & context image+shape & context image+shape & context
svm node only svm node only svm node only svm mrf assoc svm mrf nonassoc svm mrf parsimon
p / r precision recall
it makes mistakes in some cases and these usually tend to be reasonable , such as a pillow getting confused with the bed , and table - top getting confused with the shelf - rack .
one of our goals is to study the effect of various factors , and therefore we compared different versions of the algorithms with various settings .
we discuss them in the following .
do image and point - cloud features capture complimentary information ? the rgb - d data contains both image and depth information , and enables us to compute a wide variety of features .
in this experiment , we compare the two kinds of features : image ( rgb ) and shape ( point cloud ) features .
to show the effect of the features independent of the effect of context , we only use the node potentials from our model , referred to as svm node only in table 123
the svm node only model is equivalent to the multi - class svm formulation ( 123 ) .
table 123 shows that shape features are more effective compared to the image , and the combination works better on both precision and recall .
this indicates that the two types of features offer complementary information and their combination is better for our classication task .
how important is context ? using our svm mrf parsimon model as described in section 123 , we show signicant improvements in the performance over using svm node only model on both in ofce scenes , the micro precision increased by 123% over the best svm node only model that does not use any context .
in home scenes the increase is much higher , 123% .
the type of contextual relations we capture depend on the type of edge potentials we model .
to study this , we compared our method with models using only associative or only non - associative edge potentials referred to as svm mrf assoc and svm mrf nonassoc respectively .
we observed that modeling all edge features using associative potentials is poor compared to our full model .
in fact , using only associative potentials showed a drop in performance compared to svm node only model on the ofce dataset .
this indicates it is important to capture the relations between regions having different labels .
our svm mrf nonassoc model does so , by modeling all edge features using non - associative potentials , which can favor or disfavor labels of different classes for nearby segments .
it gives higher precision and recall compared to svm node only and svm mrf assoc .
this shows that modeling using non - associative potentials is a better choice for our labeling problem .
however , not all the edge features are non - associative in nature , modeling them using only non - associative potentials could be an overkill ( each non - associative feature adds k 123 more parameters to be learnt ) .
therefore using our svm mrf parsimon model to model these relations achieves higher performance in both datasets .
how large should the context range be ? context rela - tionships of different objects can be meaningful for different spatial distances .
this range may vary depending on the en - vironment as well .
for example , in an ofce , keyboard and monitor go together , but they may have little relation with a sofa that is slightly farther away .
in a house , sofa and table may go together even if they are farther away .
in order to study this , we compared our svm mrf parsimon with varying context range for determining the neighborhood ( see figure 123 for average micro precision vs range plot ) .
note that the context range is determined from the boundary of one segment to the boundary of the other , and hence it is somewhat independent of the size of the object .
we note that increasing the context range increases the performance to some level , and then it drops slightly .
we attribute this to the fact that increasing the context range can connect irrelevant objects
figure 123 : effect of context range on precision ( =recall here ) .
with an edge , and with limited training data , spurious relationships may be learned .
we observe that the optimal context range for ofce scenes is around 123 meters and 123 meters for home scenes .
how does a full 123d model compare to a 123d model ? in table 123 , we compare the performance of our full model with a model that was trained and tested on single views of the same scenes .
during the comparison , the training folds were consistent with other experiments , however the segmentation of the point clouds was different ( because each point cloud is from a single view ) .
this makes the micro precision values meaningless because the distribution of labels is not same for the two cases .
in particular , many large object in scenes ( e . g . , wall , ground ) get split up into multiple segments in single views .
we observed that the macro precision and recall are higher when multiple views are combined to form the scene .
we attribute the improvement in macro precision and recall to the fact that larger scenes have more context , and models are more complete because of multiple views .
what is the effect of the inference method ? the results for svm mrf algorithms table 123 were generated using the mip solver .
we observed that the mip solver is typically 123 - 123% more accurate than the lp solver .
the graph - cut algorithm however , gives a higher precision and lower recall on both datasets .
for example , on ofce data , the graphcut inference for our svm mrf parsimon gave a micro precision of 123 and micro recall of 123 .
here , the micro precision and recall are not same as some of the segments might not get any label .
since it is orders of magnitude faster , it is ideal for realtime robotic applications .
123 robotic experiments the ability to label segments is very useful for robotics applications , for example , in detecting objects ( so that a robot can nd / retrieve an object on request ) or for other robotic tasks .
we therefore performed two relevant in some robotic tasks , such as robotic grasping , it is not important to know the exact object category , but just knowing a few attributes of an object may be useful .
for example , if a robot has to clean a oor , it would help if it knows which objects it can move and which it cannot .
if it has to place an object , it should place them on horizontal surfaces , preferably where hu - mans do not sit .
with this motivation we have designed 123 attributes , each for the home and ofce scenes , giving a total of 123 unique attributes in total , comprised of : wall , oor , at - horizontal - surfaces , furniture , fabric , heavy , seating - areas , small - objects , table - top - objects , electronics .
note that each segment in the point cloud can have multiple attributes and therefore we can learn these attributes using our model which naturally allows multiple labels per segment .
we compute the precision and recall over the attributes by counting how many attributes were correctly inferred .
in home scenes we obtained a precision of 123% and 123% recall , and in the ofce scenes we obtain 123% precision and 123% recall .
object detection : we nally use our algorithm on two mobile robots , mounted with kinects , for completing the goal of nding objects such as a keyboard in cluttered ofce scenes .
the following video shows our robot successfully nding a keyboard in an ofce : http : / / pr . cs . cornell .
figure 123 : cornells polar robot using our classier for detecting a keyboard in a clut -
in conclusion , we have proposed and evaluated the rst model and learning algorithm for scene un - derstanding that exploits rich relational information from the full - scene 123d point cloud .
we applied this technique to object labeling problem , and studied affects of various factors on a large dataset .
our robotic application shows that such inexpensive rgb - d sensors can be extremely useful for scene understanding for robots .
this research was funded in part by nsf award iis - 123
