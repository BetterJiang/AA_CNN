the world wide web
we describe an information agent , called webwatcher , interactively helps users locate desired information by employing learned knowledge about which hyperlinks are likely to lead to the target information .
our primary focus to date has been on two issues : webwatcher to provide interactive to mosaic users while logging their suc - cessful and unsuccessful searches as train - ing data , and ( 123 ) incorporating machine learning methods to automatically acquire knowledge for selecting an appropriate hy - perlink given the current web page viewed by the user and the users goal .
we describe webwatcher , and the results of our pre - liminary learning experiments .
machine learning information services tlds ~ ti ~ being rnaintu ~ cd bf the ml groul ~ at the austrianresea ~ . h arti123cial int cll ~ ence ( opal ) , vienna , austria
it is far from complete and is being opdatcd on anincgular basis .
pleas e direct comment ~ / su ~ estions / . . . to gelll ~ d widmer ( gerh ~ dcc ~ , cd , ~ nilie , ~ : . ~
to ~ out our experlnncnt ~ l wcbwatcher
s catch as slstant , click lj_ _e ~ _
gejmral ml l , tfottrtatio , t sotuces
univcr ~ i ~ , qf cal ~ omla - lr , ~ e ( uci ) machine lcamin ~ paec , university of 123snob / urbana ( us uc ~ as / m l paec , m l m ahin p .
list archive moderate . d by m , pozzani ~ , m lnct - network of excellence ~ m acl ~ lcaratmz ( gmd s tj ~ cr ) .
m lnet m ailing lis t arckivc ( armtcrdam - - - not yet |nsta l l ed ~ .
pro ~ ar ~ c " l caratn ~ . tn huraam and m addncs " ( euranean science foundation ~ ,
tile inductive lo p . ic pro mam / l ~ p .
pan - l ~ urol ~ can sclent ~ ic network ,
variou ~ ml prograra m123 data sout ~ ces
gmd m addnc lczcnjn ~ .
rcgo siton ~ , uc irvi ~ rano sitor ) o f m l databases .
u c irvinc rano sitovl of m l pro ~ rams , m lc++ - a m acl ~ e lcam ~ t library in c123+ ( r , k123hav ~ stal ~ 123rti ui ~ v123
pr123benl - - - a $e$ 123f n etral network benchmark problems ( siz ~ - 123m b l i ~ , mlt - mac ) fine lcamln ~ toolbox ( es+ ~ dt prolcct ~ , ecoadata - econoredc time series data ( univ .
of m aryiand ~ , uiatied states census bt ~ cau , ins ) erie collc ~ . a prolo ~ t i123 datubas c ,
- - - des c , dlltio n ( tcch ranort ~ .
( l ~ s , ) l ~ pro sect ) ,
many have noted the need for software to assist peo - ple in locating information on the world wide web .
design and imple - this paper presents mentation of an agent called webwatcher that intended to assist users both by interactively advis - ing them as they traverse web links in search of in - formation , and by searching autonomously on their behalf .
in interactive mode , webwatcher acts as a learning apprentice ( mitchell et al . , 123; mitchell et .
al . , 123 ) , providing interactive advice to the mosaic user regarding which hyperlinks next , then learning by observing the users reaction to this advice as well as the eventual success or fail - ure of the users actions .
the initial of webwatcher provides only this interactive mode , and it does not yet possess sufficient knowledge to give widely useful search advice .
in this paper we present webwatcher as a case study in the design of web - based learning agents for information retrieval .
we focus in particular on the interface that enables webwatcher to observe and advise any consenting user browsing any location on the web , and on re - sults of initial experiments with its learning meth -
this section presents the design of webwatcher through a scenario of its use .
webwatcher is an information search agent that is " invoked " by fol - lowing a web hyperlink to its web page , then filling out a mosaic form to indicate what information is a publication by some author ) .
web - watcher then returns the user to ( a copy of ) the web page from which he or she came , and assists the user as they follow hyperlinks forward through the web in search of the target information .
as the the web , webwateher uses its learned knowledge to recommend especially promising hy - perlinks to the user by highlighting these links on the users display .
at any point , the user may dis - miss webwatcher , by clicking one of two indicators on the webwatcher icon , indicating either search has succeeded , or that the user wishes to give up on this search .
the sequence of web pages visited by the user in
file o ~ otlon ~ / vavlgate annotate documents
document url : ifile : / / localhost / afs / cs / project / theo - 123 / web - ag ,
welcome to the webwatcher
this is an c ~ ) rjtmemtal
! ystr . m to ? ~ iv you advice wldje you s torch for thetz ~ ormati123n you
if you would like ma to hdp you , pleas e ( ndinate 123e type of lrfformn ~ on you n$ ~ s ee123jn g .
i wig then wamil over your s houldct and idg ) djght rnks 123at i think arc mo st us e / u123
i wig ~ lso make
rcco rd o ( you ~ scotch path , in order to imam more usejul search sbat ~ ghis
yas , please help me ( b ~ l :
a pc - , = ons homepage .
a protect homepagc ~
n o thanks , , ~ us t take me bar . ~ to where i come from .
i found it !
i give up !
machine learning information services
t ) ds llst is bdngma ~ ta ~ e , dby the ml orqlq ) at the avsuian research institute for
( ntcl ~ lzcnce ( offal ) , victoria , aus bi ~
it is tar frem corn ) lists , andis berg ulldated on an irregular basis .
pleas e direct comracmts / suggestiom / , to o edward wldmer ( gerhardc_ ~ univiem ~ at )
to i ~ o ut our exp er ~ emtal we ~ watchet
~ eard ~ at sis tent , dick ) _l _e ~ _ .
c . , etleral i% ~ l ) #lfortnailult sotlt ~ e . ~
univ ~ dtv ot calffomie - lrvine ( ucd m ad ~ ine leaminf .
pa ~ . e ~ e ~ tbdverzttv of llllnab / ( ix , m l mailing lift archive ( moderatedbv m , pv , ~ anl ~ mlnct - network el exc ~ emcein machine leamin ~ ( gmd lelver ) , m lnet m ~ l ~ g list arc ) dye taunte . rdam - - - not vet installed ~ ilpn et , the inductive lo ~ jc pro ~ ramrt ~ pan - euro : ) ean science network pro rramme " leamlne in humam and iv ( ad ~ incs " teu . , o ~ ) cm ~ .
science foundation ) .
balm kiiuc| ai / ml p ~ - ~ ~ o ~
vaxtam ml program altl dale sources
gmd m addne leamln ~ re; ~ 123 siren , , uc irvine p . epo sltow of m l database , uc irvine repo sitov / of m l pro : ~ raun .
m lc - h - - a m a ~ n leam ~ t librar ~ in c++ tr .
iehavl stanford univ . ) .
pmhenl - - - a set at neural network bendtmark problems ( size . : ~ 123mb i i ) .
prebenl - - - des c ~ ution ( tech rel ) orb .
m lt - biaddne leaming toolbox ( esprit proiect ) .
ecandata - economic time s e123ies data
iiho ~ ollro , omillo . o . , , . l ~ ~ ~ ~
figure 123 : copy of original page with webwatcher
documenttltle : llearning web apprentice paper agent
document url : lhttp : i / pansy , learnlng , cs , cmu , edu : 123obo / cgi - bln
lets find a paper !
ill uy to hejl ) you ~ nd it pleas e ~ llin eny o ( the folio wing that e ~ l ~ ht help me nerrow yo ~ search , use keyword ! in a ~ , / ormat :
o ) : , letg ~ , well | tart with the |late you came trom , from now on i wbl ) o ok over your d ~ ouldcr and hlghligl ~ t tl ~ k fo r you whenevex
i t ) dnk i haw go o d advice ,
uiuc artificial intelligence information
if youre wondcr ~ f ~
thexes k ~ ind o f a i ~ q ~ o s e to this , and vejy few rrjutctiom .
in case yo u came in a back do or , lo cal ai related res catch link ~ i ~ at 123 ~ ebottom of the
figure 123 : paper search form
figure 123 : next page ( user has followed web -
in figures 123 through a typical scenario is illustrated 123
the first screen shows a typical web page , 123 pro - viding information about machine learning .
notice in the third paragraph , this page invites the user to try out webwatcher .
if the user clicks on this link , he or she arrives at the front door webwatcher page ( figure 123 ) , which allows the user to identify the type of information he seeks .
in this scenario the user in - dicates that the goal is to locate a paper , so he is shown a new screen ( figure 123 ) with a form to elabo - rate this information request .
once completed , the user is returned to the original page ( figure 123 ) , with webwatcher now " looking over his shoulder " .
no - the webwatcher icon at the top of the screen , and the highlighted link ( bracketed by the web - watcher eyes icon ) halfway down the screen .
this highlighted link indicates webwatchers advice that the user follow the link to the university of illinois / urbana ( uiuc ) ai / ml page .
the user decides to select this recommended link , and arrives at the new web page shown in figure 123 , which contains new advice from webwatcher .
the search contin - ues in this way , with the user directing and webwatcher highlighting " i found it " or " i give up " .
the user dismisses webwatcher by clicking on
from the users perspective webwatcher is an agent with specialized knowledge about how to search outward from the page on which it was in - voked .
while webwatcher suggests which hyper - link the user should take , the user remains firmly in control , and may ignore the systems advice at any step .
we feel it is important for the user to remain in control , because webwatchers knowledge may provide imperfect advice , and because webwatcher might not perfectly understand the users informa - tion seeking goal .
prom webwatchers perspective ,
the above sce - nario looks somewhat different .
when first it accepts an argument , encoded in the url that ac - cesses it , which contains the users " return address . " the return address is the up ~ l of the web page from which the user came .
once the user fills out the form specifying his or her information seeking goal , webwatcher sends the user back to a copy of this original page , after making three changes .
first , webwatcher banner is added to the top of the page .
second , each hyperlink ui%l in the original page is replaced by a new url that points back to the any of the hyperlinks on this page are strongly rec - ommended by its search control knowledge , then it highlights the most promising links in order to sug - gest them to the user .
it sends this modified copy of the return page to the user , and opens a file begin logging this users information search as train - ing data .
while it waits for the users next step , it prefetches any web pages it has just
the webwatcher finds
123this is a copy of the web page
to which we have added the third paragraph inviting the user to invoke webwatcher .
to the user , and begins to process these pages to determine their most promising outgoing hyperlink .
when the user clicks on the next hyperlink , web - watcher updates the log for this search , retrieves the page ( unless it has already been prefetched ) , performs similar substitutions , and returns the copy to the user .
this process continues , with webwatcher track - ing the users search across the web , providing ad - vice at each step , until the user elects to dismiss the agent .
at this point , log file for this session ( indicating either success or failure in the search , depending on which button the user selected when dismissing webwatcher ) , and re - turns the user to the original , unsubstituted copy of the web page he is currently at .
the webwatcher closes
the above scenario describes a typical
tion with the current webwatcher .
we plan to ex - tend the initial system in several ways .
for example , webwatcher could be made to search several pages ahead , by following its own advice while waiting for the users next input , in order to improve upon the quality of advice it provides .
in addition , if it en - counters an especially promising page while search - ing ahead , it might suggest that the user jump di - rectly to this page rather than follow tediously along the path that the agent has already traversed .
the success of webwatcher depends crucially the quality of its knowledge for guiding search .
be - cause of the difficulty of hand - crafting this knowl - edge , and because we wish for many different copies of webwatcher to become knowledgeable regions of the web , we are explor - ing methods for automatically learning control knowledge from experience .
123 what should what is the form of the knowledge required by web - watcher ? in general , task is to suggest an ap - propriate link given the current user , goal , and web page .
hence , one general form of knowledge that would be useful corresponds to knowledge of the
: page x goal x user x link ~ ( 123 , 123 )
where page is the current web page , goal is the in - formation sought by the user , user is the identity of the user , and link is one of the hyperlinks found on page .
the value of linkutility is the probability that following link from page leads along a short - est path to a page that satisfies the current goal for the current user .
in the learning experiments reported here , we
consider learning a simpler function for which train - ing data is more readily available , and which is still of considerable practical use .
this function is :
userchoice ? : page x goal x link - - * ( 123 , 123 )
table 123 : encoding of selected given page , link , and goal .
where the value of userchoice ? is the probability that an arbitrary user will select link given the cur - rent page and goal .
notice here the user is not an input , and the function value predicts only whether users tend to select link - not whether it leads optimally toward to the goal .
notice also that information about the search trajectory the user arrived at the current page is not consid -
one reason for focusing on uscrchoice ? in our experiments is that the data automatically logged by webwatcher provides of this function .
in particular , each time the user selects a new hyperlink , a training example is logged for each hyperlink on the current page , correspond - ing to the page , goal , link , and whether the user chose this link .
in order to learn and utilize knowledge of the tar - get function userchoice ? , it is necessary to first choose an appropriate for page x goal link .
this representation must be com - patible with available learning methods , and must allow the agent to evaluate learned knowledge ef - ( i . e . , with a delay negligible compared to typical page access delays on the web ) .
notice that one issue here is that web pages , information asso - ciated with hyperlinks , and user information goals are all predominantly text - based , whereas most ma - chine learning methods assume a more structured have experimented with a variety of representations ated with pages , links , and goals as a fixed - length feature vector .
this idea is common within informa - retrieval systems ( salton and mcgill , 123 ) .
it offers the advantage that the information in an arbitrary is summarized in a fixed length feature vector compatible with cur - rent machine learning methods .
it also carries disadvantage that much information is lost by this
such as a feature vector
amount of text
the experiments described here all use the same
information about the current
page , the users search goal , and a particular outgoing link is represented by a vec - tor of approximately 123 boolean features , each fea - ture indicating the occurrence of a particular word within the text that originally defines these three attributes .
the vector of 123 features of four concatenated subvectors :
that occur within the scope of the hypertext the underlined words seen by the user ) .
these 123 features correspond to only the 123 words found to be most informative over all links in the training data ( see below . ) 123
words in the sentence containing the hyperlink .
123 boolean features are allocated to indicate the occurrence of 123 selected words within the sentence ( if any ) that contains link .
words in the headings associated with the hy - perlink .
123 boolean features are allocated to indicate selected words that occur in the head - ings ( if any ) under which link is found .
this includes words occurring in headings at any level of nesting , as long as link is within the scope of the heading .
for example , in fig - ure 123 , any of the words in the headings machine learning information services and general ml information sources may be used as features describe the link that was highlighted .
words used to define the user goal .
these fea - tures indicate words entered by the user while the information search goal .
in our the only goals considered were searches for technical papers , for which the user could optionally enter the title , author , organi - zation , etc .
( see figure 123 ) .
all words entered in this way throughout the training included ( approximately 123 words , though the exact number varied with the training set used in the particular experiment ) .
the encoding of the boolean feature in this case is assigned a 123 if and only if the word occurs in the user - specified goal and occurs in the hyperlink , sentence , or headings associated with this example .
in each case ,
to choose the encodings for the first
to select which words would be it was necessary the words were selected by first gathering every distinct word that occurred then ranking these accord - over the training set , ing to their mutual information with respect the training data , and finally choosing the top n words in this ranking .
123 mutual information is a common statistical measure ( see , e . g . , ( quinlan , 123 ) ) of the degree to which an in - dividual feature ( in this case a word ) can correctly classify the observed data .
figure 123 summarizes the encoding of information
about the current page , link , and goal .
123 what learning
the task of the learner is to learn the general func - tion userchoice ? , given a sample of training data logged from users .
in order to explore possible learning approaches and to determine the level of competence achievable by a learning agent , we ap - plied the following four methods to training data
underlined words in the hyperlink .
123 boolean features are allocated to encode selected words
123the appendix lists
the words selected by this pro -
cedure using one of our training sets .
by webwatcher during 123 information
* winnou ( littlestone , 123 ) learns a boolean con - cept represented as a single linear function of the instance features .
weights for this threshold function are learned using a mul - update rule .
in our experiments we enriched the original 123 attributes by a trans - formation .
each attribute a of an example vec - tor was transformed into is equivalent with the original , the other is its negation .
after the learning phase we removed the threshold and used the output of the learned linear function as an eval - uation for instances .
to make a prediction
in the page goal link vector ,
whether a link is followed based directly on of individual words .
for each keeps two counts : a count of the number of times this feature was set over all training ex - and a count of the number of times this feature was set and the instance was classified as positive ( pos ) .
the ratio pos / total provides an estimate of the conditional proba - bility that the link will be followed , given that this feature occurs .
we experimented with var - ious ways of combining these ratios .
of the ap - proaches we tried , the one that worked best in our experiments , the results of which we report here , involves assuming that these single - word estimates are mutually independent .
this as - sumptions allows us to combine individual es - timates in a straightforward way .
if pl , . . . , pn are the individual probabilities , and i is the set of indexes for which a bit is set in a given test vector , then the probability that the cor - responding link was followed is determined by 123 - 123 - ( i ~ i ( 123 - pi ) .
tfidf with cosine similarity measure ( salton and mcgill , 123; lang , 123 ) is a method de - veloped in information retrieval .
in the gen - eral case at first a vector v of words is cre - ated .
in our experiments it is already given by the representation described above .
every in - stance can now be represented as a vector with the same length as v , replacing every word by a number .
these numbers are calculated by the formula t ~ = ereq ( wordi ) * ( log123 ( n ) log123 ( doceveq ( wordi ) ) ) , with n being the total number of examples , freq ( wordi ) the number of occurrences of wordi in the actual exam - ple and docfreq ( wordi ) the number of exam - ples wordl appears in .
the length of the vec - tor is normalized to 123
prototype vectors for each class of the target concept are created by adding all training vectors of this class .
in our case we had a target concept with two classes : negative ( link was not followed by the user ) .
the evaluation of an instance is calculated by
( link was followed by the user ) , and
the cosine between the instance
vector and the negative prototype vector from the cosine between the instance vector and the positive prototype vector .
random to provide a baseline measure against which to compare the learning methods , we also measured the performance achieved by ran - domly choosing one link on the page with uni - the mean number of links per page over the data used here is 123 , ranging from a minimum of 123 to a maximum of 123
in order to explore the potential of machine learn - ing methods to automatically acquire search control knowledge for webwateher , we collected a set of data from 123 sessions using webwatcher to search for technical papers .
in each session the user began at the web page shown in figure 123 , and searched for type of technical paper following links forward from there .
searches were conducted by three different users .
the average depth of a search was 123 steps , with 123 of the 123 searches successfully locating a paper .
each search session provided a set of training examples corresponding to all the page link pairs occurring on each page visited by the user .
given the above representation method , the obvious questiorkis " how well can web - watcher learn to advise the user ? " to estimate the answer to this question , the available data was split into training and testing sets .
each learning method was applied to the set of training sessions and eval - uated according to how frequently the hyperlink taken by the user in the separate test -
in order to obtain more statistically
timates of learning accuracy , the training data was separated into 123 training sessions and one test ses - sion , in each of the 123 possible ways .
each learn - ing method was then applied to each training sion collection and evaluated on the test session .
the results of these 123 experiments were averaged .
this procedure was run for each of the four learning
figure 123 plots the results of this experiment .
the vertical axis indicates the fraction of test cases in which the user - selected hyperlink was among those recommended by the learned knowledge .
the hori - zontal axis indicates the number of hyperlinks that the learner was allowed to recommend for each page .
thus , the leftmost point of each line indicates fraction of cases in which the user chose the learners link .
the second point to the left in - dicates the fraction of cases in which the user chose one of the two highest - rated links , and so on .
notice that all three learning methods signifi -
cantly outperform randomly generated advice
webwatcher predictive accuracy
worst case ~ -
123 , 123 . : : : : . . . . . . . . .
numbar of links to advise
o : , o : ~ o . ~ o : , , olo o : o o : , o : , , o . ,
fraction of predictions considered
figure 123 : accuracy of advice for different meth - ods .
the vertical axis indicates the fraction of pages for which the recommended hyperlinks included the link chosen by the user .
the horizontal the number of hyperlinks recommended per page .
the worst case line shows the fraction of pages having n or fewer links total .
figure 123 : increasing accuracy by reducing cover - age .
the vertical axis indicates the fraction of test pages for which the learners was taken by the user .
the horizontal axis indicates the fraction of test cases covered by advice as the confidence threshold is varied from high confidence ( left ) to low ( right ) .
example , winnow recommends the user - selected as its first choice in 123% of the test cases , and among its top three choices in 123% of the cases .
given the mean of 123 links per page in this data , random ad - vice chooses the user - selected link only 123% of the
123 can accuracy be improved by
coverage is decreased to a more selective 123% of the cases .
interestingly , while wordstats advice is rel - atively accurate in general , its accuracy degrades at higher thresholds .
the presence of features which occur very infrequently in the train - ing set , resulting in poor probability estimates , and independence assumption , which the training set by no means justifies , appear to ac - count for this phenomenon .
some users may prefer that the agent provide more accurate advice , even if this requires that it make recommendations more sparingly .
to determine the feasibility of increasing advice accuracy by reducing coverage , we experimented with adding a thresh - old on the confidence of the advice .
for each of the learning methods considered here , the learners number that can be used in recommending the link .
therefore , it is easy to introduce a confidence threshold in each of these cases .
is a real - valued
figure 123 shows how advice accuracy varies with coverage , as the confidence threshold is varied .
for high values of the confidence threshold , provides advice less often , but can usually achieve higher accuracy .
in this case , accuracy is measured by the fraction of test cases for which the learners top ranked hyperlink is the link selected by the user .
thus , the rightmost points in the plots of figure 123 correspond exactly to the leftmost plots in figure 123 ( i . e . , 123% coverage ) .
notice that the accuracy of i ~ innows top - ranked from 123% to 123% as its
is already needed to deal with the growing flood of information available on the www .
the design of webwatcher is based on the assumption that knowledge about how to search the web can be learned by interactively watching searches performed by humans .
if suc - cessful , different copies of webwatcher could easily be attached to any web page for which a specialized search assistant would be useful .
over time , each copy could learn expertise specializing in the types of users , information needs , and information sources commonly encountered through its page .
in the preliminary learning experiments reported here , webwatcher was able to learn search control knowledge that approximately predicts link selected by users , conditional on the current page , link , and goal .
these experiments also showed that the accuracy of the agents advice can be in - creased by allowing it to give advice only when it has high confidence .
while these experimental re - sults are positive ,
they are based on a small number
of training sessions , searching for a particular type of information , from a specific web page .
we do not yet know whether the results reported here are rep - resentative of what can be expected for other search goals , users , and web localities .
based on our initial exploration , we are optimistic that a learning apprentice for the world wide web is feasible .
although learned knowledge may provide only imperfect advice , even a modest reduction in the number of hyperlinks considered at each page leads to an exponential improvement in the overall search .
moreover , we believe learning can be made more effective by taking advantage of the abundant data available from many users on the web , and by considering methods beyond those reported here .
for additional information , see the webwatcher
project page , http : / / www . cs . cmu . edu : 123 / afs / cs . cmu . edu
/ theo - 123 / web - agent / www / project - home . html .
we thank ken lang for providing much of the soft - ware for learning over pages of text , and for sug - gesting the idea of implementing the agent by dy - namically editing web pages .
thanks to michael mauldin for software and advice on the construc - tion of a web - based text - retrieval system .
we are grateful to rich caruana and ken lang for helpful comments on this paper .
this research is supported by a rotary international fellowship grant , an nsf graduate fellowship , and by arpa under grant num -
