markov chain monte carlo ( mcmc ) originated with the classic paper of metropolis et al .
( 123 ) , where it was used to simulate the distribution of states for a system of ideal - ized molecules .
not long after , another approach to molecular simulation was introduced ( alder and wainwright , 123 ) , in which the motion of the molecules was deterministic , fol - lowing newtons laws of motion , which have an elegant formalization as hamiltonian dy - namics .
for nding the properties of bulk materials , these approaches are asymptotically equivalent , since even in a deterministic simulation , each local region of the material ex - periences eectively random inuences from distant regions .
despite the large overlap in their application areas , the mcmc and molecular dynamics approaches have continued to co - exist in the following decades ( see frenkel and smit , 123 ) .
in 123 , a landmark paper by duane , kennedy , pendleton , and roweth united the mcmc and molecular dynamics approaches .
they called their method hybrid monte carlo , which
mcmc using hamiltonian dynamics
abbreviates to hmc , but the phrase hamiltonian monte carlo , retaining the abbrevi - ation , is more specic and descriptive , and i will use it here .
duane , et al .
applied hmc not to molecular simulation , but to lattice eld theory simulations of quantum chromody - namics .
statistical applications of hmc began with my use of it for neural network models ( neal , 123a ) .
i also provided a statistically - oriented tutorial on hmc in a review of mcmc methods ( neal , 123 , chapter 123 ) .
there have been other applications of hmc to statisti - cal problems ( eg , ishwaran , 123; schmidt , 123 ) and statistically - oriented reviews ( eg , liu , 123 , chapter 123 ) , but hmc still seems to be under - appreciated by statisticians , and perhaps also by physicists outside the lattice eld theory community .
this review begins by describing hamiltonian dynamics .
despite terminology that may be unfamiliar to non - physicists , the features of hamiltonian dynamics that are needed for hmc are elementary .
the dierential equations of hamiltonian dynamics must be discretized for computer implementation .
the leapfrog scheme that is typically used is quite simple .
following this introduction to hamiltonian dynamics , i describe how to use it to construct a markov chain monte carlo method .
the rst step is to dene a hamiltonian function in terms of the probability distribution we wish to sample from .
in addition to the variables we are interested in ( the position variables ) , we must introduce auxiliary momentum variables , which typically have independent gaussian distributions .
the hamiltonian monte carlo method alternates simple updates for these momentum variables with metropolis up - dates in which a new state is proposed by computing a trajectory according to hamiltonian dynamics , implemented with the leapfrog method .
a state proposed in this way can be distant from the current state but nevertheless have a high probability of acceptance .
this bypasses the slow exploration of the state space that occurs when metropolis updates are done using a simple random - walk proposal distribution .
( an alternative way of avoiding random walks is to use short trajectories but only partially replace the momentum variables between trajectories , so that successive trajectories tend to move in the same direction . )
after presenting the basic hmc method , i discuss practical issues of tuning the leapfrog stepsize and number of leapfrog steps , as well as theoretical results on the scaling of hmc with dimensionality .
i then present a number of variations on hmc .
the acceptance rate for hmc can be increased for many problems by looking at windows of states at the begin - ning and end of the trajectory .
for many statistical problems , approximate computation of trajectories ( eg , using subsets of the data ) may be benecial .
tuning of hmc can be made easier using a short - cut in which trajectories computed with a bad choice of stepsize take little computation time .
finally , tempering methods may be useful when multiple isolated
123 hamiltonian dynamics
hamiltonian dynamics has a physical interpretation that can provide useful intuitions .
in two dimensions , we can visualize the dynamics as that of a frictionless puck that slides over a surface of varying height .
the state of this system consists of the position of the puck , given by a 123d vector q , and the momentum of the puck ( its mass times its velocity ) , given by a 123d vector p .
the potential energy , u ( q ) , of the puck is proportional to the height of the surface at its current position , and its kinetic energy , k ( p ) , is equal to |p|123 / ( 123m ) , where m is the mass of the puck .
on a level part of the surface , the puck moves at a constant velocity , equal to p / m .
if it encounters a rising slope , the pucks momentum allows it to continue , with its kinetic energy decreasing and its potential energy increasing , until the kinetic energy ( and
hamiltonian dynamics
hence p ) is zero , at which point it will slide back down ( with kinetic energy increasing and potential energy decreasing ) .
in non - physical mcmc applications of hamiltonian dynamics , the position will corre - spond to the variables of interest .
the potential energy will be minus the log of the proba - bility density for these variables .
momentum variables , one for each position variable , will be introduced articially .
these interpretations may help motivate the exposition below , but if you nd otherwise , the dynamics can also be understood as simply resulting from a certain set of dierential
123 hamiltons equations
hamiltonian dynamics operates on a d - dimensional position vector , q , and a d - dimensional momentum vector , p , so that the full state space has 123d dimensions .
the system is described by a function of q and p known as the hamiltonian , h ( q , p ) .
equations of motion .
the partial derivatives of the hamiltonian determine how q and p change over time , t , according to hamiltons equations :
for i = 123 , .
for any time interval of duration s , these equations dene a mapping , ts , from the state at any time t to the state at time t + s .
( here , h , and hence ts , are assumed to not depend on t . )
alternatively , we can combine the vectors q and p into the vector z = ( q , p ) with 123d
dimensions , and write hamiltons equations as
where h is the gradient of h ( ie , ( h ) k = h / zk ) , and idd 123dd ( cid : 123 )
j = ( cid : 123 ) 123dd
= j h ( z )
is a 123d 123d matrix whose quadrants are dened above in terms identity and zero matrices .
potential and kinetic energy .
for hamiltonian monte carlo , we usually use hamilto - nian functions that can be written as follows :
h ( q , p ) = u ( q ) + k ( p )
here , u ( q ) is called the potential energy , and will be dened to be minus the log probability density of the distribution for q that we wish to sample , plus any constant that is convenient .
k ( p ) is called the kinetic energy , and is usually dened as
k ( p ) = pt m 123p / 123
mcmc using hamiltonian dynamics
here , m is a symmetric , positive - denite mass matrix , which is typically diagonal , and is often a scalar multiple of the identity matrix .
this form for k ( p ) corresponds to minus the log probability density ( plus a constant ) of the zero - mean gaussian distribution with covariance matrix m .
with these forms for h and k , hamiltons equations , ( 123 ) and ( 123 ) , can be written as
follows , for i = 123 ,
= ( m 123p ) i
a one - dimensional example .
consider a simple example in one dimension ( for which q and p are scalars and will be written without subscripts ) , in which the hamiltonian is dened as follows :
h ( q , p ) = u ( q ) + k ( p ) , u ( q ) = q123 / 123 , k ( p ) = p123 / 123
as well see later in section 123 , this corresponds to a gaussian distribution for q with mean zero and variance one .
the dynamics resulting from this hamiltonian ( following equa - tions ( 123 ) and ( 123 ) ) is
solutions have the following form , for some constants r and a :
q ( t ) = r cos ( a + t ) ,
p ( t ) = r sin ( a + t )
hence the mapping ts is a rotation by s radians clockwise around the origin in the ( q , p ) plane .
in higher dimensions , hamiltonian dynamics generally does not have such a simple periodic form , but this example does illustrate some important properties that we will look
123 properties of hamiltonian dynamics
several properties of hamiltonian dynamics are crucial to its use in constructing markov chain monte carlo updates .
reversibility .
first , hamiltonian dynamics is reversible the mapping ts from the state at time t , ( q ( t ) , p ( t ) ) , to the state at time t+s , ( q ( t+s ) , p ( t+s ) ) , is one - to - one , and hence has an inverse , ts .
this inverse mapping is obtained by simply negating the time derivatives in equations ( 123 ) and ( 123 ) .
when the hamiltonian has the form in equation ( 123 ) , and k ( p ) = k ( p ) , as in the quadratic form for the kinetic energy of equation ( 123 ) , the inverse mapping can also be obtained by negating p , applying ts , and then negating p again .
in the simple 123d example of equation ( 123 ) , ts is just a counter - clockwise rotation by s
radians , undoing the clockwise rotation of ts .
the reversibility of hamiltonian dynamics is important for showing that mcmc updates that use the dynamics leave the desired distribution invariant , since this is most easily proved by showing reversibility of the markov chain transitions , which requires reversibility of the dynamics used to propose a state .
hamiltonian dynamics
conservation of the hamiltonian .
a second property of the dynamics is that it keeps the hamiltonian invariant ( ie , conserved ) .
this is easily seen from equations ( 123 ) and ( 123 )
xi=123 ( cid : 123 ) h
pi ( cid : 123 ) = 123
with the hamiltonian of equation ( 123 ) , the value of the hamiltonian is half the squared distance from the origin , and the solutions ( equation ( 123 ) ) stay at a constant distance from the origin , keeping h constant .
for metropolis updates using a proposal found by hamiltonian dynamics , which form part of the hmc method , the acceptance probability is one if h is kept invariant .
we will see later , however , that in practice we can only make h approximately invariant , and hence we will not quite be able to achieve this .
volume preservation .
a third fundamental property of hamiltonian dynamics is that it preserves volume in ( q , p ) space ( a result known as liouvilles theorem ) .
if we apply the mapping ts to the points in some region r of ( q , p ) space , with volume v , the image of r under ts will also have volume v .
with the hamiltonian of equation ( 123 ) , the solutions ( equation ( 123 ) ) are rotations , which obviously do not change the volume .
such rotations also do not change the shape of a region , but this is not so in general hamiltonian dynamics might stretch a region in one direction , as long as the region is squashed in some other direction so as to preserve volume .
the signicance of volume preservation for mcmc is that we neednt account for any change in volume in the acceptance probability for metropolis updates .
if we proposed new states using some arbitrary , non - hamiltonian , dynamics , we would need to compute the determinant of the jacobian matrix for the mapping the dynamics denes , which might well
the preservation of volume by hamiltonian dynamics can be proved in several ways .
one is to note that the divergence of the vector eld dened by equations ( 123 ) and ( 123 ) is zero , which can be seen as follows :
dt ( cid : 123 ) =
xi=123 ( cid : 123 ) 123h
piqi ( cid : 123 ) = 123 ( 123 )
a vector eld with zero divergence can be shown to preserve volume ( arnold , 123 ) .
here , i will show informally that hamiltonian dynamics preserves volume more directly , without presuming this property of the divergence .
i will , however , take as given that volume preservation is equivalent to the determinant of the jacobian matrix of ts having absolute value one , which is related to the well - known role of this determinant in regard to the eect of transformations on denite integrals and on probability density functions .
the 123d 123d jacobian matrix of ts , seen as a mapping of z = ( q , p ) , will be written as bs .
in general , bs will depend on the values of q and p before the mapping .
when bs is diagonal , it is easy to see that the absolute values of its diagonal elements are the factors by which ts stretches or compresses a region in each dimension , so that the product of these
mcmc using hamiltonian dynamics
factors , which is equal to the absolute value of det ( bs ) , is the factor by which the volume of the region changes .
i will not prove the general result here , but note that if we were to ( say ) rotate the coordinate system used , bs would no longer be diagonal , but the determinant of bs is invariant to such transformations , and so would still give the factor by which the
lets rst consider volume preservation for hamiltonian dynamics in one dimension ( ie , with d = 123 ) , for which we can drop the subscripts on p and q .
we can approximate t for near zero as follows :
t ( q , p ) = ( cid : 123 ) q
p ( cid : 123 ) + ( cid : 123 ) dq / dt
dp / dt ( cid : 123 ) + terms of order 123 or higher
taking the time derivatives from equations ( 123 ) and ( 123 ) , the jacobian matrix can be
+ terms of order 123 or higher
we can then write the determinant of this matrix as
det ( b ) = 123 +
+ terms of order 123 or higher
= 123 + terms of order 123 or higher
since log ( 123 + x ) x for x near zero , log det ( b ) is zero except perhaps for terms of order 123 or higher ( though we will see later that it is exactly zero ) .
now consider log det ( bs ) for some time interval s that is not close to zero .
setting = s / n , for some integer n , we can write ts as the composition of t applied n times ( from n points along the trajectory ) , so det ( bs ) is the n - fold product of det ( b ) evaluated at these points .
we then nd that
log det ( bs ) =
xi=123 nterms of order 123 / n123 or smallero
= terms of order 123 / n or smaller
note that the value of b in the sum in ( 123 ) might perhaps vary with i , since the values of q and p vary along the trajectory that produces ts .
however , assuming that trajectories are not singular , the variation in b must be bounded along any particular trajectory .
taking the limit as n , we conclude that log det ( bs ) = 123 , so det ( bs ) = 123 , and hence ts preserves
when d > 123 , the same argument applies .
the jacobian matrix will now have the following form ( compare equation ( 123 ) ) , where each entry shown below is a d d sub - matrix , with
hamiltonian dynamics
rows indexed by i and columns by j :
+ terms of order 123 or higher
i + ( cid : 123 ) 123h
i ( cid : 123 ) 123h
as for d = 123 , the determinant of this matrix will be one plus terms of order 123 or higher , since all the terms of order cancel .
the remainder of the argument above then applies
symplecticness .
volume preservation is also a consequence of hamiltonian dynamics be - ing symplectic .
letting z = ( q , p ) , and dening j as in equation ( 123 ) , the symplecticness condition is that the jacobian matrix , bs , of the mapping ts satises
s j 123 bs = j 123
s ) det ( j 123 ) det ( bs ) = det ( j 123 ) implies that this implies volume conservation , since det ( b t det ( bs ) 123 is one .
when d > 123 , the symplecticness condition is stronger than volume preser - vation .
hamiltonian dynamics and the symplecticness condition can be generalized to where j is any matrix for which j t = j and det ( j ) 123= 123
crucially , reversibility , preservation of volume , and symplecticness can be maintained exactly even when , as is necessary in practice , hamiltonian dynamics is approximated , as we will see next .
123 discretizing hamiltons equations the leapfrog method
for computer implementation , hamiltons equations must be approximated by discretizing time , using some small stepsize , .
starting with the state at time zero , we iteratively compute ( approximately ) the state at times , 123 , 123 , etc .
in discussing how to do this , i will assume that the hamiltonian has the form h ( q , p ) = u ( q ) +k ( p ) , as in equation ( 123 ) .
although the methods below can be applied with any form for the kinetic energy , i for simplicity assume that k ( p ) = pt m 123p , as in equation ( 123 ) , and furthermore that m is diagonal , with diagonal elements m123 , .
, md , so that
eulers method .
perhaps the best - known way to approximate the solution to a system of dierential equations is eulers method .
for hamiltons equations , this method performs the following steps , for each component of position and momentum , indexed by i = 123 ,
pi ( t + ) = pi ( t ) +
qi ( t + ) = qi ( t ) +
( t ) = pi ( t )
( t ) = qi ( t ) +
mcmc using hamiltonian dynamics
the time derivatives above are from the form of hamiltons equations given by ( 123 ) and ( 123 ) .
if we start at t = 123 with given values for qi ( 123 ) and pi ( 123 ) , we can iterate the steps above to get a trajectory of position and momentum values at times , 123 , 123 , .
. , and hence nd ( approximate ) values for q ( ) and p ( ) after / steps ( assuming / is an integer ) .
figure 123 ( a ) shows the result of using eulers method to approximate the dynamics dened by the hamiltonian of ( 123 ) , starting from q ( 123 ) = 123 and p ( 123 ) = 123 , and using a stepsize of = 123 for 123 steps ( ie , to = 123 123 = 123 ) .
the results arent good eulers method produces a trajectory that diverges to innity , but the true trajectory is a circle .
using a smaller value of , and correspondingly more steps , produces a more accurate result at = 123 , but although the divergence to innity is slower , it is not eliminated .
a modication of eulers method .
much better results can be obtained by slightly modifying eulers method , as follows :
pi ( t + ) = pi ( t )
qi ( t + ) = qi ( t ) +
pi ( t + )
we simply use the new value for the momentum variables , pi , when computing the new value for the position variables , qi .
a method with similar performance can be obtained by instead updating the qi rst and using their new values to update the pi .
figure 123 ( b ) shows the results using this modication of eulers method with = 123 .
though not perfect , the trajectory it produces is much closer to the true trajectory than that obtained using eulers method , with no tendency to diverge to innity .
this better performance is related to the modied methods exact preservation of volume , which helps avoid divergence to innity or spiraling into the origin , since these would typically involve the volume expanding to innity or contracting to zero .
to see that this modication of eulers method preserves volume exactly despite the nite discretization of time , note that both the transformation from ( q ( t ) , p ( t ) ) to ( q ( t ) , p ( t + ) ) via equation ( 123 ) and the transformation from ( q ( t ) , p ( t+ ) ) to ( q ( t+ ) , p ( t+ ) ) via equa - tion ( 123 ) are shear transformations , in which only some of the variables change ( either the pi or the qi ) , by amounts that depend only on the variables that do not change .
any shear transformation will preserve volume , since its jacobian matrix will have determinant one ( as the only non - zero term in the determinant will be the product of diagonal elements , which will all be one ) .
the leapfrog method .
even better results can be obtained with the leapfrog method , which works as follows :
pi ( t + / 123 ) = pi ( t ) ( / 123 )
qi ( t + ) = qi ( t ) +
pi ( t + / 123 )
pi ( t + ) = pi ( t + / 123 ) ( / 123 )
( q ( t + ) )
hamiltonian dynamics
( a ) eulers method , stepsize 123
( b ) modified eulers method , stepsize 123
( c ) leapfrog method , stepsize 123
( d ) leapfrog method , stepsize 123
figure 123 : results using three methods for approximating hamiltonian dynamics , when h ( q , p ) = q123 / 123 + p123 / 123
the initial state was q = 123 , p = 123
the stepsize was = 123 for ( a ) , ( b ) , and ( c ) , and = 123 for ( d ) .
twenty steps of the simulated trajectory are shown for each method , along with the true trajectory ( in gray ) .
mcmc using hamiltonian dynamics
we start with a half step for the momentum variables , then do a full step for the position variables , using the new values of the momentum variables , and nally do another half step for the momentum variables , using the new values for the position variables .
an analogous scheme can be used with any kinetic energy function , with k / pi replacing pi / mi above .
when we apply equations ( 123 ) to ( 123 ) a second time to go from time t + to t + 123 , we can combine the last half step of the rst update , from pi ( t + / 123 ) to pi ( t + ) , with the rst half step of the second update , from pi ( t + ) to pi ( t + + / 123 ) .
the leapfrog method then looks very similar to the modication of eulers method in equations ( 123 ) and ( 123 ) , except that leapfrog performs half steps for momentum at the very beginning and very end of the trajectory , and the time labels of the momentum values computed are shifted by / 123
the leapfrog method preserves volume exactly , since each of ( 123 ) to ( 123 ) are shear transformations .
due to its symmetry , it is also reversible by simply negating p , applying the same number of steps again , and then negating p again .
figure 123 ( c ) shows the results using the leapfrog method with a stepsize of = 123 , which are indistinguishable from the true trajectory , at the scale of this plot .
in figure 123 ( d ) , the results of using the leapfrog method with = 123 are shown ( still with 123 steps , so almost four cycles are seen , rather than almost one ) .
with this larger stepsize , the approximation error is clearly visible , but the trajectory still remains stable ( and will stay stable indenitely ) .
only when the stepsize approaches = 123 do the trajectories become unstable .
local and global error of discretization methods .
i will briey discuss how the error from discretizing the dynamics behaves in the limit as the stepsize , , goes to zero; leimkuhler and reich ( 123 ) provide a much more detailed discussion .
for useful methods , the error goes to zero as goes to zero , so that any upper limit on the error will apply ( apart from a usually unknown constant factor ) to any dierentiable function of state eg , if the error for ( q , p ) is no more than order 123 , the error for h ( q , p ) will also be no more than order 123
the local error is the error after one step , that moves from time t to time t + .
the global error is the error after simulating for some xed time interval , s , which will require s / steps .
if the local error is order p , the global error will be order p123 the local errors of order p accumulate over the s / steps to give an error of order p123
if we instead x and consider increasing the time , s , for which the trajectory is simulated , the error can in general increase exponentially with s .
interestingly , however , this is often not what happens when simulating hamiltonian dynamics with a symplectic method , as can be seen in figure 123
the euler method and its modication above have order 123 local error and order global error .
the leapfrog method has order 123 local error and order 123 global error .
as shown by leimkuhler and reich ( 123 , section 123 . 123 ) this dierence is a consequence of leapfrog being reversible , since any reversible method must have global error that is of even order in .
123 mcmc from hamiltonian dynamics
using hamiltonian dynamics to sample from a distribution requires translating the density function for this distribution to a potential energy function and introducing momentum variables to go with the original variables of interest ( now seen as position variables ) .
we can then simulate a markov chain in which each iteration resamples the momentum and then does a metropolis update with a proposal found using hamiltonian dynamics .
mcmc from hamiltonian dynamics
123 probability and the hamiltonian canonical distributions
the distribution we wish to sample can be related to a potential energy function via the concept of a canonical distribution from statistical mechanics .
given some energy function , e ( x ) , for the state , x , of some physical system , the canonical distribution over states has probability or probability density function
p ( x ) =
here , t is the temperature of the system123 , and z is the normalizing constant needed for this function to sum or integrate to one .
viewing this the opposite way , if we are interested in some distribution with density function p ( x ) , we can obtain it as a canonical distribution with t = 123 by setting e ( x ) = log p ( x ) log z , where z is any convenient positive constant .
the hamiltonian is an energy function for the joint state of position , q , and momen -
tum , p , and so denes a joint distribution for them , as follows :
p ( q , p ) =
exp ( h ( q , p ) / t )
note that the invariance of h under hamiltonian dynamics means that a hamiltonian trajec - tory will ( if simulated exactly ) move within a hyper - surface of constant probability density .
if h ( q , p ) = u ( q ) + k ( p ) , the joint density is
p ( q , p ) =
exp ( u ( q ) / t ) exp ( k ( p ) / t )
and we see that q and p are independent , and each have canonical distributions , with energy functions u ( q ) and k ( p ) .
we will use q to represent the variables of interest , and introduce p just to allow hamiltonian dynamics to operate .
in bayesian statistics , the posterior distribution for the model parameters is the usual focus of interest , and hence these parameters will take the role of the position , q .
we can express the posterior distribution as a canonical distribution ( with t = 123 ) using a potential energy function dened as follows :
where ( q ) is the prior density , and l ( q|d ) is the likelihood function given data d .
u ( q ) = logh ( q ) l ( q|d ) i
123 the hamiltonian monte carlo algorithm
we now have the background needed to present the hamiltonian monte carlo ( hmc ) algo - rithm .
hmc can be used to sample only from continuous distributions on rd for which the density function can be evaluated ( perhaps up to an unknown normalizing constant ) .
for the moment , i will also assume that the density is non - zero everywhere ( but this is relaxed in section 123 ) .
we must also be able to compute the partial derivatives of the log of the density function .
these derivatives must therefore exist , except perhaps on a set of points with probability zero , for which some arbitrary value could be returned .
123note to physicists : i assume here that temperature is measured in units that make boltzmanns constant be one .
mcmc using hamiltonian dynamics
hmc samples from the canonical distribution for q and p dened by equation ( 123 ) , in which q has the distribution of interest , as specied using the potential energy function u ( q ) .
we can choose the distribution of the momentum variables , p , which are independent of q , as we wish , specifying the distribution via the kinetic energy function , k ( p ) .
current practice with hmc is to use a quadratic kinetic energy , as in equation ( 123 ) , which leads p to have a zero - mean multivariate gaussian distribution .
most often , the components of p are specied to be independent , with component i having variance mi .
the kinetic energy function producing this distribution ( setting t = 123 ) is
we will see in section 123 how the choice for the mi aects performance .
the two steps of the hmc algorithm .
each iteration of the hmc algorithm has two steps .
the rst changes only the momentum; the second may change both position and momentum .
both steps leave the canonical joint distribution of ( q , p ) invariant , and hence their combination also leaves this distribution invariant .
in the rst step , new values for the momentum variables are randomly drawn from their gaussian distribution , independently of the current values of the position variables .
for the kinetic energy of equation ( 123 ) , the d momentum variables are independent , with pi having mean zero and variance mi .
since q isnt changed , and p is drawn from its correct conditional distribution given q ( the same as its marginal distribution , due to independence ) , this step obviously leaves the canonical joint distribution invariant .
in the second step , a metropolis update is performed , using hamiltonian dynamics to pro - pose a new state .
starting with the current state , ( q , p ) , hamiltonian dynamics is simulated for l steps using the leapfrog method ( or some other reversible method that preserves vol - ume ) , with a stepsize of .
here , l and are parameters of the algorithm , which need to be tuned to obtain good performance ( as discussed below in section 123 ) .
the momentum vari - ables at the end of this l - step trajectory are then negated , giving a proposed state ( q , p ) .
this proposed state is accepted as the next state of the markov chain with probability
minh123 , exp ( h ( q , p ) + h ( q , p ) ) i = minh123 , exp ( u ( q ) + u ( q ) k ( p ) + k ( p ) ) i ( 123 )
if the proposed state is not accepted ( ie , it is rejected ) , the next state is the same as the current state ( and is counted again when estimating the expectation of some function of state by its average over states of the markov chain ) .
the negation of the momentum variables at the end of the trajectory makes the metropolis proposal symmetrical , as needed for the acceptance probability above to be valid .
this negation need not be done in practice , since k ( p ) = k ( p ) , and the momentum will be replaced before it is used again , in the rst step of the next iteration .
( this assumes that these hmc updates are the only ones performed . )
if we look at hmc as sampling from the joint distribution of q and p , the metropolis step using a proposal found by hamiltonian dynamics leaves the probability density for ( q , p ) unchanged or almost unchanged .
movement to ( q , p ) points with a dierent probability density is accomplished only by the rst step in an hmc iteration , in which p is replaced by a new value .
fortunately , this replacement of p can change the probability density for ( q , p ) by a large amount , so movement to points with a dierent probability density is not a problem ( at least not for this reason ) .
looked at in terms of q only , hamiltonian dynamics for ( q , p )
mcmc from hamiltonian dynamics
can produce a value for q with a much dierent probability density ( equivalently , a much dierent potential energy , u ( q ) ) .
however , the resampling of the momentum variables is still crucial to obtaining the proper distribution for q .
without resampling , h ( q , p ) = u ( q ) +k ( p ) will be ( nearly ) constant , and since k ( p ) and u ( q ) are non - negative , u ( q ) could never exceed the initial value of h ( q , p ) if no resampling for p were done .
a function that implements a single iteration of the hmc algorithm , written in the r is shown in figure 123
its rst two arguments are functions u , which returns the potential energy given a value for q , and grad u , which returns the vector of partial derivatives of u given q .
other arguments are the stepsize , epsilon , for leapfrog steps , the number of leapfrog steps in the trajectory , l , and the current position , current q , that the trajectory starts from .
momentum variables are sampled within this function , and discarded at the end , with only the next position being returned .
the kinetic energy is assumed to have i / 123 ( ie , all mi are one ) .
in this program , all components of p and of q are updated simultaneously , using vector operations .
this simple implementation of hmc is available from my web page123 , along with other r programs with extra features helpful for practical use , and that illustrate some of the variants of hmc in section 123
the simplest form , k ( p ) =p p123
proof that hmc leaves the canonical distribution invariant .
the metropolis up - date above is reversible with respect to the canonical distribution for q and p ( with t = 123 ) , a condition also known as detailed balance , and which can be phrased informally as follows .
suppose we partition the ( q , p ) space into regions ak , each with the same small volume v .
let the image of ak with respect to the operation of l leapfrog steps , plus a negation of the momentum , be bk .
due to the reversibility of the leapfrog steps , the bk will also partition the space , and since the leapfrog steps preserve volume ( as does negation ) , each bk will also have volume v .
detailed balance holds if , for all i and j ,
p ( ai ) t ( bj|ai ) = p ( bj ) t ( ai|bj )
where p is probability under the canonical distribution , and t ( x|y ) is the conditional probability of proposing and then accepting a move to region x if the current state is in region y .
clearly , when i 123= j , t ( ai|bj ) = t ( bj|ai ) = 123 and so equation ( 123 ) will be satised .
since the hamiltonian is continuous almost everywhere , in the limit as the regions ak and bk become smaller , the hamiltonian becomes eectively constant within each region , with value hx in region x , and hence the canonical probability density and the transition probabilities become eectively constant within each region as well .
we can now rewrite equation ( 123 ) for i = j ( say both equal to k ) as
exp ( hak ) minh123 , exp ( hbk+hak ) i =
which is easily seen to be true .
exp ( hbk ) minh123 , exp ( hak+hbk ) i ( 123 )
detailed balance implies that this metropolis update leaves the canonical distribution for q and p invariant .
this can be seen as follows .
let r ( x ) be the probability that the metropolis update for a state in the small region x leads to rejection of the proposed state .
suppose that the current state is distributed according to the canonical distribution .
the probability that the next state is in a small region bk is the sum of the probability that the current state is in bk and the update leads to rejection , and the probability that the current
123r is available for free from r - project . org
mcmc using hamiltonian dynamics
hmc = function ( u , grad_u , epsilon , l , current_q )
q = current_q p = rnorm ( length ( q ) , 123 , 123 ) current_p = p
# independent standard normal variates
# make a half step for momentum at the beginning
p = p - epsilon * grad_u ( q ) / 123
# alternate full steps for position and momentum
for ( i in 123 : l )
# make a full step for the position
q = q + epsilon * p
# make a full step for the momentum , except at end of trajectory
if ( i ! =l ) p = p - epsilon * grad_u ( q )
# make a half step for momentum at the end .
p = p - epsilon * grad_u ( q ) / 123
# negate momentum at end of trajectory to make the proposal symmetric
p = - p
# evaluate potential and kinetic energies at start and end of trajectory
current_u = u ( current_q ) current_k = sum ( current_p^123 ) / 123 proposed_u = u ( q ) proposed_k = sum ( p^123 ) / 123
# accept or reject the state at end of trajectory , returning either # the position at the end of the trajectory or the initial position
if ( runif ( 123 ) < exp ( current_u - proposed_u+current_k - proposed_k ) )
figure 123 : the hamiltonian monte carlo algorithm
mcmc from hamiltonian dynamics
state is in some region from which a move to bk is proposed and accepted .
the probability of the next state being in bk can therefore be written as
p ( bk ) r ( bk ) + xi
p ( ai ) t ( bk|ai ) = p ( bk ) r ( bk ) + xi
p ( bk ) t ( ai|bk )
= p ( bk ) r ( bk ) + p ( bk ) xi = p ( bk ) r ( bk ) + p ( bk ) ( 123 r ( bk ) ) = p ( bk )
the metropolis update within hmc therefore leaves the canonical distribution invariant .
since both the sampling of momentum variables and the metropolis update with a pro - posal found by hamiltonian dynamics leave the canonical distribution invariant , the hmc algorithm as a whole does as well .
ergodicity of hmc .
typically , the hmc algorithm will also be ergodic it will not be trapped in some subset of the state space , and hence will asymptotically converge to its ( unique ) invariant distribution .
in an hmc iteration , any value can be sampled for the momentum variables , which can typically then aect the position variables in arbitrary ways .
however , ergodicity can fail if the l leapfrog steps in a trajectory produce an exact periodicity for some function of state .
for example , with the simple hamiltonian of equation ( 123 ) , the exact solutions ( given by equation ( 123 ) ) are periodic with period 123
approximate trajectories found with l leapfrog steps with stepsize may return to the same position coordinate when l is approximately 123
hmc with such values for l and will not be ergodic .
for nearby values of l and , hmc may be theoretically ergodic , but take a very long time to move about the full state space .
this potential problem of non - ergodicity can be solved by randomly choosing or l ( or both ) from some fairly small interval ( mackenzie , 123 ) .
doing this routinely may be advisable .
although in real problems interactions between variables typically prevent any exact periodicities from occurring , near periodicities might still slow hmc considerably .
illustrations of hmc and its benets
here , i will illustrate some practical issues with hmc , and demonstrate its potential to sample much more eciently than simple methods such as random - walk metropolis .
i use simple gaussian distributions for these demonstrations , so that the results can be compared with known values , but of course hmc is typically used for more complex distributions .
trajectories for a two - dimensional problem .
consider sampling from a distribution for two variables that is bivariate gaussian , with means of zero , standard deviations of one , and correlation 123 .
we regard these as position variables , and introduce two cor - responding momentum variables , dened to have a gaussian distribution with means of zero , standard deviations of one , and zero correlation .
we then dene the hamiltonian as
h ( q , p ) = q t 123q / 123 + pt p / 123 ,
with = ( cid : 123 ) 123
value of hamiltonian
mcmc using hamiltonian dynamics
figure 123 : a trajectory for a 123d gaussian distribution , simulated using 123 leapfrog steps with a stepsize of 123 .
the ellipses plotted are one standard deviation from the means .
the initial state had q = ( 123 , 123 ) t and p = ( 123 , 123 ) t .
figure 123 shows a trajectory based on this hamiltonian , such as might be used to propose a new state in the hamiltonian monte carlo method , computed using l = 123 leapfrog steps , with a stepsize of = 123 .
since the full state space is four - dimensional , the figure shows the two position coordinates and the two momentum coordinates in separate plots , while the third plot shows the value of the hamiltonian after each leapfrog step .
notice that this trajectory does not resemble a random - walk .
instead , starting from the lower - left corner , the position variables systematically move upwards and to the right , until they reach the upper - right corner , at which point the direction of motion is reversed .
the consistency of this motion results from the role of the momentum variables .
the projection of p in the diagonal direction will change only slowly , since the gradient in that direction is small , and hence the direction of diagonal motion stays the same for many leapfrog steps .
while this large - scale diagonal motion is happening , smaller - scale oscillations occur , moving back and forth across the valley created by the high correlation between the variables .
the need to keep these smaller oscillations under control limits the stepsize that can be used .
as can be seen in the rightmost plot in figure 123 , there are also oscillations in the value of the hamiltonian ( which would be constant if the trajectory were simulated exactly ) .
if a larger stepsize were used , these oscillations would be larger .
at a critical stepsize ( = 123 in this example ) , the trajectory becomes unstable , and the value of the hamiltonian grows without bound .
as long as the stepsize is less than this , however , the error in the hamiltonian stays bounded regardless of the number of leapfrog steps done .
this lack of growth in the error is not guaranteed for all hamiltonians , but it does hold for many distributions more complex than gaussians .
as can be seen , however , the error in the hamiltonian along the trajectory does tend to be positive more often than negative .
in this example , the error is +123 at the end of the trajectory , so if this trajectory were used for an hmc proposal , the probability of accepting the end - point as the next state would be exp ( 123 ) = 123 .
sampling from a two - dimensional distribution .
figures 123 and 123 show the results of using hmc and a simple random - walk metropolis method to sample from a bivariate gaussian similar to the one just discussed , but with stronger correlation of 123 .
in this example , as in the previous one , hmc used a kinetic energy ( dening the momen - tum distribution ) of k ( p ) = pt p / 123
the results of 123 hmc iterations , using trajectories of
mcmc from hamiltonian dynamics
hamiltonian monte carlo
figure 123 : twenty iterations of the random - walk metropolis method ( with 123 updates per iteration ) and of the hamiltonian monte carlo method ( with 123 leapfrog steps per trajectory ) for a 123d gaussian distribution with marginal standard deviations of one and correlation 123 .
only the two position coordinates are plotted , with ellipses drawn one standard deviation away from the mean .
hamiltonian monte carlo
figure 123 : two hundred iterations , starting with the twenty iterations shown above , with only the rst position coordinate plotted .
mcmc using hamiltonian dynamics
l = 123 leapfrog steps with stepsize = 123 are shown in the right plot of figure 123
these values were chosen so that the trajectory length , l , is sucient to move to a distant point in the distribution , without being so large that the trajectory will often waste computation time by doubling back on itself .
the rejection rate for these trajectories was 123 .
figure 123 also shows every 123th state from 123 iterations of random - walk metropolis , with a bivariate gaussian proposal distribution with the current state as mean , zero correlation , and the same standard deviation for the two coordinates .
the standard deviation of the proposals for this example was 123 , which is the same as the stepsize used for hmc proposals , so that the change in state in these random - walk proposals was comparable to that for a single leapfrog step for hmc .
the rejection rate for these random - walk proposals was 123 .
one can see in figure 123 how the systematic motion during an hmc trajectory ( illustrated in figure 123 ) produces larger changes in state than a corresponding number of random - walk metropolis iterations .
figure 123 illustrates this dierence for longer runs of 123 123 random - walk metropolis iterations and of 123 hmc iterations .
the benet of avoiding random walks .
avoidance of random - walk behaviour , as il - lustrated above , is one major benet of hamiltonian monte carlo .
in this example , because of the high correlation between the two position variables , keeping the acceptance proba - bility for random - walk metropolis reasonably high requires that the changes proposed have a magnitude comparable to the standard deviation in the most constrained direction ( 123 in this example , the square root of the smallest eigenvalue of the covariance matrix ) .
the changes produced using one gibbs sampling scan would be of similar magnitude .
the num - ber of iterations needed to reach a state almost independent of the current state is mostly determined by how long it takes to explore the less constrained direction , which for this example has standard deviation 123 about ten times greater than the standard deviation in the most constrained direction .
we might therefore expect that we would need around ten iterations of random - walk metropolis in which the proposal was accepted to move to a nearly independent state .
but the number needed is actually roughly the square of this around 123 iterations with accepted proposals because the random - walk metropolis proposals have no tendency to move consistently in the same direction .
to see this , note that the variance of the position after n iterations of random walk metropolis from some start state will grow in proportion to n ( until this variance becomes comparable to the overall variance of the state ) , since the position is the sum of mostly independent movements for each iteration .
the standard deviation of the amount moved ( which gives the typical amount of movement ) is therefore proportional to n .
the stepsize used for the leapfrog steps is similarly limited by the most constrained direction , but the movement will be in the same direction for many steps .
the distance moved after n steps will therefore tend to be proportional to n , until the distance moved becomes comparable to the overall width of the distribution .
the advantage compared to movement by a random walk will be a factor roughly equal to the ratio of the standard deviations in the least conned direction and most conned direction about 123 here .
because avoiding a random walk is so benecial , the optimal standard deviation for random - walk metropolis proposals in this example is actually much larger than the value of 123 used here .
a proposal standard deviation of 123 gives a very low acceptance rate ( 123 ) , but this is more than compensated for by the large movement ( to a nearly independent point ) on the rare occasions when a proposal is accepted , producing a method that is about as ecient as hmc .
however , this strategy of making large changes with a small acceptance
mcmc from hamiltonian dynamics
hamiltonian monte carlo
figure 123 : values for the variable with largest standard deviation for the 123 - dimensional example , from a random - walk metropolis run and an hmc run with l = 123
to match computation time , 123 updates were counted as one iteration for random - walk metropolis .
rate works only when , as here , the distribution is tightly constrained in only one direction .
sampling from a 123 - dimensional distribution .
more typical behaviour of hmc and random - walk metropolis is illustrated by a 123 - dimensional multivariate gaussian distribu - tion in which the variables are independent , with means of zero , and standard deviations of 123 , 123 , .
, 123 , 123 .
suppose we have no knowledge of the details of this distribution , so we will use hmc with the same simple , rotationally symmetric kinetic energy function as above , k ( p ) = pt p / 123 , and use random - walk metropolis proposals in which changes to each variable are independent , all with the same standard deviation .
as discussed below in sec - tion 123 , the performance of both these sampling methods is invariant to rotation , so this ex - ample is illustrative of how they perform on any multivariate gaussian distribution in which the square roots of the eigenvalues of the covariance matrix are 123 , 123 , .
, 123 , 123 .
for this problem , the position coordinates , qi , and corresponding momentum coordinates , pi , are all independent , so the leapfrog steps used to simulate a trajectory operate indepen - dently for each ( qi , pi ) pair .
however , whether the trajectory is accepted depends on the total error in the hamiltonian due to the leapfrog discretization , which is a sum of the errors due to each ( qi , pi ) pair ( for the terms in the hamiltonian involving this pair ) .
keeping this error small requires limiting the leapfrog stepsize to a value roughly equal to the smallest of the standard deviations ( 123 ) , which implies that many leapfrog steps will be needed to move a distance comparable to the largest of the standard deviations ( 123 ) .
consistent with this , i applied hmc to this distribution using trajectories with l = 123 and with randomly selected for each iteration , uniformly from ( 123 , 123 ) , which is 123 123% .
i used random - walk metropolis with proposal standard deviation drawn uniformly from ( 123 , 123 ) , which is 123 123% .
these are close to optimal settings for both methods .
the rejection rate was 123 for hmc and 123 for random - walk metropolis .
figure 123 shows results from runs of 123 iterations of hmc ( right ) and of random - walk
mcmc using hamiltonian dynamics
hamiltonian monte carlo
standard deviation of coordinate
standard deviation of coordinate
standard deviation of coordinate
standard deviation of coordinate
figure 123 : estimates of means ( top ) and standard deviations ( bottom ) for the 123 - dimensional example , using random - walk metropolis ( left ) and hmc ( right ) .
the 123 variables are labelled on the horizontal axes by the true standard deviaton of that variable .
estimates are on the vertical axes .
hmc in practice and theory
metropolis ( left ) , counting 123 random - walk metropolis updates as one iteration , so that the computation time per iteration is comparable to that for hmc .
the plot shows the last variable , with the largest standard deviation .
the autocorrelation of these values is clearly much higher for random - walk metropolis than for hmc .
figure 123 shows the estimates for the mean and standard deviation of each of the 123 variables obtained using the hmc and random - walk metropolis runs ( estimates were just the sample means and sample standard deviations of the values from the 123 iterations ) .
except for the rst few variables ( with smallest standard deviations ) , the error in the mean estimates from hmc is roughly 123 times less than the error in the mean estimates from random - walk metropolis .
the standard deviation estimates from hmc are also better .
the randomization of the leapfrog stepsize done in this example follows the advice dis - cussed at the end of section 123 .
in this example , not randomizing the stepsize ( xing = 123 ) does in fact cause problems the variables with standard deviations near 123 or 123 change only slowly , since 123 leapfrog steps with = 123 produces nearly a full or half cycle for these variables , so an accepted trajectory does not make much of a change in the absolute value of the variable .
123 hmc in practice and theory
obtaining the benets from hmc illustrated in the previous section , including random - walk avoidance , requires proper tuning of l and .
i discuss tuning of hmc below , and also show how performance can be improved by using whatever knowledge is available regarding the scales of variables and their correlations .
after briey discussing what to do when hmc alone is not enough , i discuss an additional benet of hmc its better scaling with dimensionality than simple metropolis methods .
123 eect of linear transformations
like all mcmc methods im aware of , the performance of hmc may change if the variables being sampled are transformed by multiplication by some non - singular matrix , a .
however , performance stays the same ( except perhaps in terms of computation time per iteration ) if at the same time the corresponding momentum variables are multiplied by ( at ) 123
these facts provide insight into the operation of hmc , and can help us improve performance when we have some knowledge of the scales and correlations of the variables .
let the new variables be q = aq .
the probability density for q will be given by p ( q ) = p ( a123q ) / |det ( a ) | , where p ( q ) is the density for q .
if the distribution for q is the canonical distribution for a potential energy function u ( q ) ( see section 123 ) , we can obtain the distribution for q as the canonical distribution for u ( q ) = u ( a123q ) .
( since |det ( a ) | is a constant , we neednt include a log |det ( a ) | term in the potential energy . )
we can choose whatever distribution we wish for the corresponding momentum variables , so we could decide to use the same kinetic energy as before .
alternatively , we can choose to transform the momentum variables by p = ( at ) 123p , and use a new kinetic energy of k ( p ) = k ( at p ) .
if we were using a quadratic kinetic energy , k ( p ) = pt m 123p / 123 ( see equation ( 123 ) ) , the new kinetic energy will be
k ( p ) = ( at p ) t m 123 ( at p ) / 123 = ( p ) t ( a m 123at ) p / 123 = ( p ) t ( m ) 123p / 123 ( 123 )
mcmc using hamiltonian dynamics
where m = ( a m 123at ) 123 = ( a123 ) t ma123
if we use momentum variables transformed in this way , the dynamics for the new variables , ( q , p ) , essentially replicates the original dynamics for ( q , p ) , so the performance of hmc will be the same .
to see this , note that if we follow hamiltonian dynamics for ( q , p ) , the result in terms of the original variables will be as follows ( see equations ( 123 ) and ( 123 ) ) :
= a123 dq = at dp
= a123 ( m ) 123 p = a123 ( a m 123at ) ( at ) 123 p = m 123 p
= at u ( q ) = at ( a123 ) t u ( a123q ) = u ( q )
which matches what would happen following hamiltonian dynamics for ( q , p ) .
if a is an orthogonal matrix ( such as a rotation matrix ) , for which a123 = at , the performance of hmc is unchanged if we transform both q and p by multiplying by a ( since ( at ) 123 = a ) .
if we chose a rotationally symmetric distribution for the momentum , with m = mi ( ie , the momentum variables are independent , each having variance m ) , such an orthogonal transformation will not change the kinetic energy function ( and hence not change the distribution of the momentum variables ) , since we will have m = ( a ( mi ) 123at ) 123 = mi .
such an invariance to rotation holds also for a random - walk metropolis method in which the proposal distribution is rotationally symmetric ( eg , gaussian with covariance matrix mi ) .
in contrast , gibbs sampling is not rotationally invariant , nor is a scheme in which the metropolis algorithm is used to update each variable in turn ( with a proposal that changes only that variable ) .
however , gibbs sampling is invariant to rescaling of the variables ( trans - formation by a diagonal matrix ) , which is not true for hmc or random - walk metropolis , unless the kinetic energy or proposal distribution is transformed in a corresponding way .
suppose we have an estimate , , of the covariance matrix for q , and suppose also that q has at least a roughly gaussian distribution .
how can we use this information to improve the performance of hmc ? one way is to transform the variables so that their covariance matrix is close to the identity , by nding the cholesky decomposition , = llt , with l being lower - triangular , and letting q = l123q .
we then let our kinetic energy function be k ( p ) = pt p / 123
since the momentum variables are independent , and the position variables are close to independent with variances close to one ( if our estimate , and assumption that q is close to gaussian are good ) , hmc should perform well using trajectories with a small number of leapfrog steps , which will move all variables to a nearly independent point .
more realistically , the estimate may not be very good , but this transformation could still improve performance compared to using the same kinetic energy with the original q variables .
an equivalent way to make use of the estimated covariance is to keep the original q variables , but use the kinetic energy function k ( p ) = pt p / 123 ie , we let the momentum variables have covariance 123
the equivalence can be seen by transforming this kinetic energy to correspond to a transformation to q = l123q ( see equation ( 123 ) ) , which gives k ( p ) = ( p ) t m 123p with m = ( l123 ( llt ) ( l123 ) t ) 123 = i .
using such a kinetic energy function to compensate for correlations between position variables has a long history in molecular dynamics ( bennett , 123 ) .
the usefulness of this technique is limited by the computational cost of matrix operations when the dimensionality
hmc in practice and theory
using a diagonal can be feasible even in high - dimensional problems .
of course , this provides information only about the dierent scales of the variables , not their correlation .
moreover , when the actual correlations are non - zero , it is not clear what scales to use .
making an optimal choice is probably infeasible .
some approximation to the conditional standard deviation of each variable given all the others may be possible as i have done for bayesian neural network models ( neal , 123a ) .
if this also is not feasible , using approximations to the marginal standard deviations of the variables may be better than using the same scale for them all .
123 tuning hmc
one practical impediment to the use of hamiltonian monte carlo is the need to select suitable values for the leapfrog stepsize , , and the number of leapfrog steps , l , which together determine the length of the trajectory in ctitious time , l .
most mcmc methods have parameters that need to be tuned , with the notable exception of gibbs sampling when the conditional distributions are amenable to direct sampling .
however , tuning hmc is more dicult in some respects than tuning a simple metropolis method .
preliminary runs and trace plots .
tuning hmc will usually require preliminary runs with trial values for and l .
in judging how well these runs work , trace plots of quantities that are thought to be indicative of overall convergence should be examined .
for bayesian inference problems , high - level hyperparameters are often among the slowest - moving quanti - ties .
the value of the potential energy function , u ( q ) , is also usually of central signicance .
the autocorrelation for such quantities indicates how well the markov chain is exploring the state space .
ideally , we would like the state after one hmc iteration to be nearly independent of the previous state .
unfortunately , preliminary runs can be misleading , if they are not long enough to have reached equilibrium .
it is possible that the best choices of and l for reaching equilibrium are dierent from the best choices once equilibrium is reached , and even at equilibrium , it is possible that the best choices vary from one place to another .
if necessary , at each iteration of hmc , and l can be chosen randomly from a selection of values that are appropriate for dierent parts of the state space ( or these selections and can be used sequentially ) .
doing several runs with dierent random starting states is advisable ( for both preliminary and nal runs ) , so that problems with isolated modes can be detected .
note that hmc is no less ( or more ) vulnerable to problems with isolated modes than other mcmc methods that make local changes to the state .
if isolated modes are found to exist , something needs to be done to solve this problem just combining runs that are each conned to a single mode is not valid .
a modication of hmc with tempering along a trajectory ( section 123 ) can sometimes help with multiple modes .
what stepsize ? selecting a suitable leapfrog stepsize , , is crucial .
too large a stepsize will result in a very low acceptance rate for states proposed by simulating trajectories .
too small a stepsize will either waste computation time , by the same factor as the stepsize is too small , or ( worse ) will lead to slow exploration by a random walk , if the trajectory length , l , is then too short ( ie , l is not large enough , see below ) .
fortunately , as illustrated in figure 123 , the choice of stepsize is almost independent of how many leapfrog steps are done .
the error in the value of the hamiltonian ( which will determine the rejection rate ) usually does not increase with the number of leapfrog steps ,
mcmc using hamiltonian dynamics
provided that the stepsize is small enough that the dynamics is stable .
the issue of stability can be seen in a simple one - dimensional problem in which the
following hamiltonian is used :
h ( q , p ) = q123 / 123 + p123 / 123
the distribution for q that this denes is gaussian with standard deviation .
a leapfrog step for this system ( as for any quadratic hamiltonian ) will be a linear mapping from ( q ( t ) , p ( t ) ) to ( q ( t + ) , p ( t + ) ) .
referring to equations ( 123 ) to ( 123 ) , we see that this mapping can be represented by a matrix multiplication as follows :
( cid : 123 ) q ( t + ) p ( t + ) ( cid : 123 ) = ( cid : 123 )
/ 123 + 123 / 123
123 123 / 123 ( cid : 123 ) ( cid : 123 ) q ( t )
whether iterating this mapping leads to a stable trajectory , or one that diverges to innity , depends on the magnitudes of the eigenvalues of the above matrix , which are
( 123 123 / 123 ) ( / ) p123 / 123 123
when / > 123 , these eigenvalues are real , and at least one will have absolute value greater than one .
trajectories computed using the leapfrog method with this will therefore be unstable .
when / < 123 , the eigenvalues are complex , and both have squared magnitude of
trajectories computed with < 123 are therefore stable .
( 123 123 / 123 ) 123 + ( 123 / 123 ) ( 123 123 / 123 ) = 123
for multi - dimensional problems in which the kinetic energy used is k ( p ) = pt p / 123 ( as in the example above ) , the stability limit for will be determined ( roughly ) by the width of the distribution in the most constrained direction for a gaussian distribution , this would the square root of the smallest eigenvalue of the covariance matrix for q .
stability for more general quadratic hamiltonians with k ( p ) = pt m 123p / 123 can be determined by applying a linear transformation that makes k ( p ) = ( p ) t p / 123 , as discussed above in section 123 .
when a stepsize , , that produces unstable trajectories is used , the value of h grows exponentially with l , and consequently the acceptance probability will be extremely small .
for low - dimensional problems , using a value for that is just a bit below the stability limit is sucient to produce a good acceptance rate .
for high - dimensional problems , however , the stepsize may need to be reduced further than this to keep the error in h to a level that produces a good acceptance probability .
this is discussed further in section 123 .
choosing too large a value of can have very bad eects on the performance of hmc .
in this respect , hmc is more sensitive to tuning than random - walk metropolis .
a standard deviation for proposals needs to be chosen for random - walk metropolis , but performance degrades smoothly as this choice is made too large , without the sharp degradation seen with hmc when exceeds the stability limit .
( however , in high - dimensional problems , the degradation in random - walk metropolis with too large a proposal standard deviation can also be quite sharp , so this distinction becomes less clear . )
this sharp degradation in performance of hmc when the stepsize is too big would not be a serious issue if the stability limit were constant the problem would be obvious from preliminary runs , and so could be xed .
the real danger is that the stability limit may dier
hmc in practice and theory
for several regions of the state space that all have substantial probability .
if the preliminary runs are started in a region where the stability limit is large , a choice of a bit less than this limit might appear to be appropriate .
however , if this is above the stability limit for some other region , the runs may never visit this region , even though it has substantial probability , producing a drastically wrong result .
to see why this could happen , note that if the run ever does visit the region where the chosen would produce instability , it will stay there for a very long time , since the acceptance probability with that will be very small .
since the method nevertheless leaves the correct distribution invariant , it follows that the run only rarely moves to this region from a region where the chosen leads to stable trajectories .
one simple context where this problem can arise is when sampling from a distribution with very light tails ( lighter than a gaussian distribution ) , for which the log of the density will fall faster than quadratically .
in the tails , the gradient of the log density will be large , and a small stepsize will be needed for stability .
see roberts and tweedie ( 123 ) for a discussion of this in the context of the langevin method ( see section 123 ) .
this problem can be alleviated by choosing randomly from some distribution .
even if the mean of this distribution is too large , suitably small values for may be chosen occasionally .
( see section 123 for another reason to randomly vary the stepsize . ) the random choice of should be done once at the start of a trajectory , not for every leapfrog step , since even if all the choices are below the stability limit , random changes at each step lead to a random - walk in the error for h , rather than the bounded error that is illustrated in figure 123
the short - cut procedures described in section 123 can be seen as ways of saving com -
putation time when a randomly chosen stepsize in inappropriate .
what trajectory length ? choosing a suitable trajectory length is crucial if hmc is to explore the state space systematically , rather than by a random walk .
many distributions are dicult to sample from because they are tightly constrained in some directions , but much less constrained in other directions .
exploring the less constrained directions is best done using trajectories that are long enough to reach a point that is far from the current point in that direction .
trajectories can be too long , however , as is illustrated in figure 123
the trajectory shown on the left of that gure is a bit too long , since it reverses direction and then ends at a point that might have been reached with a trajectory about half its length .
if the trajectory were a bit longer , the result could be even worse , since the trajectory would not only take longer to compute , but might also end near its starting point .
for more complex problems , one cannot expect to select a suitable trajectory length by looking at plots like figure 123
finding the linear combination of variables that is least conned will be dicult , and will be impossible when , as is typical , the least conned direction is actually a non - linear curve or surface .
setting the trajectory length by trial and error therefore seems necessary .
for a problem thought to be fairly dicult , a trajectory with l = 123 might be a suitable starting point .
if preliminary runs ( with a suitable , see above ) shows that hmc reaches a nearly independent point after only one iteration , a smaller value of l might be tried next .
preliminary runs are actually sucient , in which case there is of course no need to do more runs . ) if instead there is high autocorrelation in the run with l = 123 , runs with l = 123 might be tried next .
as discussed at the ends of sections 123 and 123 , randomly varying the length of the trajectory ( over a fairly small interval ) may be desirable , to avoid choosing a trajectory length that happens to produce a near - periodicity for some variable or combination of variables .
mcmc using hamiltonian dynamics
using multiple stepsizes .
using the results in section 123 , we can exploit information about the relative scales of variables to improve the performance of hmc .
this can be done in two equivalent ways .
if si is a suitable scale for qi , we could transform q , by setting i = qi / si , or we could instead use a kinetic energy function of k ( p ) = pt m 123p with m being a diagonal matrix with diagonal elements mi = 123 / s123
a third equivalent way to exploit this information , which is often the most convenient , is to use dierent stepsizes for dierent pairs of position and momentum variables .
to see how this works , consider a leapfrog update ( following equations 123 to 123 ) with mi = 123 / s123
pi ( t + / 123 ) = pi ( t ) ( / 123 ) qi ( t + ) = qi ( t ) + s123
i pi ( t + / 123 )
pi ( t + ) = pi ( t + / 123 ) ( / 123 )
( q ( t + ) )
dene ( q ( 123 ) , p ( 123 ) ) to be the state at the beginning of the leapfrog step ( ie , ( q ( t ) , p ( t ) ) ) , dene ( q ( 123 ) , p ( 123 ) ) to be the nal state ( ie , ( q ( t + ) , p ( t + ) ) ) , and dene p ( 123 / 123 ) to be half - way momentum ( ie , p ( t + / 123 ) ) .
we can now rewrite the leapfrog step above as
i + s123
if we now dene rescaled momentum variables , pi = sipi , and stepsizes i = si , we can write the leapfrog update as
i + i p ( 123 / 123 )
this is just like a leapfrog update with all mi = 123 , but with dierent stepsizes for dierent ( qi , pi ) pairs .
of course , the successive values for ( q , p ) can no longer be interpreted as following hamiltonian dynamics at consistent time points , but that is of no consequence for the use of these trajectories in hmc .
note that when we sample for the momentum before each trajectory , each pi is drawn independently from a gaussian distribution with mean zero and variance one , regardless of the value of si .
this multiple stepsize approach is often more convenient , especially when the estimated scales , si , are not xed , as discussed in section 123 , and the momentum is only partially refreshed ( section 123 ) .
hmc in practice and theory
123 combining hmc with other mcmc updates
for some problems , mcmc using hamiltonian monte carlo alone will be impossible or undesirable .
two situations where non - hmc updates will be necessary are when some of the variables are discrete , and when the derivatives of the log probability density with respect to some of the variables are expensive or impossible to compute .
hmc can then be feasibly applied only to the other variables .
another example is when special mcmc updates have been devised that may help convergence in ways that hmc does not eg , by moving between otherwise isolated modes but which are not a complete replacement for hmc .
as discussed in section 123 below , bayesian hierarchical models may also be best handled with a combination of hmc and other methods such as gibbs sampling .
in such circumstances , one or more hmc updates for all or a subset of the variables can be alternated with one or more other updates that leave the desired joint distribution of all variables invariant .
the hmc updates can be viewed as either leaving this same joint distribution invariant , or as leaving invariant the conditional distribution of the variables that hmc changes , given the current values of the variables that are xed during the hmc update .
these are equivalent views , since the joint density can be factored as this conditional density times the marginal density of the variables that are xed , which is just a constant from the point of view of a single hmc update , and hence can be left out of the potential
when both hmc and other updates are used , it may be best to use shorter trajectories for hmc than would be used if only hmc were being done .
this allows the other updates to be done more often , which presumably helps sampling .
finding the optimal tradeo is likely to be dicult , however .
a variation on hmc that reduces the need for such a tradeo is described below in section 123 .
123 scaling with dimensionality
in section 123 , one of the main benets of hmc was illustrated its ability to avoid the inecient exploration of the state space via a random walk .
this benet is present ( in at least some degree ) for most practical problems .
for problems in which the dimensionality is moderate to high , another benet of hmc over simple random - walk metropolis methods is a slower increase in the computation time needed ( for a given level of accuracy ) as the dimensionality increases .
( note that here i will consider only sampling performance after equilibrium is reached , not the time needed to approach equilibrium from some initial state not typical of the distribution , which is harder to analyse . )
creating distributions of increasing dimensionality by replication .
to talk about how performance scales with dimensionality we need to assume something about how the distribution changes with dimensionality , d .
i will assume that dimensionality increases by adding independent replicas of variables ie , the potential energy function for q = ( q123 , .
, qd ) has the form u ( q ) = ui ( qi ) , for functions ui drawn independently from some distribution .
of course , this is not what any real practical problem is like , but it may be a reasonable model of the eect of increasing dimensionality for some problems for instance , in statistical physics , distant regions of large systems are often nearly independent .
note that the independence assumption itself is not crucial , since as discussed in section 123 , the performance of hmc ( and of simple random - walk metropolis ) does not change if independence is removed by rotating the coor -
mcmc using hamiltonian dynamics
dinate system , provided the kinetic energy function ( or random - walk proposal distribution ) is rotationally symmetric .
for distributions of this form , in which the variables are independent , gibbs sampling will perform very well ( assuming it is feasible ) , producing an independent point after each scan of all variables .
applying metropolis updates to each variable separately will also work well , provided the time for a single - variable update does not grow with d .
however , these methods are not invariant to rotation , so this good performance may not generalize to the more interesting distributions for which we hope to obtain insight with the analysis below .
scaling of hmc and random - walk metropolis .
here , i discuss informally how well hmc and random - walk metropolis scale with dimension , loosely following creutz ( 123 ,
to begin , cruetz notes that the following relationship holds when any metropolis - style
algorithm is used to sample a density p ( x ) = ( 123 / z ) exp ( e ( x ) ) :
123 = e ( p ( x ) / p ( x ) ) = e ( exp ( ( e ( x ) e ( x ) ) ) ) = e ( exp ( ) )
where x is the current state , assumed to be distributed according to p ( x ) , x is the proposed state , and = e ( x ) e ( x ) .
jensens inequality then implies that the expectation of the energy dierence is non - negative :
the inequality will usually be strict .
e ( ) 123
when u ( q ) = ui ( qi ) , and proposals are produced independently for each i , we can apply these relationships either to a single variable ( or pair of variables ) or to the entire state .
for a single variable ( or pair ) , i will write 123 for e ( x ) e ( x ) , with x = qi and e ( x ) = ui ( qi ) , or x = ( qi , pi ) and e ( x ) = ui ( qi ) + p123 i / 123
for the entire state , i will write d for e ( x ) e ( x ) , with x = q and e ( x ) = u ( q ) , or x = ( q , p ) and e ( x ) = u ( q ) + k ( p ) ) .
for both random - walk metropolis and hmc , increasing dimension by replicating variables will lead to increasing energy dierences , since d is the sum of 123 for each variable , each of which has positive mean .
this will lead to a decrease in the acceptance probability equal to min ( 123 , exp ( d ) ) unless the width of the proposal distribution or the leapfrog stepsize is decreased to compensate .
more specically , for random - walk metropolis with proposals that change each variable independently , the dierence in potential energy between a proposed state and the current state will be the sum of independent dierences for each variable .
if we x the standard deviation , , for each proposed change , the mean and the variance of this potential energy dierence will both grow linearly with d , which will lead to a progressively lower accep - tance rate .
to maintain reasonable performance , will have to decrease as d increases .
furthermore , the number of iterations needed to reach a nearly independent point will be proportional to 123 , since exploration is via a random walk .
similarly , when hmc is used to sample from a distribution in which the components of q are independent , using the kinetic energy k ( p ) = p123 i / 123 , the dierent ( qi , pi ) pairs do not interact during the simulation of a trajectory each ( qi , pi ) pair follows hamiltonian dynamics according to just the one term in the potential energy involving qi and the one term in the kinetic energy involving pi .
there is therefore no need for the length in ctitious time of a trajectory to increase with dimensionality .
however , acceptance of the end - point of the
hmc in practice and theory
trajectory is based on the error in h due to the leapfrog approximation , which is the sum of the errors pertaining to each ( qi , pi ) pair .
for a xed stepsize , , and xed trajectory length , l , both the mean and the variance of the error in h grow linearly with d .
this will lead to a progressively lower acceptance rate as dimensionality increases , if it is not counteracted by a decrease in .
the number of leapfrog steps needed to reach an independent point will be proportional to 123
to see which method scales better , we need to determine how rapidly we must reduce and as d increases , in order to maintain a reasonable acceptance rate .
as d increases and or go to zero , 123 will go to zero as well .
using a second - order approximation of exp ( 123 ) as 123 123 + 123
123 / 123 , together with equation ( 123 ) , we nd that
e ( 123 ) e ( 123
123 ) / 123
it follows from this that the variance of 123 is twice the mean of 123 ( when 123 is small ) , which implies that the variance of d is twice the mean of d ( even when d is not small ) .
to achieve a good acceptance rate , we must therefore keep the mean of d near one , since a large mean will not be saved by a similarly large standard deviation ( which would produce fairly frequent acceptances as d occasionally takes on a negative value ) .
for random - walk metropolis with a symmetric proposal distribution , we can see how needs to scale by directly averaging 123 for a proposal and its inverse .
let the proposal for one variable be x = x + c , and suppose that c = a and c = a are equally likely .
approximating u ( x ) to second order as u ( x ) + cu ( x ) + c123u ( x ) / 123 , we nd that the average of 123 = u ( x ) u ( x ) over c = a and c = a is a123u ( x ) .
averaging this over the distribution of a , with standard deviation , and over the distribution of x , we see that e ( 123 ) is proportional to 123
it follows that e ( d ) is proportional to d 123 , so we can maintain a reasonable acceptance rate by letting be proportional to d123 / 123
the number of iterations needed to reach a nearly independent point will be proportional to 123 , which will be proportional to d .
the amount of computation time needed will typically be proportional
as discussed at the end of section 123 , the error in h when using the leapfrog discretization to simulate a trajectory of a xed length is proportional to 123 ( for suciently small ) .
the error in h for a single ( qi , pi ) pair is the same as 123 , so we see that 123 123 is proportional to 123
equation 123 then implies that e ( 123 ) is also proportional to 123
the average total error in h for all variables , e ( d ) , will be proportional to d123 , and hence we must make be proportional to d123 / 123 to maintain a reasonable acceptance rate .
the number of leapfrog updates to reach a nearly independent point will therefore grow as d123 / 123 , and the amount of computation time will typically grow as d123 / 123 , which is much better than the d123 growth for
optimal acceptance rates .
by extending the analysis above , we can determine what the acceptance rate of proposals is when the optimal choice of or is used .
this is helpful when tuning the algorithms provided , of course , that the distribution sampled is high - dimensional , and has properties that are adequately modeled by a distribution with
to nd this acceptance rate , we rst note that since metropolis methods satisfy detailed balance , the probability of an accepted proposal with d negative must be equal to the probability of an accepted proposal with d positive .
since all proposals with negative
mcmc using hamiltonian dynamics
d are accepted , the acceptance rate is simply twice the probability that a proposal has a negative d .
for large d , the central limit theorem implies that the distribution of d is gaussian , since it is a sum of d independent 123 values .
( this assumes that the variance of each 123 is nite . ) we saw above that the variance of d is twice its mean , e ( d ) = .
the acceptance probability can therefore be written as follows ( gupta et al . , 123 ) , for large d :
p ( accept ) = 123 ( cid : 123 ) ( 123 ) ( cid : 123 ) p123 ( cid : 123 ) = 123 ( cid : 123 ) p / 123 ( cid : 123 ) = a ( )
where ( z ) is the cumulative distribution function for a gaussian variable with mean zero and variance one .
for random - walk metropolis , the cost to obtain an independent point will be proportional to 123 / ( a 123 ) , where a is the acceptance rate .
we saw above that = e ( d ) is proportional to 123 , so the cost follows the proportionality
numerical calculation shows that this is minimized when = 123 and a ( ) = 123 .
crw 123 / ( a ( ) )
for hmc , the cost to obtain an independent point will be proportional to 123 / ( a ) , and as
we saw above , is proportional to 123
from this we obtain chmc 123 / ( a ( ) 123 / 123 )
numerical calculation shows that the minimum is when = 123 and a ( ) = 123 .
the same optimal 123% acceptance rate for random - walk metropolis was previously ob - tained using a more formal analysis by roberts et al .
( 123 ) .
the optimal 123% acceptance rate for hmc that i derive above is consistent with previous empirical results on distribu - tions following the model here ( neal , 123 , figure 123 ) , and on real high - dimensional problems ( creutz , 123 , figures 123 and 123; sexton and weingarten , 123 , table 123 ) .
kennedy and pendleton ( 123 ) obtained explicit and rigorous results for hmc applied to multivariate gaussian dis -
exploring the distribution of potential energy .
the better scaling behaviour of hmc seen above depends crucially on the resampling of momentum variables .
we can see this by considering how well the methods explore the distribution of the potential energy , u ( q ) = ui ( qi ) .
because u ( q ) is a sum of d independent terms , its standard deviation will grow in proportion to d123 / 123
following caracciolo et al .
( 123 ) , we note that the expected change in potential energy from a single metropolis update will be no more than order one intuitively , large upwards changes are unlikely to be accepted , and since metropolis updates satisfy detailed balance , large downward changes must also be rare ( in equilibrium ) .
because changes in u will follow a random walk ( due again to detailed balance ) , it will take at least order ( d123 / 123 / 123 ) 123 = d metropolis updates to explore the distribution of u .
in the rst step of an hmc iteration , the resampling of momentum variables will typically change the kinetic energy by an amount that is proportional to d123 / 123 , since the kinetic energy is also a sum of d independent terms , and hence has standard deviation that grows as d123 / 123 ( more precisely , its standard deviation is d123 / 123 / 123 / 123 ) .
if the second step of hmc proposes a distant point , this change in kinetic energy ( and hence in h ) will tend , by the end of
hmc in practice and theory
the trajectory , to have become equally split between kinetic and potential energy .
end - point of this trajectory is accepted , the change in potential energy from a single hmc iteration will be proportional to d123 / 123 , comparable to its overall range of variation .
so , in contrast to random - walk metropolis , we may hope that only a few hmc iterations will be sucient to move to a nearly independent point , even for high - dimensional distributions .
analysing how well methods explore the distribution of u can also provide insight into their performance on distributions that arent well modeled by replication of variables , as we will see in the next section .
123 hmc for hierarchical models
many bayesian models are dened hierarchically .
a large set of low - level parameters have prior distributions that are determined by fewer higher - level hyperparameters , which in turn may have priors determined by yet - higher - level hyperparameters .
for example , in a regression model with many predictor variables , the regression coecients might be given gaussian prior distributions , with mean of zero and a variance that is a hyperparameter .
this hyperparameter could be given a broad prior distribution , so that its posterior distribution is determined mostly by the data .
one could apply hmc to these models in an obvious way ( after taking the logs of variance hyperparameters , so they will be unconstrained ) .
however , it may be better to apply hmc only to the lower - level parameters , for reasons i will now discuss .
( see section 123 for general discussion of applying hmc to a subset of variables . )
i will use my work on bayesian neural network models ( neal , 123a ) as an example .
such models typically have several groups of low - level parameters , each with an associated variance hyperparameter .
the posterior distribution of these hyperparameters reects im - portant aspects of the data , such as which predictor variables are most relevant to the task .
the eciency with which values for these hyperparameters are sampled from the posterior distribution can often determine the overall eciency of the mcmc method .
i use hmc only for the low - level parameters in bayesian neural network models , with the hyperparameters being xed during an hmc update .
these hmc updates alternate with gibbs sampling updates of the hyperparameters , which ( in the simpler versions of the models ) are independent given the low - level parameters , and have conditional distributions of standard form .
by using hmc only for the low - level parameters , the leapfrog stepsizes used can be set using heuristics that are based on the current hyperparameter values .
( i use the multiple stepsize approach described at the end of section 123 , equivalent to using dierent mass values , mi , for dierent parameters . ) for example , the size of the network weights on connections out of a hidden unit determine how sensitive the likelihood function is to changes in weights on connections into the hidden unit; the variance of the weights on these outgoing connections is therefore useful in setting the stepsize for the weights on the incoming connections .
if the hyperparameters were changed by the same hmc updates as change the lower - level parameters , using them to set stepsizes would not be valid , since a reversed trajectory would use dierent stepsizes , and hence not retrace the original trajectory .
without a good way to set stepsizes , hmc for the low - level parameters would likely be much
choo ( 123 ) bypassed this problem by using a modication of hmc in which trajecto - ries are simulated by alternating leapfrog steps that update only the hyperparameters with
mcmc using hamiltonian dynamics
leapfrog steps that update only the low - level parameters .
this procedure maintains both reversibility and volume - preservation ( though not necessarily symplecticness ) , while allowing the stepsizes for the low - level parameters to be set using the current values of the hyper - parameters ( and vice versa ) .
however , performance did not improve as hoped because of a second issue with hierarchical models .
in these bayesian neural network models , and many other hierarchical models , the joint distribution of both low - level parameters and hyperparameters is highly skewed , with the probability density varying hugely from one region of high posterior probability to another .
unless the hyperparameters controlling the variances of low - level parameters have very nar - row posterior distributions , the joint posterior density for hyperparameters and low - level parameters will vary greatly from when the variance is low to when it is high .
for instance , suppose that in its region of high posterior probability , a variance hyperpa - rameter varies by a factor of four .
if this hyperparameter controls 123 low - level parameters , their typical prior probability density will vary by a factor of 123 = 123 123 , corre - sponding to a potential energy range of log ( 123 ) = 123 , with a standard deviation of 123 / 123 / 123 = 123 ( since the variance of a uniform distribution is one twelfth of its range ) .
as discussed at the end of section 123 , one hmc iteration changes the energy only through the resampling of the momentum variables , which at best leads to a change in potential energy with standard deviation of about d123 / 123 / 123 / 123
for this example , with 123 low - level parameters , this is 123 , so about ( 123 / 123 ) 123 = 123 hmc iterations will be needed to reach an independent point .
one might obtain similar performance for this example using gibbs sampling .
however , for neural network models , there is no feasible way of using gibbs sampling for the posterior distribution of the low - level parameters , but hmc can be applied to the conditional distri - bution of the low - level parameters given the hyperparameters .
gibbs sampling can then be used to update the hyperparameters .
as we have seen , performance would not be improved by trying to update the hyperparameters with hmc as well , and updating them by gibbs sampling is easier .
choo ( 123 ) tried another approach that could potentially improve on this reparam - eterizing low - level parameters i , all with variance exp ( ) , by letting i = i exp ( / 123 ) , and then sampling for and the i using hmc .
the reparameterization eliminates the extreme variation in probability density that hmc cannot eciently sample .
however , he found that it is dicult to set a suitable stepsize for , and that the error in h tended to grow with trajectory length , unlike the typical situation when hmc is used only for the low - level parameters .
use of tempering techniques ( see section 123 ) is another possibility .
even though it does not eliminate all diculties , hmc is very useful for bayesian neural network models indeed , without it , they might not be feasible for most applications .
using hmc for at least the low - level parameter can produce similar benets for other hierarchical models ( eg , ishwaran , 123 ) , especially when the posterior correlations of these low - level parameters are high .
as in any application of hmc , however , careful tuning of the stepsize and trajectory length is generally necessary .
extensions and variations on hmc
123 extensions and variations on hmc
the basic hmc algorithm of figure 123 can be modied in many ways , either to improve its eciency , or to make it useful for a wider range of distributions .
in this section , i will start by discussing alternatives to the leapfrog discretization of hamiltons equations , and also show how hmc can handle distributions with constraints on the variables ( eg , variables that must be positive ) .
i will then discuss a special case of hmc when only one leapfrog step is done and show how it can be extended to produce an alternative method of avoiding random walks , which may be useful when not all variables are updated by hmc .
most applications of hmc can benet from using a variant in which windows of states are used to increase the acceptance probability .
another widely applicable technique is to use approximations to the hamiltonian to compute trajectories , while still obtaining correct results by using the exact hamiltonian when deciding whether to accept the endpoint of the trajectory .
tuning of hmc may be assisted by using a short - cut method that avoids computing the whole trajectory when the stepsize is inappropriate .
tempering methods have potential to help with distributions having multiple modes , or which are highly skewed .
there are many other variations that i will not be able to review here , such as the use of a shadow hamiltonian that is exactly conserved by the inexact simulation of the real hamil - tonian ( izagguirre and hampton , 123 ) , and the use of symplectic integration methods more sophisticated than the leapfrog method ( eg , creutz and gocksch , 123 ) , including a recent proposal by girolami et al .
( 123 ) of a symplectic integrator for a non - separable hamiltonian in which m in the kinetic energy of ( 123 ) depends on q , allowing for adaptation based on
123 discretization by splitting : handling constraints and other applications
the leapfrog method is not the only discretization of hamiltons equations that is reversible and volume - preserving , and hence can be used for hamiltonian monte carlo .
many sym - plectic integration methods have been devised , mostly for applications other than hmc ( eg , simulating the solar system for millions of years to test its stability ) .
it is possible to devise methods that have a higher order of accuracy than the leapfrog method ( for example , see mclachlan and atela , 123 ) .
using such a method for hmc will produce asymptotically better performance than the leapfrog method , as dimensionality increases .
experience has shown , however , that the leapfrog method is hard to beat in practice .
nevertheless , it is worth taking a more general look at how hamiltonian dynamics can be simulated , since this also points to how constraints on the variables can be handled , as well as possible improvements such as exploiting partial analytic solutions .
splitting the hamiltonian .
many symplectic discretizations of hamiltonian dynamics can be derived by splitting the hamiltonian into several terms , and then for each term in succession , simulating the dynamics dened by that term for some small time step , then repeating this procedure until the desired total simulation time is reached .
if the simulation for each term can be done analytically , we obtain a symplectic approximation to the dynamics that is feasible to implement .
this general scheme is described by leimkuhler and reich ( 123 , section 123 ) and by sexton and weingarten ( 123 ) .
suppose that the hamiltonian can be written as a sum of k terms , as follows :
h ( q , p ) = h123 ( q , p ) + h123 ( q , p ) + + hk123 ( q , p ) + hk ( q , p )
mcmc using hamiltonian dynamics
suppose also that we can exactly implement hamiltonian dynamics based on each hi , for i = 123 , .
, k , with ti , being the mapping dened by applying dynamics based on hi for time .
as shown by leimkuhler and reich , if the hi are twice dierentiable , the composition of these mappings , t123 , t123 , tk123 , tk , , is a valid discretization of hamiltonian dynamics based on h , which will reproduce the exact dynamics in the limit as goes to zero , with global error of order or less .
furthermore , this discretization will preserve volume , and will be symplectic , since these properties are satised by each of the ti , mappings .
the discretization will also be re - versible if the sequence of hi is symmetrical ie , hi ( q , p ) = hki+123 ( q , p ) .
as mentioned at the end of section 123 , any reversible method must have global error of even order in ( leimkuhler and reich , 123 , section 123 . 123 ) , which means the global error must be of order 123 or better .
we can derive the leapfrog method from a symmetrical splitting of the hamiltonian
h ( q , p ) = u ( q ) + k ( p ) , we can write the hamiltonian as
h ( q , p ) = u ( q ) / 123 + k ( p ) + u ( q ) / 123
which corresponds to a split with h123 ( q , p ) = h123 ( q , p ) = u ( q ) / 123 and h123 ( q , p ) = k ( p ) .
hamiltonian dynamics based on h123 is ( equations ( 123 ) and ( 123 ) ) :
applying this dynamics for time just adds ( / 123 ) u / qi to each pi , which is the rst part of a leapfrog step ( equation ( 123 ) ) .
the dynamics based on h123 is as follows :
if k ( p ) = ( 123 / 123 ) p p123
i / mi , applying this dynamics for time results in adding pi / mi to each qi , which is the second part of a leapfrog step ( equation ( 123 ) ) .
finally , h123 produces the third part of a leapfrog step ( equation ( 123 ) ) , which is the same as the rst part , since h123 = h123
splitting to exploit partial analytical solutions .
one situation where splitting can help is when the potential energy contains a term that can , on its own , be handled analyti - cally .
for example , the potential energy for a bayesian posterior distribution will be the sum of minus the log prior density for the parameters and minus the log likelihood .
if the prior is gaussian , the log prior density term will be quadratic , and can be handled analytically ( eg , see the one dimensional example at the end of section 123 ) .
we can modify the leapfrog method for this situation by using a modied split .
suppose u ( q ) = u123 ( q ) + u123 ( q ) , with u123 being analytically tractable , in conjunction with the kinetic energy , k ( p ) .
we use the split
h ( q , p ) = u123 ( q ) / 123 + ( cid : 123 ) u123 ( q ) + k ( p ) ( cid : 123 ) + u123 ( q ) / 123
extensions and variations on hmc
ie , h123 ( q , p ) = h123 ( q , p ) = u123 ( q ) / 123 and h123 ( q , p ) = u123 ( q ) + k ( p ) .
the rst and last half - steps for p are the same as for ordinary leapfrog , based on u123 alone .
the middle full step for q , which in ordinary leapfrog just adds p to q , is replaced by the analytical solution for following the exact dynamics based on the hamiltonian u123 ( q ) + k ( p ) for time .
with this procedure , it should be possible to use a larger stepsize ( and hence use fewer steps in a trajectory ) , since part of the potential energy has been separated out and handled exactly .
the benet of handling the prior exactly may be limited , however , since the prior is usually dominated by the likelihood .
splitting potential energies with variable computational costs .
splitting can also help if the potential energy function can be split into two terms , one of which requires less computation time to evaluate than the other ( sexton and weingarten , 123 ) .
suppose u ( q ) = u123 ( q ) + u123 ( q ) , with u123 being cheaper to compute than u123 , and let the kinetic energy be k ( p ) .
we can use the following split , for some m > 123 :
h ( q , p ) = u123 ( q ) / 123 +
xm=123hu123 ( q ) / 123m + k ( p ) / m + u123 ( q ) / 123mi + u123 ( q ) / 123
we label the k = 123m + 123 terms as h123 ( q , p ) = hk ( q , p ) = u123 ( q ) / 123 and for i = 123 , .
, m , h123i123 ( q , p ) = h123i+123 ( q , p ) = u123 ( q ) / 123m and h123i ( q , p ) = k ( p ) / m .
the resulting discretization can be seen as a nested leapfrog method .
the m inner leapfrog steps involve only u123 , and use an eective stepsize of / m .
the outer leapfrog step takes half steps for p using only u123 , and replaces the update for q in the middle with the m inner leapfrog steps .
if u123 is much cheaper to compute than u123 , we can use a large value for m without increasing computation time by much .
the stepsize , , that we can use will then be limited mostly by the properties of u123 , since the eective stepsize for u123 is much smaller , / m .
using a bigger than with the standard leapfrog method will usually be possible , and hence we will need fewer steps in a trajectory , with fewer computations of u123
splitting according to data subsets .
when sampling from the posterior distribution for a bayesian model of independent data points , it may be possible to save computation time by splitting the potential energy into terms for subsets of the data .
suppose we partition the data into subsets sm , for i = 123 , .
, m , typically of roughly equal size .
we can then write the log likelihood function as ( q ) = pm m=123 m ( q ) , where m is the log likelihood function based on the data points in sm .
if ( q ) is the prior density for the parameters , we can let um ( q ) = log ( ( q ) ) / m m ( q ) , and split the hamiltonian as
h ( q , p ) =
xm=123hum ( q ) / 123 + k ( p ) / m + um ( q ) / 123i
ie , we let the k = 123m terms be h123m123 ( q , p ) = h123m ( q , p ) = um ( q ) / 123 and h123m123 ( q , p ) = k ( p ) / m .
the resulting discretization with stepsize eectively performs m leapfrog steps with stepsize / m , with the mth step using mum as the potential energy function .
this scheme can be benecial if the data set is redundant , with many data points that are similar .
we then expect mum ( q ) to be approximately the same as u ( q ) , and we might hope that we could set to be m times larger than with the standard leapfrog method ,
mcmc using hamiltonian dynamics
obtaining similar results with m times less computation .
in practice , however , the error in h at the end of the trajectory will be larger than with standard leapfrog , so the gain will be less than this .
i found ( neal , 123a , sections 123 . 123 and 123 . 123 ) that the method can be benecial for neural network models , especially when combined with the windowed hmc procedure described below in section 123 .
note that unlike the other examples above , this split is not symmetrical , and hence the resulting discretization is not reversible .
however , it can still be used to produce a proposal for hmc as long as the labelling of the subsets is randomized for each iteration , so that the reverse trajectory has the same probability of being produced as the forward trajectory .
( it is possible , however , that some symmetrical variation on this split might produce better
handling constraints .
an argument based on splitting shows how to handle constraints on the variables being sampled .
here , i will consider only separate constraints on some subset of the variables , with the constraint on qi taking the form qi ui , or qi li , or both .
a similar scheme can handle constraints taking the form g ( q ) 123 , for any dierentiable
we can impose constraints on variables by letting the potential energy be innite for values of q that violate any of the constraints , which will give such points probability zero .
to see how to handle such innite potential energies , we can look at a limit of potential energy functions that approach innity , and the corresponding limit of the dynamics .
to illustrate , suppose that u ( q ) is the potential energy ignoring constraints , and that qi is constrained to be less than ui .
we can take the limit as r of the following potential energy function ( which is one of many that could be used ) : u ( q ) = u ( q ) + cr ( qi , ui ) , where cr ( qi , ui ) = ( cid : 123 ) 123 it is easy to see that limr cr ( qi , ui ) is zero for any qi ui and innity for any qi > ui .
for any nite r > 123 , u ( q ) is dierentiable , so we can use it to dene hamiltonian dynamics .
to simulate the dynamics based on this u ( q ) , with a kinetic energy k ( p ) = ( 123 / 123 ) p p123
we can use the split of equation ( 123 ) , with u123 ( q ) = u ( q ) and u123 ( q ) = cr ( qi , ui ) :
if qi ui if qi > ui
h ( q , p ) = u ( q ) / 123 + ( cid : 123 ) cr ( qi , ui ) + k ( p ) ( cid : 123 ) + u ( q ) / 123
but if q
i > ui .
if not , the value of cr ( qi , ui ) must be zero all along the path from qi to q
this produces a variation on the leapfrog method in which the half - steps for p ( equa - tions ( 123 ) and 123 ) remain the same , but the full step for q ( equation ( 123 ) ) is modied to account for the constraint on qi .
after computing q i = qi ( t ) + pi ( t + / 123 ) / mi , we check i , and we can set q ( t+ ) to q i > ui , the dynamics based on the hamiltonian cr ( qi , ui ) + k ( p ) will be aected by the cr term .
this term can be seen as a steep hill , which will be climbed as qi moves past ui , until the point is reached where cr is equal to the previous value of i / mi , at which point pi will be zero .
( if r is suciently large , as it will be in the limit as r , this point will be reached before the end of the full step . ) we will then fall down the hill , with pi taking on increasingly negative values , until we again reach qi = ui , when pi will be just the negative of the original value of pi .
we then continue , now moving in the opposite direction , away from the upper limit .
extensions and variations on hmc
for each variable , i = 123 ,
123 ) let p
123 ) let q
i = pi ( t + / 123 ) i = qi ( t ) + p
123 ) if qi is constrained , repeat the following until q
satisfies all constraints :
a ) if qi has an upper constraint , and q i = p b ) if qi has a lower constraint , and q i = p
i = li + ( li q
i ) and p
i = ui ( q
i ui ) and p
i > ui
i < li
123 ) let qi ( t + ) = q
i and pi ( t + / 123 ) = p
figure 123 : modication to the leapfrog update of q ( equation ( 123 ) ) to handle constraints of the form qi ui or qi li .
if several variables have constraints , we must follow this procedure for each , and if a variable has both upper and lower constraints , we must repeat the procedure until neither constraint is violated .
the end result is that the full step for q of equation ( 123 ) is replaced by the procedure shown in figure 123
intuitively , the trajectory just bounces o the walls given by the constraints .
if u ( q ) is constant , these bounces are the only interesting aspect of the dynamics , and the procedure is sometimes referred to as billiards ( see , for example ,
123 taking one step at a time the langevin method
a special case of hamiltonian monte carlo arises when the trajectory used to propose a new state consists of only a single leapfrog step .
suppose that we use the kinetic energy k ( p ) = i .
an iteration of hmc with one leapfrog step can be expressed in the following way .
we sample values for the momentum variables , p , from their gaussian distributions with mean zero and variance one , and then propose new values , q and p , as follows :
i = qi
i = pi
( q ) + pi
we accept q as the new state with probability
minh123 , exp ( cid : 123 ) ( u ( q ) u ( q ) )
and otherwise keep q as the new state .
i ) 123 p123
equation ( 123 ) is known in physics as one type of langevin equation , and this method is therefore known as langevin monte carlo ( lmc ) in the the lattice eld theory literature ( eg , kennedy , 123 ) .
mcmc using hamiltonian dynamics
one can also remove any explicit mention of momentum variables , and view this method as performing a metropolis - hastings update in which q is proposed from a gaussian distri - i are independent , with means of qi ( 123 / 123 ) ( u / qi ) ( q ) , and variances of bution where the q 123
since this proposal is not symmetrical , it must be accepted or rejected based on both the ratio of the probability densities of q and q and on the ratio of the probability densities for proposing q from q and vice versa ( hastings , 123 ) .
to see the equivalence with hmc using one leapfrog step , we can write the metropolis - hastings acceptance probability as follows :
exp ( cid : 123 ) ( cid : 123 ) qi q
i + ( 123 / 123 ) ( u / qi ) ( q ) ( cid : 123 ) 123 i qi + ( 123 / 123 ) ( u / qi ) ( q ) ( cid : 123 ) 123
to see that this is the same as ( 123 ) , note that using equations ( 123 ) and ( 123 ) , we can
i qi +
after substituting these into ( 123 ) , it is straightforward to see the equivalence to ( 123 ) .
in this metropolis - hastings form , the langevin monte carlo method was rst proposed by rossky , doll , and friedman ( 123 ) , for use in physical simulations .
approximate langevin methods without an accept / reject step can also be used ( for a discussion of this , see neal , 123 , section 123 ) as , for instance , in a paper on statistical inference for complex models by grenander and miller ( 123 ) , where also an accept / reject step is proposed in the discussion by j .
besag ( p
although lmc can be seen as a special case of hmc , its properties are quite dierent .
since lmc updates are reversible , and generally make only small changes to the state ( since typically cannot be very large ) , lmc will explore the distribution via an inecient random walk , just like random - walk metropolis updates .
however , lmc has better scaling behaviour than random - walk metropolis as dimension - ality increases , as can be seen from an analysis paralleling that in section 123 ( creutz , 123; kennedy , 123 ) .
the local error of the leapfrog step is of order 123 , so e ( 123 123 ) , the average squared error in h from one variable , will be of order 123
from equation ( 123 ) , e ( ) will also be of order 123 , and with d independent variables , e ( d ) will be of order d123 , so that must scale as d123 / 123 in order to maintain a reasonable acceptance rate .
since lmc explores the distribution via a random walk , the number of iterations needed to reach a nearly inde - pendent point will be proportional to 123 , which grows as d123 / 123 , and the computation time to reach a nearly independent point grows as d123 / 123
this is better than the d123 growth in computation time for random walk metropolis , but worse than the d123 / 123 growth when hmc is used with trajectories that are long enough to reach a nearly independent point .
we can also nd what the acceptance rate for lmc will be when the optimal is used , when sampling a distribution with independent variables replicated d times .
as for random walk metropolis and hmc , the acceptance rate is given in terms of = e ( d ) by equa - tion ( 123 ) .
the cost of obtaining a nearly independent point using lmc is proportional to
extensions and variations on hmc
123 / ( a ( ) 123 ) , and since is proportional to 123 , we can write the cost as
clmc 123 / ( a ( ) 123 / 123 )
numerical calculation shows that this is minimized when a ( ) is 123 a result obtained more formally by roberts and rosenthal ( 123 ) .
this may be useful for tuning , if the behaviour of lmc for the distribution being sampled resembles its behaviour when sampling for replicated
123 partial momentum refreshment another way to avoid random walks
the single leapfrog step used in the langevin monte carlo algorithm will usually not be sucient to move to a nearly independent point , so lmc will explore the distribution via an inecient random walk .
this is why hmc is typically used with trajectories of many leapfrog steps .
an alternative that can suppress random walk behaviour even when trajec - tories consist of just one leapfrog step is to only partially refresh the momentum between trajectories , as proposed by horowitz ( 123 ) .
suppose that the kinetic energy has the typical form k ( p ) = pt m 123p / 123
the following update for p will leave invariant the distribution for the momentum ( gaussian with mean zero and covariance m ) :
p = p + ( 123 123 ) 123 / 123n
here , is any constant in the interval ( 123 , +123 ) , and n is a gaussian random vector with mean zero and covariance matrix m .
to see this , note that if p has the required gaussian distribution , the distribution of p will also be gaussian ( since it is a linear combination of independent gaussians ) , will have mean 123 , and will have covariance 123m + ( 123 123 ) m = m .
if is only slightly less than one , p will be similar to p , but repeated updates of this sort will eventually produce a value for the momentum variables almost independent of the initial value .
when = 123 , p is just set to a random value drawn from its gaussian distribution , independent of its previous value .
note that when m is diagonal , the update of each momentum variable , pi , is independent of the updates of other momentum variables .
the partial momentum update of equation ( 123 ) can be substituted for the full replace - ment of the momentum in the standard hmc algorithm .
this gives a generalized hmc algorithm in which an iteration consists of three steps :
123 ) update the momentum variables using equation ( 123 ) .
let the new momentum be p .
123 ) propose a new state , ( q , p ) , by applying l leapfrog steps with stepsize , starting at
( q , p ) , and then negating the momentum .
accept ( q , p ) with probability
minh123 , exp ( u ( q ) + u ( q ) k ( p ) + k ( p ) ) i
if ( q , p ) is accepted , let ( q , p ) = ( q , p ) ; otherwise , let ( q , p ) = ( q , p ) .
123 ) negate the momentum , so that the new state is ( q , p ) .
the transitions in each of these steps ( q , p ) ( q , p ) , ( q , p ) ( q , p ) , and ( q , p ) ( q , p ) leave the canonical distribution for ( q , p ) invariant .
the entire update therefore
mcmc using hamiltonian dynamics
also leaves the canonical distribution invariant .
the three transitions also each satisfy de - tailed balance , but the sequential combination of the three does not satisfy detailed balance ( except when = 123 ) .
this is crucial , since if the combination were reversible , it would still result in random walk behaviour when l is small .
note that omitting step ( 123 ) above would result in a valid algorithm , but then , far from suppressing random walks , the method ( with close to one ) would produce nearly back - and - forth motion , since the direction of motion would reverse with every trajectory accepted in step ( 123 ) .
with the reversal in step ( 123 ) , motion continues in the same direction as long as the trajectories in step ( 123 ) are accepted , since the two negations of p will cancel .
motion reverses whenever a trajectory is rejected , so if random walk behaviour is to be suppressed , the rejection rate must be kept small .
if = 123 , the above algorithm is the same as standard hmc , since step ( 123 ) will completely replace the momentum variables , step ( 123 ) is the same as for standard hmc , and step ( 123 ) will have no eect , since the momentum will be immediately replaced anyway , in step ( 123 ) of the next iteration .
since this algorithm can be seen as a generalization of standard hmc , with an additional parameter , one might think it will oer an improvement , provided that is tuned for best performance .
however , kennedy and pendleton ( 123 ) show that when the method is applied to high - dimensional multivariate gaussian distributions only a small constant factor improvement is obtained , with no better scaling with dimensionality .
best performance is obtained using long trajectories ( l large ) , and a value for that is not very close to one ( but not zero , so the optimum choice is not standard hmc ) .
if l is small , the need to keep the rejection rate very low ( by using a small ) , as needed to suppress random walks , makes the method less advantageous than standard hmc .
it is disappointing that only a small improvement is obtained with this generalization when sampling a multivariate gaussian , due to limitations that likely apply to other distributions as well .
however , the method may be more useful than one would think from this .
for reasons discussed in sections 123 and 123 , we will often combine hmc updates with other mcmc updates ( perhaps for variables not changed by hmc ) .
there may then be a tradeo between using long trajectories to make hmc more ecient , and using shorter trajectories so that the other mcmc updates can be done more often .
if shorter - than - optimal trajectories are to be used for this reason , setting greater than zero can reduce the random walk behaviour that would otherwise result .
furthermore , rejection rates can be reduced using the window method described in the next section .
an analysis of partial momentum refreshment combined with the window method might nd that using trajectories of moderate length in conjunction with a value for greater than zero produces a more substantial improvement .
123 acceptance using windows of states
figure 123 ( right plot ) shows how the error in h varies along a typical trajectory computed with the leapfrog method .
rapid oscillations occur , here with a period of between 123 and 123 leapfrog steps , due to errors in simulating the motion in the most conned direction ( or directions , for higher - dimensional distributions ) .
when a long trajectory is used to propose a state for hmc , it is essentially random whether the trajectory ends at a state where the error in h is negative or close to zero , and hence will be accepted with probability close to one , or
extensions and variations on hmc
whether it happens to end at a state with a large positive error in h , and a correspondingly lower acceptance probability .
if somehow we could smooth out these oscillations , we might obtain a high probability of acceptance for all trajectories .
i introduced a method for achieving this result that uses windows of states at the beginning and end of the trajectory ( neal , 123 ) .
here , i will present the method as an application of a general technique in which we probabilistically map to a state in a dierent space , perform a markov chain transition in this new space , and then probabilistically map back to our original state space ( neal , 123 ) .
our original state space consists of pairs , ( q , p ) , of position and momentum variables .
we will map to a sequence of w pairs , ( ( q123 , p123 ) , .
, ( qw 123 , pw 123 ) ) , in which each ( qi , pi ) for i > 123 is the result of applying one leapfrog step ( with some xed stepsize , ) to ( qi123 , pi123 ) .
note that even though a point in the new space seems to consist of w times as many numbers as a point in the original space , the real dimensionality of the new space is the same as the old , since the whole sequence of w pairs is determined by ( q123 , p123 ) .
to probabilistically map from ( q , p ) to a sequence of pairs , ( ( q123 , p123 ) , .
, ( qw 123 , pw 123 ) ) , we select s uniformly from ( 123 , .
, w 123 ) , and set ( qs , ps ) in the new state to our current state ( q , p ) .
the other ( qi , pi ) pairs in the new state are obtained using leapfrog steps from ( qs , ps ) , for i > s , or backwards leapfrog steps ( ie , done with stepsize ) for i < s .
it is easy to see , using the fact that leapfrog steps preserve volume , that if our original state is distributed with probability density p ( q , p ) , then the probability density of obtaining the sequence ( ( q123 , p123 ) , .
, ( qw 123 , pw 123 ) ) by this procedure is
p ( ( ( q123 , p123 ) , .
, ( qw 123 , pw 123 ) ) ) =
p ( qi , pi )
since we can obtain this sequence from a ( q , p ) pair that matches any pair in the sequence , and the probability is 123 / w that we will produce the sequence starting from each of these pairs ( which happens only if the random selection of s puts the pair at the right place in the
having mapped to a sequence of w pairs , we now perform a metropolis update that keeps the sequence distribution dened by equation ( 123 ) invariant , before mapping back to the original state space .
to obtain a metropolis proposal , we perform l w + 123 leapfrog steps ( for some l w 123 ) , starting from ( qw 123 , pw 123 ) , producing pairs ( qw , pw ) to ( ql , pl ) .
we then propose the sequence ( ( ql , pl ) , .
, ( qlw +123 , plw +123 ) ) .
we accept or reject this proposed sequence by the usual metropolis criterion , with the acceptance probability being
i=lw +123 p ( qi , pi )
i=123 p ( qi , pi )
with p ( q , p ) exp ( h ( q , p ) ) .
( note here that h ( q , p ) = h ( q , p ) , and that starting from the proposed sequence would lead symmetrically to the original sequence being proposed . )
this metropolis update leaves us with either the sequence ( ( ql , pl ) , .
, ( qlw +123 , plw +123 ) ) called the accept window , or the sequence ( ( q123 , p123 ) , .
, ( qw 123 , pw 123 ) ) called the reject window .
( note that these windows will overlap if l + 123 < 123w . ) we label the pairs in the window chosen as ( ( q+ w 123 ) ) .
we now produce a nal state for the windowed hmc update by probabilistically mapping from this sequence to a single pair ,
123 , p+
w 123 , p+
mcmc using hamiltonian dynamics
e , p+
e ) with probability
e , p+ i , p+ i=123 p ( q+
e , p+
if the sequence in the chosen window was distributed according to equation ( 123 ) , the pair e ) chosen will be distributed according to p ( q , p ) exp ( h ( q , p ) ) , as desired .
to see this , let ( q+ e+n ) be the result of applying n leapfrog steps ( backward ones if n < 123 ) starting at ( q+ e ) will result from mapping from a sequence to a single pair can then be written as follows , considering all sequences that can
the probability density that ( q+
e , p+
e ) and their probabilities :
e , p+
e , p+
xk=ew +123 ( cid : 123 ) 123
w pk+w 123
i , p+
e , p+ i , p+
= p ( q+
e , p+
the entire procedure therefore leaves the correct distribution invariant .
when w > 123 , the potential problem with ergodicity discussed at the end of section 123 does not arise , since there is a non - zero probability of moving to a state only one leapfrog step away , where q may dier arbitrarily from its value at the current state .
it might appear that the windowed hmc procedure requires saving all 123w states in the accept and reject windows , since any one of these states might become the new state when a state is selected from either the accept window or reject window .
actually , however , at most three states need to be saved the start state , so that forward simulation can be resumed after the initial backward simulation , plus one state from the reject window and one state from the accept window , one of which will become the new state after one of these windows is chosen .
as states in each window are produced in sequence , a decision is made whether the state just produced should replace the state presently saved for that window .
suppose the sum of the probability densities of states seen so far is si = p123 + + pi .
if the state just produced has probability density pi+123 , it replaces the previous state saved from this window with probability pi+123 / ( si + pi+123 ) .
i showed ( neal , 123 ) that , compared to standard hmc , using windows improves the performance of hmc by a factor of two or more , on multivariate gaussian distributions in which the standard deviation in some directions is much larger than in other directions .
this is because the acceptance probability in equation ( 123 ) uses an average of probability densities over states in a window , smoothing out the oscillations in h from inexact simulation of the trajectory .
empirically , the advantage of the windowed method was found to increase with dimensionality .
for high - dimensional distributions , the acceptance probability when using the optimal stepsize was approximately 123 , larger than the theoretical value of 123 for hmc ( see section 123 ) .
these results for multivariate gaussian distributions were obtained with a window size , w , much less than the trajectory length , l .
for less regular distributions , it may be ad - vantageous to use a much larger window .
when w = l / 123 , the acceptance test determines whether the new state is from the rst half of the trajectory ( which includes the current state ) or the second half; the new state is then chosen from one half or the other with prob - abilities proportional to the probability densities of the states in that half .
this choice of w guards against the last few states of the trajectory having low probability density ( high h ) ,
extensions and variations on hmc
as might happen if the trajectory had by then entered a region where the stepsize used was
the windowed variant of hmc may make other variants of hmc more attractive .
one such variant ( section 123 ) splits the hamiltonian into many terms corresponding to subsets of the data , which tends to make errors in h higher ( while saving computation ) .
errors in h have less eect when averaged over windows .
as discussed in section 123 , very low rejection rates are desirable when using partial momentum refreshment .
it is easier to obtain a low rejection probability using windows ( ie , a less drastic reduction in is needed ) , which makes partial momentum refreshment more attractive .
qin and liu ( 123 ) introduced a variant on windowed hmc .
in their version , l leapfrog steps are done from the start state , with the accept window consisting of the states after the last w of these steps .
a state from the accept window is then selected with probabilities proportional to their probability densities .
if the state selected is k states before the end , k backwards leapfrog steps are done from the start state , and the states found by these steps along with those up to w k 123 steps forward of the start state form the reject window .
the state selected from the accept window then becomes the next state with probability given by the analogue of equation ( 123 ) ; otherwise the state remains the same .
qin and lius procedure is quite similar to the original windowed hmc procedure .
one disadvantage of qin and lius procedure is that the state is unchanged when the accept window is rejected , whereas in the original procedure a state is selected from the reject window ( which might be the current state , but often will not be ) .
the only other dierence is that the number of steps from the current state to an accepted state ranges from lw +123 to l ( average l ( w + 123 ) / 123 ) with qin and lius procedure , versus from l 123w + 123 to l ( average l w + 123 ) for the original windowed hmc procedure , while the number of leapfrog steps computed varies from l to l + w 123 with qin and lius procedure , and is xed at l with the original procedure .
these dierences are slight if w l .
qin and lin claim that their procedure performs better than the original on high - dimensional multivariate gaussian distributions , but their experiments are awed . 123
qin and liu ( 123 ) also introduce the more useful idea of weighting the states in the accept and reject windows non - uniformly , which can be incorporated into the original procedure as well .
when mapping from the current state to a sequence of w weighted states , the position of the current state is chosen with probabilities equal to the weights , and when computing the acceptance probability or choosing a state from the accept or reject window , the probability densities of states are multiplied by their weights .
qin and liu use weights that favour states more distant from the current state , which could be useful by usually causing movement to a distant point , while allowing choice of a nearer point if the distant points have low probability density .
alternatively , if one sees a window as a way of smoothing the errors in h , symmetrical weights that implement a better low pass lter would make sense .
123 using approximations to compute the trajectory
the validity of hamiltonian monte carlo does not depend on using the correct hamiltonian when simulating the trajectory .
we can instead use some approximate hamiltonian , as long
123in their rst comparison , their method computes an average of 123 leapfrog steps per iteration , but the original only computes 123 steps , a dierence in computation time which if properly accounted for negates the slight advantage they see for their procedure .
their second comparison has a similar problem , and it is also clear from an examination of the results ( in their table i ) that the sampling errors in their comparison are too large for any meaningful conclusions to be drawn .
mcmc using hamiltonian dynamics
as we simulate the dynamics based on it by a method that is reversible and volume preserving .
however , the exact hamiltonian must be used when computing the probability of accepting the end - point of the trajectory .
there is no need to look for an approximation to the kinetic energy , when it is of a simple form such as ( 123 ) , but the potential energy is often much more complex and costly to compute for instance , it may involve the sum of log likelihoods based on many data points , if the data cannot be summarized by a simple sucient statistic .
when using trajectories of many leapfrog steps , we can therefore save much computation time if a fast and accurate approximation to the potential energy is available , while still obtaining exact results ( apart from the usual sampling variation inherent in mcmc ) .
many ways of approximating the potential energy might be useful .
for example , if its evaluation requires iterative numerical methods , fewer iterations might be done than are necessary to get a result accurate to machine precision .
in a bayesian statistical application , a less costly approximation to the unnormalized posterior density ( whose log gives the potential energy ) may be obtainable by simply looking at only a subset of the data .
this may not be a good strategy in general , but i have found it useful for gaussian process models ( neal , 123; rasmussen and williams , 123 ) , for which computation time scales as the cube of the number of data points , so that even a small reduction in the number of points produces a
rasmussen ( 123 ) has proposed approximating the potential energy by modeling it as a gaussian process , that is inferred from values of the potential energy at positions selected during an initial exploratory phase .
this method assumes only a degree of smoothness of the potential energy function , and so could be widely applied .
it is limited , however , by the cost of gaussian process inference , and so is most useful for problems of moderate dimensionality for which exact evaluation of the potential energy is very costly .
an interesting possibility , to my knowledge not yet explored , would be to express the exact potential energy as the sum of an approximate potential energy and the error in this approximation , and to then apply one of the splitting techniques described in section 123 exploiting either the approximations analytic tractability ( eg , for a gaussian approximation , with quadratic potential energy ) , or its low computational cost , so that its dynamics can be accurately simulated at little cost using many small steps .
this would reduce the number of evaluations of the gradient of the exact potential energy if the variation in the potential energy removed by the approximation term permits a large stepsize for the error term .
123 short - cut trajectories adapting the stepsize without adaptation
one signicant disadvantage of hamiltonian monte carlo is that , as discussed in section 123 , its performance depends critically on the settings of its tuning parameters which consist of at least the leapfrog stepsize , , and number of leapfrog steps , l , with variations such as windowed hmc having additional tuning parameters as well .
the optimal choice of trajec - tory length ( l ) depends on the global extent of the distribution , so nding a good trajectory length likely requires examining a substantial number of hmc updates .
in contrast , just a few leapfrog steps can reveal whether some choice of stepsize is good or bad , which leads to the possibility of trying to set the stepsize adaptively during an hmc run .
recent work on adaptive mcmc methods is reviewed by andrieu and thoms ( 123 ) .
as they explain , naively choosing a stepsize for each hmc update based on results of previous updates eg , reducing the stepsize by 123% if the previous 123 trajectories were all rejected , and increasing it by 123% if less than two of the 123 previous trajectories were rejected
extensions and variations on hmc
undermines proofs of correctness ( in particular , the process is no longer a markov chain ) , and will in general produce points from the wrong distribution .
however , correct results can be obtained if the degree of adaptation declines over time .
adaptive methods of this sort could be used for hmc , in much the same way as for any other tunable mcmc method .
an alternative approach ( neal , 123 , 123 ) is to perform mcmc updates with various values of the tuning parameters , set according to a schedule that is predetermined or cho - sen randomly without reference to the realized states , so that the usual proofs of mcmc convergence and error analysis apply , but to do this using mcmc updates that have been tweaked so that they require little computation time when the tuning parameters are not appropriate for the distribution .
most of the computation time will then be devoted to up - dates with appropriate values for the tuning parameters .
eectively , the tuning parameters are set adaptively from a computational point of view , but not from a mathematical point
for example , trajectories that are simulated with a stepsize that is much too large can be rejected after only a few leapfrog steps , by rejecting whenever the change ( either way ) in the hamiltonian due to a single step ( or a short series of steps ) is greater than some threshold ie , we reject if |h ( q ( t + ) , p ( t + ) ) h ( q ( t ) , p ( t ) ) | is greater than the threshold .
if this happens early in the trajectory , little computation time will have been wasted on this unsuitable stepsize .
such early termination of trajectories is valid , since any mcmc update that satises detailed balance will still satisfy detailed balance if it is modied to eliminate transitions either way between certain pairs of states .
with this simple modication , we can randomly choose stepsizes from some distribution without wasting much time on those stepsizes that turn out to be much too large .
however , if we set the threshold small enough to reject when the stepsize is only a bit too large , we may terminate trajectories that would have been accepted , perhaps after a substantial amount of computation has already been done .
trying to terminate trajectories early when the stepsize is smaller than optimal carries a similar risk .
a less drastic alternative to terminating trajectories when the stepsize seems inappropriate is to instead reverse the trajectory .
suppose we perform leapfrog steps in groups of k steps .
based on the changes in h over these k steps , we can test whether the stepsize is inappropriate eg , the group may fail the test if the standard deviation of h over the k + 123 states is greater than some upper threshold or less than some lower threshold ( any criterion that would yield the same decision for the reversed sequence is valid ) .
when a group of k leapfrog steps fails this test , the trajectory stays at the state where this group started , rather than moving k steps forward , and the momentum variables are negated .
the trajectory will now exactly retrace states previously computed ( and which therefore neednt be recomputed ) , until the initial state is reached , at which point new states will again be computed .
if another group of k steps fails the test , the trajectory will again reverse , after which the whole remainder of the trajectory will traverse states already computed , allowing its endpoint to be found immediately without further computation .
this scheme behaves the same as standard hmc if no group of k leapfrog steps fails the test .
if there are two failures early in the trajectory , little computation time will have been wasted on this ( most likely ) inappropriate stepsize .
between these extremes , it is possible that one or two reversals will occur , but not early in the trajectory; the endpoint of the trajectory will then usually not be close to the initial state , so the non - negligible computation performed will not be wasted ( as it would be if the trajectory had been terminated ) .
mcmc using hamiltonian dynamics
such short - cut schemes can be eective at nding good values for a small number of tuning parameters , for which good values will be picked reasonably often when drawing it will not be feasible for setting a large number of tuning parameters , such as the entries in the mass matrix of equation ( 123 ) when dimensionality is high , since even if two reversals happen early on , the cost of using inappropriate values of the tuning parameters will dominate when appropriate values are chosen only very rarely .
123 tempering during a trajectory
standard hamiltonian monte carlo and the variations described so far have as much dif - culty moving between modes that are separated by regions of low probability as other local mcmc methods , such as random - walk metropolis or gibbs sampling .
several general schemes have been devised for solving problems with such isolated modes that involve sam - pling from a series of distributions that are more diuse than the distribution of interest .
such schemes include parallel tempering ( geyer , 123; earl and deem , 123 ) , simulated tempering ( marinari and parisi , 123 ) , tempered transitions ( neal , 123b ) , and annealed importance sampling ( neal , 123 ) .
most commonly , these distributions are obtained by varying a temperature parameter , t , as in equation ( 123 ) , with t = 123 corresponding to the distribution of interest , and larger values of t giving more diuse distributions .
any of these tempering methods could be used in conjunction with hmc .
however , tempering - like behaviour can also be incorporated directly into trajectory used to propose a new state in the hmc procedure .
in the simplest version of such a tempered trajectory scheme ( neal , 123b , section 123 ) , each leapfrog step in the rst half of the trajectory is combined with multiplication of the momentum variables by some factor slightly greater than one , and each leapfrog step in the second half of the trajectory is combined with division of the momentum by the same factor .
these multiplications and divisions can be done in various ways , as long as the result is reversible , and the divisions are paired exactly with multiplications .
the most symmetrical scheme is to multiply the momentum by before the rst half - step for mo - mentum ( equation ( 123 ) ) and after the second half - step for momentum ( equation ( 123 ) ) , for leapfrog steps in the rst half of the trajectory , and correspondingly , to divide the mo - mentum by before the rst and after the second half - steps for momentum in the second half of the trajectory .
( if the trajectory has an odd number of leapfrog steps , for the middle leapfrog step of the trajectory , the momentum is multiplied by before the rst half - step for momentum , and divided by after the second half - step for momentum . ) note that most of the multiplications and divisions by are preceded or followed by another such , and so can be combined into a single multiplication or division by .
it is easy to see that the determinant of the jacobian matrix for such a tempered trajectory is one , just as for standard hmc , so its endpoint can be used as a proposal without any need to include a jacobian factor in the acceptance probability .
multiplying the momentum by an that is slightly greater than one increases the value of h ( q , p ) slightly .
if h initially had a value typical of the canonical distribution at t = 123 , after this multiplication , h will be typical of a value of t that is slightly higher . 123 initially , the change in h ( q , p ) = k ( p ) + u ( q ) is due entirely to a change in k ( p ) as p is made bigger ,
123this assumes that the typical value of h is a continuous function of t , which may not be true for systems that have a phase transition .
where there is a discontinuity ( in practice , a near discontinuity ) in the expected value of h as a function of t , making small changes to h , as here , may be better than making small changes to t ( which may imply big changes in the
extensions and variations on hmc
but subsequent dynamical steps will tend to distribute the increase in h between k and u , producing a more diuse distribution for q than is seen when t = 123
after many such multiplications of p by , values for q can be visited that are very unlikely in the distribution at t = 123 , allowing movement between modes that are separated by low - probability regions .
the divisions by in the second half of the trajectory result in h returning to values that are typical for t = 123 , but perhaps now in a dierent mode .
if is too large , the probability of accepting the endpoint of a tempered trajectory will be small , since h at the endpoint will likely be much larger than h at the initial state .
to see this , consider a trajectory consisting of only one leapfrog step .
if = 123 , so that this step does nothing , the multiplication by before the rst half step for momentum would be exactly cancelled by the division by after the second half step for momentum , so h would be unchanged , and the trajectory would be accepted .
since we want something to happen , however , we will use a non - zero , which will on average result in the kinetic energy decreasing when the leapfrog step is done , as the increase in h from the multiplication by is redistributed from k alone to both k and u .
the division of p by will now not cancel the multiplication by instead , on average , it will reduce h by less than the earlier increase .
this tendency for h to be larger at the endpoint than at the initial state can be lessened by increasing the number of leapfrog steps , say by a factor of r , while reducing to 123 / r , which ( roughly ) maintains the eective temperature reached at the midpoint of
figure 123 illustrates tempered trajectories used to sample from an equal mixture of two bivariate gaussian distributions , with means of ( 123 123 ) and ( 123 123 ) , and covariances of i and 123i .
each trajectory consists of 123 leapfrog steps , done with = 123 , with tempering done as described above with = 123 .
the left plots show how h varies along the trajectories; the right plots show the position coordinates for the trajectories .
the top plots are for a trajectory starting at q = ( 123 123 ) and p = ( 123 123 ) , which has an endpoint in the other mode around ( 123 123 ) .
the bottom plots are for a trajectory starting at q = ( 123 123 ) and p = ( 123 123 ) , which ends in the same mode it begins in .
the change in h for the top trajectory is 123 , so it would be accepted with probability exp ( 123 ) = 123 .
the change in h for the bottom trajectory is 123 , so it would be accepted with probability one .
by using such tempered trajectories , hmc is able to sample these two well - separated modes 123% of the trajectories move to the other mode and are accepted whereas standard hmc does very poorly , being trapped for a very long time in one of the modes .
the parameters for the tempered trajectories in figure 123 where chosen to produce easily interpreted pictures , and are not optimal .
more ecient sampling is obtained with a much smaller number of leapfrog steps , larger stepsize , and larger eg , l = 123 , = 123 , and = 123 gives a 123% probability of moving between modes .
a fundamental limitation of the tempering method described above is that ( as for standard hmc ) the endpoint of the tempered trajectory is unlikely to be accepted if the value for h there is much higher that for the initial state .
this corresponds to the probability density at the endpoint being much lower than at the current state .
consequently , the method will not move well between two modes with equal total probability if one mode is high and narrow and the other low and broad , especially when the dimensionality is high .
( since acceptance is based on the joint density for q and p , there is some slack for moving to a point where the density for q alone is dierent , but not enough to eliminate this problem . ) i have proposed ( neal , 123 ) a modication that addresses this , in which the point moved to can come from anywhere along the tempered trajectory , not just the endpoint .
such a point must be selected
mcmc using hamiltonian dynamics
leapfrog step number
leapfrog step number
position coordinate 123
position coordinate 123
figure 123 : illustration of tempered trajectories on a mixture of two gaussians .
the trajectory shown in the top plots moves between modes; the one shown in the bottom plots ends in the
based both on its value for h and the accumulated jacobian factor for that point , which is easily calculated , since the determinant of the jacobian matrix for a multiplication of p by is simply d , where d is the dimensionality .
this modied tempering procedure can not only move between modes of diering width , but also move back and forth between the tails and the central area of a heavy - tailed distribution .
more details on these variations on hamiltonian monte carlo can be found in the r
implementations available from my web page , at www . cs . utoronto . ca / radford .
this work was supported by the natural sciences and engineering research council of canada .
the author holds a canada research chair in statistics and machine learning .
extensions and variations on hmc
