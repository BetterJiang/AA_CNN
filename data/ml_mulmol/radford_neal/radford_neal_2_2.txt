the attempt to find a single " optimal " weight vector in conven ( cid : 123 ) tional network training can lead to overfitting and poor generaliza ( cid : 123 ) tion .
bayesian methods avoid this , without the need for a valida ( cid : 123 ) tion set , by averaging the outputs of many networks with weights sampled from the posterior distribution given the training data .
this sample can be obtained by simulating a stochastic dynamical system that has the posterior as its stationary distribution .
123 conventional and bayesian learning
i view neural networks as probabilistic models , and learning as statistical inference .
conventional network learning finds a single " optimal " set of network parameter values , corresponding to maximum likelihood or maximum penalized likelihood in ( cid : 123 ) ference .
bayesian inference instead integrates the predictions of the network over all possible values of the network parameters , weighting each parameter set by its posterior probability in light of the training data .
123 neural networks as probabilistic models
consider a network taking a vector of real - valued inputs , x , and producing a vector of real - valued outputs , y , perhaps computed using hidden units .
such a network architecture corresponds to a function , i , with y = i ( x , w ) , where w is a vector of connection weights .
if we assume the observed outputs , y , are equal to y plus gaus ( cid : 123 ) sian noise of standard deviation ( j , the network defines the conditional probability
for an observed output vector given an input vector as follows : ex : exp ( - iy - ! ( x , w ) 123 / 123 " 123 )
p ( y i x , 123 " )
the probability of the outputs in a training set ( xl , yt ) , . . .
, ( xn , yn ) given this fixed noise level is therefore
p ( yl , . . .
, yn i xl , . , xn , 123 " )
ex : exp ( - e lye - ! ( xe , w ) 123 / 123 " 123 )
often 123 " is unknown .
a bayesian approach to handling this is to assign 123 " a vague prior distribution and then . ntcgrating it away , giving the following probability for the training set ( see ( buntine and weigend , 123 ) or ( neal , 123 ) for details ) :
p ( yl , " " yn i xl , . .
( so + e lye - ! ( xe , w ) 123 ) -
where so and mo are parameters of the prior for 123 " .
123 conventional learning
conventional backpropagation learning tries to find the weight vector that assigns the highest probability to the training data , or equivalently , that minimizes minus the log probability of the training data .
when 123 " is assumed known , we can use ( 123 ) to obtain the following objective function to minimize :
m ( w ) = e lye - ! ( xe , w ) 123 / 123 " 123
when 123 " is unknown , we can instead minimize the following , derived from ( 123 ) :
conventional learning often leads to the network over fitting the training data - modeling the noise , rather than the true regularities .
this can be alleviated by stopping learning when the the performance of the network on a separate validation set begins to worsen , rather than improve .
another way to avoid overfitting is to include a weight decay term in the objective function , as follows :
m ' ( w ) = alwl 123 + m ( w )
here , the data fit term , m ( w ) , may come from either ( 123 ) or ( 123 ) .
we must somehow find an appropriate value for a , perhaps , again , using a separate validation set .
123 bayesian learning and prediction
unlike conventional training , bayesian learning does not look for a single " optimal " set of network weights .
instead , the training data is used to find the posterior probability distribution over weight vectors .
predictions for future cases are made by averaging the outputs obtained with all possible weight vectors , with each con ( cid : 123 ) tributing in proportion to its posterior probability .
to obtain the posterior , we must first define a prior distribution for weight vectors .
we might , for example , give each weight a gaussian prior of standard deviation w :
bayesian learning via stochastic dynamics
we can then obtain the posterior distribution over weight vectors given the training cases ( xl , yt ) , . . .
, ( xn , yn ) using bayes ' theorem :
p ( w i ( xl , yt ) , . . .
, ( xn , yn ) )
oc p ( w ) p ( yi , . . .
, yn i xl , . . .
, xn , w )
based on the training data , the best prediction for the output vector in a test case with input vector x . , assuming squared - error loss , is
= j / ( x . , w ) p ( w i ( xi , yd , . .
, ( xn , yn ) ) dw
a full predictive distribution for the outputs in the test case can also be obtained , quantifying the uncertainty in the above prediction .
integration by monte carlo methods
integrals such as that of ( 123 ) are difficult to evaluate .
buntine and weigend ( 123 ) and mackay ( 123 ) approach this problem by approximating the posterior distribu ( cid : 123 ) tion by a gaussian .
instead , i evaluate such integrals using monte carlo methods .
if we randomly select weight vectors , wo , . . .
, wn - i , each distributed according to the posterior , the prediction for a test case can be found by approximating the integral of ( 123 ) by the average output of networks with these weights :
~ ~ l / ( x . , wt )
this formula is valid even if the wt are dependent , though a larger sample may then be needed to achieve a given error bound .
such a sample can be obtained by simulating an ergodic markov chain that has the posterior as its stationary distribution .
the early part of the chain , before the stationary distribution has been reached , is discarded .
subsequent vectors are used to estimate the integral .
123 formulating the problem in terms of energy
consider the general problem of obtaining a sample of ( dependent ) vectors , qt , with probabilities given by p ( q ) .
for bayesian network learning , q will be the weight vector , or other parameters from which the weights can be obtained , and the distribution of interest will be the posterior .
it will be convenient to express this probability distribution in terms of a potential energy function , e ( q ) , chosen so that
a momentum vector , p , of the same dimensions as q , is also introduced , and defined to have a kinetic energy of ~ \pi123
the sum of the potential and kinetic energies is
h ( q , p ) = e ( q ) + ~ lpl123
from the hamiltonian , we define ajoint probability distribution over q and p ( phase space ) as follows :
p ( q , p ) oc exp ( - h ( q , p ) )
the marginal distribution for q in ( 123 ) is that of ( 123 ) , from which we wish to sample .
we can therefore proceed by sampling from this joint distribution for q and p , and then just ignoring the values obtained for p .
123 hamiltonian dynamics
sampling from the distribution ( 123 ) can be split into two subproblems - to sample uniformly from a surface where h , and hence the probability , is con ( cid : 123 ) stant , and second , to visit points of differing h with the correct probabilities .
the solutions to these subproblems can then be interleaved to give an overall solution .
the first subproblem can be solved by simulating the hamiltonian dynamics of the system , in which q and p evolve through a fictitious time , r , according to the
123p = p ,
- = - - = - ve ( q )
this dynamics leaves h constant , and preserves the volumes of regions of phase space .
it therefore visits points on a surface of constant h with uniform probability .
when simulating this dynamics , some discrete approximation must be used .
the leapfrog method exactly maintains the preservation of phase space volume .
given a size for the time step , e , an iteration of the leapfrog method goes as follows :
p ( r + e )
per ) - ( e / 123 ) ve ( q ( r ) p ( r + e ) - ( e / 123 ) v e ( q ( r + e
123 the stochastic dynamics method
to create a markov chain that converges to the distribution of ( 123 ) , we must inter ( cid : 123 ) leave leapfrog iterations , which keep h ( approximately ) constant , with steps that can change h .
it is convenient for the latter to affect only p , since it enters into h in a simple way .
this general approach is due to anderson ( 123 ) .
i use stochastic steps of the following form to change h :
where 123 < ( l ' < 123 , and n is a random vector with components picked independently from gaussian distributions of mean zero and standard deviation one .
one can show that these steps leave the distribution of ( 123 ) invariant .
alternating these stochastic steps with dynamical leapfrog steps will therefore sample values for q and p with close to the desired probabilities .
in so far as the discretized dynamics does not keep h exactly constant , however , there will be some degree of bias , which will be eliminated only in the limit as e goes to zero .
it is best to use a value of ( l ' close to one , as this reduces the random walk aspect of the dynamics .
if the random term in ( 123 ) is omitted , the procedure is equivalent to ordinary batch mode backpropagation learning with momentum .
bayesian learning via stochastic dynamics
123 the hybrid monte carlo method
the bias introduced into the stochastic dynamics method by using an approxima ( cid : 123 ) tion to the dynamics is eliminated in the hybrid monte carlo method of duane , kennedy , pendleton , and roweth ( 123 ) .
this method is a variation on the algorithm of metropolis , et al ( 123 ) , which generates a markov chain by considering randomly - selected changes to the state .
a change is always accepted if it lowers the energy ( h ) , or leaves it unchanged .
if it increases the energy , it is accepted with probability exp ( - llh ) , and is rejected otherwise , with the old state then being repeated .
in the hybrid monte carlo method , candidate changes are produced by picking a random value for p from its distribution given by ( 123 ) and then performing some pre ( cid : 123 ) determined number of leapfrog steps .
if the leapfrog method were exact , h would be unchanged , and these changes would always be accepted .
since the method is actually only approximate , h sometimes increases , and changes are sometimes rejected , exactly cancelling the bias introduced by the approximation .
of course , if the errors are very large , the acceptance probability will be very low , and it will take a long time to reach and explore the stationary distribution .
to avoid this , we need to choose a step size ( f ) that is small enough .
123 results on a test problem
i use the " robot arm " problem of mackay ( 123 ) for testing .
the task is to learn the mapping from two real - valued inputs , xl and x123 , to two real - valued outputs , yi and y123 , given by
ih = 123 cos ( xi ) + 123 cos ( xi + x123 ) y123 = 123 sin ( xi ) + 123 sin ( xi + x123 )
gaussian noise of mean zero and standard deviation 123 is added to ( yi ' y123 ) to give the observed position , ( yi , y123 ) .
the training and test sets each consist of 123 cases , with xl picked randomly from the ranges ( - 123 , - 123 ) and ( +123 , +123 ) , and x123 from the range ( 123 , 123 ) .
a network with 123 sigmoidal hidden units was used .
the output units were linear .
like mackay , i group weights into three categories - input to hidden , bias to hidden , and hidden / bias to output .
mackay gives separate priors to weights in i fix w to one , but each category , finding an appropriate value of w for each .
multiply each weight by a scale factor associated with its category before using it , giving an equivalent effect .
for conventional training with weight decay , i use an analogous scheme with three weight decay constants ( . \ in ( 123
in all cases , i assume that the true value of u is not known .
i therefore use ( 123 ) for the training set probability , and ( 123 ) for the data fit term in conventional training .
i set 123 = rno = 123 , which corresponds to a very vague prior for u .
123 performance of conventional learning
conventional backpropagation learning was tested on the robot arm problem to gauge how difficult it is to obtain good generalization with standard methods .
. 123 ~ . - . . .
~ . ~ - r - - - ~ - - - ~
( a ) . 123 + - l , - - - - - t - - ___ == ! r . : - : : , ===* " ( b ) . 123 + - - + - , - - t - - - - - + - - - - _+_ . 123+ - ~ . . .
~ . ~ - - - ~
. ~ . 123+ - ~ ___ - - r - - - - ~ - - - ~
herations x 123
iterations x 123
figure 123 : conventional backpropagation learning - ( a ) with no weight decay , ( b ) with carefully - chosen weight decay constants .
the solid lines give the squared error on the training data , the dotted lines the squared error on the test data .
l ( a ) shows results obtained without using weight decay .
error on the test set declined initially , but then increased with further training .
to achieve good results , the point where the test error reaches its minimum would have to be identified using a separate validation set .
l ( b ) shows results using good weight decay constants , one for each category of weights , taken from the bayesian runs described below .
in this case there is no need to stop learning early , but finding the proper weight decay constants by non ( cid : 123 ) bayesian methods would be a problem .
again , a validation set seems necessary , as well as considerable computation .
use of a validation set is wasteful , since data that could otherwise be included in the training set must be excluded .
standard techniques for avoiding this , such as " n - fold " cross - validation , are difficult to apply to neural networks .
123 performance of bayesian learning
bayesian learning was first tested using the unbiased hybrid monte carlo method .
the parameter vector in the simulations ( q ) consisted of the unsealed network weights together with the scale factors for the three weight categories .
the actual weight vector ( w ) was obtained by multiplying each unsealed weight by the scale factor for its category .
each hybrid monte carlo run consisted of 123 metropolis steps .
for each step , a trajectory consisting of 123 leapfrog iterations with f = 123 was computed , and accepted or rejected based on the change in h at its end - point .
each run therefore required 123 , 123 batch gradient evaluations , and took approximately four hours on a machine rated at about 123 mips .
123 ( a ) shows the training and test error for the early portion of one hybrid monte carlo run .
after initially declining , these values fluctuate about an average .
though not apparent in the figure , some quantities ( notably the scale factors ) require a hundred or more steps to reach their final distribution .
the first 123 steps of each run were therefore discarded as not being from the stationary distribution .
123 ( b ) shows the training and test set errors produced by networks with weight vectors taken from the last 123 steps of the same run .
also shown is the error on the test set using the average of the outputs of all these networks - that is , the estimate given by ( 123 ) for the bayesian prediction of ( 123 ) .
for the run shown , this
bayesian learning via stochastic dynamics
( b ) . 123 - - i . - - - - t - - - - - - - 123i - - - + - - + - - - - - ii - - - - - ! ( cid : 123 )
" ' . , " ; . . . . .
, j ! . . . . . . . .
" " " ' - ' ~
i&era&ions x 123
i&era&ions x 123 figure 123 : bayesian learning using hybrid mon ~ e carlo - ( a ) early portion of run , ( b ) last 123 iterations .
the solid lines give the squared error on the training set , the dotted lines the squared error on the test set , for individual networks .
the dashed line in ( b ) is the test error when using the average of the outputs of all 123 networks .
figure 123 : predictive distribution for outputs .
the two regions from which training data was drawn are outlined .
circles indicate the true , noise - free out - puts for a grid of cases in the input space .
the dots in the vicinity of each circle ( often piled on top of it ) are the outputs of every fifth network from the last 123 iterations of a hybrid monte
test set error using averaged outputs is 123 , which is ( slightly ) better than any results obtained using conventional training .
note that with bayesian training no validation set is necessary .
the analogues of the weight decay constants - weight scale factors -
are found during the course of the simulation .
another advantage of the bayesian approach is that it can provide an indication of how uncertain the predictions for test cases are .
123 demonstrates this .
as one would expect , the uncertainty is greater for test cases with inputs outside the region where training data was supplied .
123 stochastic dynamics vs .
hybrid monte carlo
the uncorrected stochastic dynamics method will have some degree of systematic bias , due to inexact simulation of the dynamics .
is the amount of bias introduced of any practical importance , however ?
( a ) . ixy123o ~ - - - - - - + - - - ~ - ++ - - - - - ~ - - - - ~ - - - - - 123 - ( b )
iterations x 123
iterations x 123
figure 123 : bayesian learning using uncorrected stochastic dynamics - ( a ) training and test error for the last 123 iterations of a run with c = 123 , ( b ) potential energy ( e ) for a run with c = 123 .
note the two peaks where the dynamics became unstable .
to help answer this question , the stochastic dynamics method was run with pa ( cid : 123 ) rameters analogous to those used in the hybrid monte carlo runs .
the step size of ( = 123 used in those runs was chosen to be as large as possible while keeping the number of trajectories rejected low ( about 123% ) .
a smaller step size would not give competitive results , so this value was used for the stochastic dynamics runs as well .
a value of 123 for 123 ' in ( 123 ) was chosen as being ( loosely ) equivalent to the use of trajectories 123 iterations long in the hybrid monte carlo runs .
the results shown in fig .
123 ( a ) are comparable to those obtained using hybrid monte carlo in fig .
123 ( b ) shows that with a larger step size the uncorrected stochastic dynamics method becomes unstable .
large step sizes also cause problems for the hybrid monte carlo method , however , as they lead to high rejection rates .
the hybrid monte carlo method may be the more robust choice in some circum ( cid : 123 ) stances , but uncorrected stochastic dynamics can also give good results .
as it is simpler , the stochastic dynamics method may be better for hardware implemen ( cid : 123 ) tation , and is a more plausible starting point for any attempt to relate bayesian methods to biology .
numerous other variations on these methods are possible as well , some of which are discussed in ( neal , 123 ) .
