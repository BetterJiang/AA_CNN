markov chain monte carlo ( mcmc ) al - gorithms are routinely used to draw sam - ples from distributions with intractable nor - malization constants .
however , standard mcmc algorithms do not apply to doubly - intractable distributions in which there are additional parameter - dependent normaliza - over parameters of an undirected graphi - cal model .
an ingenious auxiliary - variable scheme ( mller et al . , 123 ) oers a solution : exact sampling ( propp and wilson , 123 ) is used to sample from a metropolishastings proposal for which the acceptance probabil - ity is tractable .
unfortunately the accep - tance probability of these expensive updates can be low .
this paper provides a generaliza - tion of mller et al .
( 123 ) and a new mcmc algorithm , which obtains better acceptance probabilities for the same amount of exact sampling , and removes the need to estimate model parameters before sampling begins .
markov chain monte carlo ( mcmc ) methods draw correlated samples from a distribution of interest ,
p ( y| ) = f ( y; ) / z ( ) ,
normalization z ( ) = r f ( y; ) dy is often unknown;
and use these samples to construct estimators
standard mcmc methods are designed for use with in - tractable distributions .
the markov - chain update rule restricts each move to a manageable subset of the ys state space : in metropolishastings only two settings are considered , the current setting y and a randomly chosen proposal , y123; gibbs sampling changes only one
component of y at a time .
metropolis requires an abil - ity to evaluate f ( y; ) for various y , and gibbs sam - pling requires the ability to sample from the condi - tional distributions dened by f , but neither method needs to know the normalizing constant z ( ) .
we now consider sampling from the posterior over pa - rameters , , rather than the variables , y .
given a prior p ( ) , the posterior is
( cid : 123 ) f ( y; ) p ( )
for many models of interest z ( ) cannot be computed .
this includes learning in many interesting models , e . g .
large - tree - width undirected graphical models and some spatial point processes .
although p ( y ) is not needed , the normalizing constant z ( ) can not be ignored as it is a function of the parameters . 123 al - most all known valid mcmc algorithms for require an ability to compute values or ratios of z ( ) for the parameter settings considered at each iteration .
as mcmc estimators are approximations unless an in - nite number of iterations are performed , and each iteration requires an infeasible computation , we call p ( |y ) a doubly - intractable distribution .
in previous work we conjectured that for general undi - rected models , there are no tractable mcmc schemes giving the correct equilibrium distribution over param - eters ( murray and ghahramani , 123 ) .
our pragmatic solution was to explore a variety of approximations for the unknown normalizers and their ratios .
such ap - proximations can give useful results , but will not lead to a markov chain with the correct stationary distri - bution .
this can cause problems in practice .
an ingenious approach by mller et al .
describes an ecient markov chain monte carlo method for distributions with intractable normalising constants , which we will refer to as the single aux -
123this potential source of confusion suggests favoring the
statistical physics term partition function .
iliary variable method ( savm ) .
here ecient means that in some situations the algorithm will be feasible , unlike all other valid mcmc methods of which we are aware .
our conjecture still stands , but savm oers an exciting way out for distributions in which exact sampling is possible .
here , we generalize savm and then construct a new method which is easier to apply and has better performance .
in section 123 we review the savm method from mller et al .
( 123 ) .
our interpretation suggests a general - ization , described in section 123 , which should improve acceptance at a modest cost ( section 123 ) .
we then in - troduce a new family of algorithms in section 123 , which seem preferable to the savm variants .
123 the single auxiliary variable
in this section we describe the savm method due to mller et al .
( 123 ) .
we focus our attention on a joint distribution of the form ( gure 123 ( a ) ) : p ( y , ) = p ( y| ) p ( ) = f ( y; )
here we assume that p ( ) is a simple distribution and that y is a vector containing all variables with soft mu - tual constraints ( e . g .
the state of an undirected graph - ical model ) .
we will assume that the y are observed .
note that unobserved y , or children of y would not cause any special dicultly : unlike these variables could be sampled with standard mcmc and would otherwise behave like the y that are observed .
see mller et al .
( 123 ) for a more detailed discussion of the standard metropolishastings ( mh ) algorithm ( hastings , 123 ) constructs a markov chain through proposals drawn from an arbitrary distribution q .
input : initial setting , number of iterations t
propose 123 q ( 123; , y ) compute a = p ( 123|y ) q ( ;123 , y )
for t = 123 .
draw r uniform ( 123 , 123 ) 123
end for
if ( r < a ) then set = 123
ideal proposals , q ( 123; , y ) , would be constructed for rapid exploration of the posterior p ( 123|y ) .
however , simple perturbations such as a gaussian with mean are commonly chosen .
the accept / reject step , 123 in the algorithm , corrects for the mismatch between the proposal and target distributions .
( a ) the original model , unknown parameters generated observed variables y , ( b ) the savm aug - mented model .
the conditional distribution of x must have a tractable dependence .
in existing approaches this distribution is only a function of one of y or , e . g .
f ( x; ( y ) ) / z ( ) or a normalizable function of ( x , ) .
q ( ; 123 , y ) q ( 123; , y )
= f ( y; 123 ) p ( 123 ) q ( ; 123 , y ) f ( y; ) p ( ) q ( 123; , y )
there appears to be no practical way to implement the standard mh algorithm for doubly - intractable distri - butions .
the acceptance ratio becomes
perhaps the requirement to compute z ( ) can be re - moved ? we are not free to change f , which denes our model .
in theory the proposals could be dened to re - move explicit z dependence from ( 123 ) , but in practice this does not seem to help : e . g .
q ( 123; , y ) =z ( ) g ( 123 ) or q ( 123; , y ) 123 / z ( 123 ) would be dicult to construct without knowing z , and would be terrible proposals .
instead mller et al .
( 123 ) extend the joint distribu - tion to include an auxiliary variable , x , which shares the same state space as y ( gure 123 ( b ) ) :
p ( x , y , ) = p ( x| , y ) f ( y; )
the joint distribution p ( y , ) is unaected .
no known method of dening auxiliary variables removes z ( ) from the joint distribution .
however , through careful choice of q , explicit z ( ) dependence can be removed from the mh ratio for this distribution : a = p ( x123 , 123|y ) q ( x , ; x123 , 123 , y ) p ( x , |y ) q ( x123 , 123; x , , y ) .
a convenient form of proposal distribution is q ( x123 , 123; x , , y ) = q ( 123; , y ) q ( x123; 123 ) ,
which corresponds to the usual change in parameters 123 , followed by a choice for the auxiliary variable .
if this choice , which happens to ignore the old x , uses
q ( x123; 123 ) = f ( x123; 123 ) / z ( 123 ) ,
yyx q ( ; 123 , y ) q ( 123; , y )
q ( ; 123 , y ) q ( 123; , y )
where f and z are the same functions as in p ( y| ) , equation ( 123 ) , then the mh acceptance ratio becomes a = p ( x123|123 , y )
q ( x; x123 , ) q ( x123; x , 123 )
= p ( x123|123 , y ) = f ( y; 123 ) p ( 123 )
q ( ; 123 , y ) q ( 123; , y )
f ( x123; 123 ) .
now every term can be computed .
the big assump - tion is that we can draw independent , exact sam - ples from the proposal distribution ( 123 ) .
surprisingly this is possible for some interesting distributions over large numbers of variables with undirected constraints ( propp and wilson , 123 ) .
the algorithms typically require tracking sets of states through a random , possi - bly large , number of markov chain steps; see ( wilson , 123 ) for reviews and examples .
the missing part of this description was the condi - tional distribution of the auxiliary variable p ( x| , y ) .
this choice is not key to constructing a valid mh al - gorithm but our choice will have a strong impact on the eciency of the markov chain .
normally we have a choice over the proposal distribution .
here that choice is forced upon us and instead we choose the target dis - tribution p ( x|y , ) to match the proposals as closely as possible .
we can not maximize the acceptance rate by choosing p ( x|y , ) = f ( x; ) / z ( ) , as that would rein - troduce explicit z ( ) terms into the mh ratio .
two possibilities are 123 ) use a normalizable approximation to the ideal case , 123 ) replace with a xed value
p ( x| , y ) = p ( x|y ) = p ( x| ( y ) ) = f ( x; )
where is a point estimate of the parameters , such as the maximum pseudo - likelihood estimate based on the observations y .
when the normalization is xed , it will cancel in ( 123 ) .
the broken lines in gure 123 ( b ) indicate that while x could be a child of and y , in practice all previous methods have used only one of the possible parents .
for concreteness we assume p ( x| , y ) = f ( x| ) / z ( ) for some xed ( y ) in all that follows , but our results are applicable to either case .
123 a tempered - transitions renement
the mh rule using the acceptance rate ( 123 ) must im - plicitly estimate the relative importance of pairs of states; in some sense it is using the additional ran - dom variables to approximate the acceptance ratio ( 123 ) .
this becomes apparent by identifying two unbiased
one - sample importance - sampling estimators :
x123 f ( x; 123 ) / z ( 123 )
x f ( x; ) / z ( )
a biased estimate of z ( ) / z ( 123 ) is obtained by divid - ing ( 123 ) by ( 123 ) .
the unknown constant z ( ) fortu - itously cancels .
unlike previous attempts , substituting this elementary approximation into the mh rule ( 123 ) leads to a valid algorithm .
given the simple nature of savms importance sam - pling estimators , or equivalently the mismatch be - tween p ( x| , y ) and q ( x; , y ) , the mh algorithm can suer a high rejection rate .
annealed importance sam - pling ( ais ) ( neal , 123; jarzynski , 123 ) is a natu - ral way to make the target and proposal distributions closer to improve estimators of normalizing constants .
linked importance sampling ( neal , 123 ) could also be used as a drop - in replacement .
we now show that this is a valid extension of savm .
we notionally extend the auxiliary variables x to an ensemble of similar variables x = ( x123 , x123 , . . . xk+123 ) ( gure 123 ) .
we give x123 the same conditional distribu - tion ( 123 ) as the single auxiliary variable x in savm .
the distribution over the remaining variables is de - ned by a sequence of markov chain transition opera - tors tk ( xk+123; xk ) with k = 123
p ( x123|x123 , , y ) t123 ( x123; x123 , , ( y ) ) p ( x123|x123 , , y ) t123 ( x123; x123 , , ( y ) )
p ( xk+123|xk , , y ) tk ( xk+123; xk , , ( y ) ) .
transition operator tk is chosen to leave a distribution pk stationary .
the sequence of stationary distribu - tions should bridge from the approximate or estimator - based distribution p ( x123| , y ) towards the distribution f ( x; ) / z ( ) from which are forced to draw an ex - act sample as part of the proposal .
one interpolation pk ( x; , ) f ( x; ) k f ( x; ) ( 123k ) fk ( x; , )
k = k k + 123
is used in neal ( 123 ) as a default choice .
note that as with ais , the nal stationary distribution , pk , is nearly the same as f ( x; ) / z ( ) for large k .
other sets of bridging distributions may perform better , although nding them may be dicult ( meng and wong , 123 ) .
we now perform mh sampling on the new joint dis - tribution p ( , x|y ) .
first we propose a change in pa - rameters , 123 q ( 123; , y ) , as before .
then a change in
cancel .
we call this method with k 123 the multiple auxiliary variable method ( mavm ) .
while we were motivated by improving the impor - tance sampling like estimators using ais , it turns out mavm is more closely related to tempered transi - tions ( neal , 123 ) .
our approach has cheaper moves than standard tempered transitions , which would re - generate x123 .
xk+123 from p ( x| , y ) before every m h proposal .
this trick could be applied to tempered transitions in general; the trade - o with acceptance rate will be explored in future work .
in reviewing savm it appeared that the auxiliary pro - posal distribution had to consist of a single exact sam - ple .
our extension allows us to augment the sample with a xed number of additional steps .
this allows us to improve the implicit normalization constant es - timation and improve the acceptance rate , for some additional cost .
however , no further expensive exact sampling , on top of that needed by the original algo - rithm , is required per iteration .
the performance as a function of k is explored in section 123
we have also provided an answer to an open question in mller et al .
( 123 ) on how to use both and y in p ( x| , y ) .
we use y in coming up with the point estimate of the parameters to get the distribution in roughly the right place .
then we bridge towards a better t for using tempered transitions .
we know the savm algorithm is valid , as it is an implementation of mh .
and we have a pseudo - explanation in terms of importance sampling , which motivated mavm .
however , the meaning of the aux - iliary variables has been left unexplained .
it is tempt - ing to draw parallels with alternative algorithms , e . g .
the boltzmann machine learning rule ( ackley et al . , 123 ) also involves generating variables that exist in the same state space as the observed variables .
how - ever , it seems dicult to attach any general meaning to the auxiliary variable settings visited by the markov chain .
the correlated samples come asymptotically
fromr p ( x|y , ) p ( ) d , which can be arbitrary .
in this
section we derive a method which draws more mean - ingful variables .
in section 123 we will see that our sim - pler method leads to an improvement in performance .
it was unclear why two normalizing constant ratio esti - mates were needed as a proxy for z ( ) / z ( 123 ) .
a more direct estimate is obtained from a single one - sample unbiased importance sampler :
x f ( x; 123 ) / z ( 123 ) .
123 simpler , more direct methods
figure 123 : the joint distribution for the annealing - based multiple auxiliary variable method ( mavn ) .
here it is as - sumed that p ( x123| , y ) is based only on a data - driven pa - rameter estimate as in ( 123 ) .
the auxiliary variables bridge towards the distribution implied by .
the gray - level and thickness of the arrows from y and indicate the strengths of inuence , k , on the auxiliary variables in ( 123 ) .
x is proposed in reverse order : xk+123 is drawn by exact sampling from the same distribution as in savm and xk .
x123 are proposed using transition operators that bridge towards p ( x123|123 , y ) :
q ( xk+123; 123 , y ) = f ( xk+123; 123 ) / z ( 123 )
q ( xk; xk+123 , 123 , y ) tk ( xk; xk+123 , 123 , ( y ) ) q ( xk123; xk , 123 , y ) tk123 ( xk123; xk , 123 , ( y ) )
q ( x123; x123 , 123 , y ) t123 ( x123; x123 , 123 , ( y ) ) ,
where tk are the corresponding reverse transition op - erators to those used to dene p ( x| , y ) , such that
tk ( x123; x ) pk ( x ) = tk ( x; x123 ) pk ( x123 ) .
the mh ratio for accepting the whole move ( , x = 123 , . . . ) ) is still free of any ( x123 , x123 , . . . ) ) ( 123 , x123 = ( x123 explicit z ( ) - dependence .
substituting equations ( 123 ) and ( 123 ) into ( 123 ) , eliminating t with ( 123 ) , rearranging and cancelling gives : a = f ( y; 123 ) p ( 123 )
fk+123 ( xk+123; , ) fk ( xk+123; , )
k+123; 123 , ) k+123; 123 , )
q ( ; 123 , y ) q ( 123; , y )
the terms have been arranged to make it clear that all ratios involving the auxiliary variables can be com - puted online as the transitions t are generated .
as in savm ( k = 123 ) , all unknown normalization constants
to ensure that wj = y , we deterministically swap the settings of wi and wj .
the new and old states of the joint model have probability ratio : p ( j ) f ( y; j ) f ( wj; i ) ( ( ( ( ( ( ( l123=i , j f ( wl; l ) p ( i ) f ( y; i ) f ( wj; j ) ( ( ( ( ( ( ( l123=i , j f ( wl; l ) .
as all terms involving wl123=i , j cancel , we need only know the initial setting of wj .
under the joint model p ( wj ) = f ( wj; j ) / z ( j ) ; we can generate wj when required by exact sampling .
this is not part of the proposal , which was deterministic after the change of index i j .
we simply deferred nding out what wj was until it was needed .
the mh ratio becomes a = q ( i; j ) p ( j ) f ( y; j ) q ( j; i ) p ( i ) f ( y; i )
for which all terms are tractable .
loosely speaking the second term acts as the importance sampling estimate suggested at the beginning of the section .
compare this to the last term of ( 123 ) for savm .
despite the underlying innite model , the resulting algorithm is slightly simpler than the original savm :
single - variable exchange algorithm input : initial , number of iterations t
for t = 123
propose 123 q ( 123; , y ) generate an auxiliary variable , w f ( w; 123 ) / z ( 123 ) a = q ( ; 123 , y ) p ( 123 ) f ( y; 123 ) q ( 123; , y ) p ( ) f ( y; ) 123
draw r uniform ( 123 , 123 ) if ( r < a ) then set = 123
end for
we call this the exchange algorithm .
each step tries to take the data y from the current parameter set - ting .
we speculate that a better parameter setting is 123 , which was generated by q ( 123; , y ) .
how can we persuade to give up the data to the rival parameter setting 123 ? we oer it a replacement data set w from if f ( w; ) / f ( y; ) > 123 then this re - placement is preferred by to the real data y , which is a good thing .
we have to consider both sides of the exchange : the ratio f ( y; 123 ) / f ( w; 123 ) measures how much 123 likes the trade in data sets .
the other terms in ( 123 ) respect any disparity between the frequency with which we propose swaps and our prior preference over the parameter that should own the data .
the exchange algorithm is a valid mcmc method be - cause it is the mh algorithm for a joint system with the correct posterior distribution p ( i|y ) .
we now out - line a more direct mathematical proof; see neal ( 123 ,
figure 123 : an alternative representation of the generative model for observations y .
all possible parameter settings , l , are instantiated , xed and used to generate a set of data variables wl .
the indicator i is used to set y = wi .
the posterior over i , the parameter chosen by the indicator variable i , is identical to p ( |y ) in the original model .
in this section we provide a proof that using this direct estimator leads to a valid algorithm .
the work in this section was originally inspired by relating carlin and chib ( 123 ) to savm .
the joint model we use is also related to parallel or replica tempering methods in the physics literature , e . g .
swendsen and wang ( 123 ) .
consider a huge model in which all possible parameter settings l exist .
each parameter setting generates its own setting of variables
wl f ( wl; l ) / z ( l ) .
to generate the data , y , we choose an index using the same prior over parameters as in our original model i p ( i ) = p ( i ) , and copy y from wi : p ( y ) = ( ywi ) .
this generative model is illustrated in gure 123
the marginal distribution over y is identical to that of the original model .
also the prior and posterior over which parameter i generated the data is equivalent to the distributions over the original .
all that is dierent is that we also choose to generate a lot of unobserved data , ( wl123=i ) , which does not aect the marginal dis - tribution over the variables of interest .
if the parameters take on a nite number of possi - ble settings , standard mcmc would now apply .
all normalizing constants , zl ( l ) , appear in the joint dis - tribution for all choices of the index i and therefore cancel in mh ratios .
however , all the variables wl must be instantiated and sampled for suciently long to reach equilibrium .
navely it seems this is a very costly or impossible approach .
however , we now out - line how , through judicious use of exact sampling , it is possible to deal with this model even in the limit of an innite number of possible parameter settings .
consider starting a chain with index i and proposing a change to index j with probability q ( j; i ) .
in order
=123=123=123=123w123w123w123w123yi p123 ) for the details of a similar proof .
it is easily shown that detailed balance holds for any particular interme - diate exact sample w by checking that the probability of starting at i ( under the intended equilibrium dis - tribution p ( i|y ) ) and then moving to j via the exact sample w is symmetric in i and j .
summing over the intermediate quantity w gives detailed balance overall .
123 reinterpreting savm
seen in the light of the joint distribution in gure 123 , the savm method appears slightly strange .
the savm method can be reproduced by augmenting the joint model in gure 123 with the savm auxiliary variable , x , and using the following proposal : 123
draw j q ( j; i ) 123
deterministically perform the three - way swap x =
wj , wi = x and wj = y .
the acceptance factor for this proposal is precisely the mh ratio in ( 123 ) .
if we want to take y from i and give it to rival setting j why involve a third parameter ? in section 123 we see that the third party can make the transaction harder ( gure 123 ) or mediate it ( gure 123 ) .
in the next section we add auxiliary variables to the exchange algorithm that are specically designed to make the swap more palatable .
in section 123 we improved savms proposal distribu - tion by bridging between the original proposal and tar - get distributions .
a similar renement can be applied to the exchange algorithm .
after taking the new pa - rameters data we take steps to make it more appealing to the current parameter .
the general exchange algo - rithm with bridging is shown opposite; k = 123 recovers the previous single - variable version .
this bridging method is slightly less general than our extension to savm , as the transition operators r must satisfy detailed balance :
rk ( x123; x , , 123 ) pk ( x; , 123 )
= rk ( x; x123 , , 123 ) pk ( x123; , 123 ) ,
where the stationary distributions pk and correspond - ing fk are dened as before in equations ( 123 ) and ( 123 ) , i . e .
pk ( x; , 123 ) fk ( x; , 123 ) = f ( x; 123 ) k f ( x; ) 123k .
for clarity the details of the motivating innite model , section 123 , have been omitted from the algorithm .
the correspondence is as follows : the exact sample x123 p123 ( x123; , 123 ) is the current setting of w123 corresponding to 123 , which we then make more attractive to through a sequence of transitions before proposing to set w = xk and w123 = y .
exchange algorithm with bridging input : initial , #iterations t , #bridging levels k
for t = 123
propose 123 q ( 123; , y ) generate k + 123 auxiliary variables :
x123 p123 ( x123; , 123 )
x123 r123 ( x123; x123 , , 123 ) x123 r123 ( x123; x123 , , 123 )
xk rk ( xk; xk123 , , 123 )
a = q ( ; 123 , y ) p ( 123 ) f ( y; 123 ) q ( 123; , y ) p ( ) f ( y; ) 123
draw r uniform ( 123 , 123 ) 123
end for
if ( r < a ) then set = 123
fk+123 ( xk; , 123 ) fk ( xk; , 123 )
the proof of validity is again a strong detailed bal - the probability of being in state i at equilibrium , obtaining the numbers ( x123 , x123 , x123 , .
, xk ) and transitioning to state j is the same as the probability of being in state j at equilib - rium , obtaining the numbers ( xk , .
, x123 , x123 , x123 ) and transitioning to state i .
summing over all possible settings of intermediate auxiliary variables gives de - tailed balance overall .
123 comparison of the algorithms
we consider a concrete example for which all com - putations are easy .
this allows comparison with ex - act partition function evaluation as in ( 123 ) and av - eraging over chains starting from the true posterior .
we consider sampling from the posterior of a sin - gle precision parameter , which has likelihood corre - sponding to n i . i . d .
zero - mean gaussian observations y = ( y123 , y123 , .
yn ) , with a conjugate prior : p ( yn| ) =n ( 123 , 123 / ) , p ( | , ) =gamma ( , )
the corresponding posterior is tractable
p ( |y ) = gamma ( cid : 123 ) n / 123 + , p
n / 123 + ( cid : 123 ) ,
but we pretend that the normalizing constant in the likelihood is unknown .
we compare the average accep - tance rate of the algorithms for two choices of proposal distribution q ( 123; , y ) .
all of the algorithms require n exact gaussian sam - ples , for which we used standard generators .
we also draw directly from the stationary distributions , pk , in the bridging algorithms .
this simulates an ideal case where the energy levels are close , or the transition op - erators mix well .
more levels would be required for the same performance with less ecient operators .
we now report results for =123 , =123 , n =123 and y =123
the rst experiment uses proposals drawn directly from the parameter posterior ( 123 ) .
the mh accep - tance probability in ( 123 ) becomes a 123; all propos - als would be accepted if z ( ) were computed exactly .
therefore any rejections are undesirable by - products of the auxiliary variable scheme , which can ( implic - itly ) obtain only noisy estimates of the normalizing constants .
figure 123 shows that both mavm and the exchange algorithm improve over the savm baseline .
it appears that a large number , k , of bridging levels are required to bring the acceptance rate close to the attainable a = 123
however , signicant benet is ob - tained from a relatively small number of levels , after which there are diminishing returns .
as each algo - rithm requires an exact sample , which in applications can require many markov chain steps , the improve - ment from a few extra steps ( k >123 ) can be worth the cost ( see section 123 ) .
in this articial situation the performance of mavm was similar to the exchange algorithm .
this result fa - vors the exchange algorithm , which has a slightly sim - pler update rule and does not need to nd a maximum ( pseudo ) - likelihood estimate before sampling begins .
in gure 123 we had set = 123
figure 123 shows that the performance of mavm falls o when this estimate is of poor quality .
for moderate k , the exchange algorithm automatically obtains an acceptance rate similar to the best possible performance of mavm; only for k = 123 was performance considerably worse than savm .
for this simple posterior sometimes manages to be a use - ful intermediary , but by k =123 the exchange algorithm has caught up with mavm .
more importantly , the exchange algorithm performs signicantly better than savm and mavm in a more realistic situation where the parameter proposal q ( 123; , y ) is not ideal .
figure 123 shows results using a gaussian proposal centred on the current param - eter value .
the exchange algorithm exploits the lo - cal nature of the proposal , rapidly obtaining the same acceptance rate as exactly evaluating z ( ) .
mavm performs much worse , although adding bridging lev - els does rapidly improve performance over the original savm algorithm .
savm is now hindered by , which is more rarely between and 123
the posterior distribution over , equation ( 123 ) , be -
figure 123 : average acceptance rate as a function of k for the gaussian example ( section 123 ) .
mavm with k = 123 corresponds to savm , the method of mller et al .
( 123 ) .
exact normalizing constant evaluation in ( 123 ) would give an acceptance rate of one .
figure 123 : average acceptance rate under the example in section 123 as a function of the initial parameter estimate required by savm ( k = 123 ) and our extended version , mavm .
horizontal bars show the results for the exchange algorithm , which has no , for k = 123 , 123 , 123
figure 123 : as in gure 123 but with a gaussian proposal distribution of width 123 centered on the current parameter setting .
the horizontal line shows the maximum average acceptance rate for a reversible transition operator , this is obtained by exact normalizing constant evaluation in ( 123 ) .
123 . 123 . 123ave . acceptanceprobabilitykexchangemavmsavm123 . 123 . 123 . 123 . 123ave . acceptanceprobabilitymavm , k=123mavm , k=123savm123 . 123 . 123 . 123 . 123ave . acceptanceprobabilitykexchangemavmsavm only recover a = 123 as k .
this is because the third party in the proposed swap ( see section 123 ) is not necessarily close to .
even in a simple unimodal 123 - dimensional posterior distribution , gure 123 , this is a signicant disadvantage in comparison with the ex - change algorithm .
we found the exchange algorithm performs better than the only other existing mcmc method for this problem and is simpler to implement .
acknowledgements : we thank radford neal for
