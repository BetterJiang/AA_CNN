abstractstatistical learning theory was introduced in the late 123s .
until the 123s it was a purely theoretical analysis of the problem of function estimation from a given collection of data .
in the middle of the 123s new types of learning algorithms ( called support vector machines ) based on the developed theory were proposed .
this made statistical learning theory not only a tool for the theoretical analysis but also a tool for creating practical algorithms for estimating multidimensional functions .
this article presents a very general overview of statistical learning theory including both theoretical and algorithmic aspects of the theory .
the goal of this overview is to demonstrate how the abstract learning theory established conditions for generalization which are more general than those discussed in classical statis - tical paradigms and how the understanding of these conditions inspired new algorithmic approaches to function estimation prob - lems .
a more detailed overview of the theory ( without proofs ) can be found in vapnik ( 123 ) .
in vapnik ( 123 ) one can nd detailed description of the theory ( including proofs ) .
setting of the learning problem
in this section we consider a model of the learning and show
that analysis of this model can be conducted in the general statistical framework of minimizing expected loss using ob - served data .
we show that practical problems such as pattern recognition , regression estimation , and density estimation are particular case of this general model .
function estimation model
the model of learning from examples can be described
using three components :
123 ) a generator of random vectors
, drawn independently
from a xed but unknown distribution
123 ) a supervisor that returns an output vector
, according to a conditional distribution
, also xed but unknown;
123 ) a learning machine capable of implementing a set of
the problem of learning is that of choosing from the given the one which predicts the set of functions supervisors response in the best possible way .
the selection random independent identically is based on a training set of distributed ( i . i . d . ) observations drawn according to
problem of risk minimization
in order to choose the best available approximation to the supervisors response , one measures the loss or discrepancy of the supervisor to provided by the a given input learning machine .
consider the expected value of the loss , given by the risk functional
between the response
and the response
mizes the risk functional
is to nd the function
( over the class of functions in the situation where the joint probabil - is unknown and the only available
information is contained in the training set ( 123 ) .
three main learning problems
this formulation of the learning problem is rather general .
it encompasses many specic problems .
below we consider the main ones : the problems of pattern recognition , regression estimation , and density estimation .
take on only two values
the problem of pattern recognition : let
be a set of indicator functions ( functions which take on only two values zero and one ) .
consider the
for this loss function , the functional ( 123 ) provides the proba - bility of classication error ( i . e . , when the answers by supervisor and the answers given by indicator function differ ) .
the problem , therefore , is to nd the function which minimizes the probability of classication errors when is unknown , but the data ( 123 ) are
the problem of regression estimation : let
set of real functions which contains the regression function
be a real value , and let
it is known that if then the regression function is the one which minimizes the functional ( 123 ) with the the
manuscript received january 123 , 123; revised may 123 , 123
the author is with at&t labs - research , red bank , nj 123 usa .
publisher item identier s 123 - 123 ( 123 ) 123 - 123
123 this is the general case which includes a case where the supervisor uses
a function y = f ( x ) :
thus the problem of regression estimation is the problem of minimizing the risk functional ( 123 ) with the loss function
vapnik : overview of statistical learning theory
( 123 ) in the situation where the probability measure unknown but the data ( 123 ) are given .
empirical risk minimization principle and the classical methods
the problem of density estimation : finally , consider the problem of density estimation from the set of densities for this problem we consider the following
it is known that desired density minimizes the risk functional ( 123 ) with the loss - function ( 123 ) .
thus , again , to estimate the density from the data one has to minimize the risk - functional under the condition where the corresponding probability mea -
is unknown but i . i . d
the erm principle is quite general .
the classical methods for solving a specic learning problem , such as the least squares method in the problem of regression estimation or the maximum likelihood method in the problem of density estimation are realizations of the erm principle for the specic loss functions considered above .
in order to specify the regression problem one
and uses loss function ( 123 ) .
using this loss
function in the functional ( 123 ) yelds the functional
which one needs to minimize in order to nd the regression estimate ( i . e . , the least square method ) .
in order to estimate a density function from a given set of one uses the loss function ( 123 ) .
putting this loss function into ( 123 ) one obtains the maximum likelihood method : the functional
which one needs to minimize in order to nd the approxima - tion to the density .
since the erm principle is a general formulation of these classical estimation problems , any theory concerning the erm principle applies to the classical methods as well .
four parts of learning theory
learning theory has to address the following four questions .
123 ) what are the conditions for consistency of the erm
to answer this question one has to specify the neces - sary and sufcient conditions for convergence in proba - bility123 of the following sequences of the random values .
the values of risks minimal possible value of the risk
converging to the are the expected risks for each minimizing the empirical
converging to the
the general setting of the learning problem : the general setting of the learning problem can be described as follows .
let the probability measure consider the set of functions minimize the risk functional
be dened on the space
the goal is : to
if probability measure
is unknown but an i . i . d .
sample
the learning problems considered above are particular cases of this general problem of minimizing the risk functional ( 123 ) on the basis of empirical data ( 123 ) , where is the specic loss function ( for example , one of ( 123 ) , ( 123 ) , or ( 123 ) ) .
below we will describe results obtained for the general statement of the problem .
to apply it for specic problems one has to substitute the corresponding loss - functions in the formulas obtained .
describes a pair
empirical risk minimization induction principle
in order to minimize the risk functional ( 123 ) , for an unknown the following induction principle is
the expected risk functional
is replaced by the
empirical risk functional
minimal possible value of the risk
constructed on the basis of the training set ( 123 ) .
the principle is to approximate the function
minimizes risk ( 123 ) by the function empirical risk ( 123 ) .
this principle is called the empirical risk minimization induction principle ( erm principle ) .
123 convergence in probability of values r ( ` ) means that for any " > 123 and for any > 123 there exists a number `123 = `123 ( " ; ) such , that for any ` > `123 with probability at least 123 the inequality
r ( ` ) r ( 123 ) < "
ieee transactions on neural networks , vol .
123 , no .
123 , september 123
equation ( 123 ) shows that solutions found using erm converge to the best possible one .
equation ( 123 ) shows that values of empirical risk converge to the value of the smallest risk .
123 ) how fast does the sequence of smallest empirical risk values converge to the smallest actual risk ? in other words what is the rate of generalization of a learning machine that implements the empirical risk minimization
123 ) how can one control the rate of convergence ( the rate of
generalization ) of the learning machine ?
123 ) how can one construct algorithms that can control the
this type of convergence is called uniform one - sided conver -
in other words , according to the key theorem the conditions for consistency of the erm principle are equivalent to the conditions for existence of uniform one - sided convergence
this theorem is called the key theorem because it asserts that any analysis of the convergence properties of the erm principle must be a worst case analysis .
the necessary condi - tion for consistency ( not only the sufcient condition ) depends on whether or not the deviation for the worst function over the given set of of functions
rate of generalization ?
the answers to these questions form the four parts of
123 ) the theory of consistency of learning processes; 123 ) the nonasymptotic theory of the rate of convergence of
123 ) the theory of controlling the generalization of learning
123 ) the theory of constructing learning algorithms .
the theory of consistency of learning processes the theory of consistency is an asymptotic theory .
it de - scribes the necessary and sufcient conditions for convergence of the solutions obtained using the proposed method to the best possible as the number of observations is increased
why do we need a theory of consistency if our goal is to
construct algorithms for a small ( nite ) sample size ?
the answer is : we need a theory of consistency because it provides not only sufcient but necessary conditions for convergence of the empirical risk minimization inductive principle .
therefore any theory of the empirical risk minimization principle must satisfy the necessary and sufcient conditions .
in this section , we introduce the main capacity concept ( the so - called vapnikcervonenkis ( vc ) entropy which denes the generalization ability of the erm principle .
in the next sections we show that the nonasymptotic theory of learning is based on different types of bounds that evaluate this concept for a xed amount of observations .
the key theorem of the learning theory
the key theorem of the theory concerning the erm - based
learning processesis the following ( 123 ) .
the key theorem : let
be a set of functions
that has a bounded loss for probability measure
converges in probability to zero .
from this theorem it follows that the analysis of the erm principle requires an analysis of the properties of uniform convergence of the expectations to their probabilities over the given set of functions .
the necessary and sufcient conditions for uniform convergence
to describe the necessary and sufcient condition for uni - form convergence ( 123 ) , we introduce a concept called the on the sample entropy of the set of functions
we introduce this concept in two steps : rst for sets of indicator functions and then for sets of real - valued functions .
entropy of the set of indicator functions : let
be a set of indicator functions , that is the functions which take on only the values zero or one .
consider a sample
let us characterize the diversity of this set of functions on the given sample by a quantity the number of different separations of this sample that can be obtained using functions from the given set of indicator functions .
let us write this in another form .
consider the set of
- dimensional binary vectors
takes various values from
that one obtains when is the number of dif - ferent vertices of the - dimensional cube that can be obtained and the set of functions on the basis of the sample
let us call the value
then for the erm principle to be consistent it is necessary and sufcient that the empirical risk to the actual risk
over the set
the random entropy .
the random entropy describes the diver - sity of the set of functions on the given data .
is a random variable since it was constructed using random i . i . d .
now we consider the expectation of the random entropy over the joint distribution function
vapnik : overview of statistical learning theory
on samples of size
the set of functions
this quantity the entropy of the set of indicator it depends on , the probability measure , and the number of observations the entropy describes the expected diversity of the given set of indicator functions on the sample of size
the main result of the theory of consistency for the pat - tern recognition problem ( the consistency for indicator loss function ) is the following theorem ( 123 ) .
theorem : for uniform two - sided convergence of the fre -
quencies to their probabilities123
it is necessary and sufcient that the equality
slightly modifying the condition ( 123 ) one can obtain the necessary and sufcient condition for one - sided uniform con -
entropy of the set of real functions : now we generalize the concept of entropy for sets of real - valued functions .
let be a set of bounded loss functions .
using this set of functions and the training set ( 123 ) one can construct the following set of
this set of vectors belongs to the - dimensional cube with be the number of elements of the
and has a nite - net123 in the metric
- net of the set of vectors
the logarithm of the ( random ) value
is called the random vc - entropy123 of the set of functions
on the sample
of the random vc - entropy
is called the vc - entropy of the set of functions
on the sample of the size
123 the sets of indicator functions r ( ) denes probability and remp ( )
123 the set of vectors q ( ) ; 123 has minimal " - net q ( 123 ) ; ; q ( n ) if : 123
there exist n = n ( " ; z123; ; z` ) vectors q ( 123 ) ; ; q ( n ) ; such that for any vector q ( ) ; 123 one can nd among these n vectors one q ( r ) which is " - close to this vector ( in a given metric ) .
for a c metric that
( q ( ) ; q ( r ) ) = max
jq ( zi ) q ( zi; r ) j " :
n is minimal number of vectors which possess this property .
123 note that vc - entropy is different from classical metrical " - entropy
cl ( " ) = ln n ( " )
where n ( " ) is cardinality of the minimal " - net of the set of functions q ( z; ) ; 123 :
is taken with respect to product - measure
the main results of the theory of uniform convergence of the empirical risk to actual risk for bounded loss function includes the following theorem ( 123 ) .
theorem : for uniform two - sided convergence of the em -
pirical risks to the actual risks
it is necessary and sufcient that the equality
slightly modifying the condition ( 123 ) one can obtain the necessary and sufcient condition for one - sided uniform con -
according to the key assertion this implies the necessary and
sufcient conditions for consistency of the erm principle .
three milestones in learning theory
in this section , for simplicity , we consider a set of indicator ( i . e . , we consider the problem of pattern recognition ) .
the results obtained for sets of indicator functions can be generalized for sets of real - valued functions .
in the previous section we introduced the entropy for sets
of indicator functions
now , we consider two new functions that are constructed the annealed vc - on the basis of the values
and the growth function
these functions are determined in such a way that for any
are valid .
on the basis of these functions , the three main milestones in statistical learning theory are constructed .
in the previous section , we introduced the equation
describing the necessary and sufcient condition for consis - tency of the erm principle .
this equation is the rst milestone in learning theory : any machine minimizing empirical risk should satisfy it .
convergence of obtained risks
this equation says nothing about
the rate of to the minimal one it is possible that the erm principle is consistent but
has arbitrary slow asymptotic rate of convergence .
ieee transactions on neural networks , vol .
123 , no .
123 , september 123
the question is : under what conditions is the asymptotic rate of convergence
we say that the asymptotic rate of convergence is fast if for
the exponential bound
the structure of the growth function
theorem : any growth function either satises the equality
or is bounded by the inequality
holds true , where
is some constant .
is an integer for which
describes the sufcient condition for fast convergence . 123 it is the second milestone in statistical learning theory : it guarantees a fast asymptotic rate of convergence .
note that both the equation describing the necessary and sufcient condition for consistency and the one that describes the sufcient condition for fast convergence of the erm method are valid for a given probability measure structed using this measure ) .
however our goal is to construct a learning machine for solving many different problems ( i . e . , for many different probability measures ) .
and vc - annealed entropy
the question is : under what conditions is the erm principle consistent and rapidly converging , independently of the probability measure ? the following equation describes the necessary and suf - cient conditions for consistency of erm for any probability
this condition is also sufcient for fast convergence .
this equation is the third milestone in statistical learning theory .
it describes the conditions under which the learning machine implementing erm principle has an asymptotic high rate of convergence independently of the problem to be solved .
these milestones form a foundation for constructing both distribution independent bounds and rigorous distribution de - pendent bounds for the rate of convergence of learning ma -
bounds on the rate of convergence
of the learning processes
in order to estimate the quality of the erm method for a given sample size it is necessary to obtain nonasymptotic bounds on the rate of uniform convergence .
a nonasymptotic bound of the rate of convergence can be obtained using a new capacity concept , called the vc dimension , which allows us to obtain a constructive bound for the growth function .
the concept of vc - dimension is based on a remarkable
property of the growth - function
123 the necessity of this condition for fast convergence is open question .
in other words the growth function will be either a linear function or will be bounded by a logarithmic function .
( for example , it cannot be of the form
we say that
the vc dimension of the set of indicator is innite if the growth function
for this set of functions is linear .
we say that
the vc dimension of the set of indicator if the growth function is bounded by a logarithmic function with coefcient
is nite and equals
the niteness of the vc - dimension of the set of indicator functions implemented by the learning machine forms the necessary and sufcient condition for consistency of the erm method independent of probability measure .
finiteness of vc - dimension also implies fast convergence .
equivalent denition of the vc dimension
in this section , we give an equivalent denition of the vc dimension of sets of indicator functions and then we generalize this denition for sets of real - valued functions .
the vc dimension of a set of indicator functions : the
vc - dimension of a set of indicator functions is the maximum number be separated in all set123 ( shattered by this set of functions ) .
if for any exists a set of
possible ways using functions of this vectors which can be shattered by the set
then the vc - dimension is equal to innity .
the vc dimension of a set of real - valued functions : let be a set of real - valued functions
bounded by constants
let us consider along with the set of real - valued functions
the set of indicator functions
is some constant ,
is the step function
the vc dimension of
the set of real valued functions is dened to be the vc - dimension of the
set of indicator functions ( 123 ) .
123 any indicator function separates a set of vectors into two subsets : the subset of vectors for which this function takes value zero and the subset of vectors for which it takes value one .
vapnik : overview of statistical learning theory
two important examples
123 ) the vc - dimension of the set of linear indicator func -
case 123the set of totally bounded functions : without
restriction in generality , we assume that
in - dimensional coordinate space , since using functions of this set one is the step can shatter at most function , which takes value one , if the expression in the brackets is positive and takes value zero otherwise .
123 ) the vc - dimension of the set of linear functions
because the vc - dimension of
in - dimensional coordinate space also equal to corresponding linear indicator functions is equal to
does not changes the set of
example 123 : we call a hyperplane
- margin separating hyperplane if it classies vectors
( classications of vectors
that fall into the margin
theorem : let vectors .
then the set of
belong to a sphere of radius - margin separating hyperplanes has the
bounded by the inequality
these examples show that in general the vc dimension of the set of hyperplanes is equal dimensionality of input space .
however , the vc dimension - margin separating hyperplanes ( with a large of the set of this fact will play value of margin an important role for constructing new function estimation
can be less than
distribution independent bounds for the rate of convergence of learning processes
the main result in the theory of bounds for sets of totally
bounded functions is the following ( 123 ) ( 123 ) .
theorem : with probability at least
, the inequality
holds true simultaneously for all functions of the set ( 123 ) ,
for the set of indicator functions , this theorem provides bounds for the risks of all func - tions of the set ( 123 ) ( including the function minimizes empirical risk ( 123 ) ) .
the bounds follow from the bound on uniform convergence ( 123 ) for sets of totally bounded functions that have nite vc dimension .
case 123the set of unbounded functions : consider
set of ( nonnegative ) unbounded functions
is easy to show ( by constructing an example ) that , without additional information about the set of unbounded functions and / or probability measures , is impossible to obtain an inequality of type ( 123 ) .
below we use the following
is some xed constant . 123
the main result for the case of unbounded sets of loss
functions is the following ( 123 ) ( 123 ) .
theorem : with probability at least
holds true simultaneously for all functions of the set , where is determined by ( 123 ) ,
the theorem bounds the risks for all functions of the set
( including the function
consider sets of functions which possess a nite vc -
dimension we distinguish between two cases :
123 ) the case where the set of loss functions
is a set of totally bounded functions;
123 ) the case where the set of loss functions
is not necessarily a set of totally bounded functions .
123 this inequality describes some general properties of distribution functions of the random variables = q ( z; ) , generated by the p ( z ) : it describes the tails of distributions ( the probability of big values for the random variables ) : if the inequality ( 123 ) with p > 123 holds , then the distributions have so - called light tails ( large values do not occurs very often ) .
in this case rapid convergence is possible .
if , however , ( 123 ) holds only for p < 123 ( large values of the random variables occur rather often ) then the rate of convergence will be small ( it will be arbitrarily small if p is sufciently close to one ) .
ieee transactions on neural networks , vol .
123 , no .
123 , september 123
problem of constructing rigorous ( distribution dependent ) bounds
sample size ) . 123 the goal appropriate for a given sample size .
is to specify methods which are
to construct rigorous bounds for the rate of convergence one has to take into account information about probability be a set of all probability measures and let we say that one has prior
information about an unknown probability measure one knows the set of measures
be a subset of the set
consider the following generalization of the growth func -
for indicator functions
and for the extreme
the generalized growth function
coincides with the growth function growth function coincides with the annealed vc - entropy .
contains only one function
for another extreme
the following assertion is true ( 123 ) , ( 123 ) .
theorem : suppose that a set of loss - functions is bounded
then for sufciently large
the following inequality :
structural risk minimization induction principle
the erm principle is intended for dealing with a large sample size .
indeed , the erm principle can be justied by is large , the second considering the inequalities ( 123 ) .
when summand on the right hand side of inequality ( 123 ) becomes small .
the actual risk is then close to the value of the empirical risk .
in this case , a small value of the empirical risk provides a small value of ( expected ) risk .
is small , then even a small
does not guarantee a small value of risk .
in this case the requires a new principle , based on the simultaneous minimization of two terms in ( 123 ) one of which depends on the value of the empirical risk while the second depends on the vc - dimension of the set of functions .
to minimize risk in this case it is necessary to nd a method which , along with minimizing the value of empirical risk , controls the vc - dimension of the learning machine .
the following principle , which is called the principle of structural risk minimization ( srm ) , is intended to minimize the risk functional with respect to both empirical risk and vc - dimension of the set of functions .
the set of functions
a structure : so that
be provided with is composed of the nested subsets of
from this bound it follows that for sufciently large with one that minimizes the empirical risk ) the following inequality
simultaneously for all
an admissible structure is one satisfying the following three
123 ) the set 123 ) the vc - dimension
is everywhere dense in of each set
of functions is
123 ) any element
of the structure contains totally bounded
the srm principle suggests that for a given set of obser -
and choose the particular function from
choose the element of structure
this bound is nonconstructive because theory does not specify a method to evaluate the generalized growth function .
to make this bound constructive and rigorous one has to estimate the generalized growth function for a given set of loss - functions and a given set of probability measures .
this is one of the main subjects of the current learning theory
theory for controlling the
generalization of learning machines
the theory for controlling the generalization of a learning machine is devoted to constructing an induction principle for minimizing the risk functional which takes into account the size of the training set ( an induction principle for a small
the guaranteed risk ( 123 ) is minimal .
the srm principle actually suggests a tradeoff between the quality of the approximation and the complexity of the increases , the minima of em - approximating function .
( as pirical risk are decreased; however , the term responsible for the condence interval ( summand in ( 123 ) ) is increased .
the srm principle takes both factors into account . )
the main results of the theory of srm are the following
theorem : for any distribution function the srm method provides convergence to the best possible solution with prob -
in other words srm method is universally strongly con -
123 the sample size ` is considered to be small if `=h is small , say `=h < 123 :
vapnik : overview of statistical learning theory
theorem : for admissible structures the method of structural converge to the best
risk minimization provides approximations which the sequence of risks
with asymptotic rate of convergence123
if the law
is such that
the rate of approximation
is the bound for functions from
theory of constructing learning algorithms
the srm induction principle in learning algorithms one has to control two factors that exist in the bound ( 123 ) which has to be minimized :
123 ) the value of empirical risk; 123 ) the capacity factor ( to choose the element
appropriate value of vc dimension ) .
below we restrict ourselves to the pattern recognition case .
we consider two type of learning machines : 123 ) neural networks ( nns ) that were inspired by the bio -
logical analogy to the brain;
123 ) the support vector machines that were inspired by sta -
tistical learning theory .
we will discuss how each corresponding machine can
control these factors .
methods of separating hyperplanes and
consider rst the problem of minimizing empirical risk on
the set of linear indicator functions
can nd the exact solution while when the minimum of this functional is nonzero one can nd an approximate solution .
therefore by constructing a separating hyperplane one can control the value of empirical risk .
unfortunately the set of separating hyperplanes is not ex - ible enough to provide low empirical risk for many real - life
two opportunities were considered to increase the exibility
of the sets of functions :
123 ) to use a richer set of indicator functions which are
superpositions of linear indicator functions;
123 ) to map the input vectors in high dimensional feature
space and construct in this space a hyperplane ( see example 123 in section iii - c )
the rst idea corresponds to the neural network .
the second
idea leads to support vector machines .
sigmoid approximation of indicator functions and neural nets
to describe the idea behind the nn let us consider the method of minimizing the functional ( 123 ) .
it is impossible to use regular gradient - based methods of optimization to min - imize this functional .
( the gradient of the indicator function is either equal to zero or is undened . ) the solution is to approximate the set of indicator functions ( 123 ) by so - called sigmoid functions
is a smooth monotonic function such that
for example , the functions
are sigmoid functions .
for the set of sigmoid function , the empirical risk functional
it has a gradient grad
is smooth in can be minimized using gradient - based methods .
for example , the gradient descent method uses the following update rule :
be a training set , where
is a vector ,
to minimize the empirical risk one has to nd the pa - ( weights ) which minimize the
empirical risk functional
where the data a local minimum , it is enough that
depends on the iteration for convergence of the gradient descent method to satisfy the conditions
there are several methods for minimizing this functional .
in the case when the minimum of the empirical risk is zero one 123 we say that the random variables `; ` = 123; 123; converge to the value
123 with asymptotic rate v ( ` ) if there exists constant c such that
v 123 ( ` ) j` 123j ! p
thus , the idea is to use the sigmoid approximation at the stage of estimating the coefcients , and use the indicator functions with these coefcients at the stage of recognition .
the generalization of this idea leads to feedforward nns .
in order to increase the exibility of the set of decision rules
ieee transactions on neural networks , vol .
123 , no .
123 , september 123
of the learning machine one considers a set of functions which are the superposition of several linear indicator func - tions ( networks of neurons ) ( 123 ) instead of the set of linear indicator functions ( single neuron ) .
all indicator functions in this superposition are replaced by sigmoid functions .
a method for calculating the gradient of the empirical risk for the sigmoid approximation of nns , called the backprop - agation method , was found ( 123 ) , ( 123 ) .
using this gradient descent method , one can determine the corresponding coef - cient values ( weights ) of all elements of the nn .
in the 123s , it was proven that the vc dimension of nns depends on the type of sigmoid functions and the number of weights in the nn .
under some general conditions the vc dimension of the nn is bounded ( although it is sufciently large ) .
suppose that the vc dimension does not change during the nn training procedure , then the generalization ability of nn depends on how well the nn minimizes the empirical risk using sufciently large training data .
the three main problems encountered when minimizating the empirical risk using the backpropagation method are as
123 ) the empirical risk functional has many local minima .
optimization procedures guarantee convergence to some local minimum .
in general the function which is found using the gradient - based procedure can be far from the best one .
the quality of the obtained approximation depends on many factors , in particular on the initial parameter values of the algorithm .
123 ) convergence to a local minimum can be rather slow ( due
to the high dimensionality of the weight - space ) .
123 ) the sigmoid function has a scaling factor which affects the quality of the approximation .
to choose the scaling factor one has to make a tradeoff between quality of approximation and the rate of convergence .
therefore , a good minimization of the empirical risk de -
pends in many respects on the art of the researcher .
the optimal separating hyperplanes
to introduce the method which is an alternative to the nn
let us consider the optimal separating hyperplanes ( 123 ) .
suppose the training data
can be separated by a hyperplane
we say that this set of vectors is separated by the optimal hy - perplane ( or the maximal margin hyperplane ) if it is separated without error and the distance between the closest vector and the hyperplane is maximal .
to describe the separating hyperplane let us use the follow -
in the following we use a compact notation for these inequal -
it is easy to check that the optimal hyperplane is the one that satises the conditions ( 123 ) and minimizes functional
( the minimization is taken with respect to both vector
the solution to this optimization problem is given by the
saddle point of the lagrange functional ( lagrangian )
be minimized with respect to
are lagrange multipliers .
the lagrangian has to and maximized with respect
in the saddle point , the solutions
satisfy the conditions
rewriting these equations in explicit form one obtains the following properties of the optimal hyperplane .
123 ) the coefcients
for the optimal hyperplane should
satisfy the constraints
123 ) the parameters of the optimal hyperplane ( vector
are linear combination of the vectors of the training set .
123 ) the solution must satisfy the following kuhntucker
from these conditions it follows that only some training vectors in expansion ( 123 ) , the support vectors , can have support vectors are the vectors for which , in ( 123 ) , the equality is achieved .
therefore we obtain
in the expansion of
substituting the expression for
back into the lagrangian the kuhntucker conditions , one
and taking into account obtains the functional
it remains to maximize this functional in the nonnegative
vapnik : overview of statistical learning theory
under the constraint
putting the expression for as an expansion on support vectors
in ( 123 ) we obtain the hyperplane
the optimal hyperplane in the case when the data are linearly nonseparable , we introduce nonnegative
and the functional
the problem then arises of how to computationally deal with such high - dimensional spaces : to construct a polynomial of degree 123 or 123 in a 123 - dimensional space it is necessary to construct hyperplanes in a billion - dimensional feature space .
in 123 , it was noted ( 123 ) that for both describing the optimal separating hyperplane in the feature space ( 123 ) and estimating the corresponding coefcients of expansion of the separating hyperplane ( 123 ) one uses the inner product of two vectors , which are images in the feature space of the therefore if one can estimate the
inner product of two vectors in the feature space as a function of two variables in input space
which we will minimize subject to constraints
using the same formalism with lagrange multipliers one can show that the optimal hyperplane also has an expansion can be found by ( 123 ) on support vectors .
the coefcients maximizing the same quadratic form as in the separable case ( 123 ) under slightly different constraints
than it will be possible to construct the solutions which are equivalent to the optimal hyperplane in the feature space .
to get this solution one only needs to replace the inner product
in ( 123 ) and ( 123 ) with the function
in other words , one constructs nonlinear decision functions
in the input space
that are equivalent to the linear decision functions ( 123 ) in the in ( 123 ) are dened by solving feature space .
the coefcients
the support vector network
the support - vector network implements the following idea ( 123 ) : map the input vectors into a very high - dimensional fea - through some nonlinear mapping chosen a priori .
in this space comstruct an optimal separating hyperplane .
the goal is to create the situation described in example 123 of - margin separating hyperplanes the section iii - c , where for vc dimension is dened by the ratio well , we control ( decrease ) the vc dimension by constructing an optimal separating hyperplane ( that maximizes the margin ) .
to increase the margin we use very high dimensional spaces .
example : consider a maping that allows us to construct decision polynomials in the input space .
to construct a poly - nomial of degree two , one can create a feature space which
coordinates of the form
the separating hyperplane con - structed in this space is a separating second - degree polynomial in the input space .
to construct a polynomial of degree
input space one has to construct space , where one then constructs the optimal hyperplane .
in an - dimensional
under constraints ( 123 ) .
in 123 mercer proved a theorem which denes the general
form of inner products in hilbert spaces .
theorem : the general form of the inner product in hilbert space is dened by the symmetric positive denite function
that satises the condition
for all functions
satisfying the inequality
therefore any function
satisfying mercers condi - tion can be used for constructing rule ( 123 ) which is equivalent to constructing an optimal separating hyperplane in some
the learning machines which construct decision functions of the type ( 123 ) are called support vectors networks or support vector machines ( svms ) . 123
using different expressions for inner products
can construct different learning machines with arbitrary types of ( nonlinear in input space ) decision surfaces .
123 this name stresses that for constructing this type of machine , the idea of expanding the solution on support vectors is crucial .
in the svm the complexity of construction depends on the number of support vectors rather than on the dimensionality of the feature space .
ieee transactions on neural networks , vol .
123 , no .
123 , september 123
for example to specify polynomials of any xed order
one can use the following functions for the inner product in the corresponding feature space :
radial basis function machines with decision functions of the
can be implemented by using a function of the type
in this case the svm machine will nd both the centers and the corresponding weights
the svm possesses some useful properties .
the optimization problem for constructing an svm has
a unique solution .
training data ) , the condence interval will be large .
in this case , even if one could minimize the empirical risk down to zero , the amount of errors on the test set could be big .
this case is called overtting .
to avoid over tting ( to get a small condence interval ) one
has to construct networks with small vc - dimension .
therefore to generalize well using an nn one must rst suggest an appropriate architecture of the nn and second nd in this network the function that minimizes the number of errors on the training data .
for nns both of these prob - lems are solving using some heuristics ( see remarks on the
in support vector methods one can control both parameters : in the separable case one obtains the unique solution which minimizes the empirical risk ( down to zero ) using a separating hyperplane with the maximal margin ( i . e . , subset with the smallest vc dimension ) .
in the general case one obtains the unique solution when
one chooses the value of the trade off parameter
the learning process for constructing an svm is rather
simultaneously with constructing the decision rule , one
obtains the set of support vectors .
implementation of a new set of decision functions can be
done by changing only one function ( kernel which denes the dot product in
why can neural networks and support vectors networks generalize ?
the generalization ability of both the nns and support vectors networks is based on the factors described in the theory for controlling the generalization of the learning processes .
ac - cording to this theory , to guarantee a high rate of generalization of the learning machine one has to construct a structure
on the set of decision functions of the structure then choose both an appropriate element and a function minimizes bound ( 123 ) .
the bound ( 123 ) can be rewritten in the simple form
within this element
where the rst term is an estimate of the risk and the second is the condence interval for this estimate .
in designing an nn , one determines a set of admissible
functions with some vc - dimension of training data the value
determines the condence interval for the network .
choosing the appropriate element of a structure is therefore a problem of designing the network for a given training set .
for a given amount
during the learning process this network minimizes the rst term in the bound ( 123 ) ( the number of errors on the training
if it happens that at the stage of designing the network one constructs a network too complex ( for the given amount of
this article presents a very general overview of statistical learning theory .
it demonstrates how an abstract analysis allows us to discover a general model of generalization .
according to this model , the generalization ability of learn - ing machines depends on capacity concepts which are more sophisticated than merely the dimensionality of the space or the number of free parameters of the loss function ( these con - cepts are the basis for the classical paradigm of generalization ) .
the new understanding of the mechanisms behind gen - eralization not only changes the theoretical foundation of generalization ( for example from the new point of view the occam razor principle is not always correct ) , but also changes the algorithmic approaches to function estimation problems .
the approach described is rather general .
it can be applied for various function estimation problems including regression , density estimation , solving inverse equations and so on .
statistical learning theory started more than 123 years ago .
the development of this theory did not involve many re - searchers .
after the success of the svm in solving real - life problems , the interest in statistical learning theory signicantly increased .
for the rst time , abstract mathematical results in statistical learning theory have a direct impact on algorithmic tools of data analysis .
in the last three years a lot of articles have appeared that analyze the theory of inference and the svm method from different perspectives .
these include :
123 ) obtaining better constructive bounds than the classical one described in this article ( which are closer in spirit to the nonconstructive bound based on the growth function than on bounds based on the vc dimension concept ) .
success in this direction could lead , in particular , to creating machines that generalize better than the svm based on the concept of optimal hyperplane;
123 ) extending the svm ideology to many different problems
of function and data - analysis;
123 ) developing a theory that allows us to create kernels that possess desirable properties ( for example that can enforce desirable invariants ) ;
vapnik : overview of statistical learning theory
123 ) developing a new type of inductive inference that is based on direct generalization from the training set to the test set , avoiding the intermediate problem of estimating a function ( the transductive type inference ) .
the hope is that this very fast growing area of research will
signicantly boost all branches of data analysis .
the author wishes to thank f .
mulier for discussions and
helping to make this article more clear and readable .
