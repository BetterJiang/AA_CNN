Abstract

Daniel Roy

CSAIL
MIT

droy@mit.edu

We introduce a new Bayesian model for hierarchical clustering based on a prior
over trees called Kingmans coalescent. We develop novel greedy and sequential
Monte Carlo inferences which operate in a bottom-up agglomerative fashion. We
show experimentally the superiority of our algorithms over others, and demon-
strate our approach in document clustering and phylolinguistics.

1

Introduction

Hierarchically structured data abound across a wide variety of domains. It is thus not surprising that
hierarchical clustering is a traditional mainstay of machine learning [1]. The dominant approach to
hierarchical clustering is agglomerative: start with one cluster per datum, and greedily merge pairs
until a single cluster remains. Such algorithms are efcient and easy to implement. Their primary
limitationsa lack of predictive semantics and a coherent mechanism to deal with missing data
can be addressed by probabilistic models that handle partially observed data, quantify goodness-of-
t, predict on new data, and integrate within more complex models, all in a principled fashion.
Currently there are two main approaches to probabilistic models for hierarchical clustering. The
rst takes a direct Bayesian approach by dening a prior over trees followed by a distribution over
data points conditioned on a tree [2, 3, 4, 5]. MCMC sampling is then used to obtain trees from
their posterior distribution given observations. This approach has the advantages and disadvantages
of most Bayesian models: averaging over sampled trees can improve predictive capabilities, give
condence estimates for conclusions drawn from the hierarchy, and share statistical strength across
the model; but it is also computationally demanding and complex to implement. As a result such
models have not found widespread use. [2] has the additional advantage that the distribution induced
on the data points is exchangeable, so the model can be coherently extended to new data. The
second approach uses a at mixture model as the underlying probabilistic model and structures the
posterior hierarchically [6, 7]. This approach uses an agglomerative procedure to nd the tree giving
the best posterior approximation, mirroring traditional agglomerative clustering techniques closely
and giving efcient and easy to implement algorithms. However because the underlying model has
no hierarchical structure, there is no sharing of information across the tree.
We propose a novel class of Bayesian hierarchical clustering models and associated inference algo-
rithms combining the advantages of both probabilistic approaches above. 1) We dene a prior and
compute the posterior over trees, thus reaping the benets of a fully Bayesian approach; 2) the dis-
tribution over data is hierarchically structured allowing for sharing of statistical strength; 3) we have
efcient and easy to implement inference algorithms that construct trees agglomeratively; and 4) the
induced distribution over data points is exchangeable. Our model is based on an exchangeable distri-
bution over trees called Kingmans coalescent [8, 9]. Kingmans coalescent is a standard model from
population genetics for the genealogy of a set of individuals. It is obtained by tracing the genealogy
backwards in time, noting when lineages coalesce together. We review Kingmans coalescent in
Section 2. Our own contribution is in using it as a prior over trees in a hierarchical clustering model
(Section 3) and in developing novel inference procedures for this model (Section 4).

1

Figure 1: (a) Variables describing the n-coalescent. (b) Sample path from a Brownian diffusion
coalescent process in 1D, circles are coalescent points. (c) Sample observed points from same in
2D, notice the hierarchically clustered nature of the points.

2 Kingmans coalescent

Kingmans coalescent is a standard model in population genetics describing the common genealogy
(ancestral tree) of a set of individuals [8, 9]. In its full form it is a distribution over the genealogy of
a countably innite set of individuals. Like other nonparametric models (e.g. Gaussian and Dirich-
let processes), Kingmans coalescent is most easily described and understood in terms of its nite
dimensional marginal distributions over the genealogies of n individuals, called n-coalescents. We
obtain Kingmans coalescent as n.
Consider the genealogy of n individuals alive at the present time t = 0. We can trace their ancestry
backwards in time to the distant past t =. Assume each individual has one parent (in genetics,
haploid organisms), and therefore genealogies of [n] = {1, ..., n} form a directed forest. In general,
at time t0, there are m (1 m n) ancestors alive. Identify these ancestors with their correspond-
ing sets 1, ..., m of descendants (we will make this identication throughout the paper). Note that
(t) = {1, ..., m} form a partition of [n], and interpret t(cid:55) (t) as a function from (, 0] to the
set of partitions of [n]. This function is piecewise constant, left-continuous, monotonic (s t implies
that (t) is a renement of (s)), and (0)={{1}, ...,{n}} (see Figure 1a). Further,  completely
and succinctly characterizes the genealogy; we shall henceforth refer to  as the genealogy of [n].
Kingmans n-coalescent is simply a distribution over genealogies of [n], or equivalently, over the
space of partition-valued functions like . More specically, the n-coalescent is a continuous-time,
partition-valued, Markov process, which starts at {{1}, ...,{n}} at present time t = 0, and evolves
backwards in time, merging (coalescing) lineages until only one is left. To describe the Markov
process in its entirety, it is sufcient to describe the jump process (i.e. the embedded, discrete-time,
Markov chain over partitions) and the distribution over coalescent times. Both are straightforward
and their simplicity is part of the appeal of Kingmans coalescent. Let li, ri be the ith pair of
lineages to coalesce, tn1 <    < t1 < t0 = 0 be the coalescent times and i = ti1  ti > 0
be the duration between adjacent events (see Figure 1a). Under the n-coalescent, every pair of
lineages merges independently with rate 1. Thus the rst pair amongst m lineages merge with rate

(cid:1)(cid:1) independently, the pair li, ri is chosen from among

2
those right after time ti, and with probability one a random draw from the n-coalescent is a binary
tree with a single root at t= and the n individuals at time t=0. The genealogy is given as:

(cid:1)= m(m1)

(cid:0)m

2

2

. Therefore iExp(cid:0)(cid:0)ni+1
{{1}, ...,{n}}
(cid:1) exp(cid:0)(cid:0)ni+1
(cid:0)ni+1
(cid:1)i

(t) =

p() =(cid:81)n1

ti1  li  ri + (li  ri)
ti

if t = 0;
if t = ti;
if ti+1 < t < ti.

(1)

(cid:1) /(cid:0)ni+1

(cid:1) =(cid:81)n1

i=1 exp(cid:0)(cid:0)ni+1
(cid:1)i

2

(cid:1)

Combining the probabilities of the durations and choices of lineages, the probability of  is simply:

2

2

i=1

(2)
The n-coalescent has some interesting statistical properties [8, 9]. The marginal distribution over
tree topologies is uniform and independent of the coalescent times. Secondly, it is innitely ex-
changeable: given a genealogy drawn from an n-coalescent, the genealogy of any m contemporary
individuals alive at time t  0 embedded within the genealogy is a draw from the m-coalescent.
Thus, taking n  , there is a distribution over genealogies of a countably innite population
for which the marginal distribution of the genealogy of any n individuals gives the n-coalescent.
Kingman called this the coalescent.

2

2

!!"#!!"$!!"%!!!&"!&"#!&"$!&"%&!(!%")!%!!")!!!&")&&")!!")t1t2t3t0=0123x1x2x3x4y{1,2}y{3,4}y{1,2,3,4}z{{1,2,3,4}}{{1,2},{3,4}}{{1},{2},{3},{4}}{{1},{2},{3,4}}(t)=!!!"!#!$%$!#!$&!$!%&%%&$$&##&(a)(b)(c)t3 Hierarchical clustering with coalescents

We take a Bayesian approach to hierarchical clustering, placing a coalescent prior on the latent tree
and modeling observed data with a Markov process evolving forward in time along the tree. We will
alter our terminology from genealogy to tree, from n individuals at present time to n observed data
points, and from individuals on the genealogy to latent variables on the tree-structured distribution.
Let x1, ..., xn be n observed data at the leaves of a tree  drawn from the n-coalescent.  has n  1
coalescent points, the ith occuring when li and ri merge at time ti to form i = li  ri. Let tli
and tri be the times at which li and ri are themselves formed.
We construct a continuous-time Markov process evolving along the tree from the past to the present,
branching independently at each coalescent point until we reach time 0, where the n Markov pro-
cesses induce a distribution over the n data points. The joint distribution respects the conditional
independences implied by the structure of the directed tree. Let yi be a latent variable that takes on
the value of the Markov process at i just before it branches (see Figure 1a). Let y{i} = xi at leaf i.
To complete the description of the likelihood model, let q(z) be the initial distribution of the Markov
process at time t = , and kst(x, y) be the transition probability from state x at time s to state y
at time t. This Markov process need be neither stationary nor ergodic. Marginalizing over paths of
the Markov process, the joint probability over the latent variables and the observations is:

p(x, y, z|) = q(z)k tn1(z, yn1)(cid:81)n1

i=1 ktitli(yi, yli)ktitri(yi, yri)

(3)
Notice that the marginal distributions at each observation p(xi|) are identical and given by the
Markov process at time 0. However, they are not independent: they share the same sample path down
the Markov process until they split. In fact the amount of dependence between two observations is
a function of the time at which the observations coalesce in the past. A more recent coalescent time
implies larger dependence. The overall distribution induced on the observations p(x) inherits the
innite exchangeability of the n-coalescent. We considered a brownian diffusion (see Figures 1(b,c))
and a simple independent sites mutation process on multinomial vectors (Section 4.3).

4 Agglomerative sequential Monte Carlo and greedy inference

We develop two classes of efcient and easily implementable inference algorithms for our hierar-
chical clustering model based on sequential Monte Carlo (SMC) and greedy schemes respectively.
In both classes, the latent variables are integrated out, and the trees are constructed in a bottom-up
fashion. The full tree  can be expressed as a series of n  1 coalescent events, ordered backwards
in time. The ith coalescent event involves the merging of the two subtrees with leaves li and ri
and occurs at a time i before the previous coalescent event. Let i = {j, lj, rj for j  i} denote
the rst i coalescent events. n1 is equivalent to  and we shall use them interchangeably.
We assume that the form of the Markov process is such that the latent variables {yi}n1
i=1 and z can
be efciently integrated out using an upward pass of belief propagation on the tree. Let Mi(y) be
the message passed from yi to its parent; M{i}(y) = xi(y) is point mass at xi for leaf i. Mi(y)
is proportional to the likelihood of the observations at the leaves below coalescent event i, given that
yi = y. Belief propagation computes the messages recursively up the tree; for i = 1, ..., n  1:

Zi(x, i) is a normalization constant introduced to avoid numerical problems. The choice of Z
does not affect the probability of x, but does impact the accuracy and efciency of our inference

algorithms. We found that Zi(x, i) =(cid:82) q(y)Mi(y) dy worked well. At the root, we have:

Mi(y) = Z1

i (x, i)(cid:81)

(cid:82) ktitbi(y, yb)Mbi(yb) dyb
Z(x, n1) =(cid:82) q(z)k tn1(z, y)Mn1(y) dy dz

b=l,r

The marginal probability p(x|) is now given by the product of normalization constants:

p(x|) = Z(x, n1)(cid:81)n1

(4)

(5)

(6)

(7)

Multiplying in the prior (2) over , we get the joint probability for the tree  and observations x:

p(x, ) = Z(x, n1)(cid:81)n1

i=1 exp(cid:0)(cid:0)ni+1
(cid:1)i

2

(cid:1) Zi(x, i)

i=1 Zi(x, i)

3

Our inference algorithms are based upon (7). Note that each term Zi(x, i) can be interpreted as a
1. In general, for each i, we choose a duration i
local likelihood term for coalescing the pair li, ri
and a pair of subtrees li, ri to coalesce. This choice is based upon the ith term in (7), interpreted
as the product of a local prior and a local likelihood for choosing i, li and ri given i1.

4.1 Sequential Monte Carlo algorithms

2

i

s ws

i1)

lj, s

n1s

ws

i = ws

i1 = {s
li and s

j , s
ri from a proposal distribution fi(s

(cid:1)s
i1exp(cid:0)(cid:0)ni+1

(cid:1) Zi(x, s

After n  1 iterations, we obtain a set of trees s

i1), with weights:
li, s
n1 and weights ws

Sequential Monte Carlo algorithms (aka particle lters), approximate the posterior using a weighted
sum of point masses [10]. These point masses are constructed iteratively. At iteration i  1, particle
i1. At iteration i, s is extended by
s consists of s
ri|s
sampling s
i , s
i , s

rj for j < i}, and has weight ws
i , s
li, s
i )/fi(s

is approximated by: p(, x)  (cid:80)

ri|s
(8)
n1. The joint distribution
n1(), while the posterior is approximated with the
weights normalized. An important aspect of SMC is resampling, which places more particles in
high probability regions and prunes particles stuck in low probability regions. We resample as in
Algorithm 5.1 of [11] when the effective sample size ratio as estimated in [12] falls below one half.
i , s
SMC-PriorPrior. The simplest proposal distribution is to sample s
ri from the local
ri are drawn uniformly from
prior. s
li, s
all available pairs. The weight updates (8) reduce to multiplying by Zi(x, s
i ). This approach is
computationally very efcient, but performs badly with many objects due to the uniform draws over
pairs. SMC-PriorPost. The second approach addresses the suboptimal choice of pairs to coalesce.
We rst draw s
ri|s

i is drawn from an exponential with rate(cid:0)ni+1

r) (9)
This approach is more computationally demanding since we need to evaluate the local likelihood of
every pair. It also performs signicantly better than SMC-PriorPrior. We have found that it works
reasonably well for small data sets but fails in larger ones for which the local posterior for i is highly
peaked. SMC-PostPost. The third approach is to draw all of s

i from its local prior, then draw s
i1)  Zi(x, s
i , s

(cid:1) and s
(cid:80)

ri from the local posterior:
i = ws

li, s
ri); ws

ri from their posterior:

i1, s

i , s

li, s

li and s

i , (cid:48)

l, (cid:48)

Zi(x, s

i1, s

fi(s

li, s

(cid:48)
l,(cid:48)

r

i1

2

(cid:1)s
(cid:1) Zi(x, s
(cid:82) exp(cid:0)(cid:0)ni+1

i

2

i , s
i , s

li and s
li, s

(cid:1)(cid:48)(cid:1) Zi(x, s

ri)
i1, (cid:48), (cid:48)

i1, s

l, (cid:48)

r) d(cid:48)

(10)

fi(s

i , s

li, s

ri|s

i1)  exp(cid:0)(cid:0)ni+1

(cid:80)

2
(cid:48)
l,(cid:48)

r

ws

i = ws

i1

This approach requires the fewest particles, but is the most computationally expensive due to the
integral for each pair. Fortunately, for the case of Brownian diffusion process described below, these
integrals are tractable and related to generalized inverse Gaussian distributions.

4.2 Greedy algorithms

SMC algorithms are attractive because they produce an arbitrarily accurate approximation to the full
posterior. However in many applications a single good tree is often times sufcient. We describe a
few greedy algorithms to construct a good tree.
Greedy-MaxProb: the obvious greedy algorithm is to pick i, li and ri maximizing the ith term
in (7). We do so by computing the optimal i for each pair of li, ri, and then picking the pair
maximizing the ith term at its optimal i. Greedy-MinDuration: simply pick the pair to coalesce
whose optimal duration is minimum. Both algorithms require recomputing the optimal duration for

each pair at each iteration, since the exponential rate(cid:0)ni+1
each pair li and ri we determine the optimal i, but replacing the(cid:0)ni+1

(cid:1) on the duration varies with the iteration
(cid:1) prior rate with 1. We

i. The total computational cost is thus O(n3). We can avoid this by using the alternative view of the
n-coalesent as a Markov process where each pair of lineages coalesces at rate 1. Greedy-Rate1: for

coalesce the pair with most recent time (as in Greedy-MinDuration). This reduces the complexity to
O(n2). We found that all three perform about equally well.

2

2

1If the Markov process is stationary with equilibrium q(y), Zi (x, i) is a likelihood ratio between two
models with observations xi: (1) a single tree with leaves i; (2) two independent trees with leaves li and ri
respectively. This is similar to [6, 7] and is used later in our NIPS experiment to determine coherent clusters.

4

4.3 Examples

Brownian diffusion. Consider the case of continuous data evolving via Brownian diffusion. The
transition kernel kst(y,) is a Gaussian centred at y with variance (t  s), where  is a symmetric
p.d. covariance matrix. Because the joint distribution (3) over x, y and z is Gaussian, we can express

(11)
where (cid:107)x(cid:107) = x(cid:62)1x is the Mahanalobis norm. The optimal duration i can also be solved for,
(12)

each message Mi(y) as a Gaussian with mean(cid:98)yi and variance vi. The local likelihood is:
2 exp(cid:0) 1
Zi(x, i) = |2(cid:98)i| 1
(cid:98)i = (vli +vri +tli+tri2ti)
2 ||(cid:98)yli(cid:98)yri||2bi
(cid:1)(cid:16)(cid:113)
(cid:17)  1
(cid:1)||(cid:98)yli(cid:98)yri||2
4(cid:0)ni+1
4(cid:0)ni+1
2(vli +vri +tli+tri2ti1)
vi =(cid:0)(vli + tli  ti)1 + (vri + tri  ti)1(cid:1)1;(cid:98)yi =(cid:0)

where D is the dimensionality. The message at the newly coalesced point has mean and covariance:
(13)

+D2  D

(cid:1)vi

byri

byli

(cid:1);

i =

vri +triti

vli +tliti

+

1

2

2

Multinomial vectors. Consider a Markov process acting on multinomial vectors with each entry
taking one of K values and evolving independently. Entry d evolves at rate d and has equilibrium
h 111K  Ik) where 111K is a vector of
distribution vector qd. The transition rate matrix is Qd = d(q(cid:62)
K ones and IK is identity matrix of size K, while the transition probability matrix for entry d in
a time interval of length t is eQdt = edtIK + (1  edt)q(cid:62)
d 111K. Representing the message for
](cid:62), normalized so that qd  M d
i = 1,
entry d from i to its parent as a vector M d
i , ..., M dK
i
the local likelihood terms and messages are computed as,

i = [M d1

i(x, i) = 1  eh(2titlitri)(cid:0)1 (cid:80)K

(14)
(15)
Unfortunately the optimal i cannot be solved analytically and we use Newton steps to compute it.

i = (1  ed(titli)(1  M d
M d

li))(1  ed(titri)(1  M d

k=1 qdkM dk

ri))/Z d

i(x, i)

liM dk
ri

(cid:1)

Z d

4.4 Hyperparameter estimation and predictive density

We perform hyperparameter estimation by iterating between estimating a geneology, then re-
estimating the hyperparamters conditioned on this tree. Space precludes a detailed discussion of
the algorithms we use; they can be found in the supplemental material. In the Brownian case, we
place an inverse Wishart prior on  and the MAP posterior  is available in a standard closed form.
In the multinomial case, the updates are not available analytically and must be solved iteratively.
Given a tree and a new individual y(cid:48) we wish to know: (a) where y(cid:48) might coalescent and (b) what
the density is at y(cid:48). In the supplemental material, we show that the probability that y(cid:48) merges at
time t with a given sibling is available in closed form for the Brownian motion case. To obtain the
density, we sum over all possible siblings and integrate out t by drawing equally spaced samples.

5 Experiments

Synthetic Data Sets
In Figure 2 we compare the various SMC algorithms and Greedy-Rate12 on
a range of synthetic data sets drawn from the Brownian diffusion coalescent process itself ( = ID)
to investigate the effects of various parameters on the efcacy of the algorithms. Generally SMC-
PostPost performed best, followed by SMC-PriorPost, SMC-PriorPrior and Greedy-Rate1. With
increasing D the amount of data given to the algorithms increases and all algorithms do better,
especially Greedy-Rate1. This is because the posterior becomes concentrated and the Greedy-Rate1
approximation corresponds well with the posterior. As n increases, the amount of data increases
as well and all algorithms perform better3. However, the posterior space also increases and SMC-
PriorPrior which simply samples from the prior over genealogies does not improve as much. We
see this effect as well when S is small. As S increases all SMC algorithms improve. Finally, the
algorithms were surprisingly robust when there is mismatch between the generated data sets  and
the  used by the model. We expected all models to perform worse with SMC-PostPost best able to
maintain its performance (though this is possibly due to our experimental setup).

2We found in unreported experiments that the greedy algorithms worked about equally well.
3Each panel was generated from independent runs. Data set variance affected all algorithms, varying overall

performance across panels. However, trends in each panel are still valid, as they are based on the same data.

5

Figure 2: Predictive performance of algorithms as we vary (a) the numbers of dimensions D, (b)
observations n, (c) the mutation rate  ( = ID), and (d) number of samples S. In each panel
other parameters are xed to their middle values (we used S = 50) in other panels, and we report
log predictive probabilities on one unobserved entry, averaged over 100 runs.

MNIST
BHC

Avg-link
Coalescent
.363.004 .392.006 .412.006
.581.005 .579.005 .610.005
.755.005 .763.005 .773.005

Purity
Subtree
LOO-acc

SPAMBASE

BHC

Avg-link
Coalescent
.616.007 .711.010 .689.008
.607.011
.661.012
.861.008
.846.010

.549.015
.832.010

Table 1: Comparative results. Numbers are averages and standard errors over 50 and 20 repeats.

MNIST and SPAMBASE We compare the performance of our approach (Greedy-Rate1 with
10 iterations of hyperparameter update) to two other hierarchical clustering algorithms: average-
link agglomerative clustering and Bayesian hierarchical clustering [6].
In MNIST, We use 10
digits from the MNIST data set, 20 examplars for each digit and 20 dimensions (reduced via
PCA), repeating the experiment 50 times.
In SPAMBASE, we use 100 examples of 57 at-
tributes each from 2 classes, repeating 20 times. We present purity scores [6], subtree scores
(#{interior nodes with all leaves of same class}/(n  #classes)) and leave-one-out accuracies (all
scores between 0 and 1, higher better). The results are in Table 1; as we can see, except for purity on
SPAMBASE, ours gives the best performance. Experiments not presented here show that all greedy
algorithms perform about the same and that performance improves with hyperparameter updates.

Phylolinguistics We apply our approach (Greedy-Rate1) to a phylolinguistic problem: language
Unlike previous research [13] which studies only phonological data, we use a full
evolution.
the World Atlas of Language
typological database of 139 binary features over 2150 languages:
Structures (henceforth, WALS) [14]. The data is sparse: about 84% of the entries are unknown.
We use the same version of the database as extracted by [15]. Based on the Indo-European subset of
this data for which at most 30 features are unknown (48 language total), we recover the coalescent
tree shown in Figure 3(a). Each language is shown with its genus, allowing us to observe that it
teases apart Germanic and Romance languages, but makes a few errors with respect to Iranian and
Greek. (In the supplemental material, we report results applied to a wider range of languages.)
Next, we compare predictive abilities to other algorithms. We take a subset of WALS and tested on
5% of withheld entries, restoring these with various techniques: Greedy-Rate1; nearest neighbors
(use value from nearest observed neighbor); average-linkage (nearest neighbor in the tree); and
probabilistic PCA (latent dimensions in 5, 10, 20, 40, chosen optimistically). We use ve subsets
of the WALS database of varying size, obtained by sorting both the languages and features of the
database according to how many cells are observed. We then use a varying percentage (10%50%)
of the densest portion. The results are in Figure 3(b). The performance of PPCA is steady around
76%. The performance of the other algorithms degrades as the sparsity incrases. Our approach
performs at least as well as all the other techniques, except at the two extremes.

NIPS We applied Greedy-Rate1 to all NIPS abstracts through NIPS12 (1740, total). The data was
preprocessed so that only words occuring in at least 100 abstracts were retained. The word counts
were then converted to binary. We performed one iteration of hyperparameter re-estimation. In the
supplemental material, we depict the top levels of the coalescent tree. Here, we use use the tree to

6

4681.61.41.210.80.6(a)averagelogpredictiveD:dimensions4681.61.41.210.80.6(b)n:observations0.5121.61.41.210.80.6(c):mutationrate103050701.61.41.210.80.6(d)S:particles  SMCPostPostSMCPriorPostSMCPriorPriorGreedyRate1(b) Data restoration on WALS. Y-axis is accuracy;
X-axis is percentage of data set used in experiments.
At 10%, there are N = 215 languages, H = 14
features and p = 94% observed data; at 20%, N =
430, H = 28 and p = 80%; at 30%: N = 645,
H = 42 and p = 66%; at 40%: N = 860, H =
56 and p = 53%; at 50%: N = 1075, H = 70
and p = 43%. Results are averaged over ve folds
with a different 5% hidden each time. (We also tried
a mode prediction, but its performance is in the
60% range in all cases, and is not depicted.)

(a) Coalescent for a subset of Indo-European lan-
guages from WALS.

Figure 3: Results of the phylolinguistics experiments.

Top Authors

LLR (t) Top Words
32.7 (-2.71) bifurcation attractors hopeld network saddle Mjolsness (9) Saad (9) Ruppin (8) Coolen (7)
0.106 (-3.77) voltage model cells neurons neuron
83.8 (-2.02) chip circuit voltage vlsi transistor
140.0 (-2.43) spike ocular cells ring stimulus
2.48 (-3.66) data model learning algorithm training
31.3 (-2.76) infomax image ica images kurtosis
31.6 (-2.83) data training regression learning model
39.5 (-2.46) critic policy reinforcement agent controller
23.0 (-3.03) network training units hidden input

Koch (30) Sejnowski (22) Bower (11) Dayan (10)
Koch (12) Alspector (6) Lazzaro (6) Murray (6)
Sejnowski (22) Koch (18) Bower (11) Dayan (10)
Jordan (17) Hinton (16) Williams (14) Tresp (13)
Hinton (12) Sejnowski (10) Amari (7) Zemel (7)
Jordan (16) Tresp (13) Smola (11) Moody (10)
Singh (15) Barto (10) Sutton (8) Sanger (7)
Mozer (14) Lippmann (11) Giles (10) Bengio (9)

Table 2: Nine clusters discovered in NIPS abstracts data.

generate a at clustering. To do so, we use the log likelihood ratio at each branch in the coalescent
to determine if a split should occur. If the log likelihood ratio is greater than zero, we break the
branch; otherwise, we recurse down. On the NIPS abstracts, this leads to nine clusters, depicted
in Table 2. Note that clusters two and three are quite similarhad we used a slighly higher log
likelihood ratio, they would have been merged (the LLR for cluster 2 was only 0.105). Note that
the clustering is able to tease apart Bayesian learning (cluster 5) and non-bayesian learning (cluster
7)both of which have Mike Jordan as their top author!

6 Discussion

We described a new model for Bayesian agglomerative clustering. We used Kingmans coalescent
as our prior over trees, and derived efcient and easily implementable greedy and SMC inference
algorithms for the model. We showed empirically that our model gives better performance than other
agglomerative clustering algorithms, and gives good results on applications to document modeling
and phylolinguistics.
Our model is most similar in spirit to the Dirichlet diffusion tree of [2]. Both use innitely exchange-
able priors over trees. While [2] uses a fragmentation process for trees, our prior uses the reversea

7

00.10.2[Armenian]  Armenian (Eastern)[Armenian]  Armenian (Western)[Indic]  Bengali[Indic]  Marathi[Indic]  Maithili[Iranian]  Ossetic[Indic]  Nepali[Indic]  Sinhala[Indic]  Kashmiri[Indic]  Hindi[Indic]  Panjabi[Iranian]  Pashto[Slavic]  Czech[Baltic]  Latvian[Baltic]  Lithuanian[Slavic]  Russian[Slavic]  Ukrainian[Slavic]  SerbianCroatian[Slavic]  Slovene[Slavic]  Polish[Albanian]  Albanian[Romance]  Catalan[Romance]  Italian[Romance]  Portuguese[Romance]  Romanian[Slavic]  Bulgarian[Greek]  Greek (Modern)[Romance]  Spanish[Germanic]  Danish[Germanic]  Norwegian[Germanic]  Swedish[Germanic]  Icelandic[Germanic]  English[Germanic]  Dutch[Germanic]  German[Romance]  French[Iranian]  Kurdish (Central)[Iranian]  Persian[Iranian]  Tajik[Celtic]  Breton[Celtic]  Cornish[Celtic]  Welsh[Celtic]  Gaelic (Scots)[Celtic]  Irish0.10.20.30.40.5727476788082  CoalescentNeighborAgglomerativePPCAcoalescent process instead. This allows us to develop simpler inference algorithms than those in
[2], though it will be interesting to consider the possibility of developing analogous algorithms for
[2]. [3] also describes a hierarchical clustering model involving a prior over trees, but his prior is
not innitely exchangeable. [5] uses tree-consistent partitions to model relational data; it would be
interesting to apply our approach to their setting. Another related work is the Bayesian hierarchical
clustering of [6], which uses an agglomerative procedure returning a tree structured approximate
posterior for a Dirichlet process mixture model. As opposed to our work [6] uses a at mixture
model and does not have a notion of distributions over trees.
There are a number of unresolved issues with our work. Firstly, our algorithms take O(n3) compu-
tation time, except for Greedy-Rate1 which takes O(n2) time. Among the greedy algorithms we see
that there are no discernible differences in quality of approximation thus we recommend Greedy-
Rate1. It would be interesting to develop SMC algorithms with O(n2) runtime. Secondly, there
are unanswered statistical questions. For example, since our prior is innitely exchangeable, by de
Finettis theorem there is an underlying random distribution for which our observations are i.i.d.
draws. What is this underlying random distribution, and how do samples from this distribution look
like? We know the answer for at least a simple case: if the Markov process is a mutation process
with mutation rate /2 and new states are drawn i.i.d. from a base distribution H, then the induced
distribution is a Dirichlet process DP(, H) [8]. Another issue is that of consistencydoes the
posterior over random distributions converge to the true distribution as the number of observations
grows? Finally, it would be interesting to generalize our approach to varying mutation rates, and to
non-binary trees by using generalizations to Kingmans coalescent called -coalescents [16].

