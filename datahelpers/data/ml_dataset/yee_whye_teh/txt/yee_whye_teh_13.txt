Variational Bayesian Approach to Movie Rating Prediction

Yew Jin Lim

School of Computing

National University of Singapore
limyewji@comp.nus.edu.sg

Yee Whye Teh

Gatsby Computational Neuroscience Unit

University College London
ywteh@gatsby.ucl.ac.uk

ABSTRACT
Singular value decomposition (SVD) is a matrix decompo-
sition algorithm that returns the optimal (in the sense of
squared error) low-rank decomposition of a matrix. SVD
has found widespread use across a variety of machine learn-
ing applications, where its output is interpreted as compact
and informative representations of data. The Netﬂix Prize
challenge, and collaborative ﬁltering in general, is an ideal
application for SVD, since the data is a matrix of ratings
given by users to movies.
It is thus not surprising to ob-
serve that most currently successful teams use SVD, either
with an extension, or to interpolate with results returned
by other algorithms. Unfortunately SVD can easily overﬁt
due to the extreme data sparsity of the matrix in the Net-
ﬂix Prize challenge, and care must be taken to regularize
properly.

In this paper, we propose a Bayesian approach to alleviate
overﬁtting in SVD, where priors are introduced and all pa-
rameters are integrated out using variational inference. We
show experimentally that this gives signiﬁcantly improved
results over vanilla SVD. For truncated SVDs of rank 5, 10,
20, and 30, our proposed Bayesian approach achieves 2.2%
improvement over a na¨ıve approach, 1.6% improvement over
a gradient descent approach dealing with unobserved entries
properly, and 0.9% improvement over a maximum a poste-
riori (MAP) approach.

Categories and Subject Descriptors
I.2.6 [Machine Learning]: Engineering applications—ap-
plications of techniques

General Terms
Experimentation, Algorithms

Keywords
Netﬂix Prize, machine learning, SVD, Variational Inference

Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for proﬁt or commercial advantage and that copies
bear this notice and the full citation on the ﬁrst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speciﬁc
permission and/or a fee.
KDDCup.07 August 12, 2007, San Jose, California, USA
Copyright 2007 ACM 978-1-59593-834-3/07/0008 ...$5.00.

1.

INTRODUCTION

The Netﬂix Prize [2] is a competition organized by Net-
ﬂix, an on-line movie subscription rental service, to create a
recommender system that predicts movie preferences based
on user rating history. For the competition, Netﬂix pro-
vides a large movie rating dataset consisting of over 100
million ratings (and their dates) from approximately 480,000
randomly-chosen users and 18,000 movies. The data were
collected between October, 1998 and December, 2005 and
represent the distribution of all ratings Netﬂix obtained dur-
ing this time period. Given this dataset, the task is to pre-
dict the actual ratings of over 3 million unseen ratings from
these same users over the same set of movies.

One common machine learning approach to this collabo-
rative ﬁltering problem is to represent the data as a sparse
I × J matrix M consisting of ratings given by the I users
to the J movies [5]. A low-rank decomposition of M is
then found, M ≈ U V >, where U ∈ RI×n, V ∈ RJ×n with
n (cid:28) I, J. The matrices U and V can be viewed as compact
and informative representations of the users and movies re-
spectively, and the predicted rating given by a user to a
movie is given by the corresponding entry in U V >.

Singular value decomposition (SVD) is a popular matrix
decomposition algorithm that returns such a low-rank de-
composition which is optimal in the sense of squared error.
Unfortunately SVD only works for fully observed matrices,
while extensions of SVD which can handle partially observed
matrices1 can easily overﬁt due to the extreme data spar-
sity of the matrix in the Netﬂix Prize competition, and care
must be taken to regularize properly.

In this paper, we propose a Bayesian approach to alleviate
overﬁtting in SVD. Priors are introduced and all parameters
are integrated out using Variational Bayesian inference [1].
Our technique can be eﬃciently implemented and has com-
parable run time and memory requirements to an eﬃciently
implemented SVD. We show experimentally that this gives
signiﬁcantly improved results over vanilla SVD.

The outline of this paper is as follows: Section 2 describes
the Netﬂix Prize and outlines the standard SVD-based ma-
trix decomposition techniques currently used in collabora-
tive ﬁltering problems. Next, we present a Bayesian formu-
lation for matrix decomposition and a maximum a posteriori
solution in Section 3. In Section 4, we derive and explain
our proposed Variational Bayesian approach. We then show
and discuss experimental results in Section 5. Finally, we
discuss a few related models in 6 and conclude in Section 7.

1In this paper we refer to these extensions for partially ob-
served matrices as SVD algorithms as well.

152. MATRIX DECOMPOSITION

2.2 Expectation Maximization

Netﬂix provides a partially observed rating matrix M with
observed entries having values between 1 and 5, inclusive.
M has I = 480, 189 rows, corresponding to users, and J =
17, 770 columns, corresponding to movies. There are K =
100, 480, 507 observed entries in M . As part of the train-
ing data, Netﬂix designated a set of 1,408,395 ratings to be
validation data. For all algorithms tested in this paper, we
withheld this validation set during training and used the
remaining data consisting of 99, 072, 112 entries as training
data. We then tested the RMSE based on predictions for
the validation data. In Section 7 we report our results on
the oﬃcial test set. As a baseline, Netﬂix’s own system,
Cinematch, achieved a RMSE of 0.9474 on the validation
data.
We are interested in the problem of ﬁnding a low-rank
approximation to M . That is, ﬁnd two matrices U ∈ RI×n
and V ∈ RJ×n, where n is small, such that M ≈ U V >.
Using the squared loss, we formulate this problem as one of
minimizing the objective function:
j − mij)2
>

X

f (U, V ) =

(uiv

(1)

(ij)

where (ij) ranges over pairs of user/movie indices such that
the user rated that movie in the training set, ui, vj are rows
of U and V , and mij is the i,j-th entry of M .
2.1 Singular Value Decomposition

Singular value decomposition (SVD) is an eﬃcient method
of ﬁnding the optimal solution to (1), for the case when
the rating matrix M is fully observed [8]. SVD works by
factorizing the fully observed matrix M into M = ˜U ˜Σ ˜V T ,
where ˜U is an I × I orthonormal matrix, ˜Σ is an I × J
diagonal matrix with non-negative and decreasing diagonal
entries and ˜V is a J × J orthonormal matrix. The non-
negative diagonal entries of ˜Σ are called the singular values
of M . Such a decomposition into ˜U , ˜Σ and ˜V is unique (up
to rotations of the corresponding columns of ˜U and ˜V if there
are identical singular values), and is called the singular value
decomposition of M . The singular values can be viewed as
the importance of the corresponding features (columns of ˜U
and ˜V ). A low-rank approximation to M can be obtained
by keeping only the top n singular values along with ﬁrst n
columns in ˜U and ˜V . Speciﬁcally, let U = ˜U1:I,1:n ˜Σ1:n,1:n
and V = ˜V1:J,1:n. Then it can be shown that the low-rank
approximation M ≈ U V > minimizes the objective (1).

The time complexity of the standard algorithm to com-
pute SVD is O(max(I 3, J 3)), which makes using it computa-
tionally infeasible with the size of the Netﬂix Prize dataset.
Fortunately, it is possible to approximate the rank-n SVD
with successive rank-1 updates in O(I × J × n) time [3]. As
rank-1 updates involve incrementally learning one column
c of M at a time, this also reduces space requirements to
storing a single column of M in main memory (as opposed
to the whole matrix M ) when computing the SVD. Thus an
optimal low-rank approximation can be eﬃciently computed
if the matrix M is fully observed.

The main issue with using such a vanilla SVD is that it
assumes a fully observed matrix M . In the next two sub-
section we review two baseline approaches to dealing with a
sparsely observed M , one based on EM, and another based
on directly optimizing (1) in a greedy fashion.

As the matrix M contains missing entries, standard SVD
needs to be adapted to handle missing values appropriately.
One method is to use a simple expectation-maximization
(EM) algorithm that ﬁlls in the missing values with pre-
dictions from the low-rank reconstruction from the previous
iteration [10].

Assume that we have an algorithm to compute optimal
(in terms of minimizing (1)) rank n decomposition of a com-
pletely observed matrix, say one which uses the rank n trun-
cation of an SVD. Call this algorithm SVDn. The EM ap-
proach uses SVDn to impute successively better estimates
of the missing matrix entries during training. Formally, we
introduce a I × J binary matrix W , where wij has value 1 if
mij is observed, and value 0 otherwise. The EM procedure
then iterates between the following until convergence:

X = W · M + (1 − W ) · ˜M (2)

E-Step :

M-Step :

[U, V ] = SVDn(X)

>

˜M = U V

(3)
where · is the Hadamard product given by (A· B)ij = aijbij.
2.3 Greedy Residual Fitting

Another popular approach which approximately minimizes
(1) when M is partially observed is to greedily ﬁt columns
of U and V iteratively. Speciﬁcally, if U0, V 0 is a rank n − 1
approximation to M , we obtain a rank n approximation
by ﬁtting a rank 1 approximation to the residual matrix
M − U0V 0>
, and appending the new columns to U0 and V 0
respectively. In this paper we ﬁnd the rank 1 approxima-
tion by minimizing (1) (plus a L2 regularization) by gradient
descent:

>

0
j

0
iv

δij := mij − u
uin := uin + α(δijvjn − λuin)
vjn := vjn + α(δijuin − λvjn)

(4)
(5)

(6)

where α is the step size and λ is the regularization parame-
ter. We iterate through (5) and (6) until a desired threshold
for convergence is reached. Then the newly found columns
un and vn are appended to U0 and V 0 respectively. We call
this method greedy residual ﬁtting (GRF).

3. BAYESIAN FORMULATION

We turn to statistical machine learning methods to per-
form regularization by introducing prior knowledge into our
model. In particular, we shall recast our objective function
(1) using a probabilistic model with entries of M being ob-
servations and U, V being parameters, and introduce regu-
larization via placing priors on the parameters. Speciﬁcally,
we place the following likelihood model on M :

mij|U, V ∼ N (uiv

>
j , τ 2)

(7)

for each observed entry (i, j) of M , where τ 2 is variance of
observation noise about the mean uiv>
j .

The probability density at mij is:

p(mij|U, V ) =

1√
2πτ 2

exp

(mij − uiv>
j )2

τ 2

− 1
2

(8)

 

!

We place independent priors on each entry in U and V ,
l ). so the densities of

l ) and vjl ∼ N (0, ρ2

say, uil ∼ N (0, σ2

16U and V are:

p(U ) =

p(V ) =

IY
JY

i=1

nY
nY

l=1

j=1

l=1

1p2πσ2
1p2πρ2

l

l

exp

exp

„
 

− 1
2

− 1
2

«
!

u2
il
σ2
l

v2
jl
ρ2
l

(9)

(10)

Note that the prior variances σ2
l depends on the column
l in U and V respectively. We will show how to optimize
these prior variances in a later section.

l , ρ2

This completes the model, and we now need to compute

or approximate the posterior:

p(U, V |M ) =

p(M|U, V )p(U )p(V )

p(M )

(11)

3.1 Maximum A Posteriori

The method of maximum a posteriori (MAP) estimation
can be used to obtain a point estimate of the posterior (11)
based on observed data. It is similar to maximum likelihood
(ML), but as the model incorporates a prior distribution,
MAP estimation can be seen as a regularization of ML es-
timation. MAP methods approximate the posterior by its
mode:

p(U, V |M ) ≈ arg max

U,V

p(M|U, V )p(U, V )

p(M )

(12)

In this paper, we simplify the approximation by assuming
that U and V are independent in the posterior before solving
(12). The eventual derivations turns out to be similar to our
derivations for VB inference (refer to Section 5.4).

4. VARIATIONAL BAYES

The variational free energy [1] of the model introduced in

Section 3 is deﬁned as:
F (Q(U, V )) = EQ(U,V )[log p(M, U, V ) − log Q(U, V )] (13)
The variational free energy can be shown to be a lower bound
on the log likelihood p(M ) for all distributions Q(U, V ),
since we have
F (Q(U, V )) = EQ(U,V )[log p(M ) + log p(U, V |M ) − log Q(U, V )]

= log p(M ) − KL(Q(U, V )kp(U, V |M )) ≤ log p(M )

(14)

(15)
where Eq[f (x)] is the expectation of the function f (x) with

respect to the distribution q(x) and KL(qkp) =R q(x) log q(x)

p(x) dx

and solve subject to R Q(U, V ) dU dV = 1. Noting that

is the Kullback-Leibler divergence from distribution q to dis-
tribution p and is always non-negative, being zero exactly
when q(x) = p(x) almost surely.
Maximizing the lower bound on log p(M ), note that the
optimum is achieved at Q(U, V ) = p(U, V |M ) the posterior.
To see this, simply diﬀerentiate (13) with respect to Q(U, V )
this is intractable in practice, we maximize F (Q(U, V )) sub-
ject to the variational approximation Q(U, V ) = Q(U )Q(V ).
This gives the variational approximate inference procedure.
We therefore see that while MAP estimation incorporates
a prior distribution, MAP estimates are only point esti-
mates, and does not account for variance and uncertainty
observed in the empirical data. On the other hand, VB

methods strive to avoid overﬁtting by taking into account
the whole posterior distribution.

Plugging in the model for p(M, U, V ), we have

F (Q(U )Q(V ))

=EQ(U )Q(V )

  JX
0@X

j=1

(ij)

− 1
2

− 1
2

  IX

nX

i=1

l=1

− 1
2

"
nX

l=1

log(2πρ2

l ) +

v2
jl
ρ2
l

log(2πσ2

l ) +

!

log(2πτ 2) +

(mij − u>
τ 2

i vj)2

− log Q(U ) − log Q(V )

!

u2
il
σ2
l

1A
nX

#
nX

l=1

= − K
2

log(2πτ 2) − I
2

 PI

log(2πσ2

log(2πρ2
l )

PJ

l ) − J
2
EQ(V )[v2
jl]
ρ2
l

j=1

l=1

!

i=1

EQ(U )[u2
il]
σ2
l

+

EQ(U )Q(V )[(mij − uiv>

j )2]

(ij)

τ 2

(16)

nX
X

l=1

− 1
2

− 1
2

To maximize F (Q(U )Q(V )) we optimize one keeping the
other ﬁxed, and iterate until convergence. To maximize
with respect to Q(U ) with Q(V ) held ﬁxed, we diﬀerenti-
ate F (Q(U )Q(V )) with respect to Q(U ) and solve for Q(U )
by setting the derivatives to 0 subject to the constraint that

exp

„

R Q(U ) dU = 1. This gives,
Q(U ) ∝ IY
1CCA +
0BB@
0BB@ 1
1A
0@ X

ui = Φi

− 1
2

mijvj

Φi =

. . .

1
σ2
n

σ2
1

i=1

0

0

(ui − ui)
>

j∈N (i)

τ 2

«

(ui − ui)

Ψj + vjvj

>

−1
i

Φ

X

j∈N (i)

τ 2

−1

1CCA

(17)

(18)

where N (i) is the set of j’s such that mij is observed, Φiis
the covariance of ui in Q(U ), ui is the mean of ui, Ψj is the
covariance of vj in Q(V ), and vj of vj.

Thus the optimal Q(U ) with Q(V ) ﬁxed is independent
across i, with Q(ui) being Gaussian with covariance Φi and
mean ui. Similarly one derives that:

Q(V ) ∝ JY

„

exp

j=1

(vj − vj)
>

Ψ

− 1
2

«
j (vj − vj)
−1

(19)

decomposes as independent distributions Q(vj) across j, with
Q(vj) being Gaussian with covariance and mean given by:

170BB@

Ψj =

vj = Ψj

ρ2
1

0BB@ 1
0@ X

0

. . .

i∈N (j)

0

1
ρ2
n

1CCA +
1A

X

Φi + uiui

>

i∈N (j)

τ 2

−1

1CCA

(20)

(21)

mijui

τ 2

This completes the derivation of the variational algorithm,
which simply iterates the updates (17), (18), (20) and (21)
until convergence.
4.1 Further Implementational Details

In summary, the variational algorithm iterates the follow-

ing until convergence:

1. Update Q(ui) for i = 1, . . . , I using (17) and (18).

2. Update Q(vj) for j = 1, . . . , J using (20) and (21).

The computation costs are as follows. For each step we
need to go through the observed ratings once. For each
user and each movie the dominating computation cost are
to collect the values of the matrix to be inverted, followed by
the matrix inversion itself. The time complexity is O(K +
I × n3 + J × n3), where K is the number of observed entries.
For small values of n, this is much more eﬃcient than SVD
which takes O(I × J × n) time.

The information that needs to be stored from iteration to
iteration are Φi, ui, Ψj and vj for each i and j. Note that the
storage size of Φi is unacceptable since there are > 400, 000
users, and each Φi is of size n × n. To mitigate this, we
instead opt to not store Φi at all. The idea is that as soon
as Φi and ui are computed, these are added to the matrix
needed to be inverted to compute Ψj and vj. After we add
this in, we need not store Φi anymore and can discard it.
The ﬁnal algorithm keeps track of Ψj, vj and ui (ui actually
need not be kept tracked of, but is useful when we want
to predict new ratings), and iterates through the following
until convergence:

1. Initialize Sj and tj for j = 1, . . . , J:

Sj ←

. . .

ρ2
1

0

0BB@ 1
0BB@ 1

σ2
1

0

0BB@

2. Update Q(ui) for i = 1, . . . , I:

(a) Compute Φi and ui:

Φi ←

. . .

0

1
ρ2
n

1CCA
1CCA +
0@ X

0

1
σ2
n

tj ← 0

Ψj + vjvj

>

τ 2

1A

−1

1CCA

X

j∈N (i)

ui ← Φi

mijvj

τ 2

j∈N (i)

(b) Update Sj and tj for j ∈ N (i), and discard Φi:
mijui

Φi + uiui

>

Sj ← Sj +

tj ← tj +

τ 2

τ 2

3. Update Q(vj) for j = 1, . . . , J:

Ψj ← S

−1
j

vj ← Ψjtj

Finally, at test time, we predict a previously unobserved

entry mij simply by uivj
4.2 Learning the Variances

>.

It is also important to try to learning the variances σ2

l , ρ2
l
and τ 2. This turns out to be easy. We simply diﬀerentiate
(16) with respect to these variances, set the derivatives to
zero, and solve for the optimal σ2
l and τ 2. These updates
are:

l , ρ2

i=1

IX
JX
X

j=1

(ij)

σ2
l =

1

I − 1

ρ2
l =

τ 2 =

1

J − 1
1

K − 1

(Φi)ll + uil

2

(Ψj)ll + vjl

2

ij − 2mijuivj
m2

>

(22)

(23)

(24)

where Tr is the trace operator and Tr(AB) = P

+ Tr[(Φi + uiui

)(Ψj + vjvj

>

>

)]

for two symmetric matrices A and B.

ij AijBij

l

l = 1

n while σ2

is initialized at σ2

Note that there is a degree of redundancy between U and
V . If we multiply a column of U by a factor a, and divide the
corresponding column of V by a, the result will be identical.
Thus to remove this degree of redundancy, we keep ρ2
l ﬁxed
with values ρ2
l = 1 and
allowed to be learned using (22). The reason for starting
with these initial values is because if we draw U and V from
the prior, then the variance of uiv>
j will be exactly 1. This
puts the parameters of the model in a regime where it will
behave reasonably. Similarly τ 2 should be initialized to 1.
It is possible that as the algorithm runs, the value of σ2
l
for some l might become very small. This should happen
when the algorithm decides that it does not have use for
the lth column of U , thus it sets it to zero. In such a case,
we can actually remove the lth column of U and V . This
is called automatic relevance determination (ARD) [7] and
provides computational savings - however, in our own usage
of the algorithm for low-rank matrix decompositions of up
to rank 100, this eﬀect never materialized.

5. EXPERIMENTS

In our actual entry to the Netﬂix Prize, we used VB in-
ference to compute rank 100 matrix decompositions. How-
ever, each of these decompositions required several days of
computation on a PowerMac Dual 1.8 Ghz, and we did not
have the necessary resources to repeat the same rank 100
matrix decomposition using the other algorithms. In order
to compare the performance of the algorithms, we decided
to perform low-rank matrix decompositions on the Netﬂix
Prize dataset.
5.1

Implementation Details

For the Netﬂix Prize, we implemented the techniques men-
tioned in earlier sections using Python and SciPy/Numpy.
The scipy.linalg.svd function was used to compute SVD
of matrices when needed.

18VB and MAP algorithms in later experiments - These single
iteration runs typically took a few hours to complete.
5.3

Initialization

As VB inference uses an approximation of the posterior
distribution, we have found that the initialization of U and
V prior to running VB inference can aﬀect both the con-
vergence speed and RMSE performance at convergence. We
tested the following ways of initializing U and V prior to
running VB inference - (1) Random Init - Draw samples of
U and V from uil ∼ N (0, 1) and vjl ∼ N (0, 1). (2) EM Init
- Initializing U and V by using the matrix decomposition
returned by one iteration of EM SVD. (3) GRF Init - Ini-
tialize U and V using the matrix decomposition returned by
GRF.

Figure 2: Comparisons of VB between initializing
randomly, initializing to EM SVD and initializing
to GRF. The x-axis shows the number of iterations
the algorithm was ran for, and the y-axis shows the
RMSE on validation data (lower is better).

Based on Figure 2, we can make the following observa-
tions: (1) All variants are able to achieve a RMSE better
than Cinematch and GRF. (2) Randomly initializing U and
V does not perform as well as initializing to EM SVD or
GRF in terms of convergence speed or RMSE at conver-

Figure 1: Performance of EM SVD vs VB Random
Init, GRF and Cinematch with rank 5 approxima-
tion. The x-axis shows the number of iterations
the algorithm was ran for, and the y-axis shows the
RMSE on validation data (lower is better).

For GRF, the feature values are initialized to 0.1, weights
are updated using a learning rate of 0.001 and the regular-
ization parameter λ is set to 0.015. We used publicly avail-
able source code2 that implements GRF. The algorithm up-
dates each set of feature values using (5) and (6) for at least
100 epochs, or the number of passes through the training
dataset. These updates continue until the improvement on
RMSE from the last iteration falls below 0.0001. The cur-
rent set of feature values are then ﬁxed and the algorithm
continues to the next set of feature values.
5.2 EM

We used EM SVD approach to obtain rank 5 matrix de-
compositions. We initialized the missing values of the rating
matrix in the ﬁrst iteration to vj + wi, where vj is the av-
erage rating for movie j, and wi is the average oﬀset from
movie averages that user i had given in the training data.

In Figure 1, we see that EM SVD had not converged af-
ter 40 iterations, and achieved a RMSE on the validation
set of 0.9583 after 40 iterations. This is higher than the
RMSEs achieved by Cinematch and GRF, which are 0.9474
and 0.9506, respectively. In contrast, our proposed method
of using VB inference, even when initialized randomly, con-
verged after less than 10 iterations and achieved a RMSE
that is better than both Cinematch and GRF. We expect
that EM SVD would overﬁt on the training set in the long
run as it performs no regularization.
As the EM SVD approach requires the complete matrix to
be ﬁlled up, the time complexity O(I×J ×n) is much higher
than the other methods described in this paper which only
need to train on observed data. In our rank 5 experiments,
EM SVD took 2 days of computing, VB inference required
only 2 hours to complete 40 iterations and GRF took less
than 30 minutes to complete.

Since the performance and time complexity of EM SVD
turned out to be inferior to our other techniques, we only
tested EM SVD approach in our rank 5 matrix factorizations
experiments, and do not compute EM SVD in subsequent
experiments with larger rank matrix decompositions. How-
ever, we run EM SVD once to obtain an initialization for

2http://www.timelydevelopment.com/Demos/
NetflixPrize.htm

0.9350.9450.9550.9650.9750.9850.9951.0051.0151.0251.0351.0451.0551.0651.0751.0851.0950510152025303540IterationRMSEEM SVDGRFCinematchVB Random Init0.9350.940.9450.950.9550510152025303540IterationRMSEVB Random InitVB GRF InitVB EM InitCinematch0.920.9250.930.9350.940.9450.9505101520253035404550IterationRMSEVB Random InitVB GRF InitVB EM InitGRFCinematch0.9150.920.9250.930.9350.940.9450.950.95505101520253035404550IterationRMSEVB Random InitVB GRF InitVB EM InitGRFCinematch0.910.9150.920.9250.930.9350.940.9450.950.9550.9605101520253035404550IterationRMSEVB Random InitVB GRF InitVB EM InitGRFCinematchGRFRank 5Rank 10Rank 20Rank 3019gence. (3) VB inference appears to converge quickly (within
10 iterations) if initialized using EM SVD or GRF and does
not exhibit any overﬁtting. (4) Initializing to GRF appears
to be better in terms of convergence speed (for rank 10, 20
and 30 matrix decompositions). (5) Initializing using EM
SVD and GRF have the same RMSE performance at con-
vergence (although initializing to EM SVD seems to produce
very slightly better RMSE at convergence). Based on these
observations, and the fact that GRF is more computation-
ally eﬃcient than one iteration of EM SVD, we recommend
initializing VB inference with GRF. However in later exper-
iments we used EM SVD initialization instead; as observed
above the resulting RMSE at convergence is virtually indis-
tinguishable from GRF initialization.
5.4 MAP

To show that the eﬀectiveness of VB inference is not just
due to the priors introduced in our model, we compared it
to a method of MAP estimation.
In our experiments, we
used the same program for VB inference to compute MAP
estimates, except that the covariances Ψi and Φj in (17)
and (20), respectively, are set to zero. The hyperparameters
σ2
l and τ 2 are set to the values learnt by VB inference.
l , ρ2
We had also investigated learning these hyperparameters di-
rectly but found that it produced similar results as setting
the hyperparameters to the VB learned values.

Similar to our experiments with VB inference, we explored
various ways of initializing U and V prior to running MAP
- (1) Random Init - Draw samples of U and V from uil ∼
N (0, 1) and vjl ∼ N (0, 1). (2) EM Init - Initializing U and V
by using one iteration of EM SVD. (3) GRF Init - Initialize
U and V using the matrix decomposition returned by GRF.
In Figure 3, we see that MAP has much more local op-
tima issues compared to VB inference as diﬀerent initial-
izations converge to diﬀerent local optima. For example,
when initialized to EM SVD or GRF, VB inference consis-
tently converges to local optima which are better than local
optima reached when initialized randomly. On the other
hand, MAP initialized to GRF performs better compared
to randomly initializing for rank 5 and 10, whereas it per-
forms worse than random initialization for rank 20 and 30.
MAP also appears to converge much slower than VB and
requires many more iterations before reaching local optima.
Another observation we can draw from Figure 3 is that
MAP manifests overﬁtting problems while VB inference does
not. This is because the RMSEs on the validation data do
not decrease monotonically. Figure 4 shows RMSE on both
training and validation data when using MAP initialized to
EM SVD. We clearly see that while RMSE on training data
is decreasing, RMSE on validation data does not monoton-
ically decrease. In contrast, when using VB inference ini-
tialized to EM SVD, RMSE on both training and validation
data decrease monotonically.
5.5 Performance Comparisons

We also compared the performance of the various algo-
rithms at convergence for rank 5, 10, 20 and 30 matrix
decompositions. For VB inference, we used the U and V
from the last iteration of VB initialized using EM SVD. For
MAP inference, we used the U and V which achieved the
best RMSE on the validation set over all iterations and when
initialized randomly, using EM SVD and using GRF. Note
that this way of choosing U and V gives unfairly good re-

Figure 3: Comparisons of MAP between initializing
randomly, initializing to EM SVD and initializing
to GRF. The x-axis shows the number of iterations
the algorithm was ran for, and the y-axis shows the
RMSE on validation data (lower is better).

Figure 4: RMSE on training and validation data
when using MAP and VB on rank 30 matrix decom-
positions initialized to EM SVD (lower is better).

sults for MAP. However we see that even this best possible
MAP result is worse than the result we obtained using VB
inference at convergence.

0.9350.940.9450.950.9550510152025303540IterationRMSE0.920.9250.930.9350.940.9450.9505101520253035404550IterationRMSEVB EM InitCinematchMAP EM InitMAP GRF InitMAP Random InitVB EM InitGRFCinematchMAP EM InitMAP GRF InitMAP Random Init0.9150.920.9250.930.9350.940.9450.950.95505101520253035404550IterationRMSE0.910.920.930.940.950.960.970.9805101520253035404550IterationRMSEGRFVB EM InitMAP GRF InitGRFMAP Random InitCinematchMAP EM InitGRFVB EM InitMAP Random InitCinematchMAP EM InitMAP GRF InitRank 5Rank 10Rank 20Rank 300.70.750.80.850.90.95105101520253035404550IterationRMSEMAP TrainingMAP ValidationVB ValidationVB Training20Algorithm RMSE VB Improvement
Cinematch

Rank

Rank 5

Rank 10

Rank 20

Rank 30

Cinematch

0.9474
EM SVD 0.9583
GRF 0.9506
MAP 0.9389
VB 0.9367
0.9474
GRF 0.9398
MAP 0.9291
VB 0.9242
0.9474
GRF 0.9314
MAP 0.9238
VB 0.9168
0.9474
GRF 0.9273
MAP 0.9227
VB 0.9141

1.13%
2.26%
1.46%
0.24%

-

2.45%
1.66%
0.53%

-

3.23%
1.57%
0.76%

-

3.52%
1.43%
0.94%

-

Cinematch

Cinematch

Table 1: Comparison of RMSEs achieved by all algo-
rithms for matrix decompositions of diﬀerent ranks.

The results are shown in Table 1. Firstly we see that VB
inference consistently outperforms MAP, GRF, EM SVD
and Cinematch, with the amount of improvement of VB
over the other algorithms increasing as the rank increases.
We believe this is because the other algorithms become more
prone to overﬁtting as the rank increases, while as we had
seen previously VB is not prone to overﬁtting. The best im-
provement VB gives over EM SVD is 2.26% (Rank 5), over
GRF is 1.66% (Rank 10), and over MAP is 0.94% (Rank
30). We emphasize that the performance gain of VB infer-
ence over MAP is artiﬁcially low as we had purposely picked
the best possible U and V in hindsight.

6. RELATED WORK

In addition to low-rank decompositions, there are other

approaches to collaborative ﬁltering. [5] gives a good overview
of a variety of approaches. One popular alternative to solv-
ing collaborative ﬁltering problems is to cluster the users
and/or movies into groups. Ratings can then be predicted
based on how a user group would typically rate a movie
group. Such alternatives represent users and/or movies us-
ing discrete clusterings. Instead of clustering, [6] represented
users and movies using binary vectors instead, where each
feature can represent diﬀerent aspects of movies and whether
a user likes that aspect of a movie. This is a distributed rep-
resentation and can be a much richer representation than
clustering. Low-rank decompositions can also be viewed as
distributed representations of users and movies, where each
feature is a continuous value instead of binary as in [6].

Another approach to low-rank decompositions is maxi-
mum margin matrix factorization (MMMF) [9]. MMMF
has been shown to give state-of-the-art results for collabo-
rative ﬁltering problems. Though still slower than SVD and
related approaches (e.g. our VB inference approach), [4] has
described an eﬃcient implementation which appears to be
applicable to the Netﬂix Prize dataset. As future work we
would like to implement MMMF, to both compare against
our VB inference approach as well as to interpolate the two
approaches, hopefully producing better results.

7. CONCLUSION

In this paper, we described and discussed the shortcom-
ings of SVD and various matrix decomposition techniques.
We propose a Variational Bayesian Inference technique to al-
leviate overﬁtting in SVD, where priors are introduced and
all parameters are integrated out using variational inference.
We implemented and tested these algorithms on the Net-
ﬂix Prize dataset to show experimentally that our technique
gives signiﬁcantly improved results over other matrix decom-
position techniques. For low-rank matrix decompositions
of rank 5, 10, 20 and 30, our proposed Bayesian approach
achieves 2.26% improvement over an EM SVD approach,
1.66% improvement over a GRF approach, and 0.94% im-
provement over a MAP approach. As we expect VB infer-
ence to be more robust against overﬁtting, it should perform
signiﬁcantly better than GRF or MAP for larger rank ma-
trix decompositions.

For our entry in the actual Netﬂix Prize competition, we
used VB inference to compute the rank 100 matrix decom-
position of the original rating matrix and a zero-centered
rating matrix (by subtracting vj + wi, where vj is the av-
erage rating for movie j, and wi is the average oﬀset from
movie averages that user i had given in the training data).
Both methods achieved results approximately 4.5% better
than Cinematch, and blending these two results achieves
slightly better than 5.5% improvement over Cinematch on
the qualifying data.

8. REFERENCES
[1] M. J. Beal. Variational algorithms for approximate
Bayesian Inference. PhD thesis, University College
London, May 2003.

[2] J. Bennett and S. Lanning. The Netﬂix Prize. In

Proceedings of KDD Cup and Workshop 2007, San
Jose, CA, USA, Aug 2007.

[3] M. Brand. Fast online SVD revisions for lightweight

recommender systems. In Proceedings of the Third
SIAM International Conference on Data Mining, 2003.
[4] D. DeCoste. Collaborative prediction using ensembles
of maximum margin matrix factorizations. In ICML,
pages 249–256. ACM, 2006.

[5] B. Marlin. Collaborative ﬁltering: A machine learning

perspective. Master’s thesis, University of Toronto,
Canada, 2004.

[6] E. Meeds, Z. Ghahramani, R. Neal, and S. Roweis.
Modeling dyadic data with binary latent factors. In
Advances in Neural Information Processing Systems,
2007.

[7] R. M. Neal. Assessing relevance determination

methods using DELVE generalization. In Neural
Networks and Machine Learning, pages 97–129.
Springer-Verlag, 1998.

[8] W. Press, B. Flannery, S. Teukolsky, and

W. Vetterling. Numerical Recipes in C. Cambridge
University Press, 1992.

[9] J. D. M. Rennie and N. Srebro. Fast maximum margin

matrix factorization for collaborative prediction. In
ICML, pages 713–719. ACM, 2005.

[10] N. Srebro and T. Jaakkola. Weighted low-rank

approximations. In T. Fawcett and N. Mishra, editors,
ICML, pages 720–727. AAAI Press, 2003.

21