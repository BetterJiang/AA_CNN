Foundations and Trends R(cid:1) in
Machine Learning
Vol. 1, Nos. 1–2 (2008) 1–305
c(cid:1) 2008 M. J. Wainwright and M. I. Jordan
DOI: 10.1561/2200000001

Graphical Models, Exponential Families, and

Variational Inference

Martin J. Wainwright1 and Michael I. Jordan2

1 Department of Statistics, and Department of Electrical Engineering and

Computer Science, University of California, Berkeley 94720, USA,
wainwrig@stat.berkeley.edu

2 Department of Statistics, and Department of Electrical Engineering and

Computer Science, University of California, Berkeley 94720, USA,
jordan@stat.berkeley.edu

Abstract

The formalism of probabilistic graphical models provides a unifying
framework for capturing complex dependencies among random
variables, and building large-scale multivariate statistical models.
Graphical models have become a focus of research in many statisti-
cal, computational and mathematical ﬁelds, including bioinformatics,
communication theory, statistical physics, combinatorial optimiza-
tion, signal and image processing, information retrieval and statistical
machine learning. Many problems that arise in speciﬁc instances —
including the key problems of computing marginals and modes of
probability distributions — are best studied in the general setting.
Working with exponential family representations, and exploiting the
conjugate duality between the cumulant function and the entropy
for exponential families, we develop general variational representa-
tions of the problems of computing likelihoods, marginal probabili-
ties and most probable conﬁgurations. We describe how a wide variety

of algorithms — among them sum-product, cluster variational meth-
ods, expectation-propagation, mean ﬁeld methods, max-product and
linear programming relaxation, as well as conic programming relax-
ations — can all be understood in terms of exact or approximate forms
of these variational representations. The variational approach provides
a complementary alternative to Markov chain Monte Carlo as a general
source of approximation methods for inference in large-scale statistical
models.

1

Introduction

Graphical models bring together graph theory and probability theory
in a powerful formalism for multivariate statistical modeling. In vari-
ous applied ﬁelds including bioinformatics, speech processing, image
processing and control theory, statistical models have long been for-
mulated in terms of graphs, and algorithms for computing basic statis-
tical quantities such as likelihoods and score functions have often been
expressed in terms of recursions operating on these graphs; examples
include phylogenies, pedigrees, hidden Markov models, Markov random
ﬁelds, and Kalman ﬁlters. These ideas can be understood, uniﬁed, and
generalized within the formalism of graphical models. Indeed, graphi-
cal models provide a natural tool for formulating variations on these
classical architectures, as well as for exploring entirely new families of
statistical models. Accordingly, in ﬁelds that involve the study of large
numbers of interacting variables, graphical models are increasingly in
evidence.

Graph theory plays an important role in many computationally ori-
ented ﬁelds, including combinatorial optimization, statistical physics,
and economics. Beyond its use as a language for formulating models,
graph theory also plays a fundamental role in assessing computational

3

4 Introduction

complexity and feasibility. In particular, the running time of an algo-
rithm or the magnitude of an error bound can often be characterized
in terms of structural properties of a graph. This statement is also true
in the context of graphical models. Indeed, as we discuss, the com-
putational complexity of a fundamental method known as the junction
tree algorithm — which generalizes many of the recursive algorithms on
graphs cited above — can be characterized in terms of a natural graph-
theoretic measure of interaction among variables. For suitably sparse
graphs, the junction tree algorithm provides a systematic solution to
the problem of computing likelihoods and other statistical quantities
associated with a graphical model.

Unfortunately, many graphical models of practical interest are not
“suitably sparse,” so that the junction tree algorithm no longer provides
a viable computational framework. One popular source of methods for
attempting to cope with such cases is the Markov chain Monte Carlo
(MCMC) framework, and indeed there is a signiﬁcant literature on the
application of MCMC methods to graphical models [e.g., 28, 93, 202].
Our focus in this survey is rather diﬀerent: we present an alternative
computational methodology for statistical inference that is based on
variational methods. These techniques provide a general class of alter-
natives to MCMC, and have applications outside of the graphical model
framework. As we will see, however, they are particularly natural in
their application to graphical models, due to their relationships with
the structural properties of graphs.

The phrase “variational” itself is an umbrella term that refers to var-
ious mathematical tools for optimization-based formulations of prob-
lems, as well as associated techniques for their solution. The general
idea is to express a quantity of interest as the solution of an opti-
mization problem. The optimization problem can then be “relaxed”
in various ways, either by approximating the function to be optimized
or by approximating the set over which the optimization takes place.
Such relaxations, in turn, provide a means of approximating the original
quantity of interest.

The roots of both MCMC methods and variational methods lie
in statistical physics. Indeed, the successful deployment of MCMC
methods in statistical physics motivated and predated their entry into

5

statistics. However, the development of MCMC methodology specif-
ically designed for statistical problems has played an important role
in sparking widespread application of such methods in statistics [88].
A similar development in the case of variational methodology would be
of signiﬁcant interest. In our view, the most promising avenue toward
a variational methodology tuned to statistics is to build on existing
links between variational analysis and the exponential family of distri-
butions [4, 11, 43, 74]. Indeed, the notions of convexity that lie at the
heart of the statistical theory of the exponential family have immediate
implications for the design of variational relaxations. Moreover, these
variational relaxations have particularly interesting algorithmic conse-
quences in the setting of graphical models, where they again lead to
recursions on graphs.

Thus, we present a story with three interrelated themes. We begin
in Section 2 with a discussion of graphical models, providing both an
overview of the general mathematical framework, and also presenting
several speciﬁc examples. All of these examples, as well as the majority
of current applications of graphical models, involve distributions in the
exponential family. Accordingly, Section 3 is devoted to a discussion
of exponential families, focusing on the mathematical links to convex
analysis, and thus anticipating our development of variational meth-
ods. In particular, the principal object of interest in our exposition
is a certain conjugate dual relation associated with exponential fam-
ilies. From this foundation of conjugate duality, we develop a gen-
eral variational representation for computing likelihoods and marginal
probabilities in exponential families. Subsequent sections are devoted
to the exploration of various instantiations of this variational princi-
ple, both in exact and approximate forms, which in turn yield various
algorithms for computing exact and approximate marginal probabili-
ties, respectively. In Section 4, we discuss the connection between the
Bethe approximation and the sum-product algorithm, including both
its exact form for trees and approximate form for graphs with cycles.
We also develop the connections between Bethe-like approximations
and other algorithms, including generalized sum-product, expectation-
propagation and related moment-matching methods. In Section 5, we
discuss the class of mean ﬁeld methods, which arise from a qualitatively

6 Introduction

diﬀerent approximation to the exact variational principle, with the
added beneﬁt of generating lower bounds on the likelihood. In Section 6,
we discuss the role of variational methods in parameter estimation,
including both the fully observed and partially observed cases, as well
as both frequentist and Bayesian settings. Both Bethe-type and mean
ﬁeld methods are based on nonconvex optimization problems, which
typically have multiple solutions. In contrast, Section 7 discusses vari-
ational methods based on convex relaxations of the exact variational
principle, many of which are also guaranteed to yield upper bounds on
the log likelihood. Section 8 is devoted to the problem of mode compu-
tation, with particular emphasis on the case of discrete random vari-
ables, in which context computing the mode requires solving an integer
programming problem. We develop connections between (reweighted)
max-product algorithms and hierarchies of linear programming relax-
ations. In Section 9, we discuss the broader class of conic programming
relaxations, and show how they can be understood in terms of semidef-
inite constraints imposed via moment matrices. We conclude with a
discussion in Section 10.

The scope of this survey is limited in the following sense: given a dis-
tribution represented as a graphical model, we are concerned with the
problem of computing marginal probabilities (including likelihoods), as
well as the problem of computing modes. We refer to such computa-
tional tasks as problems of “probabilistic inference,” or “inference” for
short. As with presentations of MCMC methods, such a limited focus
may appear to aim most directly at applications in Bayesian statis-
tics. While Bayesian statistics is indeed a natural terrain for deploying
many of the methods that we present here, we see these methods as
having applications throughout statistics, within both the frequentist
and Bayesian paradigms, and we indicate some of these applications at
various junctures in the survey.

2

Background

We begin with background on graphical models. The key idea is that of
factorization: a graphical model consists of a collection of probability
distributions that factorize according to the structure of an underly-
ing graph. Here, we are using the terminology “distribution” loosely;
our notation p should be understood as a mass function (density with
respect to counting measure) in the discrete case, and a density with
respect to Lebesgue measure in the continuous case. Our focus in this
section is the interplay between probabilistic notions such as conditional
independence on one hand, and on the other hand, graph-theoretic
notions such as cliques and separation.

2.1 Probability Distributions on Graphs

We begin by describing the various types of graphical formalisms that
are useful. A graph G = (V, E) is formed by a collection of vertices
V = {1,2, . . . , m}, and a collection of edges E ⊂ V × V . Each edge con-
sists of a pair of vertices s, t ∈ E, and may either be undirected, in
which case there is no distinction between edge (s, t) and edge (t, s), or
directed, in which case we write (s → t) to indicate the direction. See
Appendix A.1 for more background on graphs and their properties.

7

8 Background

In order to deﬁne a graphical model, we associate with each vertex
s ∈ V a random variable Xs taking values in some space Xs. Depend-
ing on the application, this state space Xs may either be continuous,
(e.g., Xs = R) or discrete (e.g., Xs = {0,1, . . . , r − 1}). We use lower-
case letters (e.g., xs ∈ Xs) to denote particular elements of Xs, so that
the notation {Xs = xs} corresponds to the event that the random
variable Xs takes the value xs ∈ Xs. For any subset A of the vertex
set V , we deﬁne the subvector XA := (Xs, s ∈ A), with the notation
xA := (xs, s ∈ A) corresponding to the analogous quantity for values
of the random vector XA. Similarly, we deﬁne ⊗s∈AXs to be the Carte-
sian product of the state spaces for each of the elements of XA.

2.1.1 Directed Graphical Models
Given a directed graph with edges (s → t), we say that t is a child of
s, or conversely, that s is a parent of t. For any vertex s ∈ V , let π(s)
denote the set of all parents of given node s ∈ V . (If a vertex s has
no parents, then the set π(s) should be understood to be empty.) A
directed cycle is a sequence (s1, s2, . . . , sk) such that (si → si+1) ∈ E for
all i = 1, . . . , k − 1, and (sk → s1) ∈ E. See Figure 2.1 for an illustration
of these concepts.

Now suppose that G is a directed acyclic graph (DAG), meaning
that every edge is directed, and that the graph contains no directed

Fig. 2.1 (a) A simple directed graphical model with four variables (X1, X2, X3, X4). Vertices
{1,2,3} are all parents of vertex 4, written π(4) = {1,2,3}. (b) A more complicated directed
acyclic graph (DAG) that deﬁnes a partial order on its vertices. Note that vertex 6 is a child
of vertex 2, and vertex 1 is an ancestor of 6. (c) A forbidden directed graph (nonacyclic)
that includes the directed cycle (2 → 4 → 5 → 2).

2.1 Probability Distributions on Graphs

9

cycles. For any such DAG, we can deﬁne a partial order on the vertex
set V by the notion of ancestry: we say that node s is an ancestor of u
if there is a directed path (s, t1, t2, . . . , tk, u) (see Figure 2.1(b)). Given
a DAG, for each vertex s and its parent set π(s), let ps(xs | xπ(s))
denote a nonnegative function over the variables (xs, xπ(s)), normalized
ps(xs | xπ(s))dxs = 1. In terms of these local functions, a
such that
directed graphical model consists of a collection of probability distribu-
tions (densities or mass functions) that factorize in the following way:

(cid:1)

p(x1, x2, . . . , xm) =

ps(xs | xπ(s)).

(2.1)

(cid:2)

s∈V

It can be veriﬁed that our use of notation is consistent,
in that
in fact, the conditional probability of {Xs = xs}
ps(xs | xπ(s)) is,
given {Xπ(s) = xπ(s)} for the distribution p(·) deﬁned by the factor-
ization (2.1). This follows by an inductive argument that makes use of
the normalization condition imposed on ps(·), and the partial ordering
induced by the ancestor relationship of the DAG.

2.1.2 Undirected Graphical Models

In the undirected case, the probability distribution factorizes according
to functions deﬁned on the cliques of the graph. A clique C is a fully
connected subset of the vertex set V , meaning that (s, t) ∈ E for all
s, t ∈ C. Let us associate with each clique C a compatibility function
ψC : (⊗s∈CXs) → R+. Recall that ⊗s∈CXs denotes the Cartesian prod-
uct of the state spaces of the random vector XC. Consequently, the
compatibility function ψC is a local quantity, deﬁned only for elements
xC within the clique.

With this notation, an undirected graphical model — also known as
a Markov random ﬁeld (MRF), or a Gibbs distribution — is a collection
of distributions that factorize as

p(x1, x2, . . . , xm) =

1
Z

ψC(xC),

(2.2)

(cid:2)

C∈C

where Z is a constant chosen to ensure that the distribution is nor-
malized. The set C is often taken to be the set of all maximal cliques
of the graph, i.e., the set of cliques that are not properly contained

10 Background

within any other clique. This condition can be imposed without loss
of generality, because any representation based on nonmaximal cliques
can always be converted to one based on maximal cliques by redeﬁn-
ing the compatibility function on a maximal clique to be the product
over the compatibility functions on the subsets of that clique. How-
ever, there may be computational beneﬁts to using a nonmaximal rep-
resentation — in particular, algorithms may be able to exploit speciﬁc
features of the factorization special to the nonmaximal representation.
For this reason, we do not necessarily restrict compatibility functions
to maximal cliques only, but instead deﬁne the set C to contain all
cliques. (Factor graphs, discussed in the following section, allow for a
ﬁner-grained speciﬁcation of factorization properties.)

It is important to understand that for a general undirected graph
the compatibility functions ψC need not have any obvious or direct
relation to marginal or conditional distributions deﬁned over the graph
cliques. This property should be contrasted with the directed factor-
ization (2.1), where the factors correspond to conditional probabilities
over the child-parent sets.

2.1.3 Factor Graphs

For large graphs, the factorization properties of a graphical model,
whether undirected or directed, may be diﬃcult to visualize from the
usual depictions of graphs. The formalism of factor graphs provides an
alternative graphical representation, one which emphasizes the factor-
ization of the distribution [143, 157].

Let F represent an index set for the set of factors deﬁning a graph-
ical model distribution. In the undirected case, this set indexes the
collection C of cliques, while in the directed case F indexes the set
of parent–child neighborhoods. We then consider a bipartite graph
(cid:4) = (V, F, E
(cid:4) is a new
(cid:4)), where V is the original set of vertices, and E
G
edge set, joining only vertices s ∈ V to factors a ∈ F . In particular,
edge (s, a) ∈ E
(cid:4) if and only if xs participates in the factor indexed by
a ∈ F . See Figure 2.2(b) for an illustration.
For undirected models, the factor graph representation is of partic-
ular value when C consists of more than the maximal cliques. Indeed,
the compatibility functions for the nonmaximal cliques do not have

2.2 Conditional Independence

11

(a)

(b)

Fig. 2.2 Illustration of undirected graphical models and factor graphs. (a) An undirected
graph on m = 7 vertices, with maximal cliques {1,2,3,4}, {4,5,6}, and {6,7}. (b) Equiv-
alent representation of the undirected graph in (a) as a factor graph, assuming that we
deﬁne compatibility functions only on the maximal cliques in (a). The factor graph is a
bipartite graph with vertex set V = {1, . . . ,7} and factor set F = {a, b, c}, one for each of
the compatibility functions of the original undirected graph.

an explicit representation in the usual representation of an undirected
graph — however, the factor graph makes them explicit.

2.2 Conditional Independence

Families of probability distributions as deﬁned as in Equations (2.1)
or (2.2) also have a characterization in terms of conditional indepen-
dencies among subsets of random variables — the Markov properties
of the graphical model. We only touch upon this characterization here,
as it is not needed in the remainder of the survey; for a full treatment,
we refer the interested reader to Lauritzen [153].

For undirected graphical models, conditional independence is iden-
tiﬁed with the graph-theoretic notion of reachability. In particular, let
A, B, and C be an arbitrary triple of mutually disjoint subsets of ver-
tices. Let us stipulate that XA be independent of XB given XC if there
is no path from a vertex in A to a vertex in B when we remove the
vertices C from the graph. Ranging over all possible choices of subsets
A, B, and C gives rise to a list of conditional independence assertions.
It can be shown that this list is always consistent (i.e., there exist prob-
ability distributions that satisfy all of these assertions); moreover, the
set of probability distributions that satisfy these assertions is exactly
the set of distributions deﬁned by (2.2) ranging over all possible choices
of compatibility functions.

12 Background

Thus, there are two equivalent characterizations of the family of
probability distributions associated with an undirected graph. This
equivalence is a fundamental mathematical result, linking an alge-
braic concept (factorization) and a graph-theoretic concept (reachabil-
ity). This result also has algorithmic consequences, in that it reduces
the problem of assessing conditional independence to the problem of
assessing reachability on a graph, which is readily solved using simple
breadth-ﬁrst search algorithms [56].

An analogous result holds in the case of directed graphical models,
with the only alteration being a diﬀerent notion of reachability [153].
Once again, it is possible to establish an equivalence between the
set of probability distributions speciﬁed by the directed factoriza-
tion (2.1), and that deﬁned in terms of a set of conditional independence
assertions.

2.3 Statistical Inference and Exact Algorithms

Given a probability distribution p deﬁned by a graphical model, our
focus will be solving one or more of the following computational infer-
ence problems:

(a) Computing the likelihood of observed data.
(b) Computing the marginal distribution p(xA) over a partic-
ular subset A ⊂ V of nodes.
(c) Computing the conditional distribution p(xA | xB), for dis-
joint subsets A and B, where A ∪ B is in general a proper
(d) Computing a mode of the density (i.e., an element(cid:3)x in the
subset of V .

set arg maxx∈X m p(x)).

Clearly problem (a) is a special case of problem (b). The computation
of a conditional probability in (c) is similar in that it also requires
marginalization steps, an initial one to obtain the numerator p(xA, xB),
and a further step to obtain the denominator p(xB). In contrast, the
problem of computing modes stated in (d) is fundamentally diﬀerent,
since it entails maximization rather than integration. Nonetheless, our
variational development in the sequel will highlight some important

2.4 Applications

13

connections between the problem of computing marginals and that of
computing modes.
To understand the challenges inherent in these inference prob-
lems, consider the case of a discrete random vector x ∈ X m, where
Xs = {0,1, . . . , r − 1} for each vertex s ∈ V . A naive approach to com-
puting a marginal at a single node — say p(xs) — entails summing
s = xs}. Since this set
(cid:4) ∈ X m | x
over all conﬁgurations of the form {x
(cid:4)
has rm−1 elements, it is clear that a brute force approach will rapidly
become intractable. Even with binary variables (r = 2) and a graph
with m ≈ 100 nodes (a small size for many applications), this summa-
tion is beyond the reach of brute-force computation. Similarly, in this
discrete case, computing a mode entails solving an integer programming
problem over an exponential number of conﬁgurations. For continuous
random vectors, the problems are no easier1 and typically harder, since
they require computing a large number of integrals.

For undirected graphs without cycles or for directed graphs in which
each node has a single parent — known generically as trees in either
case — these inference problems can be solved exactly by recursive
“message-passing” algorithms of a dynamic programming nature, with
a computational complexity that scales only linearly in the number of
nodes. In particular, for the case of computing marginals, the dynamic
programming solution takes the form of a general algorithm known
as the sum-product algorithm, whereas for the problem of comput-
ing modes it takes the form of an analogous algorithm known as the
max-product algorithm. We describe these algorithms in Section 2.5.1.
More generally, as we discuss in Section 2.5.2, the junction tree algo-
rithm provides a solution to inference problems for arbitrary graphs.
The junction tree algorithm has a computational complexity that is
exponential in a quantity known as the treewidth of the graph.

2.4 Applications

Before turning to these algorithmic issues, however, it is helpful to
ground the discussion by considering some examples of applications of

1 The Gaussian case is an important exception to this statement.

14 Background

graphical models. We present examples of the use of graphical models in
the general areas of Bayesian hierarchical modeling, contingency table
analysis, and combinatorial optimization and satisﬁability, as well spe-
ciﬁc examples in bioinformatics, speech and language processing, image
processing, spatial statistics, communication and coding theory.

2.4.1 Hierarchical Bayesian Models

The Bayesian framework treats all model quantities — observed data,
latent variables, parameters, nuisance variables — as random variables.
Thus, in a graphical model representation of a Bayesian model, all such
variables appear explicitly as vertices in the graph. The general com-
putational machinery associated with graphical models applies directly
to Bayesian computations of quantities such as marginal likelihoods
and posterior probabilities of parameters. Although Bayesian models
can be represented using either directed or undirected graphs, it is the
directed formalism that is most commonly encountered in practice. In
particular, in hierarchical Bayesian models, the speciﬁcation of prior
distributions generally involves additional parameters known as hyper-
parameters, and the overall model is speciﬁed as a set of conditional
probabilities linking hyperparameters, parameters and data. Taking the
product of such conditional probability distributions deﬁnes the joint
probability; this factorization is simply a particular instance of Equa-
tion (2.1).

There are several advantages to treating a hierarchical Bayesian
model as a directed graphical model. First, hierarchical models are often
speciﬁed by making various assertions of conditional independence.
These assertions imply other conditional independence relationships,
and the reachability algorithms (mentioned in Section 2.1) provide a
systematic method for investigating all such relationships. Second, the
visualization provided by the graph can be useful both for understand-
ing the model (including the basic step of verifying that the graph is
acyclic), as well for exploring extensions. Finally, general computational
methods such as MCMC and variational inference algorithms can be
implemented for general graphical models, and hence apply to hier-
archical models in graphical form. These advantages and others have

2.4 Applications

15

led to the development of general software programs for specifying and
manipulating hierarchical Bayesian models via the directed graphical
model formalism [93].

2.4.2 Contingency Table Analysis

Contingency tables are a central tool in categorical data analysis [1, 80,
151], dating back to the seminal work of Pearson, Yule, and Fisher. An
m-dimensional contingency table with r levels describes a probability
distribution over m random variables (X1, . . . , Xm), each of which takes
one of r possible values. For the special case m = 2, a contingency table
with r levels is simply a r × r matrix of nonnegative elements summing
to one, whereas for m > 2, it is a multi-dimensional array with rm
nonnegative entries summing to one. Thus, the table fully speciﬁes a
probability distribution over a random vector (X1, . . . , Xm), where each
Xs takes one of r possible values.

Contingency tables can be modeled within the framework of graph-
ical models, and graphs provide a useful visualization of many natural
questions. For instance, one central question in contingency table anal-
ysis is distinguishing diﬀerent orders of interaction in the data. As a
concrete example, given m = 3 variables, a simple question is testing
whether or not the three variables are independent. From a graph-
ical model perspective, this test amounts to distinguishing whether
the associated interaction graph is completely disconnected or not (see
panels (a) and (b) in Figure 2.3). A more subtle test is to distinguish
whether the random variables interact in only a pairwise manner (i.e.,
with factors ψ12, ψ13, and ψ23 in Equation (2.2)), or if there is actually
a three-way interaction (i.e., a term ψ123 in the factorization (2.2)).
Interestingly, these two factorization choices cannot be distinguished

Fig. 2.3 Some simple graphical interactions in contingency table analysis. (a) Independence
model. (b) General dependent model. (c) Pairwise interactions only. (d) Triplet interactions.

16 Background

using a standard undirected graph; as illustrated in Figure 2.3(b), the
fully connected graph on 3 vertices does not distinguish between pair-
wise interactions without triplet interactions, versus triplet interaction
(possibly including pairwise interaction as well). In this sense, the fac-
tor graph formalism is more expressive, since it can distinguish between
pairwise and triplet interactions, as shown in panels (c) and (d) of
Figure 2.3.

2.4.3 Constraint Satisfaction and Combinatorial

Optimization

Problems of constraint satisfaction and combinatorial optimization
arise in a wide variety of areas, among them artiﬁcial intelligence [66,
192], communication theory [87], computational complexity theory [55],
statistical image processing [89], and bioinformatics [194]. Many prob-
lems in satisﬁability and combinatorial optimization [180] are deﬁned
in graph-theoretic terms, and thus are naturally recast in the graphical
model formalism.

Let us illustrate by considering what is perhaps the best-known
example of satisﬁability, namely the 3-SAT problem [55]. It is naturally
described in terms of a factor graph, and a collection of binary random
variables (X1, X2, . . . , Xm) ∈ {0,1}m. For a given triplet {s, t, u} of ver-
tices, let us specify some “forbidden” conﬁguration (zs, zt, zu) ∈ {0,1}3,
and then deﬁne a triplet compatibility function

(cid:4)

ψstu(xs, xt, xu) =

0
1

if (xs, xt, xu) = (zs, zt, zu),
otherwise.

(2.3)

Each such compatibility function is referred to as a clause in
the satisﬁability literature, where such compatibility functions are
typically encoded in terms of
if
(zs, zt, zu) = (0,0,0), then the function (2.3) can be written compactly
as ψstu(xs, xt, xu) = xs ∨ xt ∨ xu, where ∨ denotes the logical OR
operation between two Boolean symbols.

logical operations. For instance,

As a graphical model, a single clause corresponds to the model in
Figure 2.3(d); of greater interest are models over larger collections
involving many clauses. One basic problem in
of binary variables,

(cid:5)

satisﬁability is to determine whether a given set of clauses F are sat-
isﬁable, meaning that there exists some conﬁguration x ∈ {0,1}m such
that

(s,t,u)∈F ψstu(xs, xt, xu) = 1. In this case, the factorization

2.4 Applications

17

(cid:2)

p(x) =

1
Z

(s,t,u)∈F

ψstu(xs, xt, xu)

deﬁnes the uniform distribution over the set of satisfying assignments.
When instances of 3-SAT are randomly constructed — for instance,
by ﬁxing a clause density α > 0, and drawing (cid:8)αm(cid:9) clauses over m vari-
ables uniformly from all triplets — the graphs tend to have a locally
“tree-like” structure; see the factor graph in Figure 2.9(b) for an illus-
∗ at which this
tration. One major problem is determining the value α
ensemble is conjectured to undergo a phase transition from being sat-
isﬁable (for small α, hence with few constraints) to being unsatisﬁable
(for suﬃciently large α). The survey propagation algorithm, developed
in the statistical physics community [170, 171], is a promising method
for solving random instances of satisﬁability problems. Survey propa-
gation turns out to be an instance of the sum-product or belief propa-
gation algorithm, but as applied to an alternative graphical model for
satisﬁability problems [41, 162].

2.4.4 Bioinformatics

Many classical models in bioinformatics are instances of graphical mod-
els, and the associated framework is often exploited in designing new
models. In this section, we brieﬂy review some instances of graphical
models in both bioinformatics, both classical and recent. Sequential
data play a central role in bioinformatics, and the workhorse underly-
ing the modeling of sequential data is the hidden Markov model (HMM)
shown in Figure 2.4(a). The HMM is in essence a dynamical version of a
ﬁnite mixture model, in which observations are generated conditionally
on a underlying latent (“hidden”) state variable. The state variables,
which are generally taken to be discrete random variables following a
multinomial distribution, form a Markov chain. The graphical model in
Figure 2.4(a) is also a representation of the state-space model under-
lying Kalman ﬁltering and smoothing, where the state variable is a

18 Background

Fig. 2.4 (a) The graphical model representation of a generic hidden Markov model. The
shaded nodes {Y1, . . . , Y5} are the observations and the unshaded nodes {X1, . . . , X5} are
the hidden state variables. The latter form a Markov chain, in which Xs is independent
of Xu conditional on Xt, where s < t < u. (b) The graphical model representation of a
phylogeny on four extant organisms and M sites. The tree encodes the assumption that
there is a ﬁrst speciation event and then two further speciation events that lead to the four
extant organisms. The box around the tree (a “plate”) is a graphical model representation
of replication, here representing the assumption that the M sites evolve independently.

Gaussian vector. These models thus also have a right to be referred to
as “hidden Markov models,” but the terminology is most commonly
used to refer to models in which the state variables are discrete.

Applying the junction tree formalism to the HMM yields an algo-
rithm that passes messages in both directions along the chain of state
variables, and computes the marginal probabilities p(xt, xt+1| y) and
p(xt| y). In the HMM context, this algorithm is often referred to as
the forward–backward algorithm [196]. These marginal probabilities are
often of interest in and of themselves, but are also important in their
role as expected suﬃcient statistics in an expectation–maximization
(EM) algorithm for estimating the parameters of the HMM. Similarly,
the maximum a posteriori state sequence can also be computed by the
junction tree algorithm (with summation replaced by maximization) —
in the HMM context the resulting algorithm is generally referred to as
the Viterbi algorithm [82].

Gene-ﬁnding provides an important example of the application of
the HMM [72]. To a ﬁrst order of approximation, the genomic sequence
of an organism can be segmented into regions containing genes and
intergenic regions (that separate the genes), where a gene is deﬁned as
a sequence of nucleotides that can be further segmented into meaning-
ful intragenic structures (exons and introns). The boundaries between
these segments are highly stochastic and hence diﬃcult to ﬁnd reliably.

2.4 Applications

19

Hidden Markov models have been the methodology of choice for attack-
ing this problem, with designers choosing states and state transitions
to reﬂect biological knowledge concerning gene structure [44]. Hidden
Markov models are also used to model certain aspects of protein struc-
ture. For example, membrane proteins are speciﬁc kinds of proteins
that embed themselves in the membranes of cells, and play impor-
tant roles in the transmission of signals in and out of the cell. These
proteins loop in and out of the membrane many times, alternating
between hydrophilic amino acids (which prefer the environment of the
membrane) and hydrophobic amino acids (which prefer the environ-
ment inside or outside the membrane). These and other biological facts
are used to design the states and state transition matrix of the trans-
membrane hidden Markov model, an HMM for modeling membrane
proteins [141].

Tree-structured models also play an important role in bioinformat-
ics and language processing. For example, phylogenetic trees can be
treated as graphical models. As shown in Figure 2.4(b), a phylogenetic
tree is a tree-structured graphical model in which a set of observed
nucleotides (or other biological characters) are assumed to have evolved
from an underlying set of ancestral species. The conditional probabil-
ities in the tree are obtained from evolutionary substitution models,
and the computation of likelihoods are achieved by a recursion on the
tree known as “pruning” [79]. This recursion is a special case of the
junction tree algorithm.

Figure 2.5 provides examples of more complex graphical models that
have been explored in bioinformatics. Figure 2.5(a) shows a hidden

Fig. 2.5 Variations on the HMM used in bioinformatics. (a) A phylogenetic HMM. (b) The
factorial HMM.

20 Background

Markov phylogeny, an HMM in which the observations are sets of
nucleotides related by a phylogenetic tree [165, 193, 218]. This model
has proven useful for gene-ﬁnding in the human genome based on data
for multiple primate species [165]. Figure 2.5(b) shows a factorial HMM,
in which multiple chains are coupled by their links to a common set of
observed variables [92]. This model captures the problem of multi-locus
linkage analysis in genetics, where the state variables correspond to
phase (maternal or paternal) along the chromosomes in meiosis [232].

2.4.5 Language and speech processing

In language problems, HMMs also play a fundamental role. An exam-
ple is the part-of-speech problem, in which words in sentences are to be
labeled as to their part of speech (noun, verb, adjective, etc.). Here the
state variables are the parts of speech, and the transition matrix is esti-
mated from a corpus via the EM algorithm [163]. The result of running
the Viterbi algorithm on a new sentence is a tagging of the sentence
according to the hypothesized parts of speech of the words in the sen-
tence. Moreover, essentially all modern speech recognition systems are
built on the foundation of HMMs [117]. In this case the observations
are generally a sequence of short-range speech spectra, and the states
correspond to longer-range units of speech such as phonemes or pairs
of phonemes. Large-scale systems are built by composing elementary
HMMs into larger graphical models.

The graphical model shown in Figure 2.6(a) is a coupled HMM, in
which two chains of state variables are coupled via links between the

Fig. 2.6 Extensions of HMMs used in language and speech processing. (a) The coupled
HHM. (b) An HMM with mixture-model emissions.

2.4 Applications

21

chains; this model is appropriate for fusing pairs of data streams such
as audio and lip-reading data in speech recognition [208]. Figure 2.6(b)
shows an HMM variant in which the state-dependent observation dis-
tribution is a ﬁnite mixture model. This variant is widely used in speech
recognition systems [117].

Another model class that is widely studied in language processing
are so-called “bag-of-words” models, which are of particular interest
for modeling large-scale corpora of text documents. The terminology
bag-of-words means that the order of words in a document is ignored —
i.e., an assumption of exchangeability is made. The goal of such models
is often that of ﬁnding latent “topics” in the corpus, and using these
topics to cluster or classify the documents. An example bag-of-words
model is the latent Dirichlet allocation model [32], in which a topic
deﬁnes a probability distribution on words, and a document deﬁnes a
probability distribution on topics. In particular, as shown in Figure 2.7,
each document in a corpus is assumed to be generated by sampling a
Dirichlet variable with hyperparameter α, and then repeatedly selecting
a topic according to these Dirichlet probabilities, and choosing a word
from the distribution associated with the selected topic.2

2.4.6

Image Processing and Spatial Statistics

For several decades, undirected graphical models or Markov ran-
dom ﬁelds have played an important role in image processing

Fig. 2.7 Graphical illustration of the latent Dirichlet allocation model. The variable U,
which is distributed as Dirichlet with parameter α, speciﬁes the parameter for the multi-
nomial “topic” variable Z. The “word” variable W is also multinomial conditioned on Z,
with γ specifying the word probabilities associated with each topic. The rectangles, known
as plates, denote conditionally independent replications of the random variables inside the
rectangle.

2 This model is discussed in more detail in Example 3.5 of Section 3.3.

22 Background

Fig. 2.8 (a) The 4-nearest neighbor lattice model in 2D is often used for image modeling.
(b) A multiscale quad tree approximation to a 2D lattice model [262]. Nodes in the original
lattice (drawn in white) lie at the ﬁnest scale of the tree. The middle and top scales of the
tree consist of auxiliary nodes (drawn in gray), introduced to model the ﬁne scale behavior.

[e.g., 58, 89, 107, 263], as well as in spatial statistics more generally
[25, 26, 27, 201]. For modeling an image, the simplest use of a Markov
random ﬁeld model is in the pixel domain, where each pixel in the image
is associated with a vertex in an underlying graph. More structured
models are based on feature vectors at each spatial location, where
each feature could be a linear multiscale ﬁlter (e.g., a wavelet), or a
more complicated nonlinear operator.

For image modeling, one very natural choice of graphical struc-
ture is a 2D lattice, such as the 4-nearest neighbor variety shown in
Figure 2.8(a). The potential functions on the edges between adjacent
pixels (or more generally, features) are typically chosen to enforce local
smoothness conditions. Various tasks in image processing, including
denoising, segmentation, and super-resolution, require solving an infer-
ence problem on such a Markov random ﬁeld. However, exact inference
for large-scale lattice models is intractable, which necessitates the use
of approximate methods. Markov chain Monte Carlo methods are often
used [89], but they can be too slow and computationally intensive for
many applications. More recently, message-passing algorithms such as
sum-product and tree-reweighted max-product have become popular as
an approximate inference method for image processing and computer
vision problems [e.g., 84, 85, 137, 168, 227].

An alternative strategy is to sidestep the intractability of the lattice
model by replacing it with a simpler — albeit approximate — model.

2.4 Applications

23

For instance, multiscale quad trees, such as that illustrated in
Figure 2.8(b), can be used to approximate lattice models [262]. The
advantage of such a multiscale model is in permitting the application
of eﬃcient tree algorithms to perform exact inference. The trade-oﬀ
is that the model is imperfect, and can introduce artifacts into image
reconstructions.

2.4.7 Error-Correcting Coding

A central problem in communication theory is that of transmitting
information, represented as a sequence of bits, from one point to
another. Examples include transmission from a personal computer over
a network, or from a satellite to a ground position. If the communication
channel is noisy, then some of the transmitted bits may be corrupted. In
order to combat this noisiness, a natural strategy is to add redundancy
to the transmitted bits, thereby deﬁning codewords. In principle, this
coding strategy allows the transmission to be decoded perfectly even
in the presence of some number of errors.

Many of the best codes in use today, including turbo codes and low-
density parity check codes [e.g., 87, 166], are based on graphical models.
Figure 2.9(a) provides an illustration of a very small parity check code,
represented here in the factor graph formalism [142]. (A somewhat
larger code is shown in Figure 2.9(b)). On the left, the six white nodes
represent the bits xi that comprise the codewords (i.e., binary sequences
of length six), whereas the gray nodes represent noisy observations
yi associated with these bits. On the right, each of the black square
nodes corresponds to a factor ψstu that represents the parity of the
triple {xs, xt, xu}. This parity relation, expressed mathematically as
xs ⊕ xt ⊕ xu ≡ zstu in modulo two arithmetic, can be represented as an
undirected graphical model using a compatibility function of the form:

(cid:4)

ψstu(xs, xt, xu) :=

if xs ⊕ xt ⊕ xu = 1
otherwise.

1
0

For the code shown in Figure 2.9, the parity checks range over the set
of triples {1,3,4}, {1,3,5}, {2,4,6}, and {2,5,6}.

The decoding problem entails estimating which codeword was trans-
mitted on the basis of a vector y = (y1, y2, . . . , ym) of noisy observations.

24 Background

Fig. 2.9 (a) A factor graph representation of a parity check code of length m = 6. On the
left, circular white nodes (cid:1) represent the unobserved bits xi that deﬁne the code, whereas
circular gray nodes represent the observed values yi, received from the channel. On the
right, black squares (cid:1) represent the associated factors, or parity checks. This particular
code is a (2,3) code, since each bit is connected to two parity variables, and each parity
relation involves three bits. (b) A large factor graph with a “locally tree-like” structure.
Random constructions of factor graphs on m vertices with bounded degree have cycles of
typical length (cid:6) log m; this tree-like property is essential to the success of the sum-product
algorithm for approximate decoding [200, 169].

With the speciﬁcation of a model for channel noise, this decoding prob-
lem can be cast as an inference problem. Depending on the loss function,
optimal decoding is based either on computing the marginal probabil-
ity p(xs = 1 | y) at each node, or computing the most likely codeword
(i.e., the mode of the posterior). For the simple code of Figure 2.9(a),
optimal decoding is easily achievable via the junction tree algorithm.
Of interest in many applications, however, are much larger codes in
which the number of bits is easily several thousand. The graphs under-
lying these codes are not of low treewidth, so that the junction tree
algorithm is not viable. Moreover, MCMC algorithms have not been
deployed successfully in this domain.

For many graphical codes, the most successful decoder is based
on applying the sum-product algorithm, described in Section 2.6.
Since the graphical models deﬁning good codes invariably have cycles,
the sum-product algorithm is not guaranteed to compute the correct
marginals, nor even to converge. Nonetheless, the behavior of this

2.5 Exact Inference Algorithms

25

approximate decoding algorithm is remarkably good for a large class
of codes. The behavior of sum-product algorithm is well understood
in the asymptotic limit (as the code length m goes to inﬁnity), where
martingale arguments can be used to prove concentration results [160,
199]. For intermediate code lengths, in contrast, its behavior is not as
well understood.

2.5 Exact Inference Algorithms

In this section, we turn to a description of the basic exact inference
algorithms for graphical models. In computing a marginal probability,
we must sum or integrate the joint probability distribution over one
or more variables. We can perform this computation as a sequence of
operations by choosing a speciﬁc ordering of the variables (and mak-
ing an appeal to Fubini’s theorem). Recall that for either directed or
undirected graphical models, the joint probability is a factored expres-
sion over subsets of the variables. Consequently, we can make use of
the distributive law to move individual sums or integrals across fac-
tors that do not involve the variables being summed or integrated over.
The phrase “exact inference” refers to the (essentially symbolic) prob-
lem of organizing this sequential computation, including managing the
intermediate factors that arise. Assuming that each individual sum or
integral is performed exactly, then the overall algorithm yields an exact
numerical result.

In order to obtain the marginal probability distribution of a single
variable Xs, it suﬃces to choose a speciﬁc ordering of the remaining
variables and to eliminate — that is, sum or integrate out — variables
according to that order. Repeating this operation for each individual
variable would yield the full set of marginals. However, this approach is
wasteful because it neglects to share intermediate terms in the individ-
ual computations. The sum-product and junction tree algorithms are
essentially dynamic programming algorithms based on a calculus for
sharing intermediate terms. The algorithms involve “message-passing”
operations on graphs, where the messages are exactly these shared
intermediate terms. Upon convergence of the algorithms, we obtain
marginal probabilities for all cliques of the original graph.

26 Background

Both directed and undirected graphical models involve factorized
expressions for joint probabilities, and it should come as no surprise
that exact inference algorithms treat them in an essentially identical
manner. Indeed, to permit a simple uniﬁed treatment of inference algo-
rithms, it is convenient to convert directed models to undirected models
and to work exclusively within the undirected formalism. We do this
by observing that the terms in the directed factorization (2.1) are not
necessarily deﬁned on cliques, since the parents of a given vertex are
not necessarily connected. We thus transform a directed graph to an
undirected moral graph, in which all parents of each child are linked,
and all edges are converted to undirected edges. In this moral graph,
the factors are all deﬁned on cliques, so that the moralized version of
any directed factorization (2.1) is a special case of the undirected fac-
torization (2.2). Throughout the rest of the survey, we assume that this
transformation has been carried out.

2.5.1 Message-Passing on Trees

We now turn to a description of message-passing algorithms for exact
inference on trees. Our treatment is brief; further details can be found
in various sources [2, 65, 142, 125, 154]. We begin by observing that the
cliques of a tree-structured graph T = (V, E(T )) are simply the individ-
ual nodes and edges. As a consequence, any tree-structured graphical
model has the following factorization:

p(x1, x2, . . . , xm) =

1
Z

ψs(xs)

ψst(xs, xt).

(2.4)

(cid:2)

(s,t)∈E(T )

(cid:2)

s∈V

(cid:6)

Here, we describe how the sum-product algorithm computes the
marginal distribution

µs(xs) :=

{x(cid:2) | x(cid:2)

s=xs}

(cid:4)
(cid:4)
(cid:4)
p(x
m)
2, . . . , x
1, x

(2.5)

for every node of a tree-structured graph. We will focus in detail on
the case of discrete random variables, with the understanding that the
computations carry over (at least in principle) to the continuous case
by replacing sums with integrals.

2.5 Exact Inference Algorithms

27

Sum-product algorithm: The sum-product algorithm is a form of
nonserial dynamic programming [19], which generalizes the usual
serial form of deterministic dynamic programming [20] to arbitrary
tree-structured graphs. The essential principle underlying dynamic
programming (DP) is that of divide and conquer: we solve a large
problem by breaking it down into a sequence of simpler problems. In
the context of graphical models, the tree itself provides a natural way
to break down the problem.

For an arbitrary s ∈ V , consider the set of its neighbors

N(s) := {u ∈ V | (s, u) ∈ E}.

(2.6)
For each u ∈ N(s), let Tu = (Vu, Eu) be the subgraph formed by the set
of nodes (and edges joining them) that can be reached from u by paths
that do not pass through node s. The key property of a tree is that
each such subgraph Tu is again a tree, and Tu and Tv are vertex-disjoint
for u (cid:12)= v. In this way, each vertex u ∈ N(s) can be viewed as the root
of a subtree Tu, as illustrated in Figure 2.10.
For each subtree Tt, we deﬁne the subvector xVt := (xu, u ∈ Vt) of
variables associated with its vertex set. Now consider the collection of
terms in Equation (2.4) associated with vertices or edges in Tt. We
collect all of these terms into the following product:

p(xVt; Tt) ∝

ψu(xu)

ψuv(xu, xv).

(2.7)

(cid:2)

u ∈ Vt

(cid:2)

(u,v)∈Et

With this notation, the conditional independence properties of a tree
allow the computation of the marginal at node s to be broken down

Fig. 2.10 Decomposition of a tree, rooted at node s, into subtrees. Each neighbor (e.g., u)
of node s is the root of a subtree (e.g., Tu). Subtrees Tu and Tv, for u (cid:7)= v, are disconnected
when node s is removed from the graph.

28 Background

into a product of subproblems, one for each of the subtrees in the set
{Tt, t ∈ N(s)}, in the following way:
(cid:6)
µs(xs) = κ ψs(xs)

∗
ts(xs)

t∈N(s)

(2.8a)

M

∗
ts(xs) :=

M

(cid:4)
(cid:4)
t) p(x
ψst(xs, x
Vt; Tt)

(2.8b)

(cid:2)

(cid:2)
Vt

x

In these equations, κ denotes a positive constant chosen to ensure that
∗
µs normalizes properly. For ﬁxed xs, the subproblem deﬁning M
ts(xs) is
again a tree-structured summation, albeit involving a subtree Tt smaller
than the original tree T . Therefore, it too can be broken down recur-
sively in a similar fashion. In this way, the marginal at node s can be
computed by a series of recursive updates.

Rather than applying the procedure described above to each node
separately, the sum-product algorithm computes the marginals for all
nodes simultaneously and in parallel. At each iteration, each node t
passes a “message” to each of its neighbors u ∈ N(t). This message,
which we denote by Mtu(xu), is a function of the possible states xu ∈ Xu
(i.e., a vector of length |Xu| for discrete random variables). On the full
graph, there are a total of 2|E| messages, one for each direction of each
edge. This full collection of messages is updated, typically in parallel,
according to the recursion

(cid:8)

Mts(xs) ← κ

(cid:4)
(cid:4)
t) ψt(x
ψst(xs, x
t)

(cid:4)
Mut(x
t)

,

(2.9)

(cid:7)

(cid:6)

(cid:2)
t

x

(cid:2)

u∈N(t)/s

It

for

that

∗
st, M

∗ = {M

tree-structured graphs,

can
where κ > 0 again denotes a normalization constant.
be shown [192]
iterates gener-
ated by the update (2.9) will converge to a unique ﬁxed point
ts, (s, t) ∈ E} after a ﬁnite number of iterations. More-
∗
M
∗
ts of this ﬁxed point is precisely equal, up to a
over, component M
normalization constant, to the subproblem deﬁned in Equation (2.8b),
which justiﬁes our abuse of notation post hoc. Since the ﬁxed point
∗ speciﬁes the solution to all of the subproblems, the marginal µs at
M
every node s ∈ V can be computed easily via Equation (2.8a).
Max-product algorithm: Suppose
summation in the
update (2.9) is replaced by a maximization. The resulting max-product

that

the

2.5 Exact Inference Algorithms

29

algorithm solves the problem of ﬁnding a mode of a tree-structured
distribution. In this sense, it represents a generalization of the Viterbi
algorithm [82] from chains to arbitrary tree-structured graphs. More
speciﬁcally, the max-product updates will converge to another unique
∗ — distinct, of course, from the sum-product ﬁxed point.
ﬁxed point M
This ﬁxed point can be used to compute the max-marginal

νs(xs) := max

{x(cid:2) | x(cid:2)

(2.10)

(cid:4)
(cid:4)
(cid:4)
s=xs} p(x
m)
2, . . . , x
1, x
to compute a mode (cid:3)x ∈ arg maxx(cid:2) p(x

at each node of the graph, via the analog of Equation (2.7). Given
these max-marginals, a standard back-tracking procedure can be used
(cid:4)
(cid:4)
(cid:4)
m) of the distribution;
2, . . . , x
1, x
see the papers [65, 244] for further details. More generally, updates of
this form apply to arbitrary commutative semirings on tree-structured
graphs [2, 65, 216, 237]. The pairs “sum-product” and “max-product”
are two particular examples of such an algebraic structure.

2.5.2 Junction Tree Representation

We have seen that inference problems on trees can be solved exactly
by recursive message-passing algorithms. Given a graph with cycles, a
natural idea is to cluster its nodes so as to form a clique tree — that
is, an acyclic graph whose nodes are formed by the maximal cliques
of G. Having done so, it is tempting to apply a standard algorithm
for inference on trees. However, the clique tree must satisfy an addi-
tional restriction so as to ensure correctness of these computations. In
particular, since a given vertex s ∈ V may appear in multiple cliques
(say C1 and C2), what is required is a mechanism for enforcing consis-
tency among the diﬀerent appearances of the variable xs. It turns out
that the following property is necessary and suﬃcient to enforce such
consistency:

Deﬁnition 2.1. A clique tree has the running intersection property
if for any two clique nodes C1 and C2, all nodes on the unique path
joining them contain the intersection C1 ∩ C2. A clique tree with this
property is known as a junction tree.

30 Background

For what type of graphs can one build junction trees? An important
result in graph theory establishes a correspondence between junction
trees and triangulation. We say that a graph is triangulated if every
cycle of length four or longer has a chord, meaning an edge joining
a pair of nodes that are not adjacent on the cycle. A key theorem is
that a graph G has a junction tree if and only if it is triangulated
(see Lauritzen [153] for a proof). This result underlies the junction tree
algorithm [154] for exact inference on arbitrary graphs:

(1) Given a graph with cycles G, triangulate it by adding edges

as necessary.

graph (cid:9)G.

(2) Form a junction tree associated with the triangulated

(3) Run a tree inference algorithm on the junction tree.

Example 2.1 (Junction Tree). To illustrate the junction tree con-
struction, consider the 3 × 3 grid shown in Figure 2.11(a). The ﬁrst

step is to form a triangulated version (cid:9)G, as shown in Figure 2.11(b).

Note that the graph would not be triangulated if the additional edge
joining nodes 2 and 8 were not present. Without this edge, the 4-cycle
(2 − 4 − 8 − 6 − 2) would lack a chord. As a result of this additional
edge, the junction tree has two 4-cliques in the middle, as shown in
Figure 2.11(c).

Fig. 2.11 Illustration of junction tree construction. (a) Original graph is a 3 × 3 grid. (b)
Triangulated version of original graph. Note the two 4-cliques in the middle. (c) Corre-
sponding junction tree for triangulated graph in (b), with maximal cliques depicted within
ellipses, and separator sets within rectangles.

2.5 Exact Inference Algorithms

31

In principle, the inference in the third step of the junction tree
algorithm can be performed over an arbitrary commutative semiring
(as mentioned in our earlier discussion of tree algorithms). We refer
the reader to Dawid [65] for an extensive discussion of the max-product
version of the junction tree algorithm. For concreteness, we limit our
discussion here to the sum-product version of junction tree updates.
There is an elegant way to express the basic algebraic operations in
a junction tree inference algorithm that involves introducing potential
functions not only on the cliques in the junction tree, but also on the
separators in the junction tree — the intersections of cliques that are
adjacent in the junction tree (the rectangles in Figure 2.11). Let φC(·)
denote a potential function deﬁned over the subvector xC = (xt, t ∈ C)
on clique C, and let φS(·) denote a potential on a separator S. We
initialize the clique potentials by assigning each compatibility function
in the original graph to (exactly) one clique potential and taking the
product over these compatibility functions. The separator potentials
are initialized to unity. Given this set-up, the basic message-passing
step of the junction tree algorithm are given by

(cid:9)φS(xS) ←

φC(xC) ←

(cid:6)
(cid:9)φS(xS)

xB\S

φB(xB),

and

(2.11a)

φS(xS) φC(xC),

(2.11b)

where in the continuous case the summation is replaced by a suitable
integral. We refer to this pair of operations as “passing a message from
clique B to clique C” (see Figure 2.12). It can be veriﬁed that if a
message is passed from B to C, and subsequently from C to B, then
the resulting clique potentials are consistent with each other, meaning
that they agree with respect to the vertices S.

Fig. 2.12 A message-passing operation between cliques B and C via the separator set S.

32 Background

After a round of message passing on the junction tree, it can be
shown that the clique potentials are proportional to marginal probabil-
ities throughout the junction tree. Speciﬁcally, letting µC(xC) denote

the marginal probability of xC, we have µC(xC) ∝(cid:9)φC(xC) for all cliques

C. This equivalence can be established by a suitable generalization of
the proof of correctness of the sum-product algorithm sketched previ-
ously (see also Lauritzen [153]). Note that achieving local consistency
between pairs of cliques is obviously a necessary condition if the clique
potentials are to be proportional to marginal probabilities. Moreover,
the signiﬁcance of the running intersection property is now apparent;
namely, it ensures that local consistency implies global consistency.
An important by-product of the junction tree algorithm is an alter-
native representation of a distribution p. Let C denote the set of all

maximal cliques in (cid:9)G (i.e., nodes in the junction tree), and let S rep-

resent the set of all separator sets (i.e., intersections between cliques
that are adjacent in the junction tree). Note that a given separator set
S may occur multiple times in the junction tree. For each separator set
S ∈ S, let d(S) denote the number of maximal cliques to which it is
adjacent. The junction tree framework guarantees that the distribution
p factorizes in the form

(cid:5)
C∈C µC(xC)
[µS(xS)]d(S)−1 ,

(cid:5)

S∈S

p(x1, x2, . . . , xm) =

(2.12)

where µC and µS are the marginal distributions over the cliques and
separator sets, respectively. Observe that unlike the factorization (2.2),
the decomposition (2.12) is directly in terms of marginal distributions,
and does not require a normalization constant (i.e., Z = 1).

Example 2.2 (Markov Chain). Consider
the Markov chain
p(x1, x2, x3) = p(x1) p(x2| x1) p(x3| x2). The cliques in a graphical
model representation are {1,2} and {2,3}, with separator {2}. Clearly
the distribution cannot be written as the product of marginals involving
only the cliques. It can, however, be written in terms of marginals if we

2.5 Exact Inference Algorithms

33

include the separator:

p(x1, x2, x3) = p(x1, x2) p(x2, x3)

p(x2)

.

Moreover, it can be easily veriﬁed that these marginals result from
a single application of the updates (2.11), given the initialization
φ{1,2}(x1, x2) = p(x1)p(x2| x1) and φ{2,3}(x2, x3) = p(x3| x2).

To anticipate part of our development in the sequel, it is helpful to
consider the following “inverse” perspective on the junction tree repre-
sentation. Suppose that we are given a set of functions {τC, C ∈ C} and
{τS, S ∈ S} associated with the cliques and separator sets in the junc-
tion tree. What conditions are necessary to ensure that these functions
are valid marginals for some distribution? Suppose that the functions
are locally consistent in the following sense:

(cid:6)

(cid:2)
S

x

(cid:4)
τS(x
S) = 1,

and (2.13a)

(cid:4)
τC(x
C) = τS(xS).

(2.13b)

∀ C ∈ C, S ⊆ C,

∀ S ∈ S,

(cid:6)

{x

(cid:2)
C

| x

S=xS}
(cid:2)

The essence of the junction tree theory described above is that such
local consistency is both necessary and suﬃcient to ensure that these
functions are valid marginals for some distribution. For the sake of
future reference, we state this result in the following:

Proposition 2.1. A candidate set of marginal distribution {τC, C ∈ C}
and {τC, C ∈ S} on the cliques and separator sets (respectively) of a
junction tree is globally consistent if and only if the normalization con-
dition (2.13a) is satisﬁed for all separator sets S ∈ J , and the marginal-
ization condition (2.13b) is satisﬁed for all cliques C ∈ C, and separator
sets S ⊆ C. Moreover, any such locally consistent quantities are the
marginals of the probability distribution deﬁned by Equation (2.12).

This particular consequence of the junction tree representation will play
a fundamental role in our development in the sequel.

34 Background

Finally, let us turn to the key issue of the computational complex-
ity of the junction tree algorithm. Inspection of Equation (2.11) reveals
that the computational costs grow exponentially in the size of the max-
imal clique in the junction tree. Clearly then, it is of interest to control
the size of this clique. The size of the maximal clique over all possi-
ble triangulations of a graph is an important graph-theoretic quantity
known as the treewidth of the graph.3 Thus, the complexity of the
junction tree algorithm is exponential in the treewidth.

For certain classes of graphs,

including chains and trees, the
treewidth is small and the junction tree algorithm provides an eﬀec-
tive solution to inference problems. Such families include many well-
known graphical model architectures, and the junction tree algorithm
subsumes the classical recursive algorithms,
including the pruning
and peeling algorithms from computational genetics [79], the forward–
backward algorithms for hidden Markov models [196], and the Kalman
ﬁltering-smoothing algorithms for state-space models [126]. On the
other hand, there are many graphical models, including several of the
examples treated in Section 2.4, for which the treewidth is infeasibly
large. Coping with such models requires leaving behind the junction
tree framework, and turning to approximate inference algorithms.

2.6 Message-passing Algorithms for Approximate Inference

It is the goal of the remainder of the survey to develop a general theoret-
ical framework for understanding and analyzing variational methods for
computing approximations to marginal distributions and likelihoods,
as well as for solving integer programming problems. Doing so requires
mathematical background on convex analysis and exponential families,
which we provide starting in Section 3. Historically, many of these algo-
rithms have been developed without this background, but rather via
physical intuition or on the basis of analogies to exact or Monte Carlo
algorithms. In this section, we give a high-level description of this ﬂavor
for two variational inference algorithms, with the goal of highlighting
their simple and intuitive nature.

3 To be more precise, the treewidth is one less than the size of this largest clique [33].

2.6 Message-passing Algorithms for Approximate Inference

35

The ﬁrst variational algorithm that we consider is sum-product
message-passing applied to a graph with cycles, where it is known as
the “loopy” sum-product or belief propagation algorithm. Recall that
the sum-product algorithm is an exact inference algorithm for trees.
From an algorithmic point of view, however, there is nothing to pre-
vent one from running the procedure on a graph with cycles. More
speciﬁcally, the message updates (2.9) can be applied at a given node
while ignoring the presence of cycles — essentially pretending that any
given node is embedded in a tree. Intuitively, such an algorithm might
be expected to work well if the graph is sparse, such that the eﬀect
of messages propagating around cycles is appropriately diminished, or
if suitable symmetries are present. As discussed in Section 2.4, this
algorithm is in fact successfully used in various applications. Also, an
analogous form of the max-product algorithm can be used for comput-
ing approximate modes in graphical models with cycles.

A second variational algorithm is the so-called naive mean ﬁeld algo-
rithm. For concreteness, we describe here this algorithm in application
to the Ising model, which is an undirected graphical model or Markov
random ﬁeld involving a binary random vector X ∈ {0,1}m, in which
pairs of adjacent nodes are coupled with a weight θst, and each node has
an observation weight θs. (See Example 3.1 of Section 3.3 for a more
detailed description of this model.) To provide some intuition for the
naive mean ﬁeld updates, we begin by describing the Gibbs sampler, a
particular type of Monte Carlo Markov chain algorithm, for this partic-
ular model. The basic step of a Gibbs sampler is to choose a node s ∈ V
randomly, and then to update the state of the associated random vari-
able according to the conditional probability with neighboring states
ﬁxed. More precisely, denoting by N(s) the neighbors of a node s ∈ V ,
(cid:4)
(n)
N(s) denote the state of the neighbors of s at iteration n,
and letting X
the Gibbs update for vertex s takes the form
1 if U ≤ {1 + exp[−(θs +
0 otherwise

X(n+1)
where U is a sample from a uniform distribution U[0,1].

t∈N(s) θstX

)]}−1

(n)
t

,

(2.14)

(cid:10)

=

s

In a dense graph, such that the cardinality of the neighborhood
set N(s) is large, we might attempt to invoke a law of large numbers

36 Background

(cid:10)

(cid:6)

t∈N(s)

(cid:12)(cid:8)−1

θstµt)

.

(2.15)

or some other concentration result for
. To the extent
that such sums are concentrated, it might make sense to replace sample
values with expectations. That is, letting µs denote an estimate of the
marginal probability P[Xs = 1] at each vertex s ∈ V , we might consider
the following averaged version of Equation (2.14):

t∈N(s) θstX

(n)
t

(cid:7)

(cid:11) − (θs +

µs ←

1 + exp

Thus, rather than ﬂipping the random variable Xs with a probability
that depends on the state of its neighbors, we update a parameter µs
deterministically that depends on the corresponding parameters at its
neighbors. Equation (2.15) deﬁnes the naive mean ﬁeld algorithm for
the Ising model. As with the sum-product algorithm, the mean ﬁeld
algorithm can be viewed as a message-passing algorithm, in which the
right-hand side of (2.15) represents the “message” arriving at vertex s.
At ﬁrst sight, message-passing algorithms of this nature might seem
rather mysterious, and do raise some questions. Do the updates have
ﬁxed points? Do the updates converge? What is the relation between
the ﬁxed points and the exact quantities? The goal of the rest of this
survey is to shed some light on such issues. Ultimately, we will see
that a broad class of message-passing algorithms, including the mean
ﬁeld updates, the sum-product and max-product algorithms, as well as
various extensions of these methods, can all be understood as solving
either exact or approximate versions of variational problems. Exponen-
tial families and convex analysis, which are the subject of the following
section, provide the appropriate framework in which to develop these
variational principles in an uniﬁed manner.

3

Graphical Models as Exponential Families

In this section, we describe how many graphical models are naturally
viewed as exponential families, a broad class of distributions that have
been extensively studied in the statistics literature [5, 11, 43, 74]. Tak-
ing the perspective of exponential families illuminates some fundamen-
tal connections between inference algorithms and the theory of convex
analysis [38, 112, 203]. More speciﬁcally, as we shall see, various types
of inference problems in graphical models can be understood in terms
of mappings between mean parameters and canonical parameters.

3.1 Exponential Representations via Maximum Entropy

One way in which to motivate exponential family representations of
graphical models is through the principle of maximum entropy [123,
264]. Here, so as to provide helpful intuition for our subsequent develop-
ment, we describe a particularly simple version for a scalar random vari-
able X. Suppose that given n independent and identically distributed
(i.i.d.) observations X1, . . . , X n, we compute the empirical expectations
of certain functions — namely, the quantities

φα(X i),

for all α ∈ I,

(3.1)

(cid:3)µα :=

1
n

n(cid:6)

i=1

37

38 Graphical Models as Exponential Families
where each α in some set I indexes a function φα : X → R. For exam-
ple, if we set φ1(x) = x and φ2(x) = x2, then the observations (3.1)
ical expectations(cid:3)µ = ((cid:3)µα, α ∈ I), our goal is to infer a full probability
correspond to empirical versions of the ﬁrst and second moments of
the random variable X. Based on the |I|-dimensional vector of empir-

distribution over the random variable X. In particular, we represent
the probability distribution as a density p absolutely continuous with
respect to some measure ν. This base measure ν might be the counting
measure on {0,1, . . . , r − 1}, in which case p is a probability mass func-
tion; alternatively, for a continuous random vector, the base measure ν
could be the ordinary Lebesgue measure on R.

For a given distribution p,

Ep[φα(X)] :=
We say that the distribution p is consistent with the data if

let us consider the expectations
X φα(x)p(x)ν(dx) for α ∈ I, assuming that they exist.
Ep[φα(X)] = (cid:3)µα

for all α ∈ I.

(cid:1)

In words, the expectations Ep[φα(X)] under the distribution p are
matched to the expectations under the empirical distribution. An
important observation is that generically, this problem is under-
determined, in that there are many distributions p that are consistent
with the observations, so that we need a principle for choosing among
them.

In order to develop such a principle, we begin by deﬁning a func-

tional of the density p, known as the Shannon entropy, via

(cid:13)

H(p) := −

(log p(x)) p(x) ν(dx).

X

(3.2)

The principle of maximum entropy is to choose, from among the dis-
∗ whose Shannon
tributions consistent with the data, the distribution p
entropy is maximal. More formally, letting P be the set of all proba-
bility distributions over the random variable X, the maximum entropy
∗ is given by the solution to the following constrained opti-
solution p
mization problem:

subject to Ep[φα(X)] =(cid:3)µα

∗

p

:= arg max

p∈P H(p)

for all α ∈ I.

(3.3)

3.2 Basics of Exponential Families

39

One interpretation of this principle is as choosing the distribution with
maximal uncertainty, as measured by the entropy functional (3.2), while
remaining faithful to the data. Presuming that problem (3.3) is feasible
(and under certain technical conditions to be explored in the sequel),
it can be shown — by calculus of variations in the general continuous
case, and by ordinary calculus in the discrete case — that the optimal
solution p

∗ takes the form

pθ(x) ∝ exp

θαφα(x)

,

(3.4)

(cid:15)

(cid:14)(cid:6)

α∈I

where θ ∈ Rd represents a parameterization of the distribution in
exponential family form. From this maximum entropy perspective,
the parameters θ have a very speciﬁc interpretation as the Lagrange
multipliers associated with the constraints speciﬁed by the empirical

moments (cid:3)µ. We explore this connection in much more depth in the

following sections.

3.2 Basics of Exponential Families

With this motivating example in mind, let us now set up the framework
of exponential families in more precise terms and greater generality.
At a high level, an exponential family is a parameterized family of
densities, taken with respect to some underlying measure ν.
Given a random vector (X1, X2, . . . , Xm) taking values in some
space X m = ⊗m
s=1Xs, let φ = (φα, α ∈ I) be a collection of functions
φα : X m → R, known either as potential functions or suﬃcient statis-
tics. Here I is an index set with d = |I| elements to be speciﬁed, so
that φ can be viewed as a vector-valued mapping from X m to Rd. For
a given vector of suﬃcient statistics φ, let θ = (θα, α ∈ I) be an asso-
ciated vector of canonical or exponential parameters. For each ﬁxed
x ∈ X m, we use (cid:19)θ, φ(x)(cid:20) to denote the Euclidean inner product in Rd
of the two vectors θ and φ(x).

With this notation, the exponential family associated with φ consists

of the following parameterized collection of density functions

(cid:14)(cid:19)θ, φ(x)(cid:20) − A(θ)
(cid:15)

pθ(x1, x2, . . . , xm) = exp

,

(3.5)

40 Graphical Models as Exponential Families

taken with respect1 to dν. The quantity A, known as the log partition
function or cumulant function, is deﬁned by the integral

(cid:13)

exp(cid:19)θ, φ(x)(cid:20) ν(dx).

(3.6)

A(θ) = log

X m

(cid:1)

Presuming that the integral is ﬁnite, this deﬁnition ensures that pθ is
X m pθ(x)ν(dx) = 1). With the set of poten-
properly normalized (i.e.,
tials φ ﬁxed, each parameter vector θ indexes a particular member pθ
of the family. The canonical parameters θ of interest belong to the set
(3.7)
We will see shortly that A is a convex function of θ, which in turn
implies that Ω must be a convex set. The log partition function A
plays a prominent role in this survey.

Ω := {θ ∈ Rd | A(θ) < +∞}.

The following notions will be important in subsequent development:
Regular families: An exponential family for which the domain Ω is an
open set is known as a regular family. Although there do exist exponen-
tial families for which Ω is closed (for instance, see Brown [43]), herein
we restrict our attention to regular exponential families.
Minimal: It is typical to deﬁne an exponential family with a vector
of suﬃcient statistics φ = (φα, α ∈ I) for which there does not exist a
nonzero vector a ∈ Rd such that the linear combination

(cid:6)

α∈I

(cid:19)a, φ(x)(cid:20) =

aαφα(x)

is equal to a constant (ν-almost everywhere). This condition gives rise
to a so-called minimal representation, in which there is a unique param-
eter vector θ associated with each distribution.
Overcomplete: Instead of a minimal representation, it can be conve-
nient to use a nonminimal or overcomplete representation, in which
there exist linear combinations (cid:19)a, φ(x)(cid:20) that are equal to a constant
(ν-a.e.). In this case, there exists an entire aﬃne subset of parameter
vectors θ, each associated with the same distribution. The reader might
question the utility of an overcomplete representation. Indeed, from a
statistical perspective, it can be undesirable since the identiﬁability of
1 More precisely, for any measurable set S, we have P[X ∈ S] =

(cid:1)
S pθ(x)ν(dx).

3.3 Examples of Graphical Models in Exponential Form 41

the parameter vector θ is lost. However, this notion of overcompleteness
is useful in understanding the sum-product algorithm and its variants
(see Section 4).

Table 3.1 provides some examples of well-known scalar exponential
families. Observe that all of these families are both regular (since Ω is
open), and minimal (since the vector of suﬃcient statistics φ does not
satisfy any linear relations).

3.3 Examples of Graphical Models in Exponential Form

The scalar examples in Table 3.1 serve as building blocks for the con-
struction of more complex exponential families for which graphical
structure plays a role. Whereas earlier we described graphical models
in terms of products of functions, as in Equations (2.1) and (2.2), these
products become additive decompositions in the exponential family set-
ting. Here, we discuss a few well-known examples of graphical models
as exponential families. Those readers familiar with such formulations
may skip directly to Section 3.4, where we continue our general discus-
sion of exponential families.

Example 3.1 (Ising Model). The Ising model
from statistical
physics [12, 119] is a classical example of a graphical model in expo-
nential form. Consider a graph G = (V, E) and suppose that the ran-
dom variable Xs associated with node s ∈ V is Bernoulli, say taking
the “spin” values {−1,+1}. In the context of statistical physics, these
values might represent the orientations of magnets in a ﬁeld, or the
presence/absence of particles in a gas. The Ising model and varia-
tions on it have also been used in image processing and spatial statis-
tics [27, 89, 101], where Xs might correspond to pixel values in a black-
and-white image, and for modeling of social networks, for instance the
voting patterns of politicians [8].

Components Xs and Xt of the full random vector X are allowed to
interact directly only if s and t are joined by an edge in the graph. This
set-up leads to an exponential family consisting of the densities

pθ(x) = exp

θsxs +

,

(3.8)

(cid:14)(cid:6)

s∈V

(cid:6)

(cid:15)
θstxsxt − A(θ)

(s,t)∈E

42 Graphical Models as Exponential Families

}
0
<
2
θ

|

2
R
∈
)
2
θ
,
1
θ
(
{

)
2
θ
2
−

(
g
o
l

12

−

21
θ

2
θ
4
−

2

x
2
θ
+
x
1
θ

Ω

R

R

)
θ
(
A

]
)
θ
(
p
x
e
+
1
[
g
o
l

2

θ
12

s
c
i
t
s
i
t
a
t
s

t
n
e
i
c
ﬃ
u
S

(cid:9)
)
x
(
φ

,
θ
(cid:8)

x
θ

x
θ

)
2
/

π
2

2

x
−
√
(
p
x
e

ν

)
·
(
h

g
n

i
t
n
u
o
C

e
u
g
s
e
b
e
L

=

)
x
(
h

e
u
g
s
e
b
e
L

π
2

1
√

=

)
x
(
h

e
u
g
s
e
b
e
L

g
n

i
t
n
u
o
C

!

x
/
1
=

)
x
(
h

e
u
g
s
e
b
e
L

X

}
1
,
0
{

R

R

)

∞
+

}
.
.
.
2
,
1
,
0
{

,
0
(

y
l
i

m
a
f

n
o
i
t
a
c
o
L

e
l
a
c
s
-
n
o
i
t
a
c
o
L

l
a
i
t
n
e
n
o
p
x
E

n
o
s
s
i
o
P

n
a
i
s
s
u
a
G

i
l
l

u
o
n
r
e
B

n
a
i
s
s
u
a
G

y
l
i

m
a
F

)
1
,
0
(

a
t
e
B

.
s
e
i
l
i

m
a
f

l
a
i
t
n
e
n
o
p
x
e

s
a

s
e
l

b
a
i
r
a
v
m
o
d
n
a
r

r
a
l
a
c
s

f
o

s
e
s
s
a
l
c

n
w
o
n
k
-
l
l
e
w

l
a
r
e
v
e
S

1
.
3

e
l

b
a
T

)
0
,

∞
−

(

R

2

)

∞
+

,
1
−

(

d
n
a

,

X
e
c
a
p
s

)
)
1
+

i
θ
(

(
Γ
g
o
l

2(cid:2)

1
=

i

2(cid:2)

1
=

i

−

)
θ
−

(
g
o
l

−

)
θ
(
p
x
e

x
θ

x
θ

)
1
+

i
θ
(
Γ
g
o
l

)
x
−
1
(
g
o
l
2
θ
+
x
g
o
l
1
θ

e
h
t

o
t

d
e
t
c
i
r
t
s
e
r

y
l

b
a
t
i

u
s

,
e
r
u
s
a
e
m
g
n

i
t
n
u
o
c

r
o

e
u
g
s
e
b
e
L

r
e
h
t
i
e

.
r
a
l

u
g
e
r

d
n
a

i

i

l
a
m
n
m
h
t
o
b

e
r
a

s
e
l
p
m
a
x
e

e
s
e
h
t

f
o

l
l

A

.
)
·
(
h

s
i

ν

e
r
u
s
a
e
m
e
s
a
b

e
h
t

,
s
e
s
a
c

l
l
a

n
I

:
s
e
t
o
N

r
o
t
c
a
f

a

y
b

d
e
t
a
l

u
d
o
m

)
s
e
s
a
c

e
m
o
s

n

i
(

(cid:6)

(cid:7)(cid:6)

s∈V

(cid:6)

(s,t)∈E

(cid:8)

3.3 Examples of Graphical Models in Exponential Form 43
where the base measure ν is the counting measure2 restricted to {0,1}m.
Here θst ∈ R is the strength of edge (s, t), and θs ∈ R is a potential for
node s, which models an “external ﬁeld” in statistical physics, or a
noisy observation in spatial statistics. Strictly speaking, the family of
densities (3.8) is more general than the classical Ising model, in which
θst is constant for all edges.
As an exponential family, the Ising index set I consists of the union
V ∪ E, and the dimension of the family is d = m + |E|. The log parti-
tion function is given by the sum

A(θ) = log

x∈{0,1}m

exp

θsxs +

θstxsxt

.

(3.9)

Since this sum is ﬁnite for all choices of θ ∈ Rd, the domain Ω is the full
space Rd, and the family is regular. Moreover, it is a minimal represen-
tation, since there is no nontrivial linear combination of the potentials
equal to a constant ν-a.e.

The standard Ising model can be generalized in a number of dif-
ferent ways. Although Equation (3.8) includes only pairwise inter-
actions, higher-order interactions among the random variables can
also be included. For example, in order to include coupling within
the 3-clique {s, t, u}, we add a monomial of the form xsxtxu, with
corresponding canonical parameter θstu, to Equation (3.8). More gen-
erally, to incorporate coupling in k-cliques, we can add monomi-
als up to order k, which lead to so-called k-spin models in the
statistical physics literature. At the upper extreme, taking k = m
amounts to connecting all nodes in the graphical model, which
allows one to represent any distribution over a binary random vector
X ∈ {0,1}m.

Example 3.2 (Metric Labeling and Potts Model). Here, we con-
sider another generalization of the Ising model: suppose that the ran-
dom variable Xs at each node s ∈ V takes values in the discrete space
2 Explicitly, for each singleton set {x}, this counting measure is deﬁned by ν({x}) = 1 if
x ∈ {0,1}m and ν({x}) = 0 otherwise, and extended to arbitrary sets by sub-additivity.

44 Graphical Models as Exponential Families
X := {0,1, . . . , r − 1}, for some integer r > 2. One interpretation of a
state j ∈ X is as a label, for instance deﬁning membership in an image
segmentation problem. Each pairing of a node s ∈ V and a state j ∈ X
yields a suﬃcient statistic

1
0

if xs = j
otherwise,

I s;j(xs) =

(3.10)
with an associated vector θs = {θs;j, j = 0, . . . , r − 1} of canoni-
for each edge (s, t) and pair of values
cal parameters. Moreover,
(j, k) ∈ X × X , deﬁne the suﬃcient statistics

(cid:7)

(cid:4)

and xt = k,

1
0

if xs = j
otherwise,

I st;jk(xs, xt) =

(cid:10)
j∈X I s;j(xs) = 1 for all xs ∈ X .

(3.11)
as well as the associated parameter θst;jk ∈ R. Viewed as an exponential
family, the chosen collection of suﬃcient statistics deﬁnes an exponen-
tial family with dimension d = r|V | + r2|E|. Like the Ising model, the
log partition function is everywhere ﬁnite, so that the family is regular.
In contrast to the Ising model, however, the family is overcomplete:
indeed, the suﬃcient statistics satisfy various linear relations — for
instance,
A special case of this model is the metric labeling problem, in which
a metric ρ : X × X → [0,∞) speciﬁes the parameterization — that
is, θst;jk = −ρ(j, k) for all (j, k) ∈ X × X . Consequently, the canoni-
cal parameters satisfy the relations θst;kk = 0 for all k ∈ X , θst;jk < 0
for all j (cid:12)= k, and satisfy the reversed triangle inequality (that is,
θst;j(cid:7) ≥ θst;jk + θst;k(cid:7) for all triples (j, k, (cid:10))). Another special case is the
Potts model from statistical physics, in which case θst;kk = α for all
k ∈ X , and θst;jk = β for all j (cid:12)= k.

We now turn to an important class of graphical models based on con-
tinuous random variables:

Example 3.3 (Gaussian MRF). Given an undirected graph G with
vertex set V = {1, . . . , m}, a Gaussian Markov random ﬁeld [220] con-
sists of a multivariate Gaussian random vector (X1, . . . , Xm) that

3.3 Examples of Graphical Models in Exponential Form 45

Fig. 3.1 (a) Undirected graphical model on ﬁve nodes. (b) For a Gaussian Markov random
ﬁeld, the zero pattern of the inverse covariance or precision matrix respects the graph
structure: for any pair i (cid:7)= j, if (i, j) /∈ E, then Θij = 0.

respects the Markov properties of G (see Section 2.2). It can be
represented in exponential form using the collection of suﬃcient statis-
s, s ∈ V ; xsxt, (s, t) ∈ E). We deﬁne an m-vector θ of param-
tics (xs, x2
eters associated with the vector of suﬃcient statistics x = (x1, . . . , xm),
and a symmetric matrix Θ ∈ Rm×m associated with the matrix xxT .
Concretely, the matrix Θ is the negative of the inverse covariance or pre-
cision matrix, and by the Hammersley–Cliﬀord theorem [25, 102, 153],
it has the property that Θst = 0 if (s, t) /∈ E, as illustrated in Fig-
ure 3.1. Consequently, the dimension of the resulting exponential family
is d = 2m + |E|.

With this set-up, the multivariate Gaussian is an exponential fam-

ily3 of the form:

(cid:7)
(cid:19)θ, x(cid:20) +

(cid:8)
(cid:19)(cid:19)Θ, xxT(cid:20)(cid:20) − A(θ,Θ)

1
2

pθ(x) = exp

(cid:10)
(cid:19)(cid:19)Θ, xxT(cid:20)(cid:20) := trace(ΘxxT ) =

m(cid:6)

m(cid:6)

,

(3.12)

where (cid:19)θ, x(cid:20) :=

m
i=1 θixi is the Euclidean inner product on Rm, and

Θijxixj

(3.13)

i=1

j=1

is the Frobenius inner product on symmetric matrices. The integral
deﬁning A(θ,Θ) is ﬁnite only if Θ ≺ 0, so that

Ω = {(θ,Θ) ∈ Rm × Rm×m | Θ ≺ 0, Θ = ΘT}.

(3.14)

3 Our inclusion of the 1

2 -factor in the term 1

2(cid:8)(cid:8)Θ, xxT (cid:9)(cid:9) is for later technical convenience.

46 Graphical Models as Exponential Families

Fig. 3.2 (a) Graphical representation of a ﬁnite mixture of Gaussians: Xs is a multino-
mial label for the mixture component, whereas Ys is conditionally Gaussian given Xs = j,
with Gaussian density pγs (ys | xs) in exponential form. (b) Coupled mixture-of-Gaussian
graphical model, in which the vector X = (X1, . . . , Xm) are a Markov random ﬁeld on an
undirected graph, and the elements of (Y1, . . . , Ym) are conditionally independent given X.

Graphical models are not limited to cases in which the random
variables at each node belong to the same exponential family. More
generally, we can consider heterogeneous combinations of exponential
family members, as illustrated by the following examples.

Example 3.4 (Mixture Models). As shown in Figure 3.2(a), a
scalar mixture model has a very simple graphical interpretation. Con-
cretely, in order to form a ﬁnite mixture of Gaussians, let Xs be a
multinomial variable, taking values in {0,1, . . . , r − 1}. The role of Xs
is to specify the choice of mixture component, so that our mixture
model has r components in total. As in the Potts model described in
Example 3.2, the distribution of this random variable is exponential
family with suﬃcient statistics {I j[xs], j = 0, . . . , r − 1}, and associated
canonical parameters {αs;0, . . . , αs;r−1}.

In order to form the ﬁnite mixture, conditioned on Xs = j, we now
let Ys be conditionally Gaussian with mean and variance (µj, σ2
j ). Each
such conditional distribution can be written in exponential family form
}, with an associated pair of
in terms of the suﬃcient statistics {ys, y2
,− 1
). Overall, we obtain the
canonical parameters (γs;j, γ
exponential family with the canonical parameters
(cid:20), γ
(cid:20) γs;0, . . . , γs;r−1
(cid:18)(cid:19)
(cid:17)
(cid:17)

αs;0, . . . , αs;r−1,

(cid:4)
s;0, . . . , γ

(cid:4)
s;j) := ( µj

σ

(cid:18)(cid:19)

(cid:18)(cid:19)

2
j

2σ

2
j

(cid:21)

,

s

(cid:16)

(cid:17)

θs :=

αs

γs

(cid:20)

(cid:4)
s;r−1
(cid:4)
γ
s

3.3 Examples of Graphical Models in Exponential Form 47

and a density of the form:

pθs(ys, xs) = pα(xs) pγs(ys| xs)

(cid:7) r−1(cid:6)

j=0

∝ exp

(cid:11)

r−1(cid:6)

j=0

αs;jI j(xs) +

I j(xs)

γs;jys + γ

(cid:12)(cid:8)

.

(3.15)

(cid:4)
s;jy2

s

The pair

(Xs, Ys)

serves a basic block for building more
sophisticated graphical models, suitable for describing multivariate
data ((X1, Y1), . . . ,(Xm, Ym)). For instance, suppose that the vector
X = (X1, . . . , Xm) of multinomial variates is modeled as a Markov ran-
dom ﬁeld (see Example 3.2 on the Potts model) with respect to some
underlying graph G = (V, E), and the variables Ys are conditionally
independent given {X = x}. These assumptions lead to an exponential
family pθ(y, x) with parameters θ = (α, γ), and density
pα(x)pγ(y | x) ∝ exp

(cid:22)(cid:2)

(cid:4)(cid:6)

αst(xs, xt)

(cid:6)

αs(xs) +

s∈V

(s,t)∈E

pγs(ys | xs),
(3.16)

s∈V

corresponding to a product of the Potts-type distribution pα(x) over
(cid:10)
X, and the local conditional distributions pγs(ys| xs). Here, we have
used αs(xs) as a shorthand for the exponential family representation
r−1
j=0 αs;jI j(xs), and similarly for the quantity αst(xs, xt); see Exam-

ple 3.2 where this notation was used.

Whereas the mixture model just described is a two-level hierarchy, the
following example involves three distinct levels:

Example 3.5 (Latent Dirichlet Allocation). The latent Dirichlet
allocation model [32] is a particular type of hierarchical Bayes model
for capturing the statistical dependencies among words in a corpus of
documents. It involves three diﬀerent types of random variables: “docu-
ments” U, “topics” Z, and “words” W . Words are multinomial random
variables ranging over some vocabulary. Topics are also multinomial
random variables. Associated to each value of the topic variable there
is a distribution over words. A document is a distribution over topics.

48 Graphical Models as Exponential Families

Finally, a corpus is deﬁned by placing a distribution on the documents.
For the latent Dirichlet allocation model, this latter distribution is a
Dirichlet distribution.
More formally, words W are drawn from a multinomial distribu-
tion, P(W = j| Z = i; γ) = exp(γij), for j = 0,1, . . . , k − 1, where γij is
a parameter encoding the probability of the jth word under the ith
topic. This conditional distribution can be expressed as an exponential
family in terms of indicator functions as follows:

pγ(w | z) ∝ exp

γijI i(z) I j(w)

,

(3.17)

(cid:23) r−1(cid:6)

k−1(cid:6)

i=0

j=0

(cid:14) r−1(cid:6)

i=0

(cid:24)

(cid:15)

where I i(z) is an {0,1}-valued indicator for the event {Z = i}, and
similarly for I j(w). At the next level of the hierarchy (see Figure 3.3),
the topic variable Z also follows a multinomial distribution whose para-
meters are determined by the Dirichlet variable as follows:

p(z | u) ∝ exp

I i[z]log ui

.

(3.18)

the top level of

form pα(u) ∝ exp{(cid:10)

Finally, at
the Dirichlet vari-
able U has a density with respect to Lebesgue measure of the
i=0 αi log ui}. Overall then, for a single triplet
r−1
X := (U, Z, W ), the LDA model is an exponential family with param-
eter vector θ := (α, γ), and an associated density of the form:

the hierarchy,

(cid:7) r−1(cid:6)
(cid:4)
r−1(cid:6)

i=0

αi log ui +

k−1(cid:6)

(cid:8)

r−1(cid:6)

i=0

I i[z]log ui

(cid:22)

× exp

γijI i[z]I j[w]

.

(3.19)

pα(u)p(z | u) pγ(w | z) ∝ exp

The suﬃcient statistics φ consist of the collections of functions {log ui},
{I i[z]log ui}, and {I i[z]I j[w]}. As illustrated in Figure 3.3, the full LDA
model entails replicating these types of local structures many times.

i=0

j=0

Many graphical models include what are known as “hard-core”
constraints, meaning that a subset of conﬁgurations are forbidden.

3.3 Examples of Graphical Models in Exponential Form 49

Fig. 3.3 Graphical illustration of the Latent Dirichlet allocation (LDA) model. The word
variable W is multinomial conditioned on the underlying topic Z, where γ speciﬁes the topic
distributions. The topics Z are also modeled as multinomial variables, with distributions
parameterized by a probability vector U that follows a Dirichlet distribution with parameter
α. This model is an example of a hierarchical Bayesian model. The rectangles, known as
plates, denote replication of the random variables.

Instances of such problems include decoding of binary linear codes, and
other combinatorial optimization problems (e.g., graph matching, cov-
ering, packing, etc.). At ﬁrst glance, it might seem that such families
of distributions cannot be represented as exponential families, since
the density pθ in any exponential family is strictly positive — that
is, pθ(x) > 0 for all x ∈ X m. In the following example, we show that
these hard-core constraints can be incorporated within the exponential
family framework by making appropriate use of the underlying base
measure ν.

Example 3.6 (Models with Hard Constraints). One important
domain in which hard-core constraints arise is communication theory,
and in particular the problem of error-control coding [87, 166, 200]. To
motivate the coding problem, suppose that two people — following an
old convention, let us call them Alice and Bob — wish to communicate.
We assume that they can communicate by transmitting a sequence of
0s and 1s, but make the problem interesting by assuming that the
communication channel linking them behaves in a random manner.
Concretely, in a “bit-ﬂipping” channel, any binary digit transmitted
by Alice is received correctly by Bob only with probability 1 − . As
a probabilistic model, this channel can be modeled by the conditional
distribution

(cid:4)
1 − 


p(y | x) :=

if x = y
if x (cid:12)= y,

50 Graphical Models as Exponential Families
where x ∈ {0,1} represents the bit transmitted by Alice, and y ∈ {0,1}
represents the bit received by Bob.

In order to mitigate the “noisiness” of the channel, Alice and Bob
agree on the following block coding scheme: instead of transmitting
a single bit, they communicate using strings (x1, x2, . . . , xm) of bits,
and moreover, they agree to use only a subset of the total number
2m of length m binary strings. These privileged strings, which are
known as codewords, can be deﬁned using a particular type of graphical
model. Concretely, suppose that Alice decides to choose from among
strings x ∈ {0,1}m that satisfy a set of parity checks — say of the form
x1 ⊕ x2 ⊕ x3 = 0, where ⊕ denotes addition in modulo two arithmetic.
Let us consider a collection F of such parity checks; each a ∈ F enforces
a parity check constraint on some subset N(a) ⊂ {1, . . . , m} of bits. If
we deﬁne the indicator function

(cid:4)

(cid:25)

ψa(xN(a)) :=

1
0

i∈N(a) xi = 0

if
otherwise,

(3.20)

(cid:5)

a

of

all

linear

code

bit

binary

consists

strings
then
(x1, x2, . . . , xm) ∈ {0,1}m for which
a∈F ψa(xN(a)) = 1. These
constraints are known as “hard-core,” since they take the value 0 for
some settings of x, and hence eliminate such conﬁgurations from the
support of the distribution. Letting (y1, . . . , ym) ∈ {0,1}m denote the
string of bits received by Bob, his goal is to use these observations
to infer which codeword was transmitted by Alice. Depending on
the error metric used, this decoding problem corresponds to either
computing marginals or modes of the posterior distribution

p(x1, . . . , xm | y1, . . . , ym) ∝ m(cid:2)

ψa(xN(a)).

(3.21)

(cid:2)

a∈F

p(yi | xi)

i=1

This distribution can be described by a factor graph, with the bits xi
represented as unshaded circular variable nodes, the observed values
yi as shaded circular variable nodes, and the parity check indicator
functions represented at the square factor nodes (see Figure 2.9).

The code can also be viewed as an exponential family on this graph,
if we take densities with respect to an appropriately chosen base mea-
sure. In particular, let us use the parity checks to deﬁne the counting

measure restricted to valid codewords

ν({x}) :=

ψa(xN(a)).

(3.22)

3.4 Mean Parameterization and Inference Problems

51

(cid:2)

a∈F

Moreover, since the quantities yi are observed, they may be viewed as
ﬁxed, so that the conditional distribution p(yi | xi) can be viewed as
some function q(·) of xi only. A little calculation shows that we can
write this function in exponential form as

q(xi; θi) = exp{θixi − log(1 + exp(θi))},

(3.23)

is deﬁned by the obser-
where the exponential parameter θi
vation yi and conditional distribution p(yi | xi) via the relation
θi = log p(yi | 1)/p(yi | 0). In the particular case of the binary symmet-
ric channel, these canonical parameters take the form

θi = (2yi − 1) log

1 − 


.

(3.24)

Note that we are using the fact that the vector (y1, y2, . . . , ym) is
observed, and hence can be viewed as ﬁxed. With this set-up, the dis-
tribution (3.21) can be cast as an exponential family, where the density
is taken with respect to the restricted counting measure (3.22), and has
the form pθ(x | y) ∝ exp

(cid:14)(cid:10)

(cid:15)

m
i=1 θixi

.

3.4 Mean Parameterization and Inference Problems

Thus far, we have characterized any exponential family member pθ by
its vector of canonical parameters θ ∈ Ω. As we discuss in this section,
it turns out that any exponential family has an alternative parame-
terization in terms of a vector of mean parameters. Moreover, vari-
ous statistical computations, among them marginalization and maxi-
mum likelihood estimation, can be understood as transforming from
one parameterization to the other.

We digress momentarily to make an important remark regarding
the role of observed variables or conditioning for the marginalization
problem. As discussed earlier, applications of graphical models fre-
quently involve conditioning on a subset of random variables — say

52 Graphical Models as Exponential Families

Y — that represent observed quantities, and computing marginals
under the posterior distribution pθ(x | y). The application to error-
correcting coding, just discussed in Example 3.6, is one such example.
So as to simplify notation in our development to follow, it is convenient
to no longer make direct reference to observed variables, but rather
discuss marginalization and other computational problems only in
reference to unconditional forms of exponential families. For such
computational purposes, there is no loss of generality in doing so, since
the eﬀects of observations can always be absorbed by modifying the
canonical parameters θ and/or the suﬃcient statistics φ appropriately.
(For instance, in Example 3.6, the noisy observation yi at node i con-
tributes a new factor exp(θixi) to the exponential family factorization,
as described in Equation (3.23).)

3.4.1 Mean Parameter Spaces and Marginal Polytopes

Let p be a given density deﬁned with respect to the underlying base
measure ν; for the moment, we do not assume that p is a member of
an exponential family deﬁned with respect to ν. The mean parameter
µα associated with a suﬃcient statistic φα : X m → R is deﬁned by the
expectation

(cid:13)

µα = Ep[φα(X)] =

φα(x)p(x) ν(dx),

for α ∈ I.

(3.25)

In this way, we deﬁne a vector of mean parameters (µ1, . . . , µd), one for
each of the |I| = d suﬃcient statistics φα, with respect to an arbitrary
density p. An interesting object is the set of all such vectors µ ∈ Rd
traced out as the underlying density p is varied. More formally, we
deﬁne the set

M := { µ ∈ Rd | ∃ p s.t. Ep[φα(X)] = µα ∀α ∈ I},

(3.26)

corresponding to all realizable mean parameters. It is important to
note that in this deﬁnition, we have not restricted the density p to
the exponential family associated with the suﬃcient statistics φ and
base measure ν. However, it turns out that under suitable technical
conditions, this vector provides an alternative parameterization of this
exponential family.

3.4 Mean Parameterization and Inference Problems

53

We illustrate these concepts with a continuation of a previous

example:

Example 3.7 (Gaussian MRF Mean Parameters). Using the
canonical parameterization of the Gaussian Markov random ﬁeld pro-
vided in Example 3.3, the mean parameters for a Gaussian Markov ran-
dom ﬁeld are the second-order moment matrix Σ := E[XX T ] ∈ Rm×m,
and the mean vector µ = E[X] ∈ Rm. For this particular model, it is
straightforward to characterize the set M of globally realizable mean
parameters (µ,Σ). We begin by recognizing that if (µ,Σ) are realized
by some distribution (not necessarily Gaussian), then Σ − µµT must
be a valid covariance matrix of the random vector X, implying that
the positive semideﬁniteness (PSD) condition Σ − µµT (cid:25) 0 must hold.
Conversely, any pair (µ,Σ) for which the PSD constraint holds, we may
construct a multivariate Gaussian distribution with mean µ, and (pos-
sibly degenerate) covariance Σ − µµT , which by construction realizes
(µ,Σ). Thus, we have established that for a Gaussian Markov random
ﬁeld, the set M has the form

M = {(µ,Σ) ∈ Rm × S m

+ | Σ − µµT (cid:25) 0},

(3.27)
where S m
+ denotes the set of m × m symmetric positive semideﬁnite
matrices. Figure 3.4 illustrates this set in the scalar case (m = 1),

Fig. 3.4 Illustration of the set M for a scalar Gaussian: the model has two mean parameters
2 ≥ 0. Note
µ = E[X] and Σ11 = E[X
that the set M is convex, which is a general property.

2], which must satisfy the quadratic constraint Σ11 − µ

54 Graphical Models as Exponential Families

where the mean parameters µ = E[X] and Σ11 = E[X2] must satisfy
the quadratic constraint Σ11 − µ2 ≥ 0.

The set M is always a convex subset of Rd. Indeed, if µ and µ
(cid:4) are
both elements of M, then there must exist distributions p and p
(cid:4) that
(cid:4) = Ep(cid:2)[φ(X)]. For any
realize them, meaning that µ = Ep[φ(X)] and µ
λ ∈ [0,1], the convex combination µ(λ) := λµ + (1 − λ)µ
(cid:4) is realized by
the mixture distribution λp + (1 − λ)p
(cid:4), so that µ(λ) also belongs to
M. In Appendix B.3, we summarize further properties of M that hold
for general exponential families.
The case of discrete random variables yields a set M with some spe-
cial properties. More speciﬁcally, for any random vector (X1, X2, . . . Xm)
such that the associated state space X m is ﬁnite, we have the
representation
M =

(cid:4)
µ ∈ Rd | µ =

for some p(x) ≥ 0,

(cid:6)
(cid:6)

x∈X m

φ(x)p(x)

(cid:22)

x∈X m
= conv{φ(x), x ∈ X m},

p(x) = 1

(3.28)

where conv denotes the convex hull operation (see Appendix A.2). Con-
sequently, when |X m| is ﬁnite, the set M is — by deﬁnition — a convex
polytope.

The Minkowski–Weyl theorem [203], stated in Appendix A.2, pro-
vides an alternative description of a convex polytope. As opposed
to the convex hull of a ﬁnite collection of vectors, any polytope M
can also be characterized by a ﬁnite collection of linear inequality
constraints. Explicitly, for any polytope M, there exists a collection
{(aj, bj) ∈ Rd × R | j ∈ J } with |J | ﬁnite such that
M = {µ ∈ Rd | (cid:19)aj, µ(cid:20) ≥ bj ∀j ∈ J }.

(3.29)
In geometric terms, this representation shows that M is equal to the
intersection of a ﬁnite collection of half-spaces, as illustrated in Fig-
ure 3.5. Let us show the distinction between the convex hull (3.28) and
linear inequality (3.29) representations using the Ising model.

3.4 Mean Parameterization and Inference Problems

55

Fig. 3.5 Generic illustration of M for a discrete random variable with |X m| ﬁnite. In this
case, the set M is a convex polytope, corresponding to the convex hull of {φ(x) | x ∈ X m}.
By the Minkowski–Weyl theorem, this polytope can also be written as the intersection
of a ﬁnite number of half-spaces, each of the form {µ ∈ Rd | (cid:8)aj , µ(cid:9) ≥ bj} for some pair
(aj , bj) ∈ Rd × R.

Example 3.8 (Ising Mean Parameters). Continuing from Exam-
ple 3.1, the suﬃcient statistics for the Ising model are the singleton
functions (xs, s ∈ V ) and the pairwise functions (xsxt, (s, t) ∈ E). The
vector of suﬃcient statistics takes the form:

(cid:23)

(cid:24) ∈ R|V |+|E|

φ(x) :=

xs, s ∈ V ; xsxt, (s, t) ∈ E

.

(3.30)

The associated mean parameters correspond to particular marginal
probabilities, associated with nodes and edges of the graph G as

for all s ∈ V , and

(3.31a)

for all (s, t) ∈ E.

µs = Ep[Xs] = P[Xs = 1]
µst = Ep[XsXt] = P[(Xs, Xt) = (1,1)]

(3.31b)
Consequently, the mean parameter vector µ ∈ R|V |+|E| consists of
marginal probabilities over singletons (µs), and pairwise marginals
over variable pairs on graph edges (µst). The set M consists of the
convex hull of {φ(x), x ∈ {0,1}m}, where φ is given in Equation (3.30).
In probabilistic terms, the set M corresponds to the set of all
singleton and pairwise marginal probabilities that can be realized
by some distribution over (X1, . . . , Xm) ∈ {0,1}m. In the polyhedral
combinatorics literature, this set is known as the correlation polytope,
or the cut polytope [69, 187].

56 Graphical Models as Exponential Families

To make these ideas more concrete, consider the simplest nontrivial
case: namely, a pair of variables (X1, X2), and the graph consisting of
the single edge joining them. In this case, the set M is a polytope in
three dimensions (two nodes plus one edge): it is the convex hull of
the vectors {(x1, x2, x1x2) | (x1, x2) ∈ {0,1}2}, or more explicitly

conv{(0,0,0),(1,0,0),(0,1,0),(1,1,1)},

as illustrated in Figure 3.6.

Let us also consider the half-space representation (3.29) for this
case. Elementary probability theory and a little calculation shows that
the three mean parameters (µ1, µ2, µ12) must satisfy the constraints
0 ≤ µ12 ≤ µi
for i = 1,2 and 1 + µ12 − µ1 − µ2 ≥ 0. We can write
these constraints in matrix-vector form as



0
1
0
−1 −1

0
1
0 −1
1 −1
1



 µ1

µ2
µ12

 ≥



 .

0
0
0
−1

These four constraints provide an alternative characterization of the
3D polytope illustrated in Figure 3.6.

Fig. 3.6 Illustration of M for the special case of an Ising model with two variables
(X1, X2) ∈ {0,1}2. The four mean parameters µ1 = E[X1], µ2 = E[X2] and µ12 = E[X1X2]
must satisfy the constraints 0 ≤ µ12 ≤ µi for i = 1,2, and 1 + µ12 − µ1 − µ2 ≥ 0. These
constraints carve out a polytope with four facets, contained within the unit hypercube
[0,1]3.

(cid:14)

(cid:7)

(cid:2)

a∈F

(cid:2)

a∈F

(cid:15)

(cid:8)

3.4 Mean Parameterization and Inference Problems

57

Our next example deals with a interesting family of polytopes that

arises in error-control coding and binary matroid theory:

Example 3.9 (Codeword Polytopes and Binary Matroids).
Recall the deﬁnition of a binary linear code from Example 3.6: it
corresponds to the subset of binary strings x ∈ {0,1}m that satisfy a
set of parity check relations

C :=

x ∈ {0,1}m |

ψa(xN(a)) = 1

,

check

each parity

function operates

subset
where
on the
N(a) ⊂ {1,2, . . . , m} of bits. Viewed as an exponential
family,
the suﬃcient statistics are simply φ(x) = (x1, x2, . . . , xm), the base
measure ν is counting measure restricted to the set C. Consequently,
the set M for this problem corresponds to the codeword polytope —
namely, the convex hull of all possible codewords

M = conv

x ∈ {0,1}m |

= conv{x ∈ C}.

ψa(xN(a)) = 1

(3.32)

To provide a concrete illustration, consider the code on m = 3
bits, deﬁned by the single parity check relation x1 ⊕ x2 ⊕ x3 = 0.
Figure 3.7(a) shows the factor graph representation of this toy
code. This parity check eliminates half of the 23 = 8 possible binary
sequences of length 3. The codeword polytope is simply the convex
hull of {(0,0,0),(0,1,1),(1,0,1),(1,1,0)}, as illustrated in Figure 3.7(b),
Equivalently, we can represent this codeword polytope in terms of half-
space constraints. For this single parity check code, the codeword poly-
tope is deﬁned by the four inequalities

(1 − µ1) + (1 − µ2) + (1 − µ3) ≥ 1,
(1 − µ1) + µ2 + µ3 ≥ 1,
µ1 + (1 − µ2) + µ3 ≥ 1,
µ1 + µ2 + (1 − µ3) ≥ 1.

and

(3.33a)

(3.33b)

(3.33c)

(3.33d)

58 Graphical Models as Exponential Families

3.7 Illustration of M for

the

Fig.
the binary linear
C = {(0,0,0),(0,1,1),(1,1,0),(1,1,0)}. This code is deﬁned by a single parity check.

special

case

of

code

As we discuss at more length in Section 8.4.4, these inequalities can
be understood as requiring that (µ1, µ2, µ3) is at least distance 1 from
each of the forbidden odd-parity vertices of the hypercube {0,1}3.

Of course, for larger code lengths m and many parity checks, the
associated codeword polytope has a much more complicated structure.
It plays a key role in the error-control decoding problem [78], studied
intensively in the coding and information theory communities. Any
binary linear code can be identiﬁed with a binary matroid [186], in
which context the codeword polytope is referred to as the cycle polytope
of the binary matroid. There is a rich literature in combinatorics on the
structure of these codeword or cycle polytopes [9, 69, 104, 215].

Examples 3.8 and 3.9 are speciﬁc instances of a more general object
that we refer to as the marginal polytope for a discrete graphical
model. The marginal polytope is deﬁned for any graphical model with
multinomial random variables Xs ∈ Xs := {0,1, . . . , rs − 1} at each ver-
tex s ∈ V ; note that the cardinality |Xs| = rs can diﬀer from node to
node. Consider the exponential family deﬁned in terms of {0,1}-valued
indicator functions

∀s ∈ V, j ∈ Xs,

I s;j(xs) :=

∀(s, t) ∈ E,(j, k)

I st;jk(xs, xt) :=

(cid:4)
(cid:4)

1
0

1
0

if xs = j
otherwise.

if (xs, xt) = (j, k)
otherwise.

(3.34)

3.4 Mean Parameterization and Inference Problems

59

We refer to the suﬃcient statistics (3.34) as the standard overcom-
plete representation. Its overcompleteness was discussed previously in
Example 3.2.
very intuitive form: in particular, for each node s ∈ V
µs;j = Ep[I j(Xs)] = P[Xs = j] ∀j ∈ Xs,

With this choice of suﬃcient statistics, the mean parameters take a

(3.35)

and for each edge (s, t) ∈ E, we have
µst;jk = Ep[I st;jk(Xs, Xt)] = P[Xs = j, Xt = k] ∀(j, k) ∈ Xs ∈ Xt.

(3.36)

Thus, the mean parameters correspond to singleton marginal distribu-
tions µs and pairwise marginal distributions µst associated with the
nodes and edges of the graph. In this case, we refer to the set M as the
marginal polytope associated with the graph, and denote it by M(G).
Explicitly, it is given by
(cid:15)
M(G) := {µ ∈ Rd | ∃p such that (3.35) holds ∀(s; j), and
(3.36) holds ∀(st; jk

(3.37)

.

Note that the correlation polytope for the Ising model presented
in Example 3.8 is a special case of a marginal polytope, obtained
for Xs ∈ {0,1} for all nodes s. The only diﬀerence is we have deﬁned
marginal polytopes with respect to the standard overcomplete basis of
indicator functions, whereas the Ising model is usually parameterized as
a minimal exponential family. The codeword polytope of Example 3.9 is
another special case of a marginal polytope. In this case, the reduction
requires two steps: ﬁrst, we convert the factor graph representation of
the code — for instance, as shown in Figure 3.7(a) — to an equiva-
lent pairwise Markov random ﬁeld, involving binary variables at each
bit node, and higher-order discrete variables at each factor node. (See
Appendix E.3 for details of this procedure for converting from factor
graphs to pairwise MRFs.) The marginal polytope associated with this
pairwise MRF is simply a lifted version of the codeword polytope. We
discuss these and other examples of marginal polytopes in more detail
in later sections.

60 Graphical Models as Exponential Families

For the toy models considered explicitly in Examples 3.8 and 3.9,
the number of half-space constraints |J | required to characterize the
marginal polytopes was very small (|J | = 4 in both cases). It is natu-
ral to ask how the number of constraints required grows as a function
of the graph size. Interestingly, we will see later that this so-called
facet complexity depends critically on the graph structure. For trees,
any marginal polytope is characterized by local constraints — involving
only pairs of random variables on edges — with the total number grow-
ing only linearly in the graph size. In sharp contrast, for general graphs
with cycles, the constraints are very nonlocal and the growth in their
number is astonishingly fast. For the special case of the Ising model,
the book by Deza and Laurent [69] contains a wealth of information
about the correlation/cut polytope. The intractability of representing
marginal polytopes in a compact manner is one underlying cause of the
complexity in performing statistical computation.

3.4.2 Role of Mean Parameters in Inference Problems

The preceding examples suggest that mean parameters have a cen-
tral role to play in the marginalization problem. For the multivariate
Gaussian (Example 3.7), an eﬃcient algorithm for computing the mean
parameterization provides us with both the Gaussian mean vector, as
well as the associated covariance matrix. For the Ising model (see Exam-
ple 3.8), the mean parameters completely specify the singleton and
pairwise marginals of the probability distribution; the same statement
holds more generally for the multinomial graphical model deﬁned by the
standard overcomplete parameterization (3.34). Even more broadly, the
computation of the forward mapping, from the canonical parameters
θ ∈ Ω to the mean parameters µ ∈ M, can be viewed as a fundamen-
tal class of inference problems in exponential family models. Although
computing the mapping is straightforward for most low-dimensional
families, the computation of this forward mapping is
exponential
extremely diﬃcult for many high-dimensional exponential families.
The backward mapping, namely from mean parameters µ ∈
M to canonical parameters θ ∈ Ω, also has a natural statistical
interpretation. In particular, suppose that we are given a set of samples
1 := {X1, . . . , X n}, drawn independently from an exponential family
X n

3.5 Properties of A 61

n(cid:6)

log pθ(X i) = (cid:19)θ,(cid:3)µ(cid:20) − A(θ),

member pθ(x), where the parameter θ is unknown. If the goal is to esti-
mate θ, the classical principle of maximum likelihood dictates obtaining

an estimate(cid:3)θ by maximizing the likelihood of the data, or equivalently

(after taking logarithms and rescaling), maximizing the quantity

1
n

(cid:10)

n

(cid:10)(θ; X n

1 ) :=

(3.38)

parameters deﬁned by the data X n

i=1
n
i=1 φ(X i) is the vector of empirical mean
1 . The maximum likelihood estimate

where (cid:3)µ :=(cid:3)E[φ(X)] = 1
(cid:3)θ is chosen to achieve the maximum of this objective function. Note
that computing (cid:3)θ is, in general, another challenging problem, since
tionarity condition E(cid:3)θ[φ(X)] =(cid:3)µ. Finding the unique solution to this

the objective function involves the log partition function A. As will be
demonstrated by the development to follow, under suitable conditions,
the maximum likelihood estimate is unique, and speciﬁed by the sta-
equation is equivalent to computing the backward mapping µ (cid:26)→ θ, from
mean parameters to canonical parameters. In general, computing this
inverse mapping is also computationally intensive.

3.5 Properties of A

With this background in mind, we now turn to a deeper exploration of
the properties of the cumulant function A. Perhaps the most important
property of A is its convexity, which brings us into convex analysis,
and more speciﬁcally leads us to conjugate duality. Under suitable
∗ — or more pre-
conditions, the function A and its conjugate dual A
cisely, their derivatives — turn out to deﬁne a one-to-one and sur-
jective mapping between the canonical and mean parameters. As dis-
cussed above, the mapping between canonical and mean parameters
is a core challenge that underlies various statistical computations in
high-dimensional graphical models.

3.5.1 Derivatives and Convexity

Recall that a real-valued function g is convex if, for any two x, y belong-
ing to the domain of g and any scalar λ ∈ (0,1), the inequality

g(λx + (1 − λ)y) ≤ λg(x) + (1 − λ)g(y)

(3.39)

62 Graphical Models as Exponential Families

holds. In geometric terms, this inequality means that the line con-
necting the function values g(x) and g(y) lies above the graph of the
function itself. The function is strictly convex if the inequality (3.39) is
strict for all x (cid:12)= y. (See Appendix A.2.5 for some additional properties
of convex functions.) We begin by establishing that the log partition
function is smooth, and convex in terms of θ.

Proposition 3.1. The cumulant function

(cid:13)

A(θ) := log

X m

exp(cid:19)θ, φ(x)(cid:20) ν(dx)

(3.40)

associated with any regular exponential
properties:

family has the following

(a) It has derivatives of all orders on its domain Ω. The ﬁrst
two derivatives yield the cumulants of the random vector
φ(X) as follows:

(cid:13)

∂A
∂θα

∂2A

∂θα ∂θβ

φα(x)pθ(x)ν(dx).

(θ) = Eθ[φα(X)] :=
(θ) = Eθ[φα(X)φβ(X)] − Eθ[φα(X)]Eθ[φβ(X)].
(3.41b)

(3.41a)

(b) Moreover, A is a convex function of θ on its domain Ω, and

strictly so if the representation is minimal.

Proof. Let us assume that diﬀerentiating through the integral (3.40)
deﬁning A is permitted; verifying the validity of this assumption
is a standard argument using the dominated convergence theorem
(e.g., Brown [43]). Under this assumption, we have

∂A
∂θα

(θ) = ∂
∂θα

(cid:13)

(cid:7)
 (cid:1)
(cid:11)(cid:1)

(cid:8)
!
exp(cid:19)θ, φ(x)(cid:20) ν(dx)
X m
(cid:12)
exp(cid:19)θ, φ(x)(cid:20) ν(dx)
X m
X m exp(cid:19)θ, φ(u)(cid:20) ν(du)

log

=

∂

∂θα

(cid:13)

=

φα(x)

X m

(cid:1)

= Eθ[φα(X)],

3.5 Properties of A 63

exp(cid:19)θ, φ(x)(cid:20) ν(dx)
X m exp(cid:19)θ, φ(u)(cid:20) ν(du)

which establishes Equation (3.41a). The formula for the higher-order
derivatives can be proven in an entirely analogous manner.

2

∂

2

A
∂θαθβ

Observe from Equation (3.41b) that the second-order partial deriva-
is equal to the covariance element cov{φα(X), φβ(X)}.
tive
Therefore, the full Hessian ∇2A(θ) is the covariance matrix of the
random vector φ(X), and so is positive semideﬁnite on the open set
Ω, which ensures convexity (see Theorem 4.3.1 of Hiriart-Urruty and
Lemar´echal [112]). If the representation is minimal, there is no nonzero
vector a ∈ Rd and constant b ∈ R such that (cid:19)a, φ(x)(cid:20) = b holds ν-a.e.
This condition implies varθ[(cid:19)a, φ(x)(cid:20)] = aT∇2A(θ)a > 0 for all a ∈ Rd
and θ ∈ Ω; this strict positive deﬁniteness of the Hessian on the open
set Ω implies strict convexity [112].

3.5.2 Forward Mapping to Mean Parameters

We now turn to an in-depth consideration of the forward mapping
θ (cid:26)→ µ, from the canonical parameters θ ∈ Ω deﬁning a distribution pθ
to its associated vector of mean parameters µ ∈ Rd. Note that the gradi-
ent ∇A can be viewed as mapping from Ω to Rd. Indeed, Proposition 3.1
demonstrates that the range of this mapping is contained within the
set M of realizable mean parameters, deﬁned previously as

M := {µ ∈ Rd | ∃ p s.t. Ep[φ(X)] = µ}.

We will see that a great deal hinges on the answers to the following
two questions:

(a) when does ∇A deﬁne a one-to-one mapping?
(b) when does the image of Ω under the mapping ∇A — that
is, the set ∇A(Ω) — fully cover the set M?

The answer to the ﬁrst question is relatively straightforward, essen-
tially depending on whether or not the exponential family is minimal.
The second question is somewhat more delicate: to begin, note that our

64 Graphical Models as Exponential Families
deﬁnition of M allows for mean parameters µ ∈ Rd generated by any
possible distribution, not just distributions pθ in the exponential family
deﬁned by the suﬃcient statistics φ. It turns out that this extra free-
dom does not really enlarge the set M; as Theorem 3.3 makes precise,
under suitable conditions, all mean parameters in M can be realized
by an exponential family distribution (or, for boundary points, by a
limiting sequence of such distributions).
We begin with a result addressing the ﬁrst question:
Proposition 3.2. The gradient mapping ∇A : Ω → M is one-to-one
if and only if the exponential representation is minimal.

Proof. If the representation is not minimal, then there must exist a
nonzero vector γ ∈ Rd for which (cid:19)γ, φ(x)(cid:20) is a constant (almost surely
with respect to ν). Given any parameter θ1 ∈ Ω, let us deﬁne another
parameter vector θ2 = θ1 + tγ, where t ∈ R. Since Ω is open, choosing
t suﬃciently small ensures that θ2 ∈ Ω as well. By the condition on
the vector γ, the densities pθ1 and pθ2 induce the same probability
distribution (only their normalization constants diﬀer). For this pair,
we have ∇A(θ1) = ∇A(θ2), so that ∇A is not one-to-one.

Conversely, if the representation is minimal, then A is strictly con-
vex by Proposition 3.1. For any strictly convex and diﬀerentiable func-
tion, we have A(θ2) > A(θ1) + (cid:19)∇A(θ1), θ2 − θ1(cid:20), for all θ1 (cid:12)= θ2 in the
domain Ω. The same inequality also holds with the roles of θ1 and θ2
reversed; adding together these inequalities yields that

(cid:19)∇A(θ1) − ∇A(θ2), θ1 − θ2(cid:20) > 0

for all distinct θ1, θ2 ∈ Ω, which shows that ∇A is one-to-one.

In general, although the gradient mapping ∇A is not one-to-one for
an overcomplete representation, there is still a one-to-one correspon-
dence between each element of ∇A(Ω) and an aﬃne subset of Ω. In
particular, this aﬃne subset contains all those canonical parameters θ
that are mapped to the same mean parameter. For either a minimal
or an overcomplete representation, we say that a pair (θ, µ) is dually

3.5 Properties of A 65
coupled if µ = ∇A(θ). This notion of dual coupling plays an important
role in the sequel.
We now turn to the second issue regarding the image ∇A(Ω) of
the domain of valid canonical parameters Ω under the gradient map-
ping ∇A. Speciﬁcally, the goal is to determine for which mean parame-
ter vectors µ ∈ M does there exist a vector θ = θ(µ) ∈ Ω such that
Eθ[φ(X)] = µ. The solution turns out to be rather simple: the image
∇A(Ω) is simply the interior M◦. This fact is remarkable: it means
that (disregarding boundary points) all mean parameters M that are
realizable by some distribution can be realized by a member of the
exponential family. To provide some intuition into this fact, consider
the maximum entropy problem (3.3) for a given mean parameter µ
in the interior of M. As discussed earlier, when a solution to this
problem exists, it necessarily takes the form of an exponential fam-
ily member, say pθ(µ). Moreover, from the optimality conditions for the
maximum entropy problem, this exponential family member must sat-
isfy the moment-matching conditions Eθ(µ)[φ(X)] = µ. Note that these
moment-matching conditions are identical to those deﬁning the maxi-
mum likelihood problem (3.38) — as we discuss in the following section,
this fact is not coincidental, but rather a consequence of the primal–
dual relationship between maximum entropy and maximum likelihood.

In a minimal exponential family, the gradient map
Theorem 3.3.
∇A is onto the interior of M, denoted by M◦. Consequently, for each
µ ∈ M◦, there exists some θ = θ(µ) ∈ Ω such that Eθ[φ(X)] = µ.

We provide the proof of this result in Appendix B. In conjunction
with Proposition 3.2, Theorem 3.3 guarantees that for minimal expo-
nential families, each mean parameter µ ∈ M◦ is uniquely realized by
some density pθ(µ) in the exponential family. However, a typical expo-
nential family {pθ | θ ∈ Ω} describes only a strict subset of all possible
densities (with respect to the given base measure ν). In this case, there
must exist at least some other density p — albeit not a member of an
exponential family — that also realizes µ. The distinguishing property
of the exponential distribution pθ(µ) is that, among the set of all dis-
tributions that realize µ, it has the maximum entropy. The connection

66 Graphical Models as Exponential Families

between A and the maximum entropy principle is speciﬁed precisely in
terms of the conjugate dual function A

∗, to which we now turn.

3.6 Conjugate Duality: Maximum Likelihood and

Maximum Entropy

Conjugate duality is a cornerstone of convex analysis [112, 203], and
is a natural source for variational representations. In this section, we
explore the relationship between the log partition function A and its
∗. This conjugate relationship is deﬁned by a
conjugate dual function A
variational principle that is central to the remainder of this survey, in
that it underlies a wide variety of known algorithms, both of an exact
nature (e.g., the junction tree algorithm and its special cases of Kalman
ﬁltering, the forward–backward algorithm, peeling algorithms) and an
approximate nature (e.g., sum-product on graphs with cycles, mean
ﬁeld, expectation-propagation, Kikuchi methods, linear programming,
and semideﬁnite relaxations).

3.6.1 General Form of Conjugate Dual

Given a function A, the conjugate dual function to A, which we denote
by A

∗, is deﬁned as follows:

∗
A

(µ) := sup
θ∈Ω

{(cid:19)µ, θ(cid:20) − A(θ)}.

(3.42)
Here µ ∈ Rd is a ﬁxed vector of so-called dual variables of the same
dimension as θ. Our choice of notation — i.e., using µ again —
is deliberately suggestive, in that these dual variables turn out to
have a natural interpretation as mean parameters. Indeed, we have
already mentioned one statistical interpretation of this variational prob-
lem (3.42); in particular, the right-hand side is the optimized value of
the rescaled log likelihood (3.38). Of course, this maximum likelihood
problem only makes sense when the vector µ belongs to the set M; an
n
i=1 φ(X i) induced
1 = {X1, . . . , X n}. In our development, we consider
by a set of data X n
the optimization problem (3.42) more broadly for any vector µ ∈ Rd. In
∗ as a function taking values in the
this context, it is necessary to view A

example is the vector of empirical moments(cid:3)µ = 1

(cid:10)

n

3.6 Conjugate Duality: Maximum Likelihood and Maximum Entropy

67
extended real line R∗ = R ∪ {+∞}, as is standard in convex analysis
(see Appendix A.2.5 for more details).

As we have previously intimated, the conjugate dual function (3.42)
is very closely connected to entropy. Recall the deﬁnition (3.2) of the
Shannon entropy. The main result of the following theorem is that when
µ ∈ M◦, the value of the dual function A
∗(µ) is precisely the negative
entropy of the exponential family distribution pθ(µ), where θ(µ) is the
unique vector of canonical parameters satisfying the relation

Eθ(µ)[φ(X)] = ∇A(θ(µ)) = µ.

(3.43)
We will also ﬁnd it essential to consider µ /∈ M◦, in which case it is
impossible to ﬁnd canonical parameters satisfying the relation (3.43). In
∗(µ) requires a more
this case, the behavior of the supremum deﬁning A
delicate analysis. In fact, denoting by M the closure of M, it turns out
∗(µ) = +∞. This fact is essential in the
that whenever µ /∈ M, then A
use of variational methods: it guarantees that any optimization problem
involving the dual function can be reduced to an optimization problem
over M. Accordingly, a great deal of our discussion in the sequel will be
on the structure of M for various graphical models, and various approx-
imations to M for models in which its structure is overly complex.
More formally, the following theorem, proved in Appendix B.2, provides
a precise characterization of the relation between A and its conjugate
dual A

∗:

Theorem 3.4.

(a) For any µ ∈ M◦, denote by θ(µ) the unique canonical
parameter satisfying the dual matching condition (3.43).
The conjugate dual function A

∗

A

(µ) =

(cid:4)
−H(pθ(µ))
+∞

∗ takes the form
if µ ∈ M◦
if µ /∈ M.
µ ∈ M\M◦ we

(3.44)

any

For
∗(µ) = lim
n→+∞ A
A
converging to µ.

boundary

point

have
∗(µn) taken over any sequence {µn} ⊂ M◦

68 Graphical Models as Exponential Families

(b) In terms of this dual, the log partition function has the

(cid:14)(cid:19)θ, µ(cid:20) − A

∗

(cid:15)

variational representation
A(θ) = sup
µ∈M

(3.45)
(c) For all θ ∈ Ω, the supremum in Equation (3.45) is attained
uniquely at the vector µ ∈ M◦ speciﬁed by the moment-
matching conditions

(µ)

.

(cid:13)

µ =

X m

φ(x)pθ(x)ν(dx) = Eθ[φ(X)].

(3.46)

Theorem 3.4(a) provides a precise statement of the duality between
the cumulant function A and entropy. A few comments on this relation-
∗ is a slightly
ship are in order. First, it is important to recognize that A
diﬀerent object than the usual entropy (3.2): whereas the entropy maps
density functions to real numbers (and so is a functional), the dual func-
∗ is an extended real-valued function on Rd, ﬁnite only for valid
tion A
mean parameters µ ∈ M.
Second, the value −A
∗(µ) corresponds to the optimum of the maxi-
mum entropy problem (3.3), where µ ∈ Rd parameterizes the constraint
∗(µ) = +∞ corresponds to infeasibility of the maxi-
set. The event A
mum entropy problem. This is an important point. Constrained opti-
mization problems are deﬁned both by the set being optimized over and
the function being optimized. Given that the variational representation
of the cumulant function in (3.45) takes the form of a maximization
∗(µ) = −∞ can certainly
problem, we see that vectors µ for which −A
not be optima. Thus, it suﬃces to maximize over the set M instead
of Rd, as expressed in the variational representation (3.45). This fact
implies that the nature of the set M plays a critical role in determining
the complexity of computing the cumulant function.
Third, Theorem 3.4 also clariﬁes the precise nature of the bijection
between the sets Ω and M◦, which holds for any minimal exponential
family. In particular, the gradient mapping ∇A maps Ω in a one-to-one
manner onto M◦, whereas the inverse mapping from M◦ to Ω is given
by the gradient ∇A
∗ of the dual function (see Appendix B.3 for more
details). Figure 3.8 provides an idealized illustration of this bijective
correspondence based on the gradient mappings (∇A,∇A

∗).

3.6 Conjugate Duality: Maximum Likelihood and Maximum Entropy

69

Fig. 3.8 Idealized illustration of the relation between the set Ω of valid canonical param-
eters, and the set M of valid mean parameters. The gradient mappings ∇A and ∇A
∗
∗) provide a bijective mapping between Ω and
associated with the conjugate dual pair (A, A
the interior M◦.

3.6.2 Some Simple Examples

Theorem 3.4 is best understood by working through some simple
∗) for
examples. Table 3.2 provides the conjugate dual pair (A, A
several well-known exponential families of scalar random variables.
For each family, the table also lists Ω := dom A, as well as the set M,
∗, corresponding to the set of
which contains the eﬀective domain of A
values for which A

∗ is ﬁnite.

In the rest of this section, we illustrate the basic ideas by work-
ing through two simple scalar examples in detail. To be clear, neither
of these examples is interesting from a computational perspective —
indeed, for most scalar exponential families, it is trivial to compute the
mapping between canonical and mean parameters by direct methods.
Nonetheless, they are useful in building intuition for the consequences
of Theorem 3.4. The reader interested only in the main thread may
skip ahead to Section 3.7, where we resume our discussion of the role
of Theorem 3.4 in the derivation of approximate inference algorithms
for multivariate exponential families.

Example 3.10 (Conjugate Duality for Bernoulli). Consider a
Bernoulli variable X ∈ {0,1}: its distribution can be written as an expo-
nential family with φ(x) = x, A(θ) = log(1 + exp(θ)), and Ω = R. In
order to verify the claim in Theorem 3.4(a), let us compute the conju-
∗ by direct methods. By the deﬁnition of conjugate
gate dual function A

70 Graphical Models as Exponential Families

)
µ
(

∗

A

)
µ
−
1
(
g
o
l
)
µ
−
1
(

+
µ
g
o
l

µ

2

µ

1 2

M

]
1
,
0
[

R

)
θ
(
A

]
)
θ
(
p
x
e
+
1
[
g
o
l

2

θ

1 2

Ω

R

R

]
21
µ
−
2
µ
[
g
o
l

1 2
−

}
0
>

2

)
1
µ
(

−
2
µ

|

)
2
µ

,
1
µ
(
{

)
2
θ
2
−

(
g
o
l

−

2
θ
4

21
θ
−

}
0
<
2
θ

|

)
2
θ
,
1
θ
(
{

)
µ
(
g
o
l

−
1
−

µ
−
µ
g
o
l

µ

)

)

∞
+

∞
+

,
0
(

,
0
(

)
θ
−

(
g
o
l

−

)
θ
(
p
x
e

)
0
,

∞
−
(

R

y
l
i

m
a
f

i
l
l

u
o
n
r
e
B

n
a
i
s
s
u
a
G

n
o
i
t
a
c
o
L

y
l
i

m
a
F

e
l
a
c
s
-
n
o
i
t
a
c
o
L

n
a
i
s
s
u
a
G

l
a
i
t
n
e
n
o
p
x
E

n
o
s
s
i
o
P

.
s
e
l

b
a
i
r
a
v

r
a
l
a
c
s

f
o

s
e
i
l
i

m
a
f

l
a
i
t
n
e
n
o
p
x
e

n
w
o
n
k
-
l
l
e
w

l
a
r
e
v
e
s

r
o
f

4
.
3
m
e
r
o
e
h
T

f
o

s
n
o
i
t
a
l
e
r

l
a
u
d

e
t
a
g
u
j
n
o
C

2
.
3

e
l

b
a
T

3.6 Conjugate Duality: Maximum Likelihood and Maximum Entropy

71

duality (3.42), for any ﬁxed µ ∈ R, we have

∗

A

(µ) = sup
θ∈R

{θ · µ − log(1 + exp(θ))}.

(3.47)

yields

stationary

derivatives

the
condition
Taking
µ = exp(θ)/[1 + exp(θ)], which is
simply the moment matching
condition (3.43) specialized to the Bernoulli model. When is there a
solution to this stationary condition? If µ ∈ (0,1), then some simple
algebra shows that we may rearrange to ﬁnd the unique solution
θ(µ) := log[µ/(1 − µ)]. Since M◦ = (0,1) for the Bernoulli model, the
existence and uniqueness of this solution are particular consequences
of Proposition 3.2 and Theorem 3.3. Since the objective function (3.47)
is strictly convex, the solution θ(µ) speciﬁes the optimum; substituting
θ(µ) into the objective Equation (3.47) and simplifying yields that

"

#

∗

(µ) = µlog[µ/(1 − µ)] − log

A

1 + µ
1 − µ

= µlog µ + (1 − µ)log(1 − µ),

which is the negative entropy of Bernoulli variate with mean para-
meter µ. We have thus veriﬁed Theorem 3.4(a) in the case that
µ ∈ (0,1) = M◦.
Now, let us consider the case µ /∈ M = [0,1]; concretely, let us sup-
pose that µ > 1. In this case, there is no gradient stationary point in the
optimization problem (3.47). Therefore, the supremum is speciﬁed by
the limiting behavior as θ → ±∞. For µ > 1, we claim that the objec-
tive function grows unboundedly as θ → +∞. Indeed, by the convexity
(cid:4)(θ) ≤ 1 for
of A, we have A(0) = log 2 ≥ A(θ) + A
all θ ∈ R, from which we obtain the upper bound A(θ) ≤ θ + log 2, valid
for θ > 0. Consequently, for θ > 0, we have

(cid:4)(θ)(−θ). Moreover A

µ · θ − log[1 + exp(θ)] ≥ (µ − 1)θ − log 2,

showing that the objective function diverges as θ → +∞, whenever µ >
1. A similar calculation establishes the same claim for µ < 0, showing
∗(µ) = +∞ for µ /∈ M and thus verifying the second part of
that A
Theorem 3.4(a). Finally, for the boundary points µ = 0 and µ = 1, it
∗(1) = 0 for the Bernoulli
can be veriﬁed by taking limits that A
model.

∗(0) = A

72 Graphical Models as Exponential Families

Turning to the veriﬁcation of Theorem 3.4(b), since A
unless µ ∈ [0,1], the optimization problem (3.45) reduces to

{µ · θ − µlog µ − (1 − µ)log(1 − µ)}.

max
µ∈[0,1]

∗(µ) = +∞

Explicitly solving this concave maximization problem yields that its
optimal value is log[1 + exp(θ)], which veriﬁes the claim (3.45). More-
over, this same calculation shows that the optimum is attained uniquely
at µ(θ) = exp(θ)/[1 + exp(θ)], which veriﬁes Theorem 3.4(c) for the
Bernoulli model.

Example 3.11 (Conjugate Duality for Exponential). Consider
the family of exponential distributions, represented as a regular expo-
family with φ(x) = x, Ω = (−∞,0), and A(θ) = −log(−θ).
nential
From the conjugate dual deﬁnition (3.42), we have
{µ · θ + log(−θ)}.

(3.48)

A

∗

(µ) = sup
θ<0

for all µ ∈ M◦ = (0,∞), we have A

In order to ﬁnd the optimum, we take derivatives with respect to θ.
We thus obtain the stationary condition µ = −1/θ, which corresponds
to the moment matching condition (3.43) specialized to this family.
∗(µ) = −1 − log(µ). It
Hence,
can be veriﬁed that the entropy of an exponential distribution with
mean µ > 0 is given by −A
∗(µ). This result conﬁrms Theorem 3.4 for
µ ∈ M◦. For µ /∈ M — that is, for µ < 0 — we see by inspection that
the objective function µθ + log(−θ) grows unboundedly as θ → −∞,
∗(µ) = +∞ for all µ /∈ M. The remaining
thereby demonstrating that A
∗(0) = +∞
case is the boundary point µ = 0, for which we have A
from the deﬁnition (3.48). Note also that the negative entropy of the
exponential distribution −1 − log(µn) tends to inﬁnity for all sequence
µn → 0+, consistent with Theorem 3.4(a). Having computed the dual
∗, straightforward algebra shows that
A
A(θ) = −log(−θ) = sup

{µ · θ + 1 + log(µ)},

with the optimum uniquely attained at µ = −1/θ. This calculation
veriﬁes parts (b) and (c) of Theorem 3.4 for the exponential variate.

µ>0

3.7 Computational Challenges with High-Dimensional Models

73

3.7 Computational Challenges with High-Dimensional

Models

From a computational perspective, the essential features of Theo-
rem 3.4 are the representation (3.45) of the cumulant function, and
the assertion (3.46) that the optimum is uniquely achieved at the mean
parameters µ = Eθ[φ(X)]. It thus illuminates a key property of com-
puting the cumulant function A, as well as the mean parameters µ:
in principle, we can compute both of these quantities by solving the
variational problem (3.45). Even more encouragingly, at least from a
superﬁcial perspective, the optimization problem appears to be rather
simple: it is a ﬁnite-dimensional optimization problem over a convex
set, and the objective function is strictly concave and diﬀerentiable.
Thus, the optimization lacks local optima or other unpleasant fea-
tures. It is tempting, then, to assert that the problem of comput-
ing the log partition function and the associated mean parameters
is now solved, since we have “reduced” it to a convex optimization
problem.

In this context, the simple scalar examples of Table 3.2, for which
the fundamental variational problem (3.45) had an explicit form and
could be solved easily, are very misleading. For general multivariate
exponential families, in contrast, there are two primary challenges asso-
ciated with the variational representation:

(a) In many cases, the constraint set M of realizable mean
parameters is extremely diﬃcult to characterize in an
explicit manner.
∗ is deﬁned indirectly —
in a variational manner — so that it too typically lacks an
explicit form.

(b) The negative entropy function A

For instance, to illustrate issue (a) concerning the nature of
M, for Markov random ﬁelds involving discrete random variables
X ∈ {0,1, . . . , r − 1}m, the set M is always a polytope, which we have
referred to as a marginal polytope. In this case, at least in principle, the
set M can be characterized by some ﬁnite number of linear inequali-
ties. However, for general graphs, the number of such inequalities grows

74 Graphical Models as Exponential Families

∗ as the composition of two functions. Any
Fig. 3.9 A block diagram decomposition of A
mean parameter µ ∈ M◦ is ﬁrst mapped back to a canonical parameter θ(µ) in the inverse
∗(µ) corresponds to the negative entropy −H(pθ(µ)) of
image (∇A)−1(µ). The value of A
the associated exponential family density pθ(µ).

rapidly with the graph size. Indeed, unless fundamental conjectures in
complexity theory turn out to be false, it is not even possible to opti-
mize a linear function over M for a general discrete MRF. In addition
to the complexity of the constraint set, issue (b) highlights that even
evaluating the cost function at a single point µ ∈ M, let alone optimiz-
ing it over M, is extremely diﬃcult.
To understand the complexity inherent in evaluating the dual value
∗(µ), note that Theorem 3.4 provides only an implicit characteri-
A
∗ as the composition of mappings: ﬁrst, the inverse map-
zation of A
ping (∇A)−1 : M◦ → Ω, in which µ maps to θ(µ), corresponding to the
exponential family member with mean parameters µ; and second, the
mapping from θ(µ) to the negative entropy −H(pθ(µ)) of the associ-
∗(µ)
ated exponential family density. This decomposition of the value A
is illustrated in Figure 3.9. Consequently, computing the dual value
∗(µ) at some point µ ∈ M◦ requires computing the inverse map-
A
ping (∇A)−1(µ), in itself a nontrivial problem, and then evaluating
the entropy, which requires high-dimensional integration for general
graphical models. These diﬃculties motivate the use of approximations
to M and A
∗. Indeed, as shown in the sections to follow, a broad class
of methods for approximate marginalization are based on this strategy
of ﬁnding an approximation to the exact variational principle, which is
then often solved using some form of message-passing algorithm.

4

Sum-Product, Bethe–Kikuchi, and

Expectation-Propagation

In this section, we begin our exploration of the variational
inter-
pretation of message-passing algorithms. We ﬁrst discuss the sum-
product algorithm, also known as the belief propagation algorithm.
As discussed in Section 2.5, sum-product is an exact algorithm for
tree-structured graphs, for which it can be derived as a divide-and-
conquer algorithm. However, given the local form of the sum-product
updates, there is no barrier to applying it to a graph with cycles,
which yields the “loopy” form of the sum-product or belief propaga-
tion algorithm. In the presence of cycles, there are no general con-
vergence or correctness guarantees associated with the sum-product
algorithm, but it is nonetheless widely used to compute approximate
marginals. The ﬁrst part of this section describes the variational for-
mulation of the sum-product updates in terms of the Bethe approxi-
mation. Although the approximation itself dates back to the work of
Bethe [29], the connection to the sum-product algorithm was ﬁrst elu-
cidated by Yedidia et al. [268, 269]. We then describe various nat-
ural generalizations of the Bethe approximation, including Kikuchi
clustering and other hypergraph-based methods [133, 269]. Finally,
we describe expectation-propagation algorithms [175, 184] and related

75

76 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation

moment-matching methods [64, 115, 185]; these are also variational
methods based on Bethe-like approximations.

4.1 Sum-Product and Bethe Approximation

The simplest instantiation of the Bethe approximation applies to an
undirected graphical model G = (V, E) with potential functions involv-
ing at most pairs of variables; we refer to any such model as a pairwise
Markov random ﬁeld.1 The sum-product algorithm is most widely used
for the cases of discrete random variables, or Gaussian random vari-
ables. The bulk of our discussion focuses on the former case, where for
each node s ∈ V , the associated variable Xs takes values in a discrete
space Xs = {0,1, . . . , rs − 1}.

In the discrete case, the general variational principle (3.45) takes
diﬀerent forms, depending on the chosen form of suﬃcient statistics φ.
Recall from Section 3.4.1 our deﬁnition of the canonical overcomplete
representation (3.34), using indicator functions for events {Xs = j} and
{Xs = j, Xt = k}. Using these suﬃcient statistics, we deﬁne an expo-
nential family of the form
pθ(x) ∝ exp

(cid:14)(cid:6)

θst(xs, xt)

(cid:6)

(cid:15)

,

(4.1)

θs(xs) +

s∈V

(s,t)∈E

(cid:6)
(cid:6)

j

where we have introduced the convenient shorthand notation

θs(xs) :=

θst(xs, xt) :=

θs;jI s;j(xs),

and

θst;jkI st;jk(xs, xt).

(4.2a)

(4.2b)

(j,k)

As previously discussed in Example 3.2, this particular parameter-
ization is overcomplete or nonidentiﬁable, because there exist entire
aﬃne subsets of canonical parameters that induce the same probability

1 In principle, by selectively introducing auxiliary variables, any undirected graphical model
can be converted into an equivalent pairwise form to which the Bethe approximation can
be applied; see Appendix E.3 for details of this procedure. It can also be useful to treat
higher order interactions directly, which can be done using the approximations discussed
in Section 4.2.

(cid:6)
(cid:6)

j∈Xs

(j,k)∈Xs×Xt

µs(xs) :=

µst(xs, xt) :=

µs;jI s;j(xs),

and

(4.3a)

µst;jkI st;jk(xs, xt).

(4.3b)

4.1 Sum-Product and Bethe Approximation

77

distribution2 over the random vector X. Nonetheless, this overcom-
pleteness is useful because the associated mean parameters are easily
interpretable, since they correspond to singleton and pairwise marginal
probabilities (see Equations (3.35) and (3.36)). Using these mean
parameters, it is convenient for various calculations to deﬁne the short-
hand notations

Note that µs is a |Xs|-dimensional marginal distribution over Xs,
whereas µst is a |Xs| × |Xt| matrix, representing a joint marginal over
(Xs, Xt). The marginal polytope M(G) corresponds to the set of all
singleton and pairwise marginals that are jointly realizable by some
distribution p—namely

M(G) := {µ ∈ Rd | ∃ p with marginals µs(xs), µst(xs, xt)}.

(4.4)

In the case of discrete (multinomial) random variables, this set plays a
central role in the general variational principle from Theorem 3.4.

4.1.1 A Tree-Based Outer Bound to M(G)

As previously discussed in Section 3.4.1, the polytope M(G) can either
be written as the convex hull of a ﬁnite number of vectors, one associ-
ated with each conﬁguration x ∈ X m, or alternatively, as the intersec-
tion of a ﬁnite number of half-spaces (see Figure 3.5 for an illustration).
But how to provide an explicit listing of these half-space constraints,
also known as facets? In general, this problem is extremely diﬃcult,
so that we resort to listing only subsets of the constraints, thereby
obtaining a polyhedral outer bound on M(G).

(cid:2)

(cid:2)

calculation shows

that

s∈V rs +

2 A little
d =
we form a new canonical parameter θ
C ∈ R is some ﬁxed constant, and θ
to verify that pθ(x) = pθ(cid:1) (x) for all x ∈ X m, so that θ and θ
distribution.

family (4.1) has dimension
(s,t)∈E rs rt. Given some ﬁxed parameter vector θ ∈ Rd, suppose that
1;j = θ1;j + C for all j ∈ X , where
(cid:2)
(cid:2)
α = θα for all other indices α. It is then straightforward
(cid:2) describe the same probability

the
exponential
(cid:2) ∈ Rd by setting θ

78 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation

More speciﬁcally, consider a trial set of single node functions
{τs, s ∈ V } and edge-based functions {τst,(s, t) ∈ E}. If these trial
marginal distributions are to be globally realizable, they must of course
the normalization condition(cid:6)
be nonnegative, and in addition, each singleton quantity τs must satisfy

(4.5)
Moreover, for each edge (s, t) ∈ E, the singleton {τs, τt} and pairwise
quantities τst must satisfy the marginalization constraints

τs(xs) = 1.

xs

t) = τs(xs), ∀ xs ∈ Xs,
(cid:4)
τst(xs, x

and

(4.6a)

s, xt) = τt(xt), ∀ xt ∈ Xt.
(cid:4)
τst(x

(cid:6)
(cid:6)

(cid:2)
t

x

x(cid:2)

s

(4.6b)

(4.7)

These constraints deﬁne the set
L(G) := {τ ≥ 0 | condition (4.5) holds for s ∈ V ,

and

condition (4.6) holds for (s, t) ∈ E},

of locally consistent marginal distributions. Note that L(G) is also a
polytope, in fact a very simple one, since it is deﬁned by O(|V | + |E|)
constraints in total.

What is the relation between the set L(G) of locally consistent
marginals and the set M(G) of globally realizable marginals? On one
hand, it is clear that M(G) is always a subset of L(G), since any set of
globally realizable marginals must satisfy the normalization (4.5) and
marginalization (4.6) constraints. Apart from this inclusion relation, it
turns out that for a graph with cycles, these two sets are rather diﬀer-
ent. However, for a tree T , the junction tree theorem, in the form of
Proposition 2.1, guarantees that they are equivalent, as summarized in
the following proposition.
Proposition 4.1. The inclusion M(G) ⊆ L(G) holds for any graph.
For a tree-structured graph T , the marginal polytope M(T ) is equal
to L(T ).

4.1 Sum-Product and Bethe Approximation

79

Proof. Consider an element µ of the full marginal polytope M(G):
clearly, any such vector must satisfy the normalization and pair-
wise marginalization conditions deﬁning the set L(G), from which
we conclude that M(G) ⊆ L(G). In order to demonstrate the reverse
inclusion for a tree-structured graph T , let µ be an arbitrary element
of L(T ); we need to show that µ ∈ M(T ). By deﬁnition of L(T ), the
vector µ speciﬁes a set of locally consistent singleton marginals µs for
vertices s ∈ V and pairwise marginals µst for edges (s, t) ∈ E. By the
junction tree theorem, we may use them to form a distribution, Markov
with respect to the tree, as follows:

pµ(x) :=

µs(xs)

µst(xs, xt)
µs(xs)µt(xt) .

(4.8)

(cid:2)

s∈V

(cid:2)

(s,t)∈E

(We take 0/0 := 0 in cases of zeros in the elements of µ.) It is a
consequence of the junction tree theorem or can be veriﬁed directly
via an inductive “leaf-stripping” argument that with this choice of
pµ, we have Epµ[I j(Xs)] = µs(xs) for all s ∈ V and j ∈ Xs, as well
as Epµ[I jk(Xs, Xt)] = µst(xs, xt) for all (s, t) ∈ E, and (j, k) ∈ Xs × Xt.
Therefore, the distribution (4.8) provides a constructive certiﬁcate of
the membership µ ∈ M(T ), which establishes that L(T ) = M(T ).

For a graph G with cycles, in sharp contrast to the tree case, the
set L(G) is a strict outer bound on M(G), in that there exist vectors
τ ∈ L(G) that do not belong to M(G), for which reason we refer to
members τ of L(G) as pseudomarginals. The following example illus-
trates the distinction between globally realizable marginals and pseu-
domarginals.

Example 4.1 (L(G) versus M(G)). Let us explore the relation
between the two sets on the simplest graph for which they fail to
be equivalent — namely, the single cycle on three vertices, denoted
by C3. Considering the binary random vector X ∈ {0,1}3, note that
each singleton pseudomarginal τs, for s = 1,2,3, can be viewed as
a 1 × 2 vector, whereas each pairwise pseudomarginal τst, for edges
(s, t) ∈ {(12),(13),(23)} can be viewed as a 2 × 2 matrix. We deﬁne

(cid:12)

(cid:11)
"
0.5 − βst

0.5 0.5

βst

#

(4.9a)

,

and
0.5 − βst

80 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation

the family of pseudomarginals

τs(xs) :=

,

βst

τst(xs, xt) :=

(4.9b)
where for each edge (s, t) ∈ E, the quantity βst ∈ R is a parameter to
be speciﬁed.
We ﬁrst observe that for any βst ∈ [0,0.5], these pseudomarginals
satisfy the normalization (4.5) and marginalization constraints (4.6),
so the associated pseudomarginals (4.9) belong to L(C3). As a partic-
ular choice, consider the collection τ of pseudomarginals generated by
setting β12 = β23 = 0.4, and β13 = 0.1, as illustrated in Figure 4.1(a).
With these settings, the vector τ is an element of L(C3); however, as
a candidate set of global marginal distributions, certain features of the
collection τ should be suspicious. In particular, according to the puta-
tive marginals τ, the events {X1 = X2} and {X2 = X3} should each
hold with probability 0.8, whereas the event {X1 = X3} should only
hold with probability 0.2. At least intuitively, this set-up appears likely
to violate some type of global constraint.

In order to prove the global invalidity of τ, we ﬁrst specify the con-
straints that actually deﬁne the marginal polytope M(G). For ease of

Fig. 4.1 (a) A set of pseudomarginals associated with the nodes and edges of the graph:
setting β12 = β23 = 0.4 and β13 = 0.1 in Equation (4.9) yields a pseudomarginal vector τ
which, though locally consistent, is not globally consistent. (b) Marginal polytope M(C3)
for the three node cycle; in a minimal exponential representation, it is a 6D object. Illus-
2}, as well as the outer bound L(C3), also for this
trated here is the slice {µ1 = µ2 = µ3 = 1
particular slice.

4.1 Sum-Product and Bethe Approximation

81

illustration, let us consider the slice of the marginal polytope deﬁned by
the constraints µ1 = µ2 = µ3 = 1
2. Viewed in this slice, the constraints
deﬁning L(G) reduce to 0 ≤ βst ≤ 1
2 for all edges (s, t), so that the set
is simply a 3D cube, as drawn with dotted lines in Figure 4.1(b). It
can be shown that the sliced version of M(G) is deﬁned by these box
constraints, and in addition the following cycle inequalities

µ12 + µ23 − µ13 ≤ 1
2 , µ12 − µ23 + µ13 ≤ 1
2 ,
− µ12 + µ23 + µ13 ≤ 1
2 ,

and µ12 + µ23 + µ13 ≥ 1
2 .

(4.10a)

(4.10b)

(See Example 8.7 in the sequel for the derivation of these cycle inequali-
ties.) As illustrated by the shaded region in Figure 4.1(b), the marginal
polytope M(C3) is strictly contained within the scaled cube [0, 1

To conclude the discussion of our example, note that the pseudo-
marginal vector τ speciﬁed by β12 = β23 = 0.4 and β13 = 0.1 fails to
satisfy the cycle inequalities (4.10), since in particular, we have the
violation

2]3.

β12 + β23 − β13 = 0.4 + 0.4 − 0.1 >

1
2 .

Therefore, the vector τ is an instance of a set of pseudomarginals valid
under the Bethe approximation, but which could never arise from a
true probability distribution.

4.1.2 Bethe Entropy Approximation

We now turn to the second variational ingredient that underlies the
sum-product algorithm, namely an approximation to the dual function
(or negative entropy). As with the outer bound L(G) on the marginal
polytope, the Bethe entropy approximation is also tree-based.

For a general MRF based on a graph with cycles, the negative
∗ — as a function of only the mean parameters µ — typi-
entropy A
cally lacks a closed form expression. An important exception to this
rule is the case of a tree-structured Markov random ﬁeld, for which
the entropy decomposes in terms of local entropies associated with the
edges and nodes of the graph. In order to derive this decomposition,

(cid:6)
(cid:6)

s∈V

xs∈Xs

Hs(µs) := −
(cid:6)

82 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation

recall from the proof of Proposition 4.1 the factorization (4.8) of any
tree-structured MRF distribution in terms of marginal distributions
{µs, s ∈ V } and {µst,(s, t) ∈ E} on the node and edges, respectively, of
the tree. These marginal distributions correspond to the mean parame-
ters under the canonical overcomplete suﬃcient statistics (3.34). Thus,
for a tree-structured MRF, we can compute the (negative) dual value
−A
∗(µ) directly, simply by computing the entropy H(pµ) of the dis-
tribution (4.8). Denoting by Eµ the expectation under the distribu-
tion (4.8), we obtain

H(pµ) = −A
∗

(cid:6)
(µ) = Eµ[−log pµ(X)]
Hs(µs) −

=

(s,t)∈E

Ist(µst).

(4.11)

The diﬀerent terms in this expansion are the singleton entropy

µs(xs)log µs(xs)

(4.12)

for each node s ∈ V , and the mutual information

Ist(µst) :=

(xs,xt)∈Xs×Xt

µst(xs, xt)log µst(xs, xt)
µs(xs) µt(xt)

(4.13)

for each edge (s, t) ∈ E. Consequently, for a tree-structured graph, the
∗ can be expressed as an explicit and easily computable
dual function A
function of the mean parameters µ.

With this background, the Bethe approximation to the entropy of
an MRF with cycles is easily described: it simply assumes that decom-
position (4.11) is approximately valid for a graph with cycles. This
assumption yields the Bethe entropy approximation

∗

−A

(τ) ≈ HBethe(τ) :=

Hs(τs) −

Ist(τst).

(4.14)

(cid:6)

(s,t)∈E

(cid:6)

s∈V

An important fact, central in the derivation of the sum-product algo-
rithm, is that this approximation (4.14) can be evaluated for any set of
pseudomarginals {τs, s ∈ V } and {τst,(s, t) ∈ E} that belong to L(G).
For this reason, our change in notation — from µ for exact marginals
to τ for pseudomarginals — is deliberate.

4.1 Sum-Product and Bethe Approximation

83

We note in passing that Yedidia et al. [268, 269] used an alternative
form of the Bethe entropy approximation (4.14), one which can be
obtained via the relation Ist(τst) = Hs(τs) + Ht(τt) − Hst(τst), where
Hst is the joint entropy deﬁned by the pseudomarginal τst. Doing so
and performing some algebraic manipulation yields

HBethe(τ) = −

(ds − 1) Hs(τs) +

Hst(τst),

(4.15)

(cid:6)

(s,t)∈E

(cid:6)

s∈V

where ds corresponds to the number of neighbors of node s (i.e., the
degree of node s). However, the symmetric form (4.14) turns out to be
most natural for our development in the sequel.

4.1.3 Bethe Variational Problem and Sum-Product

We now have the two ingredients needed to construct the Bethe approx-
imation to the exact variational principle (3.45) from Theorem 3.4:
• the set L(G) of locally consistent pseudomarginals (4.7) is a
convex (polyhedral) outer bound on the marginal polytope
M(G); and
• the Bethe entropy (4.14) is an approximation of the exact
dual function A

∗(τ).

By combining these two ingredients, we obtain the Bethe variational
problem (BVP):

(cid:19)θ, τ(cid:20) +

Hs(τs) −

max
τ∈L(G)

Ist(τst)

.

(4.16)

(cid:7)

(cid:6)

s∈V

(cid:8)

(cid:6)

(s,t)∈E

Note that this problem has a very simple structure: the cost function
is given in closed form, it is diﬀerentiable, and the constraint set L(G)
is a polytope speciﬁed by a small number of constraints. Given this
special structure, one might suspect that there should exist a relatively
simple algorithm for solving this optimization problem (4.16). Indeed,
the sum-product algorithm turns out to be exactly such a method.

In order to develop this connection between the variational pro-
blem (4.16) and the sum-product algorithm, let λss be a Lagrange

84 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation

multiplier associated with the normalization constraint Css(τ) = 0,
where

Css(τ) := 1 −

(4.17)
Moreover, for each direction t → s of each edge and each xs ∈ Xs,
deﬁne the constraint function

τs(xs).

Cts(xs; τ) := τs(xs) −

τst(xs, xt),

(4.18)

(cid:6)
(cid:6)

xs

xt

and let λts(xs) be a Lagrange multiplier associated with the con-
straint Cts(xs; τ) = 0. These Lagrange multipliers turn out to be closely
related to the sum-product messages, in particular via the relation
Mts(xs) ∝ exp(λts(xs)).

We then consider the Lagrangian corresponding to the Bethe vari-

ational problem (4.16):
L(τ, λ; θ) := (cid:19)θ, τ(cid:20) + HBethe(τ) +

λssCss(τ)

(4.19)

#

λst(xt)Cst(xt; τ)

.

(cid:6)

xt

(cid:6)

s∈V

(cid:6)

"(cid:6)

+

(s,t)∈E

xs

λts(xs)Cts(xs; τ) +

With these deﬁnitions, the connection between sum-product and the
BVP is made precise by the following result, due to Yedidia et al. [269].

Theorem 4.2(Sum-Product and the Bethe Problem). The sum-
product updates are a Lagrangian method for attempting to solve the
Bethe variational problem:

∗

∗) such that

, λ

(a) For any graph G, any ﬁxed point of the sum-product updates

speciﬁes a pair (τ

∇τL(τ

∗

∗

and ∇λL(τ

∗

∗

, λ

, λ

; θ) = 0.

; θ) = 0,

(4.20)
(b) For a tree-structured Markov random ﬁeld (MRF), the
∗),
Lagrangian Equations (4.20) have a unique solution (τ
∗ correspond to the exact single-
where the elements of τ
ton and pairwise marginal distributions of the MRF. More-
over, the optimal value of the BVP is equal to the cumulant
function A(θ).

, λ

∗

4.1 Sum-Product and Bethe Approximation

85

It should be noted that the Lagrangian formula-
Remark 4.1.
tion (4.19) is a partial one, because it assigns Lagrange multipliers to
the normalization Css and marginalization Cts constraints, but deals
with the nonnegativity constraints implicitly. However, any optimum
∗ of the Bethe variational principle with strictly positive elements
τ
must satisfy the Lagrangian conditions (4.20) from Theorem 4.2(a). To
∗ is Lagrange multiplier vector for the BVP,
see this fact, note that if λ
∗ must maximize the Lagrangian L(τ, λ
∗)
then any optimal solution τ
over the positive orthant τ ≥ 0 (see Bertsekas [21]). If the optimal solu-
∗ has strictly positive elements, then a necessary condition for
tion τ
Lagrangian optimality is the zero-gradient condition ∇τL(τ
∗) = 0,
as claimed. Moreover, for graphical models where all conﬁgurations are
given strictly positive mass (such as graphical models in exponential
form with ﬁnite θ), the sum-product messages stay bounded strictly
∗ with
away from zero [204], so that there is always an optimum τ
strictly positive elements. In this case, Theorem 4.2(a) guarantees that
any sum-product ﬁxed point satisﬁes the Lagrangian conditions neces-
sary to be an optimum of the Bethe variational principle. For graphical
models in which some conﬁgurations are assigned zero mass, further
care is required in connecting ﬁxed points to local optima; we refer the
reader to Yedidia et al. [269] for details.

, λ

∗

Proof. Proof of part (a): Computing the partial derivative ∇τL(τ; λ)
and setting it to zero yields the relations

log τs(xs) = λss + θs(xs) +

λts(xs),

and (4.21a)

(cid:6)

t∈N(s)

(cid:10)

(cid:9)τs(xs)(cid:9)τt(xt)

log τst(xs, xt)

= θst(xs, xt) − λts(xs) − λst(xt),

(4.21b)

where we have used the shorthand (cid:9)τs(xs) :=
τ(xs, xt). The con-
(cid:10)
dition ∇λL(τ; λ) = 0 is equivalent to Cts(xs; τ) = 0 and Css(τ) = 0.
Using Equation (4.21a) and the fact that the marginalization condition
τ(xs, xt) = τs(xs)), we
Cts(xs; τ) = 0 hold at the optimum (so that

xt

xt

86 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation

can rearrange Equation (4.21b) to obtain:

log τst(xs, xt) = λss + λtt + θst(xs, xt) + θs(xs) + θt(xt)

(cid:6)

+

u∈N(s)\t

(cid:6)

u∈N(t)\s

λus(xs) +

λut(xt).

(4.22)

So as to make explicit the connection to the sum-product algorithm,
let us deﬁne, for each directed edge t → s, an rs-vector of “messages”

Mts(xs) = exp(λts(xs)),

for all xs ∈ {0,1, . . . , rs − 1}.

With this notation, we can then write an equivalent form of Equa-
tion (4.21a) as follows:

τs(xs) = κexp(θs(xs))

Mts(xs).

(4.23)

(cid:2)

t∈N(s)

(cid:23)
(cid:2)

(cid:24)

(cid:2)

Similarly, we have an equivalent form of Equation (4.22):

(cid:4)
τst(xs, xt) = κ
×

exp

θst(xs, xt) + θs(xs) + θt(xt)

Mus(xs)

Mut(xt).

(4.24)

u∈N(s)\t

u∈N(t)\s

(cid:4) are positive constants dependent on λss and λtt, chosen so
Here κ, κ
that the pseudomarginals satisfy normalization conditions. Note that
τs and τst so deﬁned are nonnegative.

To conclude, we need to adjust the Lagrange multipliers or messages
τst(xs, xt) = τs(xs) is satisﬁed for every edge.
so that the constraint
Using the relations (4.23) and (4.24) and performing some algebra, the
end result is
Mts(xs) ∝

(cid:15) (cid:2)

θst(xs, xt) + θt(xt)

(cid:6)

Mut(xt)

,

(4.25)

"

#

exp

(cid:10)
(cid:14)

xt

xt

u∈N(t)\s

which is equivalent to the familiar sum-product update (2.9). By
∗ of these updates (4.25) speciﬁes a
construction, any ﬁxed point M
pair (τ

∗) that satisﬁes the stationary conditions (4.20).

, λ

∗

Proof of part (b): See Appendix B.4 for the proof of this claim.

4.1 Sum-Product and Bethe Approximation

87

The connection between the sum-product algorithm and the Bethe
variational principle has a number of important consequences. First, it
provides a principled basis for applying the sum-product algorithm for
graphs with cycles, namely as a particular type of iterative method for
attempting to satisfy Lagrangian conditions. It should be noted, how-
ever, that this connection between sum-product and the Bethe prob-
lem in itself provides no guarantees on the convergence of the sum-
product updates on graphs with cycles. Indeed, whether or not the
algorithm converges depends both on the potential strengths and the
topology of the graph. In the standard scheduling of the messages, each
node applies Equation (4.25) in parallel. Other more global schemes
for message-passing are possible, and commonly used in certain appli-
cations like error-control coding [e.g., 166]; some recent work has also
studied adaptive schedules for message-passing [75, 226]. Tatikonda and
Jordan [230] established an elegant connection between convergence
of parallel updates and Gibbs measures on the inﬁnitely unwrapped
computation tree, thereby showing that suﬃcient conditions for con-
vergence can be obtained from classical conditions for uniqueness of
Gibbs measures (e.g., Dobrushin’s condition or Simon’s condition [90]).
In subsequent work, other researchers [109, 118, 178, 204] have used
various types of contraction arguments to obtain sharper conditions
for convergence, and/or uniqueness of ﬁxed points. For suitably weak
potentials, Dobrushin-type conditions and related contraction argu-
ments guarantee both convergence of the updates, and as a conse-
quence, uniqueness of the associated ﬁxed point. A parallel line of
work [111, 254, 270] has explored alternatives to sum-product that
are guaranteed to converge, albeit at the price of increased compu-
tational cost. However, with the exception of trees and other special
cases [110, 167, 188], the Bethe variational problem is usually a non-
convex problem, in that HBethe fails to be concave. As a consequence,
there are frequently local optima, so that even when using a conver-
gent algorithm, there are no guarantees that it will ﬁnd the global
optimum.
For each θ ∈ Rd, let ABethe(θ) denote the optimal value of the
Bethe variational problem (4.16). Theorem 4.2(b) states for any

88 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation

tree-structured problem, we have the equality ABethe(θ) = A(θ) for
all θ ∈ Rd. Given this equivalence, it is natural to consider the rela-
tion between ABethe(θ) and the cumulant function A(θ) for general
graphs. In general, the Bethe value ABethe(θ) is simply an approxi-
mation to the cumulant function value A(θ). Unlike the mean ﬁeld
methods to be discussed in Section 5, it is not guaranteed to pro-
vide a lower bound on the cumulant function. As will be discussed
at more length in Section 7, Wainwright et al. [246] derived “con-
vexiﬁed” forms of the Bethe variational principle that are guaranteed
to yield upper bounds on the cumulant function for any graphical
model. On the other hand, Sudderth et al. [224] show that ABethe(θ)
is a lower bound on the cumulant function A(θ) for certain classes
of attractive graphical models. Such models, in which the interactions
encourage random variables to agree with one another, are common
in computer vision and other applications in spatial statistics. This
lower-bounding property is closely related to the connection between
the Bethe approximation and loop series expansions [51], discussed in
Section 4.1.6.

Another important consequence of the Bethe/sum-product connec-
tion is in suggesting a number of avenues for improving upon the
ordinary sum-product algorithm, via progressively better approxima-
tions to the entropy function and outer bounds on the marginal poly-
tope. We turn to discussion of a class of such generalized sum-product
algorithms beginning in Section 4.2.

4.1.4

Inexactness of Bethe and Sum-Product

In this section, we explore some aspects of the inexactness of the
sum-product algorithm. From a variational perspective, the inexact-
ness stems from the two approximations made in setting up Bethe
variational principle:

(a) Replacing the marginal polytope M(G) by the polyhedral

outer bound L(G) and

(b) The Bethe entropy HBethe as an approximation to the exact

entropy as a function of the mean parameters.

4.1 Sum-Product and Bethe Approximation

89

We begin by considering the Bethe entropy approximation, and its

potential inexactness:

fully
Example 4.2 (Inexactness
connected graph K4 on four vertices, and the collection of singleton
and pairwise marginal distributions given by

of HBethe). Consider

the

(cid:11)
"

(cid:12)
#

µs(xs) =

µst(xs, xt) =

0.5 0.5
0
0.5
0
0.5

for s = 1,2,3,4
∀ (s, t) ∈ E.

(4.26a)

(4.26b)

It can be veriﬁed that these marginals are globally valid, generated
in particular by the distribution that places mass 0.5 on each of the
conﬁgurations (0, 0, 0, 0) and (1, 1, 1, 1). Let us calculate the Bethe
entropy approximation. Each of the four singleton entropies are given
by Hs(µs) = log 2, and each of the six (one for each edge) mutual infor-
mation terms are given by Ist(µst) = log 2, so that the Bethe entropy
is given by

HBethe(µ) = 4log 2 − 6log 2 = −2log 2 < 0,

for this example, the
which cannot be a true entropy. In fact,
true entropy (or value of the negative dual function) is given by
−A

∗(µ) = log 2 > 0.

In addition to the inexactness of HBethe as an approximation to the
negative dual function, the Bethe variational principle also involves
relaxing the marginal polytope M(G) to the ﬁrst-order constraint set
L(G). As illustrated in Example 4.1, the inclusion M(C3) ⊆ L(C3) holds
strictly for the 3-node cycle C3. The constructive procedure of Exam-
ple 4.1 can be substantially generalized to show that the inclusion
M(G) ⊂ L(G) holds strictly for any graph G with cycles. Figure 4.2
provides a highly idealized illustration3 of the relation between M(G)
and L(G): both sets are polytopes, and for a graph with cycles, M(G)
is always strictly contained within the outer bound L(G).

3 In particular, this picture is misleading in that it suggests that L(G) has more facets and
more vertices than M(G); in fact, the polytope L(G) has fewer facets and more vertices,
but this is diﬃcult to convey in a 2D representation.

90 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation

Fig. 4.2 Highly idealized illustration of the relation between the marginal polytope M(G)
and the outer bound L(G). The set L(G) is always an outer bound on M(G), and the
inclusion M(G) ⊂ L(G) is strict whenever G has cycles. Both sets are polytopes and so can
be represented either as the convex hull of a ﬁnite number of extreme points, or as the
intersection of a ﬁnite number of half-spaces, known as facets.

Both sets are polytopes, and consequently can be represented either
as the convex hull of a ﬁnite number of extreme points, or as the inter-
section of a ﬁnite number of half-spaces, known as facets. Letting φ
be a shorthand for the full vector of indicator functions in the stan-
dard overcomplete representation (3.34), the marginal polytope has
the convex hull representation M(G) = conv{φ(x) | x ∈ X}. Since the
indicator functions are {0,1}-valued, all of its extreme points consist
of {0,1} elements, of the form µx := φ(x) for some x ∈ X m; there are
a total of |X m| such extreme points. However, with the exception of
tree-structured graphs, the number of facets for M(G) is not known
in general, even for relatively simple cases like the Ising model; see
the book [69] for background on the cut or correlation polytope, which
is equivalent to the marginal polytope for an Ising model. However,
the growth must be super-polynomial in the graph size, unless certain
widely believed conjectures in computational complexity are false.
On the other hand, the polytope L(G) has a polynomial number
of facets, upper bounded by any graph by O(rm + r2|E|). It has more
extreme points than M(G), since in addition to all the integral extreme
points {µx, x ∈ X m}, it includes other extreme points τ ∈ L(G)\M(G)
that contain fractional elements; see Section 8.4 for further discussion
of integral versus fractional extreme points. With the exception of trees
and small instances, the total number of extreme points of L(G) is not
known in general.

4.1 Sum-Product and Bethe Approximation

91

The strict inclusion of M(G) within L(G) — and the fundamental
role of the latter set in the Bethe variational problem (4.16) — leads
to the following question: do solutions to the Bethe variational problem
ever fall into the gap M(G)\L(G)? The optimistically inclined would
hope that these points would somehow be excluded as optima of the
Bethe variational problem. Unfortunately, such hope turns out to be
misguided. In fact, for every element τ of L(G), it is possible to con-
struct a distribution pθ such that if the sum-product algorithm is run on
the problem, then τ arises from the messages deﬁned by a sum-product
ﬁxed point. In order to understand this fact, we need to describe the
reparameterization interpretation of the sum-product algorithm [242],
to which we now turn.

4.1.5 Bethe Optima and Reparameterization

One view of the junction tree algorithm, as described in Section 2.5.2, is
as follows: taking as input a set of potential functions on the cliques of
some graph, it returns as output an alternative factorization of the same
distribution in terms of local marginal distributions on the cliques and
separator sets of a junction tree. In the special case of an ordinary tree,
the alternative factorization is a product of local marginals at single
nodes and edges of the tree, as in Equation (4.8). Indeed, the sum-
product algorithm for trees can be understood as an eﬃcient method
for computing this alternative parameterization.

It turns out that the same interpretation applies to arbitrary graphs
with cycles: more precisely, any ﬁxed point of the sum-product algo-
rithm — and even more generally, any local optimum of the Bethe
variational principle — speciﬁes a reparameterization of the original
distribution pθ. We summarize in the following proposition [242]:

Proposition 4.3 (Reparameterization Properties of Bethe
s , s ∈ V ; τ
st,(s, t) ∈ E) denote any opti-
∗
∗
Approximation). Let τ
(cid:2)
(cid:2)
mum of the Bethe variational principle deﬁned by the distribution pθ.
Then the distribution deﬁned by the ﬁxed point as

∗ = (τ

∗
st(xs, xt)
τ
τ∗
s (xs)τ

∗
t (xt) ,

(4.27)

pτ∗(x) :=

1

Z(τ∗)

∗
s (xs)

τ

s∈V

(s,t)∈E

92 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation

is a reparameterization of the original distribution pθ — that is,
pτ∗(x) = pθ(x) for all x ∈ X m.

Note that this type of reparameterization is possible only because
the exponential family is deﬁned by an overcomplete set of suﬃcient
statistics, involving the indicator functions (3.34). The reparameteri-
zation (4.27) is the analog of the tree-structured factorization (4.8),
but as applied to a graph with cycles. In contrast to the tree case, the
∗) is not, in general, equal to one. Whereas
normalization constant Z(τ
the junction tree theorem guarantees this reparameterization for any
tree, it is not immediately obvious that even one reparameterization
need exist for a general graph. In fact, the result establishes that every
graph has at least one such reparameterization, and some graphs may
have multiple reparameterizations of the form (4.27); in particular,
this is the case for any problem for which the BVP has multiple
optima. Moreover, the reparameterization viewpoint provides some
insight into the approximation error: that is, the diﬀerence between
∗
the exact marginals µs of pθ(x) and the approximations τ
s computed
by the sum-product algorithm. Indeed, using Equation (4.27), it is
possible to derive an exact expression for the error in the sum-product
algorithm, as well as computable error bounds, as described in more
detail in Wainwright et al. [242].

We now show how the reparameterization characterization (4.27)
enables us to specify, for any pseudomarginal τ in the interior of L(G),
a distribution pθ for which τ is a ﬁxed point of the sum-product algo-
rithm. The following example illustrates this construction.

Example 4.3 (Fooling the Sum-Product Algorithm). Let us
return to the simplest graph for which sum-product is not exact —
namely, a single cycle with three nodes (see Example 4.1). Consider
candidate marginal distributions (τs, s ∈ V ) and (τst, (s, t) ∈ E) of the
form illustrated in Figure 4.1(a), with β12 = β23 = 0.4 and β13 = 0.1. As
discussed in Example 4.1, this setting yields a set of pseudomarginals
τ that lie in L(G) but not in M(G), and therefore could not possibly
arise from any global probability distribution.

4.1 Sum-Product and Bethe Approximation

93

Let us now demonstrate how,

for an appropriately chosen
distribution pθ on the graph, the sum-product algorithm can be
“fooled” into converging to this pseudomarginal vector τ. Using the
canonical overcomplete representation (3.34), consider a set of canoni-
cal parameters of the form:

θs(xs) := log τs(xs) = log
θst(xs, xt) := log τst(xs, xt)
τs(xs)τt(xt)

"
0.5 − βst

βst

= log 4

(cid:11)

0.5 0.5

0.5 − βst

βst

(cid:12) ∀ s ∈ V , and
#

∀ (s, t) ∈ E,

(4.28a)

(4.28b)

(cid:12)

0.5 0.5

message initialization Mts(xs) ∝(cid:11)

where we have adopted the short-hand notation from Equation (4.2).
With these canonical parameters, suppose that we apply the sum-
product algorithm to the Markov random ﬁeld pθ, using the uniform
. A little bit of algebra using
the sum-product update (4.25) shows that for this parameter choice, the
uniform messages M already deﬁne a ﬁxed point of the sum-product
algorithm. Moreover, if we compute the associated pseudomarginals
speciﬁed by M and θ, they are equal to the previously speciﬁed
τs, τst. In summary, the sum-product algorithm — when applied to
the distribution pθ deﬁned by the canonical parameters (4.28) — pro-
duces as its output the pseudomarginal τ as its estimate of the true
marginals.

The reader might object to the fact that the problem construc-
tion ensured the sum-product algorithm was already at this particular
ﬁxed point, and so obviates the possibility of the updates converging
to some other ﬁxed point if initialized in a diﬀerent way. However,
it is known [110, 249] that for any discrete Markov random ﬁeld in
exponential family form with at most a single cycle, sum-product has
a unique ﬁxed point, and always converges to it. Therefore, the sum-
product ﬁxed point that we have constructed (4.28) is the unique ﬁxed
point for this problem, and the algorithm converges to it from any
initialization of the messages.

94 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation

More generally,

the constructive approach illustrated in the
preceding example applies to an arbitrary member of the interior4 of
L(G). Therefore, for all pseudomarginals τ ∈ L(G), including those that
are not globally valid, there exists a distribution pθ for which τ arises
from a sum-product ﬁxed point.

4.1.6 Bethe and Loop Series Expansions

In this section, we discuss the loop series expansions of Chertkov
and Chernyak [51]. These expansions provide exact representation
of the cumulant function as a sum of terms, with the ﬁrst term
corresponding to the Bethe approximation ABethe(θ), and higher-order
terms obtained by adding in so-called loop corrections. They provided
two derivations of their loop series: one applies a trigonometric identity
to a Fourier representation of binary variables, while the second is
based upon a saddle point approximation obtained via an auxiliary
ﬁeld of complex variables. In this section, we describe a more direct
derivation of the loop expansion based on the reparameterization
characterization of sum-product ﬁxed points given in Proposition 4.3.
Although the loop series expansion can be developed for general factor
graphs, considering the case of a pairwise Markov random ﬁeld with
binary variables — that is, the Ising model from Example 3.1 —
suﬃces to illustrate the basic ideas. (See Sudderth et al. [224] for a
derivation for more general factor graphs.)

Given an undirected graph G = (V, E) and some subset (cid:9)E ⊆ E of the
edge set E, we let G((cid:9)E) denote the induced subgraph associated with
(cid:9)E — that is, the graph with edge set (cid:9)E, and vertex set
V ((cid:9)E) := {t ∈ V | (t, u) ∈ (cid:9)E for some u}.
For any vertex s ∈ V , we deﬁne its degree with respect to (cid:9)E as

Before stating the result, we require a few preliminary deﬁnitions.

ds((cid:9)E) := {t ∈ V | (s, t) ∈ (cid:9)E}.

(4.29)

(4.30)

4 Strictly speaking, it applies to members of the relative interior since, as described in the
overcomplete representation (3.34), the set L(G) is not full-dimensional and hence has an
empty interior.

4.1 Sum-Product and Bethe Approximation

95

Fig. 4.3 Illustration of generalized loops. (a) Original graph. (b)–(d) Various generalized
loops associated with the graph in (a). In this particular case, the original graph is a
generalized loop for itself.

Following Chertkov and Chernyak [51], we deﬁne a generalized loop to

be a subgraph G((cid:9)E) for which all nodes s ∈ V have degree ds((cid:9)E) (cid:12)= 1.
Otherwise stated, for every node s, it either does not belong to G((cid:9)E)
so that ds((cid:9)E) = 0, or it has degree ds((cid:9)E) ≥ 2. See Figure 4.3 for an

illustration of the concept of a generalized loop. Note also that a graph
without cycles (i.e., a tree or forest graph) does not have any generalized
loops.
Consider a BP ﬁxed point for a pairwise MRF with binary vari-
ables — that is, an Ising model (3.8). For binary variables Xs ∈ {0,1},
#
the singleton and edgewise pseudomarginals associated with a BP ﬁxed
point can be parameterized as

"
1 − τs − τt + τst

τt − τst

#

"
1 − τs
τs

τs(xs) =

,

and τst(xs, xt) =

τs − τst

τst

(4.31)

1 − τs − τt + τst ≥ 0,

Some calculation shows that membership in the set L(G) is equivalent
to imposing the following four inequalities
τst ≥ 0,
and τt − τst ≥ 0,
for each edge (s, t) ∈ E. See also Example 3.8 for some discussion of
the mean parameters for an Ising model.
Using this parameterization, for each edge (s, t) ∈ E, we deﬁne the

τs − τst ≥ 0,

edge weight

βst :=

τst − τsτt

τs(1 − τs)τt(1 − τt) ,

(4.32)

96 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation

which extends naturally to the subgraph weight β (cid:4)E :=
these deﬁnitions, we have [224]:

(s,t)∈ (cid:4)E βst. With

(cid:5)

(cid:24)

(3.8), and let ABethe(θ) be

a pairwise Markov random ﬁeld
the opti-
a BP ﬁxed point
function value A(θ)

evaluated at
. The cumulant

(cid:23)

Proposition 4.4. Consider
with binary variables
mized free
τ =
is equal to the loop series expansion:

(4.16)
τs, s ∈ V ; τst, (s, t) ∈ E
(cid:4)

energy

(cid:6)

A(θ) = ABethe(θ) + log

1 +

β (cid:4)E

∅(cid:7)= (cid:4)E⊆E

(cid:22)
Eτs[(Xs − τs)ds( (cid:4)E)]

.

(cid:2)

s∈V

(4.33)

Before proving Proposition 4.4, we pause to make some remarks.

By deﬁnition, we have

Eτs[(Xs − τs)d] = (1 − τs)(−τs)d + τs(1 − τs)d

(cid:11)
(1 − τs)d−1 + (−1)d (τs)d−1
= τs(1 − τs)

(cid:12)

,

parameter τs ∈ [0,1]. Consequently, for any (cid:9)E ⊆ E such that ds((cid:9)E) = 1
vanishes. For this reason, only generalized loops (cid:9)E lead to nonzero

corresponding to dth central moments of a Bernoulli variable with
for at least one s ∈ V , then the associated term in the expansion (4.33)

(4.34)

terms in the expansion (4.33). The terms associated with these general-
ized loops eﬀectively deﬁne corrections to the Bethe estimate ABethe(θ)
of the cumulant function. Tree-structured graphs do not contain any
nontrivial generalized loops, which provides an alternative proof of the
exactness of the Bethe approximation for trees.

The ﬁrst term ABethe(θ) in the loop expansion is easily computed
from any BP ﬁxed point, since it simply corresponds to the optimized
value of the Bethe free energy (4.16). However, explicit computation of
the full sequence of loop corrections — and hence exact calculation of
the cumulant function — is intractable for general (nontree) models.
For instance, any fully connected graph with n ≥ 5 nodes has more
than 2n generalized loops. In some cases, accounting for a small set of
signiﬁcant loop corrections may lead to improved approximations to

4.1 Sum-Product and Bethe Approximation

97

the partition function [100], or more accurate approximations of the
marginals for LDPC codes [52].

Proof of Proposition 4.4: Recall that the canonical overcomplete
parameterization (3.34) using indicator functions is overcomplete, so
that there exist many distinct parameter vectors θ (cid:12)= θ
(cid:4) such that
pθ = pθ(cid:2). However, the diﬀerence between the left-hand and right-hand
sides of the loop series expansion (4.33) is identical for any choice of
θ, since moving from θ → θ
(cid:4) simply shifts both A(θ) and ABethe(θ) by
some constant. Consequently, it suﬃces to prove the loop series expan-
sion for a single parameterization; in particular, we prove it for the
reparameterization given by the canonical parameters

and (cid:9)θst(xs, xt) = log τst(xs, xt)

(cid:9)θs(xs) = log τs(xs),
reparameterization, a little calculation shows that ABethe((cid:9)θ) = 0. Con-

as speciﬁed by any BP ﬁxed point (see Proposition 4.3). For this

τs(xs)τt(xt) ,

(4.35)

sequently, it suﬃces to show that for this particular parameteriza-
tion (4.35), we have the equality

A((cid:9)θ) = log

(cid:4)

1 +

(cid:6)

β (cid:4)E

∅(cid:7)= (cid:4)E⊆E

(cid:2)

s∈V

(cid:22)
Eτs[(Xs − τs)ds( (cid:4)E)]

.

Using the representation (4.31), a little calculation shows that

τst(xs, xt)
τs(xs)τt(xt)

= 1 + βst(xs − τs)(xt − τt).
By deﬁnition of (cid:9)θ, we have
(cid:6)
(cid:2)
exp(A((cid:9)θ)) =

(cid:2)

τs(xs)

x∈{0,1}m

s∈V

(s,t)∈E

τst(xs, xt)
τs(xs)τt(xt) .

(4.36)

(4.37)

Let E denote expectation taken with respect
distribution τfact(x) :=

to the product
s τs(xs). With this notation, and applying the

(cid:5)

98 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation

identity (4.37), we have

exp(A((cid:9)θ)) =

(cid:2)

(s,t)∈E

τs(xs)

τst(xs, xt)
τs(xs)τt(xt)

(cid:24)%

(cid:6)
$ (cid:2)

(cid:2)
(cid:23)

s∈V

x∈{0,1}n

= E

(s,t)∈E

1 + βst(Xs − τs)(Xt − τt)

.

(4.38)

E

∅(cid:7)= (cid:4)E⊆E

(s,t)∈ (cid:4)E

(cid:6)

$ (cid:2)

Expanding this polynomial and using linearity of expectation, we

%
βst(Xs − τs)(Xt − τt)

recover one term for each nonempty subset (cid:9)E ⊆ E of the graph’s edges:
exp(A((cid:9)θ)) = 1 +
variables. To evaluate these terms, note that if ds((cid:9)E) = 1, it follows that
loop (cid:9)E, in which all connected nodes have degree at least two.

The expression (4.36) then follows from the independence structure of
τfact(x), and standard formulas for the moments of Bernoulli random
E[Xs − τs] = 0. There is thus one loop correction for each generalized

.

(4.39)

Proposition 4.4 has extensions to more general factor graphs; see
the papers [51, 224] for more details. Moreover, Sudderth et al. [224]
show that the loop series expansion can be exploited to show that
for certain types of graphical models with attractive interactions, the
Bethe value ABethe(θ) is actually a lower bound on the true cumulant
function value A(θ).

4.2 Kikuchi and Hypertree-based Methods

From our development thus far, we have seen that there are two
distinct ways in which the Bethe variational principle (4.16) is an
approximate version of the exact variational principle (3.45). First,
for general graphs, the Bethe entropy (4.14) is only an approxi-
mation to the true entropy or negative dual function. Second, the
constraint set L(G) outer bound on the marginal polytope M(G),
as illustrated in Figure 4.2. In principle, the accuracy of the Bethe
variational principle could be strengthened by improving either one,
or both, of these components. This section is devoted to one natural

4.2 Kikuchi and Hypertree-based Methods

99

generalization of the Bethe approximation, ﬁrst proposed by Yedidia
et al.
[268, 269] and further explored by various researchers [111,
167, 188, 240, 270], that improves both components simultaneously.
The origins of these methods lie in the statistical physics litera-
ture, where they were referred to as cluster variational methods
[6, 133, 229].

At the high level, the approximations in the Bethe approach are
based on trees, which represent a special case of the junction trees.
A natural strategy, then,
is to strengthen the approximations by
exploiting more complex junction trees. These approximations are most
easily understood in terms of hypertrees, which represent an alterna-
tive way in which to describe junction trees. Accordingly, we begin with
some necessary background on hypergraphs and hypertrees.

4.2.1 Hypergraphs and Hypertrees

A hypergraph G = (V, E) is a generalization of a graph, consisting of
a vertex set V = {1, . . . , m}, and a set of hyperedges E, where each
hyperedge h is a particular subset of V . The hyperedges form a partially
ordered set or poset [221], where the partial ordering is speciﬁed by
inclusion. We say that a hyperedge h is maximal if it is not contained
within any other hyperedge. With these deﬁnitions, we see that an
ordinary graph is a special case of a hypergraph, in which each maximal
hyperedge consists of a pair of vertices or equivalently, an ordinary edge
of the graph.5

A convenient graphical representation of a hypergraph is in terms
of a diagram of its hyperedges, with directed edges representing the
inclusion relations; such a representation is known as a poset dia-
gram [167, 188, 221]. Figure 4.4 provides some simple graphical illus-
trations of hypergraphs. Any ordinary graph, as a special case of a
hypergraph, can be drawn in terms of a poset diagram; in particu-
lar, panel (a) shows the hypergraph representation of a single cycle on

5 There is a minor inconsistency in our deﬁnition of the hyperedge set E and previous graph-
theoretic terminology; for hypergraphs (unlike graphs), the set of hyperedges can include
a individual vertex {s} as an element.

100 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation

four nodes. Panel (b) shows a hypergraph that is not equivalent to an
ordinary graph, consisting of two hyperedges of size three joined by

Fig. 4.4 Graphical representations of hypergraphs. Subsets of nodes corresponding to hyper-
edges are shown in rectangles, whereas the arrows represent inclusion relations among
hyperedges. (a) An ordinary single cycle graph represented as a hypergraph. (b) A sim-
ple hypertree of width two. (c) A more complex hypertree of width three.

their intersection of size two. Shown in panel (c) is a more complex
hypertree, to which we will return in the sequel.

Hypertrees or acyclic hypergraphs provide an alternative way to
describe the concept of junction trees, as originally described in Sec-
tion 2.5.2. In particular, a hypergraph is acyclic if it is possible to spec-
ify a junction tree using its maximal hyperedges and their intersections.
The width of an acyclic hypergraph is the size of the largest hyperedge
minus one; we use the term k-hypertree to mean an acyclic hypergraph
of width k consisting of a single connected component. Thus, for exam-
ple, a spanning tree of an ordinary graph is a 1-hypertree, because its
maximal hyperedges, corresponding to ordinary edges in the original
graph, all have size two. As a second example, consider the hypergraph
shown in Figure 4.4(c). It is clear that this hypergraph is equivalent to
the junction tree with maximal cliques {(1245),(4578),(2356)} and sep-
arator sets {(25),(45)}. Since the maximal hyperedges have size four,
this hypergraph is a hypertree of width three.

4.2.2 Hypertree-based factorization and entropy

decomposition

With this background, we now specify an alternative form of the junc-
tion tree factorization (2.12), and show how it leads to a local decom-
position of the entropy. Recall that we view the set E of hyperedges

4.2 Kikuchi and Hypertree-based Methods

101

as a partially ordered set. As described in Appendix E.1, associated
with any poset is a M¨obius function ω : E × E → R. Using the set of
marginals µ = (µh, h ∈ E) associated with the hyperedge set, we can
deﬁne a new set of functions ϕ := (ϕh, h ∈ E) as follows:

log ϕh(xh) :=

ω(g, h)log µg(xg).

(4.40)

As a consequence of this deﬁnition and the M¨obius inversion formula
(see Lemma E.1 in Appendix E.1), the marginals can be represented as
(4.41)

log µh(xh) =

log ϕg(xg).

(cid:6)

g⊆h

(cid:6)

g⊆h

(cid:2)

h∈E

This formula provides a useful recursive method for computing the
functions ϕg, as illustrated in the examples to follow.

The signiﬁcance of the functions (4.40) is that they yield a par-
ticularly simple factorization for any hypertree-structured graph. In
particular, for a hypertree with an edge set containing all intersections
between maximal hyperedges, the underlying distribution is guaranteed
to factorize as follows:

pµ(x) =

ϕh(xh; µ).

(4.42)

Here we use the notation ϕh(xh; µ) to emphasize that ϕh is a function
of the marginals µ. Equation (4.42) is an alternative formulation of the
well-known junction tree decomposition (2.12). Let us consider some
examples to gain some intuition.

Example 4.4 (Hypertree Factorization).

(a) First, suppose that the hypertree is an ordinary tree, in which
case the hyperedge set consists of the union of the vertex set with
the (ordinary) edge set. Viewing this hyperedge set as a poset ordered
by inclusion, it can be shown (see Appendix E.1) that the M¨obius
function takes the form ω(g, g) = 1 for all g ∈ E; ω({s},{s, t}) = −1
for all vertices s and ordinary edges {s, t}, and ω(g, h) = 0 for all g that
are not contained within h. Consequently, for any ordinary edge {s, t},
we have

ϕst(xs, xt) = µst(xs, xt)
µs(xs)µt(xt) ,

102 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation

(cid:15)

whereas for each vertex, we have ϕs(xs) = µs(xs). Consequently, in this
special case, Equation (4.42) reduces to the tree factorization in Equa-
tion (4.8).

(b) Turning to a more complex example, consider the acyclic hyper-

graph speciﬁed by the hyperedge set

(cid:14)

E =

(1245),(2356),(4578),(25),(45),(56),(58),(5)

,

as illustrated in Figure 4.4(c). Rather than computing the M¨obius
function for this poset, it is more convenient to do the computation via
Equation (4.41). In particular, omitting explicit dependence on x for
notational simplicity, we ﬁrst calculate the singleton function ϕ5 = µ5,
and the pairwise function ϕ25 = µ25/µ5, with analogous expressions for
the other pairwise terms. Finally, applying the representation (4.41) to
h = (1245), we have

ϕ1245 = µ1245

ϕ25ϕ45ϕ5

= µ1245

µ25
µ5

µ45
µ5 µ5

= µ1245 µ5
µ25µ45

.

Similar reasoning yields analogous expressions for ϕ2356 and ϕ4578.
Putting the pieces together yields that the density pµ factorizes as

pµ = µ1245µ5
µ25µ45

µ2356µ5
µ25µ56
= µ1245 µ2356 µ4578

µ25 µ45

µ4578µ5
µ45µ58

µ25
µ5

µ45
µ5

µ56
µ5

µ58
µ5

µ5

,

which agrees with the expression from the junction tree formula (2.12).

An immediate but important consequence of the factorization (4.42)
is a local decomposition of the entropy. This decomposition can be
expressed either as a sum of multi-information terms over the hyper-
edges, or as a weighted sum of entropy terms. More precisely, for each
hyperedge g ∈ E, let us deﬁne the hyperedge entropy
µh(xh)log µh(xh),

(4.43)

as deﬁned by the marginal µh, and the multi-information

Ih(µh) :=

µh(xh)log ϕh(xh),

(4.44)

(cid:6)
Hh(µh) := −
(cid:6)

xh

xh

4.2 Kikuchi and Hypertree-based Methods

103

deﬁned by the marginal µh, and function ϕh.

In terms of these quantities, the entropy of any hypertree-structured

distribution has the additive decomposition

Hhyper(µ) = −

Ih(µh),

(4.45)

(cid:6)

h∈E

which follows immediately from the hypertree factorization (4.42) and
the deﬁnition of Ih.

It is also possible to derive an alternative decomposition in terms
of the hyperedge entropies. Using the M¨obius inversion relation (4.40),
we have

Ih(µh) =

ω(g, h)

µh(xh)log µg(xg)

(cid:15)

(cid:15)

µh(xf )log µf (xf )

(cid:6)
(cid:6)
(cid:6)
(cid:6)

g⊆h

e⊇f

=
f⊆h
= −

f⊆h

(cid:14)(cid:6)
(cid:14)(cid:6)

xh
ω(e, f)

xf
c(f)Hf (µf ),

where we have deﬁned the overcounting numbers

c(f) :=

ω(f, e).

(4.46)

(cid:6)
(cid:6)

e⊇f

h∈E

Thus, we have the alternative decomposition

Hhyper(µ) =

c(h)Hh(µh).

(4.47)

We illustrate the decompositions (4.45) and (4.47) by continuing with
Example 4.4:

Example 4.5 (Hypertree Entropies).

(a) For an ordinary tree, there are two types of multi-
information: for an edge (s, t), Ist is equivalent to the ordi-
nary mutual information, whereas for any vertex s ∈ V , the
term Is is equal to the negative entropy −Hs. Consequently,
in this special case, Equation (4.45) is equivalent to the tree

104 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation

entropy given in Equation (4.11). The overcounting num-
bers for a tree are c({(s, t)}) = 1 for any edge (s, t), and
c({s}) = 1 − d(s) for any vertex s, where d(s) denotes the
number of neighbors of s. Consequently, the decomposi-
tion (4.47) reduces to the alternative form (4.15) of the
Bethe entropy.

late I1245 = −(cid:11)

H1245 − H25 − H45 + H5

(b) Consider again the hypertree in Figure 4.4(c). On the basis
of our previous calculations in Example 4.4(c), we calcu-
. The expressions
for the other two maximal hyperedges (i.e., I2356 and I4578)
are analogous. Similarly, we can compute I25 = H5 − H25,
with analogous expressions for the other hyperedges of size
two. Finally, we have I5 = −H5. Putting the pieces together
and doing some algebra yields Hhyper = H1245 + H2356 +
H4578 − H25 − H45.

(cid:12)

4.2.3 Kikuchi and Related Approximations

Recall that the core of the Bethe approach of Section 4 consists of a par-
ticular tree-based (Bethe) approximation to entropy, and a tree-based
outer bound on the marginal polytope. The Kikuchi method and related
approximations extend these tree-based approximations to ones based
on more general hypertrees, as we now describe. Consider a Markov ran-
dom ﬁeld (MRF) deﬁned by some (non-acyclic) hypergraph G = (V, E),
giving rise to an exponential family distribution pθ of the form:

(cid:22)

pθ(x) ∝ exp

θh(xh)

.

(4.48)

(cid:4)(cid:6)

h∈E

Note that this equation reduces to our earlier representation (4.1) of
a pairwise MRF when the hypergraph is an ordinary graph.
Let τ = {τh} be a collection of local marginals associated with the
hyperedges h ∈ E. These marginals must satisfy the obvious normal-
ization condition

(cid:4)
h) = 1.
τh(x

(4.49)

(cid:6)

(cid:2)
h

x

4.2 Kikuchi and Hypertree-based Methods

105

Similarly, these local marginals must be consistent with one another
wherever they overlap; more precisely, for any pair of hyperedges g ⊂ h,
the marginalization condition(cid:6)

(cid:4)
τh(x
h) = τg(xg)

{x

(cid:2)
h

| x(cid:2)

g=xg}

(cid:7)

must hold. Imposing these normalization and marginalization condi-
tions leads to the following constraint set:

Lt(G) =

τ ≥ 0 | Conditions (4.49) ∀h, and (4.50) ∀g ⊂ h

.

(4.51)

(4.50)

(cid:8)

Note that this constraint set is a natural generalization of the tree-based
constraint set deﬁned in Equation (4.7). In particular, deﬁnition (4.51)
coincides with deﬁnition (4.7) when the hypergraph G is an ordinary
graph. As before, we refer to members Lt(G) as pseudomarginals. By
the junction tree conditions in Proposition 2.1, the local constraints
deﬁning Lt(G) are suﬃcient to guarantee global consistency whenever
G is a hypertree.

In analogy to the Bethe entropy approximation, the entropy decom-
position (4.45) motivates the following hypertree-based approximation
to the entropy:

Happ(τ) =

c(g)Hg(τg),

(4.52)

(cid:6)

g∈E

is

the

hyperedge-based

and
where Hg
f⊇g ω(g, f) is the overcounting number deﬁned in Equa-
c(g) :=
tion (4.46). This entropy approximation and the outer bound Lt(G)
on the marginal polytope,
lead to the following
hypertree-based approximation to the exact variational principle:

in conjunction,

entropy

(4.44),

{(cid:19)θ, τ(cid:20) + Happ(τ)}.

max
τ∈Lt(G)

(4.53)

This problem is the hypertree-based generalization of the Bethe varia-
tional problem (4.16).

Example 4.6 (Kikuchi Approximation). To illustrate the approx-
imate variational principle (4.53), consider the hypergraph shown in

(cid:10)

106 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation

1

4

7

2

5

8

3

6

9

1 2 4 5

2 3 5 6

52

4 5

5

5 6

5 8

54

7 8

5 6 8 9

Fig. 4.5 (a) Kikuchi clusters superimposed upon a 3 × 3 lattice graph. (b) Hypergraph
deﬁned by this Kikuchi clustering.

Figure 4.5(b). This hypergraph arises from applying the Kikuchi clus-
tering method [269] to the 3 × 3 lattice in panel (a); see Appendix D
for more details. We determine the form of the entropy approximation
Happ for this hypergraph by ﬁrst calculating the overcounting numbers.
By deﬁnition, c(h) = 1 for each of the four maximal hyperedges (e.g.,
h = (1245)). Since each of the 2-hyperedges has two parents, a little
calculation shows that c(g) = −1 for each 2-hyperedge g. A ﬁnal calcu-
lation shows that c({5}) = 1, so that the overall entropy approximation
takes the form:

Happ = [H1245 + H2356 + H4578 + H5689]
−[H25 + H45 + H56 + H58] + H5.

(4.54)

Since the hypergraph in panel (b) has treewidth 3, the appropriate
constraint set is the polytope L3(G), deﬁned over the pseudomarginals
(τh, h ∈ E). In particular, it imposes nonnegativity constraints, nor-
(cid:6)
malization constraints, and marginalization constraints of the form:

(cid:6)

(cid:4)
(cid:4)
2, x4, x5) = τ45(x4, x5),
τ1245(x
1, x

and

(cid:2)
1,x

(cid:2)
2

x

(cid:4)
6) = τ5(x6).
τ56(x5, x

(cid:2)
6

x

4.2.4 Generalized Belief Propagation

In principle, the variational problem (4.53) could be solved by a number
of methods. Here we describe a Lagrangian-based message-passing algo-
rithm that is a natural generalization of the ordinary sum-product
updates for the Bethe approximation. As indicated by its name, the

4.2 Kikuchi and Hypertree-based Methods

107

deﬁning feature of this scheme is that the only messages passed are
from parents to children — i.e., along directed edges in the poset rep-
resentation of a hypergraph.
In the hypertree-based variational problem (4.53), the variables
correspond to a pseudomarginal τh for each hyperedge E ∈ E
(cid:4). As
with the earlier derivation of the sum-product algorithm, a Lagrangian
formulation of this optimization problem leads to a speciﬁcation of
the optimizing pseudomarginals in terms of messages, which rep-
resent Lagrange multipliers associated with the constraints. There
are various Lagrangian reformulations of the original problem [e.g.,
167, 268, 269], which lead to diﬀerent message-passing algorithms. Here
we describe the parent-to-child form of message-passing derived by
Yedidia et al. [269].

In order to describe the message-passing updates, it is convenient to
deﬁne for a given hyperedge h, the sets of its descendants and ancestors
in the following way:

D(h) := {g ∈ E | g ⊂ h }, A(h) := {g ∈ E | g ⊃ h }.

(4.55)

For example, given the hyperedge h = (1245) in the hypergraph in Fig-
ure 4.4(c), we have A(h) = ∅ and D(h) = {(25),(45),(5)}. We use the
notation D+(h) and A+(h) as shorthand for the sets D(h) ∪ h and
A(h) ∪ h, respectively.

Given a pair of hyperedges (f, g), we let Mf→g(xg) denote the “mes-
sage” passed from hyperedge f to hyperedge g. More precisely, this mes-
sage is a function over the state space of xg (e.g., a multi-dimensional
array in the case of discrete random variables). In terms of these mes-
sages, the pseudomarginal τh in parent-to-child message-passing takes
the following form:
τh(xh) ∝

% $ (cid:2)

$ (cid:2)

Mf→g(xg)

ψg(xg; θ)

(cid:2)

%

,

g∈D+(h)

g∈D+(h)

f∈Par(g)\D+(h)

(4.56)

we

have

where
convenient
shorthand
ψg(xg; θ) = exp(θ(xg)).
the pseudomarginal τh
includes a compatibility function ψg for each hyperedge g in the set

introduced
In this equation,

the

108 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation
D+(h) := D(h) ∪ h. It also collects a message from each hyperedge
f /∈ D+(h) that is a parent of some hyperedge g ∈ D+(h). We illustrate
this construction by following up on Example 4.6.

Example 4.7 (Parent-to-child for Kikuchi). In order to illus-
trate the parent-to-child message-passing, consider
the Kikuchi
approximation for a 3 × 3 grid, illustrated in Figure 4.5. Focusing ﬁrst
on the hyperedge (1245), the ﬁrst term in Equation (4.56) speciﬁes a
product of compatibility functions ψg as g ranges over D+(1245), which
in this case yields the product ψ1245ψ25ψ45ψ5. We then take the prod-
uct over messages from hyperedges that are parents of hyperedges in
D+{(1245)}, excluding hyperedges in D+{(1245)} itself. Figure 4.6(a)
provides an illustration; the set D+{(1245)} is given by the hyperedges
within the dotted ellipses. In this case, the set ∪g Par(g)\D+(h) is given
by (2356) and (4578), corresponding to the parents of (25) and (45),
respectively, combined with hyperedges (56) and (58), which are both
parents of hyperedge (5). The overall result is an expression of the
following form:

τ1245 ∝ ψ

(cid:4)
1 ψ

(cid:4)
2 ψ

(cid:4)
4 ψ

(cid:4)
25 ψ

(cid:4)
14 ψ

(cid:4)
12 ψ
× M(2356)→(25)M(4578)→(45)M(56)→5M(58)→5.

(cid:4)
45 ψ

(cid:4)
5

By symmetry, the expressions for the pseudomarginals on the other
4-hyperedges are analogous. By similar arguments, it is straightforward

1 2 4 5

2 3 5 6

52

1 2 4 5

2 3 5 6

52

4 5

5

5 6

5 8

4 5

5

5 6

5 8

54

7 8

5 6 8 9

54

7 8

5 6 8 9

regions

relevant

Fig. 4.6 Illustration of
for parent-to-child message-passing in a
Kikuchi approximation. (a) Message-passing for hyperedge (1245). Set of descendants
D+{(1245)} is shown within a dotted ellipse. Relevant parents for τ1245 consists
of the set {(2356),(4578),(56),(58)}. (b) Message-passing for hyperedge (45). Dotted
ellipse shows descendant set D+{(45)}. In this case, relevant parent hyperedges are
{(1245),(4578),(25),(56),(58)}.

4.3 Expectation-Propagation Algorithms

109

to compute the following expression for τ45 and τ5:
τ45 ∝ ψ
τ5 ∝ ψ

(cid:4)
45 ψ
(cid:4)
5 M(45)→5 M(25)→5 M(56)→5 M(58)→5.

(cid:4)
4 ψ

(cid:4)
5 M(1245)→(45)M(4578)→(45) M(25)→5 M(56)→5 M(58)→5

Generalized forms of the sum-product updates follow by updating
the messages so as to enforce the marginalization constraints deﬁn-
ing membership in L(G); as in the proof of Theorem 4.2, ﬁxed points
of these updates satisfy the necessary stationary conditions of the
Lagrangian formulation. Further details on diﬀerent variants of gener-
alized sum-product updates can be found in various papers [268, 269,
188, 167, 128].

4.3 Expectation-Propagation Algorithms

There are a variety of other algorithms in the literature that are
message-passing algorithms in the spirit of the sum-product algorithm.
Examples of such algorithms include the family of expectation-
propagation algorithms due to Minka [175], the related class of assumed
density ﬁltering methods [152, 164, 40], expectation-consistent infer-
ence [185], structured summary-propagation algorithms [64, 115], and
the adaptive TAP method of Opper and Winther [183, 184]. These
algorithms are often deﬁned operationally in terms of sequences of
local moment-matching updates, with variational principles invoked
only to characterize each individual update, not to characterize the
overall approximation. In this section, we show that these algorithms
are in fact variational inference algorithms, involving a particular kind
of approximation to the exact variational principle in Theorem 3.4.

The earliest forms of assumed density ﬁltering [164] were developed
for time series applications, in which the underlying graphical model
is a hidden Markov model (HMM), as illustrated in Figure 2.4(a). As
we have discussed, for discrete random variables, the marginal distri-
butions for an HMM can be computed using the forward–backward
algorithm, corresponding to a particular instantiation of the sum-
product algorithm. Similarly, for a Gauss–Markov process, the Kalman
ﬁlter also computes the means and covariances at each node of an
involving general
HMM. However, given a hidden Markov model

110 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation

continuous random variables, the message Mts passed from node t to
s is a real-valued function, and hence diﬃcult to store and transmit.6
The purpose of assumed density ﬁltering is to circumvent the compu-
tational challenges associated with passing function-valued messages.
Instead, assumed density ﬁltering (ADF) operates by passing approxi-
mate forms of the messages, in which the true message is approximated
by the closest member of some tractable class. For instance, a general
continuous message might be approximated with a Gaussian message.
This procedure of computing the message approximations, if closeness
is measured using the Kullback–Leibler divergence, can be expressed
in terms of moment-matching operations.

Minka [175] observed that the basic ideas underlying ADF can be
generalized beyond Markov chains to arbitrary graphical models, an
insight that forms the basis for the family of expectation-propagation
(EP) algorithms. As with assumed density ﬁltering, expectation-
propagation [174, 175] and various related algorithms [64, 115, 185] are
typically described in terms of moment-matching operations. To date,
the close link between these algorithms and the Bethe approximation
does not appear to have been widely appreciated. In this section, we
show that these algorithms are methods for solving certain relaxations
of the exact variational principle from Theorem 3.4, using “Bethe-like”
entropy approximations and particular convex outer bounds on the
set M. More speciﬁcally, we recover the moment-matching updates of
expectation-propagation as one particular type of Lagrangian method
for solving the resulting optimization problem, thereby showing that
expectation-propagation algorithms belong to the same class of vari-
ational methods as belief propagation. This section is a reﬁnement of
results from the thesis [240].

4.3.1 Entropy Approximations Based on Term Decoupling

We begin by developing a general class of entropy approximations based
on decoupling an intractable collection of terms. Given a collection of

6 The Gaussian case is special, in that this functional message can always be parameterized
in terms of its “mean” and “variance,” and the eﬃciency of Kalman ﬁltering stems from
this fact.

111
random variables (X1, . . . , Xm) ∈ Rm, consider a collection of suﬃcient
statistics that is partitioned as

4.3 Expectation-Propagation Algorithms

φ :=

φ1, φ2, . . . , φdT

and Φ :=

Φ1,Φ2, . . . ,ΦdI

(4.57)

(cid:23)

(cid:18)(cid:19)

(cid:17)

(cid:24)
(cid:20)

,

(cid:23)

(cid:18)(cid:19)

(cid:17)

(cid:24)
(cid:20)

,

Tractable component

Intractable component.

where φi are univariate statistics and the Φi are generally multivariate.
As will be made explicit in the examples to follow, the partitioning sep-
arates the tractable from the intractable components of the associated
exponential family distribution.

Let us set up various exponential families associated with sub-
collections of (φ,Φ). First addressing the tractable component, the
vector-valued function φ : X m → RdT has an associated vector of canon-
ical parameters θ ∈ RdT . Turning to the intractable component, for
each i = 1, . . . , dI, the function Φi maps from X m to Rb, and the
all, the function Φ = (Φ1, . . . ,ΦdI ) maps from X m to Rb×dI , and has

vector (cid:9)θi ∈ Rb is the associated set of canonical parameters. Over-
the associated canonical parameter vector (cid:9)θ ∈ Rb×dI , partitioned as
(cid:23)(cid:9)θ1,(cid:9)θ2, . . . ,(cid:9)θdI
(cid:9)θ =
p(x; θ,(cid:9)θ) ∝ f0(x)exp

. These families of suﬃcient statistics deﬁne the

exponential family

(cid:24)

(cid:23)(cid:19)θ, φ(x)(cid:20)(cid:24)
(cid:23)(cid:19)θ, φ(x)(cid:20)(cid:24) dI(cid:2)

exp

(cid:23)(cid:19)(cid:9)θ, Φ(x)(cid:20)(cid:24)
exp((cid:19)(cid:9)θi, Φi(x)(cid:20)).
(cid:23)(cid:19)θ, φ(x)(cid:20)(cid:24)

i=1

= f0(x)exp

(4.58)

We say that any density p of the form (4.58) belongs to the (φ,Φ)-
exponential family.

Next, we deﬁne the base model

p(x; θ,(cid:19)0) ∝ f0(x)exp

set (cid:9)θ = (cid:19)0. We say that any distribution p of the form (4.59) belongs to

(4.59)
in which the intractable suﬃcient statistics Φ play no role, since we have
the φ-exponential family. Similarly, for each index i ∈ {1, . . . , dI}, we
deﬁne the Φi-augmented distribution

,

(cid:23)(cid:19)θ, φ(x)(cid:20)(cid:24)

exp((cid:19)(cid:9)θi, Φi(x)(cid:20)),

(4.60)
in which only a single term Φi has been introduced, and we say that
any p of the form (4.60) belongs to the (φ,Φi)-exponential family.

p(x; θ,(cid:9)θi) ∝ f0(x)exp

112 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation

The basic premises in the tractable–intractable partitioning between

φ and Φ are:

• First, it is possible to compute marginals exactly in polyno-
mial time for distributions of the base form (4.59) — that is,
for any member of the φ-exponential family.
• Second, for each index i = 1, . . . , dI, exact polynomial-time
computation is also possible for any distribution of the Φi-
augmented form (4.60) — that is, for any member of the
(φ,Φi)-exponential family.
• Third, it is intractable to perform exact computations in the
full (φ,Φ)-exponential family (4.58), since it simultaneously
incorporates all of the terms (Φ1, . . . ,ΦdI ).

Example 4.8 (Tractable/intractable Partitioning for Mixture
Models). Let us illustrate the partitioning scheme (4.58) with the
example of a Gaussian mixture model. Suppose that the random vec-
tor X ∈ Rm has a multivariate Gaussian distribution, N(0,Σ). Letting
ϕ(y; µ,Λ) denote the density of a random vector with a N(µ,Λ) distri-
bution, consider the two-component Gaussian mixture model

p(y | X = x) = (1 − α) ϕ(y;0, σ2

0I) + α ϕ(y; x, σ2

1I),

(4.61)

where α ∈ (0,1) is the mixing weight, σ2
I is the m × m identity matrix.

0 and σ2

1 are the variances, and

Given n i.i.d. samples y1, . . . , yn from the mixture density (4.61),
it is frequently of interest to compute marginals under the posterior
distribution of X conditioned on (y1, . . . , yn). Assuming a multivariate
Gaussian prior X ∼ N(0,Σ), and using Bayes’ theorem, we ﬁnd that
the posterior takes the form:

p(x | y1 . . . , yn) ∝ exp

= exp

(cid:23) − 1
(cid:23) − 1

2 xT Σ

2 xT Σ

(cid:24) n(cid:2)
−1x
(cid:24)
−1x

i=1

exp

p(yi | X = x)

(cid:7) n(cid:6)

(cid:8)
log p(yi | X = x)

.

i=1

(4.62)

113

(cid:23)− 1

4.3 Expectation-Propagation Algorithms

(cid:24)
To cast this model as a special case of the partitioned exponen-
2 xT Σ−1x
tial family (4.58), we ﬁrst observe that the term exp
can be identiﬁed with the base term f0(x)exp((cid:19)θ, φ(x)(cid:20)), so that
we have dT = m. On the other hand, suppose that we deﬁne
tion, the term exp{(cid:10)
Φi(x) := log p(yi | X = x) for each i = 1, . . . , n. Since the observation
(cid:5)
i=1 exp((cid:19)(cid:9)θi, Φi(x)(cid:20) in Equation (4.58). Note that we have dI = n and
yi is a ﬁxed quantity, this deﬁnition makes sense. With this deﬁni-
i=1 log p(yi | X = x)} corresponds to the product
b = 1, with (cid:9)θi = 1 for all i = 1, . . . , n.

dI

n

As a particular case of the (φ,Φ)-exponential family in this setting,
the base distribution p(x; θ,(cid:19)0) ∝ exp(− 1
2 xT Σ−1x) corresponds to a mul-
tivariate Gaussian, for which exact calculations of marginals is possible
in O(m3) time. Similarly, for each i = 1, . . . , n, the Φi-augmented dis-
tribution (4.60) is proportional to

−1

[(1 − α) ϕ(yi;0, σ2

0I) + α ϕ(yi; x, σ2

1I)],

(4.63)

(cid:23) − 1

exp

2 xT Σ

(cid:24)

This distribution is a Gaussian mixture with two components, so that
it is also possible to compute marginals exactly in cubic time. However,
the full distribution (4.62) is a Gaussian mixture with 2n components,
so that the complexity of computing exact marginals is exponential in
the problem size.

Returning to the main thread, let us develop a few more features of
the distribution of interest (4.48). Since it is an exponential family, it

has a partitioned set of mean parameters (µ,(cid:9)µ) ∈ RdT × RdI×b, where

and ((cid:9)µ1, . . . ,(cid:9)µdI ) = E[Φ1(X), . . . ,ΦdI (X)].

µ = E[φ(X)],

(cid:14)

M(φ,Φ) :=

As an exponential family, the general variational principle from Theo-
rem 3.4 is applicable. As usual, the relevant quantities in the variational
principle (3.45) are the set

(µ,(cid:9)µ) | (µ,(cid:9)µ) = Ep[(φ(X),Φ(X))]

and the entropy, or negative dual function H(µ,(cid:9)µ) = −A

∗(µ,(cid:9)µ). Given

,
(4.64)

for some p

our assumption that exact computation under the full distribu-
tion (4.48) is intractable, there must be challenges associated with

(cid:15)

114 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation

characterizing the mean parameter space (4.64) and/or the entropy
function. Accordingly, we now describe a natural approximation to
these quantities, based on the partitioned structure of the distri-
bution (4.48), that leads to the class of expectation-propagation
algorithms.

Associated with the base distribution (4.59) is the set
M(φ) :=

µ ∈ RdT | µ = Ep[φ(X)]

for some density p

(cid:14)

(cid:15)

,

(4.65)

corresponding to the globally realizable mean parameters for the base
distribution viewed as a dT -dimensional exponential family. By Theo-
rem 3.3, for any µ ∈ M◦(φ), there exists an exponential family mem-
ber pθ(µ) that realizes it. Moreover, by our assumption that the base
distribution is tractable, we can compute the entropy H(µ) of this
distribution. Similarly, for each i = 1, . . . , dI, the Φi-augmented distri-
(cid:14)
(cid:15)
bution (4.60) is associated with the mean parameter space M(φ,Φi)
(µ,(cid:9)µi) ∈ RdT × Rb | (µ,(cid:9)µi) = Ep[(φ(X),Φi(X))]
By similar reasoning as above, for any (µ,(cid:9)µi) ∈ M◦(φ,Φi), there is a
moreover the entropy H(µ,(cid:9)µi) can be computed easily.
(τ,(cid:9)τ) ∈ RdT × RdI×b, we deﬁne for each i = 1,2, . . . , dI the coordinate

With these basic ingredients, we can now deﬁne an outer bound
on the set M(φ,Φ). Given a candidate set of mean parameters
projection operator Πi : RdT × RdI×b → RdT × Rb that operates as

member of the (φ,Φi)-exponential family with these mean parameters.
Furthermore, since we have assumed that the Φi-distribution (4.60) is
tractable, it is easy to determine membership in the set M(φ;Φi), and

for some density p
.
(4.66)

(τ,(cid:9)τ) Πi−→ (τ,(cid:9)τ i) ∈ RdT × Rb.

We then deﬁne the set

L(φ;Φ) := {(τ,(cid:9)τ) | τ ∈ M(φ), Πi(τ,(cid:9)τ) ∈ M(φ,Φi) ∀i = 1, . . . , dI}.

(4.67)
Note that L(φ;Φ) is a convex set, and moreover it is an outer bound
on the true set M(φ;Φ) of mean parameters.

4.3 Expectation-Propagation Algorithms

115

We now develop an entropy approximation that is tailored to the

structure of L(φ;Φ). We begin by observing that for any (τ,(cid:9)τ) ∈ L(φ;Φ)
family with mean parameters (τ,(cid:9)τ i). This assertion follows because the
projected mean parameters (τ,(cid:9)τ i) belong to M(φ;Φi), so that The-
orem 3.3 can be applied. We let H(τ,(cid:9)τ i) denote the entropy of this

and for each i = 1, . . . , dI, there is a member of the (φ,Φi)-exponential

exponential family member. Similarly, since τ ∈ M(φ) by deﬁnition
of L(φ;Φ), there is a member of the φ-exponential family with mean
parameter τ; we denote its entropy by H(τ). With these ingredients,
we deﬁne the following term-by-term entropy approximation

Hep(τ,(cid:9)τ) := H(τ) +

dI(cid:6)

(cid:11)
(cid:12)
H(τ,(cid:9)τ (cid:7)) − H(τ)
(cid:14)(cid:19)τ, θ(cid:20) + (cid:19)(cid:9)τ ,(cid:9)θ(cid:20) + Hep(τ,(cid:9)τ)
(cid:15)

(cid:7)=1

.

max

(τ,(cid:4)τ)∈L(φ;Φ)

Combining this entropy approximation with the convex outer
bound (4.67) yields the optimization problem

.

(4.68)

(4.69)

This optimization problem is an approximation to the exact variational
principle from Theorem 3.4 for the (φ,Φ)-exponential family (4.48),
and it underlies the family of expectation-propagation algorithms. It
is closely related to the Bethe variational principle, as the examples to
follow should clarify.

Example 4.9 (Sum-Product and Bethe Approximation). To
provide some intuition, let us consider the Bethe approximation from
the point of view of the variational principle (4.69). More speciﬁcally,
we derive the Bethe entropy approximation (4.14) as a particular case
of the term-by-term entropy approximation (4.68), and the tree-based
outer bound L(G) from Equation (4.7) as a particular case of the con-
vex outer bound (4.67) on M(φ;Φ).
Consider a pairwise Markov random ﬁeld based on an undirected
graph G = (V, E), involving a discrete variable Xs ∈ {0,1, . . . , rs − 1}
at each vertex s ∈ V ; as we have seen, this can be expressed as an
exponential family in the form (4.1) using the standard overcomplete
parameterization (3.34) with indicator functions. Taking the point of

116 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation

view of (4.69), we partition the suﬃcient statistics in the following
way. The suﬃcient statistics associated with nodes are deﬁned to be
the tractable set, and those associated with edges are deﬁned to be
the intractable set. Thus, using the functions θs and θst deﬁned in
Equation (4.2), the base distribution (4.59) takes the form

p(x; θ1, . . . , θm,(cid:19)0) ∝

exp(θs(xs)).

(4.70)

(cid:2)

s∈V

In this particular case, the terms Φi to be added correspond to the
functions θst — that is, the index i runs over the edge set of the graph.
For edge (u, v), the Φuv-augmented distribution (4.60) takes the form:

p(x; θ1, . . . , θm, θuv) ∝

exp(θs(xs))

exp

θuv(xu, xv)

.

(4.71)

#

(cid:23)

(cid:24)

"(cid:2)

s∈V

The mean parameters associated with the standard overcomplete
representation are singleton and pairwise marginal distributions, which
we denote by (τs, s ∈ V ) and τuv respectively. The entropy of the base
distribution depends only on the singleton marginals, and given the
product structure (4.70), takes the simple form
H(τs),

H(τ1, . . . , τm) =

(cid:6)

s∈V

where H(τs) = −(cid:10)

τs(xs)log τs(xs) is the entropy of the marginal
distribution. Similarly, since the augmented distribution (4.71) has only
a single edge added and factorizes over a cycle-free graph, its entropy
has the explicit form

xs

(cid:11)
(cid:12)
H(τuv) − H(τu) − H(τv)

H(τ1, . . . , τm, τuv) =

H(τs) +

=

H(τs) − I(τuv),

where H(τuv) := −(cid:10)

s∈V
τuv(xu, xv)log τuv(xu, xv) is the joint entropy,
and I(τuv) := H(τu) + H(τv) − H(τuv) is the mutual
information.
Putting together the pieces, we ﬁnd that the term-by-term entropy
approximation (4.68) — for this particular problem — has the form:

xu,xv

Hep(τ) =

H(τs) −

Ist(τst),

(cid:6)

(s,t)∈E

(cid:6)
(cid:6)

s∈V

(cid:6)

s∈V

4.3 Expectation-Propagation Algorithms

117

which is precisely the Bethe entropy approximation deﬁned previ-
ously (4.14).
Next, we show how the outer bound L(φ;Φ) deﬁned in Equa-
tion (4.67) specializes to L(G). Consider a candidate set of local
marginal distributions

(cid:24)

τ =

τs, s ∈ V ; τst,(s, t) ∈ E

.

In the current setting, the set M(φ) corresponds to the set of all glob-
ally realizable marginals (τs, s ∈ V ) under a factorized distribution, so
that the inclusion (τs, s ∈ V ) ∈ M(φ) is equivalent to the nonnegativ-
ity constraints τs(xs) ≥ 0 for all xs ∈ Xs, and the local normalization
constraints

τs(xs) = 1

for all s ∈ V .

(4.72)

(cid:23)

(cid:6)

xs

Recall that the index i runs over edges of the graph;
for
instance i = (u, v), then the projected marginals Πuv(τ) are given by
(τ1, . . . , τm, τuv). The set M(φ;Φuv) is traced out by all globally consis-
tent marginals of this form, and is equivalent to the marginal polytope
M(Guv), where Guv denotes the graph with a single edge (u, v). Since
this graph is a tree, the inclusion Πuv(τ) ∈ M(φ;Φuv) is equivalent to
having Πuv(τ) satisfy — in addition to the nonnegativity and local
normalization constraints (4.72) — the marginalization conditions

if,

τuv(xu, xv) = τu(xu),

and

τuv(xu, xv) = τv(xv).

Therefore, the full collection of inclusions Πuv(τ) ∈ M(φ;Φuv), as (u, v)
runs over the graph edge set E, specify the same conditions deﬁning
the ﬁrst-order relaxed constraint set L(G) from Equation (4.7).

(cid:6)

xu

(cid:6)

xv

4.3.2 Optimality in Terms of Moment-Matching

Returning to the main thread, we now derive a Lagrangian method
for attempting to solve the expectation-propagation variational prin-
ciple (4.69). As we will show, these Lagrangian updates reduce to
moment-matching, so that the usual expectation-propagation updates
are recovered.

118 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation

Our Lagrangian formulation is based on the following two steps:
• First, we augment the space of pseudo-mean-parameters over
which we optimize, so that the original constraints deﬁning
L(φ;Φ) are decoupled.
• Second, we add new constraints — to be penalized with
Lagrange multipliers — so as to enforce the remaining con-
straints required for membership in L(φ;Φ).

Beginning with the augmentation step, let us duplicate the vector
τ ∈ RdT a total of dI times, deﬁning thereby deﬁning dI new vec-
tors ηi ∈ RdT and imposing the constraint that ηi = τ for each index
i = 1, . . . , dI. This yields a large collection of pseudo-mean-parameters

{τ,(ηi,(cid:9)τ i), i = 1, . . . , dI} ∈ RdT × (RdT × Rb)dI ,
(cid:7)

and we recast the variational principle (4.69) using these pseudo-mean-
parameters as follows:

(cid:8)
dI(cid:6)
(cid:11)
(cid:12)
H(ηi,(cid:9)τ i) − H(ηi)
(cid:18)(cid:19)
(cid:20)
F (τ;(ηi,(cid:9)τ i))
subject to the constraints (ηi,(cid:9)τ i) ∈ M(φ;Φi) for all i = 1, . . . , dI, and

(cid:19)(cid:9)τ i,(cid:9)θi(cid:20) + H(τ) +

max

{τ,(ηi,(cid:4)τ i)}

(cid:19)τ, θ(cid:20) +

,

(4.73)

dI(cid:6)

i=1

(cid:17)

i=1

τ = ηi

∀i = 1, . . . , dI .

(4.74)

Let us now consider a particular iterative scheme for solving the
reformulated problem (4.73). In particular, for each i = 1, . . . , dI, deﬁne
a vector of Lagrange multipliers λi ∈ RdT associated with the con-
straints τ = ηi. We then form the Lagrangian function

L(τ; λ) = (cid:19)τ, θ(cid:20) +

dI(cid:6)

(cid:19)(cid:9)τ i,(cid:9)θi(cid:20) + F (τ;(ηi,(cid:9)τ i)) +

dI(cid:6)

i=1

i=1

(cid:19)λi, τ − ηi(cid:20).

(4.75)

τ ∈ M(φ) and (ηi,(cid:9)τ i) ∈ M(φ;Φi) explicitly.

This Lagrangian is a partial one, since we are enforcing the constraints

4.3 Expectation-Propagation Algorithms

Consider an optimum solution {τ,(ηi,(cid:9)τ i), i = 1, . . . , dI} of the opti-
each i = 1, . . . , dI, the vector (ηi,(cid:9)τ i) belongs to the relative interior

mization problem (4.73) that satisﬁes the following properties: (a)
the vector τ belongs to the (relative) interior M◦(φ), and (b) for
M◦(φ;Φi). Any such solution must satisfy the zero-gradient conditions
associated with the partial Lagrangian (4.75) — namely

119

for i = 1, . . . , dI, and

∇τ L(τ; λ) = 0,
∇(ηi,(cid:4)τ i)L(τ; λ) = 0
∇λL(τ; λ) = 0.

(4.76a)
(4.76b)
(4.76c)
Since the vector τ belongs to M◦(φ), it speciﬁes a distribution in
the φ-exponential family. By explicitly computing the Lagrangian con-
dition (4.76a) and performing some algebra — essentially the same
steps as the proof of Theorem 4.2 — we ﬁnd that this exponential fam-
ily member can be written, in terms of the original parameter vector θ
and the Lagrange multipliers λ, as follows:

q(x; θ, λ) ∝ f0(x)exp

θ +

λi, φ(x)

.

Similarly, since for each i = 1, . . . , dI, the vector (τ,(cid:9)τ i) belongs to
qi(x; θ,(cid:9)θi, λ) ∝ f0(x)exp

M◦(φ;Φi), it also speciﬁes a distribution in the (φ,Φi)-exponential fam-
ily. Explicitly computing the condition (4.76b) and performing some
algebra shows that this distribution can be expressed as

)
+ (cid:19)(cid:9)θi, Φi(x)(cid:20)

(cid:6)

(&

λ(cid:7), φ(x)

(4.78)

θ +

’

(4.77)

,

(cid:7)&

dI(cid:6)

i=1

’(cid:8)

constraints
ηi = E

conditions(cid:13)

(cid:7)(cid:7)=i

(cid:13)

The ﬁnal Lagrangian condition (4.76c)

the
(4.74) are satisﬁed. Noting that τ = Eq[φ(X)] and
qi[φ(X)], these constraints reduce to the moment-matching

ensures

that

q(x; θ, λ)φ(x)ν(dx) =

qi(x; θ,(cid:9)θi, λ)φ(x)ν(dx),

(4.79)

for i = 1, . . . , dI.

On the basis of Equations (4.77), (4.78), and (4.79), we arrive at
the expectation-propagation updates, as summarized in Figure 4.7.

120 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation

Expectation-propagation (EP) updates:

(1) At iteration n = 0,

initialize the Lagrange multiplier

(2) At each iteration, n = 1,2, . . . , choose some index

vectors (λ1, . . . , λdI ).
i(n) ∈ {1, . . . , dI}, and
(cid:13)

(a) Using Equation (4.78), form the augmented distribution

qi(n) and compute the mean parameter

ηi(n) :=

qi(n)(x)φ(x)ν(dx) = E

qi(n)[φ(X)].

(4.80)

(b) Using Equation (4.77), form the base distribution q and
adjust λi(n) to satisfy the moment-matching condition

Eq[φ(X)] = ηi(n).

(4.81)

Fig. 4.7 Steps involved in the expectation-propagation updates. It is a Lagrangian algorithm
for attempting to solve the Bethe-like approximation (4.73), or equivalently (4.69).

We note that the algorithm is well deﬁned, since for any realizable mean
parameter τ, there is always a solution for λi(n) in Equation (4.81). This
fact can be seen by considering the dT -dimensional exponential family
deﬁned by the pair (λi(n), φ), and then applying Theorem 3.3. Moreover,
it follows that any ﬁxed point of these EP updates satisﬁes the neces-
sary Lagrangian conditions for optimality in the program (4.73). From
this fact, we make an important conclusion — namely, ﬁxed points of
the EP updates are guaranteed to exist, assuming that the optimiza-
tion problem (4.73) has at least one optimum. As with the sum-product
algorithm and the Bethe variational principle, there are no guarantees
that the EP updates converge in general. However, it would be rel-
atively straightforward to develop convergent algorithms for ﬁnding
at least a local optimum of the variational problem (4.73), or equiva-
lently (4.69), possibly along the lines of convergent algorithms devel-
oped for the ordinary Bethe variational problem or convexiﬁed versions
thereof [111, 254, 270, 108].

4.3 Expectation-Propagation Algorithms

121

At a high level, the key points to take away are the following:
within the variational framework, expectation-propagation algorithms
are based on a Bethe-like entropy approximation (4.68), and a partic-
ular convex outer bound on the set of mean parameters (4.67). More-
over, the moment-matching steps in the EP algorithm arise from a
Lagrangian approach for attempting to solve the relaxed variational
principle (4.69).

We conclude by illustrating the speciﬁc forms taken by the algo-

rithm in Figure 4.7 for some concrete examples:

Example 4.10 (Sum-Product as Moment-matching). As a con-
tinuation of Example 4.9, we now show how the updates (4.80)
and (4.81) of Figure 4.7 reduce to the sum-product updates. In
this particular example, the index i ranges over edges of the
graph. Associated with i = (u, v) are the pair of Lagrange multi-
plier vectors (λuv(xv), λvu(xu)). In terms of these quantities, the base
distribution (4.77) can be written as

q(x; θ, λ) ∝

exp(θs(xs))

exp

λuv(xv) + λvu(xu)

(cid:2)
(cid:2)

s∈V

(

(cid:23)

(cid:2)
(cid:6)

(u,v)∈E

)

(cid:24)

=

or more compactly as q(x; θ, λ) ∝(cid:5)

θs(xs) +

s∈V

exp

the pseudo-marginals

τs(xs) ∝ exp

(

λts(xs)

,

(4.82)

t∈N(s)
s∈V τs(xs), where we have deﬁned

)

(cid:6)

t∈N(s)

θs(xs) +

λts(xs)

.

It is worthwhile noting the similarity to the sum-product expres-
sion (4.23) for the singleton pseudomarginals τs, obtained in the
(cid:23)
proof of Theorem 4.2. Similarly, when (cid:10) = (u, v), the augmented
distribution (4.78) is given by
%
q(u,v)(x; θ; λ) ∝ q(x; θ, λ)exp

(cid:24)
(cid:23)
(cid:24)
θuv(xu, xv) − λvu(xu) − λuv(xv)
θuv(xu, xv) − λvu(xu) − λuv(xv)

$(cid:2)

τs(xs)

exp

=

.

s∈V

(4.83)

122 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation

Now consider the updates (4.80) and (4.81). If index i = (u, v)
is chosen, the update (4.80) is equivalent to computing the single-
ton marginals of the distribution (4.83). The update (4.81) dictates
that the Lagrange multipliers λuv(xv) and λvu(xu) should be adjusted
so that the marginals {τu, τv} of the distribution (4.82) match these
marginals. Following a little bit of algebra, these ﬁxed point con-
ditions reduce to the sum-product updates along edge (u, v), where
the messages are given as exponentiated Lagrange multipliers by
Muv(xv) = exp(λuv(xv)).

From the perspective of term-by-term approximations, the sum-
product algorithm uses a product base distribution (see Equa-
tion (4.70)). A natural extension, then, is to consider a base distribution
with more structure.

Example 4.11 (Tree-structured EP). We illustrate this idea by
deriving the tree-structured EP algorithm [174], applied to a pairwise
Markov random ﬁeld on a graph G = (V, E). We use the same set-up
and parameterization as in Examples 4.9 and 4.10. Given some ﬁxed
spanning tree T = (V, E(T )) of the graph, the base distribution (4.59)
is given by

(cid:24)

p(x; θ,(cid:19)0) ∝

exp(θs(xs))

exp

θst(xs, xt)

.

(4.84)

(cid:2)

(s,t)∈E(T )

(cid:2)

s∈V

(cid:23)

(cid:24)

In this case, the index i runs over edges (u, v) ∈ E\E(T ); given such
an edge (u, v), the Φuv-augmented distribution (4.60) is obtained by
adding in the term θuv:

p(x; θ, θuv) ∝ p(x; θ,(cid:19)0) exp

(4.85)
Let us now describe the analogs of the sets M(φ;Φ), M(φ), and
M(φ;Φi) for this setting. First, as we saw in Example 4.9, the subvectro
of mean parameters associated with the full model (4.48) is given by

θuv(xu, xv)

(cid:23)

(cid:24)

.

(cid:23)

µ :=

µs, s ∈ V ; µst,(s, t) ∈ E

.

Accordingly, the analog of M(φ;Φ) is the marginal polytope M(G).
Second, if we use the tree-structured distribution (4.84) as the base

4.3 Expectation-Propagation Algorithms

123

distribution, the relevant subvector of mean parameters is

(cid:23)

(cid:24)
µs, s ∈ V ; µst,(s, t) ∈ E(T )

.

µ(T ) :=

The analog of the set M(φ) is the marginal polytope M(T ), or equiv-
alently — using Proposition 4.1 — the set L(T ). Finally, if we add
in edge i = (u, v) /∈ E(T ), then the analog of the set M(φ;Φi) is the
marginal polytope M(T ∪ (u, v)).
The analog of the set L(φ;Φ) is an interesting object, which we
refer to as the tree-EP outer bound on the marginal polytope M(G). It
consists of all vectors τ =

τs, s ∈ V ; τst,(s, t) ∈ E

such that

(cid:23)

(cid:24)

(a) the inclusion τ(T ) ∈ M(T ) holds, and
(b) for all (u, v) /∈ T , the inclusion (τ(T ), τuv) ∈ M(T ∪ (u, v))

holds.

Observe that the set thus deﬁned is contained within L(G): in partic-
ular, the condition τ(T ) ∈ M(T ) ensures nonnegativity, normalization,
and marginalization for all mean parameters associated with the tree,
and the inclusion (τ(T ), τuv) ∈ M(T ∪ (u, v)) ensures that τuv is non-
negative, and satisﬁes the marginalization constraints associated with
τu and τv. For graphs with cycles, this tree-EP outer bound is strictly
contained within L(G); for instance, when applied to the single cycle C3
on three nodes, the tree-EP outer bound is equivalent to the marginal
polytope [240]. But the set M(C3) is strictly contained within L(C3),
as shown in Example 4.1.

The entropy approximation Hep associated with tree-EP is easy to
deﬁne. Given a candidate set of pseudo-mean-parameters τ in the tree-
EP outer bound, we deﬁne the tree-structured entropy associated with
the base distribution (4.84)

(cid:6)

(cid:6)

H(τ(T )) :=

H(τs) −

Ist(τst).

(4.86)

(s,t)∈E(T )

s∈V
(u, v) /∈ E(T ), we deﬁne

for

each edge

Similarly,
entropy
H(τ(T ), τuv) associated with the augmented distribution (4.85); unlike
the base case, this entropy does not have an explicit form (since the
graph is not in junction tree form), but it can be computed easily.

the

124 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation

The tree-EP entropy approximation then takes the form:

(cid:6)

(cid:11)
(cid:12)
H(τ(T ), τuv) − H(τ(T ))

.

Hep(τ) = H(τ(T )) +

(u,v) /∈E(T )

Finally,

let us derive the moment-matching updates

(4.80)
and (4.81) for tree-EP. For each edge (u, v) /∈ E(T ), let λuv(T ) denote
a vector of Lagrange multipliers, of the same dimension as τ(T ), and
let φ(x; T ) denote the subset of suﬃcient statistics associated with T .
The optimized base distribution (4.77) can be represented in terms of
the original base distribution (4.84) and these tree-structured Lagrange
multipliers as

q(x; θ, λ) ∝ p(x; θ,(cid:19)0)

(cid:2)

(u,v) /∈E(T )

exp((cid:19)λuv(T ), φ(x; T )(cid:20)).
(cid:2)

(s,t)(cid:7)=(u,v)

If edge (u, v) is added, the augmented distribution (4.78) is given by
quv(x; θ, λ) ∝ p(x; θ,(cid:19)0)exp(θuv(xu, xv))
exp((cid:19)λuv(T ), φ(x; T )(cid:20)).

For a given edge (u, v) /∈ E(T ), the moment-matching step (4.81) cor-
responds to computing singleton marginals and pairwise marginals for
edges (s, t) ∈ E(T ) under the distribution quv(x; θ, λ). The step (4.81)
corresponds to updating the Lagrange multiplier vector λuv(T ) so the
marginals of q(x; θ; λ) agree with those of quv(x; θ; λ) for all nodes s ∈ V ,
and all edges (s, t) ∈ E(T ). See the papers [174, 252, 240] for further
details on tree EP.

The previous examples dealt with discrete random variables; we now
return to the case of a mixture model with continuous variables, ﬁrst
introduced in Example 4.8.

Example 4.12 (EP for Gaussian Mixture Models). Recall from
Equation (4.62) the representation of the mixture distribution as an
exponential family with the base potentials φ(x) = (x; xxT ) and auxi-
liary terms Φi(x) = log p(yi | x), for i = 1, . . . , n. Turning to the analogs
of the various mean parameter spaces, the set M(φ;Φ) is a subset of

4.3 Expectation-Propagation Algorithms

Rm × S m
parameters partitioned as

125
+ × Rn, corresponding the space of all globally realizable mean
(cid:16)

(cid:21)

E[X]; E[XX T ]; E[log p(yi | X)],

i = 1, . . . , n

.

Recall that (y1, y2, . . . , yn) are observed, and hence remain ﬁxed
throughout the derivation.

The set M(φ) is a subset of Rm × S m

+ , corresponding to the mean
parameter space for a multivariate Gaussian, as characterized in Exam-
ple 3.7. For each i = 1, . . . , n, the constraint set M(φ;Φi) is a subset of
Rm × S m
+ × R, corresponding to the collection of all globally realizable
mean parameters with the partitioned form

(cid:16)

(cid:21)
E[X], E[XX T ], E[log p(yi | X)]

.

Turning to the various entropies, the base term is the entropy H(µ)
of a multivariate Gaussian where µ denotes the pair (E[X], E[XX T ]);
family member with suﬃcient statistics (φ(x),log p(yi | x)), and mean

similarly, the augmented term H(µ,(cid:9)µi) is the entropy of the exponential
parameters (µ,(cid:9)µi), where(cid:9)µi := E[log p(yi | X)]). Using these quantities,

we can deﬁne the analog of the variational principle (4.69).

Turning to the moment-matching steps (4.80) and (4.81), the
Lagrangian version of Gaussian-mixture EP algorithm can be formu-
lated in terms of a collection of n matrix-vector Lagrange multiplier
pairs

(λi,Λi) ∈ Rm × Rm×m,

i = 1, . . . , n,

one for each augmented distribution. Since X ∼ N(0,Σ) by deﬁnition,
the optimized base distribution (4.77) can be written in terms of Σ−1
and the Lagrange multipliers

(cid:7)
q(x;Σ;(λ,Λ)) ∝ exp

(cid:19) n(cid:6)

i=1

λi, x(cid:20) +

−1 +

Σ

Λi, xxT

. (4.87)

&&−1

2

n(cid:6)

i=1

’’(cid:8)

Note that this is simply a multivariate Gaussian distribution. The aug-
mented distribution (4.78) associated with any term i ∈ {1,2, . . . , dI},

126 Sum-Product, Bethe–Kikuchi, and Expectation-Propagation

denoted by qi, takes the form

f0(x)exp

λ(cid:7), x(cid:20) +

−1 +

Σ

(cid:6)
(cid:14)(cid:19)

(cid:7)(cid:7)=i

&&−1

2

’’

+ (cid:19)(cid:9)θi, log p(yi | x)(cid:20)(cid:15)

.

Λ(cid:7), xxT

(cid:6)

(cid:7)(cid:7)=i

qi[X], E

(4.88)
With this set-up, the step (4.80) corresponds to computing the mean
qi[XX T ]) under the distribution (4.88), and
parameters (E
step (4.81) corresponds to adjusting the multivariate Gaussian (4.87)
so that it has these mean parameters. Fixed points of these moment-
matching updates satisfy the necessary Lagrangian conditions to be
optima of the associated Bethe-like approximation of the exact varia-
tional principle.

We refer the reader to Minka [172, 175] and Seeger [213] for fur-
ther details of the Gaussian-mixture EP algorithm and some of its
properties.

5

Mean Field Methods

This section is devoted to a discussion of mean ﬁeld methods, which
originated in the statistical physics literature [e.g., 12, 47, 190]. From
the perspective of this survey, the mean ﬁeld approach is based on a
speciﬁc type of approximation to the exact variational principle (3.45).
More speciﬁcally, as discussed in Section 3.7, there are two fundamental
diﬃculties associated with the variational principle (3.45): the nature
of the constraint set M, and the lack of an explicit form for the dual
∗. The core idea of mean ﬁeld approaches is simple: let us
function A
limit the optimization to a subset of distributions for which both M and
∗ are relatively easy to characterize; e.g., perhaps they correspond to
A
a graph with small treewidth. Throughout this section, we refer to any
such distribution as “tractable.” The simplest choice is the family of
product distributions, which gives rise to the naive mean ﬁeld method.
Higher-order mean ﬁeld methods are obtained by choosing tractable
distributions with more structure.

5.1 Tractable Families

Given a graphical model based on a graph G, we base our description
of mean ﬁeld methods on the notion of a tractable subgraph, by which

127

128 Mean Field Methods

we mean a subgraph F of the graph G over which it is feasible to per-
form exact calculations. The simplest example of a tractable subgraph
is the fully disconnected subgraph F0 = (V,∅), which contains all the
vertices of G but none of the edges. Any distribution that is Markov
with respect to F is then a product distribution, for which exact com-
putations are trivial.
A bit more generally, consider an exponential family with a collec-
tion φ = (φα, α ∈ I) of suﬃcient statistics associated with the cliques of
G = (V, E). Given a subgraph F , let I(F ) ⊆ I be the subset of suﬃcient
statistics associated with cliques of F . The set of all distributions that
are Markov with respect to F is a sub-family of the full φ-exponential
family; it is parameterized by the subspace of canonical parameters

Ω(F ) := {θ ∈ Ω | θα = 0 ∀ α ∈ I\I(F )}.

(5.1)

We consider some examples to illustrate:
Example 5.1 (Tractable Subgraphs). Suppose that θ ∈ Ω para-
meterizes a pairwise Markov random ﬁeld, with potential
func-
tions associated with the vertices and edges of an undirected graph
G = (V, E). For each edge (s, t) ∈ E, let θ(s,t) denote the subvector of
parameters associated with suﬃcient statistics that depend only on
(Xs, Xt). Consider the completely disconnected subgraph F0 = (V,∅).
With respect to this subgraph, permissible parameters must belong to
the subspace

(cid:14)

(cid:15)

Ω(F0) :=

θ ∈ Ω | θ(s,t) = 0 ∀ (s, t) ∈ E

.

(5.2)

The densities in this sub-family are all of the fully factorized or product
form

pθ(x) =

p(xs; θs),

(5.3)

(cid:2)

s∈V

where θs refers to the subvector of canonical parameters associated with
vertex s.

To obtain a more structured approximation, one could choose a
spanning tree T = (V, E(T )). In this case, we are free to choose the
canonical parameters corresponding to vertices and edges in the tree

5.2 Optimization and Lower Bounds

129

T , but we must set to zero any canonical parameters corresponding
to edges not in the tree. Accordingly, the subspace of tree-structured
distributions is speciﬁed by the subset of canonical parameters

(cid:15)
θ ∈ Ω | θ(s,t) = 0 ∀ (s, t) /∈ E(T )

.

(5.4)

Ω(T ) :=

(cid:14)

Associated with the exponential family deﬁned by φ and G is the
set M(G; φ) of all mean parameters realizable by any distribution, as
previously deﬁned in Equation (3.26). (Whereas our previous nota-
tion did not make explicit reference to G and φ, the deﬁnition of M
does depend on these quantities and it is now useful to make this
dependence explicit.) For a given tractable subgraph F , mean ﬁeld
methods are based on optimizing over the subset of mean parame-
ters that can be obtained by the subset of exponential family densities
{pθ, θ ∈ Ω(F )} — namely

MF (G; φ) := {µ ∈ Rd | µ = Eθ[φ(x)]

for some θ ∈ Ω(F )}.

(5.5)

In terms of the moment mapping from Theorem 3.3, a more compact
deﬁnition of the set MF (G; φ) is as the image ∇A(Ω(F )). By Theo-
rem 3.3, we have M◦(G; φ) = ∇A(Ω) so that the inclusion

M◦

F (G; φ) ⊆ M◦

(G; φ)

holds for any subgraph F . For this reason, we say that MF is an inner
approximation to the set M of realizable mean parameters.
To lighten the notation in the remainder of this section, we gener-
ally drop the φ term from M(G; φ) and MF (G; φ), writing M(G) and
MF (G), respectively. It is important to keep in mind, though, that
these sets do depend on the choice of suﬃcient statistics.

5.2 Optimization and Lower Bounds

We now have the necessary ingredients to develop the mean ﬁeld
approach to approximate inference. Suppose that we are interested in
approximating some target distribution pθ, where θ ∈ Ω. Mean ﬁeld
methods generate lower bounds on the value A(θ) of the cumulant func-
tion, as well as approximations to the mean parameters µ = Eθ[φ(X)]
of this target distribution pθ.

130 Mean Field Methods

5.2.1 Generic Mean Field Procedure

The key property of any mean ﬁeld method is the following fact: any
valid mean parameter speciﬁes a lower bound on the log partition
function.

Proposition 5.1 (Mean Field Lower Bound). Any mean parame-
ter µ ∈ M◦ yields a lower bound on the cumulant function:

A(θ) ≥ (cid:19)θ, µ(cid:20) − A

∗

(µ).

(5.6)

Moreover, equality holds if and only if θ and µ are dually coupled (i.e.,
µ = Eθ[φ(X)]).

Proof. In convex analysis, this lower bound is known as Fenchel’s
inequality. It is an immediate consequence of the general variational
principle (3.45), since the supremum over µ is always greater than
the value at any particular µ. Moreover, the supremum is attained
when µ = ∇A(θ), which means that θ and µ are dually coupled (by
deﬁnition).

An alternative proof via Jensen’s inequality is also possible, and
given its popularity in the literature on mean ﬁeld methods, we
give a version of this proof here. By deﬁnition of M, for any mean
parameter µ ∈ M, there must exist some density q, deﬁned with respect
to the base measure ν underlying the exponential family, for which
Eq[φ(X)] = µ. We then have

(cid:14)(cid:19)θ, φ(x)(cid:20)(cid:15)

exp

(cid:13)

(cid:13)

(a)≥

X m

A(θ) = log

q(x)

ν(dx)

q(x)

X m
q(x)[(cid:19)θ, φ(x)(cid:20) − log q(x)]ν(dx)

(b)= (cid:19)θ, µ(cid:20) + H(q),

(5.7)
where H(q) = −Eq[log q(X)] is the entropy of q. In this argument, step
(a) follows from Jensen’s inequality (see Appendix A.2.5) applied to
the negative logarithm, whereas step (b) follows from the moment-
matching condition Eq[φ(X)] = µ. Since the lower bound (5.7) holds

5.2 Optimization and Lower Bounds

131

for any density q satisfying this moment-matching condition, we may
optimize over the choice of q: by Theorem 3.4, doing so yields the
∗(µ)
exponential family density q
by construction.

∗(x) = pθ(µ)(x), for which H(q

∗) = −A

Since the dual function A

∗ typically lacks an explicit form, it is not
possible, at least in general, to compute the lower bound (5.6). The
mean ﬁeld approach circumvents this diﬃculty by restricting the choice
of µ to the tractable subset MF (G), for which the dual function has an
MF (G),
explicit form. For compactness in notation, we deﬁne A
corresponding to the dual function restricted to the set MF (G). As
long as µ belongs to MF (G), then the lower bound (5.6) involves A
∗
F ,
and hence can be computed easily.

∗
F = A

∗**

The next step of the mean ﬁeld method is the natural one: ﬁnd the
best approximation, as measured in terms of the tightness of the lower
bound (5.6). More precisely, the best lower bound from within MF (G)
is given by

.

(5.8)

(cid:14)(cid:19)µ, θ(cid:20) − A

(cid:15)

∗
F (µ)

max

µ∈MF (G)

The corresponding value of µ is deﬁned to be the mean ﬁeld approxi-
mation to the true mean parameters.

In Section 5.3, we illustrate the use of this generic procedure in
obtaining lower bounds and approximate mean parameters for various
types of graphical models.

5.2.2 Mean Field and Kullback–Leibler Divergence

An important alternative interpretation of the mean ﬁeld optimization
problem (5.8) is as minimizing the Kullback–Leibler (KL) divergence
between the approximating (tractable) distribution and the target dis-
tribution. In order to make this connection clear, we ﬁrst digress to dis-
cuss various forms of the KL divergence for exponential family models.
∗, as characterized in The-
orem 3.4, leads to several alternative forms of the KL divergence for
exponential family members. Given two distributions with densities q
and p with respect to a base measure ν, the standard deﬁnition of the

The conjugate duality between A and A

132 Mean Field Methods

KL divergence [57] is

D(q (cid:31) p) :=

(cid:13)

(cid:11)

X m

(cid:12)

log q(x)
p(x)

q(x) ν(dx).

(5.9)

The key result that underlies alternative representations for exponential
families is Proposition 5.1.
Consider two canonical parameter vectors θ1, θ2 ∈ Ω; with a slight
abuse of notation, we use D(θ1 (cid:31) θ2) to refer to the KL divergence
between pθ1 and pθ2. We use µ1 and µ2 to denote the respective mean
parameters (i.e., µi = E
θi[φ(X)] for i = 1,2). A ﬁrst alternative form of
the KL divergence is obtained by substituting the exponential represen-
tations of pθi into Equation (5.9), and then expanding and simplifying
as follows:

"

#

D(θ1 (cid:31) θ2) = Eθ1

log pθ1(x)
pθ2(x)

= A(θ2) − A(θ1) − (cid:19)µ1, θ2 − θ1(cid:20).

(5.10)

We refer to this representation as the primal form of the KL divergence.
As illustrated in Figure 5.1, this form of the KL divergence can be
interpreted as the diﬀerence between A(θ2) and the hyperplane tangent
to A at θ1 with normal ∇A(θ1) = µ1. This interpretation shows that the
KL divergence is a particular example of a Bregman distance [42, 45].
A second form of the KL divergence can be obtained by using the
fact that equality holds in Proposition 5.1 for dually coupled param-
eters. In particular, given a pair (θ1, µ1) for which µ1 = Eθ1[φ(X)],

Fig. 5.1 The hyperplane A(θ
Kullback–Leibler divergence D(θ
tangent approximation.

1) + (cid:8)∇A(θ

1 (cid:19) θ

1), θ − θ

1(cid:9) supports the epigraph of A at θ

2) is equal to the diﬀerence between A(θ

1. The
2) and this

5.2 Optimization and Lower Bounds

133

we can transform Equation (5.10) into the following mixed form of
the KL divergence:

D(θ1 (cid:31) θ2) ≡ D(µ1 (cid:31) θ2) = A(θ2) + A

∗

(µ1) − (cid:19)µ1, θ2(cid:20).

(5.11)

Note that this mixed form of the divergence corresponds to the slack
in the inequality (5.6). It also provides an alternative view of the vari-
ational representation given in Theorem 3.4(b). In particular, Equa-
tion (3.45) can be rewritten as follows:

(µ) − (cid:19)θ, µ(cid:20)(cid:15)

= 0.

(cid:14)

A(θ) + A

∗

min
µ∈M

Using Equation (5.11), the variational representation in Theorem 3.4(b)
is seen to be equivalent to the assertion that minµ∈M D(µ (cid:31) θ) = 0.

Finally, by applying Equation (5.6) as an equality once again, this
time for the coupled pair (θ2, µ2), the mixed form (5.11) can be trans-
formed into a purely dual form of the KL divergence:

D(θ1 (cid:31) θ2) ≡ D(µ1 (cid:31) µ2)
(µ1) − A

∗
= A

∗

(µ2) − (cid:19)θ2, µ1 − µ2(cid:20).

(5.12)

Note the symmetry between representations (5.10) and (5.12). This
form of the KL divergence has an interpretation analogous to that of
∗.
Figure 5.1, but with A replaced by the dual A

With this background on the Kullback-Leibler divergence, let us
now return to the consequences for mean ﬁeld methods. For a given
mean parameter µ ∈ MF (G), the diﬀerence between the log partition
function A(θ) and the quantity (cid:19)µ, θ(cid:20) − A
∗
F (µ) to be maximized is
equivalent to

D(µ (cid:31) θ) = A(θ) + A

F (µ) − (cid:19)µ, θ(cid:20),
∗

corresponding to the mixed form of the KL divergence deﬁned in Equa-
tion (5.11). On the basis of this relation, it can be seen that solving the
variational problem (5.8) is equivalent to minimizing the KL divergence
D(µ (cid:31) θ), subject to the constraint that µ ∈ MF (G). Consequently, any
mean ﬁeld method can be understood as obtaining the “best” approx-
imation to pθ from a family of tractable models, where approximation
quality is measured by the KL divergence.

134 Mean Field Methods

5.3 Naive Mean Field Algorithms

In this section, we illustrate various instances of mean ﬁeld algorithms
for particular graphical models. Our examples in this section focus on
the simplest type of approximation, referred to as the naive mean ﬁeld
approach. It is based on choosing a product distribution

pθ(x1, x2, . . . , xm) :=

p(xs; θs)

(5.13)

(cid:2)

s∈V

as the tractable approximation. The naive mean ﬁeld updates are a
particular set of recursions for ﬁnding a stationary point of the resulting
optimization problem. In the case of the Ising model, the naive mean
ﬁeld updates are a classical set of recursions from statistical physics,
typically justiﬁed in a heuristic manner in terms of “self-consistency”.
For the case of a Gaussian Markov random ﬁeld, the naive mean ﬁeld
updates turn out to be equivalent to the Gauss–Jacobi or Gauss–Seidel
algorithm for solving a linear system of equations.

Example 5.2 (Naive Mean Field for Ising Model). As an illus-
tration, we derive the naive mean ﬁeld updates for the Ising model, ﬁrst
introduced in Example 3.1. Recall that the Ising model is character-
ized by the suﬃcient statistics (xs, s ∈ V ) and (xsxt, (s, t) ∈ E). The
associated mean parameters are the singleton and pairwise marginal
probabilities

µs = E[Xs] = P[Xs = 1], and µst = E[XsXt] = P[Xs = 1, Xt = 1],

respectively. The full vector µ of mean parameters is an element of
R|V |+|E|.
Letting F0 denote the fully disconnected graph — that is, without
any edges — the tractable set MF0(G) consists of all mean parameter
vectors µ ∈ R|V |+|E| that arise from the product distribution (5.13).
Explicitly, in this binary case, we have

MF0(G) := {µ ∈ R|V |+|E| | 0 ≤ µs ≤ 1 ∀ s ∈ V,

and
µst = µs µt ∀ (s, t) ∈ E.},

(5.14)

where the constraints µst = µsµt arise from the product nature of any
distribution that is Markov with respect to F0.

5.3 Naive Mean Field Algorithms

135
For any µ ∈ MF0(G), the value of the dual function — that is,
the negative entropy of a product distribution — has an explicit form
in terms of (µs, s ∈ V ). In particular, a straightforward computation
shows that this entropy takes the form:

(cid:11)
(cid:12)
µs log µs + (1 − µs)log(1 − µs)

(cid:6)
F0(µ) = −
−A
∗
(cid:6)

s∈V

(5.15)

=

Hs(µs).

s∈V

With these two ingredients, we can derive the speciﬁc form of the
mean ﬁeld optimization problem (5.8) for the product distribution and
the Ising model. Given the product structure of the tractable family,
any mean parameter µ ∈ MF0(G) satisﬁes the equality µst = µsµt for
all (s, t) ∈ E. Combining the expression for the entropy in (5.15) with
the characterization of MF0(G) in (5.14) yields the naive mean ﬁeld
problem
A(θ) ≥

(cid:4)(cid:6)

(cid:6)

(cid:6)

(cid:22)

θstµsµt +

Hs(µs)

.

θsµs +

max

(µ1,...,µm)∈[0,1]m

(5.16)
For any s ∈ V , this objective function is strictly concave as a scalar
function of µs with all other coordinates held ﬁxed. Moreover, the max-
imum over µs with the other variables µt, t (cid:12)= s held ﬁxed is attained in
the open interval (0,1). Indeed, by taking the derivative with respect
to µ, setting it to zero and performing some algebra, we obtain the
update

s∈V

(s,t)∈E

s∈V

(

(cid:6)

)

µs ← σ

θs +

θstµt

,

t∈N(s)

(5.17)

where σ(z) := [1 + exp(−z)]−1 is the logistic function. Thus, we have
derived — from a variational perspective — the naive mean ﬁeld
updates presented earlier (2.15).

What about convergence properties and the nature of the ﬁxed
points? Applying Equation (5.17) iteratively to each node in succession
amounts to performing coordinate ascent of the mean ﬁeld variational

136 Mean Field Methods

problem (5.16). Since the maximum is uniquely attained for every
coordinate update, known results on coordinate ascent methods [21]
imply that any sequence {µ0, µ1, . . .} generated by the updates (5.17)
is guaranteed to converge to a local optimum of the naive mean ﬁeld
problem (5.16).

Unfortunately, the mean ﬁeld problem is nonconvex in general, so
that there may be multiple local optima, and the limit point of the
sequence {µ0, µ1, . . .} can depend strongly on the initialization µ0. We
discuss this nonconvexity and its consequences at greater depth in
Section 5.4. Despite these issues, the naive mean ﬁeld approximation
becomes asymptotically exact for certain types of models as the
number of nodes m grows to inﬁnity [12, 267]. An example is the
ferromagnetic Ising model deﬁned on the complete graph Km with
suitably rescaled parameters θst > 0 for all (s, t) ∈ E; see Baxter [12]
for further discussion of such exact cases.

Similarly, it is straightforward to apply the naive mean ﬁeld approx-
imation to other types of graphical models, as we illustrate for a mul-
tivariate Gaussian.

Example 5.3(Gaussian Mean Field). Recall the Gaussian Markov
random ﬁeld, ﬁrst discussed as an exponential family in Example 3.3.
Its mean parameters consist of the vector µ = E[X] ∈ Rm, and the
symmetric1 matrix Σ = E[XX T ] ∈ S m
+ . Suppose that we again use the
completely disconnected graph F0 = (V,∅) as the tractable class. Any
Gaussian distribution that is Markov with respect to F0 must have a
diagonal covariance matrix, meaning that the set of tractable mean
(cid:15)
parameters takes the form:
MF0(G) =

+ | Σ − µµT = diag(Σ − µµT ) (cid:25) 0

(µ,Σ) ∈ Rm × S m

(cid:14)

1 Strictly speaking, only elements [Σ]st with (s, t) ∈ E are included in the mean
parameterization, since the associated canonical parameter is zero for any pair (u, v) /∈ E.

.

(5.18)

5.3 Naive Mean Field Algorithms

137

For any such product distribution, the entropy (negative dual function)
has the form:
−A
∗
F0(µ,Σ) = m
2
= m
2

(cid:11)
Σ − µµT

log(Σss − µ2
s).

m(cid:6)

log 2πe +

log 2πe +

log det

1
2
1
2

(cid:12)

s=1

Combining this form of the dual function with the constraints (5.18)
yields that for a multivariate Gaussian, the value A(θ) of the cumulant
function is lower bounded by

(cid:7)

(cid:8)

m(cid:6)

s=1

, (5.19)

1
2

1
2

max
(µ,Σ)

log 2πe

s) + m
2

(cid:19)(cid:19)Θ, Σ(cid:20)(cid:20) +

(Σss − µ2

s > 0, Σst = µsµt,

(cid:19)θ, µ(cid:20) +
such that Σss − µ2
where (θ,Θ) ∈ Ω are the canonical parameters associated with the mul-
tivariate Gaussian (see Example 3.3). The optimization problem (5.19)
yields the naive mean ﬁeld lower bound for the multivariate Gaussian.
This optimization problem can be further simpliﬁed by substituting
the constraints Σst = µsµt directly into the term (cid:19)(cid:19)Θ, Σ(cid:20)(cid:20) =
s,t ΘstΣst
that appears in the objective function. Doing so and then taking deriva-
tives with respect to the remaining optimization variables (namely, µs
(cid:6)
and µss) yields the stationary condition

(cid:10)

2(µss − µ2
s)
which must be satisﬁed for every vertex s ∈ V . One particular set of
updates for solving these ﬁxed point equations is the iteration

Θstµt, (5.20)

= θs +

t∈N(s)

= −Θss,

and

1

(cid:22)

µs ← − 1
Θss

θs +

Θstµt

.

(5.21)

µs

2(µss − µ2
s)
(cid:4)
(cid:6)

t∈N(s)

Are these updates convergent, and what is the nature of the ﬁxed
points? Interestingly, the updates (5.21) are equivalent, depending on
the particular ordering used, to either the Gauss–Jacobi or the Gauss–
Seidel methods [67] for solving the normal equations µ = −Θ−1θ.

138 Mean Field Methods

Therefore, if the Gaussian mean ﬁeld updates (5.21) converge, they
compute the correct mean vector. Moreover, the convergence behavior
of such updates is well understood: for instance, the updates (5.21)
are guaranteed to converge whenever −Θ is strictly diagonally dom-
inant; see Demmel [67] for further details on such Gauss–Jacobi and
Gauss–Seidel iterations for solving matrix-vector equations.

5.4 Nonconvexity of Mean Field

An important fact about the mean ﬁeld approach is that the variational
problem (5.25) may be nonconvex, so that there may be local minima,
and the mean ﬁeld updates can have multiple solutions. The source of
this nonconvexity can be understood in diﬀerent ways, depending on
the formulation of the problem. As an illustration, let us return again
to naive mean ﬁeld for the Ising model.

Example 5.4. (Nonconvexity for Naive Mean Field) We now
consider an example, drawn from Jaakkola [120], that illustrates
the nonconvexity of naive mean ﬁeld for a simple model. Con-
sider a pair (X1, X2) of binary variates, taking values in the space2
{−1,+1}2, thereby deﬁning a 3D exponential
family of the form
pθ(x) ∝ exp(θ1x1 + θ2x2 + θ12x1x2), with associated mean parameters
µi = E[Xi] and µ12 = E[X1X2]. If the constraint µ12 = µ1µ2 is imposed
directly, as in the formulation (5.16), then the naive mean ﬁeld objec-
tive function for this very special model takes the form:

f(µ1, µ2; θ) = θ12µ1µ2 + θ1µ1 + θ2µ2 + H(µ1) + H(µ2),

where H(µi) = − 1
the singleton entropies for the {−1,+1}-spin representation.

2(1 + µi) − 1

2(1 + µi)log 1

(5.22)
2(1 − µi) are

Now, let us consider a subfamily of such models, given by canonical

parameters of the form:

(

2(1 − µi)log 1
)

=: θ(q),

(θ1, θ2, θ12) =

0, 0,

1
4

log

q
1 − q

2 This model, known as a “spin” representation, is a simple transformation of the {0,1}2
state space considered earlier.

5.4 Nonconvexity of Mean Field

139

Fig. 5.2 Two diﬀerent perspectives on the nonconvexity of naive mean ﬁeld for the Ising
model. (a) Illustration of the naive mean ﬁeld objective function (5.22) for three diﬀerent
parameter values: q ∈ {0.50,0.04,0.01}. For q = 0.50 and q = 0.04, the global maximum is
achieved at (µ1, µ2) = (0,0), whereas for q = 0.01, the point (0,0) is no longer a global
maximum. Instead the global maximum is achieved at two nonsymmetric points, (+µ,−µ)
and (−µ,+µ). (b) Nonconvexity can also be seen by examining the shape of the set of fully
factorized marginals for a pair of binary variables. The gray area shows the polytope deﬁned
by the inequality (5.23), corresponding to the intersection of M(G) with the hyperplane
2
1 corresponds to the intersection of this
µ1 = µ2. The nonconvex quadratic set µ12 = µ
projected polytope with the set MF0 (G) of fully factorized marginals.

where q ∈ (0,1) is a parameter. By construction, this model
is
symmetric in X1 and X2, so that for any value of q ∈ (0,1),
we have E[X1] = E[X2] = 0. Moreover, some calculation shows that
q = P[X1 = X2].

For q = 0.50, the objective function f(µ1, µ2; θ(0.50)) achieves its
global maximum at (µ1, µ2) = (0,0), so that the mean ﬁeld approxima-
tion is exact. (This exactness is to be expected since θ(0.50) = (0,0,0),
corresponding to a completely decoupled model.) As q decreases away
from 0.50, the objective function f starts to change, until for suitably
small q, the point (µ1, µ2) = (0,0) is no longer the global maximum —
in fact, it is not even a local maximum.
To illustrate this behavior explicitly, we consider the cross-section of
f obtained by setting µ1 = τ and µ2 = −τ, and then plot the 1D func-
tion f(τ,−τ; θ(q)) for diﬀerent values of q. As shown in Figure 5.2(a),
for q = 0.50, this 1D objective function has a unique global maximum at
τ = 0. As q decreases away from 0.50, the objective function gradually
ﬂattens out, as shown in the change between q = 0.50 and q = 0.04.
For q suﬃciently close to zero, the point τ = 0 is no longer a global

140 Mean Field Methods

maximum; instead, as shown in the curve for q = 0.01, the global max-
imum is achieved at the two points ±τ
∗ on either side of τ = 0. Thus,
for suﬃciently small q, the maximum of the objective function (5.22)
1 (cid:12)= µ
∗
∗
2, even though the original model is always sym-
occurs at a pair µ
metric. This phenomenon, known in the physics literature as “sponta-
neous symmetry-breaking”, is a manifestation of nonconvexity, since
the optimum of any convex function will always respect symmetries in
the underlying problem. Symmetry-breaking is not limited to this toy
example, but also occurs with mean ﬁeld methods applied to larger and
more realistic graphical models, for which there may be a large number
of competing modes in the objective function.

Alternatively, nonconvexity in naive mean ﬁeld can be understood
in terms of the shape of the constraint set as an inner approximation to
M. For a pair of binary variates {X1, X2} ∈ {−1,1}2, the set M is eas-
ily characterized: the mean parameters µi = E[Xi] and µ12 = E[X1X2]
are completely characterized by the four inequalities 1 + abµ12 + aµ1 +
bµ2 ≥ 0, where {a, b} ∈ {−1,1}2. So as to facilitate visualization, con-
sider a particular projection of this polytope — namely, that corre-
sponding to intersection with the hyperplane µ1 = µ2. In this case, the
four inequalities reduce to three simpler ones — namely:
µ12 ≤ 1, µ12 ≥ 2µ1 − 1, µ12 ≥ −2µ1 − 1.

(5.23)

Figure 5.2(b) shows the resulting 2D polytope, shaded in gray. Now
consider the intersection between this projected polytope and the set of
factorized marginals MF0(G). The factorization condition imposes an
additional constraint µ12 = µ2
1, yielding a quadratic curve lying within
the 2D polytope described by the Equations (5.23), as illustrated in
Figure 5.2(b). Since this quadratic set is not convex, this establishes
that MF0(G) is not convex either. Indeed, if it were convex, then its
intersection with any hyperplane would also be convex.

The geometric perspective on the set M(G) and its inner approxi-
mation MF (G) reveals that more generally, mean ﬁeld optimization is
always nonconvex for any exponential family in which the state space
X m is ﬁnite. Indeed, for any such exponential family, the set M(G) is

5.4 Nonconvexity of Mean Field

141

Fig. 5.3 Cartoon illustration of the set MF (G) of mean parameters that arise from tractable
distributions is a nonconvex inner bound on M(G). Illustrated here is the case of discrete
random variables where M(G) is a polytope. The circles correspond to mean parameters
that arise from delta distributions, and belong to both M(G) and MF (G).

a ﬁnite convex hull 3

M(G) = conv{φ(e), e ∈ X m}

(5.24)

in d-dimensional space, with extreme points of the form µe := φ(e) for
some e ∈ X m. Figure 5.3 provides a highly idealized illustration of this
polytope, and its relation to the mean ﬁeld inner bound MF (G).
We now claim that MF (G) — assuming that it is a strict subset
of M(G) — must be a nonconvex set. To establish this claim, we ﬁrst
observe that MF (G) contains all of the extreme points µx = φ(x) of
the polytope M(G). Indeed, the extreme point µx is realized by the
distribution that places all its mass on x, and such a distribution is
Markov with respect to any graph. Therefore, if MF (G) were a con-
vex set, then it would have to contain any convex combination of such
extreme points. But from the representation (5.24), taking convex com-
binations of all such extreme points generates the full polytope M(G).
Therefore, whenever MF (G) is a proper subset of M(G), it cannot be
a convex set.

Consequently, nonconvexity is an intrinsic property of mean ﬁeld
approximations. As suggested by Example 5.4, this nonconvexity

3 For instance, in the discrete case when the suﬃcient statistics φ are deﬁned by indicator
functions in the standard overcomplete basis (3.34), we referred to M(G) as a marginal
polytope.

142 Mean Field Methods

can have signiﬁcant operational consequences, including symmetry-
breaking, multiple local optima, and sensitivity to initialization.
Nonetheless, mean-ﬁeld methods have been used successfully in a vari-
ety of applications, and the lower bounding property of mean ﬁeld
methods is attractive, for instance in the context of parameter estima-
tion, as we discuss at more length in Section 6.

5.5 Structured Mean Field

Of course, the essential principles underlying the mean ﬁeld approach
are not limited to fully factorized distributions. More generally, we can
consider classes of tractable distributions that incorporate additional
structure. This structured mean ﬁeld approach was ﬁrst proposed by
Saul and Jordan [209], and further developed by various researchers
[10, 259, 120].

Here, we capture the structured mean ﬁeld idea by discussing a gen-
eral form of the updates for an approximation based on an arbitrary
subgraph F of the original graph G. We do not claim that these speciﬁc
updates are the best for practical purposes; the main goal here is the
conceptual one of understanding the structure of the solution. Depend-
ing on the particular context, various techniques from nonlinear pro-
gramming might be suitable for solving the mean ﬁeld problem (5.8).
Let I(F ) be the subset of indices corresponding to suﬃcient statis-
tics associated with F , and let µ(F ) := (µα, α ∈ I(F )) be the associ-
ated subvector of mean parameters. We use M(F ) to denote the set of
realizable mean parameters deﬁned by the subgraph F and by the sub-
set of suﬃcient statistics picked out by I(F ); it is a subset of R|I(F )|. It
is important to note that M(F ) diﬀers from the previously deﬁned (5.5)
set MF (G), which is based on the entire set of suﬃcient statistics φ,
and so is a subset of R|I|.

We then observe that the mean ﬁeld problem (5.8) has the following

key properties:

(a) The subvector µ(F ) can be an arbitrary member of M(F ).
∗
F actually depends only on µ(F ), and
(b) The dual function A
not on mean parameters µβ for indices β in the complement
I c(F ) := I(G)\I(F ).

5.5 Structured Mean Field

143
Of course, the mean parameters µβ for indices β ∈ Ic(F ) do play a
role in the problem; in particular, they arise within the linear term
(cid:19)µ, θ(cid:20). Moreover, each mean parameter µβ is constrained in a non-
linear way by the choice of µ(F ). Accordingly, for each β ∈ Ic(F ), we
write µβ = gβ(µ(F )) for some nonlinear function gβ, of which particular
examples are given below. Based on these observations, the optimiza-
tion problem (5.8) can be rewritten in the form:

max

µ∈MF (G)

(cid:15)

(cid:14)(cid:19)θ, µ(cid:20) − A
(cid:7) (cid:6)
(cid:17)

α∈I(F )

∗
F (µ)

= max

µ(F )∈M(F )

θαµα +

(cid:6)

α∈Ic(F )

(cid:18)(cid:19)
θαgα(µ(F )) − A

∗
F (µ(F ))

(cid:20)

(cid:8)

.

f(µ(F ))

(5.25)

On the left-hand side, the optimization takes place over the vec-
tor µ ∈ MF (G), which is of the same dimension as θ ∈ Ω ⊆ R|I|.
The objective function f for the optimization on the right-hand
side, in contrast, is a function only of the lower-dimensional vector
µ(F ) ∈ M(F ) ⊆ R|I(F )|.
To illustrate this transformation, consider the case of naive mean
ﬁeld for the Ising model, where F ≡ F0 is the completely disconnected
graph. In this case, each edge (s, t) ∈ E corresponds to an index in the
set I c(F0); moreover, for any such edge, we have gst(µ(F0)) = µsµt.
Since F0 is the completely disconnected graph, M(F0) is simply the
hypercube [0,1]m. Therefore, for this particular example, the right-
hand side of Equation (5.25) is equivalent to Equation (5.16).
respect to some µβ with β ∈ I(F ) yields:
∂gα
∂µβ

Taking the partial derivatives of the objective function f with

∗
(µ(F )) − ∂A
F
∂µβ

(µ(F )) = θβ +

(cid:6)

∂f
∂µβ

(µ(F )).

θα

α∈I(G)\I(F )

(5.26)

Setting these partial derivatives to zero and rearranging yields the ﬁxed
point condition
∇A

θα∇gα(µ(F )).

∗
F (µ(F )) = θ +

(cid:6)

α∈I(G)\I(F )

144 Mean Field Methods

To obtain a more intuitive form of this ﬁxed point equation, recall from
Proposition 3.1 that the gradient ∇A deﬁnes the forward mapping,
from canonical parameters θ to mean parameters µ. Similarly, as we
have shown in Section 3.6, the gradient ∇A
∗ deﬁnes the backward map-
ping from mean parameters to canonical parameters. Let γ(F ) denote
the canonical parameters that are dually coupled with µ(F ), we can
rewrite the ﬁxed point update for component β as

(cid:6)

γβ(F ) ← θβ +

θα

∂gα
∂µβ

(µ(F )).

(5.27)

α∈I(G)\I(F )

After any such update, it is then necessary to adjust all mean param-
eters µδ(F ) that depend on γβ(F ) — for instance, via junction tree
updates — so that global consistency is maintained for the tractable
approximation.
∗
Alternatively, letting AF be the conjugate dual of the function A
previously deﬁned, we have ∇AF (γ(F )) = µ(F ). This fact follows from
F
∗
F ) (see Appendix B.3 for back-
the Legendre duality between (AF , A
ground), and the usual cumulant properties summarized in Proposi-
tion 3.1. By exploiting this relation, we obtain an alternative form of
the update (5.27), one which involves only the mean parameters µ(F ):

+

(cid:6)

,
θα∇gα(µ(F ))

.

µβ(F ) ← ∂AF
∂γβ

θ +

α∈I(G)\I(F )

(5.28)

We illustrate the updates (5.27) and (5.28) with some examples.

Example 5.5 (Re-derivation of Naive MF Updates). We
ﬁrst check that Equation (5.28) reduces to the naive mean ﬁeld
updates (5.17), when F = F0 is the completely disconnected graph.
For any product distribution on the Ising model, the subset of relevant
mean parameters is given by µ(F0) = (µ1, . . . , µm). By the properties of
the product distribution, we have gst(µ(F0)) = µsµt for all edges (s, t),
so that

µt

µs
0

∂gst
∂µα

=

if α = s
if α = t
otherwise.

145
Thus, for a given node index s ∈ V , the right-hand side of (5.27) is
given by the sum

5.5 Structured Mean Field

(cid:6)

θs +

θstµt.

t∈N(s)

(5.29)

F0(µ(F0) = −(cid:10)

Next, we observe that for a fully disconnected graph, the func-
∗
tion A
F0 corresponds to a sum of negative entropies — that is,
∗
s∈V H(µs) — and so is a separable function. Con-
A
sequently, the cumulant function AF0 is also separable, and of the
form AF0(γ(F0)) =
s∈V log(1 + exp(γs)). The partial derivatives are
given by

(cid:10)

∂AF0
∂γβ

(γ(F0)) =

exp(γβ)

1 + exp(γβ) ,

(5.30)

which is the logistic function. Combining the expression (5.29) with
the logistic function form (5.30) of the partial derivative shows that
Equation (5.28), when specialized to product distributions and the Ising
model, reduces to the naive mean ﬁeld update (5.17).

Example 5.6(Structured MF for Factorial HMMs). To provide
a more interesting example of the updates (5.27), consider a factorial
hidden Markov model, as described in Ghahramani and Jordan [92].
Figure 5.4(a) shows the original model, which consists of a set of M
Markov chains (M = 3 in this diagram), which share a common obser-
vation at each time step (shaded nodes). Although the separate chains
are independent a priori, the common observation induces an eﬀective
coupling among the observations. (Note that the observation nodes are
linked by the moralization process that converts the directed graph into
an undirected representation.) Thus, an equivalent model is shown in
panel (b), where the dotted ellipses represent the induced coupling of
each observation. A natural choice of approximating distribution in this
case is based on the subgraph F consisting of the decoupled set of M
chains, as illustrated in panel (c).

Now consider the nature of the quantities gβ(µ(F )), which arise in
the cost function (5.25). In this case, any function gβ will be deﬁned

146 Mean Field Methods

Fig. 5.4 Structured mean ﬁeld approximation for a factorial HMM. (a) Original model
consists of a set of hidden Markov models (deﬁned on chains), coupled at each time by
a common observation. (b) An equivalent model, where the ellipses represent interactions
among all nodes at a ﬁxed time, induced by the common observation. (c) Approximating
distribution formed by a product of chain-structured models. Here µα and µδ are the sets
of mean parameters associated with the indicated vertex and edge, respectively.

on some subset of M nodes that are coupled at a given time slice (e.g.,
see ellipse in panel (c)). Note that this subset of nodes is independent
with respect to the approximating distribution. Therefore, the function
gβ(µ(F )) will decouple into a product of terms of the form fi({µi(F )}),
where each fi is some function of the mean parameters {µi} ≡ {µi(F )}
associated with node i = 1, . . . , M in the relevant cluster. For instance, if
the factorial HMM involved binary variables and M = 3 and β = (stu),
then gstu(µ) = µsµtµu.

The decoupled nature of the approximation yields valuable savings
on the computational side. In particular, the junction tree updates nec-
essary to maintain consistency of the approximation can be performed
by applying the forward–backward algorithm (i.e., the sum-product
updates as an exact method) to each chain separately. This decoupling
also has important consequences for the structure of any mean ﬁeld
ﬁxed point. In particular, it can be seen that no term gβ(µ(F )) will

5.5 Structured Mean Field

147

ever depend on mean parameters associated with edges within any of
the chains (e.g., µδ in panel (c)). Otherwise stated, the partial derivative
is equal to 0 for all β ∈ I(G)\I(F ). As an immediate consequence
∂gβ
∂µδ
of these derivatives vanishing, the mean ﬁeld canonical parameter γδ(F )
remains equal to θδ for all iterations of the updates (5.27). Any interme-
diate junction tree steps to maintain consistency will not aﬀect γδ(F )
either. We conclude that it is, in fact, optimal to simply copy the edge
potentials θδ from the original distribution onto each of the edges in the
structured mean ﬁeld approximation. In this particular form of struc-
tured mean ﬁeld, only the single node potentials will be altered from
their original setting. This conclusion is sensible, since the structured
approximation (c) is a factorized approximation on a set of M chains,
the internal structure of which is fully preserved in the approximation.

In addition to structured mean ﬁeld, there are various other exten-
sions to naive mean ﬁeld, which we mention only in passing here.
Jaakkola and Jordan [121] explored the use of mixture distributions
in improving the mean ﬁeld approximation. A large class of tech-
niques, including linear response theory and the TAP method [e.g.,
127, 155, 182, 195, 255, 267], seek to improve the mean ﬁeld approx-
imation by introducing higher-order correction terms. Typically, the
lower bound on the log partition function is not preserved by these
higher-order methods. Leisinck and Kappen [156] proposed a class of
higher-order expansions that generate tighter lower bounds.

6

Variational Methods in Parameter Estimation

Our focus in the previous sections has been on the problems of com-
puting or approximating the cumulant function value A(θ) and the
mean parameters µ = Eθ[φ(X)], assuming that the canonical param-
eter θ specifying the density pθ was known. In this section, we turn
to the inverse problem of estimating θ on the basis of observed data.
We consider both the frequentist setting, in which the parameter θ
is assumed to be ﬁxed but unknown (Sections 6.1 and 6.2), and the
Bayesian setting, in which the parameter θ is viewed as a random vari-
able (Section 6.3).

6.1 Estimation in Fully Observed Models

The simplest case of parameter estimation corresponds to the case of
1 := {X1, . . . , X n} of n independent
fully observed data: a collection X n
and identically distributed (i.i.d.) m-vectors, each sampled according to
pθ. Suppose that our goal to estimate the unknown parameter θ, which
we view as a deterministic but nonrandom quantity for the moment.
A classical approach to this estimation problem, dating back to Fisher,
is via the principle of maximum likelihood: estimate θ by maximizing

148

6.1 Estimation in Fully Observed Models

149

1 ) := 1

n
i=1 log pθ(X i).
the log likelihood of the data, given by (cid:10)(θ; X n
It is convenient and has no eﬀect on the maximization to rescale the
log likelihood by 1/n, as we have done here.

parameters (cid:3)µ :=(cid:3)E[φ(X)] = 1

For exponential families, the rescaled log likelihood takes a particu-
larly simple and intuitive form. In particular, we deﬁne empirical mean
n
i=1 φ(X i) associated with the sample
1 . In terms of these quantities, the log likelihood for an exponential

X n
family can be written as

n

(cid:10)
1 ) = (cid:19)θ,(cid:3)µ(cid:20) − A(θ).

(cid:10)

n

(cid:10)(θ; X n

(6.1)

This expression highlights the close connection to maximum entropy
and conjugate duality, as discussed in Section 3.6. The maximum like-

lihood estimate is the vector(cid:3)θ ∈ Rd maximizing this (random) objective
function (6.1). As a corollary of Theorem 3.4, whenever(cid:3)µ ∈ M◦, there
ditions E(cid:3)θ[φ(X)] =(cid:3)µ. Moreover, by standard results on asymptotics of
M-estimators [30, 233], the MLE (cid:3)θ in regular exponential families is

exists a unique maximum likelihood solution. Indeed, by taking deriva-
tives with respect to θ of the objective function (6.1), the maximum
likelihood estimate (MLE) is speciﬁed by the moment matching con-

consistent, in that it converges in probability to θ as the sample size n
tends to inﬁnity.

6.1.1 Maximum Likelihood for Triangulated Graphs

Our discussion up to this point has ignored the computational issue

of solving the moment matching equation so as to obtain the MLE (cid:3)θ.
a closed-form function of the empirical marginals(cid:3)µ, which we describe

As with other statistical computations in exponential families, the dif-
ﬁcultly of solving this problem turns out to depend strongly on the
graph structure. For triangulated1 graphs, the MLE can be written as

here.

To illustrate the basic idea with a minimum of notational overhead,
let us consider the simplest instance of a triangulated graph: namely,
a tree T = (V, E), with discrete random variables Xs taking values in

1 See Section 2.5.2 for further discussion of triangulated graphs.

150 Variational Methods in Parameter Estimation
Xs := {0,1, . . . , rs − 1}. As previously discussed in Section 4, this collec-
tion of distributions can be represented as an exponential family (4.1),
using indicator functions I s;j[xs] for the event {Xs = j} and I st;jk[xs, xt]
for the event {Xs = j, Xt = k}. Moreover, the mean parameters in this
exponential family are marginal probabilities — explicitly,

µs;j = Pθ[Xs = j]

for all s ∈ V , j ∈ Xs, and

µst;jk = Pθ[Xs = j, Xt = k]

for all (s, t) ∈ E and (j, k) ∈ Xs × Xt.
1 := {X1, . . . , X n}, the empirical mean param-
Given an i.i.d. sample X n
and (cid:3)µst;jk =
eters correspond to the singleton and pairwise marginal probabilities

(cid:3)µs;j =

n(cid:6)

n(cid:6)

I st;jk[X i

(6.2)

I s;j[X i
s]

t],
s, X i

1
n

i=1

1
n

i=1

induced by the data.

With this set-up, we can exhibit the closed-form expression for the
MLE in terms of the empirical marginals. For this particular expo-

nential family, our assumption that (cid:3)µ ∈ M◦ means that the empiri-
cal marginals are all strictly positive. Consequently, the vector (cid:3)θ with
elements(cid:3)θs;j := log(cid:3)µs;j ∀ s ∈ V,
(cid:3)θst;jk := log
We claim that the vector (cid:3)θ is the maximum likelihood estimate for
moment matching conditions E(cid:3)θ[φ(X)] =(cid:3)µ hold for the distribution p(cid:3)θ.

the problem. In order to establish this claim, it suﬃces to show that the

∀ (s, t) ∈ E, (j, k) ∈ Xs × Xt

(cid:3)µst;jk
(cid:3)µs;j(cid:3)µt;k

is well deﬁned.

From the deﬁnition (6.3), this exponential family member has the form

j ∈ Xs

(6.3b)

(6.3a)

and

(cid:4)(cid:6)
(cid:3)µ(xs)

s∈V

(cid:22)
(cid:6)
(cid:3)θst(xs, xt)
(cid:3)µst(xs, xt)
(cid:3)µs(xs)(cid:3)µt(xt) ,

(s,t)∈E

(cid:3)θs(xs) +
(cid:2)

(s,t)∈E

p(cid:3)θ(x) = exp

(cid:2)

s∈V

=

A((cid:3)θ) = 0 in this parameterization. Moreover, the distribution p(cid:3)θ has

where we have used the fact (veriﬁable by some calculation) that

(6.4)

as its marginal distributions the empirical quantities (cid:3)µs and (cid:3)µst. This

6.1 Estimation in Fully Observed Models

151

claim follows as a consequence of the junction tree framework (see
Proposition 2.1); alternatively, they can be proved directly by an
inductive “leaf-stripping” argument, based on a directed version of the
factorization (6.4). Consequently, the MLE has an explicit closed-form
solution in terms of the empirical marginals for a tree. The same closed-
form property holds more generally for any triangulated graph.

6.1.2

Iterative Methods for Computing MLEs

For nontriangulated graphical models, there is no longer a closed-form
solution to the MLE problem, and iterative algorithms are needed. As
an illustration, here we describe the iterative proportional ﬁtting (IPF)
algorithm [61, 59], a type of coordinate ascent method with particularly
intuitive updates. To describe it, let us consider a generalization of the
suﬃcient statistics {I s;j(xs)} and {I st;jk(xs, xt)} used for trees, in which
we deﬁne similar indicator functions over cliques of higher order. More
speciﬁcally, for any clique C of size k in a given graph G, let us deﬁne
a set of clique indicator functions

k(cid:2)

I J(xC) =

I s;js[xs],

s=1

one for each conﬁguration J = (j1, . . . , jk) over xC. Each such suﬃ-
cient statistic is associated with a canonical parameter θC;J. As before,
the associated mean parameters µC;J = E[I C;J(XC)] = Pθ[XC = J] are
simply marginal probabilities, but now deﬁned over cliques. Simi-

larly, the data deﬁnes a set (cid:3)µC;J =(cid:3)P[XC = J] of empirical marginal

probabilities.

Since the MLE problem is diﬀerentiable and jointly concave in the
vector θ, coordinate ascent algorithms are guaranteed to converge to
the global optimum. Using the cumulant generating properties of A
(see Proposition 3.1), we can take derivatives with respect to some
coordinate θC;J, thereby obtaining

= (cid:3)µC;J − ∂A

(θ) = (cid:3)µC;J − µC;J ,

∂θC;J

∂(cid:10)

∂θC;J

(6.5)

152 Variational Methods in Parameter Estimation

Iterative Proportional Fitting: At iterations t = 0,1,2, . . .

(i) Choose a clique C = C(t) and compute the local marg-
θ(t)[XC = J] ∀ J ∈ X |C|.

inal distribution µ

(t)
C;J := P

(ii) Update the canonical parameter vector

θ(t+1)
α

=

(cid:3)µC;J

(t)
C;J

µ

(t)
C;J + log
(t)
α

if α = (C; J) for some J ∈ X |C|.

otherwise.

θ

θ

Fig. 6.1 Steps in the iterative proportional ﬁtting (IPF) procedure.

where µC;J = Eθ[I C;J(XC)] are the mean parameters deﬁned by the
current model. As a consequence, zero gradient points are speciﬁed by
matching the model marginals Pθ[XC = J] to the empirical marginals
estimates {θ(t)} via the recursion in Figure 6.1.
(cid:14) (cid:6)

(cid:3)P[XC = J]. With this set-up, we may deﬁne a sequence of parameter
(cid:15)

These updates have two key properties: ﬁrst, the log partition func-

tion is never changed by the updates. Indeed, we have

(cid:6)

A(θ(t+1)) = log

log

I C;J[xC]

J∈X |C|

+ A(θ(t))

Note that this invariance in A arises due to the overcompleteness of this
I C;J(xC) = 1
particular exponential family — in particular, since
for all cliques C. Second, the update in step (ii) enforces exactly
the zero-gradient condition (6.5). Indeed, after the parameter update
θ(t) → θ(t+1), we have

J

(cid:3)µC;J

(t)
C;J

µ

θ(t)[I C;J(XC)] =(cid:3)µC;J .

E

θ(t+1)[I C;J(XC)] =
E

x

exp

exp

(cid:14)(cid:19)θ(t), φ(x)(cid:20))
(cid:15)
)I C;J [xC]!
((cid:3)µC;J
 (cid:2)
(cid:6)
(cid:3)µC;J + A(θ(t))

(t)
C;J

θ(t)

µ

J

= log E

= log

J∈X |C|

= A(θ(t)).

(cid:3)µC;J

(t)
C;J

µ

(cid:10)

6.2 Partially Observed Models and Expectation–Maximization

153

Consequently, this IPF algorithm corresponds to as a blockwise coor-
dinate ascent method for maximizing the objective function (6.1). At
each iteration, the algorithm picks a particular block of coordinates —
that is, θC;J, for all conﬁgurations J ∈ X |C| deﬁned on the block —
and maximizes the objective function over this subset of coordinates.
Consequently, standard theory on blockwise coordinate ascent meth-
ods [21] can be used to establish convergence of the IPF procedure.
More generally, this iterative proportional ﬁtting procedure is a spe-
cial case of a broader class of iterative scaling, or successive projection
algorithms; see papers [59, 60, 61] or the book [45] for further details
on such algorithms and their properties.

From a computational perspective, however, there are still some
open issues associated with the IPF algorithm in application to graph-
ical models. Note that step (i) in the updates assume a “black box”
routine that, given the current canonical parameter vector θ(t), returns
the associated vector of mean parameters µ(t). For graphs of low
treewidth, this computation can be carried out with the junction tree
algorithm. For more general graphs not amenable to the junction
tree method, one could imagine using approximate sampling meth-
ods or variational methods. The use of such approximate methods
and their impact on parameter estimation is still an active area of
research [225, 231, 241, 243, 253].

6.2 Partially Observed Models and

Expectation–Maximization

A more challenging version of parameter estimation arises in the par-
tially observed setting, in which the random vector X ∼ pθ is not
observed directly, but indirectly via a “noisy” version Y of X. This
formulation includes the special case in which some subset where the
remaining variates are unobserved — that is, “latent” or “hidden”.
The expectation–maximization (EM) algorithm of Dempster et al. [68]
provides a general approach to computing MLEs in this partially
observed setting. Although the EM algorithm is often presented as an
alternation between an expectation step (E step) and a maximization
step (M step), it is also possible to take a variational perspective on EM,

154 Variational Methods in Parameter Estimation

and view both steps as maximization steps [60, 179]. Such a perspective
illustrates how variational inference algorithms can be used in place of
exact inference algorithms in the E step within the EM framework, and
in particular, how the mean ﬁeld approach is especially appropriate for
this task.

A brief outline of our presentation in this section is as follows. We
begin by deriving the EM algorithm in the exponential family setting,
showing how the E step reduces to the computation of expected suf-
ﬁcient statistics — i.e., mean parameters. As we have seen, the vari-
ational framework provides a general class of methods for computing
approximations of mean parameters. This observation suggests a gen-
eral class of variational EM algorithms, in which the approximation
provided by a variational inference algorithm is substituted for the
mean parameters in the E step. In general, as a consequence of mak-
ing such a substitution, one loses the guarantees of exactness that are
associated with the EM algorithm. In the speciﬁc case of mean ﬁeld
algorithms, however, one is still guaranteed that the method performs
coordinate ascent on a lower bound of the likelihood function.

6.2.1 Exact EM Algorithm in Exponential Families

We begin by deriving the exact EM algorithm for exponential families.
Suppose that the set of random variables is partitioned into a vector Y
of observed variables, and a vector X of unobserved variables, and the
probability model is a joint exponential family distribution for (X, Y ):
(6.6)
Given an observation Y = y, we can also form the conditional
distribution

(cid:14)(cid:19)θ, φ(x, y)(cid:20) − A(θ)
(cid:15)

pθ(x, y) = exp

.

pθ(x | y) =

exp{(cid:19)θ, φ(x, y)(cid:20)}

(cid:1)
(cid:15)
X m exp{(cid:19)θ, φ(x, y)(cid:20)} ν(dx)
:= exp{(cid:19)θ, φ(x, y)(cid:20) − Ay(θ)
(cid:13)

exp{(cid:19)θ, φ(x, y)(cid:20)} ν(dx).

(6.7)
where for each ﬁxed y, the log partition function Ay associated with
this conditional distribution is given by the integral

,

Ay(θ) := log

X m

(6.8)

6.2 Partially Observed Models and Expectation–Maximization

155
Thus, we see that the conditional distribution pθ(x | y) belongs to an
d-dimensional exponential family, with vector φ(·, y) of suﬃcient statis-
tics.

The maximum likelihood estimate (cid:3)θ is obtained by maximizing log

probability of the observed data y, which is referred to as the incomplete
log likelihood in the setting of EM. This incomplete log likelihood is
given by the integral

(cid:13)

(cid:14)(cid:19)θ, φ(x, y)(cid:20) − A(θ)
(cid:15)

ν(dx) = Ay(θ) − A(θ),(6.9)

(cid:10)(θ; y) := log

exp

X

where the second equality follows by deﬁnition (6.8) of Ay.
We now describe how to obtain a variational lower bound on the
incomplete log likelihood. For each ﬁxed y, the set My of valid mean
parameters in this exponential family takes the form

0
µ ∈ Rd | µ = Ep[φ(X, y)]

for some p

,

(6.10)

My =

1

where p is any density function over X, taken with respect to underlying
base measure ν. Consequently, applying Theorem 3.4 to this exponen-
tial family provides the variational representation

(cid:14)(cid:19)θ, µy(cid:20) − A

∗
y(µy)

(cid:15)

Ay(θ) = sup
µy∈My

,

(6.11)

where the conjugate dual is also deﬁned variationally as
{(cid:19)µy, θ(cid:20) − Ay(θ)}.

∗
y(µy) :=

sup

A

θ∈dom(Ay)

(6.12)

From the variational representation (6.11), we obtain the lower bound
Ay(θ) ≥ (cid:19)µy, θ(cid:20) − A
y(µy), valid for any µy ∈ My. Using the representa-
∗
tion (6.9), we obtain the lower bound for the incomplete log likelihood:

(cid:10)(θ; y) ≥ (cid:19)µy, θ(cid:20) − A

y(µy) − A(θ) =: L(µy, θ).
∗

(6.13)

With this set-up, the EM algorithm is coordinate ascent on this func-
tion L deﬁning the lower bound (6.13):

(E step)

µy

(t+1) = arg max
µy∈My

(M step)

θ(t+1) = arg max
θ∈Ω

L(µy, θ(t))
L(µy

(t+1), θ).

(6.14a)

(6.14b)

156 Variational Methods in Parameter Estimation

To see the correspondence with the traditional presentation of the
EM algorithm, note ﬁrst that the maximization underlying the E step
reduces to

{(cid:19)µy, θ(t)(cid:20) − A

y(µy)},
∗

max
µy∈My

(6.15)

which by the variational representation (6.11) is equal to Ay(θ(t)),
with the maximizing argument equal to the mean parameter that is
(t+1)
dually coupled with θ(t). Otherwise stated, the vector µ
that is
y
computed by maximization in the ﬁrst argument of L(µy, θ) is exactly
θ(t)[φ(X, y)], a computation that is tradi-
the expectation µy
tionally referred to as the E step, for obvious reasons. Moreover, the
maximization underlying the M step reduces to
(t+1), θ(cid:20) − A(θ)},

(t+1) = E

(6.16)

{(cid:19)µy

max
θ∈Ω

which is simply a maximum likelihood problem based on the expected
suﬃcient statistics µy

(t+1) — traditionally referred to as the M step.

Moreover, given that the value achieved by the E step on the right-
hand side of (6.15) is equal to Ay(θ(t)), the inequality in (6.13) becomes
an equality by (6.9). Thus, after the E step, the lower bound L(µy, θ(t))
is actually equal to the incomplete log likelihood (cid:10)(θ(t); y), and the sub-
sequent maximization of L with respect to θ in the M step is guaranteed
to increase the log likelihood as well.

Example 6.1 (EM for Gaussian Mixtures). We illustrate the
EM algorithm with the classical example of the Gaussian mixture
model, discussed earlier in Example 3.4. Let us focus on a scalar mix-
ture model for simplicity, for which the observed vector Y is Gaus-
sian mixture vector with r components, where the unobserved vector
X ∈ {0,1, . . . , r − 1} indexes the components. The complete likelihood
of this mixture model can be written as

(cid:11)
αj + γjy +(cid:9)γjy2 − Aj(γj,(cid:9)γj)

 ,
(cid:12) − A(α)

(6.17)

r−1(cid:6)

j=0

pθ(x, y) = exp

I j(x)

6.2 Partially Observed Models and Expectation–Maximization

where θ = (α, γ,(cid:9)γ), with the vector α ∈ Rr parameterizing the
(γj,(cid:9)γj) ∈ R2 parameterizing the Gaussian distribution of the jth mix-
ture component. The log normalization function Aj(γj,(cid:9)γj) is for the

multinomial distribution over the hidden vector X, and the pair

157

(conditionally) Gaussian distribution of Y given X = j, whereas the
r−1
j=0 exp(αj)] normalizes the multinomial distri-
function A(α) = log[
bution. When the complete likelihood is viewed as an exponential
family, the suﬃcient statistics are the collection of triplets

(cid:10)

Ψj(x, y) := {I j(x), I j(x)y, I j(x)y2}

for j = 0, . . . , r − 1.

Consider a collection of i.i.d. observations y1, . . . , yn. To each obser-

vation yi, we associate a triplet (µi, ηi, (cid:9)ηi) ∈ Rr × Rr × Rr, corre-
(cid:12) ,
(cid:11)
αj + γjyi +(cid:9)γj(yi)2 − Aj(γj,(cid:9)γj)

sponding to expectations of the triplet of suﬃcient statistics Ψj(X, yi),
j = 0, . . . , r − 1. Since the conditional distribution has the form

r−1(cid:6)

p(x | yi, θ) ∝ exp

I j(x)

j=0

some straightforward computation yields that the probability of the
jth mixture component — or equivalently, the mean parameter
j = E[I j(X)] — is given by
µi

(cid:10)

j = E[I j(X)]
µi
exp
r−1
k=0 exp

=

(cid:14)

(cid:15)
αj + γjyi +(cid:9)γj(yi)2 − Aj(γj,(cid:9)γj)
(cid:14)
(cid:15) .
αk + γkyi +(cid:9)γk(yi)2 − Ak(γk,(cid:9)γk)

Similarly, the remaining mean parameters are

(cid:9)ηi

j = E[I j(X)yi] = µi
ηi
j = E[I j(X)yi] = µi

jyi,
j(yi)2.

and

(6.18)

(6.19a)

(6.19b)

The computation of these expectations (6.18) and (6.19) correspond to
the E step for this particular model.

over the triplet θ = (α, γ,(cid:9)γ), using the expected suﬃcient statistics com-

The M step requires solving the MLE optimization problem (6.16)

puted in the E step. Some computation shows that this maximization

158 Variational Methods in Parameter Estimation

takes the form:

(cid:7)&

n(cid:6)
’
n(cid:6)
’ − r−1(cid:6)

i=1

µi

+

&

’

n(cid:6)
(cid:8)
jAj(γj,(cid:9)γj) − nA(α)

µiyi

i=1

γ,

.

µi

α,

arg max

(α,γ,(cid:4)γ)∈Ω

n(cid:6)

&(cid:9)γ,

+

µi(yi)2

n(cid:6)

i=1

j=0

i=1

Consequently, the optimization decouples into separate maximization
problems: one for the vector α parameterizing the mixture component

distribution, and one for each of the pairs (γj,(cid:9)γj) specifying the Gaus-

sian mixture components. By the moment-matching property of maxi-
mum likelihood estimates, the optimum solution is to update α such
that

1
n

for each j = 0, . . . , r − 1,

µi
j

Eα[I j(X)] =

i=1

and to update the canonical parameters (γj,(cid:9)γj) specifying the jth

Gaussian mixture component (Y | X = j) such that the associated
mean parameters — corresponding to the Gaussian mean and second
moment — are matched to the data as follows:
n
i=1 µi
jyi
j
n
i=1 µi
j
n
j(yi
i=1 µi
n
i=1 µi
j

(cid:10)
(cid:10)
(cid:10)
(cid:10)
Eγj ,(cid:4)γj [Y 2 | X = j] =
family distribution speciﬁed by (γj,(cid:9)γj).

In these equations, the expectations are taken under the exponential

Eγj ,(cid:4)γj [Y | X = j] =

(6.20)

(6.21)

and

j)2

,

.

6.2.2 Variational EM

What if it is infeasible to compute the expected suﬃcient statistics? One
possible response to this problem is to make use of a mean ﬁeld approx-
imation for the E step. In particular, given some class of tractable
subgraphs F , recall the set MF (G), as deﬁned in Equation (5.5),
corresponding to those mean parameters that can be obtained by

159
distributions that factor according to F . By using MF (G) as an inner
approximation to the set My, we can compute an approximate version
of the E step (6.15), of the form

6.3 Variational Bayes

(cid:14)(cid:19)µ, θ(t)(cid:20) − A

(cid:15)

(Mean ﬁeld E step)

max

µ∈MF (G)

∗
y(µ)

.

(6.22)

This variational E step thus involves replacing the exact mean parame-
θ(t)[φ(X, y)], under the current model θ(t), with the approximate
ter E
set of mean parameters computed by a mean ﬁeld algorithm. Despite
this (possibly crude) approximation, the resulting variational EM algo-
rithm is a still coordinate ascent algorithm for L. However, given that
the E step no longer closes the gap between the auxiliary function L
and the incomplete log likelihood, it is no longer the case that the algo-
rithm necessarily goes uphill in the latter quantity. Nonetheless, the
variational mean ﬁeld EM algorithm still has the attractive interpreta-
tion of maximizing a lower bound on the incomplete log likelihood.

In Section 4, we described a broad class of variational methods,
including belief propagation and expectation-propagation, that also
generate approximations to mean parameters. It is tempting, and
common in practice, to substitute the approximate mean parameters
obtained from these relaxations in the place of the expected suﬃcient
statistics in deﬁning a “variational EM algorithm.” Such a substitu-
tion is particularly tempting given that these methods can yield better
approximations to mean parameters than the mean ﬁeld approach. Care
must be taken in working with these algorithms, however, because the
underlying relaxations do not (in general) guarantee lower bounds on
the log partition function.2 In the absence of guaranteed lower bounds,
the connection to EM is thus less clear than in the mean ﬁeld case; in
particular, the algorithm is not guaranteed to maximize a lower bound
on the incomplete log likelihood.

6.3 Variational Bayes

All of the variational approximations that we have discussed thus
far in the survey, as well as those to be discussed in later sections,

2 However, see Sudderth et al. [224] for results on certain classes of attractive graphical
models for which the Bethe approximation does provide such a lower bound.

160 Variational Methods in Parameter Estimation

are applicable in principle to Bayesian inference problems, where the
parameters are endowed with probability distributions and viewed as
random variables. In the literature on the topic, however, the term
“variational Bayes” has been reserved thus far for the application of
the mean-ﬁeld variational method to Bayesian inference [16, 91]. In this
section, we review this application and use the terminology of varia-
tional Bayes to refer to the application, but it should be borne in mind
that this is but one potential application of variational methodology to
Bayesian inference.

We consider a general set-up akin to that used in the preceding
development of the EM algorithm. In particular, let the data be parti-
tioned into an observed component Y and an unobserved component X,
and assume that the complete data likelihood lies in some exponential
family

p(x, y | θ) = exp{(cid:19)η(θ), φ(x, y)(cid:20) − A(η(θ))} .

(6.23)
The function η : Rd → Rd provides some additional ﬂexibility in the
parameterization of the exponential family; this is convenient in the
Bayesian setting.3 We assume moreover that the prior distribution over
Θ also lies in some exponential family, of the conjugate prior form:

pξ,λ(θ) = exp{(cid:19)ξ, η(θ)(cid:20) − λA(η(θ)) − B(ξ, λ)} .

(6.24)

Note that this exponential family is speciﬁed by the suﬃcient statis-
tics {η(θ),−A(η(θ))} ∈ Rd × R, with associated canonical parameters
(ξ, λ) ∈ Rd × R. Its cumulant function B is deﬁned in the usual way

(cid:13)

B(ξ, λ) := log

exp{(cid:19)ξ, η(θ)(cid:20) − λA(η(θ))} dθ,

and expectations of the suﬃcient statistics η(θ) and −A(η(θ)) can be
obtained in the usual way by taking derivatives of B(ξ, λ) with respect
to ξ and λ.

3 Up to this point, we have considered only exponential families in canonical form, for
which [η(θ)]i = θi for all i = 1, . . . , d. This is without loss of generality, because any regular,
minimal exponential family can be reparameterized in such a canonical form [43]. However,
it can be convenient to express exponential families with nonidentity η.

6.3 Variational Bayes

161

The class of models speciﬁed by the pair of Equations (6.23)
and (6.24) is broad. It includes as special cases Gaussian mixture mod-
els with Dirichlet priors, and the latent Dirichlet allocation model from
Example 3.5.

We now consider a central problem in Bayesian inference, that of
computing the marginal likelihood pξ∗,λ∗(y), where y is an observed
∗) are ﬁxed values of the hyperparameters.
data point and where (ξ
This computation entails averaging over both the unobserved variates
X and the random parameters Θ. Working in the log domain, we have.

, λ

∗

#

(cid:13) "(cid:13)
(cid:13)

log pξ∗,λ∗(y) = log

= log

p(x, y | θ) dx

pξ∗,λ∗(θ) dθ

pξ∗,λ∗(θ) p(y | θ) dθ.

(6.25)

#

"
log pξ∗,λ∗(Θ)
pξ,λ(Θ)

,

We now multiply and divide by pξ,λ(θ) and use Jensen’s inequality (see
Proposition 5.1), to obtain the following lower bound, valid for any
choice of (ξ, λ) in the domain of B:

∗

, λ

log pξ∗,λ∗(y) ≥ Eξ,λ[log p(y | Θ)] + Eξ,λ

with equality for (ξ, λ) = (ξ
with respect to the distribution pξ,λ(θ).

(6.26)
∗). Here Eξ,λ denotes averaging over Θ
From Equation (6.9), we have log p(y | Θ) = Ay(η(Θ)) − A(η(Θ)),
#

which when substituted into Equation (6.26) yields
log pξ∗,λ∗(y) ≥ Eξ,λ [Ay(η(Θ)) − A(η(Θ))] + Eξ,λ

"
log pξ∗,λ∗(Θ)
pξ,λ(Θ)

where Ay is the cumulant function of the conditional density p(x |
y, θ).
For each ﬁxed y, recall the set My of mean parameters of the form
µ = E[φ(X, y)]. For any realization of Θ, we could in principle apply
the mean ﬁeld lower bound (6.13) on the log likelihood Ay(Θ), using
a value µ(Θ) ∈ My that varies with Θ. We would thereby obtain that
#
the marginal log likelihood log pξ∗,λ∗(y) is lower bounded by

(cid:11)(cid:19)µ(Θ), η(Θ)(cid:20) − A

(cid:12)
y(µ(Θ)) − A(η(Θ))
∗

"
log pξ∗,λ∗(Θ)
pξ,λ(Θ)

+ Eξ,λ

Eξ,λ

,

.

(6.27)

162 Variational Methods in Parameter Estimation

At this stage, even after this sequence of lower bounds, if we were to
optimize over the set of joint distributions on (X,Θ) — or equivalently,
over the choice µ(Θ) and the hyperparameters (ξ, λ) specifying the
distribution of Θ — the optimized lower bound (6.27) would be equal
to the original marginal log likelihood log pξ∗,λ∗(y).

The variational Bayes algorithm is based on optimizing this lower
bound using only product distributions over the pair (X,Θ). Such opti-
mization is often described as “free-form”, in that beyond the assump-
tion of a product distribution, the factors composing this product dis-
tribution are allowed to be arbitrary. But as we have seen in Section 3.1,
the maximum entropy principle underlying the variational framework
yields solutions that necessarily have exponential form. Therefore, we
can exploit conjugate duality to obtain compact forms for these solu-
tions, working with dually coupled sets of parameters for the distribu-
tions over both X and Θ.

We now derive the variational Bayes algorithm as a coordinate-
ascent method for solving the mean ﬁeld variational problem over prod-
uct distributions. We begin by reformulating the objective function into
a form that allows us to exploit conjugate duality. Since µ is indepen-
dent of Θ, the optimization problem (6.27) can be simpliﬁed to

#

"
log pξ∗,λ∗(Θ)
pξ,λ(Θ)

+ Eξ,λ

,

(6.28)

where ¯η := Eξ,λ[η(Θ)] and A := Eξ,λ[A(Θ)]. Using the exponential
form (6.24) of pξ,λ, we have

(cid:12)

(cid:11)(cid:19)µ, ¯η(cid:20) − A
y(µ) − A
∗
#

"
log pξ∗,λ∗(Θ)
pξ,λ(Θ)
∗ − ξ(cid:20) + (cid:19)−A, λ
= (cid:19)¯η, ξ

Eξ,λ

∗ − λ(cid:20) − B(ξ

∗

∗

, λ

) + B(ξ, λ).

(6.29)
∗), and since (¯η, A) are dually

By the conjugate duality between (B, B
coupled with (ξ, λ) by construction, we have

∗

(η, A) = (cid:19)η, ξ(cid:20) + (cid:19)−A, λ(cid:20) − B(ξ, λ).

B

(6.30)

By combining Equations (6.28) through (6.30) and performing some
algebra, we ﬁnd that the decoupled optimization problem is equivalent

6.3 Variational Bayes

163

to maximizing the function

∗

+ 1, −A(cid:20) − B

∗

∗

, η(cid:20) − A

(6.31)
over µ ∈ My and (η, A) ∈ dom(B). Performing coordinate ascent on
this function amounts to ﬁrst maximizing ﬁrst over µ, and then maxi-
mizing over the mean parameters4 (η, A). Doing so generates a sequence
of iterates

, which are updated as follows:

y(µ) + (cid:19)λ
∗
(t)(cid:24)

(cid:19)µ + ξ
(cid:23)

(η, A)

µ(t), η(t), A
µ(t+1) = arg max
µ∈My

(cid:14)(cid:19)µ, η(t)(cid:20) − A

(cid:15)

∗
y(µ)

,

and

(6.32)

(cid:14)(cid:19)µ(t+1) + ξ

∗

, η(cid:20) − (1 + λ

∗

) A − B

∗

(cid:15)

(η, A)

.

(6.33)

(η(t+1), A

(t+1))
= arg max
(η,A)

In fact, both of these coordinate-wise optimizations have explicit solu-
tions. The explicit form of Equation (6.32) is given by

µ(t+1) = E
η

(t)[φ(X, y)],

(6.34)

as can be veriﬁed by taking derivatives in Equation (6.32), and using
∗
y (see Proposition 3.1). By analogy to the
the cumulant properties of A
EM algorithm, this step is referred to as the “VB-E step.” Similarly,
in the “VB-M step” we ﬁrst update the hyperparameters (ξ, λ) as

(ξ(t+1), λ(t+1)) = (ξ

∗

+ µ(t+1), λ

∗

+ 1),

and then use these updated hyperparameters to compute the new mean
parameters η:

η(t+1) = E(ξ(t+1),λ(t+1))[η(Θ)].

(6.35)

In summary, the variational Bayes algorithm is an iterative algo-
rithm that alternates between two steps. The VB-E step (6.34) entails
computing the conditional expectation of the suﬃcient statistics given
the data

(cid:13)

(VB-E step)

µ(t+1) =

φ(x, y)p(x | y, η(t))dx,

4 Equivalently, by the one-to-one correspondence between exponential and mean parame-
ters (Theorem 3.3), this step corresponds to maximization over the associated canonical
parameters (ξ, λ).

164 Variational Methods in Parameter Estimation

with the conditional distribution speciﬁed by the current parameter
estimate η(t). The VB-M step (6.35) entails updating the hyperpa-
rameters to incorporate the data, and then recomputing the averaged
parameter

(cid:13)

(VB-M step)

η(t+1) =

η(θ) pξ(t+1),λ(t+1)(θ) dθ.

The ordinary variational EM algorithm can be viewed as a “degenerate”
form of these updates, in which the prior distribution over Θ is always
a delta function at a single point estimate of θ.

7

Convex Relaxations and Upper Bounds

Up to this point, we have considered two broad classes of approxi-
mate variational methods: Bethe approximations and their extensions
(Section 4), and mean ﬁeld methods (Section 5). Mean ﬁeld methods
provide not only approximate mean parameters but also lower bounds
on the log partition function. In contrast, the Bethe method and its
extensions lead to neither upper or lower bounds on the log parti-
tion function. We have seen that both classes of methods are, at least
in general, based on nonconvex variational problems. For mean ﬁeld
methods, the nonconvexity stems from the nature of the inner approx-
imation to the set of mean parameters, as illustrated in Figure 5.3.
For the Bethe-type approaches, the lack of convexity in the objective
function — in particular, the entropy approximation — is the source.
Regardless of the underlying cause, such nonconvexity can have unde-
sirable consequences, including multiple optima and sensitivity to the
problem parameters (for the variational problem itself), and conver-
gence issues and dependence on initialization (for iterative algorithms
used to solve the variational problem).

Given that the underlying exact variational principle (3.45) is cer-
tainly convex, it is natural to consider variational approximations that

165

166 Convex Relaxations and Upper Bounds

retain this convexity. In this section, we describe a broad class of such
convex variational approximations, based on approximating the set M
∗ with a convex
with a convex set, and replacing the dual function A
function. These two steps lead to a new variational principle, which rep-
resents a computationally tractable alternative to the original problem.
Since this approximate variational principle is based on maximizing a
concave and continuous function over a convex and compact set, the
global optimum is unique, and is achieved. If in addition, the negative
dual function −A
∗, corresponding to the entropy function, is replaced
by an upper bound, and the set M is approximated by a convex outer
bound, then the global optimum of the approximate variational princi-
ple also provides an upper bound on the log partition function. These
upper bounds are complementary to the lower bounds provided by
mean ﬁeld procedures (see Section 5).

We begin by describing a general class of methods based on approx-
imating the entropy by a convex combination of easily computable
entropies, thereby obtaining a tractable relaxation that is guaranteed
to be convex. As our ﬁrst example illustrates, following this proce-
dure using tree-structured distributions as the tractable class leads
to the family of “convexiﬁed” Bethe variational problems, and asso-
ciated reweighted sum-product algorithms [243, 246]. However, this
basic procedure for “convexiﬁcation” is quite broadly applicable; as we
describe, it yields convex analogs of other known variational methods,
including Kikuchi and region-graph methods [246, 251, 260], as well
as expectation-propagation approximation. It has also suggested novel
variational methods, also based on the notion of convex combinations,
including those based on planar graph decomposition [94]. Finally,
there are other convex variational relaxations that are not directly
based on convex combinations of tractable distributions, including the
method of conditional entropy decompositions [95], and methods based
on semideﬁnite constraints and log-determinant programming [248].
Apart from these known algorithms, there are a large number of
novel methods based on convex variational relaxations that await
discovery.

We conclude the section by discussing some beneﬁts of convexity in
variational methods. In addition to the obvious one of unique optima,

7.1 Generic Convex Combinations and Convex Surrogates

167

possible beneﬁts include guarantees of algorithmic stability and useful-
ness as surrogate likelihoods in parameter estimation.

7.1 Generic Convex Combinations and Convex Surrogates

We begin with a generic description of approximations based
on convex combinations of tractable distributions. Consider a d-
dimensional exponential family, deﬁned by a vector of suﬃcient statis-
tics φ = (φα, α ∈ I), and an associated vector of canonical parameters
θ = (θα, α ∈ I). Although computing mean parameters for an arbitrary
θ ∈ Ω might be intractable, it is frequently the case that such compu-
tations are tractable for certain special choices of the canonical param-
eters. If the exponential family is viewed as a Markov random ﬁeld
deﬁned by some underlying graph G, many such special choices can
be indexed by particular subgraphs F , say belonging to some class D.
Examples that we consider below include D corresponding to the set of
all spanning trees of G, or planar subgraphs of G. In terms of the expo-
nential family, we can think of the subgraph F as extracting a subset
of indices I(F ) from the full index set I of potential functions, thereby
deﬁning a lower-dimensional exponential family based on d(F ) < d suf-
ﬁcient statistics. We let M(F ) denote the lower-dimensional set of mean
parameters associated with this exponential family; concretely, this set
has the form:
M(F ) :=
(7.1)
For any mean parameter µ ∈ M, let µ (cid:26)→ µ(F ) represent the coor-
dinate projection mapping from the full space I to the subset I(F )
of indices associated with F . By deﬁnition of the sets M ⊆ Rd and
M(F ) ⊆ Rd(F ), we are guaranteed that the projected vector µ(F ) is an
element of M(F ). Let −A
∗(µ(F )) be the negative dual function value
(or entropy) associated with the projected mean parameter µ(F ). A
simple consequence of Theorem 3.4 is that this entropy is always an
∗(µ) deﬁned in the origi-
upper bound on the negative dual function A
nal d-dimensional exponential family. With a slight abuse of notation,
we use H(µ) to denote the negative dual function or entropy −A
∗(µ),
and similarly H(µ(F )) to denote the entropy −A

(cid:15)
µ ∈ R|I(F )| | ∃p s.t. µα = Ep[φ(X)] ∀ α ∈ I(F )

(cid:14)

.

∗(µ(F )).

168 Convex Relaxations and Upper Bounds

Proposition 7.1 (Maximum Entropy Bounds). Given any mean
parameter µ ∈ M and its projection µ(F ) onto any subgraph F , we
have the bound

(µ(F )) ≤ A
∗
or alternatively stated, H(µ(F )) ≥ H(µ).

A

∗

(µ),

(7.2)

From Theorem 3.4, the negative dual value −A

∗(µ) corresponds
to the entropy of the exponential family member with mean param-
∗(µ(F )). Alternatively
eters µ, with a similar interpretation for A
phrased, Proposition 7.1 states the entropy of the exponential fam-
ily member pµ(F ) is always larger than the entropy of the distribu-
tion pµ. Intuitively, the distribution pµ is obtained from a maximum
entropy problem with more constraints — corresponding to the indices
α ∈ I\I(F ) — and so has lower entropy. Our proof makes this intuition
precise.

Proof. From Theorem 3.4, the dual function is realized as the solution
of the optimization problem

∗

{(cid:19)µ, θ(cid:20) − A(θ)} .

A

(µ) = sup
θ∈Rd

(7.3)
Since the exponential family deﬁned by F involves only a subset I(F )
∗(µ(F )) is
of the potential functions, the associated dual function A
realized by the lower-dimensional optimization problem

∗

A

(µ(F )) =

sup

θ(F )∈Rd(F )

{(cid:19)µ(F ), θ(F )(cid:20) − A(θ(F ))} .

But this optimization problem can be recast as a restricted version of
the original problem (7.3):

∗

A

(µ(F )) =

sup
θ∈Rd,

θα=0 ∀ α /∈ I(F )

{(cid:19)µ, θ(cid:20) − A(θ)} ,

from which the claim follows.

7.1 Generic Convex Combinations and Convex Surrogates

169

Given the bound (7.2) for each subgraph F , any convex combination
of subgraph-structured entropies is also an upper bound on the original
entropy. In particular, if we consider a probability distribution over the
set of tractable graphs, meaning a probability vector ρ ∈ R|D| such that
(7.4)

ρ(F ) ≥ 0 for all tractable F ∈ D, and
(cid:6)

F
Any such distribution generates the upper bound

(cid:6)

ρ(F ) = 1.

H(µ) ≤ Eρ[H(µ(F ))] :=

ρ(F )H(µ(F )).

(7.5)

F∈D

(cid:14)

L(G; D) :=

Having derived an upper bound on the entropy,

it remains to
obtain a convex outer bound on the set of mean parameters M. An
important restriction is that each of the subgraph-structured entropies
H(µ(F )) = −A
∗(µ(F )) must be well-deﬁned on this outer bounding
set. The simplest outer approximation with this property is deﬁned
by requiring that each projected mean parameter µ(F ) belong to the
projected set M(F ). In particular, let us deﬁne the constraint set

(cid:15)
τ ∈ Rd | τ(F ) ∈ M(F ) ∀F ∈ D

(7.6)
Our shift in notation, from µ to τ, is deliberate, since L(G; D) is an
outer bound on M(G). (Indeed, by deﬁnition of the sets M(F ), any
mean parameter µ ∈ M(G), when projected down to µ(F ), is also glob-
ally realizable, so that µ ∈ L(G; D).) Moreover, L(G; D) is a convex set,
since each of the subsets M(F ) in its deﬁnition are convex.
(cid:22)

Overall, these two ingredients — the convex upper bound (7.5) and
the convex outer bound (7.6) — yield the following approximate varia-
tional principle

.

(cid:4)
(cid:19)τ, θ(cid:20) +

(cid:6)

F∈D

BD(θ; ρ) := sup

τ∈L(G;D)

ρ(F )H(τ(F ))

.

(7.7)

Note that the objective function deﬁning BD is concave; moreover, the
constraint set ∩FMF is convex, since it is the intersection of the sets
MF , each of which are individually convex sets. Overall, then, the
function BD is a new convex function that approximates the original
cumulant function A. We refer to such a function as a convex surrogate
to A.

170 Convex Relaxations and Upper Bounds

Of course, in order for variational principles of the form (7.7) to be
useful, it must be possible to evaluate and optimize the objective func-
tion. Accordingly, in the following sections, we provide some speciﬁc
examples of the tractable class D that lead to interesting and practical
algorithms.

7.2 Variational Methods from Convex Relaxations

In this section, we describe a number of versions of the convex surro-
gate (7.7), including convex versions of the Bethe/Kikuchi problems, as
well as convex versions of expectation-propagation and other moment-
matching methods.

7.2.1 Tree-reweighted Sum-Product and Bethe

We begin by deriving the tree-reweighted sum-product algorithm and
the tree-reweighted Bethe variational principle [243, 246], correspond-
ing to a “convexiﬁed” analog of the ordinary Bethe variational principle
described in Section 4. Given an undirected graph G = (V, E), consider
a pairwise Markov random ﬁeld

(cid:22)

(cid:4)(cid:6)

s∈V

(cid:6)

(s,t)∈E

pθ(x) ∝ exp

θs(xs) +

θst(xs, xt)

,

(7.8)

where we are using the standard overcomplete representation based on
indicator functions at single nodes and edges (see Equation (3.34)). Let
the tractable class D be the set T of all spanning trees T = (V, E(T ))
of the graph G. (A spanning tree of a graph is a tree-structured sub-
graph whose vertex set covers the original graph.) Letting ρ denote a
probability distribution over the set of spanning trees, Equation (7.5)
T ρ(T )H(µ(T )), based on a convex

yields the upper bound H(µ) ≤(cid:10)

combination of tree-structured entropies.

An attractive property of tree-structured entropies is that they
decompose additively in terms of entropies associated with the vertices
and edges of the tree. More speciﬁcally, these entropies are deﬁned
by the mean parameters, which (in the canonical overcomplete repre-
sentation (3.34)) correspond to singleton marginal distributions µs(·)

7.2 Variational Methods from Convex Relaxations

171
deﬁned at each vertex s ∈ V , and a joint pairwise marginal distribu-
tion µst(· , ·) deﬁned for each edge (s, t) ∈ E(T ). As discussed earlier
in Section 4, the factorization (4.8) of any tree-structured probability
distribution yields the entropy decomposition

H(µ(T )) =

Hs(µs) −

Ist(µst).

(7.9)

(cid:6)

(s,t)∈E(T )

(cid:6)

s∈V

(cid:6)

s∈V

Now consider the averaged form of the bound (7.5). Since the trees are
all spanning, the entropy term Hs for node s ∈ V receives a weight of
one in this average. On the other hand, the mutual information term
, where
Ist for edge (s, t) receives the weight ρst = Eρ
I[(s, t) ∈ E(T )] is an indicator function for the event that edge (s, t) is
included in the edge set E(T ) of a given tree T . Overall, we obtain the
following upper bound on the exact entropy:

(cid:11)
(cid:12)
I[(s, t) ∈ E(T )]

H(µ) ≤

Hs(µs) −

ρstIst(µst).

(7.10)

(cid:6)

(s,t)∈E

We refer to the edge weight ρst as the edge appearance probability,
since it reﬂects the probability mass associated with edge (s, t). The
vector ρ = (ρst, (s, t) ∈ E) of edge appearance probabilities belong to
a set called the spanning tree polytope, as discussed at more length in
Theorem 7.2 to follow.
Let us now consider the form of the outer bound L(G; T) on the
set M. For the pairwise MRF with the overcomplete parameterization
under consideration, the set M is simply the marginal polytope M(G).
On the other hand, the set M(T ) is simply the marginal polytope for
the tree T , which from our earlier development (see Proposition 4.1) is
equivalent to L(T ). Consequently, the constraint µ(T ) ∈ M(T ) is equiv-
alent to enforcing nonnegativity constraints, normalization (at each
vertex) and marginalization (across each edge) of the tree. Enforc-
ing the inclusion µ(T ) ∈ M(T ) for all trees T ∈ T is equivalent to
enforcing the marginalization on every edge of the full graph G.
We conclude that in this particular case, the set L(G; T) is equiva-
lent to the set L(G) of locally consistent pseudomarginals, as deﬁned
earlier (4.7).

172 Convex Relaxations and Upper Bounds

Overall, then, we obtain a variational problem that can be viewed as
a “convexiﬁed” form of the Bethe variational problem. We summarize
our ﬁndings in the following result [243, 246]:

Theorem 7.2 (Tree-Reweighted Bethe and Sum-Product).
(a) For any choice of edge appearance vector (ρst, (s, t) ∈ E)
in the spanning tree polytope, the cumulant function A(θ)
(cid:8)
evaluated at θ is upper bounded by the solution of the tree-
reweighted Bethe variational problem (BVP):

(cid:7)

(cid:6)

BT(θ; ρe) := max
τ∈L(G)

(cid:19)τ, θ(cid:20) +

Hs(τs) −

(cid:6)

s∈V

(s,t)∈E

ρstIst(τst)

.

(7.11)

For any edge appearance vector such that ρst > 0 for all
edges (s, t), this problem is strictly convex with a unique
optimum.

(b) The tree-reweighted BVP can be solved using the tree-

reweighted sum-product updates

(cid:6)

(cid:5)
(cid:11)

(cid:11)

(cid:12)
(cid:12)(1−ρts)

(cid:4)
Mvt(x
t)

v∈N(t)\s

(cid:4)
Mst(x
t)

ρvt

)

Mts(xs) ← κ

(cid:4)
ϕst(xs, x
t)

(

x

(cid:2)
t

∈Xt
(cid:4)
ϕst(xs, x
t) := exp

where
. The
updates (7.12) have a unique ﬁxed point under the
assumptions of part (a).

(cid:4)
(cid:4)
t) + θt(x
θst(xs, x
t)

1
ρst

, (7.12)

We make a few comments on Theorem 7.2, before providing the proof.
Valid edge weights: Observe that the tree-reweighted Bethe variational
problem (7.11) is closely related to the ordinary Bethe problem (4.16).
In particular, if we set ρst = 1 for all edges (s, t) ∈ E, then the two for-
mulations are equivalent. However, the condition ρst = 1 implies that
every edge appears in every spanning tree of the graph with proba-
bility one, which can happen if and only if the graph is actually tree-
structured. More generally, the set of valid edge appearance vectors ρe

7.2 Variational Methods from Convex Relaxations

173

f

e

b

f

e

b

f

e

b

f

e

b

Fig. 7.1 Illustration of valid edge appearance probabilities. Original graph is shown in panel
(a). Probability 1/3 is assigned to each of the three spanning trees { Ti | i = 1,2,3} shown
in panels (b)–(d). Edge b appears in all three trees so that ρb = 1. Edges e and f appear
in two and one of the spanning trees, respectively, which gives rise to edge appearance
probabilities ρe = 2/3 and ρf = 1/3.

must belong to the so-called spanning tree polytope [54, 73] associated
with G. Note that these edge appearance probabilities must satisfy
various constraints, depending on the structure of the graph. A simple
example should help to provide intuition.

Example 7.1 (Edge Appearance Probabilities). Figure 7.1(a)
shows a graph, and panels (b) through (d) show three of its spanning
trees {T 1, T 2, T 3}. Suppose that we form a uniform distribution ρ over
these trees by assigning probability ρ(T i) = 1/3 to each T i, i = 1,2,3.
Consider the edge with label f; notice that it appears in T 1, but in
neither of T 2 and T 3. Therefore, under the uniform distribution ρ,
the associated edge appearance probability is ρf = 1/3. Since edge e
appears in two of the three spanning trees, similar reasoning establishes
that ρe = 2/3. Finally, observe that edge b appears in any spanning tree
(i.e., it is a bridge), so that it must have edge appearance probability
ρb = 1.

In their work on fractional belief propagation, Wiegerinck and Hes-
kes [261] examined the class of reweighted Bethe problems of the
form (7.11), but without the requirement that the weights ρst belong
to the spanning tree polytope. Although loosening this requirement
does yield a richer family of variational problems, in general one loses

174 Convex Relaxations and Upper Bounds

the guarantee of convexity, and (hence) that of a unique global opti-
mum. On the other hand, Weiss et al. [251] have pointed out that other
choices of weights ρst, not necessarily in the spanning tree polytope, can
also lead to convex variational problems. In general, convexity and the
upper bounding property are not equivalent. For instance, for any single
cycle graph, setting ρst = 1 for all edges (i.e., the ordinary BVP choice)
yields a convex variational problem [251], but the value of the Bethe
variational problem does not upper bound the cumulant function value.
Various other researchers [110, 167, 188, 189] also discuss the choice of
edge/clique weights in Bethe/Kikuchi approximations, and its conse-
quences for convexity.
Properties of tree-reweighted sum-product: In analogy to the ordinary
Bethe problem and sum-product algorithm, the ﬁxed point of tree-
reweighted sum-product (TRW) message-passing (7.12) speciﬁes the
optimal solution of the variational problem (7.11) as follows:

(cid:14)

(cid:15) (cid:2)
(cid:11)

M

(cid:11)
(cid:12)
(cid:12)(1−ρst)

ρvs

ρvs

(cid:12)
(cid:5)
(cid:11)

τ

∗
s , τ

M

ρst

θs(xs)

(7.13a)

(cid:11)

M

ρvt

,

∗
vs(xs)

∗
s (xs) = κ exp

τ

v∈N(t)\s
∗
st(xt)

M

v∈N(s)
∗
vs(xs)
M

(cid:12)
(cid:12)(1−ρts)

∗
vt(xt)

v∈N(s)\t
∗
ts(xs)

∗
st(xs, xt) = κ ϕst(xs, xt)

(cid:5)
(cid:11)
(7.13b)
θst(xs, xt) + θs(xs) + θt(xt)}. In contrast
where ϕst(xs, xt) := exp{ 1
to the ordinary sum-product algorithm, the ﬁxed point (and associ-
∗
st)) is unique for any valid vector of edge appear-
ated optimum (τ
ances. Roosta et al. [204] provide suﬃcient conditions for convergence,
based on contraction arguments such as those used for ordinary sum-
product [90, 118, 178, 230]. In practical terms, the updates (7.12)
appear to always converge if damped forms of the updates are used
(i.e., setting log M new = (1 − λ)log M old + λlog M, where M old is the
previous vector of messages, and λ ∈ (0,1] is the damping parameter).
As an alternative, Globerson and Jaakkola [96] proposed a related
message-passing algorithm based on oriented trees that is guaran-
teed to converge, but appears to do so more slowly than damped
TRW-message passing. Another possibility would be to adapt other
double-loop algorithms [110, 111, 254, 270], originally developed for

7.2 Variational Methods from Convex Relaxations

175

the ordinary Bethe/Kikuchi problems, to solve these convex minimiza-
tion problems; see Hazan and Shashua [108] for some recent work along
these lines.

Optimal choice of edge appearance probabilities: Note that Equa-
tion (7.11) actually describes a family of variational problems, one for
each choice of probability distribution over the set of spanning trees
T. A natural question thus arises: what is the “optimal” choice of this
probability distribution, or equivalently the choice of the edge appear-
ance vector (ρst, (s, t) ∈ E)? One notion of optimality is to choose the
edge appearance probabilities that leads to the tightest upper bound on
the cumulant function (i.e., for which the gap BT(θ; ρ) − A(θ) is small-
est). In principle, it appears as if the computation of this optimum
might be diﬃcult, since it seems to entail searching over all probabil-
ity distributions over the set T of all spanning trees of the graph. The
number |T| of spanning trees can be computed via the matrix-tree the-
orem [222], and for suﬃciently dense graphs, it grows rapidly enough to
preclude direct optimization over T. However, Wainwright et al. [246]
show that it is possible to directly optimize the vector (ρst, (s, t) ∈ E)
of edge appearance probabilities, subject to the constraint of mem-
bership in the spanning tree polytope. Although this polytope has a
prohibitively large number of inequalities, it is possible to maximize a
linear function over it — equivalently, to solve a maximum weight span-
ning tree problem — by a greedy algorithm [212]. Using this fact, it is
possible to develop a version of the conditional gradient algorithm [21]
for eﬃciently computing the optimal choice of edge appearance proba-
bilities (see the paper [246] for details).

Proof of Theorem 7.2:

We begin with the proof of part (a). Our discussion preceding the
statement of the result establishes that BT is an upper bound on A.
It remains to establish the strict convexity, and resulting uniqueness of
the global optimum. Note that the cost function deﬁning the func-
tion BT consists of a linear term (cid:19)θ, τ(cid:20) and a convex combination
Eρ[−A
∗(τ(T ))] of tree entropies, and hence is concave. Moreover, the
constraint set L(G) is a polytope, and hence convex. Therefore, the
variational problem (7.11) is always convex. We now establish unique-

176 Convex Relaxations and Upper Bounds

ness of the optimum when ρe > 0. To simplify details of the proof, we
assume without loss of generality that we are working in a minimal
representation. (If the variational problem is formulated in an over-
complete representation, it can be reduced to an equivalent minimal
formulation.) To establish uniqueness, it suﬃces to establish that the
∗(τ(T ))] is strictly convex when ρe > 0. This function is a
function Eρ[A
∗(τ(T )), each of which is
convex combination of functions of the form A
strictly convex in the (nonzero) components of τ(T ), but independent
of the other components in the full vector τ. For any vector λ ∈ Rd,
deﬁne ΠT (λ)α = λα if α ∈ I(T ), and ΠT (λ)α = 0 otherwise. We then
have

(cid:19)λ, ∇2A
∗

(τ(T ))λ(cid:20) = (cid:19)ΠT (λ), ∇2A
∗

(τ(T ))ΠT (λ)(cid:20) ≥ 0,

with strict inequality unless ΠT (λ) = 0. Now the condition ρe > 0 for
all e ∈ E ensures that λ (cid:12)= 0 implies that ΠT (λ) must be diﬀerent from
zero for at least one tree T

(cid:4). Therefore, for any λ (cid:12)= 0, we have

(cid:19)λ, Eρ[∇2A
∗

(τ(T ))] λ(cid:20) ≥ (cid:19)ΠT

(cid:4)

(cid:2)

))ΠT

(λ)(cid:20) > 0,

(cid:2)

(λ), ∇2A
∗

(τ(T

which establishes the assertion of strict convexity.

We now turn to proof of part (b). Derivation of the TRW-S
updates (7.12) is entirely analogous to the proof of Theorem 4.2: setting
up the Lagrangian, taking derivatives, and performing some algebra
yields the result (see the paper [246] for full details). The uniqueness
follows from the strict convexity established in part (a).

7.2.2 Reweighted Kikuchi Approximations

A natural extension of convex combinations of trees, entirely analogous
to the transition from the Bethe to Kikuchi variational problems, is to
take convex combinations of hypertrees. This extension was sketched
out in Wainwright et al. [246], and has been further studied by other
researchers [251, 260]. Here we describe the basic idea with one illustra-
tive example. For a given treewidth t, consider the set of all hypertrees
of width T(t) of width less than or equal to t. Of course, the under-
lying assumption is that t is suﬃciently small that performing exact
computations on hypertrees of this width is feasible. Applying Propo-
sition 7.1 to a convex combination based on a probability distribution

7.2 Variational Methods from Convex Relaxations

177
ρ = (ρ(T ), T ∈ T(t)) over the set of all hypertrees of width at most t,
we obtain the following upper bound on the entropy:

H(µ) ≤ Eρ[H(µ(T ))] = −

ρ(T )H(µ(T )).

(7.14)

(cid:6)

T

For a ﬁxed distribution ρ, our strategy is to optimize the right-hand
side of this upper bound over all pseudomarginals that are consistent
on each hypertree. The resulting constraint set is precisely the poly-
tope Lt(G) deﬁned in Equation (4.51). Overall, the hypertree analog of
Theorem 7.2 asserts that the log partition function A is upper bounded
by the hypertree-based convex surrogate:

(cid:14)(cid:19)τ, θ(cid:20) + Eρ[H(τ(T ))]
(cid:15)

.

(7.15)

A(θ) ≤ BT(t)(θ; ρ) := max
τ∈L(G)

(Again, we switch from µ to τ to reﬂect the fact that elements of the
constraint set L(G) need not be globally realizable.) Note that the
cost function in this optimization problem is concave for all choices of
distributions ρ over the hypertrees. The variational problem (7.15) is
the hypertree analog of Equation (7.11); indeed, it reduces to the latter
equation in the special case t = 1.

Example 7.2 (Convex Combinations of Hypertrees). Let us
derive an explicit form of Equation (7.15) for a particular hypergraph
and choice of hypertrees. The original graph is the 3 × 3 grid, as illus-
trated in the earlier Figure D.1(a). Based on this grid, we construct the
augmented hypergraph shown in Figure 7.2(a), which has the hyper-
edge set E given by
{(1245),(2356),(4578),(5689),(25),(45),(56),(58),(5),(1),(3),(7),(9)}.
It is straightforward to verify that it satisﬁes the single counting crite-
rion (see Appendix D for background).

Now consider a convex combination of

four hypertrees, each
obtained by removing one of the 4-hyperedges from the edge set. For
instance, shown in Figure 7.2(b) is one particular acyclic substructure
T 1 with hyperedge set E(T 1)

{(1245),(2356),(4578),(25),(45),(56),(58),(5),(1),(3),(7),(9)},

178 Convex Relaxations and Upper Bounds

1

7

1 2 4 5

2 3 5 6

52

4 5

5

5 6

5 8

54

7 8

5 6 8 9

3

9

1

7

1 2 4 5

2 3 5 6

52

4 5

5

5 6

5 8

54

7 8

3

9

1

7

2 3 5 6

52

4 5

5

5 6

5 8

54

7 8

5 6 8 9

3

9

Fig. 7.2 Hyperforests embedded within augmented hypergraphs. (a) An augmented hyper-
graph for the 3 × 3 grid with maximal hyperedges of size four that satisﬁes the single
counting criterion. (b) One hyperforest of width three embedded within (a). (c) A second
hyperforest of width three.

obtained by removing (5689) from the full hyperedge set E. To be
precise, the structure T 1 so deﬁned is a spanning hyperforest, since
it consists of two connected components (namely, the isolated hyper-
edge (9) along with the larger hypertree). This choice, as opposed to a
spanning hypertree, turns out to simplify the development to follow.
Figure 7.2(c) shows the analogous spanning hyperforest T 2 obtained
by removing hyperedge (1245); the ﬁnal two hyperforests T 3 and T 4
are deﬁned analogously.

To specify the associated hypertree factorization, we ﬁrst compute
the form of ϕh for the maximal hyperedges (i.e., of size four). For
instance, looking at the hyperedge h = (1245), we see that hyperedges
(25), (45), (5), and (1) are contained within it. Thus, using the
deﬁnition in Equation (4.40), we write (suppressing the functional

7.2 Variational Methods from Convex Relaxations

179

dependence on x):

ϕ1245 =

τ1245

ϕ25 ϕ45 ϕ5ϕ1

= τ1245

τ25
τ5

τ45
τ5 τ5τ1

= τ1245 τ5
τ25τ45τ1

.

Having calculated all the functions ϕh, we can combine them, using
the hypertree factorization (4.42), in order to obtain the following fac-
torization for a distribution on T 1:

! 

!

! 

 

 

! 

τ1245 τ5
τ25τ45τ1
×

τ25
τ5

! 

τ2356 τ5
τ25τ56τ3

! 

!

τ4578 τ5
τ45τ58τ7

τ45
τ5

τ56
τ5

τ58
τ5

[τ1][τ3][τ5][τ7][τ9].

(7.16)

pτ(T 1)(x) =

Here each term within square brackets corresponds to ϕh for some
hyperedge h ∈ E(T 1); for instance, the ﬁrst three terms correspond
to the three maximal 4-hyperedges in T 1. Although this factorization
could be simpliﬁed, leaving it in its current form makes the connec-
tion to Kikuchi approximations more explicit; in particular, the factor-
ization (7.16) leads immediately to a decomposition of the entropy.
In an analogous manner,
it is straightforward to derive factoriza-
tions and entropy decompositions for the remaining three hyperforests
{T i, i = 2,3,4}.
Now let E4 = {(1245),(2356),(5689),(4578)} denote the set of all
4-hyperedges. We then form the convex combination of the four (nega-
tive) entropies with uniform weight 1/4 on each T i; this weighted sum

∗(τ(T i)) takes the form:

τh(xh)log ϕh(xh) +

+

(cid:6)
(cid:6)

(cid:6)
(cid:6)
τs5(xs5)log τs5(xs5)
τ5(x5)

xs5

s∈{2,4,6,8}

τs(xs)log τs(xs).

(7.17)

s∈{1,3,5,7,9}

xs

(cid:10)4

3
4

i=1

1
4 A

(cid:6)

(cid:6)

h∈E4

xh

The weight 3/4 arises because each of the maximal hyperedges h ∈ E4
appears in three of the four hypertrees. All of the (nonmaximal) hyper-
edge terms receive a weight of one, because they appear in all four
hypertrees. Overall, then, these weights represent hyperedge appear-
ance probabilities for this particular example, in analogy to ordinary
edge appearance probabilities in the tree case. We now simplify the

180 Convex Relaxations and Upper Bounds

so yields that the sum −(cid:10)4

1
4 A
weighted combination of entropies:

expression in Equation (7.17) by expanding and collecting terms; doing
∗(τ(T i)) is equal to the following

i=1

3
4

[H1245 + H2356 + H5689 + H4578] − 1
2

+

1
4

[H1 + H3 + H7 + H9].

[H25 + H45 + H56 + H58]

(7.18)

If, on the other hand, starting from Equation (7.17) again, suppose
that we included each maximal hyperedge with a weight of 1, instead
of 3/4. Then, after some simpliﬁcation, we would ﬁnd that (the nega-
tive of) Equation (7.17) is equal to the following combination of local
entropies
[H1245 + H2356 + H5689 + H4578] − [H25 + H45 + H56 + H58] + H5,

which is equivalent to the Kikuchi approximation derived in Exam-
ple 4.6. However, the choice of all ones for the hyperedge appearance
probabilities is invalid — that is, it could never arise from taking a
convex combination of hypertree entropies.

More generally, any entropy approximation formed by taking such
convex combinations of hypertree entropies will necessarily be convex.
In contrast, with the exception of certain special cases [110, 167, 188,
189], Kikuchi and other hypergraph-based entropy approximations are
typically not convex. In analogy to the tree-reweighted sum-product
algorithm, it is possible to develop hypertree-reweighted forms of gen-
eralized sum-product updates [251, 260]. With a suitable choice of con-
vex combination, the underlying variational problem will be strictly
convex, and so the associated hypertree-reweighted sum-product algo-
rithms will have a unique ﬁxed point. An important diﬀerence from
the case of ordinary trees, however, is that optimization of the hyper-
edge weights ρe cannot be performed exactly using a greedy algorithm.
Indeed, the hypertree analog of the maximum weight spanning tree
problem is known to be NP-hard [129].

7.2 Variational Methods from Convex Relaxations

181

7.2.3 Convex Forms of Expectation-Propagation

As discussed in Section 4.3, the family of expectation-propagation
algorithms [172, 175], as well as related moment-matching algo-
rithms [64, 115, 185], can be understood in terms of term-by-term
entropy approximations. From this perspective,
it is clear how to
derive convex analogs of the variational problem (4.69) that underlies
expectation-propagation.

In particular, recall from Equation (4.75) the form of the term-by-

term entropy approximation

Hep(τ,(cid:9)τ) := H(τ) +

dI(cid:6)

(cid:11)
(cid:12)
H(τ,(cid:9)τ (cid:7)) − H(τ)

where H(τ) represents the entropy of the base distribution, and H(τ,(cid:9)τ (cid:7))

(cid:7)=1

,

represents the entropy of the base plus (cid:10)th term. Implicitly, this entropy
approximation is weighting each term i = 1, . . . , dI with weight one.
Suppose instead that we consider a family of nonnegative weights
{ρ(1), . . . , ρ(dI)} over the diﬀerent terms, and use the reweighted term-
by-term entropy approximation

Hep(τ,(cid:9)τ; ρ) := H(τ) +
(cid:10)

(cid:11)
(cid:12)
H(τ,(cid:9)τ (cid:7)) − H(τ)

.

ρ((cid:10))

dI(cid:6)

(cid:7)=1

(7.19)

For suitable choice of weights — for instance, if we enforce the con-
dI
(cid:7)=1 ρ((cid:10)) = 1 — this reweighted entropy approximation is
straint
concave. Other choices of nonnegative weights could also produce con-
cave entropy approximations. The EP outer bound L(φ;Φ) on the set
M(φ), as deﬁned in Equation (4.67), is a convex set by deﬁnition. Con-
sequently, if we combine a convex entropy approximation (7.19) with
this outer bound, we obtain “convexiﬁed” forms of the EP variational
problem. Following the line of development in Section 4.3, it is also
possible to derive Lagrangian algorithms for solving these optimization
problems. Due to underlying structure, the updates can again be cast
in terms of moment-matching steps. In contrast to standard forms of
EP, a beneﬁt of these algorithms would be the existence of unique ﬁxed
points, assured by the convexity of the underlying variational princi-
ple. With diﬀerent motivations, not directly related to convexity and

182 Convex Relaxations and Upper Bounds

uniqueness, Minka [173] has discussed reweighted forms of EP, referred
to as “power EP.” Seeger et al. [214] reported that reweighted forms of
EP appear to have better empirical convergence properties than stan-
dard EP. It would be interesting to study connections between the
convexity of the EP entropy approximation, and the convergence and
stability properties of the EP updates.

7.2.4 Other entropy approximations

the form pθ(x) ∝ exp{(cid:10)

Trees (and the associated hierarchy of hypertrees) represent the best
known classes of tractable graphical models. However, exact compu-
tation is also tractable for certain other classes of graphical models.
Unlike hypertrees, certain models may be intractable in general, but
tractable for speciﬁc settings of the parameters. For instance, consider
the subclass of planar graphs (which can be drawn in the 2D plane with-
out any crossing of the edges, for instance 2D grid models). Although
exact computation for an arbitrary Markov random ﬁeld on a planar
graph is known to be intractable, if one considers only binary ran-
dom variables without any observation potentials (i.e., Ising models of
(s,t)∈E θstxsxt}), then it is possible to compute
the cumulant function A(θ) exactly, using clever combinatorial reduc-
tions due independently to Fisher [81] and Kastelyn [132]. Globerson
and Jaakkola [94] exploit these facts in order to derive a variational
relaxation based on convex combination of planar subgraphs, as well
as iterative algorithms for computing the optimal bound. They provide
experimental results for various types of graphs (both grids and fully
connected graphs), with results superior to the TRW relaxation (7.11)
for most coupling strengths, albeit with higher computational cost. As
they point out, it should also be possible to combine hypertrees with
planar graphs to form composite approximations.

7.3 Other Convex Variational Methods

The previous section focused exclusively on variational methods based
on the idea of convex combinations, as stated in Equation (7.7). How-
ever, not all convex variational methods need arise in this way; more
generally, a convex variational method requires only (a) some type of

7.3 Other Convex Variational Methods

183
∗ (negative entropy), and
convex approximation to the dual function A
(b) convex outer bound on the set M. This basic two-step procedure
can be used to derive many convex relaxations of the marginalization
problem.

7.3.1 Semideﬁnite Constraints and Log-determinant Bound

We illustrate this two-step procedure by describing a log-determinant
relaxation for discrete Markov random ﬁelds [248]. This method diﬀers
qualitatively from the previously described Bethe/Kikuchi methods, in
that it uses a semideﬁnite outer bound on the marginal polytope M(G).
Although the basic ideas are more generally applicable, let us focus for
concreteness on the case of a binary random vector X ∈ {0,1}m, with
a distribution in the Ising form:

(cid:4)(cid:6)

s∈V

(cid:22)
θstxsxt − A(θ)

.

(cid:6)

(s,t)

pθ(x) = exp

θsxs +

(7.20)

Without loss of generality,1 we assume that the underlying graph is
the complete graph Km, so that the marginal polytope of interest is
M(Km). With this set-up, the mean parameterization consists of the
vector µ ∈ M(Km) ⊂ Rm+(m
2 ), with elements µs = E[Xs] for each node,
and µst = E[XsXt] for each edge.
First, we describe how to approximate the negative dual function
−A
∗, or entropy function. An important characterization of the mul-
tivariate Gaussian is as the maximum entropy distribution subject to

covariance constraints [57]. In particular, the diﬀerential entropy h((cid:9)X)
of any continuous random vector (cid:9)X is upper bounded by the entropy
where cov((cid:9)X) is the covariance matrix of (cid:9)X. The upper bound (7.21)

of a Gaussian with matched covariance. In analytical terms, we have

h((cid:9)X) ≤ 1

log detcov((cid:9)X) + m

log(2πe),

(7.21)

2

2

is not directly applicable to a random vector taking values in a dis-
crete space (since diﬀerential entropy in this case diverges to minus

1 A problem deﬁned on an arbitrary G = (V, E) can be embedded into the complete graph
by setting θst = 0 for all (s, t) /∈ E.

184 Convex Relaxations and Upper Bounds

inﬁnity). Therefore, in order to exploit this bound for the discrete
random vector X ∈ {0,1}m of interest, it is necessary to construct a
suitably matched continuous version of X. One method to do so is
by the addition of an independent random vector U, such that the
atoms in the distribution of X are smoothed out. In particular, let us

deﬁne the continuous random vector (cid:9)X := X + U, where U is inde-
the discrete entropy of X with the diﬀerential entropy of (cid:9)X — that is,
h((cid:9)X) = H(X); see Wainwright and Jordan [248] for the proof. Since X
yields cov((cid:9)X) = cov(X) + 1
"

and U are continuous by construction, a straightforward computation
12 Im, so Equation (7.21) yields the upper

pendent of X, with independent components distributed uniformly as
Us ∼ U[− 1
2 , 1
2]. A key property of this construction is that it matches

bound

#

H(X) ≤ 1
2

log det

cov(X) +

1
12 Im

+ m
2

log(2πe).

Second, we need to provide an outer bound on the marginal polytope
for which the entropy approximation above is well deﬁned. The simplest
such outer bound is obtained by observing that the covariance matrix
cov(X) must always be positive semideﬁnite. (Indeed, for any vector
a ∈ Rm, we have (cid:19)a, cov(X)a(cid:20) = var((cid:19)a, X(cid:20)) ≥ 0.) Note that elements
of the matrix cov(X) can be expressed in terms of the mean parameters
µs and µst. In particular, consider the (m + 1) × (m + 1) matrix

""

#(cid:11)

(cid:12)#

N1[µ] = E

1 X

 .

µm
µ1m
µ2m
...

µ(m−1) m

µm

1
X
1
µ1
µ2
...



=

µ1
µ1
µ21
...

µ2
µ12
µ2
...
···
···

. . .
. . .
µ23
...
···
···

µm−1
. . .
. . . µ1(m−1)
. . .
...
···
µ(m−1)
··· µm(m−1)

. . .
...

µm−1 µ(m−1)1
µm

µm1

By the Schur complement formula [114], the constraint N1[µ] (cid:25) 0 is
equivalent to the constraint cov(X) (cid:25) 0. Consequently, the set

S1(Km) := {τ ∈ Rm+(m

2 ) | N1[τ] (cid:25) 0}

7.3 Other Convex Variational Methods

185

is an outer bound on the marginal polytope M(Km). It is not diﬃcult
to see that the set S1(Km) is closed, convex, and also bounded, since
it is contained within the hypercube [0,1]m+(m
2 ). Again, our switch in
notation from µ to τ is deliberate, since vectors τ belonging to the
semideﬁnite constraint set S1(Km) need not be globally consistent (see
Section 9 for more details).

We now have the two necessary ingredients to deﬁne a convex varia-
tional principle based on a log-determinant relaxation [248]. In addition
to the constraint τ ∈ S1(Km), one might imagine enforcing other con-
straints (e.g., the linear constraints deﬁning the set L(G)). Accordingly,
let B(Km) denote any convex and compact outer bound on M(Km) that
is contained within S1(Km). With this notation, the cumulant func-
tion A(θ) is upper bounded by the log-determinant convex surrogate
BLD(θ), deﬁned by the variational problem

(cid:7)

(cid:12)(cid:8)

(cid:11)

1
12

max

(cid:19)θ, τ(cid:20) +

1
2

+ m
2

log(2πe),

log det

N1[τ] +

blkdiag[0, Im]

τ∈B(Km)
(7.22)
where blkdiag[0, Im] is an (m + 1) × (m + 1) block-diagonal matrix. By
enforcing the inclusion B(Km) ⊆ S1(Km) we guarantee that the matrix
N1[τ], and hence the matrix sum
1
12

blkdiag[0, Im]

N1[τ] +

will always be positive semideﬁnite. Importantly, the optimization
problem (7.22) is a standard determinant maximization problem, for
which eﬃcient interior point methods have been developed [e.g., 235].
Wainwright and Jordan [248] derive an eﬃcient algorithm for solving
a slightly weakened form of the log-determinant problem (7.22), and
provide empirical results for various types of graphs. Banerjee et al. [8]
exploit the log-determinant relaxation (7.22) for a sparse model selec-
tion procedure, and develop coordinate-wise algorithms for solving a
broader class of convex programs.

7.3.2 Other Entropy Approximations and Polytope Bounds

There are many other approaches, using diﬀerent approximations to
the entropy and outer bounds on the marginal polytope, that lead

186 Convex Relaxations and Upper Bounds

to interesting convex variational principles. For instance, Globerson
and Jaakkola [95] exploit the notion of conditional entropy decompo-
sition in order to construct whole families of upper bounds on the
entropy, including as a special case the hypertree-based entropy bounds
that underlie the reweighted Bethe/Kikuchi approaches. Sontag and
Jaakkola [219] examine the eﬀect of tightened outer bounds on the
marginal polytope, including the so-called cycle inequalities [69, 187].
Among other issues, they examine the diﬀering eﬀects of changing
the entropy approximation versus reﬁning the outer bound on the
marginal polytope. These questions remain an active and ongoing area
of research.

7.4 Algorithmic Stability

As discussed earlier, an obvious beneﬁt of approximate marginaliza-
tion methods based on convex variational principles is the resulting
uniqueness of the minima, and hence lack of dependence on algorithmic
details, or initial conditions. In this section, we turn to a less obvious
but equally important beneﬁt of convexity, of particular relevance in a
statistical setting. More speciﬁcally, in typical applications of graphi-
cal models, the model parameters or graph topologies themselves are
uncertain. (For instance, they may have been estimated from noisy or
incomplete data.) In such a setting, then, it is natural to ask whether
the output of a given variational method remains stable under small
perturbations to the model parameters. Not all variational algorithms
are stable in this sense; for instance, both mean ﬁeld methods and the
ordinary sum-product algorithm can be highly unstable, with small
perturbations in the model parameters leading to very large changes in
the ﬁxed point(s) and outputs of the algorithm.

In this section, we show that any variational method based on a
suitable convex optimization problem — in contrast to mean ﬁeld and
ordinary sum-product — has an associated guarantee of Lipschitz sta-
bility. In particular, let τ(θ) denote the output when some variational
method is applied to the model pθ. Given two norms (cid:31)·(cid:31)a and (cid:31)·(cid:31)b,
we say that the method is globally Lipschitz stable if there exists some

7.4 Algorithmic Stability

187

(cid:31)τ(θ) − τ(θ

(cid:4)

)(cid:31)a ≤ L(cid:31)θ − θ

(cid:4)(cid:31)b,

ﬁnite constant L such that

(cid:4) is small, then the diﬀerence (cid:31)τ(θ) − τ(θ

(7.23)
(cid:4) ∈ Ω. This deﬁnition is one way of formalizing the notion of
for any θ, θ
(cid:4)(cid:31)b between
algorithmic stability: namely, that if the diﬀerence (cid:31)θ − θ
(cid:4))(cid:31)a
models indexed by θ and θ
between the algorithm’s outputs is correspondingly small. As an illus-
tration, Figure 7.3 compares the behavior of the ordinary sum-product
algorithm — known to be instable in certain regimes — to the tree-
reweighted sum-product algorithm. Note how the sum-product algo-
rithm degrades rapidly beyond a certain critical coupling strength,
whereas the performance of the tree-reweighted algorithm varies
smoothly as a function of the coupling strength.

Let us now try to gain some theoretical insight into which variational
methods satisfy this Lipschitz property. Consider a generic variational

Grid with attractive coupling

Upper
Opt. upper
Bethe

0.7

0.6

0.5

0.4

0.3

0.2

0.1

l

i

s
a
n
g
r
a
m
n

 

i
 
r
o
r
r

E

0

0

0.2

0.4

0.6

1

0.8
Coupling strength

1.2

1.4

1.6

1.8

2

Fig. 7.3 Contrast between the instability of ordinary sum-product and stability of tree-
reweighted sum-product [246]. Plots show the error between the true marginals and correct
marginals versus the coupling strength in a binary pairwise Markov random ﬁeld. Note that
the ordinary sum-product algorithm is very accurate up to a critical coupling (≈ 0.70), after
which it degrades rapidly. On the other hand, the performance of TRW message-passing
varies smoothly as a function of the coupling strength. The plot shows two versions of
the TRW sum-product algorithm, either based on uniform edge weights ρst = 1/2, or edge
weights optimized to minimize the upper bound.

188 Convex Relaxations and Upper Bounds

method of the form:

{(cid:19)θ, τ(cid:20) − B

∗

(τ)} ,

B(θ) = sup
τ∈L

(7.24)
where L is a convex outer bound on the set M, and B
∗ is a
∗. Let us consider the
convex approximation to the dual function A
properties of the surrogate function B that we have deﬁned. As
mentioned previously, it is always a convex function of θ. In terms
of properties beyond convexity, they are determined by the nature of
∗ is strictly convex; then
the function B
the optimum (7.24) is uniquely attained, so that Danskin’s theorem [21]
ensures that B is diﬀerentiable.

∗. For instance, suppose that B

In terms of Lipschitz stability, it turns out that a somewhat stronger
notion of convexity is required; in particular, a diﬀerentiable function
f : Rd → R is strongly convex with parameter c if for all y, z ∈ Rd,

f(z) ≥ f(y) + (cid:19)∇f(y), z − y(cid:20) + c
2

(cid:31)z − y(cid:31)2.

(7.25)

2

Note that any diﬀerentiable convex function satisﬁes this inequal-
ity (7.25) with c = 0; the essence of strong convexity is that the same
(cid:31)z − y(cid:31)2. (In fact, an equivalent
inequality is satisﬁed with slack c
2
characterization of strong convexity is to require that the function
(cid:31)z(cid:31)2 be convex [112].) In the setting of the convex surro-
f(z) − c
gate (7.24), suppose that the function B is strictly convex, and the (neg-
∗ is strongly convex, say with parameter
ative) entropy approximation B
1/L > 0. Under this assumption, it can be shown [241] that the output
τ(θ) = ∇B(θ) of the variational method is Lipschitz stable, in the sense
of deﬁnition (7.23), with parameter L and norms (cid:31)·(cid:31)a = (cid:31)·(cid:31)b = (cid:31)·(cid:31)2.
Thus, when using variational methods of the form (7.24), the
issue of algorithmic stability reduces to strong convexity of the neg-
∗. What existing variational methods
ative entropy approximation B
are based on strongly convex entropy approximations? For instance,
the tree-reweighted Bethe entropy (7.10) is strongly convex [241]
for any pairwise Markov random ﬁeld, so that as a corollary, the
tree-reweighted sum-product algorithm is guaranteed to be globally
Lipschitz stable. This Lipschitz stability provides a theoretical expla-
nation of the behavior illustrated in Figure 7.3. Similarly, empirical

7.5 Convex Surrogates in Parameter Estimation

189

results due to Wiegerinck [260] show that suitably reweighted forms of
generalized belief propagation (GBP) also behave in a stable manner
(unlike standard GBP), and this stability can be conﬁrmed theoreti-
cally via strong convexity. It can also be shown that the log-determinant
relaxation (7.22) is Lipschitz stable.

7.5 Convex Surrogates in Parameter Estimation

Until now, we have discussed convex variational methods in the context
of computing approximations to the cumulant function value A(θ), as
well as approximate mean parameters µ. Here, we discuss an alterna-
tive use of convex surrogates of the form (7.24), namely for approx-
imate parameter estimation. Recall from Section 6 our discussion of
maximum likelihood (ML) estimation in exponential families: it entails
maximizing the rescaled log likelihood, given by

1 ) = (cid:10)(θ) = (cid:19)θ,(cid:3)µ(cid:20) − A(θ),

(cid:10)(θ; X n

(cid:10)

n

where (cid:3)µ := 1
the derivative of the log likelihood takes the form ∇(cid:10)(θ) =(cid:3)µ − µ(θ),

n
i=1 φ(X i) is the empirical expectation of the suﬃ-
1 = (X1, . . . , X n). Recall also that

cient statistics given the data X n

(7.26)

where µ(θ) = Eθ[φ(X)] are the mean parameters under the current
model parameter. As discussed in Section 6, this fact motivates a
natural approach to approximate parameter estimation, in which the
true model parameters µ(θ) are approximated by the output τ(θ) of
some variational method. For instance, this approach has frequently
been suggested, using sum-product to compute the approximate mean
parameters τ(θ). Such heuristics may yield good results in some set-
tings; however, if the underlying variational method is nonconvex, such
a heuristic cannot be interpreted as minimizing an approximation to
the likelihood. Indeed, given multiple ﬁxed points, its behavior can be
unstable and erratic; the papers [241, 243] provide some cautionary
instances of poor behavior with ordinary sum-product.

7.5.1 Surrogate Likelihoods

On the other hand, the perspective of convex surrogates to A, of
the form (7.24), suggests a related but more principled method for

190 Convex Relaxations and Upper Bounds

approximate ML estimation, based on maximizing a concave approx-
imation to the likelihood. Let us assume that the outer bound L is
∗ is strictly convex,
compact and the negative entropy approximation B
so that the maximum (7.24) is uniquely attained, say at some τ(θ) ∈ L.
Recall that Danskin’s theorem [21] shows that the convex surrogate B
is diﬀerentiable, with ∇B(θ) = τ(θ). (Note the parallel with the gradi-
ent ∇A, and its link to the mean parameterization, as summarized in
Proposition 3.1). Given a convex surrogate B, let us deﬁne the associ-
ated surrogate likelihood as

1 ) = (cid:10)B(θ) := (cid:19)θ,(cid:3)µ(cid:20) − B(θ).

(cid:10)B(θ; X n

(7.27)

Assuming that B is strictly convex, then this surrogate likelihood is
strictly concave, and so (at least for compact parameter spaces Ω), we
have the well-deﬁned surrogate ML estimate

(cid:9)θB := arg max

θ∈Ω

(cid:10)B(θ; X n

1 ).

Note that when B upper bounds the true cumulant function (as in the
convex variational methods described in Section 7.1), then the surro-

gate likelihood (cid:10)B lower bounds the true likelihood, and(cid:9)θB is obtained

from maximizing this lower bound.

7.5.2 Optimizing Surrogate Likelihoods

In general, it is relatively straightforward to compute the surrogate

estimate (cid:9)θ =(cid:9)θB. Indeed, from our discussion above, the derivative of
the surrogate likelihood is ∇(cid:10)B(θ) =(cid:3)µ − τ(θ), where τ(θ) = ∇B(θ) are
used to compute (cid:9)θB.

the approximate mean parameters computed by the variational method
associated with B. Since the optimization problem is concave, a stan-
dard gradient ascent algorithm (among other possibilities) could be

Interestingly, in certain cases, the unregularized surrogate MLE can
be speciﬁed in closed form, without the need for any optimization. As
an example, consider the reweighted Bethe surrogate (7.11), and the
associated surrogate likelihood. The surrogate MLE is deﬁned by the

ﬁxed point relation ∇(cid:10)B((cid:9)θ) = 0, which has a very intuitive interpre-
tation. Namely, the model parameters (cid:9)θ are chosen such that, when

7.5 Convex Surrogates in Parameter Estimation

the TRW sum-product updates (7.12) are applied to the model p(cid:4)θ, the

resulting pseudo mean parameters τ((cid:9)θ) computed by the algorithm are
equal to the empirical mean parameters (cid:3)µ. Assuming that the empiri-
cal mean vector has strictly positive elements, the unique vector(cid:9)θ with

191

this property has the closed-form expression:

(cid:9)θs;j = log(cid:3)µs;j,
(cid:9)θst;jk = ρst log

and

(cid:3)µst;jk
(cid:3)µs;j(cid:3)µt;k

.

(7.28a)

(7.28b)

∀ s ∈ V, j ∈ Xs,
∀ (s, t) ∈ E, (j, k) ∈ Xs × Xt,
Here(cid:3)µs;j =(cid:3)E[I j(Xs)] is the empirical probability of the event {Xs = j},
and(cid:3)µst;jk is the empirical probability of the event {Xs = j, Xt = k}. By
construction, the vector(cid:9)θ deﬁned by Equation (7.28) has the property
that (cid:3)µ are the pseudomarginals associated with mode p(cid:4)θ. The proof of

this fact relies on the tree-based reparameterization interpretation of
the ordinary sum-product algorithm, as well as its reweighted exten-
sions [243, 246]; see Section 4.1.4 for details on reparameterization.
Similarly, closed-form solutions can be obtained for reweighted forms
of Kikuchi and region graph approximations (Section 7.2.2), and con-
vexiﬁed forms of expectation-propagation and other moment-matching
algorithms (Section 7.2.3). Such a closed-form solution eliminates the
need for any iterative algorithms in the complete data setting (as
described here), and can substantially reduce computational overhead
if a variational method is used within an inner loop in the incomplete
data setting.

7.5.3 Penalized Surrogate Likelihoods

ter to maximize a penalized likelihood function(cid:9)(cid:10)(θ; λ) := (cid:10)(θ) − λR(θ),

Rather than maximizing the log likelihood (7.26) itself, it is often bet-

where λ > 0 is a regularization constant and R is a penalty func-
tion, assumed to be convex but not necessarily diﬀerentiable (e.g., (cid:10)1
penalization). Such procedures can be motivated either from a frequen-
tist perspective (and justiﬁed in terms of improved loss and risk), or
from a Bayesian perspective, where the quantity λR(θ) might arise
from a prior over the parameter space. If maximization of the likeli-
hood is intractable then regularized likelihood is still intractable, so let

192 Convex Relaxations and Upper Bounds

ized surrogate likelihood (RSL)(cid:9)(cid:10)B(θ; λ) := (cid:10)B(θ) − λR(θ). Again, given

us consider approximate procedures based on maximizing a regular-

that (cid:10)B is convex and diﬀerentiable, this optimization problem could
be solved by a variety of standard methods.

Here, we describe an alternative formulation of optimizing the
penalized surrogate likelihood, which exploits the variational manner
in which the surrogate B was deﬁned (7.24). If we reformulate the
problem as one of minimizing the negative RSL, substituting the deﬁ-
nition (7.24) yields the equivalent saddlepoint problem:

inf
θ∈Ω

{−(cid:19)θ,(cid:3)µ(cid:20) + B(θ) + λR(θ)}
0
−(cid:19)θ,(cid:3)µ(cid:20) + sup
{(cid:19)θ, τ −(cid:3)µ(cid:20) − B

= inf
θ∈Ω
= inf
θ∈Ω

τ∈L

sup
τ∈L

1
(τ)} + λR(θ)

{(cid:19)θ, τ(cid:20) − B

∗

∗

(τ) + λR(θ)}.

Note that this saddlepoint problem involves convex minimization and
concave maximization; therefore, under standard regularity assump-
tions (e.g., either compactness of the constraint sets, or coercivity of
the function; see Section VII of Hiriart-Urruty and Lemar´echal [112]),
we can exchange the sup and inf to obtain

{−(cid:10)B(θ) + λR(θ)} = sup

inf
θ∈Ω

∗

{(cid:19)θ, τ −(cid:3)µ(cid:20) − B
0&
τ −(cid:3)µ
(cid:24)(cid:8)
(cid:23) τ −(cid:3)µ

(τ) − λsup
θ∈Ω
(τ) − λ R
∗
Ω

θ,

λ

∗

∗

,

λ

(cid:7)
τ∈L inf
θ∈Ω
(cid:7)
−B
−B

= sup
τ∈L

= sup
τ∈L

(τ) + λR(θ)}

1(cid:8)
’ − R(θ)

(7.29)

∗
where R
Ω is the conjugate dual function of R(θ) + I Ω(θ). Consequently,
∗
Ω, max-
assuming that it is feasible to compute the dual function R
imizing the RSL reduces to an unconstrained optimization problem
∗ used to deﬁne the surrogate function B. We
involving the function B
illustrate with a particular family of examples:

Example 7.3 (Regularized Surrogate Bethe Likelihood). Sup-
pose that we use the surrogate function BT(θ; ρe) deﬁned in

7.5 Convex Surrogates in Parameter Estimation

193

Theorem 7.2 to form a surrogate likelihood (cid:10)B, and that for our reg-
ularizing function, we use an (cid:10)q norm (cid:31)θ(cid:31)q with q ≥ 1. For the dis-
crete Markov random ﬁelds to which the reweighted Bethe surrogate
BT(θ; ρe) applies, the parameter space is simply Ω = Rd, so that we can
calculate

∗

R

=

{(cid:19)θ, τ(cid:20) − (cid:31)θ(cid:31)q}

(cid:4)
(τ) = sup
θ∈Rd
0
+∞ otherwise,
(cid:12)

(cid:11) − B

(τ)

=

∗

using the fact that (cid:31)θ(cid:31)q = sup(cid:19)τ(cid:19)
lem (7.29) takes the form:

sup
(cid:19)τ−(cid:3)µ(cid:19)

q(cid:2)≤λ

if (cid:31)τ(cid:31)q(cid:2) ≤ 1, where 1/q

(cid:4) = 1 − 1/q,

q(cid:2)≤1(cid:19)τ, θ(cid:20). Thus, the dual RSL prob-
(cid:4)(cid:6)
(cid:22)

(cid:6)

sup
(cid:19)τ−(cid:3)µ(cid:19)

q(cid:2)≤λ

s∈V

Hs(τs) −

ρstIst(τst)

.

(s,t)∈E

Note that this problem has a very intuitive interpretation: it involves
maximizing the Bethe entropy, subject to an (cid:10)q(cid:2)-norm constraint on

the distance to the empirical mean parameters (cid:3)µ. As pointed out by

several authors [63, 71], a similar dual interpretation also exists for reg-
ularized exact maximum likelihood. The choice of regularization trans-
lates into a certain uncertainty or robustness constraint in the dual
domain. For instance, given (cid:10)2 regularization (q = 2) on θ, we have
(cid:4) = 2 so that the dual regularization is also (cid:10)2-based. On the other
q
hand, for (cid:10)1-regularization, (q = 1) the corresponding dual norm is (cid:10)∞
(cid:4) = +∞), so that we have box constraints in the dual domain.
(q

from a convex surrogate. These properties are straightforward to ana-

There remain a large number of open research questions associ-
ated with the use of convex surrogates for approximate estimation. An
immediate statistical issue is to understand the consistency, asymptotic

normality and other issues associated with an estimate (cid:9)θB obtained
lyze, since the estimate(cid:9)θB is a particular case of an M-estimator [233].
we are guaranteed that(cid:9)θB converges in probability to the minimizer of

Consequently, under mild conditions on the surrogate (so as to ensure
uniform convergence of the empirical version to the population version),

194 Convex Relaxations and Upper Bounds

the population surrogate likelihood — namely

(cid:14)(cid:19)θ, µ(cid:20) − B(θ)
(cid:15)

∗
B = arg min
θ∈Ω

θ

,

(7.30)

where µ = Eθ∗[φ(X)] are the mean parameters under the true distribu-
tion pθ∗. When the convex surrogate is strictly convex, the unique min-
∗
B such that
imizer of the population version is the parameter vector θ
B) = µ. Consequently, unless the mapping ∇B coincides with the
∇B(θ
∗
mapping ∇A, the estimators based on convex surrogates of the type
described here can be inconsistent, meaning that the random variable

(cid:9)θB may not converge to the true model parameter θ

∗.

Of course, such inconsistency is undesirable if the true parameter
∗ is of primary interest. However, in other settings, it may actually be
θ
desirable to use an inconsistent estimator. For instance, suppose that
we are interested in constructing a model with good predictive power,
and moreover that in constructing new predictions, we are constrained
to use only “tractable” algorithms. For instance, we might be prevented
from computing the exact likelihoods and marginal distributions of a
graphical model, but instead required to use only approximate algo-
rithms, such as sum-product or expectation-propagation. In such set-
tings, one can imagine that it might be beneﬁcial to use an “incorrect”
model, since we are applying an approximate algorithm to generate pre-
dictions. Based on this intuition, Wainwright [241] proves that when
performing prediction using the reweighted sum-product algorithm, the
parameter estimates from the tree-reweighted Bethe surrogate, even
though they are diﬀerent from the true model, yield lower prediction
error than an oracle given access to the true model, but also required
to use the reweighted sum-product algorithm. It is likely that such
phenomena also arise in other settings where computation is limited.

8

Integer Programming, Max-product, and Linear

Programming Relaxations

Thus far, the bulk of our discussion has focused on variational methods
that, when applied to a given model pθ, yield approximations to the
mean parameters µ = Eθ[φ(X)], as well as to the log partition or cumu-
lant function A(θ). In this section, we turn our attention to a related
but distinct problem — namely, that of computing a mode or most
probable conﬁguration associated with the distribution pθ. It turns out
that the mode problem has a variational formulation in which the set M
of mean parameters once again plays a central role. More speciﬁcally,
since mode computation is of signiﬁcant interest for discrete random
vectors, the marginal polytopes M(G) play a central role through much
of this section.

8.1 Variational Formulation of Computing Modes

Given a member pθ of some exponential family, the mode computation
∗ ∈ X m that belongs to
problem refers to computing a conﬁguration x
the set

arg max
x∈X m

pθ(x) := {y ∈ X m | pθ(y) ≥ pθ(x) ∀ x ∈ X m} .

(8.1)

195

196 Max-product and LP Relaxations

We assume that at least one mode exists, so that this arg max set is
nonempty. Moreover, it is convenient for development in the sequel to
note the equivalence

arg max
x∈X m

pθ(x) = arg max
x∈X m

(cid:19)θ, φ(x)(cid:20),

(8.2)

which follows from the exponential form of the density pθ, and the fact
that the cumulant function A(θ) does not depend on x.

It is not immediately obvious how the MAP problem (8.2) is related
to the variational principle from Theorem 3.4. As it turns out, the link
lies in the notion of the “zero-temperature limit”. We begin by provid-
ing intuition for the more formal result to follow. From its deﬁnition and
Theorem 3.4, for any parameter vector θ ∈ Ω, the cumulant function
has the following two representations:

(cid:13)

(cid:14)(cid:19)θ, φ(x)(cid:20)(cid:15)

ν(dx)

A(θ) := log

= sup
µ∈M

exp
{(cid:19)θ, µ(cid:20) − A

∗

(µ)} .

(8.3)

Now suppose that we rescale the canonical parameter θ by some scalar
β > 0. For the sake of this argument, let us assume that βθ ∈ Ω for all
β > 0. Such a rescaling will put more weight, in a relative sense, on
regions of the sample space X m for which (cid:19)θ, φ(x)(cid:20) is large. Ultimately,
as β → +∞, probability mass should remain only on conﬁgurations x
∗
in the set arg maxx∈X m(cid:19)θ, φ(x)(cid:20).

This intuition suggests that the behavior of the function A(βθ)
should have a close connection to the problem of computing
maxx∈X m(cid:19)θ, φ(x)(cid:20). Since A(βθ) may diverge as β → +∞, it is most nat-
ural to consider the limiting behavior of the scaled quantity A(βθ)/β.
More formally, we state the following:
Theorem 8.1 For all θ ∈ Ω, the problem of mode computation has
the following alternative representations:
(cid:19)θ, φ(x)(cid:20) = max
µ∈ ¯M
(cid:19)θ, φ(x)(cid:20) = lim
β→+∞

(cid:19)θ, µ(cid:20),

max
x∈X m

max
x∈X m

A(βθ)

.

β

(8.4b)

and

(8.4a)

8.1 Variational Formulation of Computing Modes

197

We provide the proof of this result in Appendix B.5; here we
elaborate on its connections to the general variational principle (3.45),
stated in Theorem 3.4. As a particular consequence of the general
variational principle, we have

lim
β→+∞

A(βθ)

β

= lim
β→+∞

1
β

(cid:7)

sup
µ∈M

(cid:14)(cid:19)βθ, µ(cid:20) − A

(cid:15)
(cid:8)

∗

(µ)

= lim

β→+∞ sup
µ∈M

(cid:19)θ, µ(cid:20) − 1
β

∗
A

(µ)

.

In this context, one implication of Theorem 8.1 is that the order of
the limit over β and the supremum over µ can be exchanged. It is
important to note that such an exchange is not correct in general;
∗ (see
in this case, justiﬁcation is provided by the convexity of A
Appendix B.5 for details).
As with the variational principle of Theorem 3.4, only certain special
cases of the variational problem maxµ∈ ¯M(cid:19)θ, µ(cid:20) can be solved exactly in
a computationally eﬃcient manner. The case of tree-structured Markov
random ﬁelds on discrete random variables, discussed in Section 8.2,
is one such case; another important exactly solvable case is the Gauss
Markov random ﬁeld, discussed in Section 8.3 and Appendix C.3. With
reference to other (typically intractable) models, since the objective
function itself is linear, the sole source of diﬃculty is the set M, and
in particular, the complexity of characterizing it with a small number
of constraints. In the particular case of a discrete Markov random ﬁeld
associated with a graph G, the set M corresponds to the marginal
polytope M(G), as discussed previously in Sections 3 and 4. For a dis-
crete random vector, the mode-ﬁnding problem maxx∈X m(cid:19)θ, φ(x)(cid:20) is an
integer program (IP), since it involves searching over a ﬁnite discrete
space. An implication of Theorem 8.1, when specialized to this setting,
is that this IP is equivalent to a linear program over the marginal poly-
tope. Since integer programming problems are NP-hard in general, this
equivalence underscores the inherent complexity of marginal polytopes.
from an integer pro-
gram to a linear program over the convex hull of its solutions —
is a standard technique in integer programming and combinato-
rial optimization [e.g., 24, 103]. The ﬁeld of polyhedral combinatorics

This type of transformation — namely,

198 Max-product and LP Relaxations

[69, 103, 180, 212] is devoted to understanding the structure of poly-
topes arising from various classes of discrete problems. As we describe
in this section, the perspective of graphical models provides additional
insight into the structure of these marginal polytopes.

8.2 Max-product and Linear Programming on Trees

As discussed in Section 4, an important class of exactly solvable mod-
els are Markov random ﬁelds deﬁned on tree-structured graphs, say
T = (V, E). Our earlier discussion focused on the computation of mean
parameters and the cumulant function, showing that the sum-product
algorithm can be understood as an iterative algorithm for exactly solv-
ing the Bethe variational problem on trees [268, 269]. In this section, we
discuss the parallel link between the ordinary max-product algorithm
and linear programming [245].
For a discrete MRF on the tree, the set M is given by the marginal
polytope M(T ), whose elements consist of a marginal probability vector
µs(·) for each node, and joint probability matrix µst(· , ·) for each edge
(s, t) ∈ E. Recall from Proposition 4.1 that for a tree, the polytope
M(T ) is equivalent to the constraint set L(T ), and so has a compact
description in terms of nonnegativity, local normalization, and edge
marginalization conditions. Using this fact, we now show how the mode-
ﬁnding problem for a tree-structured problem can be reformulated as
a simple linear program (LP) over the set L(G).

Using Eµs[θs(xs)] :=

µs(xs)θs(xs) to expectation under the
marginal distribution µs and with a similar deﬁnition for Eµst, let us
deﬁne the cost function

xs

(cid:10)

Eµs[θs(xs)] +

Eµst[θst(xs, xt)].

(cid:6)

s∈V

(cid:19)µ, θ(cid:20) :=

$(cid:6)

s∈V

(cid:6)

(s,t)∈E

%

With this notation, Theorem 8.1 implies that the MAP problem for a
tree is equivalent to

max
x∈X m

θs(xs) +

θst(xs, xt)

= max
µ∈L(T )

(cid:19)µ, θ(cid:20).

(8.5)

(cid:6)

(s,t)∈E

The left-hand side is the standard representation of the MAP problem
as an integer program, whereas the right-hand side — an optimization

8.2 Max-product and Linear Programming on Trees

199

problem over the polytope L(T ) with a linear objective function — is
a linear program.

We now have two links: ﬁrst, the equivalence between the origi-
nal mode-ﬁnding integer program and the LP (8.5), and second, via
Theorem 8.1, a connection between this linear program and the zero-
temperature limit of the Bethe variational principle. These links raise
the intriguing possibility: is there a precise connection between the max-
product algorithm and the linear program (8.5)? The max-product algo-
rithm — like its relative the sum-product algorithm — is a distributed
graph-based algorithm, which operates by passing a message Mts along
each direction t → s of each edge of the tree. For discrete random vari-
ables Xs ∈ {0,1, . . . , r − 1}, each message is a r-vector, and the mes-
sages are updated according to recursion

%

$

(cid:14)

(cid:15) (cid:2)

Mts(xs) ← κ max
xt∈Xt

exp

θst(xs, xt) + θt(xt)

u∈N(t)\s

Mut(xt)

.

(8.6)

The following result [245] gives an aﬃrmative answer to the question
above: for tree-structured graphs, the max-product updates (8.6) are a
Lagrangian method for solving the dual of the linear program (8.5).
This result can be viewed as the max-product analog to the con-
nection between sum-product and the Bethe variational problem on
trees, and its exactness for computing marginals, as summarized in
Theorem 4.2.
To set up the Lagrangian, for each xs ∈ Xs, let λst(xs) be a Lagrange
multiplier associated with the marginalization constraint Cts(xs) = 0,
where

Cts(xs) := µs(xs) −

µst(xs, xt).

(8.7)

(cid:6)

xt

Let N ⊂ Rd be the set of µ that are nonnegative and appropriately
normalized:

(cid:4)
µ ∈ Rd | µ ≥ 0,

(cid:6)

N :=

µs(xs) = 1,

µst(xs, xt) = 1

. (8.8)

(cid:6)

(cid:22)

With this notation, we have the following result:

xs

xs,xt

200 Max-product and LP Relaxations

Proposition 8.2 (Max-product and LP Duality). Consider the
dual function Q deﬁned by the following partial Lagrangian formulation
of the tree-structured LP (8.5):
 (cid:6)
!
L(µ; λ), where

(cid:6)

(cid:6)

Q(λ) := max
µ∈N
L(µ; λ) := (cid:19)θ, µ(cid:20) +

λts(xs)Cts(xs) +

λst(xt)Cst(xt)

.

(s,t)∈E(T )

xs

xt

∗ of the max-product updates (8.6), the vector
∗, where the logarithm is taken elementwise, is an optimal

For any ﬁxed point M
∗ := log M
λ
solution of the dual problem minλQ(λ).

Proof. We begin by deriving a convenient representation of the dual
function Q. First, let us convert the tree to a directed version by ﬁrst
designating some node, say node 1 without loss of generality, as the
root, and then directing all the edges from parent to child t → s. With
regard to this rooted tree, the objective function (cid:19)θ, µ(cid:20) has the alter-
native decomposition:

(cid:12)

µ1(x1)θ1(x1) +

µst(xs, xt)

θst(xs, xt) + θs(xs)

.

(cid:6)

(cid:6)

t→s

xt,xs

(cid:11)

(cid:6)

x1

With this form of the cost function, the dual function can be put into
the form

(cid:7)(cid:6)
Q(λ) := max
(cid:6)
(cid:6)
µ∈N

x1

µ1(x1)ν1(x1)

(cid:11)
νst(xs, xt) − νt(xt)

(cid:12)(cid:8)

,

(8.9)

where the quantities νs and νst are deﬁned in terms of λ and θ as:

νt(xt) = θt(xt) +

λut(xt),

and

(8.10a)

νst(xs, xt) = θst(xs, xt) + θs(xs) + θt(xt)

λus(xs) +

λut(xt).

(8.10b)

+

t→s

xt,xs

µst(xs, xt)

(cid:6)

u∈N(t)

(cid:6)

+

u∈N(s)\t

(cid:6)

u∈N(t)\s

8.2 Max-product and Linear Programming on Trees

201
Taking the maximum over µ ∈ N in Equation (8.9) yields that the dual
function has the explicit form:

(cid:11)

(cid:12)

(cid:6)

t→s

Q(λ) = max

x1

ν1(x1)

+

max
xs,xt

(cid:11)
(cid:12)
νst(xs, xt) − νt(xt)

.

(8.11)

Using the representation (8.11), we now have the necessary ingre-
dients to make the connection to the max-product algorithm. Given a
vector of messages M in the max-product algorithm, we use it to deﬁne
a vector of Lagrange multipliers via λ = log M, where the logarithm is
taken elementwise. With a bit of algebra, it can be seen that a message
∗ is a ﬁxed point of the max-product updates (8.6) if and
vector M
∗, satisfy the
∗
s and ν
only if the associated ν
edgewise consistency condition

∗
st, as deﬁned by λ

∗ := log M

∗
st(xs, xt) = ν

∗
t (xt) + κst

max
xs

(8.12)
for all xt ∈ Xt, where κst is a constant independent of x. We now show
that any such λ

∗ is a dual optimal solution.

ν

We ﬁrst claim that under the edgewise consistency condition on a
tree-structured graph, we can always ﬁnd at least one conﬁguration
∗
∗
∗
∗ = (x
m) that satisﬁes the conditions:
2, . . . , x
1, x
x

∗
x
s

∈ arg max
∗
s (xs)
xs
∗
st(xs, xt)
ν

ν

xs,xt

t ) ∈ arg max
∗
∗
(x
s, x

∀ s ∈ V ,
∀ (s, t) ∈ E.

and

(8.13a)

(8.13b)

Indeed, such a conﬁguration can be constructed recursively as fol-
∗
1 to achieve the maximum
lows. First, for the root node 1, choose x
1(x1). Second, for each child t ∈ N(1), choose xt to maxi-
∗
maxx1 ν
∗
mize νt,1(xt, x
1), and then iterate the process. The edgewise consis-
∗
∗
∗
m) con-
tency (8.12) guarantees that any conﬁguration (x
2, . . . , x
1, x
structed in this way satisﬁes the conditions (8.13a) and (8.13b).

The edgewise consistency condition (8.12) also guarantees the fol-

lowing equalities:

st(xs, xt) − ν
∗
[ν

max
xs,xt

t (xt) + κst − ν
∗
∗
t (xt)] = max
[ν
xt
= κst
t ) − ν
∗
∗
∗
st(x
= ν
s, x

∗
∗
t (x
t ).

∗
t (xt)]

202 Max-product and LP Relaxations

Q(λ

∗

) = ν

∗
∗
1(x
1) +

Next, applying the deﬁnition (8.10) of ν

Q(λ

∗

∗
) = θ1(x
1) +

(cid:6)
(cid:6)

t→s

(cid:11)
(cid:11)

t→s

(cid:12)
(cid:12)

Combining these relations yields the following expression for the dual
value at λ

∗:

.

∗
∗
t (x
t )

t ) − ν
∗
∗
∗
st(x
ν
s, x
∗ and simplifying, we ﬁnd that
∗
∗
∗
t ) + θs(x
θst(x
s)
s, x

.

s[xs] and
s[xs] is an indicator function for
∗ is primal feasible; moreover, the

(cid:12)

∗
s(xs) := I x∗
Now consider the primal solution deﬁned by µ

∗
t

[xt], where I x∗
}. It is clear that µ
(cid:6)

s[xs] I x

(cid:6)

∗
1(x1)θ1(x1) +
µ

∗
st(xs, xt) = I x∗
µ
the event {xs = x
∗
s
primal cost is equal to

(cid:6)
(cid:6)
(cid:11)
which is precisely equal to Q(λ
∗
programs [24], the pair (µ
, λ

∗
= θr(x
r) +

t→s

t→s

x1

∗
st(xs, xt)
µ

θst(xs, xt) + θs(xs)

xt,xs
∗
∗
∗
θst(x
t ) + θs(x
s)
s, x
∗). Therefore, by strong duality for linear
∗) is primal–dual optimal.

,

(cid:11)

(cid:12)

Remark 8.1 A careful examination of the proof of Proposition 8.2
shows that several steps rely heavily on the fact that the underlying
graph is a tree. In fact, the corresponding result for a graph with cycles
fails to hold, as we discuss at length in Section 8.4.

8.3 Max-product For Gaussians and Other Convex

Problems

Multivariate Gaussians are another special class of Markov random
ﬁelds for which there are various guarantees of correctness associated
with the max-product (or min-sum) algorithm. Given an undirected
graph G = (V, E), consider a Gaussian MRF in exponential form:

(cid:14)(cid:19)θ, x(cid:20) + (cid:19)(cid:19)Θ, xxT(cid:20)(cid:20) − A(θ,Θ)
(cid:15)
0(cid:6)
1
Θstxsxt − A(θ,Θ)

(cid:6)

θsxs +

.

s∈V

s,t

(8.14)

p(θ,Θ)(x) = exp

= exp

8.3 Max-product For Gaussians and Other Convex Problems

203

Recall that the graph structure is reﬂected in the sparsity of the matrix
Θ, with Θuv = 0 whenever (u, v) /∈ E.

In Appendix C.3, we describe how taking the zero-temperature limit
for a multivariate Gaussian, according to Theorem 8.1, leads to either a
quadratic program, or a semideﬁnite program. There are various ways
in which these convex programs could be solved; here we discuss known
results for the application of the max-product algorithm.

To describe the max-product as applied to a multivariate Gaussian,
we ﬁrst need to convert the model into pairwise form. Let us deﬁne
potential functions of the form

γs(xs) = θsxs + θsx2

γst(xs, xt) = γss;t x2

∀ (s, t) ∈ E,

(8.15a)

(8.15b)

where the free parameters {γs, γss;t} must satisfy the constraint

and
s + 2Θstxsxt + γtt;s x2

t

s, ∀ s ∈ V,
(cid:6)

γs +

γss;t = Θss.

t∈N(s)

(cid:7)(cid:6)

s∈V

(cid:6)

(s,t)∈E

Under this condition, the multivariate Gaussian density (8.14) can
equivalently expressed as the pairwise Markov random ﬁeld

pγ(x) ∝ exp

γs(xs) +

γst(xs, xt)

.

(8.16)

(cid:8)

With this set-up, we can now describe the max-product message-
passing updates. For graphical models involving continuous random
variables, each message Mts(xs) is a real-valued function of the inde-
terminate xs. These functional messages are updated according to the
usual max-product recursion (8.6), with the potentials θs and θst in
Equation (8.6) replaced by their γs and γst analogs from the pair-
wise factorization (8.16). In general continuous models, it is computa-
tionally challenging to represent and compute with these functions,
as they are inﬁnite-dimensional quantities. An attractive feature of
the Gaussian problems these messages can be compactly paramete-
rized; in particular, assuming a scalar Gaussian random variable Xs at
each node, any message must be an exponentiated-quadratic function
of its argument, of the form Mts(xs) ∝ exp(axs + bx2
s). Consequently,

204 Max-product and LP Relaxations

max-product message-passing updates (8.6) can be eﬃciently imple-
mented with one recursion for the mean term (number a), and a second
recursion for the variance component (see the papers [250, 262] for fur-
ther details).

s = E[X2

s ] − µ2

For Gaussian max-product applied to a tree-structured problem,
the updates are guaranteed to converge, and compute both the correct
means µs = E[Xs] and variances σ2
s at each node [262].
For general graphs with cycles, the max-product algorithm is no longer
guaranteed to converge. However, Weiss and Freeman [250] and inde-
pendently Rusmevichientong and van Roy [205] showed that if Gaus-
sian max-product (or equivalently, Gaussian sum-product) converges,
then the ﬁxed point speciﬁes the correct Gaussian means µs, but
the estimates of the node variances σ2
s need not be correct. The cor-
rectness of Gaussian max-product for mean computation also follows
as a consequence of the reparameterization properties of the sum-
and max-product algorithms [242, 244]. Weiss and Freeman [250] also
showed that Gaussian max-product converges for arbitrary graphs if
the precision matrix (−Θ in our notation) satisﬁes a certain diagonal
dominance condition. This suﬃcient condition for convergence was sub-
stantially tightened in later work by Malioutov et al. [161], using the
notions of walk-summability and pairwise normalizability; see also the
paper [176] for further reﬁnements. Moallemi and van Roy [177] con-
sider the more general problem of maximizing an arbitrary function
of the form (8.16), where the potentials {γs, γst} are required only to
deﬁne a convex function. The quadratic functions (8.15) for the multi-
variate Gaussian are a special case of this general set-up. For this fam-
ily of pairwise separable convex programs, Moallemi and van Roy [177]
established convergence of the max-product updates under a certain
scaled diagonal dominance condition.

8.4 First-order LP Relaxation and Reweighted

Max-product

In this section, we return to Markov random ﬁelds with discrete random
variables, for which the mode-ﬁnding problem is an integer program,
as opposed to the quadratic program that arises in the Gaussian case.

8.4 First-order LP Relaxation and Reweighted Max-product

205

For a general graph with cycles, this discrete mode-ﬁnding problem
is known to be computationally intractable, since it includes as spe-
cial cases many problems known to be NP-complete, among them
MAX-CUT and related satisﬁability problems [131]. Given the com-
putational diﬃculties associated with exact solutions, it is appropriate
to consider approximate algorithms.

An important class of approximate methods for solving integer and
combinatorial optimization problems is based on linear programming
relaxation. The basic idea is to approximate the convex hull of the
solution set by a set of linear constraints, and solve the resulting linear
program. If the obtained solution is integral, then the LP relaxation is
tight, whereas in other cases, the obtained solution may be fractional,
corresponding to looseness of the relaxation. Frequently, LP relaxations
are developed in a manner tailored to speciﬁc subclasses of combinato-
rial problems [180, 236].

In this section, we discuss the linear programming (LP) relax-
ation that emerges from the Bethe variational principle, or its zero-
temperature limit. This LP relaxation, when specialized to particular
combinatorial problems — among them node cover, independent set,
matching, and satisﬁability problems — recovers various classical LP
relaxations as special cases. Finally, we discuss connections between this
LP relaxation and max-product message-passing. For general MRFs,
max-product itself is not a method for solving this LP, as we demon-
strate with a concrete counterexample [245]. However, it turns out that
suitably reweighted versions of max-product are intimately linked to
this LP relaxation, which provides an entry point to an ongoing line of
research on LP relaxations and message-passing algorithms on graphs.

8.4.1 Basic Properties of First-order LP Relaxation

For a general graph, the set L(G) no longer provides an exact charac-
terization of the marginal polytope M(G), but is always guaranteed to
outer bound it. Consequently, the following inequality is valid for any
graph:

max
x∈X m

(cid:19)θ, φ(x)(cid:20) = max
µ∈M(G)

(cid:19)θ, µ(cid:20) ≤ max
τ∈L(G)

(cid:19)θ, τ(cid:20).

(8.17)

206 Max-product and LP Relaxations

Since the relaxed constraint set L(G) is a polytope, the right-hand
side of Equation (8.17) is a linear program, which we refer to as the
ﬁrst-order LP relaxation.1 Most importantly, the right-hand side is a
linear program, where the number of constraints deﬁning L(G) grows
only linearly in the graph size, so that it can be solved in polynomial
time for any graph [211].

Special cases of this LP relaxation (8.17) have studied in past
and ongoing work by various authors,
including the special cases
of {0,1}-quadratic programs [105], metric labeling with Potts mod-
els [135, 48], error-control coding problems [76, 78, 239, 228, 50, 62],
independent set problems [180, 207], and various types of matching
problems [15, 116, 206]. We begin by discussing some generic proper-
ties of the LP relaxation, before discussing some of these particular
examples in more detail.

By standard properties of linear programs [211], the optimal value
of the relaxed LP must be attained by at least one an extreme point of
the polytope L(G). (A element of a convex set is an extreme point if it
cannot be expressed as a convex combination of two distinct elements
of the set; see Appendix A.2.4 for more background). We say that an
extreme point of L(G) is integral if all of its components are zero or one,
and fractional otherwise. By its deﬁnition, any extreme point M(G) is
of the form µy := φ(y), where y ∈ X m is a ﬁxed conﬁguration. Recall
that in the canonical overcomplete representation (3.34), the suﬃcient
statistic vector φ consists of {0,1}-valued indicator functions, so that
µy = φ(y) is a vector with {0,1} components. The following result spec-
iﬁes the relation between extreme points of M(G) and those of L(G):

Proposition 8.3 The extreme points of L(G) and M(G) are related
as follows:

(a) All the extreme points of M(G) are integral, and each one

is also an extreme point of L(G).

1 The term “ﬁrst-order” refers to its status as the ﬁrst in a natural hierarchy of relaxations,
based on the treewidth of the underlying graph, as discussed at more length in Section 8.5.

8.4 First-order LP Relaxation and Reweighted Max-product

207

(b) For any graph with cycles, L(G) also includes additional
extreme points with fractional elements that lie strictly out-
side M(G).

Proof. (a) Any extreme point of M(G) is of the form φ(y),
for
some conﬁguration y ∈ X m. Each of these extreme points has 0–1
components, and so is integral. Since L(G) is a polytope in

(cid:6)

(cid:6)

s∈V

d =

rs +

rsrt

(s,t)∈E

dimensions, in order to show that φ(y) is also an extreme point of L(G),
it is equivalent [24] to show that there are d constraints of L(G) that
are active at φ(y) and are also linearly independent. For any y ∈ X m,
we have I k(xs) = 0 for all k ∈ Xs\{ys}, and I k(xs)I l(xt) = 0 for all
(k, l) ∈ (Xs × Xt)\{ys, yt}. All of these active inequality constraints
are linearly independent, and there are a total of

(cid:4)

d

=

(rs − 1) +

(rsrt − 1) = d − m − |E|

(cid:6)

(s,t)∈E

(cid:6)

s∈V

such constraints. All of the normalization and marginalization con-
straints are also satisﬁed by the vector µy = φ(y), but not all of
them are linearly independent (when added to the active inequality
constraints). However, we can add a normalization constraint for each
vertex s = 1, . . . , m, as well as a normalization constraint for each edge
(s, t) ∈ E, while still preserving linear independence. Adding these
m + |E| equality constraints to the d
(cid:4) inequality constraints yields a
total of d linearly independent constraints of L(G) that are satisﬁed
by µy, which implies that it is an extreme point [24].

(b) Example 8.1 provides a constructive procedure for constructing
fractional extreme points of the polytope L(G) for any graph G with
cycles.

The distinction between fractional and integral extreme points is
crucial, because it determines whether or not the LP relaxation (8.17)
speciﬁed by L(G) is tight. In particular, there are only two possible

208 Max-product and LP Relaxations

outcomes to solving the relaxation:

(a) The optimum is attained at an extreme point of M(G), in
which case the upper bound in Equation (8.17) is tight, and
a mode can be obtained.

(b) The optimum is attained only at one or more fractional
extreme points of L(G), which lie strictly outside M(G). In
this case, the upper bound of Equation (8.17) is loose, and
the optimal solution to the LP relaxation does not specify
the optimal conﬁguration. In this case, one can imagine
various types of rounding procedures for producing near-
optimal solutions [236].

When the graph has cycles, it is possible to explicitly construct a frac-
tional extreme point of the relaxed polytope L(G).

Example 8.1 (Fractional Extreme Points of L(G)). As an illus-
tration, let us explicitly construct a fractional extreme point for the
simplest problem on which the ﬁrst-order relaxation (8.17) is not always
exact: a binary random vector X ∈ {0,1}3 following an Ising model on
the complete graph K3. Consider the canonical parameter θ shown in
matrix form in Figure 8.1(a). When βst < 0, then conﬁgurations with
xs (cid:12)= xt are favored, so that the interaction is repulsive. In contrast,
when βst > 0, the interaction is attractive, because it favors conﬁgura-
tions with xs = xt. When βst > 0 for all (s, t) ∈ E, it can be shown [138]
that the ﬁrst-order LP relaxation (8.17) is tight, for any choice of the
single node parameters {θs, s ∈ V }. In contrast, when βst < 0 for all
edges, then there are choices of θs, s ∈ V for which the relaxation breaks
down.

The following canonical parameter corresponds to a direction for
which the relaxation (8.17) is not tight, and hence exposes a frac-
tional extreme point. First, choose θs = (0, 0) for s = 1,2,3, and then
set βst = β < 0 for all edges (s, t), and use these values to deﬁne the
pairwise potentials θst via the construction in Figure 8.1(a). Observe
that for any conﬁguration x ∈ {0,1}3, we must have xs = xt for at least
one edge (s, t) ∈ E. Therefore, any µ ∈ M(G) must place nonzero mass

8.4 First-order LP Relaxation and Reweighted Max-product

209

τ

(cid:11)
"

Fig. 8.1 The smallest graph G = (V, E) on which the relaxation (8.17) can fail to be tight.
For βst ≥ 0 for all (s, t) ∈ E, the relaxation is tight for any choice of θs, s ∈ V . On the other
hand, if βst < 0 for all edges (s, t), the relaxation will fail for certain choices of θs, s ∈ V .
on at least one term of θ involving β, whence maxµ∈M(G)(cid:19)θ, µ(cid:20) < 0. In
fact, this optimal value is exactly equal to β < 0. On the other hand,
∗ ∈ L(G) formed by the singleton and
(cid:12)T
consider the pseudomarginal τ
pairwise pseudomarginals deﬁned as follows:
#

∗
s :=
∗
st =
τ
∗(cid:20) = 0. Since θα ≤ 0 for all elements α, this value
Observe that (cid:19)θ, τ
is the optimum of (cid:19)θ, τ(cid:20) over L(G), thereby showing that the relax-
ation (8.17) is not tight.
∗ is an extreme point of the polytope
∗. If (cid:19)θ, τ(cid:20) =
L(G), it is suﬃcient [24] to show that (cid:19)θ, τ(cid:20) < 0 for all τ (cid:12)= τ
0, then for all (s, t) ∈ E the pairwise pseudomarginals must be of the
form:

for s ∈ V ,
for (s, t) ∈ E.

Finally, to establish that τ

0.5 0.5

0
0.5

0.5
0

and

"
1 − αst

0

#

αst
0

τst :=

for some αst ∈ [0,1]. Enforcing the marginalization constraints on these
pairwise pseudomarginals yields the constraints α12 = α13 = α23 and
1 − α12 = α23, whence αst = 0.5 is the only possibility. Therefore, we
∗ is a fractional extreme
conclude that the pseudomarginal vector τ
point of the polytope L(G).

210 Max-product and LP Relaxations

Given the possibility of fractional extreme points in the ﬁrst-order
LP relaxation (8.5), it is natural to ask the question: do fractional
solutions yield partial information about the set of optimal solutions
to the original integer program? One way in which to formalize this
question is through the notion of persistence [105]. In particular, let-
ting O∗ := arg maxx∈X m(cid:19)θ, φ(x)(cid:20) denote the set of optima to an integer
program, we have:

Deﬁnition 8.1 Given a fractional solution τ to the LP relax-
ation (8.5), let I ⊂ V represent the subset of vertices for which τs has
s for all s ∈ I. The fractional
∗
only integral elements, say ﬁxing xs = x
∗ ∈ O∗
solution is strongly persistent if any optimal integral solution y
s for all s ∈ I. The fractional solution is weakly persistent
∗
∗
satisﬁes y
s = x
if there exists some y

∗ ∈ O∗ such that y

s for all s ∈ I.
∗
∗
s = x

Thus, any persistent fractional solution (whether weak or strong)
can be used to ﬁx a subset of elements in the integer program, while
still being assured that there exists an optimal integral solution that is
consistent. Strong persistency ensures that no candidate solutions are
eliminated by the ﬁxing procedure. Hammer et al. [105] studied the
roof-dual relaxation for binary quadratic programs, an LP relaxation
which is equivalent to specializing the ﬁrst-order LP to binary variables,
and proved the following result:

Proposition 8.4 Suppose that the ﬁrst-order LP relaxation (8.5) is
applied to the binary quadratic program

(cid:4)(cid:6)

s∈V

max
x∈{0,1}m

(cid:6)

(cid:22)

θsxs +

θstxsxt

.

(s,t)∈E

(8.18)

Then any fractional solution is strongly persistent.

As will be discussed at more length in Example 8.4, the class of
binary QPs includes as special cases various classical problems from
the combinatorics literature, among them MAX-2SAT, independent
set, MAX-CUT, and vertex cover. For all of these problems, then,

8.4 First-order LP Relaxation and Reweighted Max-product

211

the ﬁrst-order LP relaxation is strongly persistent. Unfortunately, this
strong persistency fails to extend to the ﬁrst-order relaxation (8.5) with
nonbinary variables; see the discussion following Example 8.3 for a
counterexample.

8.4.2 Connection to Max-Product Message-Passing

In analogy to the general connection between the Bethe variational
problem and the sum-product algorithm (see Section 4), one might pos-
tulate that Proposition 8.2 could be extended to graphs with cycles —
speciﬁcally, that the max-product algorithm solves the dual of the tree-
based relaxation (8.17). In general, this conjecture is false, as shown by
the following counterexample [245].

Example 8.2 (Max-product does not Solve the LP). Consider
the diamond graph Gdia shown in Figure 8.2, and suppose that we wish
to maximize a cost function of the form:

(cid:6)

(s,t)∈E

α(x1 + x4) + β(x2 + x3) + γ

I[xs (cid:12)= xt].

(8.19)

Here the maximization is over all binary vectors x ∈ {0,1}4, and α, β,
and γ are parameters to be speciﬁed. By design, the cost function (8.19)
is such that if we make γ suﬃciently negative, then any optimal solu-
tion will either be 04 := (0, 0, 0, 0) or 14 := (1, 1, 1, 1). As an extreme
example, if we set α = 0.31, β = −0.30, and γ = −∞, we see imme-
diately that the optimal solution is 14. (Note that setting γ = −∞ is
equivalent to imposing the “hard-core” constraint that xs = xt for all
(s, t) ∈ E.)

A classical way of studying the ordinary sum- and max-product
algorithms, dating back to the work of Gallager [87] and Wiberg
et al. [258], is via the computation tree associated with the message-
passing updates. As illustrated in Figure 8.2(b), the computation tree
is rooted at a particular vertex (1 in this case), and it tracks the paths
of messages that reach this root node. In general, the (n + 1)th level
of tree includes all vertices t such that a path of length n joins t to
the root. For the particular example shown in Figure 8.2(b), in the

212 Max-product and LP Relaxations

Fig. 8.2 (a) Simple diamond graph Gdia. (b) Associated computation tree after four rounds
of message-passing. Max-product solves exactly the modiﬁed integer program deﬁned by
the computation tree.

ﬁrst iteration represented by the second level of the tree in panel (b),
the root node 1 receives messages from nodes 2 and 3, and at the sec-
ond iteration represented by the third level of the tree, it receives one
message from node 3 (relayed by node 2), one message from node 2
(relayed by node 3), and two messages from node 4, one via node 2 and
the other via node 3, and so on down the tree.

The signiﬁcance of this computation tree is based on the following
observation: by deﬁnition, the decision of the max-product algorithm
at the root node 1 after n iterations is optimal with respect to the
modiﬁed integer program deﬁned by the computation tree with n + 1

levels. That is, the max-product decision will be (cid:3)x1 = 1 if and only if

the optimal conﬁguration in the tree with x1 = 1 has higher probabil-
ity than the optimal conﬁguration with x1 = 0. For the diamond graph
under consideration and given the “hard-core” constraints imposed by
setting γ = −∞, the only two possible conﬁgurations in any computa-
tion tree are all-zeros, or all-ones. Thus, the max-product reduces to
comparing the total weight on the computation tree associated with
all-ones to that associated with all-zeros.

However, the computation tree in Figure 8.2(b) has a curious prop-
erty: due to the inhomogeneous node degrees — more speciﬁcally, with
nodes 2 and 3 having three neighbors, and 1 and 4 having only two
neighbors — nodes 2 and 3 receive a disproportionate representation
in the computation tree. This fact is clear by inspection, and can be

8.4 First-order LP Relaxation and Reweighted Max-product

213

veriﬁed rigorously by setting up a simple recursion to compute the
appearance fractions of nodes 2 and 3 versus nodes 1 and 4. Doing so
shows that nodes 2 and 3 appear roughly ρ ≈ 1.0893 more frequently
than nodes 1 and 4. As a consequence, the ordinary max-product algo-
rithm makes its decision according to the threshold rule

(cid:7)

(cid:3)xMP =

14
04

if α + ρβ > 0
otherwise,

(8.20)

whereas the correct decision rule is based on thresholding α + β. Con-
sequently, for any (α, β) ∈ R2 such that α + β > 0 but α + ρβ < 0,
the max-product algorithm outputs an incorrect conﬁguration. For
instance, setting α = 0.31 and β = −0.30 yields one such counterexam-
ple, as discussed in Wainwright et al. [245]. Kulesza and Pereira [144]
provide a detailed analysis of the max-product message-passing updates
for this example, analytically deriving the updates and explicitly
demonstrating convergence to incorrect conﬁgurations.

Thus far, we have demonstrated a simple problem for which the
max-product algorithm fails. What is the connection to the LP relax-
ation (8.17)? It turns out that the problem instance that we have con-
structed is an instance of a supermodular maximization problem. As
discussed at more length in Example 8.4 to follow. it can be shown [138]
that the ﬁrst-order LP relaxation (8.17) is tight for maximizing any
binary quadratic cost function with supermodular interactions. The
cost function (8.19) is supermodular for all weights γ ≤ 0, so that in par-
ticular, the ﬁrst-order LP relaxation is tight for the cost function spec-
iﬁed by (α, β, γ) = (0.31,−0.30,−∞). However, as we have just shown,
ordinary max-product fails for this problem, so it is not solving the LP
relaxation.

As discussed at more length in Section 8.4.4, for some problems with
special combinatorial structure, the max-product algorithm does solve
the ﬁrst-order LP relaxation (8.5). These instances include the prob-
lem of bipartite matching and weighted b-matching. However, establish-
ing a general connection between message-passing and the ﬁrst-order
LP relaxation (8.5) requires developing related but diﬀerent message-
passing algorithms, the topic to which we now turn.

214 Max-product and LP Relaxations

8.4.3 Reweighted Max-product and Other Modiﬁed

Message-passing Schemes

In this section, we begin by presenting the tree-reweighted max-product
updates [245], and describing their connection to the ﬁrst-order LP
relaxation (8.5). Recall that in Theorem 7.2, we established a connec-
tion between the tree-reweighted Bethe variational problem (7.11), and
the tree-reweighted sum-product updates (7.12). Note that the con-
straint set in the tree-reweighted Bethe variational problem is exactly
the polytope L(G) that deﬁnes the ﬁrst-order LP relaxation (8.5). This
fact suggests that there should be a connection between the “zero-
temperature limit” of the tree-reweighted Bethe variational problem
and the ﬁrst-order LP relaxation. In particular, recalling the convex
surrogate B(θ) = BT(θ; ρe) deﬁned by the tree-reweighted Bethe varia-
tional problem from Theorem 7.2, let us consider the limit B(βθ)/β as
β → +∞. From the variational deﬁnition (7.11), we have

"

(cid:14)(cid:19)θ, τ(cid:20) − 1

β

(cid:15)#

.

∗

B

(τ)

lim
β→+∞

B(βθ)

β

= lim
β→+∞

sup
τ∈L(G)

As discussed previously, convexity allows us to exchange the order
of the limit and supremum, so that we conclude that the zero-
temperature limit of the convex surrogate B is simply the ﬁrst-order
LP relaxation (8.5).

Based on this intuition,

it is natural to suspect that the tree-
reweighted max-product algorithm should have a general connection
to the ﬁrst-order LP relaxation. In analogy to the TRW-sum-product
updates (7.12), the reweighted max-product updates take the form:

Mts(xs) ← κ max
∈Xt

x

(cid:2)
t

exp

(cid:4)

(cid:24)

(cid:23) 1
(cid:5)
(cid:11)

ρst

(cid:4)
(cid:4)
t) + θt(x
θst(xs, x
t)

(cid:22)

ρvt

(cid:11)

(cid:12)
(cid:12)(1−ρts)

(cid:4)
Mvt(x
t)

v∈N(t)\s

×

(cid:4)
Mst(x
t)

.

(8.21)

8.4 First-order LP Relaxation and Reweighted Max-product

215
where (ρst, (s, t) ∈ E) is a vector of positive edge weights in the span-
ning tree polytope.2

As with the reweighted sum-product updates, these messages deﬁne

a collection of pseudo-max-marginals of the form

νs(xs) ∝ exp(θs(xs))

[Mts(xs)]ρts,

and

(cid:2)

νs(xs, xt) ∝ exp(γst(xs, xt))

t∈N(s)

(cid:5)
[Mts(xs)]1−ρst

[Mus(xs)]ρus

(cid:5)
[Mst(xt)]1−ρst

[Mut(xt)]ρut

u∈N(t)\s

u∈N(s)\t

×

(8.22a)

,

(8.22b)

.

ρst

where γst(xs, xt) := θs(xs) + θt(xt) + θst(xs,xt)

Pseudo-max-marginals that satisfy certain conditions can be used to

the most general suﬃcient condition is that there exists a conﬁgura-

specify an optimal conﬁguration(cid:3)xTRW. As detailed in the paper [245],
tion(cid:3)x =(cid:3)xTRW that is nodewise and edgewise optimal across the entire
graph, meaning that(cid:3)xs ∈ arg max
((cid:3)xs,(cid:3)xt) ∈ arg max

νs(xs) ∀ s ∈ V ,
and
νst(xs, xt) ∀ (s, t) ∈ E.

(8.23b)

(8.23a)

xs

xs,xt

In this case, we say that the pseudo-max-marginals ν satisfy the strong
tree agreement condition (STA).

Under this condition, Wainwright et al. [245] showed the following:

Proposition 8.5 Given a weight vector ρe in the spanning tree poly-
∗) of TRW-max-product speciﬁes an
tope, any STA ﬁxed point (M
optimal dual solution for the ﬁrst-order tree LP relaxation (8.5).

, ν

∗

Fixed points ν

∗ satisfying conditions (8.23) are the most prac-
tically relevant, since in this case, the ﬁxed point can be used to

determine the conﬁguration (cid:3)xTRW, which is guaranteed to be glob-

ally optimal

for the original problem — that is, an element of

2 See Theorem 7.2 on the reweighted sum-product algorithm and the accompanying discus-
sion for more details on the choice of these edge weights.

∗

, ν

216 Max-product and LP Relaxations
arg maxx∈X m(cid:19)θ, φ(x)(cid:20) — so that the LP relaxation solves the origi-
nal MAP problem. An interesting theoretical question is whether any
∗), regardless of whether it satisﬁes the criteria (8.23),
ﬁxed point (M
speciﬁes an optimal solution to the dual of the ﬁrst-order LP relax-
ation (8.5). This question was left open by Wainwright et al. [245],
and later resolved by Kolmogorov [137], who provided a counterex-
ample, involving nonbinary variables, for which a TRW max-product
ﬁxed point does not correspond to a dual-optimal solution. In subse-
quent work, Kolmogorov and Wainwright [138] showed that for pairwise
MRFs with binary variables, the equivalence between TRW message-
passing and the LP relaxation is exact in all cases: any ﬁxed point of
TRW max-product speciﬁes a dual-optimal solution to the ﬁrst-order
LP relaxation (8.5). Examples of pairwise MRFs with binary variables
for which TRW message-passing always solves the LP relaxation include
the Ising ground state problem, as well as various combinatorial prob-
lems such as the independent set problem and the vertex cover problem;
see Example 8.4 for further discussion of these examples.

Kolmogorov [137] also established convergence guarantees for a cer-
tain sequential scheduling of TRW updates (known as TRW-S updates),
and showed empirically that TRW-S updates converge faster than
standard parallel scheduling of the TRW max-product updates (8.21).
Various forms of these reweighted max-product algorithms have been
applied in problems such as segmentation and disparity problems in
computer vision [137, 139, 168, 227, 251, 265], error-control coding [76],
side-chain prediction [251, 266], and sensor fusion [46, 49]. There also
turn out to be a number of interesting connections between TRW max-
product and a line of research, due to Schlesinger and collaborators, pre-
viously published in the Russian literature [140, 210]. The survey [256]
provides a detailed overview of this line of work, and some connections
to reweighted max-product and LP relaxation.

In addition to the basic TRW algorithm [245] and the TRW-S
scheduling studied by Kolmogorov [137], other researchers have
proposed distributed algorithms
solving the tree-based LP
relaxation (8.5), including subgradient methods [76, 139], dual coor-
dinate ascent methods [97, 239], annealing-type methods [124, 251],
proximal optimization schemes [197], and adaptive LP solvers [228].

for

8.4 First-order LP Relaxation and Reweighted Max-product

217

Weiss et al. [251] discuss connections between the zero-temperature
limits of convex free energy problems, including the tree-reweighted
Bethe problem from Theorem 7.2 as a special case, and optima of the
ﬁrst-order LP (8.5). Ravikumar et al. [197] discuss various rounding
schemes that can be used for ﬁnite termination of LP-solving algo-
rithms, with guarantees of correctness for the rounded solutions.

8.4.4 Examples of the First-order LP Relaxation

In this section, we discuss various examples of the ﬁrst-order LP relax-
ation (8.5). One line of ongoing work in communication and information
theory studies the behavior of the LP relaxation for decoding in error-
control coding. When applied to combinatorial problems, the ﬁrst-order
LP relaxation recovers various known methods from the integer pro-
gramming and approximation literature [180, 236]. In the special case
of binary variables, there are a number of links to the literature on
pseudo-Boolean optimization [37, 105].

Example 8.3 (LP Relaxations for Error-control Coding). We
begin by discussing an instance of the ﬁrst-order LP relaxation (8.5),
introduced by Feldman et al.
[78] for decoding low-density parity
check (LDPC) codes. Recall from Example 3.6 the notion of an error-
correcting code, and its deﬁnition as an exponential family. The code C
is a subset of the Boolean hypercube {0,1}m, deﬁned by a set of parity
checks ψa. The base measure ν is the counting measure restricted to
the set C of all valid codewords, and the m-dimensional vector of suﬃ-
cient statistics is given by φ(x) = (x1, . . . , xm). From Example 3.9, the
set M is given by the convex hull of all possible codewords, which is
known as the codeword polytope. Figure 8.3 provides a toy example of
an LDPC code over bits (x1, x2, x3, x4) ∈ {0,1}4, and with two parity
checks ψa and ψb, corresponding to the constraints x1 ⊕ x2 ⊕ x3 = 0
and x2 ⊕ x3 ⊕ x4 = 0, respectively. A family of codes is said to be
low-density if the degrees of the parity checks and variable nodes in
this graphical representation remain bounded as the blocklength m is
increased.

218 Max-product and LP Relaxations

x2

x1

a

b

x4

1

a

x3

(a)

1
2

1
2
(b)

b

0

Fig. 8.3 (a) The factor graph representation of a toy binary linear code on four bits
(x1, x2, x3, x4) ∈ {0,1}4. Each codeword must satisfy the two parity check constraints
x1 ⊕ x2 ⊕ x3 = 0 and x2 ⊕ x3 ⊕ x4 = 0, as deﬁned by the constraint functions ψa and
(cid:6)
ψb. (b) Construction of a fractional vertex, also known as a pseudocodeword, for the code
shown in panel (a). The pseudocodeword has elements (cid:4)τ =
, which satisfy all the
constraints (8.25) deﬁning the LP relaxation. However, the vector (cid:4)τ cannot be expressed
as a convex combination of codewords, and so lies strictly outside the codeword polytope,
which corresponds to the marginal polytope for this graphical model.

(cid:5)
1 1
2

1
2 0

When expressed as a graphical model using the parity check func-
tions (see Equation (3.20)), the code is not immediately recogniz-
able as a pairwise MRF to which the ﬁrst-order LP relaxation (8.5)
can be applied. However, any Markov random ﬁeld over discrete vari-
ables can be converted into pairwise form by the selective introduc-
tion of auxiliary variables. In particular, suppose that for each check
a ∈ F , we introduce an auxiliary variable za taking values in the space
{0,1}|N(a)|. Deﬁning pairwise interactions between za and each bit xi
for nodes i ∈ N(a), we can use za as a device to enforce constraints
over the subvector (xi, i ∈ N(a)). See Appendix E.3 for further details
on converting a general discrete graphical model to an equivalent pair-
wise form.
(cid:11)
If we apply the ﬁrst-order LP relaxation (8.5) to this pair-
wise MRF, the relevant variables consist of a pseudomarginal vector
for each i ∈ V , and for each check a ∈ F , a set of pseu-
1 − τi
domarginals {τa;J , J an even-sized subset of N(a)}. In this case, the
(cid:6)
pairwise marginalization conditions that deﬁne the set L(G) reduce to

(cid:12)

τi

τa;J = τi,

J(cid:23)i

for each a, and i ∈ N(a),

(8.24)

(cid:11)

8.4 First-order LP Relaxation and Reweighted Max-product

219
along with the box constraints τi, τa;J ∈ [0,1]. It is also possible to
remove the variables τa;J by Fourier–Motzkin elimination [24], so as
to obtain an equivalent LP relaxation that is described only in terms
. Doing so shows that the ﬁrst-order
of the vector
relaxation (8.5), when applied to the coding problem, is characterized
by the box constraints τi ∈ [0,1] for each i ∈ V , and for each a ∈ F , the
(cid:6)
forbidden set constraints

(cid:6)

τ1

τ2

. . .

τm

(cid:12)

τk ≥ 1 ∀ K ⊂ N(a) with |K| odd.

(8.25)

(1 − τk) +

k∈K

k∈N(a)\K

The interpretation of this inequality is very intuitive: it enforces that
for each parity check a ∈ F , the subvector τN(a) = (τi, i ∈ N(a)) must
be at Hamming distance at least one from any odd-parity conﬁguration
over the bits N(a).
In practice, a binary codeword x ∈ C is transmitted through a chan-
nel, so that the user receives only a vector of noisy observations. As
described in Example 3.6, channel transmission can be modeled in
terms of a conditional distribution p(yi | xi). Given a particular received
sequence (y1, . . . , ym) from the channel, deﬁne the vector θ ∈ Rm of log
(cid:10)
likelihoods, with components θi = log p(yi|xi=1)
p(yi|xi=0). The ML decoding prob-
lem corresponds to the integer program of maximizing the likelihood
i∈V θixi over the discrete set of codewords x ∈ C. It is well known to
be computationally intractable [18] in a worst case sense.

The LP decoding algorithm of Feldman et al. [78] is based on
i∈V θiτi subject to the box constraints
maximizing the objective
(τ1, τ2, . . . , τm) ∈ [0,1]m as well as the forbidden set constraints (8.25).
Since its introduction [76, 78], the performance of this LP relaxation
has been extensively studied [e.g., 50, 53, 62, 70, 77, 136, 228, 238, 239].
Not surprisingly, given the role of the constraint set L(G) in the
Bethe variational problem, there are close connections between LP
decoding and standard iterative algorithms like sum-product decoding
[76, 78, 136]. Among other connections, the fractional extreme points of
the ﬁrst-order LP relaxation have a very speciﬁc interpretation as pseu-
docodewords of the underlying code, studied in earlier work on iterative
decoding [83, 86, 257]. Figure 8.3(b) provides a concrete illustration of
a pseudocodeword that arises when the relaxation is applied to the toy

(cid:10)

220 Max-product and LP Relaxations

code shown in Figure 8.3(b). Consider the vector (cid:9)τ := (1, 1
a little more work, it can be shown that (cid:9)τ is a vertex of the relaxed
LP decoding polytope.) However, we claim that (cid:9)τ does not belong to

2 , 0); it
is easy to verify that it satisﬁes the box inequalities and the forbid-
den set constraints (8.25) that deﬁne the LP relaxation. (In fact, with

2 , 1

the marginal polytope for this graphical model — that is, it cannot
be written as a convex combination of codewords. To see this fact,
note that by taking a modulo two sum of the parity check constraints
x1 ⊕ x2 ⊕ x3 = 0 and x2 ⊕ x3 ⊕ x4 = 0, we obtain that x1 ⊕ x4 = 0 for
we must have µ1 = µ4, which implies that (cid:9)τ lies outside the codeword
any codeword. Therefore, for any vector µ in the codeword polytope,

polytope.

Apart from its interest in the context of error-control coding,
the fractional vertex in Figure 8.3(b) also provides a counterexample
regarding the persistency of fractional vertices of the polytope L(G).
Recall from our discussion at the end of Section 8.4.1 that the ﬁrst-
order LP relaxation, when applied to integer programs with binary
variables, has the strong persistency property [105], as summarized in
Proposition 8.4. It is natural to ask whether strong persistency also
holds for higher-order variables as well. Note that after conversion to
a pairwise Markov random ﬁeld (to which the ﬁrst-order LP relax-
We now claim that the fractional vertex (cid:9)τ illustrated in Figure 8.3
ation applies), the coding problem illustrated in Figure 8.3(a) includes
nonbinary variables za and zb at each of the factor nodes a, b ∈ F .
2 , 0), a little calculation shows that (cid:19)θ,(cid:9)τ(cid:20) = 2. In contrast,
(cid:9)τ = (1, 1
have x4 = 0, even though(cid:9)τ4 = 0 in the fractional vertex. Consequently,

constitutes a failure of strong persistency for the ﬁrst-order LP relax-
ation with higher-order variables. Consider applying the LP decoder
to the cost function θ = (2,0,0,−1); using the previously constructed
∗ = (1,0,1,1), both with
∗(cid:20) = 1. Thus, neither of the optimal integral solutions

the optimal codewords are x
value (cid:19)θ, x(cid:20) = (cid:19)θ, y

∗ = (1,1,0,1) and y

2 , 1

strong persistency is violated for this instance.

We conclude that relaxation (8.5) is strongly persistent only for
pairwise Markov random ﬁelds over binary random variables, otherwise

8.4 First-order LP Relaxation and Reweighted Max-product

221

known as binary quadratic programs. We now turn to an in-depth con-
sideration of this particular case:

Example 8.4 (Binary Quadratic Programs and Combinatorial
Problems). Recall the Ising model, as ﬁrst introduced in Example 3.1:
it is an exponential family over a vector X of binary random vari-
ables, which may take either “spin” values {−1,+1}m, or zero-one
values {0,1}m. Note that the mapping xs (cid:26)→ 2xs − 1 and its inverse
zs (cid:26)→ 1
2(zs + 1) may be used to convert freely back and forth from the
{0,1} form to the {−1,+1} form.
Let us consider the {0,1}-case and the mode-ﬁnding problem asso-
ciated with the canonical overcomplete set of potential functions —
namely

max
x∈{0,1}m

(cid:19)θ, φ(x)(cid:20) = max
x∈{0,1}m

θs(xs) +

(cid:7)(cid:6)

s∈V

(cid:6)

(cid:8)

(s,t)∈E

θst(xs, xt)

,

(8.26)

where

θs(xs) :=

1(cid:6)

j=0

θs;jI j[xs]

and θst(xs, xt) :=

1(cid:6)

j,k=0

θst;jkI j[xs]I k[xt]

are weighted sums of indicator functions.

This problem is a binary quadratic program, and includes as special
cases various types of classical problems in combinatorial optimization.

(cid:10)

Independent
set and vertex cover: Given an undirected graph
G = (V, E), an independent set I is a subset of vertices such that
(s, t) /∈ E for all s, t ∈ I. Given a set of vertex weights ws ≥ 0, the max-
imum weight independent set (MWIS) problem is to ﬁnd the indepen-
s∈I ws. This problem has
dent set I with maximal weight, w(I) :=
applications in scheduling for wireless sensor networks, where the inde-
pendent set constraints are imposed to avoid interference caused by
having neighboring nodes transmit simultaneously.
To model this combinatorial problem as an instance of the binary
quadratic program, let X ∈ {0,1}m be an indicator vector for mem-
bership in S, meaning that Xs = 1 if and only if s ∈ S. Then deﬁne

222 Max-product and LP Relaxations

(cid:11)

(cid:12)

θs(xs) =

0 ws

, and the pairwise interaction

"
#
0
0
0 −∞

.

θst(xs, xt) =

With these deﬁnitions, the binary quadratic program corresponds to
the maximum weight independent set (MWIS) problem.
A related problem is that of ﬁnding a vertex cover — that is, a
set C of vertices such that for any edge (s, t) ∈ E, at least one of s
s∈C ws. This
or t belongs to C — with minimum weight w(C) =
minimum weight vertex cover (MWVC) problem can be recast as a
maximization problem: it is another special case of the binary QP with
θs(xs) =

(cid:11)
0 −ws

(cid:10)

, and

(cid:12)

"−∞ 0

#

.

0

0

θst(xs, xt) =

(cid:11)

(cid:12)

Let us now consider how the ﬁrst-order LP relaxation (8.5) special-
izes to these problems. Recall that the general LP relaxation is in terms
, and an
of the two-vector of singleton pseudomarginals τs =
analogous 2 × 2 matrix τst of pairwise pseudomarginals. In the inde-
pendent set problem, the parameter setting θst;11 = −∞ is tantamount
to enforcing the constraint τst;11 = 0, so that the LP relaxation can be
expressed purely in terms of a vector µ ∈ Rm with elements µs := τs;1.
After simpliﬁcation, the constraints deﬁning L(G) (see Proposition 4.1)
can be reduced to µs ≥ 0 for all nodes s ∈ V , and µs + µt ≤ 1 for all
edges (s, t) ∈ E. Thus, for the MWIS problem, the ﬁrst-order relax-
ation (8.5) reduces to the linear program

τs;1

τs;0

such that µs + µt ≤ 1 for all (s, t) ∈ E.

max
µ≥0

wsµs

s∈V

This LP relaxation is the classical one for the independent set prob-
lem [180, 236]. Sanghavi et al. [207] discuss some connections between
the ordinary max-product algorithm and this LP relaxation, as well as
to auction algorithms [22].

In a similar way, specializing the ﬁrst-order LP relaxation (8.5) to

the MWVC problem yields the linear program

such that µs + µt ≥ 1 for all (s, t) ∈ E,

min
µ≥0

wsµs

s∈V

(cid:6)

(cid:6)

8.4 First-order LP Relaxation and Reweighted Max-product

223

which is another classical LP relaxation from the combinatorics
literature [180].
MAX-CUT : Consider the following graph-theoretic problem: given
a nonnegative weight wst ≥ 0 for each edge of an undirected graph
G = (V, E), ﬁnd a partition (U, U c) of the vertex set such that the asso-
ciated weight

(cid:6)

w(U, U c) :=

{(s,t) | s∈U,t∈U c}

wst

of edges across the partition is maximized. To model this MAX-
CUT problem as an instance of the binary quadratic program, let
X ∈ {0,1}m be an indicator vector for membership in U, meaning that
Xs = 1 if and only if s ∈ U. Then deﬁne θs(xs) = 0 for all vertices, and
deﬁne the pairwise interaction

"

#

θst(xs, xt) =

.

(8.27)

0 wst
0
wst

With these deﬁnitions, a little algebra shows that problem (8.26) is
equivalent to the MAX-CUT problem, a canonical example of an NP-
complete problem. As before, the ﬁrst-order LP relaxation (8.5) can be
specialized to this problem. In Section 9, we also describe the celebrated
semideﬁnite program (SDP) relaxation for MAX-CUT due to Goemans
and Williamson [98] (see Example 9.3).
Supermodular and submodular interactions: An important subclass of
binary quadratic programs are those based on supermodular potential
functions [158]. The interaction θst is supermodular if
θst(1,1) + θst(0,0) ≥ θst(1,0) + θst(0,1),

(8.28)
and it is submodular if the function gst(xs, xt) = −θst(xs, xt) is super-
modular. Note that the MAX-CUT problem and the independent set
problem both involve submodular potential functions, whereas the ver-
tex cover problem involves supermodular potentials. It is well known
that the class of regular binary QPs — meaning supermodular max-
imization problems or submodular minimization problems — can be
solved in polynomial time. As a particular instance, consider the prob-
lem of ﬁnding the minimum s–t cut in a graph. This can be formulated

224 Max-product and LP Relaxations

as a minimization problem in terms of the potential functions (8.27),
with additional nonzero singleton potentials θs, yielding an instance of
submodular minimization. It is easily solved by conversion to a max-
imum ﬂow problem, using the classical Ford–Fulkerson duality theo-
rem [22, 101]. However, the MAX-CUT, independent set, and vertex
cover problems all fall outside the class of regular binary QPs, and
indeed are canonical instances of intractable problems.

Among other results, Kolmogorov and Wainwright [138] establish
that tree-reweighted max-product is exact for any regular binary QP.
The same statement fails to hold for the ordinary max-product updates,
since it fails on the regular binary QP discussed in Example 8.2. The
exactness of tree-reweighted max-product stems from the tightness of
the ﬁrst-order LP relaxation (8.5) for regular binary QPs. This tight-
ness can be established via results due to Hammer et al. [105] on the
so-called roof dual relaxation in pseudo-Boolean optimization, which
turns out to be equivalent to the tree-based relaxation (8.5) for the
special case of binary variables.

Finally, we discuss a related class of combinatorial problems for
which some recent work has studied message-passing and linear
programming:

(cid:10)

Example 8.5 (Maximum Weight Matching Problems). Given
an undirected graph G = (V, E), the matching problem is to ﬁnd a
subset F of edges, such that each vertex is adjacent to at most one
edge e ∈ F . In the weighted variant, each edge is assigned a weight
we, and the goal is to ﬁnd the matching F that maximizes the weight
e∈F we. This maximum weight matching (MWM) problem
function
is well known to be solvable in polynomial time for any graph [212]. For
bipartite graphs, the MWM problem can be reduced to an especially
simple linear program, which we derive here as a special case of the
ﬁrst-order relaxation (8.5).

In order to apply the ﬁrst-order relaxation, it is convenient to ﬁrst
reformulate the matching problem as a mode-ﬁnding problem in an
MRF described by a factor graph, and then convert the factor graph to
a pairwise form, as in Example 8.3. We begin by associating with the

8.4 First-order LP Relaxation and Reweighted Max-product

original graph G = (V, E) a hypergraph (cid:9)G, in which each edge e ∈ E
corresponds to a vertex of (cid:9)G, and each vertex s ∈ V corresponds to a
of (cid:9)G (edges of the original graph) in the set E(s) = {e ∈ E | s ∈ e}.

hyperedge. The hyperedge indexed by s connects to all those vertices

225

Finally, we deﬁne a Markov random ﬁeld over the hypergraph as follows.
First, let each e ∈ E be associated with a binary variable xe ∈ {0,1},
which acts as an indicator variable for whether edge e participates in the
matching. We deﬁne the weight function θe(xe) = wexe, where we is the
weight speciﬁed for edge e in the matching problem. Second, given the
subvector xE(s) = (xe, e ∈ E(s)), we deﬁne an associated interaction
potential

(cid:4)
0
−∞ otherwise.
With this deﬁnition, the mode-ﬁnding problem

θs(xE(s)) :=

(cid:10)
e(cid:23)s xe ≤ 1
(cid:8)
(cid:6)

(cid:7)(cid:6)

if

max

x∈{0,1}|E|

e∈E

θe(xe) +

θ(xE(s))

s∈V

(8.29)

in the hypergraph is equivalent to the original matching problem.

This hypergraph-based mode-ﬁnding problem (8.29) can be con-
verted to an equivalent mode-ﬁnding problem in a pairwise Markov
random ﬁeld by following the generic recipe described in Appendix E.3.
Doing so and applying the ﬁrst-order LP relaxation (8.5) to the result-
ing pairwise MRF yields the following LP relaxation of the maximum
weight matching M

∗:

M

weτe

∗ ≤ max
τ∈R|E|
s.t. xe ≥ 0 ∀e ∈ E,

e∈E

(cid:6)

e(cid:23)s

and

xe ≤ 1 ∀s ∈ V .

(8.30)

(cid:6)

This LP relaxation is a classical one for the matching problem,
known to be tight for any bipartite graph but loose for nonbipar-
tite graphs [212]. A line of recent research has established close
links between the LP relaxation and the ordinary max-product algo-
rithm, including the case of bipartite weighted matching [15], bipartite

226 Max-product and LP Relaxations

weighted b-matching [116], weighted matching on general graphs [206],
and weighted b-matching on general graphs [13].

8.5 Higher-order LP Relaxations

The tree-based relaxation (8.17) can be extended to hypertrees of
higher treewidth t, by using the hypertree-based outer bounds Lt(G)
on marginal polytopes described in Section 4.2.3. This extension pro-
duces a sequence of progressively tighter LP relaxations, which we
describe here. Given a hypergraph G = (V, E), we use the short-
hand notation xh := (xi, i ∈ h) to denote the subvector of variables
associated with hyperedge h ∈ E. We deﬁne interaction potentials
θh(xh) :=
J θh;J I[xh = J] and consider the mode-ﬁnding problem of
computing

(cid:10)

(cid:8)

(cid:7)(cid:6)

h∈E

∗ ∈ arg max
x
x∈X m

θh(xh)

.

(8.31)

Note that problem (8.31) generalizes the analogous problem for pair-
wise MRFs, a special case in which the hyperedge set consists of only
vertices and ordinary edges.

Letting t + 1 denote the maximal cardinality of any hyperedge, the
relaxation based on Lt(G) involves the collection of pseudomarginals
{τh | h ∈ E} subject to local consistency constraints
h) = 1 ∀ h ∈ E,
(cid:4)
τh(x

Lt(G) :=

(cid:7)

and

h) = τg(xg) ∀g ⊂ h
(cid:4)
τh(x

.

(8.32)

(cid:6)
τ ≥ 0 |
(cid:6)

(cid:2)
h

x

{x

(cid:2)
h

| x(cid:2)

g=xg}

(cid:8)

(cid:17)
≤ max
τ∈Lt(G)

(cid:8)

!
(cid:20)

Following the same reasoning as in Section 8.4.1, we have the upper
bound

(cid:7)(cid:6)

h∈E

max
x∈X m

θh(xh)

(cid:6)

 (cid:6)
(cid:18)(cid:19)

max
τ∈Lt(G)

h∈E

xh
(cid:8)τ, θ(cid:9)

τh(xh)θh(xh)

.

(8.33)

8.5 Higher-order LP Relaxations

227

Notice that the relaxation (8.33) can be applied directly to a graphical
model that involves higher-order interactions, obviating the need
to convert higher-order interactions into pairwise form, as done in
illustrating the ﬁrst-order LP relaxation (see Example 8.3). In fact,
in certain cases, this direct application can yield a tighter relaxation
than that based on conversion to the pairwise case, as illustrated in
Example 8.6. Of course, the relaxation (8.33) can also be applied
directly to a pairwise Markov random ﬁeld, which can always be
embedded into a hypergraph with higher-order interactions. Thus,
Equation (8.33) actually describes a sequence of relaxations, based on
the nested constraint sets

L1(G) ⊇ L2(G) ⊇ L3(G) ⊇ . . . Lt(G) ⊇ . . . ⊇ M(G),

(8.34)

with increasing accuracy as the interaction size t is increased. The
tradeoﬀ, of course, is that computational complexity of the relaxation
also increases in the parameter t. The following result is an immediate
consequence of our development thus far:

Proposition 8.6 (Hypertree Tightness). For any hypergraph G of
treewidth t, the LP relaxation (8.33) based on the set Lt(G) is exact.

Proof. This assertion is equivalent to establishing that Lt(G) = M(G)
for any hypergraph G of treewidth t. Here M(G) denotes the
marginal polytope, corresponding to marginal probability distributions
(µh, h ∈ E) deﬁned over the hyperedges that are globally consistent.
First, the inclusion Lt(G) ⊇ M(G) is immediate, since any set of glob-
ally consistent marginals must satisfy the local consistency conditions
deﬁning Lt(G).
In the reverse direction, consider a locally consistent set of pseudo-
marginals τ ∈ Lt(G). Using these pseudomarginals, we may construct
the functions ϕh deﬁned previously (4.40) in our discussion of hypertree
factorization. Using these quantities, let us deﬁne distribution

pτ (x1, x2, . . . , xm) :=

ϕh(xh; τ).

(8.35)

(cid:2)

h∈E

228 Max-product and LP Relaxations

This distribution is constructed according to the factorization princi-
ple (4.42) for hypertrees. Using the local normalization and marginal-
(cid:10)
ization conditions that (τh, h ∈ E) satisﬁes by virtue of membership
in Lt(G), it can be veriﬁed that this this distribution is properly nor-
x pτ (x) = 1). Moreover, for each hyperedge h ∈ E, this
(cid:6)
malized (i.e.,
distribution has marginal distribution τh, meaning that

pτ (x1, . . . , xm) = τh(xh)

for all h ∈ E.

xs,s /∈h

Again, this fact can be veriﬁed by direct calculation from the factoriza-
tion, or can be derived as a consequence of the junction tree theorem.
Consequently, the distribution (8.35) provides a certiﬁcate of the mem-
bership of τ in the marginal polytope M(G).
In the binary {0,1} case, the sequence of relaxations (8.34) has been
proposed and studied previously by Hammer et al. [105], Boros et
al. [36], and Sherali and Adams [217], although without the connections
to the underlying graphical structure provided by Proposition 8.6.

Example 8.6 (Tighter Relaxations for Higher-order Interac-
tions). We begin by illustrating how higher-order LP relaxations yield
tighter constraints with a continuation of Example 8.3. Consider the
factor graph shown in Figure 8.4(a), corresponding to a hypergraph-
structured MRF of the form

pθ(x) ∝ exp

θi(xi) + θa(x1, x2, x3) + θb(x2, x3, x4)

(8.36)
for suitable potential functions {θi, i = 1, . . .4}, θa, and θb. In this exam-
ple, we consider two diﬀerent procedures for obtaining an LP relaxation:

i=1

(cid:7) 4(cid:6)

(cid:8)

,

(a) First convert the hypergraph MRF (8.36) into a pairwise

MRF and then apply the ﬁrst-order relaxation (8.5); or

(b) Apply the second-order relaxation based on L2(G) directly

to the original hypergraph MRF.

After some algebraic manipulation, both relaxations can be expressed
purely in terms of the triplet pseudomarginals τ123(x1, x2, x3) and

8.5 Higher-order LP Relaxations

229

Fig. 8.4 (a) A hypergraph-structured Markov random ﬁeld with two sets of triplet interac-
tions over a = {1,2,3} and b = {2,3,4}. The ﬁrst-order LP relaxation (8.5) applied to this
graph ﬁrst converts it into an equivalent pairwise MRF, and thus enforces only consistency
only via the singleton marginals τ2 and τ3. (b) The second-order LP relaxation enforces
additional consistency over the shared pairwise pseudomarginal τ23, and is exact for this
graph.

τ234(x2, x3, x4), and in particular their consistency on the overlap
(x2, x3). The basic ﬁrst-order LP relaxation (procedure (a)) imposes
only the two marginalization conditions

(cid:4)
(cid:4)
τ123(x
2, x3) =
1, x

(cid:4)
(cid:4)
τ123(x
3) =
1, x2, x

(cid:4)
(cid:4)
τ234(x
4),
2, x3, x

and

(8.37a)

(cid:4)
(cid:4)
τ234(x2, x
4),
3, x

(8.37b)

(cid:6)
(cid:6)

(cid:2)
1,x

(cid:2)
2

x

(cid:2)
1,x

(cid:2)
3

x

(cid:6)
(cid:6)

(cid:2)
2,x

(cid:2)
4

x

(cid:2)
3,x

(cid:2)
4

x

(cid:6)

(cid:2)
4

x

which amount to ensuring that the singleton pseudomarginals τ2 and τ3
induced by τ123 and τ234 agree. Note, however, that the ﬁrst-order relax-
ation imposes no constraint on the pairwise marginal(s) τ23 induced by
the triplet.

In contrast,

the triplets
(x1, x2, x3) and (x2, x3, x4) exactly, and so addition to the singleton
conditions (8.37), also requires agreement on the overlap — viz.

the second-order

relaxation treats

(cid:4)
τ123(x
1, x2, x3) =

(cid:4)
τ234(x2, x3, x
4).

(8.38)

(cid:6)

(cid:2)
1

x

As a special case of Proposition 8.6, this second-order relaxation is
tight, since the hypergraph in Figure 8.4(a) has treewidth two.

In Example 8.3, we considered the ﬁrst-order LP relaxation applied
to the MRF in Figure 8.4(a) for the special case of a linear code deﬁned

(cid:24)

(cid:23)

(cid:9)τ =

230 Max-product and LP Relaxations
over binary random variables x ∈ {0,1}4. There we constructed the
fractional vector

1
2 ,

1
2 , 0),

τ1(1), τ2(1), τ3(1), τ4(1)

= (1,

and showed that it was a fractional vertex for the relaxed polytope.

Although the vector (cid:9)τ is permitted under the pairwise relaxation in
ation in Figure 8.4(b). Indeed, the singleton pseudomarginals(cid:9)τ are con-

Figure 8.4(a), we claim that it is forbidden by the second-order relax-

sistent with triplet pseudomarginals τ123 and τ234 deﬁned as follows: let
τ123 assign mass 1
2 to the conﬁgurations (x1, x2, x3) = (101) and (110),
with zero mass elsewhere, and let τ234 assign mass 1
2 to the conﬁgura-
tions (x2, x3, x4) = (000) and (110), and zero elsewhere. By computing
the induced marginals, it can be veriﬁed that τ123 and τ234 marginal-

required by the ﬁrst-order relaxation. However, the second-order relax-
ation also requires agreement over the overlap (x2, x3), as expressed by
condition (8.38). On one hand, by deﬁnition of τ123, we have

ize down to (cid:9)τ, and satisfy the ﬁrst-order consistency condition (8.37)
(cid:6)
(cid:6)

whereas on the other hand, by deﬁnition of τ234, we have

(cid:4)
τ123(x
1, x2, x3) =

I[(x2, x3) = (0,1)] +

I[(x2, x3) = (1,0)],

(cid:2)
1

x

I[(x2, x3) = (1,1)] +

I[(x2, x3) = (1,1)].

1
2

1
2

1
2

1
2

(cid:4)
τ234(x2, x3, x
4) =

(cid:2)
1

x

Consequently, condition (8.38) is violated.

More generally, the second-order LP relaxation is exact for Fig-
ure 8.4(b), meaning that it is impossible to ﬁnd any triplet pseudo-

marginals τ123 and τ234 that marginalize down to(cid:9)τ, and agree over the

overlap (x2, x3).

Of course, the treewidth-two relaxation can be applied directly to
MRFs with cost functions already in pairwise form. In explicit terms,
the second-order LP relaxation applied to a pairwise MRF has the form

#(cid:22)

(cid:4)(cid:6)

"(cid:6)

s∈V

xs

max

τ

#

(cid:6)

"(cid:6)

(s,t)∈E

xs,xt

τs(xs)θs(xs)

+

τst(xs, xt)θst(xs, xt)

,

(8.39)

subject to the constraints

(cid:6)
(cid:6)

(cid:2)
t,x(cid:2)

x

u

x(cid:2)

u

τs(xs) =

τst(xs, xt) =

(cid:4)
(cid:4)
τstu(xs, x
u)
t, x

∀(s, t, u) ! s, ∀s ∈ V

(cid:4)
τstu(xs, xt, x
u)

∀(s, t, u) ! (s, t), ∀(s, t) ∈ E.

(8.40a)

(8.40b)

8.5 Higher-order LP Relaxations

231

(cid:23)

(cid:24)

(cid:23)

(cid:24)

m
3

Assuming that all edges and vertices are involved in the cost function,
pairwise marginals,
this relaxation involves m singleton marginals,
and

triplet marginals.

m
2

x

(cid:2)
t

(cid:10)

Note that even though the triplet pseudomarginals τstu play no role
in the cost function (8.39) itself, they nonetheless play a central role in
the relaxation via the consistency conditions (8.40) that they impose.
Among other implications, Equations (8.40a) and (8.40b) imply that
the pairwise marginals must be consistent with the singleton marginals
(cid:4)
τst(xs, x
t) = τs(xs)). Since these pairwise conditions deﬁne the
(i.e.,
ﬁrst-order LP relaxation (8.5), this fact conﬁrms that the second-order
LP relaxation is at least as good as the ﬁrst-order one. In general, the
triplet consistency also imposes additional constraints not ensured by
pairwise consistency alone. For instance, Example 4.1 shows that the
pairwise constraints are insuﬃcient to characterize the marginal poly-
tope of a single cycle on three nodes, whereas Proposition 8.6 implies
that the triplet constraints (8.40) provide a complete characterization,
since a single cycle on three nodes has treewidth two.

This technique — namely, introducing additional parameters in
order to tighten a relaxation, such as the triplet pseudomarginals
τstu — is known as a lifting operation. It is always possible, at least
in principle, to project the lifted polytope down to the original space,
thereby yielding an explicit representation of the tightened relaxation
in the original space. This combination is known as a lift-and-project
method [217, 150, 159]. In the case of the lifted relaxation based on the
triplet consistency (8.40) deﬁning L2(G), the projection is from the full
space down to the set of pairwise and singleton marginals.

Example 8.7(Lift-and-project for Binary MRFs). Here we illus-
trate how to project the triplet consistency constraints (8.40) for
any binary Markov random ﬁeld, thereby deriving the so-called cycle

232 Max-product and LP Relaxations

inequalities for the binary marginal polytope. (We presented these
cycle inequalities earlier in Example 4.1; see Section 27.1 of Deza and
Laurent [69] for a complete discussion.) In order to do so, it is con-
venient to work with a minimal set of pseudomarginal parameters:
in particular, for a binary Markov random ﬁeld, the seven numbers
{τstu, τst, τsu, τtu, τs, τt, τu} suﬃce to characterize the triplet pseudo-
marginal over variables (Xs, Xt, Xu). Following a little algebra, it can
be shown that the singleton (8.40a) and pairwise consistency (8.40b)
conditions are equivalent to the inequalities:

τstu ≥ 0
τstu ≥ −τs + τst + τsu
τstu ≤ 1 − τs − τt − τu + τst + τsu + τtu
τstu ≤ τst, τsu, τtu.

(8.41a)
(8.41b)
(8.41c)
(8.41d)

(cid:23)

Note that following permutations of the triplet (s, t, u), there are eight
inequalities in total, since inequality (8.41b) has three distinct versions.
The goal of projection is to eliminate the variable τstu from the
description, and obtain a set of constraints purely in terms of the
singleton and pairwise pseudomarginal parameters. If we consider sin-
gleton, pairwise, and triplet pseudomarginals for all possible combina-
possible pseudomarginal
tions, there are a total of T = m +
parameters. We would like to project this subset of RT down to a lower-
dimensional subset of RL, where L = m +
is the total number of
singleton and pairwise parameters. More speciﬁcally, we would like to
determine the set Π(L2(G)) ⊂ RL of pseudomarginal parameters of the
(cid:15)
form(cid:14)
(τs, τt, τu, τst, τsu, τtu) | ∃ τstu such that inequalities (8.41) hold

(cid:24)
(cid:23)

(cid:24)

m
2

+

m
3

,

(cid:23)

(cid:24)

m
2

corresponding to the projection of L2(G) down to RL.

A classical technique for computing such projections is Fourier–
Motzkin elimination [24, 271]. It is based on the following two steps: (a)
ﬁrst express all the inequalities so that the variable τstu to be eliminated
appears on the left-hand side; and (b) then combine the (≤) constraints
with the (≥) constraints in pairs, thereby yielding a new inequality in
which the variable τstu no longer plays a role. Note that τstu appears

8.5 Higher-order LP Relaxations

233

combine (8.41a) and (8.41d)
combine (8.41b) and (8.41c)
combine (8.41b) and (8.41d)
combine (8.41b) and (8.41d)
combine (8.41a) and (8.41c).

on the left-hand side of all the inequalities (8.41); hence, performing
step (b) yields the following inequalities
τst, τsu, τtu ≥ 0,
1 + τtu − τt − τu ≥ 0,
τs − τsu ≥ 0,
τs + τtu − τsu − τst ≥ 0,
1 − τs − τt − τu + τst + τsu + τtu ≥ 0,
The ﬁrst three sets of inequalities should be familiar; in particular, they
correspond to the constraints deﬁning the ﬁrst-order relaxation, in the
special case of binary variables (see Example 4.1). Finally, the last two
inequalities, and all permutations thereof, correspond to a known set
of inequalities on the binary marginal polytope, usually referred to as
the cycle inequalites.3 In recent work, Sontag and Jaakkola [219] exam-
ined the use of these cycle inequalities, as well as their extensions to
non-binary variables, in variational methods for approximate marginal-
ization, and showed signiﬁcantly more accurate results in many cases.

(cid:7)|V |
(cid:8)

3 To be clear, in the speciﬁed form, these inequalities are usually referred to as the triangle
inequalities, for obvious reasons. Note that for a graph G = (V, E) with |V | variables, there
are a total of
such groups of triangle inequalities. However, if the graph G is not fully
connected, then some of these triangle inequalities involve mean parameters µuv for pairs
(u, v) not in the graph edge set. In order to obtain inequalities that involve only mean
parameters µst for edges (s, t) ∈ E, one can again perform Fourier–Motzkin elimination,
which leads to the so-called cycle inequalities. See Deza and Laurent [69] for more details.

3

9

Moment Matrices, Semideﬁnite Constraints, and

Conic Programming Relaxation

Although the linear constraints that we have considered thus far yield
a broad class of relaxations, many problems require a more expressive
framework for imposing constraints on parameters. In particular, as
we have seen at several points in the preceding sections, semideﬁnite
constraints on moment matrices arise naturally within the variational
approach — for instance, in our discussion of Gaussian mean param-
eters from Example 3.7. This section is devoted to a more system-
atic study of moment matrices, in particular their use in constructing
hierarchies of relaxations based on conic programming. Moment matri-
ces and conic programming provide a very expressive language for the
design of variational relaxations. In particular, we will see that the
LP relaxations considered in earlier sections are special cases of conic
relaxations in which the underlying cone is the positive orthant. We
will also see that moment matrices allow us to deﬁne a broad class of
additional conic relaxations based on semideﬁnite programming (SDP)
and second-order cone programming (SOCP).

The study of moment matrices and their properties has an extremely
rich history (e.g., [3, 130]), particularly in the context of scalar ran-
dom variables. The basis of our presentation is more recent work

234

9.1 Moment Matrices and Their Properties

235

[e.g., 147, 148, 150, 191] that applies to multivariate moment problems.
While much of this work aims at general classes of problems in algebraic
geometry, in our treatment we limit ourselves to considering marginal
polytopes and we adopt the statistical perspective of imposing posi-
tive semideﬁniteness on covariance and other moment matrices. The
moment matrix perspective allows for a uniﬁed treatment of various
relaxations of marginal polytopes. See Wainwright and Jordan [247]
for additional material on the ideas presented here.

9.1 Moment Matrices and Their Properties
Given a random vector Y ∈ Rd, consider the collection of its second-
order moments: λst = E[YsYt], for s, t = 1, . . . , d. Using these moments,
we can form the following symmetric d × d matrix:

λ11 λ12

λ21 λ22
...
...
λn1 λn2

 .

··· λ1n
··· λ2n
...
···
··· λnn

N[λ] := E[Y Y T ] =

(9.1)

(cid:11)

At ﬁrst sight, this deﬁnition might seem limiting, because the matrix
involves only second-order moments. However, given some random
vector X of interest, we can expose any of its moments by deﬁning
Y = f(X) for a suitable choice of function f, and then considering the
associated second-order moment matrix (9.1) for Y . For instance, by
setting Y :=
both ﬁrst and second-order moments of X. Similarly, by including terms
of the form XsXt in the deﬁnition of Y , we can expose third moments
of X. The signiﬁcance of the moment matrix (9.1) lies in the following
simple result:

(cid:12) ∈ R × Rm, the moment matrix (9.1) will include

1 X

Lemma 9.1 (Moment Matrices). Any valid moment matrix N[λ]
is positive semideﬁnite.

Proof. We must show that aT N[λ]a ≥ 0 for an arbitrary vector a ∈ Rd.
If λ is a valid moment vector, then it arises by taking expectations

236 Moment Matrices and Conic Relaxations

under some distribution p. Accordingly, we can write
aT N[λ]a = Ep[aT Y Y T a] = Ep[(cid:31)aT Y ](cid:31)2],

which is clearly nonnegative.

Lemma

a necessary

9.1 provides

condition for

a vector
λ = (λst, s, t = 1, . . . , d) to deﬁne balid second-order moments. Such a
condition is both necessary and suﬃcient for certain classical moment
problems involving scalar random variables [e.g., 114, 130]. This condi-
tion is also necessary and suﬃcient for a multivariate Gaussian random
vector, as discussed in Example 3.7.

9.1.1 Multinomial and Indicator Bases
Now, consider a discrete random vector X ∈ {0,1, . . . , r − 1}m. In order
to study moments associated with X, it is convenient to deﬁne some
function bases. Our ﬁrst basis involves multinomial functions over
(x1, . . . , xm). Each multinomial is associated with a multi-index, mean-
ing a vector α := (α1, α2, . . . , αm) of nonnegative integers αs. For each
such multi-index, we deﬁne the multinomial function

m(cid:2)

xα :=

xαs
s ,

(9.2)

s=1

following the convention that x0

t = 1 for any position t such that αt = 0.
For discrete random variables in X m := {0,1, . . . , r − 1}m, it suf-
ﬁces1
to consider multi-indices such that the maximum degree
(cid:31)α(cid:31)∞ := maxs=1,...,m αs is less than or equal to r − 1. Consequently,
our multinomial basis involves a total of rm multinomial functions. We
deﬁne the Hamming norm (cid:31)α(cid:31)0 := card{i = 1, . . . , m | αi (cid:12)= 0}, which
counts the number of nonzero elements in the multi-index α. For each
integer k = 1, . . . , m, we then deﬁne the multi-index set

Ik := {α | | (cid:31)α(cid:31)0 ≤ k } .

(9.3)
r−1
j=0(x − j) = 0
1 Indeed, for any variable x ∈ X = {0,1, . . . , r − 1}, note that there holds
A simple rearrangement of this relation yields an expression for xr as a polynomial of
degree r − 1, which implies that any monomial xi with i ≥ r can be expressed as a linear
combination of lower-order monomials.

(cid:9)

9.1 Moment Matrices and Their Properties

237

The nested sequence of multi-index sets

I1 ⊂ I2 ⊂ . . . ⊂ Im

(9.4)
(cid:23)
(cid:24)
describes a hierarchy of models, which can be associated with hyper-
graphs with increasing sizes of hyperedges. To calculate the cardinality
of Ik, observe that for each i = 0, . . . , k, there are
possible subsets of
size i. Moreover, for each member of each such subset, there are (r − 1)
(cid:24)
(r − 1)i
possible choices of the index value, so that Ik has
elements in total. The total number of all possible multi-indices (with
(cid:31)α(cid:31)∞ ≤ r − 1) is given by |Im| =

(cid:10)
(r − 1)i = rm.

(cid:10)

k
i=0

(cid:23)

(cid:24)

(cid:23)

m
i

m
i

Our second basis is a generalization of the standard overcom-
plete potentials (3.34), based on indicator functions for events of
the form {Xs = j} as well as their higher-order analogs. Recall the
{0,1}-valued indicator function I js(xs) for the event {Xs = js}. Using
these node-based functions, we deﬁne, for each global conﬁguration
J = (j1, . . . , jm) ∈ {0,1, . . . , r − 1}m, the indicator function
if (x1, . . . , xm) = (j1, . . . , jm)
otherwise.

I js(xs) =

I J(x) :=

m(cid:2)

(cid:4)

(9.5)

1
0

m
i=0

m
i

s=1

In our discussion thus far, we have deﬁned these function bases
over the full vector (x1, . . . , xm); more generally, we can also consider
the same bases for subvectors (x1, . . . , xk). Overall, for any integer
k ≤ m, we have two function bases: the rk vector of multinomial
functions

(cid:4)
k(cid:2)
(cid:14)

s=1

(cid:22)
| α ∈ {0,1, . . . , r − 1}k
(cid:15)

,

Mk(x1, . . . , xk) :=

xαs
s

and the rk vector of indicator functions

Ik(x1, . . . , xk) :=

I J(x) | J ∈ {0,1, . . . , r − 1}k

,

The following elementary lemma shows that these two bases are in
one-to-one correspondence:
Lemma 9.2 For each k = 2,3, . . . , m, there is an invertible rk × rk
matrix B such that

Mk(x) = B Ik(x)

for all x ∈ X k.

(9.6)

238 Moment Matrices and Conic Relaxations

Proof. Our proof is based on explicitly constructing the matrix B. For
each s = 1, . . . , k and j ∈ {0,1,2, . . . , r − 1}, consider the following iden-
tities between the scalar indicator functions I j(xs) and monomials xj
s:

I j(xs) =

xs − (cid:10)
j − (cid:10)

,

and xj

s =

(cid:10)j I (cid:7)(xs).

(9.7)

r−1(cid:6)

(cid:7)=0

(cid:2)

(cid:7)(cid:7)=j

Using the second identity multiple times (once for each s ∈ {1, . . . , k}),
we obtain that for each α ∈ Ik,

k(cid:2)

k(cid:2)

  r−1(cid:6)

!

xα =

s =
xαs

(cid:10)αs I (cid:7)(xs)

.

s=1

s=1

(cid:7)=0

By expanding the product on the right-hand side, we obtain an expres-
sion for multinomial xα as a linear combination of the indicator func-
tions {I J(x),| J ∈ X k}. Conversely, for each J ∈ {0,1, . . . , r − 1}k, we
have

k(cid:2)

s=1

k(cid:2)

 (cid:2)

s=1

(cid:7)(cid:7)=js

!

.

xs − (cid:10)
js − (cid:10)

I J(x) :=

I js(xs) =

As before, by expanding the product on the right-hand side, we obtain
an expression for the indicator function I J as a linear combination of
the monomials {xα, α ∈ Ik}. Thus, there is an invertible linear transfor-
mation between the indicator functions {I J(x), J ∈ X k} and the mono-
mials {xα, α ∈ Ik}. We let B ∈ Rrk×rk denote the invertible matrix that
carries out this transformation.

These bases are convenient for diﬀerent purposes, and Lemma 9.2
allows us to move freely between them. The mean parameters associ-
ated with the indicator basis I are readily interpretable as probabil-
ities — viz. E[I J(X)] = P[X = J]. However, the multinomial basis is
convenient for deﬁning hierarchies of semideﬁnite relaxations.

9.1.2 Marginal Polytopes for Hypergraphs

We now turn to the use of these function bases in deﬁning marginal
polytopes for general hypergraphs. Given a hypergraph G = (V, E)

239

0(cid:10)

9.2 Semideﬁnite Bounds on Marginal Polytopes

1
in which the maximal hyperedge has cardinality k, we may consider
the multinomial Markov random ﬁeld pθ(x) ∝ exp
.
α∈I(G) θαxα
Here I(G) ⊆ Ik corresponds to those multi-indices associated with the
hyperedges of G. For instance, if G includes the triplet hyperedge
{s, t, u}, then I(G) must include the set of r3 multi-indices of the form
for some (αs, αt, αu) ∈ {0,1, . . . , r − 1}3.
(0, 0, . . . , αs, αt, αu, . . . ,0)
As an important special case, for each integer t = 1,2, . . . , m, we also
deﬁne the multi-index sets It := I(Km,t), where Km,t denotes the
hypergraph on m nodes that includes all hypergraphs up to size t. For
instance, the hypergraph Km,2 is simply the ordinary complete graph
on m nodes, including all
Let P(X m) denote the set of all distributions p supported on
X m = {0,1, . . . , r − 1}m. For any multi-index α ∈ Zm
%
+ and distribution
p ∈ P(X m), let

m
2

edges.

(cid:23)

(cid:24)

$

m(cid:2)

µα := Ep[X α] = Ep

X αi
i

(9.8)

i=1

(cid:14)

denote the associated mean parameter or moment. (We simply write
E[X α] when the underlying distribution p is understood from the con-
(cid:15)
text.) We use M(G) to denote the marginal polytope associated with
hypergraph G — that is, M(G) is the set
µ ∈ R|I(G)| | ∃ p ∈ P(X m) such that µα = Ep[X α] ∀α ∈ I(G)

.
(9.9)
To be precise,
it should be noted that our choice of notation is
slightly inconsistent with previous sections, where we deﬁned marginal
polytopes in terms of the indicator functions I j(xs) and I j[xs]I k[xt].
However, by the one-to-one correspondence between these indicator
functions and the multinomials {xα} from Lemma 9.2, the correspond-
ing marginal polytopes are isomorphic objects, regardless of the under-
lying potential functions chosen.

9.2 Semideﬁnite Bounds on Marginal Polytopes

We now describe the Lasserre sequence [148, 150] of semideﬁnite outer
bounds on the marginal polytope M(G). This sequence is deﬁned in

240 Moment Matrices and Conic Relaxations

terms of a hierarchy of moment matrices which generate a nested
sequence of semideﬁnite outer bounds on any marginal polytope.

9.2.1 Lasserre Sequence

To deﬁne the relevant moment matrices,
for each t = 1,2, . . . , m,
consider the |It| × |It| matrix of moments Nt[µ] deﬁned by the
|It|-dimensional random vector Y := (X α, α ∈ It). Each row and col-
umn of Nt[µ] is associated with some multi-index α ∈ It, and its entries
are speciﬁed as follows:

(cid:23)

(cid:24)

Nt[µ]

αβ := µα+β = E[X αX β].

(9.10)

As a particular example, Figure 9.1(a) provides an illustration of
the matrix N3[µ] for the special case of binary variables (r = 2) on
three nodes (m = 3), so that the overall matrix is eight-dimensional.

Fig. 9.1 Moment matrices and minors deﬁning the Lasserre sequence of semideﬁnite relax-
ations for a triplet (m = 3) of binary variables (r = 2). (a) Full matrix N3[µ]. (b) Shaded
region: 7 × 7 principal minor N2[µ] constrained by the Lasserre relaxation at order 1.

9.2 Semideﬁnite Bounds on Marginal Polytopes

241

The shaded region in Figure 9.1(b) shows the matrix N2[µ] for this
same example; note that it has |I2| = 7 rows and columns.

Let us make some clarifying comments regarding these moment
matrices. First, so as to simplify notation in this binary case, we
have used µ1 as a shorthand for the ﬁrst-order moment µ1,0,0, with
similar shorthand for the other ﬁrst-order moments µ2 and µ3. Sim-
ilarly, the quantity µ12 is shorthand for the second-order moment
µ1,1,0 = E[X1
3 ], and the quantity µ123 denotes the triplet moment
µ1,1,1 = E[X1X2X3]. Second, in both matrices, the element in the upper
left-hand corner is

1 X1

2 X0

µ∅ = µ0,0,0 = E[X0],

which is always equal to one. Third, in calculating the form of these
moment matrices, we have repeatedly used the fact that X2
i = Xi for
any binary variable to simplify moment calculations. For instance, in
computing the (8,7) element of N3[µ], we write

E[(X1X2X3)(X1X3)] = E[X1X2X3] = µ123.

We now describe how the moment matrices Nt[µ] induce outer
bounds on the marginal polytope M(G). Given a hypergraph G, let
t(G) denote the smallest integer such that all moments associated with
M(G) appear in the moment matrix Nt(G)[µ]. (For example, for an ordi-
nary graph with maximal cliques of size two, such as a 2D lattice, we
have t(G) = 1, since all moments of orders one and two appear in the
matrix N1[µ].) For each integer t = t(G), . . . , m, we can deﬁne the map-
ping ΠG : R|It| → R|I(G)| that maps any vector µ ∈ RIt to the indices
{α ∈ I(G)}. Then for each t = t(G),2, . . ., deﬁne the semideﬁnite con-
straint set

St(G) := ΠG[{µ ∈ R|It| | Nt[µ] (cid:25) 0}].

(9.11)

As a consequence of Lemma 9.1, each set St(G) is an outer bound on
the marginal polytope M(G), and by deﬁnition of the matrices Nt[µ],
these outer bounds form a nested sequence

S1(G) ⊇ S2(G) ⊇ S3(G) ⊇ ··· ⊇ M(G).

(9.12)

242 Moment Matrices and Conic Relaxations

This sequence is known as the Lasserre sequence of relaxations [147,
150]. Lov´asz and Schrijver [159] describe a related class of relaxations,
also based on semideﬁnite constraints.

Example 9.1 (First-order Semideﬁnite Bound on M(K3)). As
an illustration of the power of semideﬁnite bounds, recall Exam-
in which we considered the fully connected graph K3
ple 4.3,
on three nodes. In terms of the 6D vector of suﬃcient statistics
(X1, X2, X3, X1X2, X2X3, X1X3), we considered the pseudomarginal
vector

(cid:24)

(cid:23)

τ1,

τ2,

τ3,

τ12,

τ23,

τ13

=

0.5, 0.5, 0.5, 0.4, 0.4, 0.1

.

(cid:23)

(cid:24)

In Example 4.3, we used the cycle inequalities, as derived in Exam-
ple 8.7, to show that τ does not belong to M(K3). Here we provide
an alternative and arguably more direct proof of this fact based on
semideﬁnite constraints. In particular, the moment matrix N1[τ] asso-
ciated with these putative mean parameters has the form:

 1

0.5
0.5
0.5

 .

0.5
0.5
0.4
0.1

0.5
0.4
0.5
0.4

0.5
0.1
0.4
0.5

N1[τ] =

A simple calculation shows that this matrix N1[τ] is not positive deﬁ-
nite, whence τ /∈ S1(K3), so that by the inclusions (9.12), we conclude
that τ /∈ M(K3).

9.2.2 Tightness of Semideﬁnite Outer Bounds

Given the nested sequence (9.12) of outer bounds on the marginal poly-
tope M(G), we now turn to a natural question: what is the minimal
required order (if any) for which St(G) provides an exact character-
ization of the marginal polytope? It turns out that for an arbitrary
hypergraph, t = m is the minimal required (although see Section 9.3
and Proposition 9.5 for sharper guarantees based on treewidth). This
property of ﬁnite termination for semideﬁnite relaxations in a general

9.2 Semideﬁnite Bounds on Marginal Polytopes

243

setting was proved by Lasserre [147], and also by Laurent [149, 150]
using diﬀerent methods. We provide here one proof of this exactness:

Proposition 9.3 (Tightness of Semideﬁnite Constraints). For
any hypergraph G with m vertices, the semideﬁnite constraint set
Sm(G) provides an exact description of the associated marginal poly-
tope M(G).

(cid:5)

Proof. Although the result holds more generally [147], we prove it here
for the case of binary random variables. The inclusion M(G) ⊆ Sm(G)
is an immediate consequence of Lemma 9.1, so that it remains to estab-
lish the reverse inclusion. In order to do so, it suﬃces to consider a vec-
tor τ ∈ R2m, with elements indexed by indicator vectors α ∈ {0,1}m of
subsets of {1, . . . , m}. In particular, element τα represents a candidate
moment associated with the multinomial xα =
s . Suppose that
the matrix Nm[τ] ∈ R2m×2m is positive semideﬁnite; we need to show
that τ is a valid moment vector, meaning that there is some distribution
p supported on {0,1}m such that τα = Ep[X α] for all α ∈ Im.
Lemma 9.2 shows that the multinomial basis Mm and the indicator
basis Im are related by an invertible linear transformation B ∈ R2m×2m.
In the binary case, each multi-index α can be associated with a subset
of {1,2, . . . , m}, and we have the partial order α ⊆ β deﬁned by inclusion
of these subsets. It is straightforward to verify that the matrix B arises
from the inclusion-exclusion principle, and so has entries

m
s=1 xαs

B(α, β) =

if α ⊆ β
otherwise.

(cid:4)
(−1)|β\α|
0
(cid:4)
−1 has entries
if α ⊆ β
otherwise.

1
0

Moreover, the inverse matrix B
−1(α, β) =

B

(9.13)

(9.14)

See Appendix E.1 for more details on these matrices, which arise as a
special case of the M¨obius inversion formula.

In Appendix E.2, we prove that B diagonalizes Nm[τ], so that we
have BNm[τ]BT = D for some diagonal matrix D with a nonnegative

244 Moment Matrices and Conic Relaxations

entries, and trace(D) = 1. Thus, we can deﬁne a probability distribu-
tion p supported on {0,1}m with elements p(α) = Dα ≥ 0. Since B is
−T . Focusing on the αth diago-
invertible, we have Nm[τ] = B
nal entry, the deﬁnition of Nm[τ] implies that (Nm[τ])αα = τα. Conse-
quently, we have

−1DB

(cid:6)

τα =

=

(β,γ)∈{0,1}m×{0,1}m
D(β, β)B

β∈{0,1}m

−1(α, β)DB

−T (γ, α)

B

−1(α, β)B

−T (β, α),

(cid:6)

(cid:6)

α⊆β

using the fact that D is diagonal. Using the form (9.14) of B
conclude

−1, we

τα =

p(β) = Ep[X α],

which provides an explicit demonstration of the global realizability
of τα.

This result shows that imposing a semideﬁnite constraint on the
largest possible moment matrix Nm[µ] is suﬃcient to fully character-
ize all marginal polytopes. Moreover, the t = m condition in Proposi-
tion 9.3 is not only suﬃcient for exactness, but also necessary in a worst
case setting — that is, for any t < m, there exists some hypergraph G
such that M(G) is strictly contained within St(G). The following exam-
ple illustrates both the suﬃciency and necessity of Proposition 9.3:

Example 9.2
((In)exactness of Semideﬁnite Constraints).
Consider a pair of binary random variables (X1, X2) ∈ {0,1}2. With
respect to the monomials (X1, X2, X1X2), the marginal polytope
M(K2) consists of three moments (µ1, µ2, µ12). Figure 9.2(a) provides
an illustration of this 3D polytope; as derived previously in Exam-
ple 3.8, this set is characterized by the four constraints
µ12 ≥ 0,
and µs − µ12 ≥ 0

1 + µ1 + µ2 − µ12 ≥ 0,

for s = 1,2.
(9.15)

9.2 Semideﬁnite Bounds on Marginal Polytopes

245

The ﬁrst-order semideﬁnite constraint set S1(K2) is deﬁned by the
semideﬁnite moment matrix constraint

(9.16)

 1

N1[µ] =

µ1

µ2
µ1 µ1 µ12
µ2 µ12 µ2

 (cid:25) 0.

In order to deduce the various constraints implied by this semideﬁ-
nite inequality, we make use of an extension of Sylvester’s criterion for
assessing positive semideﬁniteness: a square matrix is positive semidef-
inite if and only if the determinant of any principal submatrix is non-
negative (see Horn and Johnson [114], p. 405). So as to facilitate both
our calculation and subsequent visualization, it is convenient to focus
on the intersection of both the marginal polytope and the constraint
set S1(K2) with the hyperplane µ1 = µ2. Stepping through the require-
ments of Sylvester’s criterion, positivity of the (1,1) element is trivial,
and the remaining singleton principal submatrices imply that µ1 ≥ 0
and µ2 ≥ 0. With a little calculation, it can be seen the (1,2) and
(1,3) principal submatrices yield the interval constraints µ1, µ2 ∈ [0,1].
The (2,3) principal submatrix yields µ1µ2 ≥ µ2
12, which after setting
µ1 = µ2 reduces to µ1 ≥ |µ12|. Finally, we turn to nonnegativity of the
full determinant: after setting µ1 = µ2 and some algebraic manipula-
tion, we obtain the the constraint
1) = [µ12 − µ1] [µ12 − µ1 (2µ1 − 1)] ≤ 0.
12 − (2µ2
µ2
Since µ1 ≥ |µ12| from before, this quadratic inequality implies the pair
of constraints

1)µ12 + (2µ3

1 − µ2

µ12 ≤ µ1,

and µ12 ≥ µ1 (2µ1 − 1).

(9.17)

The gray area in Figure 9.2(b) shows the intersection of the 3D marginal
polytope M(K2) from panel (a) with the hyperplane µ1 = µ2. The
intersection of the semideﬁnite constraint set S1(K2) with this same
hyperplane is characterized by the interval inclusion µ1 ∈ [0,1] and the
two inequalities in Equation (9.17). Note that the semideﬁnite con-
straint set is an outer bound on M(K2), but that it includes points
that are clearly not valid marginals. For instance, it can be veriﬁed that
(µ1, µ2, µ12) = ( 1
8) corresponds to a positive semideﬁnite N1[µ],
but this vector certainly does not belong to M(K2).

4 ,− 1
4 , 1

246 Moment Matrices and Conic Relaxations

Fig. 9.2 (a) The marginal polytope M(K2) for a pair (X1, X2) ∈ {0,1}2 of random variables;
it is a a polytope with four facets contained within the cube [0,1]3. (b) Nature of the
semideﬁnite outer bound S1 on the marginal polytope M(K2). The gray area shows the
cross-section of the binary marginal polytope M(K2) corresponding to intersection with
the hyperplane µ1 = µ2. The intersection of S1 with this same hyperplane is deﬁned by
the inclusion µ1 ∈ [0,1], the linear constraint µ12 ≤ µ1, and the quadratic constraint µ12 ≥
1 − µ1. Consequently, there are points belonging to S1 that lie strictly outside M(K2).
2µ

2

In this case, if we move up one more step to the semideﬁnite outer
bound S2(K2), then Proposition 9.3 guarantees that the description
should be exact. To verify this fact, note that S2(K2) is based on
imposing positive semideﬁniteness of the moment matrix

 1

N2[µ] =

µ1
µ2 µ12
µ1
µ1 µ12 µ12
µ2 µ12 µ2 µ12
µ12 µ12 µ12 µ12

 .

Positivity of the diagonal element (4,4) gives the constraint µ12 ≥ 0.
The determinant of 2 × 2 submatrix formed by rows and columns 3 and
4 (referred to as the (3,4) subminor for short) is given by µ12[µ2 − µ12].
Combined with the constraint µ12 ≥ 0, the nonnegativity of this deter-
minant yields the inequality µ2 − µ12 ≥ 0. By symmetry, the (2,4) sub-
minor gives µ1 − µ12 ≥ 0. Finally, calculating the determinant of N2[µ]
yields

(cid:11)
µ1 − µ12

(cid:12)(cid:11)
µ1 − µ12

(cid:12)(cid:11)
1 + µ12 − µ1 − µ2

det N2[µ] = µ12

(9.18)
The constraint det N2[µ] ≥ 0, in conjunction with the previous con-
implies the inequality 1 + µ12 − µ1 − µ2 ≥ 0. In fact, the
straints,

.

(cid:12)

9.2 Semideﬁnite Bounds on Marginal Polytopes

247
quantities {µ12, µ1 − µ12, µ2 − µ12, 1 + µ12 − µ1 − µ2} are the eigen-
values of N2[µ], so positive semideﬁniteness of N2[µ] is equivalent to
nonnegativity of these four quantities. The positive semideﬁniteness of
S2(K2) thus recovers the four inequalities (9.15) that deﬁne M(K2),
thereby providing an explicit conﬁrmation of Proposition 9.3.

From a practical point of view, however, the consequences of Propo-
sition 9.3 are limited, because Nm[µ] is a |Im| × |Im| matrix, where
|Im| = rm is exponentially large in the number of variables m. Appli-
cations of SDP relaxations are typically based on solving a semideﬁ-
nite program involving the constraint Nt[µ] (cid:25) 0 for some t substantially
smaller than the total number m of variables. We illustrate with a con-
tinuation of the MAX-CUT problem, introduced earlier in Section 8.4.4.

Example 9.3 (First-order SDP relaxation of MAX-CUT). As
described previously in Example 8.4, the MAX-CUT problem arises
from a graph-partitioning problem, and is computationally intractable
(NP-complete) for general graphs G = (V, E). Here, we describe a natu-
ral semideﬁnite programming relaxation obtained by applying the ﬁrst-
order semideﬁnite relaxation S1(G). In the terminology of graphical
models, the MAX-CUT problem is equivalent to computing the mode
of a binary pairwise Markov random ﬁeld (i.e., an Ising model) with a
very speciﬁc choice of interactions. More speciﬁcally, it corresponds to
solving the binary quadratic program

(cid:14)

(cid:15)
xsxt + (1 − xs)(1 − xt)

,

wst

(s,t)∈E

max
x∈{0,1}m

(9.19)
where wst ≥ 0 is a weight associated with each edge (s, t) of the graph
G. By Theorem 8.1, this integer program can be represented as an
equivalent linear program. In particular, introducing the mean param-
eters µs = E[Xs] for each node s ∈ V , and µst = E[XsXt] for each edge
(s, t) ∈ E, we can rewrite the binary quadratic program (9.19) as

(cid:6)

(cid:15)

(cid:6)

(cid:14)

max
µ∈M(G)

wst

(s,t)∈E

2µst + 1 − µs − µt

,

where M(G) is the marginal polytope associated with the ordinary
graph. Although originally described in somewhat diﬀerent terms, the

248 Moment Matrices and Conic Relaxations

relaxation proposed by Goemans and Williamson [98] amounts to
replacing the marginal polytope M(G) with the ﬁrst-order semideﬁ-
nite outer bound S1(G), thereby obtaining a semideﬁnite programming
relaxation. Solving this SDP relaxation yields a moment matrix, which
can be interpreted as the covariance matrix of a Gaussian random vec-
tor in m-dimensions. Sampling from this Gaussian distribution and
then randomly rounding the resulting m-dimensions yields a random-
ized algorithm for approximating the maximum cut. Remarkably, Goe-
mans and Williamson [98] show that in the worst case, the expected
cut value obtained in this way is at most ≈ 0.878 less than the optimal
cut value. Related work by Nesterov [181] provides similar worst-case
guarantees for applications of the ﬁrst-order SDP relaxation to general
classes of binary quadratic programs.

In addition to the MAX-CUT problem, semideﬁnite programming
relaxations based on the sequence St(G), t = 1,2, . . . have been stud-
ied for various other classes of combinatorial optimization problems,
including graph coloring, graph partitioning and satisﬁability prob-
lems. Determining when the additional computation required to impose
higher-order semideﬁnite constraints does (or does not) yield more
accurate approximations is an active and lively area of research.

9.3 Link to LP Relaxations and Graphical Structure

Recall from our previous discussion that the complexity of a given
marginal polytope M(G) depends very strongly on the structure of
the (hyper)graph G. One consequence of the junction tree theorem is
that marginal polytopes associated with hypertrees are straightforward
to characterize (see Propositions 2.1 and 8.6). This simplicity is also
apparent in the context of semideﬁnite characterizations. In fact, the
LP relaxations discussed in Section 8.5, which are tight for hypertrees
of appropriate widths, can be obtained by imposing semideﬁnite con-
straints on particular minors of the overall moment matrix Nm[µ], as
we illustrate here.
Given a hypergraph G = (V, E) and the associated subset of multi-
indices I(G), let M(G) be the |I(G)|-dimensional marginal polytope

9.3 Link to LP Relaxations and Graphical Structure

249
deﬁned by the suﬃcient statistics (xα, α ∈ I(G)). For each hyper-
edge h ∈ E, let I(h) be the subset of multi-indices with nonzero com-
ponents only in the elements of h, and let M({h}) be the |I(h)|-
dimensional marginal polytope associated with the subvector of multi-
nomials (xα, α ∈ I(h)). Letting the maximal hyperedge have cardinal-
ity t + 1, we can then rewrite the hypertree-based LP relaxation from
Section 8.5 in the form

Lt(G) =

{µ ∈ R|I(G)| | Πh(µ) ∈ M({h})},

(9.20)

5

h∈E

where Πh : R|I(G)| → R|I(h)| is the standard coordinate projection.

In general,

imposing semideﬁniteness on moment matrices pro-
duces constraint sets that are convex but nonpolyhedral (i.e., with
curved boundaries; see Figure 9.2(b) for an illustration). In certain
cases, however, a semideﬁnite constraint actually reduces to a set of
linear inequalities, so that the associated constraint set is a polytope.
We have already seen one instance of this phenomenon in Proposi-
tion 9.3, where by a basis transformation (between the indicator func-
tions I j(xs) and the monomials xαs
s ), we showed that a semideﬁnite
constraint on the full matrix Nm[µ] is equivalent to a total of rm linear
inequalities.

In similar fashion, it turns out that the LP relaxation Lt(G) can be
described in terms of semideﬁniteness constraints on a subset of minors
from the full moment matrix Nm[µ]. In particular, for each hyperedge
h ∈ E, let N{h}[µ] denote the |I(h)| × |I(h)| minor of Nm[µ], and deﬁne
the semideﬁnite constraint set

S({h}) =

µ ∈ R|Im| | N{h}[µ] (cid:25) 0

(9.21)
As a special case of Proposition 9.3 for m = |h|, we conclude that the
projection of this constraint set down to the mean parameters indexed
by I(h) — namely, the set Πh(S({h})) — is equal to the local marginal
polytope M({h}). We have thus established the following:

.

(cid:14)

(cid:15)

Proposition 9.4 Given a hypergraph G with maximal hyperedge size
|h| = t + 1, an equivalent representation of the polytope Lt(G) is in

250 Moment Matrices and Conic Relaxations

terms of the family of hyperedge-based semideﬁnite constraints

5

h∈E

Lt(G) =

S({h}),

(9.22)

obtained by imposing semideﬁniteness on certain minors of the full
moment matrix Nm[µ]. This relaxation is tight when G is a hypertree
of width t.

Figure 9.3 provides an illustration of the particular minors that
are constrained by the relaxation Lt(G) in the special case of the sin-
gle cycle K3 on m = 3 nodes with binary variables (see Figure 8.1).
Each panel in Figure 9.3 shows the full 8 × 8 moment matrix N3[µ]
associated with this graph; the shaded portions in each panel demar-
cate the minors N{12}[µ] and N{13}[µ] constrained in the ﬁrst-order

Fig. 9.3 Shaded regions correspond to the 4 × 4 minors N{12}[µ] in panel (a), and N{13}[µ]
in panel (b) are constrained by the Sherali–Adams relaxation of order 2. Also constrained
is the minor N{23}[µ] (not shown).

9.3 Link to LP Relaxations and Graphical Structure

251

LP relaxation L(G). In addition, this LP relaxation also constrains the
minor N{23}[µ], not shown here.

Thus, the framework of moment matrices allows us to understand
both the hierarchy of LP relaxations deﬁned by the hypertree-based
polytopes Lt(G), as well as the SDP hierarchy based on the nonpolyhe-
dral sets St(G). It is worth noting that at least for general graphs with
m ≥ 3 vertices, this hierarchy of LP and SDP relaxations are mutu-
ally incomparable, in that neither one dominates the other at a ﬁxed
level of the hierarchy. We illustrate this mutual incomparability in the
following example:

Example 9.4 (Mutual Incomparability of LP/SDP Relax-
ations). For the single cycle K3 on m = 3 vertices, neither the ﬁrst-
order LP relaxation L1(G) nor the ﬁrst-order semideﬁnite relaxation
S1(K3) are exact. At the same time, these two relaxations are mutually
incomparable, in that neither dominates the other. In one direction,
Example 9.1 provides an instance of a pseudomarginal vector τ that
belongs to L1(K3), but violates the semideﬁnite constraint deﬁning
S1(K3). In the other direction, we need to construct a pseudomarginal
vector τ that satisﬁes the semideﬁnite constraint N1[τ] (cid:25) 0, but vio-
lates at least one of the linear inequalities deﬁning L1(K3). Consider
the pseudomarginal τ with moment matrix N1[τ] of the form:

 1

τ1
τ2
τ3

N1[τ] =

 =

 1

τ1
τ1
τ12
τ13

τ2
τ12
τ2
τ23

τ3
τ13
τ23
τ3

0.75 0.75 0.75
0.5
0.5
0.75

0.75 0.75 0.45
0.75 0.45 0.75
0.75
0.5

0.5

 .

Calculation shows that N1[τ] is positive deﬁnite, yet the inequality
1 + τ12 − τ1 − τ2 ≥ 0 from the conditions (9.15), necessary for mem-
bership in L1(K3), is not satisﬁed. Hence, the constructed vector τ
belongs to S1(K3) but does not belong to L1(K3).

Of course, for hypergraphs of low treewidth, the LP relaxation is
deﬁnitely advantageous, in that it is tight once the order of relaxation
t hits the hypergraph treewidth — that is, the equality Lt(G) = M(G)
holds for any hypergraph of treewidth t, as shown in Proposition 8.6.

252 Moment Matrices and Conic Relaxations

In contrast, the semideﬁnite relaxation St(G) is not tight for a general
hypergraph of width t; as concrete examples, see Example 9.2 for the
failure of S1(G) for the graph G = K2, which has treewidth t = 1, and
Example 9.4 for the failure of S2(G) for the graph G = K3, which has
treewidth t = 2. However, if the order of semideﬁnite relaxation is raised
to one order higher than the treewidth, then the semideﬁnite relaxation
is tight:
Proposition 9.5 For a random vector X ∈ {0,1, . . . , r − 1}m that is
Markov with respect to a hypergraph G, we always have

St+1(G) ⊆ Lt(G),

where the inclusion is strict unless G is a hypertree of width t. For any
such hypertree, the equality St+1(G) = M(G) holds.

includes as minors

Proof. Each maximal hyperedge h in a hypergraph G with treewidth
t has cardinality |h| = t + 1. Note that the moment matrix Nt+1[µ]
constrained by the relaxation St+1(G)
the
|I(h)| × |I(h)| matrix N{h}[µ], for every hyperedge h ∈ E. This fact
implies that St+1(G) ⊆ S({h}) for each hyperedge h ∈ E, where the set
S({h}) was deﬁned in Equation (9.21). Hence, the asserted inclusion fol-
lows from Proposition 9.4. For hypergraphs of treewidth t, the equal-
ity St+1(G) = M(G) follows from this inclusion, and the equivalence
between Lt(G) and M(G) for hypergraphs of width t, as asserted in
Proposition 8.6.

9.4 Second-order Cone Relaxations

In addition to the LP and SDP relaxations discussed thus far, another
class of constraints on marginal polytopes are based on the second-order
cone (see Appendix A.2). The resulting second-order cone program-
ming (SOCP) relaxations of the mode-ﬁnding problem as well as of
general nonconvex optimization problems have been studied by various
researchers [134, 146]. In the framework of moment matrices, second-
order cone constraints can be understood as a particular weakening of
a positive semideﬁniteness constraint, as we describe here.

9.4 Second-order Cone Relaxations

253

The semideﬁnite relaxations that we have developed are based on
enforcing that certain moment matrices are positive semideﬁnite. All
of these constraints can be expressed in terms of moment matrices of
the form

(cid:12)#

""

#(cid:11)

1
Y

N[µ] := E

1 Y

,

(9.23)

where the random vector Y = f(X1, . . . , Xm) is a suitable function of
the vector X. The class of SOCP relaxations are based on the following
equivalence:

Lemma 9.6 For any moment matrix (9.23), the positive semideﬁnite-
ness constraint N[µ] (cid:25) 0 holds if and only if

(cid:19)(cid:19)U T U , E[Y Y T ](cid:20)(cid:20) ≥ (cid:31)U E[Y ](cid:31)2

for all U ∈ Rd×d.

(9.24)

Proof. Using the Schur complement formula [114], a little calculation
shows that the condition N[µ] (cid:25) 0 is equivalent to requiring that the
covariance matrix Σ := E[Y Y T ] − E[Y ]E[Y ] be positive semideﬁnite. A
symmetric matrix Σ is positive semideﬁnite if and only if its Frobenius
inner product (cid:19)(cid:19)Σ, Λ(cid:20)(cid:20) := trace(ΣΛ) with any other positive semideﬁnite
matrix Λ ∈ S d
+ is nonnegative [114]. (This fact corresponds to the self-
duality of the positive semideﬁnite cone [39].) By the singular value
decomposition [114], any Λ ∈ S d
+ can be written2 as Λ = U T U for some
matrix U ∈ Rd×d, so that the constraint (cid:19)(cid:19)Σ, Λ(cid:20)(cid:20) ≥ 0 can be rewritten
as (cid:19)(cid:19)U T U , E[Y Y T ](cid:20)(cid:20) ≥ (cid:31)U E[Y ](cid:31)2, as claimed.

An inequality of the form (9.24) corresponds to a second-order
cone constraint on the elements of the moment matrix N[µ]; see
Appendix A.2 for background on this cone. The second-order cone pro-
gramming approach is based on imposing the constraint (9.24) only for
a subset of matrices U, so that SOCPs are weaker than the associated
SDP relaxation. The beneﬁt of this weakening is that many SOCPs

2 We can obtain rank-deﬁcient Λ by allowing U to have some zero rows.

254 Moment Matrices and Conic Relaxations

can be solved with lower computational complexity than semideﬁ-
nite programs [39]. Kim and Kojima [134] study SOCP relaxations
for fairly general classes of nonconvex quadratic programming prob-
lems. Kumar et al. [146] study the use of SOCPs for mode-ﬁnding in
pairwise Markov random ﬁelds, in particular using matrices U that are
locally deﬁned on the edges of the graph, as well as additional linear
inequalities, such as the cycle inequalities in the binary case (see Exam-
ple 8.7). In later work, Kumar et al. [145] showed that one form of their
SOCP relaxation is equivalent to a form of the quadratic programming
(QP) relaxation proposed by Laﬀerty and Ravikumar [198]. Kumar et
al. [145] also provide a cautionary message, by demonstrating that cer-
tain classes of SOCP constraints fail to improve upon the ﬁrst-order
tree-based LP relaxation (8.5). An example of such redundant SOCP
constraints are those in which the matrix U T U has nonzero entries only
in pairs of elements, corresponding to a single edge, or more generally,
is associated with a subtree of the original graph on which the MRF is
deﬁned. This result can be established using moment matrices by the
following reasoning: any SOC constraint (9.24) that constrains only ele-
ments associated with some subtree of the graph is redundant with the
ﬁrst-order LP constraints (8.5), since the LP constraints ensure that
any moment vector µ is consistent on any subtree embedded within the
graph.

Overall, we have seen that a wide range of conic programming relax-
ations, including linear programming, second-order cone programming,
and semideﬁnite programming, can be understood in a uniﬁed manner
in terms of multinomial moment matrices. An active area of current
research is devoted to understanding the properties of these types of
relaxations when applied to particular classes of graphical models.

10

Discussion

The core of this survey is a general set of variational principles for the
problems of computing marginal probabilities and modes, applicable to
multivariate statistical models in the exponential family. A fundamen-
tal object underlying these optimization problems is the set of realiz-
able mean parameters associated with the exponential family; indeed,
the structure of this set largely determines whether or not the asso-
ciated variational problem can be solved exactly in an eﬃcient man-
ner. Moreover, a large class of well-known algorithms for both exact
and approximate inference — including belief propagation or the sum-
product algorithm, expectation propagation, generalized belief prop-
agation, mean ﬁeld methods, the max-product algorithm and linear
programming relaxations, as well as generalizations thereof — can be
derived and understood as methods for solving various forms, either
exact or approximate, of these variational problems. The variational
perspective also suggests convex relaxations of the exact principle, and
so is a fertile source of new approximation algorithms.

Many of the algorithms described in this survey are already stan-
dard tools in various application domains, as described in more detail
in Section 2.4. While such empirical successes underscore the promise

255

256 Discussion

of variational approaches, a variety of theoretical questions remain to
be addressed. One important direction to pursue is obtaining a priori
guarantees on the accuracy of a given variational method for particular
subclasses of problems. Past and ongoing work has studied the perfor-
mance of linear programming relaxations of combinatorial optimiza-
tion problems (e.g., [135, 236, 78, 48]), many of them particular cases
of the ﬁrst-order LP relaxation (8.5). It would also be interesting to
study higher-order analogs of the sequence of LP relaxations described
in Section 8. For certain special classes of graphical models, particu-
larly those based on “locally tree-like” graphs, recent and ongoing work
(e.g., [7, 14, 169, 200]) has provided some encouraging results on the
accuracy of the sum-product algorithm in computing approximations
of the marginal distributions and the cumulant function. Similar ques-
tions apply to other types of more sophisticated variational methods,
including the various extensions of sum-product (e.g., Kikuchi methods
or expectation-propagation) discussed in this survey.

We have focused in this survey on regular exponential families where
the parameters lie in an open convex set. This class covers a broad class
of graphical models, particularly undirected graphical models, where
clique potentials often factor into products over parameters and suf-
ﬁcient statistics. However, there are also examples in which nonlinear
constraints are imposed on the parameters in a graphical model. Such
constraints, which often arise in the setting of directed graphical mod-
els, require the general machinery of curved exponential families [74].
Although there have been specialized examples of variational meth-
ods applied to such families [122], there does not yet exist a general
treatment of variational methods for curved exponential families.

Another direction that requires further exploration is the study of
variational inference for distributions outside of the exponential family.
In particular, it is of interest to develop variational methods for the
stochastic processes that underlie nonparametric Bayesian modeling.
Again, special cases of variational inference have been presented for
such models — see in particular the work of Blei and Jordan [31] on
variational inference for Dirichlet processes — but there is as of yet no
general framework.

257

Still more broadly, there are many general issues in statistical infer-
ence that remain to be investigated from a variational perspective. In
particular, the treatment of multivariate point estimation and interval
estimation in frequentist statistical inference often requires treating nui-
sance variables diﬀerently from parameters. Moreover, it is often neces-
sary to integrate over some variables (e.g., random eﬀects) while maxi-
mizing over others. Our presentation has focused on treating marginal-
ization separately from maximization; further research will be needed
to ﬁnd ways to best combine these operations. Also, although marginal-
ization is natural from a Bayesian perspective, our focus on the expo-
nential family is limiting from this perspective, where it is relatively
rare for the joint probability distribution of all random variables (data,
latent variables and parameters) to follow an exponential family dis-
tribution. Further work on ﬁnding variational approximations for non-
exponential-family contributions to joint distributions, including nonin-
formative and robust prior distributions, will be needed for variational
inference methods to make further inroads into Bayesian inference.

Finally, it should be emphasized that the variational approach pro-
vides a set of techniques that are complementary to Monte Carlo
methods. One important program of research, then, is to characterize
the classes of problems for which variational methods (or conversely,
Monte Carlo methods) are best suited, and moreover to develop a the-
oretical characterization of the trade-oﬀs in complexity versus accuracy
inherent to each method. Indeed, there are various emerging connec-
tions between the mixing properties of Markov chains for sampling from
graphical models, and the contraction or correlation decay conditions
that are suﬃcient to ensure convergence of the sum-product algorithm.

Acknowledgments

A large number of people contributed to the gestation of this survey,
and it is a pleasure to acknowledge them here. The intellectual contri-
butions and support of Alan Willsky and Tommi Jaakkola were par-
ticularly signiﬁcant in the development of the ideas presented here. In
addition, we thank the following individuals for their comments and
insights along the way: David Blei, Constantine Caramanis, Laurent
El Ghaoui, Jon Feldman, G. David Forney Jr., David Karger, John
Laﬀerty, Adrian Lewis, Jon McAuliﬀe, Kurt Miller, Guillaume Obozin-
ski, Michal Rosen-Zvi, Lawrence Saul, Nathan Srebro, Erik Sudderth,
Sekhar Tatikonda, Romain Thibaux, Yee Whye Teh, Lieven Vanden-
berghe, Yair Weiss, Jonathan Yedidia, and Junming Yin. (Our apolo-
gies to those individual who we have inadvertently forgotten.)

258

A

Background Material

In this appendix, we provide some basic background on graph theory,
and convex sets and functions.

A.1 Background on Graphs and Hypergraphs

Here, we collect some basic deﬁnitions and results on graphs and hyper-
graphs; see the standard books [17, 34, 35] for further background.
A graph G = (V, E) consists of a set V = {1,2, . . . , m} of vertices, and
a set E ⊂ V × V of edges. By deﬁnition, a graph does not contain
self-loops (i.e., (s, s) /∈ E for all vertices s ∈ V ), nor does it contain
multiple copies of the same edge. (These features are permitted only in
the extended notion of a multigraph.) For a directed graph, the ordering
of the edge matters, meaning that (s, t) is distinct from (t, s), whereas
for an undirected graph, the quantities (s, t) and (t, s) refer to the same
edge. A subgraph F of a given graph G = (V, E) is a graph (V (F ), E(F ))
such that V (F ) ⊆ V and E(F ) ⊆ E. Given a subset S ⊆ V of the ver-
tex set of a graph G = (V, E), the vertex-induced subgraph is the sub-
graph F [S] = (S, E(S)) with edge-set E(S) := {(s, t) ∈ E | (s, t) ∈ E}.
(cid:4)) =
Given a subset of edges E
(V (E

(cid:4) ⊆ E, the edge-induced subgraph is F (E

(cid:4)) = {s ∈ V | (s, t) ∈ E

(cid:4)), E

(cid:4)), where V (E

(cid:4)}.

259

260 Background Material

A path P is a graph P = (V (P ), E(P )) with vertex set

V (P ) := {v0, v1, v2, . . . , vk}, and edge set

E(P ) := {(v0, v1),(v1, v2), . . . ,(vk−1, vk)}.

We say that the path P joins vertex v0 to vertex vk. Of parti-
cular
interest are paths that are subgraphs of a given graph
G = (V, E), meaning that V (P ) ⊆ V and E(P ) ⊆ E. A cycle is a graph
C = (V (C), E(C)) with V (C) = {v0, v1, . . . , vk} with k ≥ 2 and edge set
E(C) = {(v0, v1),(v1, v2), . . . ,(vk−1, vk),(vk, v0)}. An undirected graph
is acyclic if it contains no cycles. A graph is bipartite if its vertex set
can be partitioned as a disjoint union V = VA ∪ VB (where ∪ denotes
disjoint union), such that (s, t) ∈ E implies that s ∈ VA and t ∈ VB (or
vice versa).
A clique of a graph is a subset S of vertices that are all joined by
edges (i.e., (s, t) ∈ E for all s, t ∈ S). A chord of a cycle C on the vertex
set V (C) = {v0, v1, . . . , vk} is an edge (vi, vj) that is not part of the cycle
edge set E(C) = {(v0, v1),(v1, v2), . . . ,(vk−1, vk),(vk, v0)}. A cycle C of
length four or greater contained within a larger graph G is chordless
if the graph’s edge set contains no chords for the cycle C. A graph is
triangulated if it contains no cycles of length four or greater that are
chordless. A connected component of a graph is a subset of vertices
S ⊆ V such that for all s, t ∈ S, there exists a path contained within
the graph G joining s to t. We say that a graph G is singly connected,
or simply connected, if it consists of a single connected component. A
tree is an acyclic graph with a single connected component; it can be
shown by induction that any tree on m vertices must have m − 1 edges.
More generally, a forest is an acyclic graph consisting of one or more
connected components.
A hypergraph is G = (V, E) is a natural generalization of a graph:
it consists of a vertex set V = {1,2, . . . , m}, and a set E of hyperedges,
which each hyperedge h ∈ E is a particular subset of V . (Thus, an
ordinary graph is the special case in which |h| = 2 for each hyperedge.)
The factor graph associated with a hypergraph G is a bipartite graph
(cid:4) corresponding to the union V ∪ E of the
(V
hyperedge vertex set V , and the set of hyperedges E, and an edge set

(cid:4)) with vertex set V

(cid:4)

, E

261
(cid:4) that includes the edge (s, h), where s ∈ V and h ∈ E, if and only if
E
the hyperedge h includes vertex s.

A.2 Basics of Convex Sets and Functions

A.2 Basics of Convex Sets and Functions

Here, we collect some basic deﬁnitions and results on convex sets and
functions. Rockafellar [203] is a standard reference on convex analysis;
see also the books by Hiriart-Urruty and Lemar´echal [112, 113], Boyd
and Vandenberghe [39], and Bertsekas [23].

A.2.1 Convex Sets and Cones
A set C ⊆ Rd is convex if for all x, y ∈ C and α ∈ [0,1], the set C
also contains the point αx + (1 − α)y. Equivalently, the set C must
contain the entire line segment joining any two of its elements. Note
that convexity is preserved by various operations on sets:

• The intersection ∩j∈J Cj of a family {Cj}j∈J of convex sets
remains convex.
• The Cartesian product C1 ⊗ C2 ⊗ ··· ⊗ Ck of a family of con-
vex sets is convex.
• The image f(C) of a convex set C under any aﬃne mapping
f(x) = Ax + b is a convex set.
• The closure C and interior C
◦ of a convex set C are also
convex sets.

Note that the union of convex sets is not convex, in general.

A cone K is a set such that for any x ∈ K, the ray {λx | λ > 0}
also belongs to K. A convex cone is a cone that is also convex.
(To appreciate the distinction, the union of two distinct rays is a
cone, but not convex in general.) Important examples of convex cones
include:

• A subspace {y ∈ Rd | Ay = 0} for some matrix A ∈ Rm×d.
• The nonnegative orthant

{y ∈ Rd | y1 ≥ 0, y2 ≥ 0, . . . , yd ≥ 0}.

262 Background Material

n(cid:6)

(cid:4)
y ∈ Rd | y =

(cid:22)
• The conical hull of a collection of vectors {x1, . . . , xn}:
λixi with λi ≥ 0, i = 1, . . . , n
• The second-order cone {(y, t) ∈ Rd × R | (cid:31)y(cid:31)2 ≤ t}.
• The cone S d
+ of symmetric positive semideﬁnite matrices
+ = {X ∈ Rd×d | X = X T , X (cid:25) 0}.
S d

i=1

.

(A.1)

(A.2)

k

(cid:10)

A.2.2 Convex and Aﬃne Hulls

(cid:10)
A linear combination of elements x1, x2, . . . , xk from a set S is a sum
i=1 αixi, for arbitrary scalars αi ∈ R. An aﬃne combination is a lin-
(cid:10)
k
i=1 αi = 1, whereas
ear combination with the further restriction that
a convex combination is a linear combination with the further restric-
i=1 αi = 1 and αi ≥ 0 for all i = 1, . . . k. The aﬃne hull of a
tions
set S, denoted by aﬀ(S), is the smallest set that contains all aﬃne com-
binations. Similarly, the convex hull of a set S, denoted by conv(S), is
the smallest set that contains all its convex combinations. Note that
conv(S) is a convex set, by deﬁnition.

k

(cid:14)

A.2.3 Aﬃne Hulls and Relative Interior
For any  > 0 and vector z ∈ Rd, deﬁne the Euclidean ball
(cid:15)

(cid:15)
y ∈ Rd | (cid:31)y − z(cid:31) < 
The interior of a convex set C ⊆ Rd, denoted by C
z ∈ C | ∃  > 0 s.t. B(z) ⊂ C

B(z) :=

(cid:14)

:=

C

◦

.
◦, is given by

(A.3)

(A.4)

.

(cid:15)

The relative interior is deﬁned similarly, except that the interior is taken
with respect to the aﬃne hull of C, denoted aﬀ(C). More formally, the
relative interior of C, denoted ri(C), is given by

ri(C) := {z ∈ C | ∃ > 0 s.t. B(z) ∩ aﬀ(C) ⊂ C

.

(A.5)

To illustrate the distinction, note that the interior of the convex set
[0,1], when viewed as a subset of R2, is empty. In contrast, the aﬃne

A.2 Basics of Convex Sets and Functions

263

hull of [0,1] is the real line, so that the relative interior of [0,1] is the
open interval (0,1).
A key property of any convex set C is that its relative interior is
always nonempty [203]. A convex set C ⊆ Rd is full-dimensional if its
aﬃne hull is equal to Rd. For instance, the interval [0,1], when viewed
as a subset of R2, is not full-dimensional, since its aﬃne hull is only the
real line. For a full-dimensional convex set, the notion of interior and
relative interior coincide.

A.2.4 Polyhedra and Their Representations

A polyhedron P is a set that can be represented as the intersection of
a ﬁnite number of half-spaces

P = {x ∈ Rd | (cid:19)aj, x(cid:20) ≤ bj ∀j ∈ J },

(A.6)
where for each j ∈ J , the pair (aj, bj) ∈ Rd × R parameterizes a par-
ticular half-space.
We refer to a bounded polyhedron as a polytope. Given a polyhedron
P , we say that x ∈ P is an extreme point if it is not possible to write
x = λy + (1 − λ)z for some λ ∈ (0,1) and y, z ∈ P . We say that x is
a vertex if there exists some c ∈ Rd such that (cid:19)c, x(cid:20) > (cid:19)c, y(cid:20) for all
y ∈ P with y (cid:12)= x. For a polyhedron, x is a vertex if and only if it
is an extreme point. A consequence of the Minkowski–Weyl theorem
is that any nonempty polytope can be written as the convex hull of
its extreme points. This convex hull representation is dual to the half-
space representation. Conversely, the convex hull of any ﬁnite collection
of vectors is a polytope, and so has a half-space representation (A.6).

A.2.5 Convex Functions
It is convenient to allow convex functions to take the value +∞, par-
ticularly in performing dual calculations. More formally, an extended
real-valued function f on Rd takes values in the extended reals
R∗ := R ∪ {+∞}. A function f : Rd → R ∪ {+∞} is convex if for all
x, y ∈ Rd and α ∈ [0,1], we have

f(αx + (1 − α)y) ≤ αf(x) + (1 − α)f(y).

(A.7)

264 Background Material

The function is strictly convex if the inequality (A.7) holds strictly for
all x (cid:12)= y and α ∈ (0,1).

The domain of a extended real-valued convex function f is the set

dom(f) := {x ∈ Rd | f(x) < +∞}.

(A.8)

Note that the domain is always a convex subset of Rd. Throughout, we
restrict our attention to proper convex functions, meaning that dom(f)
is nonempty.

(cid:10)
(cid:24) ≤(cid:10)
A key consequence of the deﬁnition (A.7) is Jensen’s inequality,
i=1 αixi of points {xi}
k
which says that for any convex combination
k
i=1 αif(xi).
in the domain of f, we have f
ticular, given a collection of convex functions {fj j ∈ J }:

(cid:23)(cid:10)
(cid:10)
• any linear combination
j∈J αjfj with αi ≥ 0 is a convex
function;
• the pointwise supremum f(x) := supj∈J fj(x) is also a con-
vex function.

Convexity of functions is preserved by various operations. In par-

k
i=1 αixi

The convexity of a function can also be deﬁned in terms of its epigraph,
namely the subset of Rd × R given by

0
(x, t) ∈ Rd × R | f(x) ≤ t

1

,

(A.9)

epi(f) :=

as illustrated in Figure A.1. Many properties of convex functions can
be stated in terms of properties of this epigraph. For instance, it is a
straightforward exercise to show that the function f is convex if and
only if its epigraph is a convex subset of Rd × R. A convex function is
lower semi-continuous if limy→x f(y) ≥ f(x) for all x in its domain. It
can be shown that a convex function f is lower semi-continuous if and
only if its epigraph is a closed set; in this case, f is said to be a closed
convex function.

A.2.6 Conjugate Duality
Given a convex function f : Rd → R ∪ {+∞} with non-empty
domain, its conjugate dual is a new extended real-valued function

A.2 Basics of Convex Sets and Functions

265

f

Fig. A.1 The epigraph of a convex function is a subset of Rd × R, given by
epi(f) = {(x, t) ∈ Rd × R | f(x) ≤ t}. For a convex function, this set is always convex.
∗ : Rd → R ∪ {+∞}, deﬁned as
(y) := sup
x∈Rd
= sup

(cid:14)(cid:19)y, x(cid:20) − f(x)
(cid:15)
(cid:14)(cid:19)y, x(cid:20) − f(x)
(cid:15)

(A.10)

∗

f

,

x∈dom(f)

where the second equality follows by deﬁnition of the domain of f. Note
∗ is always a convex function, since it is the pointwise supre-
that f
mum of a family of convex functions. Geometrically, this operation can
be interpreted as computing the intercept of the supporting hyper-
plane to epi(f) with normal vector (y,−1) ∈ Rd × R, as illustrated in
Figure A.2.

It is also possible to take the conjugate dual of this dual function

thereby yielding a new function known as the biconjugate

(cid:14)(cid:19)z, y(cid:20) − f

∗

(cid:15)

∗

∗
)

(f

(z) = sup
y∈Rd

(y)

.

(A.11)

An important property of conjugacy is that whenever f is a closed
∗∗ is equal to the original
convex function, then the biconjugate f
function f.

For closed, convex, and diﬀerentiable functions f that satisfy
∗) induce
∗), based
In particular, we say

additional technical conditions, the conjugate pair (f, f
a one-to-one correspondence between dom(f) and dom(f
on the gradient mappings ∇f and ∇f

∗.

266 Background Material

Fig. A.2 Interpretation of the conjugate dual function in terms of supporting hyperplanes
to the epigraph. The negative value of the dual function −f
∗(y) corresponds to the intercept
of the supporting hyperplane to epi(f) with normal vector (y,−1) ∈ Rd × R.

is essentially smooth if

it has a
that a convex function f
◦, and
nonempty domain C = dom(f), f is diﬀerentiable throughout C
limi→∞∇f(xi) = +∞ for any sequence {xi} contained in C, and con-
verging to a boundary point of C. Note that a convex function with
domain Rd is always essentially smooth, since its domain has no bound-
ary. The property of essential smoothness is also referred to as steepness
in some statistical treatments [43].

∗), it can be shown that (f, C

A function f is of Legendre type if it is strictly convex, diﬀeren-
◦ of its domain, and essentially smooth. Letting
tiable on the interior C
◦) is a convex function of
D = dom(f
◦) is a convex function of Legendre
Legendre type if and only if (f
type. In this case, the gradient mapping ∇f is one-to-one from C
◦ onto
◦, continuous in both directions, and moreover
the open convex set D
∗ = (∇f)−1. See Section 26 of Rockafellar [203] for further details
∇f
∗.
on these types of Legendre correspondences between f and its dual f

∗

, D

B

Proofs and Auxiliary Results: Exponential

Families and Duality

In this section, we provide the proofs of Theorems 3.3 and 3.4 from
Section 3, as well as some auxiliary results of independent interest.

B.1 Proof of Theorem 3.3

We prove the result ﬁrst for a minimal representation, and then dis-
cuss its extension to the overcomplete case. Recall from Appendix A.2.3
that a convex subset of Rd is full-dimensional if its aﬃne hull is equal
to Rd. We ﬁrst note that M is a full-dimensional convex set if and only
if the exponential family representation is minimal. Indeed, the repre-
sentation is not minimal if and only if there exists some vector a ∈ Rd
and constant b ∈ R such that (cid:19)a, φ(x)(cid:20) = b holds ν-a.e. By deﬁnition of
M, this equality holds if and only if (cid:19)a, µ(cid:20) = b for all µ ∈ M, which is
equivalent to M not being full-dimensional.
Thus, if we restrict attention to minimal exponential families for
the time-being, the set M is full-dimensional. Our proof makes use of
the following properties of a full-dimensional convex set [see 112, 203]:
(a) its interior M◦ is nonempty, and the interior of the closure [M]◦
is equal to the interior M◦; and (b) the interior M◦ contains the zero

267

268 Proofs for Exponential Families and Duality
vector 0 if and only if for all nonzero γ ∈ Rd, there exists some µ ∈ M
with (cid:19)γ, µ(cid:20) > 0.
We begin by establishing the inclusion ∇A(Ω) ⊆ M◦. By shifting
the potential φ by a constant vector if necessary, it suﬃces to consider
the case 0 ∈ ∇A(Ω). Let θ0 ∈ Ω be the associated canonical parameter
satisfying ∇A(θ0) = 0. We prove that for all nonzero directions γ ∈ Rd,
there is some µ ∈ M such that (cid:19)γ, µ(cid:20) > 0, which implies 0 ∈ M◦ by
property (b). For any γ ∈ Rd, the openness of Ω ensures the existence
of some δ > 0 such that (θ0 + δγ) ∈ Ω. Using the strict convexity and
diﬀerentiability of A on Ω and the fact that ∇A(θ0) = 0 by assumption,
we have

A(θ0 + δγ) > A(θ0) + (cid:19)∇A(θ0), δγ(cid:20) = A(θ0).

Similarly, deﬁning µδ := ∇A(θ0 + δγ), we can write
A(θ0) > A(θ0 + δγ) + (cid:19)µδ, −δγ(cid:20).

These two inequalities in conjunction imply that

δ (cid:19)µδ, γ(cid:20) > A(θ0 + δγ) − A(θ0) > 0.

Since µδ ∈ ∇A(Ω) ⊆ M and γ ∈ Rd was arbitrary, this establishes that
0 ∈ M◦.
Next we show that M◦ ⊆ ∇A(Ω). As in the preceding argument, we
may take 0 ∈ M◦ without loss of generality. Then, we must establish the
existence of θ ∈ Ω such that ∇A(θ) = 0. By convexity, it is equivalent
to show that inf θ∈Ω A(θ) is attained. To establish the attainment of this
inﬁmum, we prove that A has no directions of recession, meaning that
limn→+∞ A(θn) = +∞ for all sequences {θn} such that (cid:31)θn(cid:31) → +∞.
For an arbitrary nonzero direction γ ∈ Rd and  > 0, consider the
set Hγ, := {x ∈ X m | (cid:19)γ, φ(x)(cid:20) ≥ }. Since 0 ∈ M◦, this set must have
positive measure under ν for all suﬃciently small  > 0. Otherwise, the
inequality (cid:19)γ, φ(x)(cid:20) ≤ 0 would hold ν-a.e., which implies that (cid:19)γ, µ(cid:20) ≤ 0
for all µ ∈ M. By the convexity of M, this inequality would imply that
0 /∈ [M]◦ = M◦, which contradicts our starting assumption.

(cid:13)

A(θ0 + tγ) ≥ log

For an arbitrary θ0 ∈ Ω, we now write

(cid:14)(cid:19)θ0 + tγ, φ(x)(cid:20)(cid:15)
(cid:14)(cid:19)θ0, φ(x)(cid:20)(cid:15)
(cid:18)(cid:19)
C(θ0)
Note that we must have C(θ0) > −∞, because

Hγ,

(cid:17)
≥ t + log

(cid:13)

exp

B.2 Proof of Theorem 3.4

269

exp

Hγ,

ν(dx)

ν(dx)

(cid:20) .

exp{(cid:19)θ0, φ(x)(cid:20)} > 0

for all x ∈ X m,

and ν(Hγ,) > 0. Hence, we conclude that limt→+∞ A(θ0 + tγ) = +∞
for all directions γ ∈ Rd, showing that A has no directions of recession.
Finally, we discuss the extension to the overcomplete case. For any
overcomplete vector φ of suﬃcient statistics, let ϕ be a set of poten-
tial functions in an equivalent minimal representation. In particular,
a collection ϕ can be speciﬁed by eliminating elements of φ until no
aﬃne dependencies remain. Let ∇Aϕ and ∇Aφ be the respective mean
parameter mappings associated with ϕ and φ, with the sets Mϕ and
Mφ similarly deﬁned. By the result just established, ∇Aϕ is onto the
interior of Mϕ. By construction of ϕ, each member in the relative
interior of Mφ is associated with a unique element in the interior of
Mϕ. We conclude that the mean parameter mapping ∇Aφ is onto the
relative interior of Mφ.

B.2 Proof of Theorem 3.4

We begin with proof of part (a), which we divide into three cases.

Case (i) µ ∈ M◦: In this case, Theorem 3.3 guarantees that the
inverse image (∇A)−1(µ) is nonempty. Any point in this inverse
image attains the supremum in Equation (3.42). In a minimal rep-
resentation, there is only one optimizing point, whereas there is an
aﬃne subset for an overcomplete representation. Nonetheless, for any
θ(µ) ∈ (∇A)−1(µ), the value of the optimum is given by

∗
A

(µ) = (cid:19)θ(µ), µ(cid:20) − A(θ(µ)).

270 Proofs for Exponential Families and Duality

By deﬁnition (3.2) of the entropy, we have

−H(pθ(µ)) = Eθ(µ)[(cid:19)θ(µ), φ(X)(cid:20) − A(θ(µ))]

= (cid:19)θ(µ), µ(cid:20) − A(θ(µ)),

∗ = {µ ∈ Rd | A

Case (ii) µ /∈ M: Let dom A

where the ﬁnal equality uses linearity of expectation, and the fact that
Eθ(µ)[φ(X)] = µ.
∗(µ) < +∞} denote the
∗. With this notation, we must prove that
eﬀective domain of A
M ⊇ dom A
∗. In order to do so, we use Corollary 26.4.1 of Rockafel-
lar [203] which asserts that if A is essentially smooth and lower semi-
∗]◦ ⊆ ∇A(Ω) ⊆ dom A
∗,
continuous, then we have the inclusions [dom A
or equivalently

[dom A

∗

◦ ⊆ M◦ ⊆ dom A
∗
]

,

since ∇A(Ω) = M◦ from Theorem 3.3. Since both M and dom A
∗
are convex sets, taking closures in these inclusions yields that
dom A∗ = [M◦] = M, where the second equality follows by the convex-
∗(µ) = +∞
ity of M. Therefore, by deﬁnition of the eﬀective domain, A
for any µ /∈ M.

It remains to verify that A is both lower semi-continuous, and
essentially smooth (see Appendix A.2.5 for the deﬁnition). Recall
from Proposition 3.1 that A is diﬀerentiable; hence, it is lower semi-
continuous on its domain. To establish that A is essentially smooth, let
θb be a boundary point, and let θ0 ∈ Ω be arbitrary. Since the set Ω
is convex and open, the line θt := tθb + (1 − t)θ0 is contained in Ω for
all t ∈ [0,1) (see Theorem 6.1 of Rockafellar [203]). Using the diﬀeren-
tiability of A on Ω and its convexity (see Proposition 3.1(b)), for any
t < 1, we can write

A(θ0) ≥ A(θt) + (cid:19)∇A(θt), θ0 − θt(cid:20).

Re-arranging and applying the Cauchy–Schwartz inequality to the
inner product term yields that

A(θt) − A(θ0) ≤ (cid:31)θt − θ0(cid:31) (cid:31)∇A(θt)(cid:31).

Now as t → 1−, the left-hand side tends to inﬁnity by the lower
semi-continuity of A, and the regularity of the exponential family.

(cid:14)(cid:19)θ, µ(cid:20) − A
(cid:14)(cid:19)θ, µ(cid:20) − A

∗

∗

A(θ) = sup
µ∈M
= sup
µ∈M

(cid:15)
(cid:15)

(µ)

B.3 General Properties of M and A∗

271

Case (iii) µ ∈ M\M◦: Since A

Consequently, the right-hand side must also tend to inﬁnity; since
(cid:31)θt − θ0(cid:31) is bounded, we conclude that (cid:31)∇A(θt)(cid:31) → +∞, which shows
that A is essentially smooth.
∗ is deﬁned as a conjugate function,
∗(µ) for any
it is lower semi-continuous. Therefore, the value of A
boundary point µ ∈ M\M◦ is determined by the limit over a sequence
approaching µ from inside M◦, as claimed.

We now turn to the proof of part (b). From Proposition 3.1, A is
∗)∗ = A, and

convex and lower semi-continuous, which ensures that (A
part (a) shows that dom A∗ = M. Consequently, we can write

(B.1)
since it is inconsequential whether we take the supremum over M or
its closure M.

(µ)

,

Last, we prove part (c) of the theorem. For a minimal representation,
Proposition 3.2 and Theorem 3.3 guarantee that the gradient mapping
∇A is a bijection between Θ and M◦. On this basis, it follows that
the gradient mapping ∇A
∗ also exists and is bijective [203], whence
the supremum (B.1) is attained at a unique point whenever θ ∈ Ω. The
analogous statement for an overcomplete representation can be proved
via reduction to a minimal representation.
B.3 General Properties of M and A∗
In this section, we state and prove some auxiliary results of indepen-
∗, and the
dent interest on general properties of the dual function A
associated set M of valid mean parameters.

B.3.1 Properties of M
From its deﬁnition, it is clear that M is always a convex set. Other more
speciﬁc properties of M turn out to be determined by the properties of
the exponential family. Recall from Appendix A.2.3 that a convex set

272 Proofs for Exponential Families and Duality
M ⊆ Rd is full-dimensional if its aﬃne hull is equal to Rd. With this
notion, we have the following:
Proposition B.1 The set M has the following properties:

(a) M is full-dimensional if and only if the exponential family is
(b) M is bounded if and only if Θ = Rd and A is globally Lips-

minimal.

chitz on Rd.

Proof. (a) The representation is not minimal if and only if there exists
some vector a ∈ Rd and constant b ∈ R such that (cid:19)a, φ(x)(cid:20) = b holds
ν-a.e. By deﬁnition of M, this equality holds if and only if (cid:19)a, µ(cid:20) = b
for all µ ∈ M, which is equivalent to M not being full-dimensional.
(b) The recession function A∞ is the support function supµ∈M(cid:19)µ, θ(cid:20).
Therefore, the set M is bounded if and only if A∞(θ) is ﬁnite for all
θ ∈ Rd. The recession function A∞ is ﬁnite-valued if and only if A is
Lipschitz and hence ﬁnite on all of Rd (see Proposition 3.2.7 in Hiriart-
Urruty and Lemar´echal [112]).

The necessity of the condition Ω = Rd for M to be bounded is clear
from the boundary behavior of ∇A given in Proposition 3.1. However,
the additional global Lipschitz condition is also necessary, as demon-
strated by the Poisson family (see Table 3.2). In this case, we have
Θ = R yet the set of mean parameters M = (0,+∞) is unbounded.
This unboundedness occurs because the function A(θ) = exp(θ), while
ﬁnite on R, is not globally Lipschitz.
B.3.2 Properties of A∗
∗ is not given in closed form, a number of proper-
Despite the fact that A
ties can be inferred from its variational deﬁnition (3.42). For instance,
∗ is always convex. More speciﬁc
an immediate consequence is that A
∗ depend on the nature of the exponential family. Recall
properties of A
from Appendix A.2.6 the deﬁnition of an essentially smooth convex
function.

B.4 Proof of Theorem 4.2(b)

273

Proposition B.2 The dual function A
semi-continuous. Moreover,
family:

∗ is always convex and lower
in a minimal and regular exponential

(a) A
(b) A

∗ is diﬀerentiable on M◦, and ∇A
∗ is strictly convex and essentially smooth.

∗(µ) = (∇A)−1(µ).

∗ is
Proof. The convexity and lower semi-continuity follow because A
the supremum of collection of functions linear in µ. Since both A and
∗ has these properties if and
∗ are lower semi-continuous, the dual A
A
only if A is strictly convex and essentially smooth (see our discussion
of Legendre duality in Appendix A.2.6, and Theorem 26.3 in Rockafel-
lar [203]). For a minimal representation, A is strictly convex by Propo-
sition 3.1, and from the proof of Theorem 3.4(a), it is also essentially
smooth, so that the stated result follows.

This result is analogous to Proposition 3.1, in that the conditions
∗ in a
stated ensure the essential smoothness of the dual function A
minimal representation. The boundary behavior of ∇A
∗ can be veri-
ﬁed explicitly for the examples shown in Table 3.2, for which we have
∗. For instance, in the Bernoulli case,
closed form expressions for A
∗(µ)| = |log[(1 − µ)/µ]|, which tends to
we have M = [0,1] and |∇A
inﬁnity as µ → 0+ or µ → 1−. Similarly, in the Poisson case, we have
∗(µ)| = |log µ|, which tends to inﬁnity as µ tends
M = (0,+∞) and |∇A
to the boundary point 0.

B.4 Proof of Theorem 4.2(b)

For any MRF deﬁned by a tree T , both components of the Bethe vari-
ational problem (4.16) are exact:

(a) by Proposition 4.1, the set L(T ) is equivalent to the marginal

(b) the Bethe entropy HBethe is equivalent to the negative dual

polytope M(T ), and
function −A

∗.

274 Proofs for Exponential Families and Duality

Consequently, for the tree-structured problem, the Bethe variational
principle is equivalent to a special case of the conjugate duality between
∗ from Theorem 3.4. Therefore, the value of the optimized
A and A
Bethe problem is equal to the cumulant function value A(θ), as claimed.
∗ corresponds to
Finally, Theorem 3.4(c) implies that the optimum τ
the exact marginal distributions of the tree-structured MRF. Strict
convexity implies that the solution is unique.

B.5 Proof of Theorem 8.1
We begin by proving assertion (8.4a). Let P be the space of all
densities p, taken with respect to the base measure ν associated with
the given exponential family. On the one hand, for any p ∈ P, we have

(cid:1) (cid:19)θ, φ(x)(cid:20)p(x)ν(dx) ≤ maxx∈X m(cid:19)θ, φ(x)(cid:20), whence

(cid:13)

sup
p∈P

(cid:19)θ, φ(x)(cid:20).

(cid:19)θ, φ(x)(cid:20)p(x)ν(dx) ≤ max
x∈X m

(cid:1) (cid:19)θ, φ(x)(cid:20)p(x)ν(dx) = supµ∈M(cid:19)θ, µ(cid:20), which establishes the

(B.2)
Since the support of ν is X m, equality is achieved in the
inequality (B.2) by taking a sequence of densities {pn} con-
∗ ∈ arg maxx(cid:19)θ, φ(x)(cid:20).
verging to a delta function δx∗(x), where x
Finally, by linearity of expectation and the deﬁnition of M, we
have supp∈P
claim (8.4a).
We now turn to the claim (8.4b). By Proposition 3.1, the func-
tion A is lower semi-continuous. Therefore, for all θ ∈ Ω, the quantity
limβ→+∞ A(βθ)/β is equivalent to the recession function of A, which
we denote by A∞ (see Corollary 8.5.2 of Rockafellar [203]). Hence, it
suﬃces to establish that A∞(θ) is equal to supµ∈M(cid:19)θ, µ(cid:20). Using the
lower semi-continuity of A and Theorem 13.3 of Rockafellar [203], the
recession function of A corresponds to the support function of the eﬀec-
tive domain of its dual. By Theorem 3.4, we have dom A∗ = M, whence
A∞(θ) = supµ∈ ¯M(cid:19)θ, µ(cid:20). Finally, the supremum is not aﬀected by taking
the closure.

C

Variational Principles for Multivariate Gaussians

In this appendix, we describe how the general variational representa-
tion (3.45) specializes to the multivariate Gaussian case. For a Gaus-
sian Markov random ﬁeld, as described in Example 3.7, computing
the mapping (θ,Θ) (cid:26)→ (µ,Σ) amounts to computing the mean vector
µ ∈ Rd, and the covariance matrix Σ − µµT . These computations are
typically carried out through the so-called normal equations [126]. In
this section, we derive such normal equations for Gaussian inference
from the principle (3.45).

C.1 Gaussian with Known Covariance

We ﬁrst consider the case of X = (X1, . . . , Xm) with unknown mean
µ ∈ Rm, but known covariance matrix Λ, which we assume to be strictly
positive deﬁnite (hence invertible). Under this assumption, we may
alternatively use the precision matrix P , corresponding to the inverse
covariance Λ−1. This collection of models can be written as an m-
dimensional exponential family with respect to the base measure

6

exp

ν(dx) =

(cid:23) − 1

(cid:24)
(2π)m|P −1| dx,
275

2 xT P x

276 Variational Principles for Multivariate Gaussians

with densities of the form pθ(x) = exp
. With this
notation, the well-known normal equations for computing the Gaussian
mean vector µ = E[X] are given by µ = P

Let us now see how these normal equations are a consequence of the
variational principle (3.45). We ﬁrst compute the cumulant function for
the speciﬁed exponential family as follows:

(cid:13)

(cid:14)(cid:10)
(cid:15)
i=1 θixi − A(θ)
−1θ.

m

(cid:15) exp
6

(cid:23) − 1

(cid:24)
(2π)m|P −1| dx

2 xT P x

(cid:14) m(cid:6)

θixi

i=1

A(θ) = log

exp

Rm

−1θ

1
2 θT P
1
2 θT Λθ,

=

=

where have completed the square in order to compute the integral.1
Consequently, we have A(θ) < +∞ for all θ ∈ Rm, meaning that Ω =
Rm. Moreover, the mean parameter µ = E[X] takes values in all of Rm,
so that M = Rm. Next, a straightforward calculation yields that the
∗(µ) = 1
2 µT P µ. Consequently, the
conjugate dual of A is given by A
variational principle (3.45) takes the form:

(cid:14)(cid:19)θ, µ(cid:20) − 1

(cid:15)
2 µT P µ

,

A(θ) = sup
µ∈Rm

which is an unconstrained quadratic program. Taking derivatives to
ﬁnd the optimum yields that µ(θ) = P

−1θ.

Thus, we have shown that the normal equations for Gaussian infer-
ence are a consequence of the variational principle (3.45) specialized
to this particular exponential family. Moreover, by the Hammersley–
Cliﬀord theorem [25, 102, 106], the precision matrix P has the same
sparsity pattern as the graph adjacency matrix (i.e., for all i (cid:12)= j,
Pij (cid:12)= 0 implies that (i, j) ∈ E). Consequently, the matrix-inverse-vector
−1θ can often be solved very quickly by specialized meth-
problem P
ods that exploit the graph structure of P (see, for instance, Golub
and van Loan [99]). Perhaps the best-known example is the case of
a tri-diagonal matrix P , in which case the original Gaussian vector X
is Markov with respect to a chain-structured graph, with edges (i, i + 1)
1 Note that since [∇2
tion 3.1 (see Equation (3.41b)).

A(θ)]ij = cov(Xi, Xj), this calculation is consistent with Proposi-

C.2 Gaussian with Unknown Covariance

277
for i = 1, . . . , m − 1. More generally, the Kalman ﬁlter on trees [262] can
be viewed as a fast algorithm for solving the matrix-inverse-vector sys-
tem of normal equations. For graphs without cycles, there are also local
iterative methods for solving the normal equations. In particular, as we
discuss in Example 5.3 in Section 5, Gaussian mean ﬁeld theory leads
to the Gauss–Jacobi updates for solving the normal equations.

C.2 Gaussian with Unknown Covariance

We now turn to the more general case of a Gaussian with unknown
covariance (see Example 3.3). Its mean parameterization is speciﬁed
by the vector µ = E[X] ∈ Rm and the second-order moment matrix
Σ = E[XX T ] ∈ Rm×m. The set M of valid mean parameters is com-
pletely characterized by the positive semideﬁniteness (PSD) constraint
Σ − µµT (cid:25) 0 (see Example 3.7). Turning to the form of the dual func-
tion, given a set of valid mean parameters (µ,Σ) ∈ M◦, we can associate
them with a Gaussian random vector X with mean µ ∈ Rm and covari-
ance matrix Σ − µµT " 0. The entropy of such a multivariate Gaussian
takes the form [57]:
h(X) = −A
∗

(µ,Σ) =

log 2πe.

log det

(cid:12)

+ m
2

1
2

By the Schur complement formula [114], we may rewrite the negative
dual function as
−A
∗

(µ,Σ) =

log 2πe.

log det

(C.1)

"

1
2

1 µT
µ Σ

+ m
2

(cid:11)
Σ − µµT
#

Since the log-determinant function is strictly concave on the cone of
positive semideﬁnite matrices [39], this representation demonstrates the
convexity of A

∗ in an explicit way.

These two ingredients allow us to write the variational princi-
ple (3.45) specialized to the multivariate Gaussian with unknown
covariance as follows: the value of cumulant function A(θ,Θ) is equal to

"

#

sup

(µ,Σ),Σ−µµT (cid:24)0

(cid:19)(cid:19)Θ, Σ(cid:20)(cid:20) +

1
2

1
2

log det

1 µT
µ Σ

+

1
2

0
(cid:19)θ, µ(cid:20) +

1

log 2πe

.

(C.2)

278 Variational Principles for Multivariate Gaussians

as

problems,

known

(for

In general,

obvious

reasons)

This problem is an instance of a well-known class of concave
maximization
a
log-determinant prob-
log-determinant problem [235].
lems can be solved eﬃciently using standard methods for convex
programming, such as interior point methods. However, this speciﬁc
log-determinant problem (C.2) actually has a closed-form solution: in
particular, it can be veriﬁed by a Lagrangian reformulation that the
∗
,Σ∗) is speciﬁed by the relations
optimal pair (µ
∗ − µ
∗

(C.3)
Note that these relations, which emerge as the optimality con-
ditions for the log-determinant problem (C.2), are actually familiar
statements. Recall from our exponential representation of the Gaussian
density (3.12) that −Θ is the precision matrix. Consequently, the ﬁrst
equality in Equation (C.3) conﬁrms that the covariance matrix is the
inverse of the precision matrix, whereas the second equality corresponds
to the normal equations for the mean µ of a Gaussian. Thus, as a spe-
cial case of the general variational principle (3.45), we have re-derived
the familiar equations for Gaussian inference.

∗
and µ

)T = −[Θ]

−1,

= −[Θ]

−1 θ.

Σ

∗
(µ

C.3 Gaussian Mode Computation

In Section C.2, we showed that for a multivariate Gaussian with
unknown covariance, the general variational principle (3.45) corre-
sponds to a log-determinant optimization problem. In this section, we
show that the mode-ﬁnding problem for a Gaussian is a semideﬁnite
program (SDP), another well-known class of convex optimization prob-
lems [234, 235]. Consistent with our development in Section 8.1, this
SDP arises as the “zero-temperature limit” of the log-determinant prob-
lem. Recall that for the multivariate Gaussian, the mean parameters are
the mean vector µ = E[X] and second-moment matrix Σ = E[XX T ],
and the set M of valid mean parameters is characterized by the semidef-
inite constraint Σ − µµT (cid:25) 0, or equivalently (via the Schur comple-
ment formula [114]) by a linear matrix inequality

"

#

Σ − µµT (cid:25) 0 ⇐⇒

1 µT
µ Σ

(cid:25) 0.

(C.4)

Consequently, by applying Theorem 8.1, we conclude that

C.3 Gaussian Mode Computation

(cid:14)(cid:19)θ, µ(cid:20) +

(cid:19)(cid:19)Θ, Σ(cid:20)(cid:20)(cid:15)

1
2

279

(C.5)

(cid:14)(cid:19)θ, x(cid:20) +

(cid:19)(cid:19)Θ, xxT(cid:20)(cid:20)(cid:15)

1
2

max
x∈X

= max

Σ−µµT (cid:25)0

The problem on the left-hand side is simply a quadratic program, with
∗ = −[Θ]−1θ of the Gaus-
optimal solution corresponding to the mode x
sian density. The problem on the right-hand side is a semideﬁnite pro-
gram [234], as it involves an objective function that is linear in the
matrix-vector pair (µ,Σ), with a constraint deﬁned by the linear matrix
inequality (C.4).

In order to demonstrate how the optimum of this semideﬁnite
∗, we begin with the
program (SDP) recovers the Gaussian mode x
fact [114] that a matrix B is positive semideﬁnite if and only if
(cid:19)(cid:19)B, C(cid:20)(cid:20) := trace(BC) ≥ 0 for all other positive semideﬁnite matrices C.
(This property corresponds to the self-duality of the cone S m
+ .) Apply-
ing this fact to the matrices B = Σ − µµT (cid:25) 0 and C = −Θ " 0 yields
the inequality (cid:19)(cid:19)Θ, Σ(cid:20)(cid:20) ≤ (cid:19)(cid:19)Θ, µµT(cid:20)(cid:20), which in turn implies that

(cid:19)θ, µ(cid:20) +

1
2

(cid:19)(cid:19)Θ, Σ(cid:20)(cid:20) ≤ (cid:19)θ, µ(cid:20) +

(cid:19)(cid:19)Θ, µµT(cid:20)(cid:20).

1
2

(C.6)

Observe that the right-hand side is a quadratic program in the vector
∗ = −[Θ]−1θ. Consequently, if
µ ∈ Rm, with its maximum attained at µ
we maximize the left-hand side over the set Σ − µµT (cid:25) 0, the bound
∗ and Σ∗ = µ
∗(µ
∗)T . The interpretation is the
will be achieved at µ
optimal solution corresponds to a degenerate Gaussian, speciﬁed by
,Σ∗), with a zero covariance matrix, so that all
∗
mean parameters (µ
mass concentrates on its mean µ

∗ = x
∗.

In practice,

it is not necessary to solve the semideﬁnite pro-
gram (C.5) in order to compute the mode of a Gaussian problem.
For multivariate Gaussians, the mode (or mean) can be computed by
more direct methods, including Kalman ﬁltering [126], corresponding
to the sum-product algorithm on trees, by numerical methods such
as conjugate gradient [67], by the max-product/min-sum algorithm
(see Section 8.3), both of which solve the quadratic program in an
iterative manner, or by iterative algorithms based on tractable sub-
graphs [161, 223]. However, the SDP-based formulation (C.6) provides
valuable perspective on the use of semideﬁnite relaxations for integer
programming problems, as discussed in Section 9.

D

Clustering and Augmented Hypergraphs

In this appendix, we elaborate on various techniques use to transform
hypergraphs so as to apply the Kikuchi approximation and related clus-
ter variational methods. The most natural strategy is to construct vari-
ational relaxations directly using the original hypergraph. The Bethe
approximation is of this form, corresponding to the case when the origi-
nal structure is an ordinary graph. Alternatively, it can be beneﬁcial to
develop approximations based on an augmented hypergraph G = (V, E)
built on top of the original hypergraph. A natural way to deﬁne new
hypergraphs is by deﬁning new hyperedges over clusters of the original
vertices; a variety of such clustering methods have been discussed in
the literature [e.g., 167, 188, 268, 269].

D.1 Covering Augmented Hypergraphs

(cid:4) = (V, E

(cid:4)) denote the original hypergraph, on which the undi-
Let G
rected graphical model or Markov random ﬁeld is deﬁned. We consider
an augmented hypergraph G = (V, E), deﬁned over the same set of ver-
tices but with a hyperedge set E that includes all the original hyper-
(cid:4) is covered by the
edges E
augmented hypergraph G. A desirable feature of this requirement is

(cid:4). We say that the original hypergraph G

280

D.1 Covering Augmented Hypergraphs

281
(cid:4) can also be viewed
that any Markov random ﬁeld (MRF) deﬁned by G
as an MRF on a covering hypergraph G, simply by setting θh = 0 for
all h ∈ E\E

(cid:4).

Example D.1(Covering Hypergraph). To illustrate, suppose that
(cid:4) is simply an ordinary graph — namely,
the original hypergraph G
the 3 × 3 grid shown in Figure D.1(a). As illustrated in panel (b),
we cluster the nodes into groups of four, which is known as Kikuchi
4-plaque clustering in statistical physics [268, 269]. We then form
the augmented hypergraph G shown in panel (c), with hyperedge set
E := V ∪ E
. The dark-
ness of the boxes in this diagram reﬂects the depth of the hyperedges in
the poset diagram. This hypergraph covers the original (hyper)graph,
since it includes as hyperedges all edges and vertices of the original
3 × 3 grid.

(cid:4) ∪(cid:14){1,2,4,5},{2,3,5,6},{4,5,7,8},{5,6,8,9}(cid:15)

As emphasized by Yedidia et al. [269], it turns out to be impor-
tant to ensure that every hyperedge (including vertices) in the orig-
(cid:4) is counted exactly once in the augmented hyper-
inal hypergraph G
graph G. More speciﬁcally, for a given hyperedge h ∈ E, consider the
set A+(h) := {f ∈ E | f ⊇ h} of hyperedges in E that contain h. Let
us recall the deﬁnition (4.46) of the overcounting numbers associated
with the hypergraph G. In particular, these overcounting numbers are
deﬁned in terms of the M¨obius function associated with G, viewed as
a poset, in the following way:

c(f) :=

ω(f, e),

(D.1)

(cid:6)

e∈A+(f)

The single counting criterion requires that for all vertices or hyper-
(cid:4) ∪ V — there holds

edges of the original graph — that is, for all h

(cid:4) ∈ E

c(f) = 1.

(D.2)

(cid:6)

f∈A+(h(cid:2))

In words, the sum of the overcounting numbers over all hyperedges f
that contain h

(cid:4) must be equal to one.

282 Clustering and Augmented Hypergraphs

1

4

7

2

5

3

6

8

9

1

4

7

2

5

8

3

6

9

1

1 2

2 3

3

1 4

4 7

1 2 4 5

2

52

2 3 5 6

4

4 5

5

5 6

6

54

7 8

5 8

8

5 6 8 9

3 6

6 9

7

7 8

8 9

9

1 2 4 5

2 3 5 6

1 2 4 5

2 3 5 6

52

52

4 5

5

5 6

4 5

5 6

5 8

5 8

54

7 8

5 6 8 9

54

7 8

5 6 8 9

(cid:2) is a 3 × 3 grid. Its hyperedge set E

Fig. D.1 Constructing new hypergraphs via clustering and the single counting criterion.
(cid:2) consists of the union of
(a) Original (hyper)graph G
the vertex set with the (ordinary) edge set. (b) Nodes are clustered into groups of four.
(c) A covering hypergraph G formed by adjoining these 4-clusters to the original hyperedge
(cid:2). Darkness of the boxes indicates depth of the hyperedges in the poset representation.
set E
(d) An augmented hypergraph constructed by the Kikuchi method. (e) A third augmented
hypergraph that fails the single counting criterion for (5).

Example D.2 (Single Counting). To illustrate the single counting
criterion, we consider two additional hypergraphs that can be con-
structed from the 3 × 3 grid of Figure D.1(a). The vertex set and edge
(cid:4). The hypergraph
set of the grid form the original hyperedge set E

D.1 Covering Augmented Hypergraphs

283

in panel (d) is constructed by the Kikuchi method described by
Yedidia et al. [268, 269]. In this construction, we include the four
clusters, all of their pairwise intersections, and all the intersections
of intersections (only {5} in this case). The hypergraph in panel (e)
includes only the hyperedges of size four and two; that is, it omits the
hyperedge {5}.
Let us focus ﬁrst on the hypergraph (e), and understand why it
violates the single counting criterion for hyperedge {5}. Viewed as a
poset, all of the maximal hyperedges (of size four) in this hypergraph
have a counting number of c(h) = ω(h, h) = 1. Any hyperedge f of
size two has two parents, each with an overcounting number of 1, so
that c(f) = 1 − (1 + 1) = −1. The hyperedge {5} is a member of the
(cid:4) (of the 3 × 3 grid), but not of the augmented
original hyperedge set E
hypergraph. It is included in all the hyperedges, so that A+({5}) = E
h∈A+({5}) c(h) = 0. Thus, the single criterion condition fails to
and
hold for hypergraph (e). In contrast, it can be veriﬁed that for the
hypergraphs in panels (c) and (d), the single counting condition holds
for all hyperedges h

(cid:4) ∈ E

(cid:10)

(cid:4).

There is another interesting fact about hypergraphs (c) and (d).
If we eliminate from hypergraph (c) all hyperedges that have zero
overcounting numbers, the result is hypergraph (d). To understand
this reduction, consider for instance the hyperedge {1,4} which
appears in (c) but not in (d). Since it has only one parent that
is a maximal hyperedge, we have c({1,4}) = 0. In a similar fash-
ion, we see that c({1,2}) = 0. These two equalities together imply
that c({1}) = 0, so that we can eliminate hyperedges {1,2}, {1,4},
and {1} from hypergraph (c). By applying a similar argument to
the remaining hyperedges, we can fully reduce hypergraph (c) to
hypergraph (d).

It turns out that if the augmented hypergraph G covers the original
(cid:4), then the single counting criterion is always satisﬁed.
hypergraph G
(cid:4) of
Implicit in this deﬁnition of covering is that the hyperedge set E
the original hypergraph includes the vertex set, so that Equation (D.2)
should hold for the vertices. The proof is quite straightforward.

284 Clustering and Augmented Hypergraphs

(cid:10)

Lemma D.1(Single Counting). For any h ∈ E, the associated over-
e∈A+(h) c(e) = 1, which can be
counting numbers satisfy the identity

written equivalently as c(h) = 1 −(cid:10)
(cid:6)

(cid:6)

Proof. From the deﬁnition of c(h), we have the identity:

e∈A(h) c(e).

(cid:6)

c(h) =

ω(h, f).

(D.3)

h∈A+(g)

h∈A+(g)

f∈A+(h)

Considering the double sum on the right-hand side, we see that for a
ﬁxed d ∈ A+(g), there is a term ω(d, e) for each e such that g ⊆ e ⊆ d.
Using this observation, we can write

(cid:6)

(cid:6)

(cid:6)

h∈A+(g)

f∈A+(h)

ω(h, f) =

(a)=

ω(e, d)

{e|g⊆e⊆d }

δ(d, g)

(cid:6)
(cid:6)

d∈A+(g)

d∈A+(g)

(b)= 1.

Here equality (a) follows from the deﬁnition of the M¨obius function
(see Appendix E.1), and δ(d, g) is the Kronecker delta function, from
which equality (b) follows.

Thus, the construction that we have described, in which the hyper-
(cid:4) are covered
edges (including all vertices) of the original hypergraph G
by G and the partial ordering is set inclusion, ensures that the sin-
gle counting criterion is always satisﬁed. We emphasize that there is a
broad range of other possible constructions [e.g., 268, 269, 188, 167].

D.2 Speciﬁcation of Compatibility Functions

Our ﬁnal task is to specify how to assign the compatibility func-
(cid:4)) with the
tions associated with the original hypergraph G
hyperedges of the augmented hypergraph G = (V, E). It is convenient
g(xg) := exp{θg(xg)} for the compatibility func-
(cid:4)
to use the notation ψ
tions of the original hypergraph, corresponding to terms in the prod-
uct (4.48). We can extend this deﬁnition to all hyperedges in E by

(cid:4) = (V, E

h(xh) ≡ 1 for any hyperedge h ∈ E\E
(cid:4)

setting ψ
h ∈ E, we then deﬁne a new compatibility function ψh as follows:

ψh(xh) := ψ

(cid:4)
h(xh)

(cid:4)
g(xg),

ψ

(D.4)

D.2 Speciﬁcation of Compatibility Functions

285
(cid:4). For each hyperedge

(cid:2)

g∈S(h)

(cid:4)\E | g ⊂ h} is the set of hyperedges in E

(cid:4)\E that
where S(h) := {g ∈ E
are subsets of h. To illustrate this deﬁnition, consider the Kikuchi con-
struction of Figure D.1(d), which is an augmented hypergraph for
the 3 × 3 grid in Figure D.1(a). For the hyperedge (25), we have
S(25) = {(2)}, so that ψ25 = ψ
(cid:4)
2. On the other hand, for the hyper-
1245 ≡ 1 (since (1245) appears in E but not
(cid:4)
edge (1245), we have ψ
(cid:4)), and S(1245) = {(1),(12),(14)}. Accordingly, Equation (D.4)
in E
(cid:4)
(cid:2)
yields ψ1245 = ψ
14. More generally, using the deﬁnition (D.4), it
is straightforward to verify that the equivalence

(cid:2)

(cid:4)
25ψ

(cid:4)
1ψ

(cid:4)
12ψ

ψh(xh) =

h∈E

(cid:4)
g(xg)

ψ

g∈E(cid:2)

holds, so that we have preserved the structure of the original MRF.

E

Miscellaneous Results

This appendix collects together various miscellaneous results on graphi-
cal models and posets.

E.1 M¨obius Inversion

This appendix provides brief overview of the M¨obius function associ-
ated with a partially ordered set. We refer the reader to Chapter 3 of
Stanley [221] for a thorough treatment. A partially ordered set or poset
P consists of a set along with a binary relation on elements of the set,
which we denote by ⊆, satisfying reﬂexivity (g ⊆ g for all g ∈ P), anti-
symmetry (g ⊆ h and h ⊆ g implies g = h), and transitivity (f ⊆ g and
g ⊆ h implies f ⊆ g). Although posets can be deﬁned more generally,
for our purposes it suﬃces to restrict attention to ﬁnite posets.
The zeta function of a poset is a mapping ζ : P × P → R deﬁned

by

ζ(g, h) =

(E.1)
The M¨obius function ω : P × P → R arises as the multiplicative inverse
of this zeta function. It can be deﬁned in a recursive fashion, by ﬁrst

if g ⊆ h,
otherwise.

1
0

(cid:4)

286

E.2 Auxiliary Result for Proposition 9.3

287
specifying ω(g, g) = 1 for all g ∈ P, and ω(g, h) = 0 for all h (cid:1) g. Once
ω(g, f) has been deﬁned for all f such that g ⊆ f ⊂ h, we then deﬁne:
(E.2)

ω(g, h) = −

(cid:6)

ω(g, f).

{f | g⊆f⊂h}

With this deﬁnition, it can be seen that ω and ζ are multiplicative
inverses, in the sense that

ω(g, f)ζ(f, h) =

ω(g, f) = δ(g, h),

(E.3)

(cid:6)

f∈P

(cid:6)

{f | g⊆f⊆h}

where δ(g, h) is the Kronecker delta.
An especially simple example of a poset is the set P of all subsets
of {1, . . . , m}, using set inclusion as the partial order. In this case, a
straightforward calculation shows that the M¨obius function is given by
ω(g, h) = (−1)|h\g|I[g ⊆ h]. The inverse formula (E.3) then corresponds
to the assertion

(−1)

|f\g|

= δ(g, h).

(E.4)

(cid:6)

{f | g⊆f⊆h}

We now state the M¨obius inversion formula for functions deﬁned

on a poset:

Lemma E.1 (M¨obius Inversion Formula). Given functions real-
valued functions Υ and Ω deﬁned on a poset P, then
for all h ∈ P

Ω(h) =

(E.5)

Υ(g)

(cid:6)

g⊆h

if and only if

(cid:6)

g⊆h

Υ(h) =

Ω(g) ω(g, h)

for all h ∈ P.

(E.6)

E.2 Auxiliary Result for Proposition 9.3
In this appendix, we prove that the matrix B(α, β) = (−1)|β\α|I[α ⊆ β]
diagonalizes the matrix Nm[τ], for any vector τ ∈ R2m. For any pair

288 Miscellaneous Results

(cid:6)

α, β, we calculate

(cid:23)

(cid:24)

(cid:6)

|γ\α| (cid:6)

γ,δ

Nm[τ]

B(α, γ)

γ,δB(δ, β) =

(−1)
Suppose that the event {γ ⊆ β} does not hold; then there is some ele-
(cid:6)
(cid:14)
ment i ∈ γ\β. Consequently. we can write

τγ∪δ(−1)

(cid:6)

{γ | α⊆γ}

{δ| δ⊆β}

|{δ∪{i}}\β|(cid:15)

|δ\β|

|β\δ|

(−1)

|δ\β|

+ (−1)

=

τγ∪δ

=: Ψ(β).

(E.7)

(−1)

|γ\α|I[γ ⊆ β]

(−1)

|γ\α|

{δ| β⊆δ}

{δ|β⊆δ,i /∈δ}

= 0.

Otherwise, if γ ⊆ β, then we have
=

|b\β|

τγ∪δ(−1)
(cid:6)

{δ| β⊆δ}

τγ∪δ(−1)
(cid:24)
(cid:23)

Therefore, we have

(cid:6)

γ,δ

B(α, γ)

Nm[τ]

γδB(δ, β) = Ψ(β)

(cid:6)

{δ| β⊆δ}

|δ\β|

τδ (−1)
(cid:6)
(cid:6)

{γ | α⊆γ}

{γ |α⊆γ⊆β}

= Ψ(β)

(cid:4)

=

Ψ(β)
0

if α = β
otherwise,

where the ﬁnal inequality uses Equation (E.4). Thus, we have shown
that the matrix BNm[τ]BT is diagonal with entries Ψ(β). If Nm[τ] (cid:25) 0,
then by the invertibility of B, we are guaranteed that Ψ(β) ≥ 0. It
β Ψ(β) = 1. Recall that τ∅ = 1 by deﬁnition.
remains to show that
From the deﬁnition (E.7), we have

(cid:10)

(cid:6)

β

Ψ(β) =

=

(cid:6)
(cid:6)

β

(cid:6)
0 (cid:6)
τδ (−1)

{δ| β⊆δ}

τγ

{β | ∅⊆β⊆γ}

1

|δ\β|

(−1)

|γ\β|

γ
= τ∅
= 1,

where we have again used Equation (E.4) in moving from the third to
fourth lines.

E.3 Conversion to a Pairwise Markov Random Field

E.3 Pairwise Markov Random Fields

289

In this appendix, we describe how any Markov random ﬁeld with dis-
crete random variables can be converted to an equivalent pairwise form
(i.e., with interactions only between pairs of variables). To illustrate
the general principle, it suﬃces to show how to convert a compatibility
function ψ123 deﬁned on a triplet {x1, x2, x3} of random variables into a
pairwise form. To do so, we introduce an auxiliary node A, and associate
with it random variable z that takes values in the Cartesian product
space X1 × X2 × X3. In this way, each conﬁguration of z can be identi-
ﬁed with a triplet (z1, z2, z3). For each s ∈ {1,2,3}, we deﬁne a pairwise
compatibility function ψAs, corresponding to the interaction between z
and xs, by ψAs(z, xs) := [ψ123(z1, z2, z3)]1/3I[zs = xs]. (The purpose of
the 1/3 power is to incorporate ψ123 with the correct exponent.) With
this deﬁnition, it is straightforward to verify that the equivalence

(cid:6)

3(cid:2)

ψ123(x1, x2, x3) =

ψAs(z, xs)

holds, so that our augmented model faithfully captures the interaction
deﬁned on the triplet {x1, x2, x3}.

z

s=1

References

[1] A. Agresti, Categorical Data Analysis. New York: Wiley, 2002.
[2] S. M. Aji and R. J. McEliece, “The generalized distributive law,” IEEE Trans-

actions on Information Theory, vol. 46, pp. 325–343, 2000.

[3] N. I. Akhiezer, The Classical Moment Problem and Some Related Questions

in Analysis. New York: Hafner Publishing Company, 1966.

[4] S. Amari, “Diﬀerential geometry of curved exponential families — curvatures
and information loss,” Annals of Statistics, vol. 10, no. 2, pp. 357–385, 1982.
[5] S. Amari and H. Nagaoka, Methods of Information Geometry. Providence, RI:

AMS, 2000.

[6] G. An, “A note on the cluster variation method,” Journal of Statistical

Physics, vol. 52, no. 3, pp. 727–734, 1988.

[7] A. Bandyopadhyay and D. Gamarnik, “Counting without sampling: New algo-
rithms for enumeration problems wiusing statistical physics,” in Proceedings
of the 17th ACM-SIAM Symposium on Discrete Algorithms, 2006.

[8] O. Banerjee, L. El Ghaoui, and A. d’Aspremont, “Model selection through
sparse maximum likelihood estimation for multivariate Gaussian or binary
data,” Journal of Machine Learning Research, vol. 9, pp. 485–516, 2008.

[9] F. Barahona and M. Groetschel, “On the cycle polytope of a binary matroid,”

Journal on Combination Theory, Series B, vol. 40, pp. 40–62, 1986.

[10] D. Barber and W. Wiegerinck, “Tractable variational structures for approxi-
mating graphical models,” in Advances in Neural Information Processing Sys-
tems, pp. 183–189, Cambridge, MA: MIT Press, 1999.

[11] O. E. Barndorﬀ-Nielsen, Information and Exponential Families. Chichester,

UK: Wiley, 1978.

290

References

291

[12] R. J. Baxter, Exactly Solved Models in Statistical Mechanics. New York: Aca-

demic Press, 1982.

[13] M. Bayati, C. Borgs, J. Chayes, and R. Zecchina, “Belief-propagation for
weighted b-matchings on arbitrary graphs and its relation to linear programs
with integer solutions,” Technical Report arXiv: 0709 1190, Microsoft
Research, 2007.

[14] M. Bayati and C. Nair, “A rigorous proof of the cavity method for counting
matchings,” in Proceedings of the Allerton Conference on Control, Communi-
cation and Computing, Monticello, IL, 2007.

[15] M. Bayati, D. Shah, and M. Sharma, “Maximum weight matching for max-
product belief propagation,” in International Symposium on Information The-
ory, Adelaide, Australia, 2005.

[16] M. J. Beal, “Variational algorithms for approximate Bayesian inference,” PhD
thesis, Gatsby Computational Neuroscience Unit, University College, London,
2003.

[17] C. Berge, The Theory of Graphs and its Applications. New York: Wiley, 1964.
[18] E. Berlekamp, R. McEliece, and H. van Tilborg, “On the inherent intractabil-
ity of certain coding problems,” IEEE Transactions on Information Theory,
vol. 24, pp. 384–386, 1978.

[19] U. Bertele and F. Brioschi, Nonserial Dynamic Programming. New York:

Academic Press, 1972.

[20] D. P. Bertsekas, Dynamic Programming and Stochastic Control. Vol. 1. Bel-

mont, MA: Athena Scientiﬁc, 1995.

[21] D. P. Bertsekas, Nonlinear Programming. Belmont, MA: Athena Scientiﬁc,

1995.

[22] D. P. Bertsekas, Network Optimization: Continuous and Discrete Methods.

Belmont, MA: Athena Scientiﬁc, 1998.

[23] D. P. Bertsekas, Convex Analysis and Optimization. Belmont, MA: Athena

Scientiﬁc, 2003.

[24] D. Bertsimas and J. N. Tsitsiklis, Introduction to Linear Optimization. Bel-

mont, MA: Athena Scientiﬁc, 1997.

[25] J. Besag, “Spatial interaction and the statistical analysis of lattice systems,”
Journal of the Royal Statistical Society, Series B, vol. 36, pp. 192–236, 1974.
[26] J. Besag, “Statistical analysis of non-lattice data,” The Statistician, vol. 24,

no. 3, pp. 179–195, 1975.

[27] J. Besag, “On the statistical analysis of dirty pictures,” Journal of the Royal

Statistical Society, Series B, vol. 48, no. 3, pp. 259–279, 1986.

[28] J. Besag and P. J. Green, “Spatial statistics and Bayesian computation,” Jour-
nal of the Royal Statistical Society, Series B, vol. 55, no. 1, pp. 25–37, 1993.
[29] H. A. Bethe, “Statistics theory of superlattices,” Proceedings of Royal Society

London, Series A, vol. 150, no. 871, pp. 552–575, 1935.

[30] P. J. Bickel and K. A. Doksum, Mathematical statistics: basic ideas and

selected topics. Upper Saddle River, N.J.: Prentice Hall, 2001.

[31] D. M. Blei and M. I. Jordan, “Variational inference for Dirichlet process mix-

tures,” Bayesian Analysis, vol. 1, pp. 121–144, 2005.

292 References

[32] D. M. Blei, A. Y. Ng, and M. I. Jordan, “Latent Dirichlet allocation,” Journal

of Machine Learning Research, vol. 3, pp. 993–1022, 2003.

[33] H. Bodlaender, “A tourist guide through treewidth,” Acta Cybernetica, vol. 11,

pp. 1–21, 1993.

[34] B. Bollob´as, Graph Theory: An Introductory Course. New York: Springer-

Verlag, 1979.

[35] B. Bollob´as, Modern Graph Theory. New York: Springer-Verlag, 1998.
[36] E. Boros, Y. Crama, and P. L. Hammer, “Upper bounds for quadratic 0-1

maximization,” Operations Research Letters, vol. 9, pp. 73–79, 1990.

[37] E. Boros and P. L. Hammer, “Pseudo-boolean optimization,” Discrete Applied

Mathematics, vol. 123, pp. 155–225, 2002.

[38] J. Borwein and A. Lewis, Convex Analysis. New York: Springer-Verlag, 1999.
[39] S. Boyd and L. Vandenberghe, Convex Optimization. Cambridge, UK: Cam-

bridge University Press, 2004.

[40] X. Boyen and D. Koller, “Tractable inference for complex stochastic pro-
cesses,” in Proceedings of the 14th Conference on Uncertainty in Artiﬁcial
Intelligence, pp. 33–42, San Francisco, CA: Morgan Kaufmann, 1998.

[41] A. Braunstein, M. M´ezard, and R. Zecchina, “Survey propagation: An algo-

rithm for satisﬁability,” Technical Report, arXiv:cs.CC/02122002 v2, 2003.

[42] L. M. Bregman, “The relaxation method for ﬁnding the common point of
convex sets and its application to the solution of problems in convex program-
ming,” USSR Computational Mathematics and Mathematical Physics, vol. 7,
pp. 191–204, 1967.

[43] L. D. Brown, Fundamentals of Statistical Exponential Families. Hayward, CA:

Institute of Mathematical Statistics, 1986.

[44] C. B. Burge and S. Karlin, “Finding the genes in genomic DNA,” Current

Opinion in Structural Biology, vol. 8, pp. 346–354, 1998.

[45] Y. Censor and S. A. Zenios, Parallel Optimization: Theory, Algorithms, and

Applications. Oxford: Oxford University Press, 1988.

[46] M. Cetin, L. Chen, J. W. Fisher, A. T. Ihler, R. L. Moses, M. J. Wainwright,
and A. S. Willsky, “Distributed fusion in sensor networks,” IEEE Signal Pro-
cessing Magazine, vol. 23, pp. 42–55, 2006.

[47] D. Chandler, Introduction to Modern Statistical Mechanics. Oxford: Oxford

University Press, 1987.

[48] C. Chekuri, S. Khanna, J. Naor, and L. Zosin, “A linear programming formu-
lation and approximation algorithms for the metric labeling problem,” SIAM
Journal on Discrete Mathematics, vol. 18, no. 3, pp. 608–625, 2005.

[49] L. Chen, M. J. Wainwright, M. Cetin, and A. Willsky, “Multitarget-
multisensor data association using the tree-reweighted max-product algo-
rithm,” in SPIE Aerosense Conference, Orlando, FL, 2003.

[50] M. Chertkov and V. Y. Chernyak, “Loop calculus helps to improve belief
propagation and linear programming decoding of LDPC codes,” in Proceed-
ings of the Allerton Conference on Control, Communication and Computing,
Monticello, IL, 2006.

[51] M. Chertkov and V. Y. Chernyak, “Loop series for discrete statistical models

on graphs,” Journal of Statistical Mechanics, p. P06009, 2006.

References

293

[52] M. Chertkov and V. Y. Chernyak, “Loop calculus helps to improve belief
propagation and linear programming decodings of low density parity check
codes,” in Proceedings of the Allerton Conference on Control, Communication
and Computing, Monticello, IL, 2007.

[53] M. Chertkov and M. G. Stepanov, “An eﬃcient pseudo-codeword search algo-
rithm for linear programming decoding of LDPC codes,” Technical Report
arXiv:cs.IT/0601113, Los Alamos National Laboratories, 2006.

[54] S. Chopra, “On the spanning tree polyhedron,” Operations Research Letters,

vol. 8, pp. 25–29, 1989.

[55] S. Cook, “The complexity of theorem-proving procedures,” in Proceedings of
the Third Annual ACM Symposium on Theory of Computing, pp. 151–158,
1971.

[56] T. H. Cormen, C. E. Leiserson, and R. L. Rivest, Introduction to Algorithms.

Cambridge, MA: MIT Press, 1990.

[57] T. M. Cover and J. A. Thomas, Elements of Information Theory. New York:

John Wiley and Sons, 1991.

[58] G. Cross and A. Jain, “Markov random ﬁeld texture models,” IEEE Transac-
tions on Pattern Analysis and Machine Intelligence, vol. 5, pp. 25–39, 1983.
[59] I. Csisz´ar, “A geometric interpretation of Darroch and Ratcliﬀ’s generalized

iterative scaling,” Annals of Statistics, vol. 17, no. 3, pp. 1409–1413, 1989.

[60] I. Csisz´ar and G. Tusn´ady, “Information geometry and alternating minimiza-
tion procedures,” Statistics and Decisions, Supplemental Issue 1, pp. 205–237,
1984.

[61] J. N. Darroch and D. Ratcliﬀ, “Generalized iterative scaling for log-linear

models,” Annals of Mathematical Statistics, vol. 43, pp. 1470–1480, 1972.

[62] C. Daskalakis, A. G. Dimakis, R. M. Karp, and M. J. Wainwright, “Probabilis-
tic analysis of linear programming decoding,” IEEE Transactions on Infor-
mation Theory, vol. 54, no. 8, pp. 3565–3578, 2008.

[63] A. d’Aspremont, O. Banerjee, and L. El Ghaoui, “First order methods for
sparse covariance selection,” SIAM Journal on Matrix Analysis and its Appli-
cations, vol. 30, no. 1, pp. 55–66, 2008.

[64] J. Dauwels, H. A. Loeliger, P. Merkli, and M. Ostojic, “On structured-
summary propagation, LFSR synchronization, and low-complexity trellis
decoding,” in Proceedings of the Allerton Conference on Control, Commu-
nication and Computing, Monticello, IL, 2003.

[65] A. P. Dawid, “Applications of a general propagation algorithm for probabilistic

expert systems,” Statistics and Computing, vol. 2, pp. 25–36, 1992.

[66] R. Dechter, Constraint Processing. San Francisco, CA: Morgan Kaufmann,

2003.

[67] J. W. Demmel, Applied Numerical Linear Algebra. Philadelphia, PA: SIAM,

1997.

[68] A. P. Dempster, N. M. Laird, and D. B. Rubin, “Maximum likelihood from
incomplete data via the EM algorithm,” Journal of the Royal Statistical Soci-
ety, Series B, vol. 39, pp. 1–38, 1977.

[69] M. Deza and M. Laurent, Geometry of Cuts and Metric Embeddings. New

York: Springer-Verlag, 1997.

294 References

[70] A. G. Dimakis and M. J. Wainwright, “Guessing facets: Improved LP decoding
and polytope structure,” in International Symposium on Information Theory,
Seattle, WA, 2006.

[71] M. Dudik, S. J. Phillips, and R. E. Schapire, “Maximum entropy density esti-
mation with generalized regularization and an application to species distribu-
tion modeling,” Journal of Machine Learning Research, vol. 8, pp. 1217–1260,
2007.

[72] R. Durbin, S. Eddy, A. Krogh, and G. Mitchison, eds., Biological Sequence

Analysis. Cambridge, UK: Cambridge University Press, 1998.

[73] J. Edmonds, “Matroids and the greedy algorithm,” Mathematical Program-

ming, vol. 1, pp. 127–136, 1971.

[74] B. Efron, “The geometry of exponential families,” Annals of Statistics, vol. 6,

pp. 362–376, 1978.

[75] G.

Elidan,
propagation:
passing,”
tainty
2006.

in

I. McGraw,
Informed
Proceedings

and

D.

Koller,

“Residual

scheduling
the

of

asynchronous

for
22nd Conference

belief
message-
on Uncer-
Press,

in Artiﬁcial

Intelligence, Arlington, VA: AUAI

[76] J. Feldman, D. R. Karger, and M. J. Wainwright, “Linear programming-based
decoding of turbo-like codes and its relation to iterative approaches,” in Pro-
ceedings of the Allerton Conference on Control, Communication and Comput-
ing, Monticello, IL, 2002.

[77] J. Feldman, T. Malkin, R. A. Servedio, C. Stein, and M. J. Wainwright, “LP
decoding corrects a constant fraction of errors,” IEEE Transactions on Infor-
mation Theory, vol. 53, no. 1, pp. 82–89, 2007.

[78] J. Feldman, M. J. Wainwright, and D. R. Karger, “Using linear programming
to decode binary linear codes,” IEEE Transactions on Information Theory,
vol. 51, pp. 954–972, 2005.

[79] J. Felsenstein, “Evolutionary trees from DNA sequences: A maximum likeli-
hood approach,” Journal of Molecular Evolution, vol. 17, pp. 368–376, 1981.
[80] S. E. Fienberg, “Contingency tables and log-linear models: Basic results and
new developments,” Journal of the American Statistical Association, vol. 95,
no. 450, pp. 643–647, 2000.

[81] M. E. Fisher, “On the dimer solution of planar Ising models,” Journal of

Mathematical Physics, vol. 7, pp. 1776–1781, 1966.

[82] G. D. Forney, Jr., “The Viterbi algorithm,” Proceedings of the IEEE, vol. 61,

pp. 268–277, 1973.

[83] G. D. Forney, Jr., R. Koetter, F. R. Kschischang, and A. Reznick, “On the
eﬀective weights of pseudocodewords for codes deﬁned on graphs with cycles,”
in Codes, Systems and Graphical Models, pp. 101–112, New York: Springer,
2001.

[84] W. T. Freeman, E. C. Pasztor, and O. T. Carmichael, “Learning low-level
vision,” International Journal on Computer Vision, vol. 40, no. 1, pp. 25–47,
2000.

[85] B. J. Frey, R. Koetter, and N. Petrovic, “Very loopy belief propagation for
unwrapping phase images,” in Advances in Neural Information Processing
Systems, pp. 737–743, Cambridge, MA: MIT Press, 2001.

References

295

[86] B. J. Frey, R. Koetter, and A. Vardy, “Signal-space characterization of itera-
tive decoding,” IEEE Transactions on Information Theory, vol. 47, pp. 766–
781, 2001.

[87] R. G. Gallager, Low-Density Parity Check Codes. Cambridge, MA: MIT Press,

1963.

[88] A. E. Gelfand and A. F. M. Smith, “Sampling-based approaches to calculating
marginal densities,” Journal of the American Statistical Association, vol. 85,
pp. 398–409, 1990.

[89] S. Geman and D. Geman, “Stochastic relaxation, Gibbs distributions, and the
Bayesian restoration of images,” IEEE Transactions on Pattern Analysis and
Machine Intelligence, vol. 6, pp. 721–741, 1984.

[90] H. O. Georgii, Gibbs Measures and Phase Transitions. New York: De Gruyter,

1988.

[91] Z. Ghahramani and M. J. Beal, “Propagation algorithms for variational
Bayesian learning,” in Advances in Neural Information Processing Systems,
pp. 507–513, Cambridge, MA: MIT Press, 2001.

[92] Z. Ghahramani and M. I. Jordan, “Factorial hidden Markov models,” Machine

Learning, vol. 29, pp. 245–273, 1997.

[93] W. Gilks, S. Richardson, and D. Spiegelhalter, eds., Markov Chain Monte

Carlo in Practice. New York: Chapman and Hall, 1996.

[94] A. Globerson and T. Jaakkola, “Approximate inference using planar graph
decomposition,” in Advances in Neural Information Processing Systems,
pp. 473–480, Cambridge, MA: MIT Press, 2006.

[95] A. Globerson and T. Jaakkola, “Approximate inference using conditional
entropy decompositions,” in Proceedings of the Eleventh International Con-
ference on Artiﬁcial Intelligence and Statistics, San Juan, Puerto Rico, 2007.
[96] A. Globerson and T. Jaakkola, “Convergent propagation algorithms via ori-
ented trees,” in Proceedings of the 23rd Conference on Uncertainty in Artiﬁcial
Intelligence, Arlington, VA: AUAI Press, 2007.

[97] A. Globerson and T. Jaakkola, “Fixing max-product: Convergent message
passing algorithms for MAP, LP-relaxations,” in Advances in Neural Infor-
mation Processing Systems, pp. 553–560, Cambridge, MA: MIT Press, 2007.
[98] M. X. Goemans and D. P. Williamson, “Improved approximation algorithms
for maximum cut and satisﬁability problems using semideﬁnite programming,”
Journal of the ACM, vol. 42, pp. 1115–1145, 1995.

[99] G. Golub and C. Van Loan, Matrix Computations. Baltimore: Johns Hopkins

University Press, 1996.

[100] V. G´omez, J. M. Mooij, and H. J. Kappen, “Truncating the loop series expan-
sion for BP,” Journal of Machine Learning Research, vol. 8, pp. 1987–2016,
2007.

[101] D. M. Greig, B. T. Porteous, and A. H. Seheuly, “Exact maximum a posteri-
ori estimation for binary images,” Journal of the Royal Statistical Society B,
vol. 51, pp. 271–279, 1989.

[102] G. R. Grimmett, “A theorem about random ﬁelds,” Bulletin of the London

Mathematical Society, vol. 5, pp. 81–84, 1973.

[103] M. Gr¨otschel, L. Lov´asz, and A. Schrijver, Geometric Algorithms and Combi-

natorial Optimization. Berlin: Springer-Verlag, 1993.

296 References

[104] M. Gr¨otschel and K. Truemper, “Decomposition and optimization over cycles
in binary matroids,” Journal on Combination Theory, Series B, vol. 46,
pp. 306–337, 1989.

[105] P. L. Hammer, P. Hansen, and B. Simeone, “Roof duality, complementation,
and persistency in quadratic 0-1 optimization,” Mathematical Programming,
vol. 28, pp. 121–155, 1984.

[106] J. M. Hammersley and P. Cliﬀord, “Markov ﬁelds on ﬁnite graphs and lat-

tices,” Unpublished, 1971.

[107] M. Hassner and J. Sklansky, “The use of Markov random ﬁelds as models
of texture,” Computer Graphics and Image Processing, vol. 12, pp. 357–370,
1980.

[108] T. Hazan and A. Shashua, “Convergent message-passing algorithms for infer-
ence over general graphs with convex free energy,” in Proceedings of the 24th
Conference on Uncertainty in Artiﬁcial Intelligence, Arlington, VA: AUAI
Press, 2008.

[109] T. Heskes, “On the uniqueness of loopy belief propagation ﬁxed points,” Neu-

ral Computation, vol. 16, pp. 2379–2413, 2004.

[110] T. Heskes, “Convexity arguments for eﬃcient minimization of the Bethe and
Kikuchi free energies,” Journal of Artiﬁcial Intelligence Research, vol. 26,
pp. 153–190, 2006.

[111] T. Heskes, K. Albers, and B. Kappen, “Approximate inference and constrained
optimization,” in Proceedings of the 19th Conference on Uncertainty in Arti-
ﬁcial Intelligence, pp. 313–320, San Francisco, CA: Morgan Kaufmann, 2003.
[112] J. Hiriart-Urruty and C. Lemar´echal, Convex Analysis and Minimization Algo-

rithms. Vol. 1, New York: Springer-Verlag, 1993.

[113] J. Hiriart-Urruty and C. Lemar´echal, Fundamentals of Convex Analysis.

Springer-Verlag: New York, 2001.

[114] R. A. Horn and C. R. Johnson, Matrix Analysis. Cambridge, UK: Cambridge

University Press, 1985.

[115] J. Hu, H.-A. Loeliger, J. Dauwels, and F. Kschischang, “A general compu-
tation rule for lossy summaries/messages with examples from equalization,”
in Proceedings of the Allerton Conference on Control, Communication and
Computing, Monticello, IL, 2005.

[116] B. Huang and T. Jebara, “Loopy belief propagation for bipartite maximum
weight b-matching,” in Proceedings of the Eleventh International Conference
on Artiﬁcial Intelligence and Statistics, San Juan, Puerto Rico, 2007.

[117] X. Huang, A. Acero, H.-W. Hon, and R. Reddy, Spoken Language Processing.

New York: Prentice Hall, 2001.

[118] A. Ihler, J. Fisher, and A. S. Willsky, “Loopy belief propagation: Convergence
and eﬀects of message errors,” Journal of Machine Learning Research, vol. 6,
pp. 905–936, 2005.

[119] E. Ising, “Beitrag zur theorie der ferromagnetismus,” Zeitschrift f¨ur Physik,

vol. 31, pp. 253–258, 1925.

[120] T. S. Jaakkola, “Tutorial on variational approximation methods,” in Advanced
Mean Field Methods: Theory and Practice, (M. Opper and D. Saad, eds.),
pp. 129–160, Cambridge, MA: MIT Press, 2001.

References

297

[121] T. S. Jaakkola and M. I. Jordan, “Improving the mean ﬁeld approximation
via the use of mixture distributions,” in Learning in Graphical Models, (M. I.
Jordan, ed.), pp. 105–161, MIT Press, 1999.

[122] T. S. Jaakkola and M. I. Jordan, “Variational probabilistic inference and
the QMR-DT network,” Journal of Artiﬁcial Intelligence Research, vol. 10,
pp. 291–322, 1999.

[123] E. T. Jaynes, “Information theory and statistical mechanics,” Physical Review,

vol. 106, pp. 620–630, 1957.

[124] J. K. Johnson, D. M. Malioutov, and A. S. Willsky, “Lagrangian relaxation
for MAP estimation in graphical models,” in Proceedings of the Allerton Con-
ference on Control, Communication and Computing, Monticello, IL, 2007.

[125] M. I. Jordan, Z. Ghahramani, T. S. Jaakkola, and L. Saul, “An introduction to
variational methods for graphical models,” Machine Learning, vol. 37, pp. 183–
233, 1999.

[126] T. Kailath, A. H. Sayed, and B. Hassibi, Linear Estimation. Englewood Cliﬀs,

NJ: Prentice Hall, 2000.

[127] H. Kappen and P. Rodriguez, “Eﬃcient learning in Boltzmann machines using

linear response theory,” Neural Computation, vol. 10, pp. 1137–1156, 1998.

[128] H. J. Kappen and W. Wiegerinck, “Novel iteration schemes for the cluster
variation method,” in Advances in Neural Information Processing Systems,
pp. 415–422, Cambridge, MA: MIT Press, 2002.

[129] D. Karger and N. Srebro, “Learning Markov networks: Maximum bounded
tree-width graphs,” in Symposium on Discrete Algorithms, pp. 392–401, 2001.
[130] S. Karlin and W. Studden, Tchebycheﬀ Systems, with Applications in Analysis

and Statistics. New York: Interscience Publishers, 1966.

[131] R. Karp, “Reducibility among combinatorial problems,” in Complexity of

Computer Computations, pp. 85–103, New York: Plenum Press, 1972.

[132] P. W. Kastelyn, “Dimer statistics and phase transitions,” Journal of Mathe-

matical Physics, vol. 4, pp. 287–293, 1963.

[133] R. Kikuchi, “The theory of cooperative phenomena,” Physical Review, vol. 81,

pp. 988–1003, 1951.

[134] S. Kim and M. Kojima, “Second order cone programming relaxation of non-
convex quadratic optimization problems,” Technical report, Tokyo Institute
of Technology, July 2000.

[135] J. Kleinberg and E. Tardos, “Approximation algorithms for classiﬁcation prob-
lems with pairwise relationships: Metric labeling and Markov random ﬁelds,”
Journal of the ACM, vol. 49, pp. 616–639, 2002.

[136] R. Koetter and P. O. Vontobel, “Graph-covers and iterative decoding of ﬁnite
length codes,” in Proceedings of the 3rd International Symposium on Turbo
Codes, pp. 75–82, Brest, France, 2003.

[137] V. Kolmogorov, “Convergent tree-reweighted message-passing for energy min-
imization,” IEEE Transactions on Pattern Analysis and Machine Intelligence,
vol. 28, no. 10, pp. 1568–1583, 2006.

[138] V. Kolmogorov and M. J. Wainwright, “On optimality properties of tree-
reweighted message-passing,” in Proceedings of the 21st Conference on Uncer-
tainty in Artiﬁcial Intelligence, pp. 316–322, Arlington, VA: AUAI Press, 2005.

298 References

[139] N. Komodakis, N. Paragios, and G. Tziritas, “MRF optimization via dual
decomposition: Message-passing revisited,” in International Conference on
Computer Vision, Rio de Janeiro, Brazil, 2007.

[140] V. K. Koval and M. I. Schlesinger, “Two-dimensional programming in image
analysis problems,” USSR Academy of Science, Automatics and Telemechan-
ics, vol. 8, pp. 149–168, 1976.

[141] A. Krogh, B. Larsson, G. von Heijne, and E. L. L. Sonnhammer, “Predicting
transmembrane protein topology with a hidden Markov model: Application to
complete genomes,” Journal of Molecular Biology, vol. 305, no. 3, pp. 567–580,
2001.

[142] F. R. Kschischang and B. J. Frey, “Iterative decoding of compound codes by
probability propagation in graphical models,” IEEE Selected Areas in Com-
munications, vol. 16, no. 2, pp. 219–230, 1998.

[143] F. R. Kschischang, B. J. Frey, and H.-A. Loeliger, “Factor graphs and the
sum-product algorithm,” IEEE Transactions on Information Theory, vol. 47,
no. 2, pp. 498–519, 2001.

[144] A. Kulesza and F. Pereira, “Structured learning with approximate inference,”
in Advances in Neural Information Processing Systems, pp. 785–792, Cam-
bridge, MA: MIT Press, 2008.

[145] P. Kumar, V. Kolmogorov, and P. H. S. Torr, “An analysis of convex relax-
ations for MAP estimation,” in Advances in Neural Information Processing
Systems, pp. 1041–1048, Cambridge, MA: MIT Press, 2008.

[146] P. Kumar, P. H. S. Torr, and A. Zisserman, “Solving Markov random ﬁelds
using second order cone programming,” IEEE Conference of Computer Vision
and Pattern Recognition, pp. 1045–1052, 2006.

[147] J. B. Lasserre, “An explicit equivalent positive semideﬁnite program for non-
linear 0–1 programs,” SIAM Journal on Optimization, vol. 12, pp. 756–769,
2001.

[148] J. B. Lasserre, “Global optimization with polynomials and the problem of
moments,” SIAM Journal on Optimization, vol. 11, no. 3, pp. 796–817, 2001.
[149] M. Laurent, “Semideﬁnite relaxations for Max-Cut,” in The Sharpest Cut:
Festschrift in Honor of M. Padberg’s 60th Birthday, New York: MPS-SIAM
Series in Optimization, 2002.

[150] M. Laurent, “A comparison of the Sherali-Adams, Lov´asz-Schrijver and
Lasserre relaxations for 0-1 programming,” Mathematics of Operations
Research, vol. 28, pp. 470–496, 2003.

[151] S. L. Lauritzen, Lectures on Contingency Tables. Department of Mathematics,

Aalborg University, 1989.

[152] S. L. Lauritzen, “Propagation of probabilities, means and variances in mixed
graphical association models,” Journal of the American Statistical Associa-
tion, vol. 87, pp. 1098–1108, 1992.

[153] S. L. Lauritzen, Graphical Models. Oxford: Oxford University Press, 1996.
[154] S. L. Lauritzen and D. J. Spiegelhalter, “Local computations with probabilities
on graphical structures and their application to expert systems,” Journal of
the Royal Statistical Society, Series B, vol. 50, pp. 155–224, 1988.

[155] M. A. R. Leisink and H. J. Kappen, “Learning in higher order Boltzmann
machines using linear response,” Neural Networks, vol. 13, pp. 329–335, 2000.

References

299

[156] M. A. R. Leisink and H. J. Kappen, “A tighter bound for graphical models,” in
Advances in Neural Information Processing Systems, pp. 266–272, Cambridge,
MA: MIT Press, 2001.

[157] H. A. Loeliger, “An introduction to factor graphs,” IEEE Signal Processing

Magazine, vol. 21, pp. 28–41, 2004.

[158] L. Lov´asz, “Submodular functions and convexity,” in Mathematical Program-
ming: The State of the Art, (A. Bachem, M. Gr¨otschel, and B. Korte, eds.),
pp. 235–257, New York: Springer-Verlag, 1983.

[159] L. Lov´asz and A. Schrijver, “Cones of matrices, set-functions and 0-1 opti-

mization,” SIAM Journal of Optimization, vol. 1, pp. 166–190, 1991.

[160] M. Luby, M. Mitzenmacher, M. A. Shokrollahi, and D. Spielman, “Improved
low-density parity check codes using irregular graphs,” IEEE Transactions on
Information Theory, vol. 47, pp. 585–598, 2001.

[161] D. M. Malioutov, J. M. Johnson, and A. S. Willsky, “Walk-sums and belief
propagation in Gaussian graphical models,” Journal of Machine Learning
Research, vol. 7, pp. 2013–2064, 2006.

[162] E. Maneva, E. Mossel, and M. J. Wainwright, “A new look at survey propa-
gation and its generalizations,” Journal of the ACM, vol. 54, no. 4, pp. 2–41,
2007.

[163] C. D. Manning and H. Sch¨utze, Foundations of Statistical Natural Language

Processing. Cambridge, MA: MIT Press, 1999.

[164] S. Maybeck, Stochastic Models, Estimation, and Control. New York: Academic

Press, 1982.

[165] J. McAuliﬀe, L. Pachter, and M. I. Jordan, “Multiple-sequence functional
annotation and the generalized hidden Markov phylogeny,” Bioinformatics,
vol. 20, pp. 1850–1860, 2004.

[166] R. J. McEliece, D. J. C. McKay, and J. F. Cheng, “Turbo decoding as an
instance of Pearl’s belief propagation algorithm,” IEEE Journal on Selected
Areas in Communications, vol. 16, no. 2, no. 2, pp. 140–152, 1998.

[167] R. J. McEliece and M. Yildirim, “Belief propagation on partially ordered sets,”
in Mathematical Theory of Systems and Networks, (D. Gilliam and J. Rosen-
thal, eds.), Minneapolis, MN: Institute for Mathematics and its Applications,
2002.

[168] T. Meltzer, C. Yanover, and Y. Weiss, “Globally optimal solutions for energy
minimization in stereo vision using reweighted belief propagation,” in Inter-
national Conference on Computer Vision, pp. 428–435, Silver Springs, MD:
IEEE Computer Society, 2005.

[169] M. M´ezard and A. Montanari, Information, Physics and Computation.

Oxford: Oxford University Press, 2008.

[170] M. M´ezard, G. Parisi, and R. Zecchina, “Analytic and algorithmic solution of

random satisﬁability problems,” Science, vol. 297, p. 812, 2002.

[171] M. M´ezard and R. Zecchina, “Random K-satisﬁability: From an analytic solu-

tion to an eﬃcient algorithm,” Physical Review E, vol. 66, p. 056126, 2002.

[172] T. Minka, “Expectation propagation and approximate Bayesian inference,” in
Proceedings of the 17th Conference on Uncertainty in Artiﬁcial Intelligence,
pp. 362–369, San Francisco, CA: Morgan Kaufmann, 2001.

300 References

[173] T. Minka, “Power EP,” Technical Report MSR-TR-2004-149, Microsoft

Research, October 2004.

[174] T. Minka and Y. Qi, “Tree-structured approximations by expectation propa-
gation,” in Advances in Neural Information Processing Systems, pp. 193–200,
Cambridge, MA: MIT Press, 2004.

[175] T. P. Minka, “A family of algorithms for approximate Bayesian inference,”

PhD thesis, MIT, January 2001.

[176] C. Moallemi and B. van Roy, “Convergence of the min-sum message-passing
algorithm for quadratic optimization,” Technical Report, Stanford University,
March 2006.

[177] C. Moallemi and B. van Roy, “Convergence of the min-sum algorithm for

convex optimization,” Technical Report, Stanford University, May 2007.

[178] J. M. Mooij and H. J. Kappen, “Suﬃcient conditions for convergence of loopy
belief propagation,” in Proceedings of the 21st Conference on Uncertainty in
Artiﬁcial Intelligence, pp. 396–403, Arlington, VA: AUAI Press, 2005.

[179] R. Neal and G. E. Hinton, “A view of the EM algorithm that justiﬁes incre-
mental, sparse, and other variants,” in Learning in Graphical Models, (M. I.
Jordan, ed.), Cambridge, MA: MIT Press, 1999.

[180] G. L. Nemhauser and L. A. Wolsey, Integer and Combinatorial Optimization.

New York: Wiley-Interscience, 1999.

[181] Y. Nesterov, “Semideﬁnite relaxation and non-convex quadratic optimiza-

tion,” Optimization methods and software, vol. 12, pp. 1–20, 1997.

[182] M. Opper and D. Saad, “Adaptive TAP equations,” in Advanced Mean Field
Methods: Theory and Practice, (M. Opper and D. Saad, eds.), pp. 85–98,
Cambridge, MA: MIT Press, 2001.

[183] M. Opper and O. Winther, “Gaussian processes for classiﬁcation: Mean ﬁeld

algorithms,” Neural Computation, vol. 12, no. 11, pp. 2177–2204, 2000.

[184] M. Opper and O. Winther, “Tractable approximations for probabilistic mod-
els: The adaptive Thouless-Anderson-Palmer approach,” Physical Review Let-
ters, vol. 64, p. 3695, 2001.

[185] M. Opper and O. Winther, “Expectation-consistent approximate inference,”

Journal of Machine Learning Research, vol. 6, pp. 2177–2204, 2005.

[186] J. G. Oxley, Matroid Theory. Oxford: Oxford University Press, 1992.
[187] M. Padberg, “The Boolean quadric polytope: Some characteristics, facets and

relatives,” Mathematical Programming, vol. 45, pp. 139–172, 1989.

[188] P. Pakzad and V. Anantharam, “Iterative algorithms and free energy min-
imization,” in Annual Conference on Information Sciences and Systems,
Princeton, NJ, 2002.

[189] P. Pakzad and V. Anantharam, “Estimation and marginalization using
Kikuchi approximation methods,” Neural Computation, vol. 17, no. 8,
pp. 1836–1873, 2005.

[190] G. Parisi, Statistical Field Theory. New York: Addison-Wesley, 1988.
[191] P. Parrilo, “Semideﬁnite programming relaxations for semialgebraic prob-

lems,” Mathematical Programming, Series B, vol. 96, pp. 293–320, 2003.

[192] J. Pearl, Probabilistic Reasoning in Intelligent Systems. San Francisco, CA:

Morgan Kaufmann, 1988.

References

301

[193] J. S. Pedersen and J. Hein, “Gene ﬁnding with a hidden Markov model of
genome structure and evolution,” Bioinformatics, vol. 19, pp. 219–227, 2003.
[194] P. Pevzner, Computational Molecular Biology: An Algorithmic Approach.

Cambridge, MA: MIT Press, 2000.

[195] T. Plefka, “Convergence condition of the TAP equation for the inﬁnite-ranged

Ising model,” Journal of Physics A, vol. 15, no. 6, pp. 1971–1978, 1982.

[196] L. R. Rabiner and B. H. Juang, Fundamentals of Speech Recognition. Engle-

wood Cliﬀs, NJ: Prentice Hall, 1993.

[197] P. Ravikumar, A. Agarwal, and M. J. Wainwright, “Message-passing for
graph-structured linear programs: Proximal projections, convergence and
rounding schemes,” in International Conference on Machine Learning,
pp. 800–807, New York: ACM Press, 2008.

[198] P. Ravikumar and J. Laﬀerty, “Quadratic programming relaxations for metric
labeling and Markov random ﬁeld map estimation,” International Conference
on Machine Learning, pp. 737–744, 2006.

[199] T. Richardson and R. Urbanke, “The capacity of low-density parity check
codes under message-passing decoding,” IEEE Transactions on Information
Theory, vol. 47, pp. 599–618, 2001.

[200] T. Richardson and R. Urbanke, Modern Coding Theory. Cambridge, UK:

Cambridge University Press, 2008.

[201] B. D. Ripley, Spatial Statistics. New York: Wiley, 1981.
[202] C. P. Robert and G. Casella, Monte Carlo statistical methods. Springer texts

in statistics, New York, NY: Springer-Verlag, 1999.

[203] G. Rockafellar, Convex Analysis. Princeton, NJ: Princeton University Press,

1970.

[204] T. G. Roosta, M. J. Wainwright, and S. S. Sastry, “Convergence analysis of
reweighted sum-product algorithms,” IEEE Transactions on Signal Process-
ing, vol. 56, no. 9, pp. 4293–4305, 2008.

[205] P. Rusmevichientong and B. Van Roy, “An analysis of turbo decoding with
Gaussian densities,” in Advances in Neural Information Processing Systems,
pp. 575–581, Cambridge, MA: MIT Press, 2000.

[206] S. Sanghavi, D. Malioutov, and A. Willsky, “Linear programming analysis
of loopy belief propagation for weighted matching,” in Advances in Neural
Information Processing Systems, pp. 1273–1280, Cambridge, MA: MIT Press,
2007.

[207] S. Sanghavi, D. Shah, and A. Willsky, “Message-passing for max-weight
independent set,” in Advances in Neural Information Processing Systems,
pp. 1281–1288, Cambridge, MA: MIT Press, 2007.

[208] L. K. Saul and M. I. Jordan, “Boltzmann chains and hidden Markov models,”
in Advances in Neural Information Processing Systems, pp. 435–442, Cam-
bridge, MA: MIT Press, 1995.

[209] L. K. Saul and M. I. Jordan, “Exploiting tractable substructures in intractable
networks,” in Advances in Neural Information Processing Systems, pp. 486–
492, Cambridge, MA: MIT Press, 1996.

[210] M. I. Schlesinger, “Syntactic analysis of two-dimensional visual signals in noisy

conditions,” Kibernetika, vol. 4, pp. 113–130, 1976.

302 References

[211] A. Schrijver, Theory of Linear and Integer Programming. New York: Wiley-

Interscience Series in Discrete Mathematics, 1989.

[212] A. Schrijver, Combinatorial Optimization: Polyhedra and Eﬃciency. New

York: Springer-Verlag, 2003.

[213] M. Seeger, “Expectation propagation for exponential families,” Technical

Report, Max Planck Institute, Tuebingen, November 2005.

[214] M. Seeger, F. Steinke, and K. Tsuda, “Bayesian inference and optimal design
in the sparse linear model,” in Proceedings of the Eleventh International Con-
ference on Artiﬁcial Intelligence and Statistics, San Juan, Puerto Rico, 2007.
[215] P. D. Seymour, “Matroids and multi-commodity ﬂows,” European Journal on

Combinatorics, vol. 2, pp. 257–290, 1981.

[216] G. R. Shafer and P. P. Shenoy, “Probability propagation,” Annals of Mathe-

matics and Artiﬁcial Intelligence, vol. 2, pp. 327–352, 1990.

[217] H. D. Sherali and W. P. Adams, “A hierarchy of relaxations between
the continuous and convex hull representations for zero-one programming
problems,” SIAM Journal on Discrete Mathematics, vol. 3, pp. 411–430,
1990.

[218] A. Siepel and D. Haussler, “Combining phylogenetic and hidden Markov mod-
els in biosequence analysis,” in Proceedings of the Seventh Annual Interna-
tional Conference on Computational Biology, pp. 277–286, 2003.

[219] D. Sontag and T. Jaakkola, “New outer bounds on the marginal polytope,”
in Advances in Neural Information Processing Systems, pp. 1393–1400, Cam-
bridge, MA: MIT Press, 2007.

[220] T. P. Speed and H. T. Kiiveri, “Gaussian Markov distributions over ﬁnite

graphs,” Annals of Statistics, vol. 14, no. 1, pp. 138–150, 1986.

[221] R. P. Stanley, Enumerative Combinatorics. Vol. 1, Cambridge, UK: Cambridge

University Press, 1997.

[222] R. P. Stanley, Enumerative Combinatorics. Vol. 2, Cambridge, UK: Cambridge

University Press, 1997.

[223] E. B. Sudderth, M. J. Wainwright, and A. S. Willsky, “Embedded trees: Esti-
mation of Gaussian processes on graphs with cycles,” IEEE Transactions on
Signal Processing, vol. 52, no. 11, pp. 3136–3150, 2004.

[224] E. B. Sudderth, M. J. Wainwright, and A. S. Willsky, “Loop series and Bethe
variational bounds for attractive graphical models,” in Advances in Neural
Information Processing Systems, pp. 1425–1432, Cambridge, MA: MIT Press,
2008.

[225] C. Sutton and A. McCallum, “Piecewise training of undirected models,” in
Proceedings of the 21st Conference on Uncertainty in Artiﬁcial Intelligence,
pp. 568–575, San Francisco, CA: Morgan Kaufmann, 2005.

[226] C. Sutton and A. McCallum, “Improved dyamic schedules for belief propa-
gation,” in Proceedings of the 23rd Conference on Uncertainty in Artiﬁcial
Intelligence, San Francisco, CA: Morgan Kaufmann, 2007.

[227] R. Szeliski, R. Zabih, D. Scharstein, O. Veskler, V. Kolmogorov, A. Agarwala,
M. Tappen, and C. Rother, “Comparative study of energy minimization meth-
ods for Markov random ﬁelds,” IEEE Transactions on Pattern Analysis and
Machine Intelligence, vol. 30, pp. 1068–1080, 2008.

References

303

[228] M. H. Taghavi and P. H. Siegel, “Adaptive linear programming decod-
ing,” in International Symposium on Information Theory, Seattle, WA,
2006.

[229] K. Tanaka and T. Morita, “Cluster variation method and image restoration

problem,” Physics Letters A, vol. 203, pp. 122–128, 1995.

[230] S. Tatikonda and M. I. Jordan, “Loopy belief propagation and Gibbs mea-
sures,” in Proceedings of the 18th Conference on Uncertainty in Artiﬁcial
Intelligence, pp. 493–500, San Francisco, CA: Morgan Kaufmann, 2002.

[231] Y. W. Teh and M. Welling, “On improving the eﬃciency of the iterative pro-
portional ﬁtting procedure,” in Proceedings of the Ninth International Con-
ference on Artiﬁcial Intelligence and Statistics, Key West, FL, 2003.

[232] A. Thomas, A. Gutin, V. Abkevich, and A. Bansal, “Multilocus linkage anal-
ysis by blocked Gibbs sampling,” Statistics and Computing, vol. 10, pp. 259–
269, 2000.

[233] A. W. van der Vaart, Asymptotic Statistics. Cambridge, UK: Cambridge Uni-

versity Press, 1998.

[234] L. Vandenberghe and S. Boyd, “Semideﬁnite programming,” SIAM Review,

vol. 38, pp. 49–95, 1996.

[235] L. Vandenberghe, S. Boyd, and S. Wu, “Determinant maximization with lin-
ear matrix inequality constraints,” SIAM Journal on Matrix Analysis and
Applications, vol. 19, pp. 499–533, 1998.

[236] V. V. Vazirani, Approximation Algorithms. New York: Springer-Verlag, 2003.
[237] S. Verd´u and H. V. Poor, “Abstract dynamic programming models under com-
mutativity conditions,” SIAM Journal of Control and Optimization, vol. 25,
no. 4, pp. 990–1006, 1987.

[238] P. O. Vontobel and R. Koetter, “Lower bounds on the minimum pseudo-weight
of linear codes,” in International Symposium on Information Theory, Chicago,
IL, 2004.

[239] P. O. Vontobel and R. Koetter, “Towards low-complexity linear-programming
decoding,” in Proceedings of the International Conference on Turbo Codes and
Related Topics, Munich, Germany, 2006.

[240] M. J. Wainwright, “Stochastic processes on graphs with cycles: Geometric and

variational approaches,” PhD thesis, MIT, May 2002.

[241] M. J. Wainwright, “Estimating the “wrong” graphical model: Beneﬁts in the
computation-limited regime,” Journal of Machine Learning Research, vol. 7,
pp. 1829–1859, 2006.

[242] M. J. Wainwright, T. S. Jaakkola, and A. S. Willsky, “Tree-based repara-
meterization framework for analysis of sum-product and related algorithms,”
IEEE Transactions on Information Theory, vol. 49, no. 5, pp. 1120–1146, 2003.
[243] M. J. Wainwright, T. S. Jaakkola, and A. S. Willsky, “Tree-reweighted belief
propagation algorithms and approximate ML, estimation by pseudomoment
matching,” in Proceedings of the Ninth International Conference on Artiﬁcial
Intelligence and Statistics, 2003.

[244] M. J. Wainwright, T. S. Jaakkola, and A. S. Willsky, “Tree consistency and
bounds on the max-product algorithm and its generalizations,” Statistics and
Computing, vol. 14, pp. 143–166, 2004.

304 References

[245] M. J. Wainwright, T. S. Jaakkola, and A. S. Willsky, “Exact MAP estimates
via agreement on (hyper)trees: Linear programming and message-passing,”
IEEE Transactions on Information Theory, vol. 51, no. 11, pp. 3697–3717,
2005.

[246] M. J. Wainwright, T. S. Jaakkola, and A. S. Willsky, “A new class of upper
bounds on the log partition function,” IEEE Transactions on Information
Theory, vol. 51, no. 7, pp. 2313–2335, 2005.

[247] M. J. Wainwright and M. I. Jordan, “Treewidth-based conditions for exact-
ness of the Sherali-Adams and Lasserre relaxations,” Technical Report 671,
University of California, Berkeley, Department of Statistics, September 2004.
[248] M. J. Wainwright and M. I. Jordan, “Log-determinant relaxation for approx-
imate inference in discrete Markov random ﬁelds,” IEEE Transactions on
Signal Processing, vol. 54, no. 6, pp. 2099–2109, 2006.

[249] Y. Weiss, “Correctness of local probability propagation in graphical models

with loops,” Neural Computation, vol. 12, pp. 1–41, 2000.

[250] Y. Weiss and W. T. Freeman, “Correctness of belief propagation in Gaussian
graphical models of arbitrary topology,” in Advances in Neural Information
Processing Systems, pp. 673–679, Cambridge, MA: MIT Press, 2000.

[251] Y. Weiss, C. Yanover, and T. Meltzer, “MAP estimation, linear programming,
and belief propagation with convex free energies,” in Proceedings of the 23rd
Conference on Uncertainty in Artiﬁcial Intelligence, Arlington, VA: AUAI
Press, 2007.

[252] M. Welling, T. Minka, and Y. W. Teh, “Structured region graphs: Morph-
ing EP into GBP,” in Proceedings of the 21st Conference on Uncertainty in
Artiﬁcial Intelligence, pp. 609–614, Arlington, VA: AUAI Press, 2005.

[253] M. Welling and S. Parise, “Bayesian random ﬁelds: The Bethe-Laplace
approximation,” in Proceedings of the 22nd Conference on Uncertainty in Arti-
ﬁcial Intelligence, Arlington, VA: AUAI Press, 2006.

[254] M. Welling and Y. W. Teh, “Belief optimization: A stable alternative to loopy
belief propagation,” in Proceedings of the 17th Conference on Uncertainty in
Artiﬁcial Intelligence, pp. 554–561, San Francisco, CA: Morgan Kaufmann,
2001.

[255] M. Welling and Y. W. Teh, “Linear response for approximate inference,” in
Advances in Neural Information Processing Systems, pp. 361–368, Cambridge,
MA: MIT Press, 2004.

[256] T. Werner, “A linear programming approach to max-sum problem: A review,”
IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 29,
no. 7, pp. 1165–1179, 2007.

[257] N. Wiberg, “Codes and decoding on general graphs,” PhD thesis, University

of Linkoping, Sweden, 1996.

[258] N. Wiberg, H. A. Loeliger, and R. Koetter, “Codes and iterative decoding
on general graphs,” European Transactions on Telecommunications, vol. 6,
pp. 513–526, 1995.

[259] W. Wiegerinck, “Variational approximations between mean ﬁeld theory and
the junction tree algorithm,” in Proceedings of the 16th Conference on Uncer-
tainty in Artiﬁcial Intelligence, pp. 626–633, San Francisco, CA: Morgan Kauf-
mann Publishers, 2000.

References

305

[260] W. Wiegerinck, “Approximations with reweighted generalized belief propaga-
tion,” in Proceedings of the Tenth International Workshop on Artiﬁcial Intel-
ligence and Statistics, pp. 421–428, Barbardos, 2005.

[261] W. Wiegerinck and T. Heskes, “Fractional belief propagation,” in Advances in
Neural Information Processing Systems, pp. 438–445, Cambridge, MA: MIT
Press, 2002.

[262] A. S. Willsky, “Multiresolution Markov models for signal and image process-

ing,” Proceedings of the IEEE, vol. 90, no. 8, pp. 1396–1458, 2002.

[263] J. W. Woods, “Markov image modeling,” IEEE Transactions on Automatic

Control, vol. 23, pp. 846–850, 1978.

[264] N. Wu, The Maximum Entropy Method. New York: Springer, 1997.
[265] C. Yanover, T. Meltzer, and Y. Weiss, “Linear programming relaxations
and belief propagation: An empirical study,” Journal of Machine Learning
Research, vol. 7, pp. 1887–1907, 2006.

[266] C. Yanover, O. Schueler-Furman, and Y. Weiss, “Minimizing and learning
energy functions for side-chain prediction,” in Eleventh Annual Conference
on Research in Computational Molecular Biology, pp. 381–395, San Francisco,
CA, 2007.

[267] J. S. Yedidia, “An idiosyncratic journey beyond mean ﬁeld theory,” in
Advanced Mean Field Methods: Theory and Practice, (M. Opper and D. Saad,
eds.), pp. 21–36, Cambridge, MA: MIT Press, 2001.

[268] J. S. Yedidia, W. T. Freeman, and Y. Weiss, “Generalized belief propaga-
tion,” in Advances in Neural Information Processing Systems, pp. 689–695,
Cambridge, MA: MIT Press, 2001.

[269] J. S. Yedidia, W. T. Freeman, and Y. Weiss, “Constructing free energy
approximations and generalized belief propagation algorithms,” IEEE Trans-
actions on Information Theory, vol. 51, no. 7, pp. 2282–2312, 2005.

[270] A. Yuille, “CCCP algorithms to minimize the Bethe and Kikuchi free energies:
Convergent alternatives to belief propagation,” Neural Computation, vol. 14,
pp. 1691–1722, 2002.

[271] G. M. Ziegler, Lectures on Polytopes. New York: Springer-Verlag, 1995.

