Feature selection, L1 vs. 
L2 regularization, and 
rotational invariance

Andrew Ng
ICML 2004

Presented by Paul Hammon

April 14, 2005

Outline

1. Background information

2. L1-regularized logistic regression

3. Rotational invariance and L2-regularized logistic regression

4. Experimental setup and results

2

1

Overview

The author discusses regularization as a feature selection approach.

For logistic regression he proves that L1-based regularization is superior to L2
when there are many features.

He proves lower bounds for the sample complexity: the number of training 
examples needed to learn a classifier.

L1 vs. L2 regularization

Sample complexity of L1-regularized logistic regression is logarithmic in the 
number of features.

The sample complexity of L2-regularized logistic regression is linear in the 
number of features.

Simple experiments verify the superiority of L1 over L2 regularization.

3

4

2

Background: Overfitting

Supervised learning algorithms often 
over-fit training data.

Overfitting occurs when there are so 
many free parameters that the 
learning algorithm can fit the training 
data too closely.

This increases the generalization 
error.

(Duda, Hart, & Stork 2001)

The degree of overfitting depends on several factors:
• Number of training examples—more are better
• Dimensionality of the data—lower dimensionality is better
• Design of the learning algorithm—regularization is better

Overfitting example

Consider the learning algorithm 
called polynomial regression.

Polynomial regression allows one 
to find the best fit polynomial to a 
set of data points.

Leave-one-out cross-validation 
estimates how well a learning 
algorithm generalizes

CV

=

1
n

n

=
1

i

i
)(

(

y

i
)(

xf
(

;

q

(

in

2)
)

where y(i) is the class label, 
x(i) is the training example, 
f() is the classifier, 
?(n-i) is the parameters trained 
without the ith sample.

(from T. Jaakkola lecture notes)

5

6

3

(cid:229)
-
-
VC-dimension

Vapnik-Chervonenkis (VC) dimension measures the geometric 
complexity of a classifier.

VC-dimension equals to the number of points the classifier can 
"shatter."

A classifier shatters a set of points by generating all possible
labelings.

For example, the VC-dimension of 2-D linear boundaries is 3.

The VC-dimension for most models grows roughly linearly in 
the number of model parameters (Vapnik, 1982).

(from T. Jaakkola
lecture notes)

7

Sample complexity

Recall that sample complexity is number of training examples needed to 
learn a classifier.

For (unregularized) discriminative models, the sample complexity grows 
linearly with VC-dimension.

As the number of model parameters increases, more training examples are 
necessary to generalize well.

This is a problem for learning with small data sets with large numbers of 
dimensions.

8

4

Regularization and model complexity

Adding regularization to a learning algorithm avoids overfitting.

Regularization penalizes the complexity of a learning model.

Sparseness is one way to measure complexity. Sparse parameter vectors 
have few non-zero entries

Regularization based on the zero-norm maximizes sparseness, 
but  zero-norm minimization is an NP-hard problem (Weston et al. 2003).

||

q

=

||
1

(cid:230)=

||

q

||

2

=
i
1
n

=
1

i

|

q

i

1
|

2/1

n

=
1

i

q

2
i

9

10

5

Regularization based on the L1 norm drives many parameters to zero.
L2 norm regularization does not achieve the same level of sparseness (Hastie
et al 2001). 

n

||

q

||

0

=

|

q

i

0
|

=

sum

non of 

-

 
entries
zero

Logistic regression

Logistic regression (LR) is a binary classifier.

The LR model is

(
yp

=

|1

;
x

q

)

=

1
exp(

+

1

Tq

x

)

(1)

where y = {0, 1} is the class label, 
x is a training point,
? is the parameter vector, 
and the data is assumed to be drawn i.i.d. 
from a distribution D.

A logistic function turns linear predictions into 
[0, 1].

To simplify notation, each point x is formed by 
adding a constant feature, x = [x0, 1]T.
This removes the need for a separate offset 
term.

The logistic function

)(
zg

=

1
exp(

+

1

z

)

(from A. Ng lecture notes)

(cid:247)
ł
(cid:246)
(cid:231)
Ł
(cid:229)
(cid:229)
(cid:229)
-
-
Training regularized LR

To learn LR parameters we use maximum likelihood. 

Using the model in (1) and an i.i.d. assumption, we have

log

-

likelihood

q
l
)(  

=

log

)(
i

(
yp

)(
i

|

x

;

q

)

=

log

yp
(

)(
i

)(
i

|

x

q
);

i

i

where i indexes the training points.

We maximize the regularized log-likelihood

ˆ
q

=

arg

with 

R

l

q
)(max
q
q
)(

{||

q

qa
)(

R

1 q
||,||

2
}||
2

where a determines the amount of regularization.

Training regularized LR

An equivalent formulation to (2) is

max

q
s.t.

    

log

yp
(

i
)(

i
)(

|

x

q
);

i
R

q
)(

B

11

(2)

(3)

For every a in (2), and equivalent B in (3) can be found.

This relationship can be seen by forming the Lagrangian.

This formulation has the advantage that the regularization parameter B bounds 
the regularization term R(?).

The algorithm and proof for L1-regularized LR use (3).

12

6

˛
-
(cid:229)
(cid:213)
£
(cid:229)
Metrics of generalization error

One metric for error is negative log-likelihood (log-loss)

qe
)(
l

=

E
,(
Dyx

~)

[

log

(
xyp
;

|

q

)]

where the subscript (x,y)~D indicates that the expectation is for test samples 
drawn from D. 

This has a corresponding empirical log-loss of

)(ˆ
qe
l

=

m

1
m 1
=
i

log

yp
(

i
)(

i
)(

|

x

;

q

)

The proofs in this paper use this log-loss function.

Another metric is the misclassification error:

qd
)(
m

=

P
~),(
Dyx

q
(([
gt

T

x

))

y

]

where t(z) is a threshold function equal to 0 for z < 0.5 and equal to 1 
mdˆ
otherwise. This also has a corresponding empirical log-loss of      .

Regularized regression algorithm

The L1-regularized logistic regression algorithm is:

1. Split the training data S into training set S1 for the first (1-?)m examples, 

and hold-out set S2 with the remaining ?m examples.

2. For B = 0, 1, 2, …, C,

Fit a logistic regression model to the training set S1 using

max

q
s.t.

    

log

(
yp

)(
i

)(
i

|

x

q
);

i
R

q
)(

B

Store the resulting parameter vector as ?B. 

3. Pick the ?B that produces the lowest error score on the hold-out set S2.

The theoretical results in this paper only apply to the log-loss error el. 

13

14

7

-
(cid:229)
-
„
£
(cid:229)
L1-regularized logistic regression

Theorem 1: 

Let any  e > 0, d > 0, K  = 1, and 
let m be the number of training examples and n be the number of features, 
and C = rK (the largest value of B tested).

Suppose there exists a parameter vector ?* such that 
(a) only r components of ?* are non-zero, and 
(b) every component of ?* = K 

We want the parameter output by our learning algorithm to perform nearly as 
well as ?*:
)ˆ(
qe
l

qe
(
l

*)

+

e

To guarantee this with probability at least 1-d, it suffices that 

W=

m

((log

n

)

poly

,(
Kr

,

log(

/1

d

/1),

e

,

C

))

where O is a lower bound: O(g(n))=f(n) is defined by saying for some constant 
15
c>0 and large enough n, f(n)=c g(n).

Background of theorem 1 proof
The proof of this theorem relies on covering number bounds (Anthony & 
Bartlett, 1999), the detail of which is beyond the scope of this talk.

Covering numbers are used to measure the size of a parametric function 
family (Zhang, 2002).

More details can be found in (Anthony & Bartlett, 1999).

16

8

£
(cid:215)
Discussion of theorem 1

Logistic regression using the L1 norm has a sample complexity that grows 
logarithmically with the number of features.

Therefore this approach can be effectively applied when there are many more 
irrelevant features than there are training examples.

This approach can be applied to L1 regularization of generalized linear models 
(GLMs).

17

GLM motivation: logistic regression

For logistic regression we have

(
yp

=

|1

x
;

q

)

=

)
The distribution is Bernoulli with

1

q

x

T

1
exp(

+

=

T

g

q
(

x

)

=

|0

(
yp

;
x
|1
The conditional expectation is

(
yp

x
;

q

-=
1)

=

q

)

=
(1]
yp

|

[

xyE

;
x
|0
To summarize, for logistic regression,

|1

;
x

q

+
(0)
yp

=

=

=

q

)

g

Tq
(

x

)

[
xyE
xyp
(

|
|

x

=
Tq
]
(
g
 a is )
Bernoulli
 
distributi

)

on

18

9

-
GLM motivation: linear regression

For linear regression we have

;
(
xyp

|

sq

,

2

)

=

T

N

q
(

x

,

s

2

)

=

1
2/1
p
)2(

s

1
s
2

e

(

y

2

q

T

2

x

)

The conditional expectation is

xyE

[

|

Tq=]

x

To summarize, for linear regression,

[
xyE
xyp
(

|
|

Tq=
]
 a is )

x
Gaussian 

distributi

on

19

GLMs

GLMs are a class of generative probabilistic models which generalize the setup 
for logistic regression (and other similar models) (McCullagh & Nelder, 1989).

The generalized linear model requires:

1. The data vector x enters the model as a linear combination with the

parameters, ?Tx.

2. The conditional mean µ is a function f(?Tx) called the response function

3. The observed value y is modeled as distribution from an exponential family

with conditional mean µ.

For logistic regression, 
• f(?Tx) is the logistic function g(z) = 1/(1 + exp(-z))
• p(y|x) is modeled as a Bernoulli random variable

20

10

-
-
The exponential family

GLMs involve distributions from the exponential family

(
xp

h =
)

|

1
h
)(

Z

)(
xh

exp{

Th

xT

)}(

where ? is known as the natural parameter,
h(x) and Z(?) are normalizing factors, and
T(X) is a sufficient statistic

The exponential family includes many common distributions such as
• Gaussian
• Poisson
• Bernoulli
• Multinomial

Rotational invariance

For x in Rn and rotation matrix M, Mx is x rotated about the origin by some 
angle.

Let MR = {M in Rnxn|MMT = MTM = I, |M| = +1} be the set of rotation matrices.

For a training set S = {(xi, yi)}, MS is the training set with inputs rotated by M.

Let L[S](x) be a classifier trained using S.

A learning algorithm L is rotationally invariant if L[S](x) = L[MS](Mx).

21

22

11

Rotational invariance and the L1 norm
Regularized L1 regression is not rotationally invariant.

The regularization term R(?) = ||?||1 = ? i|?i| causes this lack of invariance.

Observation: Consider the L1 norm of a point and a rotated version of that 
point.

x2

x2

p1=(1,1)T

rotate by -p /4

x1

||p1||1=2

p2=(v2,0)T
x1

||p2||1=v2

Contours of constant distance show circular symmetry for the L2 but not the L1
norm. (Hastie et al,2001)

L2 norm

L1 norm

23

Rotational invariance and L2 regularization

Proposition: L2-regularized logistic regression is rotationally invariant.

Proof:

Let S, M, x be given and let S' = MS and x' = Mx, and recall that MTM=MMT= I.

Then

1
exp(

+

1

=

T

q

x

)

1
T

+

1

exp(

q
(

(

T

xMM
)

))

=

+

1

exp(

1
q
M

(

T
()

Mx

))

so

xyp
;
(

|

q

)

=

yp
(

|

q
MMx

;

)

Recall that regularized log-likelihood is
qa
)(

(
yp

log

q
)(

= (cid:229)

R

;

q

)

J

)(
i

)(
i

|

x

Also note that regularization term 

i

R

q
)(

=

T

qqq

=

T

(

T

MM

q
)

=

(

q
M

T
()

M

q

)

=

MR

(

q

)

Define

J

q
)(

=

log

(
yp

)(
i

|

i

)(
i

q
MMx

;

)

a

q
MR

(

)

Clearly J(?) = J'(M?), and .

24

12

-
-
-
-
-
¢
(cid:229)
Rotational invariance and L2 regularization

ˆ
q

=

arg

Let
regression with data set S.

max

q J

q
)(

be the parameters for training L2-regularized logistic 

be the parameters for training with data set S'=MS.

Let

=¢
ˆ
q

Then 

q
)(

arg

max

q J¢
¢=
)ˆ
)ˆ(
q
q
J
MJ
=
ˆ
ˆ
T
q
q
M
=¢
ˆ
ˆ
q
q
M

(

and 

[
xSL
](

)

=

1

=

=

=

+

1

exp(

+
1
SL
[

exp(
x
](

1
+
exp(
1
M

()ˆ
q

T

T

ˆ
q

x

)

Mx

))

(
1
)ˆ(
q

T

x

)

)

25

Other rotationally invariant algorithms
Several other learning algorithms are also rotationally invariant:

• SVMs with linear, polynomial, RBF, and any other kernel K(x, z) which is a

function of only xTx, xTz, and zTz.

• Multilayer back-prop neural networks with weights initialized independently

from a spherically-symmetric distribution.

• Logistic regression with no regularization.

• The perceptron algorithm.

• Any algorithm using PCA or ICA for dimensionality reduction, assuming 

that there is no pre-scaling of all input features to the same variance.

26

13

¢
¢
¢
¢
¢
-
-
-
Rotational invariance & sample complexity

Theorem 2:

Let L be any rotationally invariant learning algorithm, 
0 < e < 1/8, 
0 < d < 1/100, 
m is the number of training examples, and
n is the number of features.

Then there exists a learning problem D so that: 

(i) The labels depend on a single feature: to y = 1 iff x1 = t, and

(ii) To attain e or lower 0/1 test error with probability at least 1 – d,

L requires a training set of size

m = O(n/ e)

27

Sketch of theorem 2 proof

For any rotationally invariant learning algorithm L, 
0 < e < 1/8, and
0 < d < 1/100:

Consider the concept class of all n-dimensional linear separators,

=

:

C

{
xhh
q

}0
where 1{•} is an indicator function.

qb
},

=

q
{1)(

T

x

q

The VC-dimension of C is n + 1 (Vapnik, 1982).

From a standard probability approximately correct (PAC) lower bound 
(Anthony & Bartlett, 1999) it follows that:

For L to attain e or lower 0/1 misclassication error with probability at least 1-d, 
it is necessary that the training set size be at least 

m = O(n/ e).

28

14

„
‡
Theorem 2 discussion

Rotationally-invariant learning requires a number of training examples that is 
at least linear in the number of input features.

But, a good feature selection algorithm should be able to learn with O(log n) 
examples (Ng 1998).

So, rotationally-invariant learning algorithms are ineffective for feature 
selection in high-dimensional input spaces.

Rotational invariance and SVMs

SVMs can classify well with high-dimensional input spaces,
but theorem 2 indicates that they have difficulties with many irrelevant 
features.

This can be explained by considering both the margin and the radius of the 
data.

Adding more irrelevant features does not change the margin ?.
However, it does change the radius r of the data.

The expected number of errors in SVMs is a function of r2/?2 (Vapnik, 1998).
Thus, adding irrelevant features does harm SVM performance.

29

30

15

Experimental objectives

The author designed a series of toy experiments to test the theoretical results 
of this paper.

Three different experiments compare the performance of logistic regression 
with regularization based on L1 and L2 norms.

Each experiment tests different data dimensionalities with a small number of 
relevant features.

Experimental setup

Training and test data are created with a generative logistic model

(
yp

=

|1

;
x

q

=
1/1)

+

exp(

Tq

x

)

In each case, inputs x are drawn from a multivariate normal distribution.

30% of each data set is used as the hold-out set to determine the 
regularization parameter B.

There are there different experiments:

1. Data has one relevant feature:

?1 = 10, and all other ?i = 0.

2. Data has three relevant features:

?1 = ?2 = ?3 = 10/v3, and all other ?i = 0. 

3. Data is generated with exponentially decaying features: 

?i = v75 (1/2)i-1, (i = 1)

All results are averaged over 100 trials.

31

32

16

-
Results

one relevant feature

33

34

17

Results

three relevant features

35

36

18

Results

exponential decay of relevance:
?i = v75 (1/2)i-1, (i = 1)

37

38

19

Summary

The paper proves L1 outperforms L2 regularization for logistic regression when 
there are more irrelevant dimensions than training examples.

Experiments show that L2 regularization classifies poorly for even a few 
irrelevant features.

Poor performance of L2 regularization is linked to rotational invariance.
Rotational invariance is shared by a large class of other learning algorithms.

These other algorithms presumably have similarly bad performance with 
many irrelevant dimensions.

39

References

Anthony, M., & Bartlett, P. (1999). Neural network learning: Theoretical foundations. Cambridge

University Press.

Duda, R., Hart, P., Stork, P. (2000). Pattern Classification, 2nd Ed. John Wiley & Sons.

Hastie, T., Tibshirani, R., Friedman J. (2001). The Elements of Statistical Learning. Springer-Verlag.

Jaakkola, T. (2004). Machine Learning lecture notes. Available online at

http://people.csail.mit.edu/people/tommi/courses.html

McCullagh, P., & Nelder, J. A. (1989). Generalized linear models (second edition). Chapman and

Hall.

Ng, A. Y. (1998). On feature selection: Learning with exponentially many irrelevant features as

training examples. Proceedings of the Fifteenth International Conference on Machine Learning
(pp. 404-412). Morgan Kaufmann.

Ng, A. Y. (1998). Machine Learning lecture notes. Available online at

http://www.stanford.edu/class/cs229/.

Vapnik, V. (1982). Estimation of dependences based on empirical data. Springer-Verlag.

Weston, J., Elisseeff, A., Schölkopf, B., Tipping, M. (2003). Use of the Zero-Norm with Linear Models

and Kernel Methods. Journal of Machine Learning Research, 1439-1461.

Zhang, T. (2002). Covering number bounds of certain regularized linear function classes. Journal of

40

Machine Learning Research, 527-550.

20

