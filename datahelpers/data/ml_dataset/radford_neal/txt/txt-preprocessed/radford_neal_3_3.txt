Abstract

We introduce an ecient MCMC sampling scheme to perform Bayesian inference in the
M/G/1 queueing model given only observations of interdeparture times. Our MCMC scheme
uses a combination of Gibbs sampling and simple Metropolis updates together with three
novel shift and scale updates. We show that our novel updates improve the speed of
sampling considerably, by factors of about 60 to about 180 on a variety of simulated data
sets.

This paper proposes a new approach to computation for Bayesian inference for the M/G/1
queue (Markovian arrival process/General service time distribution/1 server). Inference for this
model using ABC (Approximate Bayesian Computation) was previously considered by Bonassi
(2013), Fearnhead and Prangle (2012), and Blum and Francois (2010). ABC, in general, does not
yield samples from the exact posterior distribution. We use the strategy of considering certain
unobserved quantities as latent variables, allowing us to use Markov Chain Monte Carlo (MCMC),
which converges to the exact posterior distribution.

1 The model

In the M/G/1 queueing model, customers arrive at a single server with independent interarrival
times, Wi, distributed according to the Exp(3) distribution. Here, 3 is the arrival rate, hence
Wi has density function f (wi) = 3 exp(3wi) for wi  0 and 0 otherwise. They are served with
independent service times Ui, which have a Uniform (1, 2) distribution. (Our MCMC approach
can be generalized to other service time distributions.) We do not observe the interarrival times,
only the interdeparture times, Yi. The goal is to infer the unknown parameters of the queueing

1

model,  = (1, 2, 3), using observed interdeparture times, y = (y1, . . . , yn). We assume that the
queue is empty before the rst arrival.

The process of interdeparture times can be written as

Yi = Ui + max(cid:18)0,

i

Xj=1

Wj 

i1

Xj=1

Yj(cid:19) = Ui + max(0, Vi  Xi1)

(1)

where Wj is the time from the arrival of customer j  1 (or from 0 when j = 1) to the arrival
of customer j, Vi = Pi
j=1 Yi is the
departure time of the i-th customer, with X0 dened to be 0.

j=1 Wj is the arrival time of the i-th customer, and Xi = Pi

We take the arrival times, Vi, to be latent variables. The Vi evolve in time as a Markov

process. Viewed this way, the queueing model can be summarized as follows:

V1  Exp(3)

Vi|Vi1  Vi1 + Exp(3),

i = 2, . . . , n

Yi|Xi1, Vi  Uniform(1 + max(0, Vi  Xi1), 2 + max(0, Vi  Xi1)),

(2)
(3)
i = 1, . . . , n (4)

For convenience, set v = (v1, . . . , vn). The joint density of the Vi and the Yi can be factorized as
follows

P (v, y|) = P (v1|)

n

Yi=2

P (vi|vi1, )

n

Yi=1

P (yi|vi, xi1, )

Let () be a prior for . The posterior distribution (|y) of  is then

(|y)  ()Z   Z P (v1|)

n

n

Yi=2

P (vi|vi1, )

Yi=1

P (yi|vi, xi1, )dv1    dvn

(5)

(6)

The integral (6) cannot be computed analytically. Hence to sample from (|y) we need to include
the Vi in the MCMC state and sample from the joint posterior distribution of the Vi and  given
the data, which is

(v, |y)  ()P (v1|)

n

Yi=2

P (vi|vi1, )

n

Yi=1

P (yi|vi, xi1, )

(7)

Taking the values of  from each draw from (7) and ignoring the Vi will yield a sample from the
posterior distribution of .

2 MCMC sampling

Our MCMC procedure will be based on combining ve dierent updates. The rst is a Gibbs
update that draws new values for each Vi, given values of the other Vi, , and the data. The
second is a simple Metropolis update for , given values of the Vi and the data. The last three
updates are novel  one Metropolis shift update and two Metropolis-Hastings-Green scale
updates that propose to simultaneously change components of  and all of the Vi.

2

2.1 Gibbs updates for arrival times

We rst work out how to apply standard Gibbs sampling updates for the Vi, for which we need
to derive the full conditional density for each Vi given the other Vi and . We denote all of the
Vj except Vi as Vi. We consider three cases, when i = 1, when 2  i  n  1 and when i = n.

For the case i = 1, we have

P (v1|v1, y, )  P (v1)P (y1|v1, )P (v2|v1, )

 3e3v1I(0  v1)

I(y1  [1 + v1, 2 + v1])

2  1

 3e3(v2v1)I(v1  v2)

 I(v1  [max(0, x1  2), min(v2, x1  1)])

(8)

So, conditional on the parameters and the observed data, the distribution of V1 is Uniform(max(0, x1
2), min(v2, x1  1)).

When 2  i  n  1, we have

P (vi|vi, y, )  P (vi|vi1, )P (yi|xi1, vi, )P (vi+1|vi, )

 3e3(vivi1)I(vi1  vi)

I(yi  [1 + max(0, vi  xi1), 2 + max(0, vi  xi1)])


 3e3(vi+1vi)I(vi  vi+1)

2  1

 I(vi  [vi1, vi+1])I(yi  [1 + max(0, vi  xi1), 2 + max(0, vi  xi1)])

(9)

To simplify this expression, note that xi = yi + xi1, and rst consider the case yi > 2. When
this is so, we must have vi > xi1, hence, in this case Vi will have a Uniform distribution on
[xi  2, min(vi+1, xi  1)]. Now consider the case yi  2. We rewrite expression (9) as
I(vi  [vi1, vi+1])I(yi  [1 + max(0, vi  xi1), 2 + max(0, vi  xi1)])I(vi  xi1)
+ I(vi  [vi1, vi+1])I(yi  [1 + max(0, vi  xi1), 2 + max(0, vi  xi1)])I(vi > xi1)

= I(vi  [vi1, xi+1]) + I(vi  (xi1, min(vi+1, xi  1)])
= I(vi  [vi1, min(vi+1, xi  1)])

We see that for yi  2, Vi will have a Uniform distribution on [vi1, min(vi+1, xi  1)].

Finally, for the case i = n, we have

P (vn|vn, y, )  P (vn|vn1)P (yn|vn)

 e3(vn vn1)I(vn1  vn)

 I(yn  [1 + max(0, vn  xn1), 2 + max(0, vn  xn1)])

From this it follows that Vn will have an Exponential distribution, truncated to [xn  2, xn  1]
when yn > 2 and to [vn1, xn  1] when yn  2.

3

(10)

(11)

All of the above distributions can be easily sampled from by using the inverse CDF method.
The case i = n deserves a small note. If we suppose the truncation interval of Vn is [L, U], then
the CDF and inverse CDF will be

FVn(vn) =

e3L  e3vn
e3L  e3U , F 1

Vn (y) = log((1  y)e3L + ye3U )

(12)

So we can sample Vn as F 1

Vn (R) where R is Uniform(0, 1).

2.2 Simple Metropolis updates for parameters

We use simple Metropolis updates (Metropolis, et al (1953)) to sample from the conditional
posterior distribution of  given values of the Vi and the data, (|v, y)  (v, |y).

When doing simple Metropolis updates of  given the arrival times and the data, we used the

1-to-1 reparametrization  = (1, 2, 3) = (1, 2  1, log(3)).

A simple Metropolis update for  that leaves (|v, y) invariant proceeds as follows. We choose
a symmetric proposal density q(|), for which q( |) = q(| ). Given the current value , we
generate a proposal    q( |). We compute the acceptance probability

a = min(cid:18)1,

(|v, y) (cid:19)
( |v, y)

(13)

and let the new state,  , be   with probability a and otherwise reject the proposal, letting
  = .

We use a normal proposal with independent coordinates centered at the current value of ,
updating all components of  at once. If the proposed value for 1 or 2 is outside its range, the
proposal can be immediately rejected.

To prevent overow or underow, all MCMC computations use the logarithm of the posterior

(7), which (up to an additive constant) simplies to

log (v, |y) = log(()) + n log(3)  3vn  n log(2  1)

whenever the following constraints are satised

2  1 > 0
1  y1  v1
2  y1  v1
1  min(yi  max(0, vi  xi1))
2  max(yi  max(0, vi  xi1))

for all i  2
for all i  2

(14)

(15)
(16)
(17)
(18)
(19)

Otherwise, log((v, )|y)) = .

The dominant operation when computing the log likelihood for a data set of length n is check-
ing the constraints (15) to (19), which requires time proportional to n. Storing the constraints

4

on 1 and 2 given by (16) to (19) during evaluation of the log likelihood at (, vi) allows us to
evaluate the log likelihood for another  and the same vi in constant time. This allows us to do
K additional Metropolis updates for less than K times the computational cost it takes to do a
single update, which is likely to make sampling more ecient. A similar improvement in sampling
should be possible for models with other service time distributions that have low-dimensional suf-
cient statistics. As well, doing additional simple Metropolis updates makes an imperfect choice
of proposal distribution have less of an eect on sampling eciency.

2.3 Shift and scale updates

The Gibbs and simple Metropolis updates are sucient to give an ergodic MCMC scheme. How-
ever, as we will see, these updates are sometimes very inecient when used on their own. In this
section, we introduce our novel shift and scale updates, which can make MCMC sampling much
more ecient.

Shift updates and scale updates are used to sample from the joint posterior distribution of
the parameters and the latent variables, (v, |y). The shift update takes the form of a standard
Metropolis update, while the scale updates are Metropolis-Hastings-Green (MHG) updates.

In general, an MHG update proceeds as follows. We introduce an extra variable z  {1, +1}.
Given a current value (v, ) and a density q(|v, ) we generate z  q(z|v, ). We then propose
(v , , z) = g(v, , z). The function g is the inverse of itself, with a Jacobian |(v,)g(v, , z)|
which is nowhere zero or innite. We compute the acceptance probability

a = min(cid:18)1,

(, v |y)q(z|v , )

(, v|y)q(z|v, )

|(v,)g(v, , z)|(cid:19)

(20)

and let the new state, (v , ) be (v , ) with probability a and let (v , ) = (v, ) otherwise. For
more on the MHG algorithm, see Geyer (2003).

The motivation for the shift updates and scale updates is that conditioning on given values
of the arrival times constrains the range of parameter values for which the posterior density is
non-zero, preventing us from changing the parameters by a signicant amount. This can lead
to inecient sampling when  is updated given the Vi.
In contrast, our new shift and scale
updates change the latent variables and the parameters simultaneously, in accordance with their
dependence structure, thus allowing for much greater changes to the parameters.

Hard constraints on  given v arent necessary for these updates to be benecial. If the service
time density were non-zero for all positive values, the distribution of  given v might still be much
more concentrated than the marginal posterior for .

2.3.1 Shift updates

We rst consider updates that shift both the minimum service time, 1, and all the arrival times,
Vi, keeping the range of service times, 2  1, xed. Note that for i = 1 and for all i when
Xi1 < Vi, we have 1 < Xi  Vi. Hence the values of one or more of the Vi will constrain how

5

much we can propose to change 1  any proposal to change 1 that violates these constraints
must be rejected.

A shift update addresses the presence of these constraints as follows. We rst draw a shift s
from any distribution symmetric around 0. Then, we propose new values V 
i = Vi s for all i and

1 = 1 + s. So, a proposal to increase the minimum service time is coupled with a simultaneous
proposal to decrease all of the arrival times in a way that keeps the constraints between the arrival
times and the minimum service time satised.

A shift proposal will be rejected if it proposes a value for V1 or 1 that is less than 0. Otherwise,

the acceptance probability for a shift update is

a = min(cid:18)1,

(, v|y) (cid:19)
(, v |y)

(21)

2.3.2 Range scale updates

Next, we consider range scale updates that propose to simultaneously change the latent variables
and the range of service times 2  1, which is also constrained by the latent variables 
specically, for V1 and for all i > 2 where Vi > Xi1, we have 2  1 > Xi  1  Vi. These
updates propose to scale the gaps Xi  1  Vi (gaps between the current arrival time and
the latest possible arrival time), while at the same time proposing to scale 2  1 by the same
amount, keeping 1 xed.

In particular, we rst x (or draw from some distribution) a scale factor crange > 0. We then
i = (X1  1) 
range(2 1). We set z = z. The Jacobian |(v,)g(v, , z)| =

draw z  Uniform{1, 1}. The function g(v, , z) proposes to change Vi to V 
cz
range(Xi 1 Vi) and 2 1 to cz
cz(n+1)
range .

A range scale proposal will be rejected if it proposes a set of Vi for which some Vi < Vi1 or

for which V1 < 0. Otherwise, the MHG acceptance probability for a range scale update is

a = min(cid:18)1,

(, v |y)
(, v|y)

cz(n+1)

range (cid:19)

(22)

2.3.3 Rate scale updates

Finally, we consider rate scale updates that propose to simultaneously change both the interarrival
times Wi = ViVi1, and the arrival rate 3. We motivate these updates as follows. We expect the
distribution of 3 given the interarrival times Wi to be concentrated around 1/W . Consequently,
we would expect the joint posterior of 3 and the Wi to have a high density along a ridge with
values cWi and 3/c for some c, as long as cWi and 3/c do not lie in region with low probability.
So, proposing to change Wi to cWi and 3 to 3/c for some c potentially keeps us in a region of
high density.

We perform these updates in terms of 3 = log(3). In detail, this update proceeds as follows.
We rst x (or draw from some distribution) a scale crate > 0. We then draw z  Uniform{1, 1}.

6

The function g(v, , z) proposes to change all Wi to cz
z = z. The Jacobian |(v,)g(v, , z)| = czn
rate.

rateWi and 3 to 3  log(cz

rate). We set

We reject the proposal immediately if it violates the following constraints: for i where yi > 2
rateWi must be in [xi  2, xi  1], and for i where yi  2,
i  xi  1. Otherwise, the MHG acceptance probability for a rate scale update

the proposed arrival time V 
we must have V 
is

i = Pn

i=1 cz

a = min(cid:18)1,

( , v |y)
(, v|y)

czn

rate(cid:19)

(23)

2.3.4 Ergodicity

Although a scheme consisting of the shift, range scale, and rate scale updates changes all of the
latent variables and parameters, it is not ergodic. To see this, consider updating the arrival
times Vi, or equivalently, interarrival times Wi = Vi  Vi1. Shift updates do not change the
interarrival times. Range scale updates with scale factor crange change each interarrival time as
W 
rangeWi, and rate scale updates with scale factor crate change each interarrival
time as W 
rateWi. If we are in a situation where Wi = Wj and yi = yj for one or more j 6= i,
then all subsequent updates will keep Wi = Wj. Note that this is true even if crange and crate are
randomly selected at each update.

i = yi(1cz

range)+cz

i = cz

Hence, our novel updates must still be combined with simple Gibbs sampling updates of the
Vis to get an ergodic sampling scheme. We also still do simple Metropolis updates for . Although
this is not essential for ergodicity, it makes sampling a lot more ecient.

3 An empirical study

The goal of our empirical study is to determine when using the novel updates improves sampling
eciency. We generate three simulated data sets that are representative of a range of possible
scenarios, sample from the posterior distributions of  for each of these data sets using various
sampling schemes, and compute autocorrelation times to compare sampling eciency.

3.1 Simulated data from three scenarios

The sort of data arising from the observation of a queueing system can be roughly classied into
one of three scenarios.

The rst scenario is when the interarrival times are, on average, smaller than the service times,
that is, arrivals are relatively frequent. In this case the queue is generally full, and empty only
early on. Hence, most observed interdeparture times will tend to come from the service time
distribution, and only a small number of interdeparture times will be relevant for inferring the
arrival rate. Consequently, we expect there to be large uncertainty in 3, but less for 1 and 2.

7

25

20

15

10

h

t

g
n
e
L



e
u
e
u
Q

5

0
0

50

100

150
Time

200

250

h

t

g
n
e
L



e
u
e
u
Q

8

6

4

2

0
0

50

100

150
Time

200

250

1

h

t

g
n
e
L



e
u
e
u
Q

0
0

1000

2000

Time

3000

4000

(a)  = (8, 16, 0.15)

(b)  = (4, 7, 0.15)

(c)  = (1, 2, 0.01)

Figure 1: The three data sets.

The second scenario is when interarrival times are on average slightly larger than the service
times. The queue is then sometimes empty, and sometimes contains a number of people. In this
case, we expect the data to be informative about all parameters. This is also the case of most
practical interest, as it corresponds to how we may expect a queueing system to behave in the
real world.

The third scenario is when arrivals happen rarely, while the service time is relatively small.
In this case, the queue will usually be empty. Interarrival times are then informative for inferring
3, as most of them will come from the Exp(3) distribution with a small amount of added
Uniform(1, 2) noise. However, inference of the service time bounds 1 and 2 will now be based
on how signicantly the distribution of the interarrival times (for a given 3) deviates from the
Exponential distribution. This dierence may be rather small, and so we expect that the posterior
for the service time bounds will be rather diuse.

The three data sets we generated each consisted of n = 50 interdeparture times, corresponding
to each of the three scenarios above. For the rst scenario we take  = (8, 16, 0.15), for the second,
 = (4, 7, 0.15), and for the third,  = (1, 2, 0.01).

The plots in Figure 1 of the number of people in the queue up until the last arrival against
time for each of the three data sets demonstrate that the data sets have the desired qualitative
properties.

Numerical values of the simulated interdeparture times are presented in Table 1.

3.2 Experimental setup

We now compare the eciency of ve dierent MCMC schemes for performing Bayesian inference
for  by drawing samples from the posterior. These are

1) The basic scheme: Gibbs sampling for Vi with simple Metropolis updates for .

2) Basic scheme plus shift updates.

3) Basic scheme plus range scale updates.

8

Frequent

Intermediate

Rare

21.77

10.30

206.34

8.57

45.79

233.13

128.30

59.73

4.59

3.21

185.29

2.49

4.63

72.48

22.47

195.34

85.92

8.39

23.30

4.24

42.78

332.64

16.91

6.26

39.44

27.16

29.53

93.65

42.60

176.36

34.69

345.20

128.16

307.50

6.19

6.04

9.52

4.49

4.36

9.86

9.91

5.02

5.76

4.67

6.25

4.77

5.52

6.10

6.67

6.88

5.64

4.42

4.45

4.77

6.52

4.76

6.44

4.73

6.79

5.05

4.59

4.75

5.85

5.42

5.05

6.49

5.76

8.67

11.57

13.44

13.24

9.30

8.95

11.99

15.68

10.72

12.68

9.79

14.01

10.04

12.05

13.59

15.13

15.67

12.38

9.11

9.19

10.06

14.73

10.03

14.51

9.95

15.43

10.80

9.57

10.01

12.93

11.79

10.81

14.65

12.68

12.40

15.34

10.29

14.06

14.03

11.04

12.54

8.61

8.43

12.25

14.23

15.47

9.04

12.55

11.76

8.10

10.70

16.65

233.54

4.86

6.27

6.26

5.14

18.79

36.88

114.85

4.73

10.60

337.02

4.23

6.15

5.59

6.34

6.80

4.39

5.71

5.41

4.04

5.01

81.89

96.33

27.20

23.16

167.89

70.58

81.28

43.55

33.88

28.47

Table 1: Simulated interdeparture times yi

9

4) Basic scheme plus rate scale updates.

5) Basic scheme plus shift, rate scale, and range scale updates.

We put Uniform(0, 10) priors on 1 and on 2  1, and a Uniform(0, 1/3) prior on 3. These

are the priors that were used by Fearnhead and Prangle (2012). The prior () for  is then

()  I(1  [0, 10])I(2  1  [0, 10])I(3  [0, 1/3])

(24)

In the  parametrization, the priors on 1 and 2 remain Uniform(0, 10), while the prior for 3,
due to the log transformation, is now proportional to exp(3) on (, log(1/3)) and 0 otherwise.
In order to compare MCMC methods fairly, we need to reasonably tune their parameters
(such as the standard deviations of Metropolis proposals). In practice, tuning is usually done
by guesswork and trial and error. But for these experiments, in order to avoid the inuence
of arbitrary choices, we use trial runs to ensure a reasonable choice of tuning parameters, even
though in practice the time for such trial runs might exceed the gain compared to just making
an educated guess.

We chose the standard deviations for the normal proposal in the simple Metropolis updates for
 by performing a number of pilot runs (using the basic scheme plus shift, rate scale, and range
scale updates), nding estimates of the marginal posterior standard deviations of each component
of , and taking scalings of these estimated standard deviations as the corresponding proposal
standard deviations.

The rationale for this choice of proposal standard deviations is as follows. One extreme case
is when knowing the latent variables will give little additional information beyond the data for
inferring the parameters, so the standard deviations of the marginal posterior will correspond
closely to the standard deviations of the posterior given the latent variables and the data. The
other extreme case is when the posterior given the latent variables and the data is a lot more
concentrated than the marginal posterior, perhaps for a subset of the parameters. In most cases,
however, the situation will be between these two extremes, so the marginal posterior standard
deviations will provide a reasonable guide to setting proposal standard deviations. The case of
rare arrivals is closer to the second extreme, when the knowing the latent variables will tend to
strongly constrain 1 and 2, so we take a much smaller scaling for them than for 3.

For each simulated data set, we chose the number of simple Metropolis updates to perform in
each iteration of a scheme by looking at the performance of the basic scheme with 1, 2, 4, 8, 16, 32
Metropolis updates.

For each shift update, we drew a shift s from a N(0, 2

shift) distribution. For both scale updates
we set xed scales crange and crate. The chosen settings of tuning parameters for the dierent
scenarios are presented in Table 2.

We initialized 1 to min(yi), 2 and 3 to their prior means, and the latent variables Vi to
xi  min(yi), both for the pilot runs used to determine tuning settings and for the main runs used
to compare the relative eciency of dierent MCMC schemes.

10

Scenario

Est. stdev. of (1, 2, 3)

Scaling

Met. prop. stdev.

Met. updates

Frequent

(0.1701, 0.2399, 0.3051)

Intermediate

(0.0764, 0.1093, 0.1441)

0.7

1

(0.1191, 0.1679, 0.2136)

(0.0764, 0.1093, 0.1441)

Rare

(0.6554, 2.0711, 0.1403)

(0.1, 0.1, 1)

(0.0655, 0.2071, 0.1403)

1

16

16

2

shift

0.3

0.2

2

crange

1.008

1.03

1.4

crate

1.7

1.004

1.00005

Table 2: Tuning settings for the dierent samplers.

Scenario

Basic

Basic + Shift

Basic + Range

Basic + Rate

Basic + All

Frequent

Intermediate

Rare

20

5.2

5.2

10.8

4.2

4.2

10.8

4.2

4.2

9.6

4

4

5.1

2.9

2.9

Table 3: Run lengths for dierent scenarios and samplers, in millions of iterations.

3.3 Results

We compared the peformance of our dierent MCMC schemes with the tuning settings in Table
2 on the three data scenarios. Run lengths were chosen to take about the same amount of time
for each MCMC scheme, a total of about 43 minutes per run using MATLAB on a Linux system
with an Intel Xeon X5680 3.33 GHz CPU. Table 3 presents the run lengths. The acceptance rates
of the various updates, across dierent data sets, were all in the range 17% to 34%.

We rst veried that the dierent sampling schemes give answers which agree by estimating
the posterior means of the h, as well as the standard errors of the posterior mean estimates. For
each combination of method and data set, we estimated the posterior means by taking a grand
mean over the ve MCMC runs, after discarding 10% of each run as burn-in. (In all cases, visual
inspection of trace plots showed that the chain appears to have reached equilibrium after the rst
10% of iterations.) For each h, the standard errors of the posterior mean estimates were estimated
by computing ve posterior mean estimates using each of the ve samples separately (discarding
10% of each run as burn-in), computing the standard deviation of these posterior mean estimates,
and dividing this standard deviation by 5. The approximate condence intervals were obtained
by taking the posterior mean estimate and adding or subtracting twice the estimated standard
error of the posterior mean estimate. The results are shown in Table 4. There is no signicant
disagreement for posterior mean estimates across dierent methods.

Having established that the dierent methods we want to compare give answers which agree,
we next compare their eciency by looking at the autocorrelation times, h, of the Markov chains
used to sample h. The autocorrelation time is a common MCMC performance metric that can
be roughly interpreted as the number of draws one needs to make with the MCMC sampler to
get the equivalent of one independent point (Neal (1993)) and is dened as

h = 1 + 2



Xi=1

h,k

where h,k is the autocorrelation at lag k of the chain used to sample h.

For each combination of method and data set, for each h, we estimate h by

h = 1 + 2

Kh

Xi=1

h,k

11

(25)

(26)

Parameter

Estimates

Mean

1

CI

std. err.

Mean

2

CI

std. err.

Mean

3

CI

std. err.

Basic

7.9292

(7.9286, 7.9298)

0.00031

7.9101

(7.9092, 7.9110)

0.00045

-1.4817

(-1.4853, -1.4781)

0.00179

Basic + Shift

7.9291

(7.9287, 7.9296)

0.00022

7.9102

(7.9094, 7.9109)

0.00038

-1.4774

(-1.4816, -1.4733)

0.00207

Basic + Range

7.9292

(7.9288, 7.9296)

0.00019

7.9102

(7.9098, 7.9107)

0.00024

-1.4778

(-1.4796, -1.4760)

0.00090

Basic + Rate

7.9292

(7.9287, 7.9296)

0.00024

7.9102

(7.9094, 7.9110)

0.00041

-1.4835

(-1.4837, -1.4833)

0.00012

Basic + All

7.9293

(7.9286, 7.9301)

0.00037

7.9100

(7.9087, 7.9112)

0.00063

-1.4834

(-1.4836, -1.4832)

0.00011

(a) Frequent arrivals.

Parameter

Estimates

Mean

1

CI

std. err.

Mean

2

CI

std. err.

Mean

3

CI

std. err.

Basic

3.9612

(3.9611, 3.9613)

0.00004

2.9866

(2.9865, 2.9867)

0.00006

-1.7317

(-1.7318, -1.7317)

0.00002

Basic + Shift

3.9611

(3.9610, 3.9612)

0.00004

2.9866

(2.9865, 2.9868)

0.00007

-1.7317

(-1.7318, -1.7316)

0.00006

Basic + Range

3.9612

(3.9611, 3.9613)

0.00004

2.9865

(2.9864, 2.9866)

0.00005

-1.7318

(-1.7318, -1.7317)

0.00004

Basic + Rate

3.9611

(3.9610, 3.9613)

0.00007

2.9866

(2.9864, 2.9868)

0.00010

-1.7317

(-1.7318, -1.7316)

0.00004

Basic + All

3.9612

(3.9611, 3.9612)

0.00003

2.9865

(2.9864, 2.9866)

0.00006

-1.7316

(-1.7317, -1.7316)

0.00003

(b) Intermediate case.

Parameter

Estimates

Mean

1

CI

std. err.

Mean

2

CI

std. err.

Mean

3

CI

std. err.

Basic

1.6986

(1.6878, 1.7094)

0.00538

4.2875

(4.2330, 4.3420)

0.02725

-4.4549

(-4.4551, -4.4546)

0.00013

Basic + Shift

1.7012

(1.6984, 1.7039)

0.00138

4.3098

(4.2667, 4.3529)

0.02154

-4.4549

(-4.4550, -4.4548)

0.00005

Basic + Range

1.7038

(1.7002, 1.7074)

0.00181

4.2737

(4.2632, 4.2841)

0.00520

-4.4549

(-4.4551, -4.4547)

0.00010

Basic + Rate

1.7018

(1.6953, 1.7083)

0.00325

4.3077

(4.2631, 4.3523)

0.02230

-4.4549

(-4.4550, -4.4548)

0.00006

Basic + All

1.7003

(1.6996, 1.7010)

0.00036

4.2846

(4.2751, 4.2942)

0.00477

-4.4549

(-4.4552, -4.4546)

0.00013

(c) Rare arrivals.

Table 4: Posterior mean estimates with approximate CIs and standard errors

where the truncation point Kh is such that for k > Kh, the estimate h,k is not appreciably
dierent from 0.

To estimate h,k, we use estimates of the lag k autocovariances h,k for k = 0, . . . , Kh. These
are obtained as follows. For each of the ve samples, indexed by s = 1, . . . 5 and drawn using
some method, we rst compute an autocovariance estimate

s
h,k =

1
M

M k

Xm=1

([m,s]
h  h)([m+k,s]

h

 h)

(27)

Here M the length of the sample (after discarding 10% of the run as burn-in) and [m,s]
the m-th
value of h in the s-th sample. We take h to be the grand mean of h over all ve samples (each
of these samples has length M). We do this because it allows us to detect if the Markov chain
explores dierent regions of the parameter and latent variable space for dierent random number
generator seeds. (When the mean from one or more of the ve samples diers substantially from
the grand mean, autocovariance estimates will be much higher.)

h

We then estimate h,k by averaging autocovariance estimates from the ve samples

h,k =

1
5

5

Xs=1

s
h,k

12

(28)

Scenario

Frequent

Intermediate

Rare

Time (ms)

Frequent

Intermediate

Rare

Parameter

Basic

Basic + Shift

Basic + Range

Basic + Rate

Basic + All

1

99

46

95

95

36

2

98

75

86

94

55

3

7800

7400

5200

13

11

1

5.4

4.4

5.2

5.4

4.2

2

6.1

5.8

5.3

6.0

5.0

3

3.2

3.2

3.2

3.2

3.2

1

2

1400

4400

130

380

2100

73

1100

2800

13

40

3

5.6

4.1

4.6

4.5

4.2

Freq./Inter./Rare

0.13/0.50/0.50

0.24/0.61/0.61

0.24/0.62/0.62

0.27/0.65/0.65

0.51/0.89/0.89

1

13

11

23

26

18

2

13

18

21

25

28

3

1000

1800

1200

3.5

5.6

1

2.7

2.7

3.2

3.5

3.7

2

3

3.5

3.3

3.9

4.5

3

1.6

2.0

2.0

2.1

2.8

1

2

700

2200

79

1300

240

720

12

45

1800

36

3

2.8

2.5

2.9

2.9

3.7

Table 5: Estimates of autocorrelation times for dierent methods. Unadjusted autocorrelation
times are on the left, autocorrelation times multiplied by the average time per iteration are on
the right.

and we estimate h,k for k = 1, . . . , Kh with h,k/h,0. (In practice, for long runs, it is much
more ecient to use the fast Fourier transform (FFT) to compute the autocovariance estimates.)
Table 5 shows the estimated autocorrelation times for dierent sampling schemes. To compare
the methods fairly, we multiply each autocorrelation time by the average time per iteration.

From Table 5, we see that using just the shift, or just a scale update (either a range or a
rate scale update) improves performance for sampling parameters that are changed by one of
these updates. For a scheme which uses all updates, the greatest improvement in performance
for sampling 3 is in the case of frequent arrivals (eciency gain of 179 times), while perfomance
improvement when sampling 1 and 2 is greatest in the case of rare arrivals (eciency gains of
58 and 61 times). In other cases, performance neither increases nor decreases signicantly. These
results are in approximate agreement with the estimates of the standard errors of the posterior
mean estimates in Table 4.

In an additional run (not used to compute the autocorrelation times shown here) of the basic
plus rate scheme, for the rare arrivals scenario, we found that the sampler got stuck for a while
in a region of the parameter space. The basic and basic + shift methods (when initialized to a
state from this stuck region) also stayed in this stuck region for a while before visting other
regions. The basic plus range and basic plus all methods, when initialized with the stuck state,
quickly returned to sampling other regions. So, autocorrelation time estimates for the rare arrivals
scenario, for methods other than basic plus all and basic plus rate, probably underestimate actual
autocorrelation times.

We illustrate the performance of the samplers with trace plots in Figures 2, 3, and 4. To
produce these gures, we ran the samplers for an equal amount of computation time and thinned
each run to 4, 000 points. The black line on each plot is the true parameter value.

In the case of frequent arrivals, the marginal posterior of 3 is diuse but concentrated given
all vi and the data, so simultaneously updating all vi and 3 makes sampling more ecient. In
the case of rare arrivals, the marginal posteriors of both 1 and 2 are diuse, while they are
concentrated given all vi and the data. Simultaneously updating all vi and either 1 or 2 then
leads to a noticeable gain in eciency. In the other cases, the data is more informative about
the parameters, so additional knowledge of the latent variables does not change the concentration
of the posterior by as much. As a result, sampling eciency is not aected as signicantly by
changing the latent variables and the parameters simultaneously.

13

9

8.5

8

7.5

7

6.5

6
0

10

9.5

9

8.5

8

7.5

7
0

1

1.5

2

2.5
0

9

8.5

8

7.5

7

6.5

195,000

390,000
Iteration

585,000

780,000

6
0

50,000

100,000
Iteration

150,000

200,000

(a) 1, Basic scheme.

(b) 1, Basic + all.

195,000

390,000
Iteration

585,000

780,000

(c) 2, Basic scheme.

10

9.5

9

8.5

8

7.5

7
0

1

1.5

2

50,000

100,000
Iteration

150,000

200,000

(d) 2, Basic + all.

195,000

390,000
Iteration

585,000

780,000

2.5
0

50,000

100,000
Iteration

150,000

200,000

(e) 3, Basic scheme.

(f) 3, Basic + all.

Figure 2: Comparison of performance for frequent arrivals.

14

4.5

4

3.5

3
0

4

3.8

3.6

3.4

3.2

3

2.8

2.6

2.4

2.2

2
0

1

1.5

2

2.5
0

4.5

4

3.5

45,000

90,000
Iteration

135,000

180,000

3
0

25,000

50,000
Iteration

75,000

100,000

(a) 1, Basic scheme.

(b) 1, Basic + all.

45,000

90,000
Iteration

135,000

180,000

(c) 2, Basic scheme.

4

3.8

3.6

3.4

3.2

3

2.8

2.6

2.4

2.2

2
0

1

1.5

2

25,000

50,000
Iteration

75,000

100,000

(d) 2, Basic + all.

45,000

90,000
Iteration

135,000

180,000

2.5
0

25,000

50,000
Iteration

75,000

100,000

(e) 3, Basic scheme.

(f) 3, Basic + all.

Figure 3: Comparison of performance for intermediate case.

15

3

2.5

2

1.5

1

0.5

0

0.5

1
0

12

10

8

6

4

2

0

2
0

4

4.1

4.2

4.3

4.4

4.5

4.6

4.7

4.8

4.9

5
0

3

2.5

2

1.5

1

0.5

0

0.5

1
0

45,000

90,000
Iteration

135,000

180,000

25,000

50,000
Iteration

75,000

100,000

(a) 1, Basic scheme.

(b) 1, Basic + all.

12

10

8

6

4

2

0

45,000

90,000
Iteration

135,000

180,000

2
0

25,000

50,000
Iteration

75,000

100,000

(c) 2, Basic scheme.

(d) 2, Basic + all.

4

4.1

4.2

4.3

4.4

4.5

4.6

4.7

4.8

4.9

45,000

90,000
Iteration

135,000

180,000

5
0

25,000

50,000
Iteration

75,000

100,000

(e) 3, Basic scheme.

(f) 3, Basic + all.

Figure 4: Comparison of performance for rare arrivals.

16

4 Conclusion

In this paper, we have shown how Bayesian inference with MCMC can be performed for the
M/G/1 queueing model. As mentioned earlier, Fearnhead and Prangle (2010) used ABC for
inference in the M/G/1 queueing model. Fearnhead and Prangle (2010) also used ABC for
inference in the Ricker model of population dynamics, in which we assume that a population
process is observed with Poisson noise.

The basis of all ABC methods is the ability to simulate observations from a given stochastic
model. The simulation process for a set of observations is always driven by a latent process of
sampling and transforming certain random variables. The distributions of these random vari-
ables then determine the distribution of the nal observed quantities. If we consider the latent
variables which drive the simulation process jointly with the observations, then we can think of
the observations as coming from a model with some latent structrure. These latent variables
and the observed data will sometimes have a tractable joint density, which makes doing Bayesian
inference with MCMC possible, at least in principle.

In an earlier work, Shestopalo and Neal (2013), we used the same approach as in this paper
to do Bayesian inference for the Ricker model, i.e.
including additional latent variables in the
MCMC state and sampling for them as well as model parameters. We compared a basic MCMC
scheme with several ensemble MCMC schemes for Bayesian inference in the Ricker model, and
showed that using the ensemble schemes leads to a signicant improvement in eciency when
compared to the basic MCMC scheme. Like for the M/G/1 queueing model, we have shown that
Bayesian inference with MCMC is possible for the Ricker model, but requires more sophisticated
MCMC methods for sampling to be ecient.

It would be interesting to apply alternative inference methods for models with a time series
structure to the M/G/1 queue, for example Particle Filters and Particle Markov Chain Monte
Carlo (PMCMC) (Andrieu, Doucet, and Holenstein (2010)).

As mentioned earlier, it should be possible to extend the MCMC method in this paper to
service time distributions other than the Uniform one used in this paper. The most direct exten-
sion would be to consider location-scale service time distributions. Besides the simple Metropolis
updates, we can then do additional updates for the location parameter (or some 1-to-1 function
of it) using a shift update and additional updates for the scale parameter (or some 1-to-1 function
of it) using a range scale update. Computation would not be impacted so long as (14) can be
written in terms of low-dimensional sucient statistics.

Acknowledgements

This research was supported by the Natural Sciences and Engineering Research Council of
Canada. A. S. is in part funded by an NSERC Postgraduate Scholarship. R. N. holds a Canada
Research Chair in Statistics and Machine Learning.

17

