4
1
0
2

 

n
a
J
 

2
2

 
 
]

O
C

.
t
a
t
s
[
 
 

1
v
8
4
5
5

.

1
0
4
1
:
v
i
X
r
a

On Bayesian inference for the M/G/1 queue

with eﬃcient MCMC sampling

Alexander Y. Shestopaloﬀ

Department of Statistical Sciences

University of Toronto

alexander@utstat.utoronto.ca

Radford M. Neal

Department of Statistical Sciences
& Department of Computer Science

University of Toronto

radford@utstat.utoronto.ca

31 December 2013

Abstract

We introduce an eﬃcient MCMC sampling scheme to perform Bayesian inference in the
M/G/1 queueing model given only observations of interdeparture times. Our MCMC scheme
uses a combination of Gibbs sampling and simple Metropolis updates together with three
novel “shift” and “scale” updates. We show that our novel updates improve the speed of
sampling considerably, by factors of about 60 to about 180 on a variety of simulated data
sets.

This paper proposes a new approach to computation for Bayesian inference for the M/G/1
queue (Markovian arrival process/General service time distribution/1 server). Inference for this
model using ABC (Approximate Bayesian Computation) was previously considered by Bonassi
(2013), Fearnhead and Prangle (2012), and Blum and Francois (2010). ABC, in general, does not
yield samples from the exact posterior distribution. We use the strategy of considering certain
unobserved quantities as latent variables, allowing us to use Markov Chain Monte Carlo (MCMC),
which converges to the exact posterior distribution.

1 The model

In the M/G/1 queueing model, customers arrive at a single server with independent interarrival
times, Wi, distributed according to the Exp(θ3) distribution. Here, θ3 is the arrival rate, hence
Wi has density function f (wi) = θ3 exp(−θ3wi) for wi ≥ 0 and 0 otherwise. They are served with
independent service times Ui, which have a Uniform (θ1, θ2) distribution. (Our MCMC approach
can be generalized to other service time distributions.) We do not observe the interarrival times,
only the interdeparture times, Yi. The goal is to infer the unknown parameters of the queueing

1

model, θ = (θ1, θ2, θ3), using observed interdeparture times, y = (y1, . . . , yn). We assume that the
queue is empty before the ﬁrst arrival.

The process of interdeparture times can be written as

Yi = Ui + max(cid:18)0,

i

Xj=1

Wj −

i−1

Xj=1

Yj(cid:19) = Ui + max(0, Vi − Xi−1)

(1)

where Wj is the time from the arrival of customer j − 1 (or from 0 when j = 1) to the arrival
of customer j, Vi = Pi
j=1 Yi is the
departure time of the i-th customer, with X0 deﬁned to be 0.

j=1 Wj is the arrival time of the i-th customer, and Xi = Pi

We take the arrival times, Vi, to be latent variables. The Vi evolve in time as a Markov

process. Viewed this way, the queueing model can be summarized as follows:

V1 ∼ Exp(θ3)

Vi|Vi−1 ∼ Vi−1 + Exp(θ3),

i = 2, . . . , n

Yi|Xi−1, Vi ∼ Uniform(θ1 + max(0, Vi − Xi−1), θ2 + max(0, Vi − Xi−1)),

(2)
(3)
i = 1, . . . , n (4)

For convenience, set v = (v1, . . . , vn). The joint density of the Vi and the Yi can be factorized as
follows

P (v, y|θ) = P (v1|θ)

n

Yi=2

P (vi|vi−1, θ)

n

Yi=1

P (yi|vi, xi−1, θ)

Let π(θ) be a prior for θ. The posterior distribution π(θ|y) of θ is then

π(θ|y) ∝ π(θ)Z · · ·Z P (v1|θ)

n

n

Yi=2

P (vi|vi−1, θ)

Yi=1

P (yi|vi, xi−1, θ)dv1 · · · dvn

(5)

(6)

The integral (6) cannot be computed analytically. Hence to sample from π(θ|y) we need to include
the Vi in the MCMC state and sample from the joint posterior distribution of the Vi and θ given
the data, which is

π(v, θ|y) ∝ π(θ)P (v1|θ)

n

Yi=2

P (vi|vi−1, θ)

n

Yi=1

P (yi|vi, xi−1, θ)

(7)

Taking the values of θ from each draw from (7) and ignoring the Vi will yield a sample from the
posterior distribution of θ.

2 MCMC sampling

Our MCMC procedure will be based on combining ﬁve diﬀerent updates. The ﬁrst is a Gibbs
update that draws new values for each Vi, given values of the other Vi, θ, and the data. The
second is a simple Metropolis update for θ, given values of the Vi and the data. The last three
updates are novel — one Metropolis “shift” update and two Metropolis-Hastings-Green “scale”
updates that propose to simultaneously change components of θ and all of the Vi.

2

2.1 Gibbs updates for arrival times

We ﬁrst work out how to apply standard Gibbs sampling updates for the Vi, for which we need
to derive the full conditional density for each Vi given the other Vi and θ. We denote all of the
Vj except Vi as V−i. We consider three cases, when i = 1, when 2 ≤ i ≤ n − 1 and when i = n.

For the case i = 1, we have

P (v1|v−1, y, θ) ∝ P (v1)P (y1|v1, θ)P (v2|v1, θ)

∝ θ3e−θ3v1I(0 ≤ v1)

I(y1 ∈ [θ1 + v1, θ2 + v1])

θ2 − θ1

× θ3e−θ3(v2−v1)I(v1 ≤ v2)

∝ I(v1 ∈ [max(0, x1 − θ2), min(v2, x1 − θ1)])

(8)

So, conditional on the parameters and the observed data, the distribution of V1 is Uniform(max(0, x1−
θ2), min(v2, x1 − θ1)).

When 2 ≤ i ≤ n − 1, we have

P (vi|v−i, y, θ) ∝ P (vi|vi−1, θ)P (yi|xi−1, vi, θ)P (vi+1|vi, θ)

∝ θ3e−θ3(vi−vi−1)I(vi−1 ≤ vi)

I(yi ∈ [θ1 + max(0, vi − xi−1), θ2 + max(0, vi − xi−1)])

×
× θ3e−θ3(vi+1−vi)I(vi ≤ vi+1)

θ2 − θ1

∝ I(vi ∈ [vi−1, vi+1])I(yi ∈ [θ1 + max(0, vi − xi−1), θ2 + max(0, vi − xi−1)])

(9)

To simplify this expression, note that xi = yi + xi−1, and ﬁrst consider the case yi > θ2. When
this is so, we must have vi > xi−1, hence, in this case Vi will have a Uniform distribution on
[xi − θ2, min(vi+1, xi − θ1)]. Now consider the case yi ≤ θ2. We rewrite expression (9) as
I(vi ∈ [vi−1, vi+1])I(yi ∈ [θ1 + max(0, vi − xi−1), θ2 + max(0, vi − xi−1)])I(vi ≤ xi−1)
+ I(vi ∈ [vi−1, vi+1])I(yi ∈ [θ1 + max(0, vi − xi−1), θ2 + max(0, vi − xi−1)])I(vi > xi−1)

= I(vi ∈ [vi−1, xi+1]) + I(vi ∈ (xi−1, min(vi+1, xi − θ1)])
= I(vi ∈ [vi−1, min(vi+1, xi − θ1)])

We see that for yi ≤ θ2, Vi will have a Uniform distribution on [vi−1, min(vi+1, xi − θ1)].

Finally, for the case i = n, we have

P (vn|v−n, y, θ) ∝ P (vn|vn−1)P (yn|vn)

∝ e−θ3(vn −vn−1)I(vn−1 ≤ vn)

× I(yn ∈ [θ1 + max(0, vn − xn−1), θ2 + max(0, vn − xn−1)])

From this it follows that Vn will have an Exponential distribution, truncated to [xn − θ2, xn − θ1]
when yn > θ2 and to [vn−1, xn − θ1] when yn ≤ θ2.

3

(10)

(11)

All of the above distributions can be easily sampled from by using the inverse CDF method.
The case i = n deserves a small note. If we suppose the truncation interval of Vn is [L, U], then
the CDF and inverse CDF will be

FVn(vn) =

e−θ3L − e−θ3vn
e−θ3L − e−θ3U , F −1

Vn (y) = log((1 − y)e−θ3L + ye−θ3U )

(12)

So we can sample Vn as F −1

Vn (R) where R is Uniform(0, 1).

2.2 Simple Metropolis updates for parameters

We use simple Metropolis updates (Metropolis, et al (1953)) to sample from the conditional
posterior distribution of θ given values of the Vi and the data, π(θ|v, y) ∝ π(v, θ|y).

When doing simple Metropolis updates of θ given the arrival times and the data, we used the

1-to-1 reparametrization η = (η1, η2, η3) = (θ1, θ2 − θ1, log(θ3)).

A simple Metropolis update for η that leaves π(η|v, y) invariant proceeds as follows. We choose
a symmetric proposal density q(·|η), for which q(η ∗|η) = q(η|η ∗). Given the current value η, we
generate a proposal η ∗ ∼ q(η ∗|η). We compute the acceptance probability

a = min(cid:18)1,

π(η|v, y) (cid:19)
π(η ∗|v, y)

(13)

and let the new state, η ′, be η ∗ with probability a and otherwise reject the proposal, letting
η ′ = η.

We use a normal proposal with independent coordinates centered at the current value of η,
updating all components of η at once. If the proposed value for η1 or η2 is outside its range, the
proposal can be immediately rejected.

To prevent overﬂow or underﬂow, all MCMC computations use the logarithm of the posterior

(7), which (up to an additive constant) simpliﬁes to

log π(v, θ|y) = log(π(θ)) + n log(θ3) − θ3vn − n log(θ2 − θ1)

whenever the following constraints are satisﬁed

θ2 − θ1 > 0
θ1 ≤ y1 − v1
θ2 ≥ y1 − v1
θ1 ≤ min(yi − max(0, vi − xi−1))
θ2 ≥ max(yi − max(0, vi − xi−1))

for all i ≥ 2
for all i ≥ 2

(14)

(15)
(16)
(17)
(18)
(19)

Otherwise, log(π(v, θ)|y)) = −∞.

The dominant operation when computing the log likelihood for a data set of length n is check-
ing the constraints (15) to (19), which requires time proportional to n. Storing the constraints

4

on θ1 and θ2 given by (16) to (19) during evaluation of the log likelihood at (θ, vi) allows us to
evaluate the log likelihood for another θ∗ and the same vi in constant time. This allows us to do
K additional Metropolis updates for less than K times the computational cost it takes to do a
single update, which is likely to make sampling more eﬃcient. A similar improvement in sampling
should be possible for models with other service time distributions that have low-dimensional suf-
ﬁcient statistics. As well, doing additional simple Metropolis updates makes an imperfect choice
of proposal distribution have less of an eﬀect on sampling eﬃciency.

2.3 Shift and scale updates

The Gibbs and simple Metropolis updates are suﬃcient to give an ergodic MCMC scheme. How-
ever, as we will see, these updates are sometimes very ineﬃcient when used on their own. In this
section, we introduce our novel shift and scale updates, which can make MCMC sampling much
more eﬃcient.

Shift updates and scale updates are used to sample from the joint posterior distribution of
the parameters and the latent variables, π(v, θ|y). The shift update takes the form of a standard
Metropolis update, while the scale updates are Metropolis-Hastings-Green (MHG) updates.

In general, an MHG update proceeds as follows. We introduce an extra variable z ∈ {−1, +1}.
Given a current value (v, θ) and a density q(·|v, θ) we generate z ∼ q(z|v, θ). We then propose
(v ∗, θ∗, z∗) = g(v, θ, z). The function g is the inverse of itself, with a Jacobian |∇(v,θ)g(v, θ, z)|
which is nowhere zero or inﬁnite. We compute the acceptance probability

a = min(cid:18)1,

π(θ∗, v ∗|y)q(z∗|v ∗, θ∗)

π(θ, v|y)q(z|v, θ)

|∇(v,θ)g(v, θ, z)|(cid:19)

(20)

and let the new state, (v ′, θ′) be (v ∗, θ∗) with probability a and let (v ′, θ′) = (v, θ) otherwise. For
more on the MHG algorithm, see Geyer (2003).

The motivation for the shift updates and scale updates is that conditioning on given values
of the arrival times constrains the range of parameter values for which the posterior density is
non-zero, preventing us from changing the parameters by a signiﬁcant amount. This can lead
to ineﬃcient sampling when θ is updated given the Vi.
In contrast, our new shift and scale
updates change the latent variables and the parameters simultaneously, in accordance with their
dependence structure, thus allowing for much greater changes to the parameters.

Hard constraints on θ given v aren’t necessary for these updates to be beneﬁcial. If the service
time density were non-zero for all positive values, the distribution of θ given v might still be much
more concentrated than the marginal posterior for θ.

2.3.1 Shift updates

We ﬁrst consider updates that shift both the minimum service time, θ1, and all the arrival times,
Vi, keeping the range of service times, θ2 − θ1, ﬁxed. Note that for i = 1 and for all i when
Xi−1 < Vi, we have θ1 < Xi − Vi. Hence the values of one or more of the Vi will constrain how

5

much we can propose to change θ1 — any proposal to change θ1 that violates these constraints
must be rejected.

A shift update addresses the presence of these constraints as follows. We ﬁrst draw a shift s
from any distribution symmetric around 0. Then, we propose new values V ∗
i = Vi− s for all i and
θ∗
1 = θ1 + s. So, a proposal to increase the minimum service time is coupled with a simultaneous
proposal to decrease all of the arrival times in a way that keeps the constraints between the arrival
times and the minimum service time satisﬁed.

A shift proposal will be rejected if it proposes a value for V1 or θ1 that is less than 0. Otherwise,

the acceptance probability for a shift update is

a = min(cid:18)1,

π(θ, v|y) (cid:19)
π(θ∗, v ∗|y)

(21)

2.3.2 Range scale updates

Next, we consider range scale updates that propose to simultaneously change the latent variables
and the range of service times θ2 − θ1, which is also constrained by the latent variables —
speciﬁcally, for V1 and for all i > 2 where Vi > Xi−1, we have θ2 − θ1 > Xi − θ1 − Vi. These
updates propose to scale the “gaps” Xi − θ1 − Vi (gaps between the current arrival time and
the latest possible arrival time), while at the same time proposing to scale θ2 − θ1 by the same
amount, keeping θ1 ﬁxed.

In particular, we ﬁrst ﬁx (or draw from some distribution) a scale factor crange > 0. We then
i = (X1 − θ1) −
range(θ2− θ1). We set z∗ = −z. The Jacobian |∇(v,θ)g(v, θ, z)| =

draw z ∼ Uniform{−1, 1}. The function g(v, θ, z) proposes to change Vi to V ∗
cz
range(Xi− θ1− Vi) and θ2− θ1 to cz
cz(n+1)
range .

A range scale proposal will be rejected if it proposes a set of Vi for which some Vi < Vi−1 or

for which V1 < 0. Otherwise, the MHG acceptance probability for a range scale update is

a = min(cid:18)1,

π(θ∗, v ∗|y)
π(θ, v|y)

cz(n+1)

range (cid:19)

(22)

2.3.3 Rate scale updates

Finally, we consider rate scale updates that propose to simultaneously change both the interarrival
times Wi = Vi−Vi−1, and the arrival rate θ3. We motivate these updates as follows. We expect the
distribution of θ3 given the interarrival times Wi to be concentrated around 1/W . Consequently,
we would expect the joint posterior of θ3 and the Wi to have a high density along a ridge with
values cWi and θ3/c for some c, as long as cWi and θ3/c do not lie in region with low probability.
So, proposing to change Wi to cWi and θ3 to θ3/c for some c potentially keeps us in a region of
high density.

We perform these updates in terms of η3 = log(θ3). In detail, this update proceeds as follows.
We ﬁrst ﬁx (or draw from some distribution) a scale crate > 0. We then draw z ∼ Uniform{−1, 1}.

6

The function g(v, η, z) proposes to change all Wi to cz
z∗ = −z. The Jacobian |∇(v,η)g(v, η, z)| = czn
rate.

rateWi and η3 to η3 − log(cz

rate). We set

We reject the proposal immediately if it violates the following constraints: for i where yi > θ2
rateWi must be in [xi − θ2, xi − θ1], and for i where yi ≤ θ2,
i ≤ xi − θ1. Otherwise, the MHG acceptance probability for a rate scale update

the proposed arrival time V ∗
we must have V ∗
is

i = Pn

i=1 cz

a = min(cid:18)1,

π(η ∗, v ∗|y)
π(η, v|y)

czn

rate(cid:19)

(23)

2.3.4 Ergodicity

Although a scheme consisting of the shift, range scale, and rate scale updates changes all of the
latent variables and parameters, it is not ergodic. To see this, consider updating the arrival
times Vi, or equivalently, interarrival times Wi = Vi − Vi−1. Shift updates do not change the
interarrival times. Range scale updates with scale factor crange change each interarrival time as
W ∗
rangeWi, and rate scale updates with scale factor crate change each interarrival
time as W ∗
rateWi. If we are in a situation where Wi = Wj and yi = yj for one or more j 6= i,
then all subsequent updates will keep Wi = Wj. Note that this is true even if crange and crate are
randomly selected at each update.

i = yi(1−cz

range)+cz

i = cz

Hence, our novel updates must still be combined with simple Gibbs sampling updates of the
Vi’s to get an ergodic sampling scheme. We also still do simple Metropolis updates for θ. Although
this is not essential for ergodicity, it makes sampling a lot more eﬃcient.

3 An empirical study

The goal of our empirical study is to determine when using the novel updates improves sampling
eﬃciency. We generate three simulated data sets that are representative of a range of possible
scenarios, sample from the posterior distributions of θ for each of these data sets using various
sampling schemes, and compute autocorrelation times to compare sampling eﬃciency.

3.1 Simulated data from three scenarios

The sort of data arising from the observation of a queueing system can be roughly classiﬁed into
one of three scenarios.

The ﬁrst scenario is when the interarrival times are, on average, smaller than the service times,
that is, arrivals are relatively frequent. In this case the queue is generally full, and empty only
early on. Hence, most observed interdeparture times will tend to come from the service time
distribution, and only a small number of interdeparture times will be relevant for inferring the
arrival rate. Consequently, we expect there to be large uncertainty in θ3, but less for θ1 and θ2.

7

25

20

15

10

h

t

g
n
e
L

 

e
u
e
u
Q

5

0
0

50

100

150
Time

200

250

h

t

g
n
e
L

 

e
u
e
u
Q

8

6

4

2

0
0

50

100

150
Time

200

250

1

h

t

g
n
e
L

 

e
u
e
u
Q

0
0

1000

2000

Time

3000

4000

(a) θ = (8, 16, 0.15)

(b) θ = (4, 7, 0.15)

(c) θ = (1, 2, 0.01)

Figure 1: The three data sets.

The second scenario is when interarrival times are on average slightly larger than the service
times. The queue is then sometimes empty, and sometimes contains a number of people. In this
case, we expect the data to be informative about all parameters. This is also the case of most
practical interest, as it corresponds to how we may expect a queueing system to behave in the
real world.

The third scenario is when arrivals happen rarely, while the service time is relatively small.
In this case, the queue will usually be empty. Interarrival times are then informative for inferring
θ3, as most of them will come from the Exp(θ3) distribution with a small amount of added
Uniform(θ1, θ2) noise. However, inference of the service time bounds θ1 and θ2 will now be based
on how signiﬁcantly the distribution of the interarrival times (for a given θ3) deviates from the
Exponential distribution. This diﬀerence may be rather small, and so we expect that the posterior
for the service time bounds will be rather diﬀuse.

The three data sets we generated each consisted of n = 50 interdeparture times, corresponding
to each of the three scenarios above. For the ﬁrst scenario we take θ = (8, 16, 0.15), for the second,
θ = (4, 7, 0.15), and for the third, θ = (1, 2, 0.01).

The plots in Figure 1 of the number of people in the queue up until the last arrival against
time for each of the three data sets demonstrate that the data sets have the desired qualitative
properties.

Numerical values of the simulated interdeparture times are presented in Table 1.

3.2 Experimental setup

We now compare the eﬃciency of ﬁve diﬀerent MCMC schemes for performing Bayesian inference
for θ by drawing samples from the posterior. These are

1) The basic scheme: Gibbs sampling for Vi with simple Metropolis updates for θ.

2) Basic scheme plus shift updates.

3) Basic scheme plus range scale updates.

8

Frequent

Intermediate

Rare

21.77

10.30

206.34

8.57

45.79

233.13

128.30

59.73

4.59

3.21

185.29

2.49

4.63

72.48

22.47

195.34

85.92

8.39

23.30

4.24

42.78

332.64

16.91

6.26

39.44

27.16

29.53

93.65

42.60

176.36

34.69

345.20

128.16

307.50

6.19

6.04

9.52

4.49

4.36

9.86

9.91

5.02

5.76

4.67

6.25

4.77

5.52

6.10

6.67

6.88

5.64

4.42

4.45

4.77

6.52

4.76

6.44

4.73

6.79

5.05

4.59

4.75

5.85

5.42

5.05

6.49

5.76

8.67

11.57

13.44

13.24

9.30

8.95

11.99

15.68

10.72

12.68

9.79

14.01

10.04

12.05

13.59

15.13

15.67

12.38

9.11

9.19

10.06

14.73

10.03

14.51

9.95

15.43

10.80

9.57

10.01

12.93

11.79

10.81

14.65

12.68

12.40

15.34

10.29

14.06

14.03

11.04

12.54

8.61

8.43

12.25

14.23

15.47

9.04

12.55

11.76

8.10

10.70

16.65

233.54

4.86

6.27

6.26

5.14

18.79

36.88

114.85

4.73

10.60

337.02

4.23

6.15

5.59

6.34

6.80

4.39

5.71

5.41

4.04

5.01

81.89

96.33

27.20

23.16

167.89

70.58

81.28

43.55

33.88

28.47

Table 1: Simulated interdeparture times yi

9

4) Basic scheme plus rate scale updates.

5) Basic scheme plus shift, rate scale, and range scale updates.

We put Uniform(0, 10) priors on θ1 and on θ2 − θ1, and a Uniform(0, 1/3) prior on θ3. These

are the priors that were used by Fearnhead and Prangle (2012). The prior π(θ) for θ is then

π(θ) ∝ I(θ1 ∈ [0, 10])I(θ2 − θ1 ∈ [0, 10])I(θ3 ∈ [0, 1/3])

(24)

In the η parametrization, the priors on η1 and η2 remain Uniform(0, 10), while the prior for η3,
due to the log transformation, is now proportional to exp(η3) on (−∞, log(1/3)) and 0 otherwise.
In order to compare MCMC methods fairly, we need to reasonably tune their parameters
(such as the standard deviations of Metropolis proposals). In practice, tuning is usually done
by guesswork and trial and error. But for these experiments, in order to avoid the inﬂuence
of arbitrary choices, we use trial runs to ensure a reasonable choice of tuning parameters, even
though in practice the time for such trial runs might exceed the gain compared to just making
an educated guess.

We chose the standard deviations for the normal proposal in the simple Metropolis updates for
η by performing a number of pilot runs (using the basic scheme plus shift, rate scale, and range
scale updates), ﬁnding estimates of the marginal posterior standard deviations of each component
of η, and taking scalings of these estimated standard deviations as the corresponding proposal
standard deviations.

The rationale for this choice of proposal standard deviations is as follows. One extreme case
is when knowing the latent variables will give little additional information beyond the data for
inferring the parameters, so the standard deviations of the marginal posterior will correspond
closely to the standard deviations of the posterior given the latent variables and the data. The
other extreme case is when the posterior given the latent variables and the data is a lot more
concentrated than the marginal posterior, perhaps for a subset of the parameters. In most cases,
however, the situation will be between these two extremes, so the marginal posterior standard
deviations will provide a reasonable guide to setting proposal standard deviations. The case of
rare arrivals is closer to the second extreme, when the knowing the latent variables will tend to
strongly constrain η1 and η2, so we take a much smaller scaling for them than for η3.

For each simulated data set, we chose the number of simple Metropolis updates to perform in
each iteration of a scheme by looking at the performance of the basic scheme with 1, 2, 4, 8, 16, 32
Metropolis updates.

For each shift update, we drew a shift s from a N(0, σ2

shift) distribution. For both scale updates
we set ﬁxed scales crange and crate. The chosen settings of tuning parameters for the diﬀerent
scenarios are presented in Table 2.

We initialized η1 to min(yi), η2 and η3 to their prior means, and the latent variables Vi to
xi − min(yi), both for the pilot runs used to determine tuning settings and for the main runs used
to compare the relative eﬃciency of diﬀerent MCMC schemes.

10

Scenario

Est. stdev. of (η1, η2, η3)

Scaling

Met. prop. stdev.

Met. updates

Frequent

(0.1701, 0.2399, 0.3051)

Intermediate

(0.0764, 0.1093, 0.1441)

0.7

1

(0.1191, 0.1679, 0.2136)

(0.0764, 0.1093, 0.1441)

Rare

(0.6554, 2.0711, 0.1403)

(0.1, 0.1, 1)

(0.0655, 0.2071, 0.1403)

1

16

16

σ2

shift

0.3

0.2

2

crange

1.008

1.03

1.4

crate

1.7

1.004

1.00005

Table 2: Tuning settings for the diﬀerent samplers.

Scenario

Basic

Basic + Shift

Basic + Range

Basic + Rate

Basic + All

Frequent

Intermediate

Rare

20

5.2

5.2

10.8

4.2

4.2

10.8

4.2

4.2

9.6

4

4

5.1

2.9

2.9

Table 3: Run lengths for diﬀerent scenarios and samplers, in millions of iterations.

3.3 Results

We compared the peformance of our diﬀerent MCMC schemes with the tuning settings in Table
2 on the three data scenarios. Run lengths were chosen to take about the same amount of time
for each MCMC scheme, a total of about 43 minutes per run using MATLAB on a Linux system
with an Intel Xeon X5680 3.33 GHz CPU. Table 3 presents the run lengths. The acceptance rates
of the various updates, across diﬀerent data sets, were all in the range 17% to 34%.

We ﬁrst veriﬁed that the diﬀerent sampling schemes give answers which agree by estimating
the posterior means of the ηh, as well as the standard errors of the posterior mean estimates. For
each combination of method and data set, we estimated the posterior means by taking a grand
mean over the ﬁve MCMC runs, after discarding 10% of each run as burn-in. (In all cases, visual
inspection of trace plots showed that the chain appears to have reached equilibrium after the ﬁrst
10% of iterations.) For each ηh, the standard errors of the posterior mean estimates were estimated
by computing ﬁve posterior mean estimates using each of the ﬁve samples separately (discarding
10% of each run as burn-in), computing the standard deviation of these posterior mean estimates,
and dividing this standard deviation by √5. The approximate conﬁdence intervals were obtained
by taking the posterior mean estimate and adding or subtracting twice the estimated standard
error of the posterior mean estimate. The results are shown in Table 4. There is no signiﬁcant
disagreement for posterior mean estimates across diﬀerent methods.

Having established that the diﬀerent methods we want to compare give answers which agree,
we next compare their eﬃciency by looking at the autocorrelation times, τh, of the Markov chains
used to sample ηh. The autocorrelation time is a common MCMC performance metric that can
be roughly interpreted as the number of draws one needs to make with the MCMC sampler to
get the equivalent of one independent point (Neal (1993)) and is deﬁned as

τh = 1 + 2

∞

Xi=1

ρh,k

where ρh,k is the autocorrelation at lag k of the chain used to sample ηh.

For each combination of method and data set, for each ηh, we estimate τh by

ˆτh = 1 + 2

Kh

Xi=1

ˆρh,k

11

(25)

(26)

Parameter

Estimates

Mean

η1

CI

std. err.

Mean

η2

CI

std. err.

Mean

η3

CI

std. err.

Basic

7.9292

(7.9286, 7.9298)

0.00031

7.9101

(7.9092, 7.9110)

0.00045

-1.4817

(-1.4853, -1.4781)

0.00179

Basic + Shift

7.9291

(7.9287, 7.9296)

0.00022

7.9102

(7.9094, 7.9109)

0.00038

-1.4774

(-1.4816, -1.4733)

0.00207

Basic + Range

7.9292

(7.9288, 7.9296)

0.00019

7.9102

(7.9098, 7.9107)

0.00024

-1.4778

(-1.4796, -1.4760)

0.00090

Basic + Rate

7.9292

(7.9287, 7.9296)

0.00024

7.9102

(7.9094, 7.9110)

0.00041

-1.4835

(-1.4837, -1.4833)

0.00012

Basic + All

7.9293

(7.9286, 7.9301)

0.00037

7.9100

(7.9087, 7.9112)

0.00063

-1.4834

(-1.4836, -1.4832)

0.00011

(a) Frequent arrivals.

Parameter

Estimates

Mean

η1

CI

std. err.

Mean

η2

CI

std. err.

Mean

η3

CI

std. err.

Basic

3.9612

(3.9611, 3.9613)

0.00004

2.9866

(2.9865, 2.9867)

0.00006

-1.7317

(-1.7318, -1.7317)

0.00002

Basic + Shift

3.9611

(3.9610, 3.9612)

0.00004

2.9866

(2.9865, 2.9868)

0.00007

-1.7317

(-1.7318, -1.7316)

0.00006

Basic + Range

3.9612

(3.9611, 3.9613)

0.00004

2.9865

(2.9864, 2.9866)

0.00005

-1.7318

(-1.7318, -1.7317)

0.00004

Basic + Rate

3.9611

(3.9610, 3.9613)

0.00007

2.9866

(2.9864, 2.9868)

0.00010

-1.7317

(-1.7318, -1.7316)

0.00004

Basic + All

3.9612

(3.9611, 3.9612)

0.00003

2.9865

(2.9864, 2.9866)

0.00006

-1.7316

(-1.7317, -1.7316)

0.00003

(b) Intermediate case.

Parameter

Estimates

Mean

η1

CI

std. err.

Mean

η2

CI

std. err.

Mean

η3

CI

std. err.

Basic

1.6986

(1.6878, 1.7094)

0.00538

4.2875

(4.2330, 4.3420)

0.02725

-4.4549

(-4.4551, -4.4546)

0.00013

Basic + Shift

1.7012

(1.6984, 1.7039)

0.00138

4.3098

(4.2667, 4.3529)

0.02154

-4.4549

(-4.4550, -4.4548)

0.00005

Basic + Range

1.7038

(1.7002, 1.7074)

0.00181

4.2737

(4.2632, 4.2841)

0.00520

-4.4549

(-4.4551, -4.4547)

0.00010

Basic + Rate

1.7018

(1.6953, 1.7083)

0.00325

4.3077

(4.2631, 4.3523)

0.02230

-4.4549

(-4.4550, -4.4548)

0.00006

Basic + All

1.7003

(1.6996, 1.7010)

0.00036

4.2846

(4.2751, 4.2942)

0.00477

-4.4549

(-4.4552, -4.4546)

0.00013

(c) Rare arrivals.

Table 4: Posterior mean estimates with approximate CI’s and standard errors

where the truncation point Kh is such that for k > Kh, the estimate ˆρh,k is not appreciably
diﬀerent from 0.

To estimate ρh,k, we use estimates of the lag k autocovariances γh,k for k = 0, . . . , Kh. These
are obtained as follows. For each of the ﬁve samples, indexed by s = 1, . . . 5 and drawn using
some method, we ﬁrst compute an autocovariance estimate

ˆγs
h,k =

1
M

M −k

Xm=1

(η[m,s]
h − ηh)(η[m+k,s]

h

− ηh)

(27)

Here M the length of the sample (after discarding 10% of the run as burn-in) and η[m,s]
the m-th
value of ηh in the s-th sample. We take ηh to be the grand mean of ηh over all ﬁve samples (each
of these samples has length M). We do this because it allows us to detect if the Markov chain
explores diﬀerent regions of the parameter and latent variable space for diﬀerent random number
generator seeds. (When the mean from one or more of the ﬁve samples diﬀers substantially from
the grand mean, autocovariance estimates will be much higher.)

h

We then estimate γh,k by averaging autocovariance estimates from the ﬁve samples

ˆγh,k =

1
5

5

Xs=1

ˆγs
h,k

12

(28)

Scenario

Frequent

Intermediate

Rare

Time (ms)

Frequent

Intermediate

Rare

Parameter

Basic

Basic + Shift

Basic + Range

Basic + Rate

Basic + All

η1

99

46

95

95

36

η2

98

75

86

94

55

η3

7800

7400

5200

13

11

η1

5.4

4.4

5.2

5.4

4.2

η2

6.1

5.8

5.3

6.0

5.0

η3

3.2

3.2

3.2

3.2

3.2

η1

η2

1400

4400

130

380

2100

73

1100

2800

13

40

η3

5.6

4.1

4.6

4.5

4.2

Freq./Inter./Rare

0.13/0.50/0.50

0.24/0.61/0.61

0.24/0.62/0.62

0.27/0.65/0.65

0.51/0.89/0.89

η1

13

11

23

26

18

η2

13

18

21

25

28

η3

1000

1800

1200

3.5

5.6

η1

2.7

2.7

3.2

3.5

3.7

η2

3

3.5

3.3

3.9

4.5

η3

1.6

2.0

2.0

2.1

2.8

η1

η2

700

2200

79

1300

240

720

12

45

1800

36

η3

2.8

2.5

2.9

2.9

3.7

Table 5: Estimates of autocorrelation times for diﬀerent methods. Unadjusted autocorrelation
times are on the left, autocorrelation times multiplied by the average time per iteration are on
the right.

and we estimate ρh,k for k = 1, . . . , Kh with ˆγh,k/ˆγh,0. (In practice, for long runs, it is much
more eﬃcient to use the fast Fourier transform (FFT) to compute the autocovariance estimates.)
Table 5 shows the estimated autocorrelation times for diﬀerent sampling schemes. To compare
the methods fairly, we multiply each autocorrelation time by the average time per iteration.

From Table 5, we see that using just the shift, or just a scale update (either a range or a
rate scale update) improves performance for sampling parameters that are changed by one of
these updates. For a scheme which uses all updates, the greatest improvement in performance
for sampling η3 is in the case of frequent arrivals (eﬃciency gain of 179 times), while perfomance
improvement when sampling η1 and η2 is greatest in the case of rare arrivals (eﬃciency gains of
58 and 61 times). In other cases, performance neither increases nor decreases signiﬁcantly. These
results are in approximate agreement with the estimates of the standard errors of the posterior
mean estimates in Table 4.

In an additional run (not used to compute the autocorrelation times shown here) of the basic
plus rate scheme, for the rare arrivals scenario, we found that the sampler got stuck for a while
in a region of the parameter space. The basic and basic + shift methods (when initialized to a
state from this “stuck” region) also stayed in this “stuck” region for a while before visting other
regions. The basic plus range and basic plus all methods, when initialized with the stuck state,
quickly returned to sampling other regions. So, autocorrelation time estimates for the rare arrivals
scenario, for methods other than basic plus all and basic plus rate, probably underestimate actual
autocorrelation times.

We illustrate the performance of the samplers with trace plots in Figures 2, 3, and 4. To
produce these ﬁgures, we ran the samplers for an equal amount of computation time and thinned
each run to 4, 000 points. The black line on each plot is the true parameter value.

In the case of frequent arrivals, the marginal posterior of η3 is diﬀuse but concentrated given
all vi and the data, so simultaneously updating all vi and η3 makes sampling more eﬃcient. In
the case of rare arrivals, the marginal posteriors of both η1 and η2 are diﬀuse, while they are
concentrated given all vi and the data. Simultaneously updating all vi and either η1 or η2 then
leads to a noticeable gain in eﬃciency. In the other cases, the data is more informative about
the parameters, so additional knowledge of the latent variables does not change the concentration
of the posterior by as much. As a result, sampling eﬃciency is not aﬀected as signiﬁcantly by
changing the latent variables and the parameters simultaneously.

13

9

8.5

8

7.5

7

6.5

6
0

10

9.5

9

8.5

8

7.5

7
0

−1

−1.5

−2

−2.5
0

9

8.5

8

7.5

7

6.5

195,000

390,000
Iteration

585,000

780,000

6
0

50,000

100,000
Iteration

150,000

200,000

(a) η1, Basic scheme.

(b) η1, Basic + all.

195,000

390,000
Iteration

585,000

780,000

(c) η2, Basic scheme.

10

9.5

9

8.5

8

7.5

7
0

−1

−1.5

−2

50,000

100,000
Iteration

150,000

200,000

(d) η2, Basic + all.

195,000

390,000
Iteration

585,000

780,000

−2.5
0

50,000

100,000
Iteration

150,000

200,000

(e) η3, Basic scheme.

(f) η3, Basic + all.

Figure 2: Comparison of performance for frequent arrivals.

14

4.5

4

3.5

3
0

4

3.8

3.6

3.4

3.2

3

2.8

2.6

2.4

2.2

2
0

−1

−1.5

−2

−2.5
0

4.5

4

3.5

45,000

90,000
Iteration

135,000

180,000

3
0

25,000

50,000
Iteration

75,000

100,000

(a) η1, Basic scheme.

(b) η1, Basic + all.

45,000

90,000
Iteration

135,000

180,000

(c) η2, Basic scheme.

4

3.8

3.6

3.4

3.2

3

2.8

2.6

2.4

2.2

2
0

−1

−1.5

−2

25,000

50,000
Iteration

75,000

100,000

(d) η2, Basic + all.

45,000

90,000
Iteration

135,000

180,000

−2.5
0

25,000

50,000
Iteration

75,000

100,000

(e) η3, Basic scheme.

(f) η3, Basic + all.

Figure 3: Comparison of performance for intermediate case.

15

3

2.5

2

1.5

1

0.5

0

−0.5

−1
0

12

10

8

6

4

2

0

−2
0

−4

−4.1

−4.2

−4.3

−4.4

−4.5

−4.6

−4.7

−4.8

−4.9

−5
0

3

2.5

2

1.5

1

0.5

0

−0.5

−1
0

45,000

90,000
Iteration

135,000

180,000

25,000

50,000
Iteration

75,000

100,000

(a) η1, Basic scheme.

(b) η1, Basic + all.

12

10

8

6

4

2

0

45,000

90,000
Iteration

135,000

180,000

−2
0

25,000

50,000
Iteration

75,000

100,000

(c) η2, Basic scheme.

(d) η2, Basic + all.

−4

−4.1

−4.2

−4.3

−4.4

−4.5

−4.6

−4.7

−4.8

−4.9

45,000

90,000
Iteration

135,000

180,000

−5
0

25,000

50,000
Iteration

75,000

100,000

(e) η3, Basic scheme.

(f) η3, Basic + all.

Figure 4: Comparison of performance for rare arrivals.

16

4 Conclusion

In this paper, we have shown how Bayesian inference with MCMC can be performed for the
M/G/1 queueing model. As mentioned earlier, Fearnhead and Prangle (2010) used ABC for
inference in the M/G/1 queueing model. Fearnhead and Prangle (2010) also used ABC for
inference in the Ricker model of population dynamics, in which we assume that a population
process is observed with Poisson noise.

The basis of all ABC methods is the ability to simulate observations from a given stochastic
model. The simulation process for a set of observations is always driven by a latent process of
sampling and transforming certain random variables. The distributions of these random vari-
ables then determine the distribution of the ﬁnal observed quantities. If we consider the latent
variables which drive the simulation process jointly with the observations, then we can think of
the observations as coming from a model with some latent structrure. These latent variables
and the observed data will sometimes have a tractable joint density, which makes doing Bayesian
inference with MCMC possible, at least in principle.

In an earlier work, Shestopaloﬀ and Neal (2013), we used the same approach as in this paper
to do Bayesian inference for the Ricker model, i.e.
including additional latent variables in the
MCMC state and sampling for them as well as model parameters. We compared a basic MCMC
scheme with several “ensemble MCMC” schemes for Bayesian inference in the Ricker model, and
showed that using the ensemble schemes leads to a signiﬁcant improvement in eﬃciency when
compared to the basic MCMC scheme. Like for the M/G/1 queueing model, we have shown that
Bayesian inference with MCMC is possible for the Ricker model, but requires more sophisticated
MCMC methods for sampling to be eﬃcient.

It would be interesting to apply alternative inference methods for models with a time series
structure to the M/G/1 queue, for example Particle Filters and Particle Markov Chain Monte
Carlo (PMCMC) (Andrieu, Doucet, and Holenstein (2010)).

As mentioned earlier, it should be possible to extend the MCMC method in this paper to
service time distributions other than the Uniform one used in this paper. The most direct exten-
sion would be to consider location-scale service time distributions. Besides the simple Metropolis
updates, we can then do additional updates for the location parameter (or some 1-to-1 function
of it) using a shift update and additional updates for the scale parameter (or some 1-to-1 function
of it) using a range scale update. Computation would not be impacted so long as (14) can be
written in terms of low-dimensional suﬃcient statistics.

Acknowledgements

This research was supported by the Natural Sciences and Engineering Research Council of
Canada. A. S. is in part funded by an NSERC Postgraduate Scholarship. R. N. holds a Canada
Research Chair in Statistics and Machine Learning.

17

References

Andrieu, C., Doucet, A. and Holenstein, R. (2010), “Particle Markov chain Monte Carlo meth-

ods”. Journal of the Royal Statistical Society B, vol. 72, pp. 269-342.

Blum, M.G.B. and Francois, O. (2010). “Non-linear regression models for Approximate Bayesian

Computation”, Statistics and Computing, vol. 20, pp. 63-73.

Bonassi, F.V. (2013) “Approximate Bayesian Computation for Complex Dynamic Systems”.

Ph.D. Thesis, Department of Statistical Science, Duke University.

Fearnhead, P., Prangle, D. (2012) “Constructing summary statistics for approximate Bayesian
computation: semi-automatic approximate Bayesian computation”, Journal of the Royal Sta-
tistical Society B, vol. 74, pp. 1-28.

Geyer, C. J. (2003). “The Metropolis-Hastings-Green Algorithm”,

http://www.stat.umn.edu/geyer/f05/8931/bmhg.pdf

Metropolis, N., Rosenbluth, A.W., Rosenbluth, M.N., Teller, A.H., and Teller, E. (1953). “Equa-
tion of State Calculations by Fast Computing Machines”. Journal of Chemical Physics, vol. 21,
pp. 1087-1092.

Neal, R. M. (1993) “Probabilistic Inference Using Markov Chain Monte Carlo Methods”, Tech-

nical Report CRG-TR-93-1, Dept. of Computer Science, University of Toronto.

Neal, R. M., Beal, M. J., and Roweis, S. T. (2004) “Inferring state sequences for non-linear
systems with embedded hidden Markov models”, in S. Thrun, et al (editors), Advances in
Neural Information Processing Systems 16, MIT Press.

Neal, R. M. (2003) “Markov Chain Sampling for Non-linear State Space Models using Embedded
Hidden Markov Models”, Technical Report No. 0304, Department of Statistics, University of
Toronto, http://arxiv.org/abs/math/0305039.

Shestopaloﬀ, A. Y. and Neal, R. M. (2013). “MCMC for non-linear state space models using

ensembles of latent sequences”, Technical Report, http://arxiv.org/abs/1305.0320.

18

