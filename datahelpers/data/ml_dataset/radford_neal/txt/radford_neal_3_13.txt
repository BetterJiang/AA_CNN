3
1
0
2

 

y
a
M
2

 

 
 
]

O
C

.
t
a
t
s
[
 
 

1
v
0
2
3
0

.

5
0
3
1
:
v
i
X
r
a

MCMC for non-linear state space models

using ensembles of latent sequences

Alexander Y. Shestopaloﬀ

Department of Statistical Sciences

University of Toronto

alexander@utstat.utoronto.ca

Radford M. Neal

Department of Statistical Sciences,
Department of Computer Science

University of Toronto

radford@utstat.utoronto.ca

30 April 2013

Non-linear state space models are a widely-used class of models for biological, economic, and
physical processes. Fitting these models to observed data is a diﬃcult inference problem that
has no straightforward solution. We take a Bayesian approach to the inference of unknown
parameters of a non-linear state model; this, in turn, requires the availability of eﬃcient Markov
Chain Monte Carlo (MCMC) sampling methods for the latent (hidden) variables and model
parameters. Using the ensemble technique of Neal (2010) and the embedded HMM technique
of Neal (2003), we introduce a new Markov Chain Monte Carlo method for non-linear state
space models. The key idea is to perform parameter updates conditional on an enormously large
ensemble of latent sequences, as opposed to a single sequence, as with existing methods. We
look at the performance of this ensemble method when doing Bayesian inference in the Ricker
model of population dynamics. We show that for this problem, the ensemble method is vastly
more eﬃcient than a simple Metropolis method, as well as 1.9 to 12.0 times more eﬃcient than
a single-sequence embedded HMM method, when all methods are tuned appropriately. We also
introduce a way of speeding up the ensemble method by performing partial backward passes to
discard poor proposals at low computational cost, resulting in a ﬁnal eﬃciency gain of 3.4 to 20.4
times over the single-sequence method.

1

Introduction

Consider an observed sequence z1, . . . , zN . In a state space model for Z1, . . . , ZN , the distribution
of the Zi’s is deﬁned using a latent (hidden) Markov process X1, . . . , XN . We can describe such a
model in terms of a distribution for the ﬁrst hidden state, p(x1), transition probabilities between
hidden states, p(xi|xi−1), and emission probabilities, p(zi|xi), with these distributions dependent
on some unknown parameters θ.

1

While the state space model framework is very general, only two state space models, Hidden
Markov Models (HMM’s) and linear Gaussian models have eﬃcient, exact inference algorithms.
The forward-backward algorithm for HMM’s and the Kalman ﬁlter for linear Gaussian models
allow us to perform eﬃcient inference of the latent process, which in turn allows us to perform
eﬃcient parameter inference, using an algorithm such as Expectation-Maximizaton for maximum
likelihood inference, or various MCMC methods for Bayesian inference. No such exact and eﬃcient
algorithms exist for models with a continuous state space with non-linear state dynamics, non-
Gaussian transition distributions, or non-Gaussian emission distributions, such as the Ricker
model we consider later in this paper.

In cases where we can write down a likelihood function for the model parameters conditional
on latent and observed variables, it is possible to perform Bayesian inference for the parameters
and the latent variables by making use of sampling methods such as MCMC. For example, one
can perform inference for the latent variables and the parameters by alternately updating them
according to their joint posterior.

Sampling of the latent state sequence x = (x1, . . . , xN ) is diﬃcult for state space models when
the state space process has strong dependencies — for example, when the transitions between
states are nearly deterministic. To see why, suppose we sample from π(x1, . . . , xN|z1, . . . , zN )
using Gibbs sampling, which samples the latent variables one at a time, conditional on values of
other latent variables, the observed data, and the model parameters. In the presence of strong
dependencies within the state sequence, the conditional distribution of a latent variable will be
highly concentrated, and we will only be able to change it slightly at each variable update,
even when the marginal distribution of this latent variable, given z1, . . . , zN , is relatively diﬀuse.
Consequently, exploration of the space of latent sequences will be slow.

The embedded HMM method of (Neal (2003), Neal, et al. (2004)) addresses this problem by
updating the entire latent sequence at once. The idea is to temporarily reduce the state space
of the model, which may be countably inﬁnite or continuous, to a ﬁnite collection of randomly
generated “pool” states at each time point. If the transitions between states are Markov, this
reduced model is an HMM, for which we can use the forward-backward algorithm to eﬃciently
sample a sequence with values in the pools at each time point. Pool states are chosen from a
distribution that assigns positive probability to all possible state values, allowing us to explore the
entire space of latent sequences in accordance with their exact distribution. Neal (2003) showed
that when there are strong dependencies in the state sequence, the embedded HMM method
performs better than conventional Metropolis methods at sampling latent state sequences.

In our paper, we ﬁrst look at an MCMC method which combines embedded HMM updates of
the hidden state sequence with random-walk Metropolis updates of the parameters. We call this
method the ‘single-sequence’ method. We next reformulate the embedded HMM method as an
ensemble MCMC method. Ensemble MCMC allows multiple candidate points to be considered
simultaneously when a proposal is made. This allows us to consider an extension of the embedded
HMM method for inference of the model parameters when they are unknown. We refer to this
extension as the ensemble embedded HMM method. We then introduce and describe a “staged”
method, which makes ensemble MCMC more eﬃcient by rejecting poor proposals at low com-
putational cost after looking at a part of the observed sequence. We use the single-sequence,

2

ensemble, and ensemble with staging methods to perform Bayesian inference in the Ricker model
of population dynamics, comparing the performance of these new methods to each other, and to
a simple Metropolis sampler.

2 Ensemble MCMC

We ﬁrst describe Ensemble MCMC, introduced by Neal (2010) as a general MCMC method,
before describing its application to inference in state space models.

Ensemble MCMC is based on the framework of MCMC using a temporary mapping. Suppose
we want to sample from a distribution π on X . This can be done using a Markov chain with
transition probablity from x to x(cid:48) given by T (x(cid:48)|x), for which π is an invariant distribution —

that is, T must satisfy(cid:82) π(x)T (x(cid:48)|x)dx = π(x(cid:48)). The temporary mapping strategy deﬁnes T as

a composition of three stochastic mappings. The current state x is stochastically mapped to a
state y ∈ Y using the mapping ˆT (y|x). Here, the space Y need not be the same as the space X .
The state y is then updated to y(cid:48) using the mapping ¯T (y(cid:48)|y), and ﬁnally a state x(cid:48) is obtained
using the mapping ˇT (x(cid:48)|y(cid:48)). In this approach, we may choose whatever mappings we want, so
long as the overall transition T leaves π invariant. In particular, if ρ is a density for y, T will
leave π invariant if the following conditions hold.

(cid:90)
(cid:90)
(cid:90)

π(x) ˆT (y|x)dx = ρ(y)
ρ(y) ¯T (y(cid:48)|y)dy = ρ(y(cid:48))
ρ(y(cid:48)) ˇT (x(cid:48)|y(cid:48))dy(cid:48) = π(x(cid:48))

(1)

(2)

(3)

In the ensemble method, we take Y = X K, with y = (x(1), . . . , x(K)) referred to as an “ensem-
ble”, with K being the number of ensemble elements. The three mappings are then constructed
as follows. Consider an “ensemble base measure” over ensembles (x(1), . . . , x(K)) with density
ζ(x(1), . . . , x(K)), and with marginal densities ζk(x(k)) for each of the k = 1, . . . , K ensemble
elements. We deﬁne ˆT as

K(cid:88)

k=1

ˆT (x(1), . . . , x(K)|x) =

1
K

ζ−k|k(x(−k)|x)δx(x(k))

(4)

Here, δx is a distribution that places a point mass at x, x(−k) is all of x(1), . . . , x(K) except x(k),
and ζ−k|k(x(−k)|x(k)) = ζ(x(1), . . . , x(K))/ζk(x(k)) is the conditional density of all ensemble elements
except the k-th, given the value x(k) for the k-th.

This mapping can be interpreted as follows. First, we select an integer k, from a uniform
distribution on {1, . . . , K}. Then, we set the ensemble element x(k) to x, the current state.
Finally, we generate the remaining elements of the ensemble using the conditional density ζ−k|k.

3

The ensemble density ρ is determined by π and ˆT , and is given explicitly as

ρ(x(1), . . . , x(K)) =

π(x) ˆT (x(1), . . . , x(K)|x)dx

(cid:90)

= ζ(x(1), . . . , x(K))

1
K

π(x(k))
ζk(x(k))

(5)

K(cid:88)

k=1

¯T can be any update (or sequence of updates) that leaves ρ invariant. For example, ¯T could
be a Metropolis update for y, with a proposal drawn from some symmetrical proposal density.
Finally, ˇT maps from y(cid:48) to x(cid:48) by randomly setting x(cid:48) to x(k) with k chosen from {1, . . . , K} with
probabilities proportional to π(x(k))/ζk(x(k)).

The mappings descibed above satisfy the necessary properties to make them a valid update,
in the sense of preserving the stationary distribution π. The proof can be found in Neal (2010).

3 Embedded HMM MCMC as an

Ensemble MCMC method

The embedded HMM method brieﬂy described in the introduction was not initially introduced as
an ensemble MCMC method, but it can be reformulated as one. We assume here that we are inter-
ested in sampling from the posterior distribution of the state sequences, π(x1, . . . , xN|z1, . . . , zN ),
when the parameters of the model are known. Suppose the current state sequence is x =
(x1, . . . , xN ). We want to update this state sequence in a way that leaves π invariant.

The ﬁrst step of the embedded HMM method is to temporarily reduce the state space to a
ﬁnite number of possible states at each time, turning our model into an HMM. This is done by,
for each time i, generating a set of L “pool” states, Pi = {x[1]
i }, as follows. We ﬁrst set
to xi, the value of the current state sequence at time i. The remaining L − 1
the pool state x[1]
i
pool states x[l]
i , for l > 1 are generated by sampling independently from some pool distribution
with density κi. The collections of pool states at diﬀerent times are selected independently of
each other. The total number of sequences we can then construct using these pool states, by
choosing one state from the pool at each time, is K = LN .

, . . . , x[L]

i

The second step of the embedded HMM method is to choose a state sequence composed of

pool states, with the probability of such a state sequence, x, being proportional to

(6)

(7)

q(x|z1, . . . , zN ) ∝ p(x1)

p(xi|xi−1)

i=2

i=1

We can deﬁne γ(zi|xi) = p(zi|xi)/κi(xi), and rewrite (6) as

q(x|z1, . . . , zN ) ∝ p(x1)

p(xi|xi−1)

(cid:20)p(zi|xi)

(cid:21)

N(cid:89)

κi(xi)

N(cid:89)

i=1

γ(zi|xi)

N(cid:89)

N(cid:89)

i=2

4

We now note that the distribution (7) takes the same form as the distribution over hidden state
sequences for an HMM in which each xi ∈ Pi — the initial state distribution is proportional
to p(x1), the transition probabilities are proportional to p(xi|xi−1), and the γ(zi|xi) have the
same role as emission probabilities. This allows us to use the well-known forward-backward
algorithms for HMM’s (reviewed by Scott (2002)) to eﬃciently sample hidden state sequences
composed of pool states. To sample a sequence with the embedded HMM method, we ﬁrst
compute the “forward” probabilities. Then, using a stochastic “backwards” pass, we select a
state sequence composed of pool states. (We can alternately compute backward probabilities and
then do a stochastic forward pass). We emphasize that having an eﬃcient algorithm to sample
state sequences is crucial for the embedded HMM method. The number of possible sequences we
can compose from the pool states, LN , can be very large, and so naive sampling methods would
be impractical.

In detail, for xi ∈ Pi, the forward probabilities αi(xi) are computed using a recursion that
goes forward in time, starting from i = 1. We start by computing α1(x1) = p(x1)γ(z1|x1). Then,
for 1 < i ≤ N , the forward probabilities αi(x) are given by the recursion

αi(xi) = γ(zi|xi)

p(xi|x[l]

i−1)αi−1(x[l]

i−1),

for x ∈ Pi

(8)

l=1

The stochastic backwards recursion samples a state sequence, one state at a time, beginning with
the state at time N . First, we sample xN from the pool PN with probabilities proportional to
αN (xN ). Then, going backwards in time for i from N − 1 to 1, we sample xi from the pool Pi
with probabilities proportional to p(xi+1|xi)αi(xi), where xi+1 is the variable just sampled at time
i + 1. Both of these recursions are commonly implemented using logarithms of probabilities to
avoid numerical underﬂow.

Let us now reformulate the embedded HMM method as an ensemble MCMC method. The
step of choosing the pool states can be thought of as performing a mapping ˆT which takes a single
hidden state sequence x and maps it to an ensemble of K state sequences y = (x(1), . . . , x(K)),
with x = x(k) for some k chosen uniformly from {1, . . . , K}.
(However, we note that in this
context, the order in the ensemble does not matter.)

L(cid:88)

Since the randomly chosen pool states are independent under κi at each time, and across
time as well, the density of an ensemble of hidden state sequences in the ensemble base measure,
ζ, is deﬁned through a product of κi(x[l]
i )’s over the pool states and over time, and is non-zero
for ensembles consisting of all sequences composed from the chosen set of pool states. The
corresponding marginal density of a hidden state sequence x(k) in the ensemble base measure is

ζk(x(k)) =

κi(x(k)
i )

(9)

i=1

Together, ζ and ζk deﬁne the conditional distribution ζ−k|k, which is used to deﬁne ˆT . The
mapping ¯T is taken to be a null mapping that keeps the ensemble ﬁxed at its current value,
and the mapping ˇT to a single state sequence is performed by selecting a sequence x(k) from the
ensemble with probabilities given by (7), in the same way as in the embedded HMM method.

5

N(cid:89)

4 The single-sequence embedded HMM MCMC method

Let us assume that the parameters θ of our model are unknown, and that we want to sample
from the joint posterior distribution of state sequences x = (x1, . . . , xN ) and parameters θ =
(θ1, . . . , θP ), with density π(x, θ|z1, . . . , zN ). One way of doing this is by alternating embedded
HMM updates of the state sequence with Metropolis updates of the parameters. Doing updates in
this manner makes use of an ensemble to sample state sequences more eﬃciently in the presence of
strong dependencies. However, this method only takes into account a single hidden state sequence
when updating the parameters.

The update for the sequence is identical to that in the embedded HMM method, with initial,
transition and emission densities dependent on the current value of θ. In our case, we only consider
simple random-walk Metropolis updates for θ, updating all of the variables simultaneously.

Evaluating the likelihood conditional on x and z, as needed for Metropolis parameter updates,
is computationally inexpensive relative to updates of the state sequence, which take time pro-
portional to L2. It may be beneﬁcial to perform several Metropolis parameter updates for every
update of the state sequence, since this will not greatly increase the overall computational cost,
and allows us to obtain samples with lower autocorrelation time.

5 An ensemble extension of the embedded HMM method

When performing parameter updates, we can look at all possible state sequences composed of
pool states by using an ensemble ((x(1), θ), . . . , (x(K), θ)) that includes a parameter value θ, the
same for each element of the ensemble. The update ¯T could change both θ and x(k), but in the
method we will consider here, we only change θ.

To see why updating θ with an ensemble of sequences might be more eﬃcient than updating
θ given a single sequence, consider a Metropolis proposal in ensemble space, which proposes
to change θ for all of the ensemble elements, from θ to θ∗. Such an update can be accepted
whenever there are some elements (x(k), θ∗) in the proposed ensemble that make the ensemble
density ρ((x(1), θ∗), . . . , (x(K), θ∗)) relatively large. That is, it is possible to accept a move in
ensemble space with a high probability as long as some elements of the proposed ensemble, with
the new θ∗, lie in a region of high posterior density. This is at least as likely to happen as having
a proposed θ∗ together with a single state sequence x lie in a region of high posterior density.

Using ensembles makes sense when the ensemble density ρ can be computed in an eﬃcient
manner, in less than K times as long as it takes to compute p(x, θ|z1, . . . , zN ) for a single hidden
state sequence x. Otherwise, one could make K independent proposals to change x, which would
have approximately the same computational cost as a single ensemble update, and likely be a
more eﬃcient way to sample x. In the application here, K = LN is enormous for typical values
of N when L ≥ 2, while computation of ρ takes time proportional only to N L2.

In detail, to compute the ensemble density, we need to sum q(x(k), θ|z1, . . . , zN ) over all en-
semble elements (x(k), θ), that is, over all hidden sequences which are composed of the pool states

6

at each time. The forward algorithm described above makes it possible to compute the ensemble
density eﬃciently by summing the probabilities at the end of the forward recursion αN (xN ) over
all xN ∈ PN . That is

K(cid:88)

L(cid:88)

ρ((x(1), θ), . . . , (x(K), θ)) ∝ π(θ)

where π(θ) is the prior density of θ.

q(x(k), θ|z1, . . . , zN ) = π(θ)

αN (x[l]
N )

(10)

k=1

l=1

The ensemble extension of the embedded HMM method can be thought of as using an approx-
imation to the marginal posterior of θ when updating θ, since summing the posterior density over
a large collection of hidden sequences approximates integrating over all such sequences. Larger
updates of θ may be possible with an ensemble because the marginal posterior of θ, given the
data, is more diﬀuse than the conditional distribution of θ given a ﬁxed state sequence and the
data. Note that since the ensemble of sequences is periodically changed, when new pool states
are chosen, the ensemble method is a proper MCMC method that converges to the exact joint
posterior, even though the set of sequences using pool states is restricted at each MCMC iteration.

The ensemble method is more computationally expensive than the single-sequence method
— it requires two forward passes to evaluate the ensemble density for two values of θ and one
backward pass to sample a hidden state sequence, whereas the single-sequence method requires
only a single forward pass to compute the probabilities for every sequence in our ensemble, and
a single backward pass to select a sequence.

Some of this additional computational cost can be oﬀset by reusing the same pool states to do
multiple updates of θ. Once we have chosen a collection of pool states, and performed a forward
pass to compute the ensemble density at the current value of θ, we can remember it. Proposing
an update of θ to θ∗ requires us to compute the ensemble density at θ∗ using a forward pass.
Now, if this proposal is rejected, we can reuse the stored value of the ensemble density θ when we
make another proposal using the same collection of pool states. If this proposal is accepted, we
can remember the ensemble density at the accepted value. Keeping the pool ﬁxed, and saving the
current value of the ensemble density therefore allows us to perform M ensemble updates with
M + 1 forward passes, as opposed to 2M if we used a new pool for each update.

With a large number of pool states, reusing the pool states for two or more updates has only a
small impact on performance, since with any large collection of pool states we essentially integrate
over the state space. However, pool states must still be updated occasionally, to ensure that the
method samples from the exact joint posterior.

6 Staged ensemble MCMC sampling

Having to compute the ensemble density given the entire observed sequence for every proposal,
even those that are obviously poor, is a source of ineﬃciency in the ensemble method. If poor
proposals can be eliminated at a low computational cost, the ensemble method could be made
more eﬃcient. We could then aﬀord to make our proposals larger, accepting occasional large
proposals while rejecting others at little cost.

7

We propose to do this by performing “staged” updates. First, we choose a part of the observed
sequence that we believe is representative of the whole sequence. Then, we propose to update θ
to a θ∗ found using an ensemble update that only uses the part of the sequence we have chosen. If
the proposal found by this “ﬁrst stage” update is accepted, we perform a “second stage” ensemble
update given the entire sequence, with θ∗ as the proposal. If the proposal at the ﬁrst stage is
rejected, we do not perform a second stage update, and add the current value of θ to our sequence
of sampled values. This can be viewed as a second stage update where the proposal is the current
state — to do such an update, no computations need be performed.

Suppose that ρ1 is the ensemble density given the chosen part of the observed sequence,
and q(θ∗|θ) is the proposal density for constructing the ﬁrst stage update. Then the acceptance
probability for the ﬁrst stage update is given by

(cid:18)

min

1,

ρ1((x(1), θ∗), . . . , (x(K), θ∗))q(θ|θ∗)
ρ1((x(1), θ), . . . , (x(K), θ))q(θ∗|θ)

(cid:19)

If ρ is the ensemble density given the entire sequence, the acceptance probability for the second
stage update is given by

ρ((x(1), θ∗), . . . , (x(K), θ∗)) min

min

1,

ρ((x(1), θ), . . . , (x(K), θ)) min

(cid:18)
(cid:18)

1, ρ1((x(1),θ∗),...,(x(K),θ∗))q(θ|θ∗)
ρ1((x(1),θ),...,(x(K),θ))q(θ∗|θ)
1, ρ1((x(1),θ),...,(x(K),θ))q(θ∗|θ)
ρ1((x(1),θ∗),...,(x(K),θ∗))q(θ|θ∗)

(11)

(12)

(cid:19)
(cid:19) (cid:33)

(cid:33)

(cid:32)

(cid:32)

Regardless of whether ρ1((x(1), θ∗), . . . , (x(K), θ∗))q(θ|θ∗) < ρ1((x(1), θ), . . . , (x(K), θ))q(θ∗|θ) or
vice versa, the above ratio simpliﬁes to

min

1,

ρ((x(1), θ∗), . . . , (x(K), θ∗))ρ1((x(1), θ∗), . . . , (x(K), θ∗))q(θ|θ∗)
ρ((x(1), θ), . . . , (x(K), θ))ρ1((x(1), θ), . . . , (x(K), θ))q(θ∗|θ)

(13)

Choosing a part of the observed sequence for the ﬁrst stage update can be aided by looking at the
acceptance rates at the ﬁrst and second stages. We need the moves accepted at the ﬁrst stage to
also be accepted at a suﬃciently high rate at the second stage, but we want the acceptance rate at
the ﬁrst stage to be low so the method will have an advantage over the ensemble method in terms
of computational eﬃciency. We can also look at the ‘false negatives’ for diagnostic purposes, that
is, how many proposals rejected at the ﬁrst step would have been accepted had we looked at the
entire sequence when deciding whether to accept.

We are free to select any portion of the observed sequence to use for the ﬁrst stage. We will
look here at using a partial sequence for the ﬁrst stage consisting of observations starting at n1
and going until the end, at time N . This is appropriate for our example later in the paper, where
we only have observations past a certain point in time.

For this scenario, to perform a ﬁrst stage update, we need to perform a backward pass. As
we perform a backward pass to do the ﬁrst stage proposal, we save the vector of “backward”
probabilities. Then, if the ﬁrst stage update is accepted, we start the recursion for the full
sequence using these saved backward probabilities, and compute the ensemble density given the

8

entire sequence, avoiding recomputation of backward probabilities for the portion of the sequence
used for the ﬁrst stage.

To compute the backward probabilities βi(xi), we perform a backward recursion, starting at

time N . We ﬁrst set βN (xN ) to 1 for all xN ∈ PN . We then compute, for n1 ≤ i < N

βi(xi) =

p(x[l]

i+1)γ(zi+1|x[l]
i+1)

L(cid:88)

l=1

i+1|xi)βi+1(x[l]
L(cid:88)

We compute the ﬁrst stage ensemble density ρ1 as follows

(14)

(15)

L(cid:88)

ρ1((x(1), θ), . . . , (x(K), θ)) = π(θ)

p(x[l]

n1)p(yn1|x[l]

n1)βn1(x[l]
n1)

l=1

We do not know p(xn1), but we can choose a substitute for it (which aﬀects only performance,
not correctness). One possibility is a uniform distrubution over the pool states at n1, which is
what we will use in our example below.

The ensemble density for the full sequence can be obtained by performing the backward

recursion up to the beginning of the sequence, and then computing

ρ((x(1), θ), . . . , (x(K), θ)) = π(θ)

p(x[l]

1 )p(y1|x[l]

1 )β1(x[l]
1 )

(16)

l=1

To see how much computation time is saved with staged updates, we measure computation
time in terms of the time it takes to do a backward (or equivalently, forward) pass — generally,
the most computationally expensive operation in ensemble MCMC — counting a backward pass
to time n1 as a partial backward pass.

Let us suppose that the acceptance rate for stage 1 updates is a1. An ensemble update that
uses the full sequence requires us to perform two backwards passes if we update the pool at every
iteration, whereas a staged ensemble update will require us to perform

N − n1
N − 1

n1 − 1
N − 1

1 +

+ a1

(17)
backward passes on average (counting a pass back only to n1 as (N − n1)/(N − 1) passes). The
ﬁrst term in the above formula represents the full backward pass for the initial value of θ that is
always needed — either for a second stage update, or for mapping to a new set of pool states.
The second term represents the partial backward pass we need to perform to complete the ﬁrst
stage proposal. The third term accounts for having to compute the remainder of a backwards
pass if we accept the ﬁrst stage proposal — hence it is weighted by the ﬁrst stage acceptance
rate.

We can again save computation time by updating the pool less frequently. Suppose we decide
to update the pool every M iterations. Without staging, the ensemble method would require a

9

total of M + 1 forward (or equivalently, backward) passes. With staged updates, the expected
number of backward passes we would need to perform is

n1 − 1
N − 1
as can be seen by generalizing the expression above to M > 1.

N − n1
N − 1

1 + M

+ M a1

(18)

7 Constructing pools of states

An important aspect of these embedded HMM methods is the selection of pool states at each
time, which determines the mapping ˆT from a single state sequence to an ensemble. In this paper,
we will only consider sampling pool states independently from some distribution with density κi
(though dependent pool states are considered in (Neal, 2003).

One choice of κi is the conditional density of xi given zi, based on some pseudo-prior distri-
bution η for xi — that is, κi(xi) ∝ η(xi)p(zi|xi). This distribution approximates, to some extent,
the marginal posterior of xi given all observations. We hope that such a pool distribution will
produce sequences in our ensemble which have a high posterior density, and as a result make
sampling more eﬃcient.

To motivate how we might go about choosing η, consider the following. Suppose we sample
values of θ from the model prior, and then sample hidden state sequences, given the sampled
values of θ. We can then think of η as a distribution that is consistent with this distribution of
hidden state sequences, which is in turn consistent with the model prior. In this paper, we choose
η heuristically, setting it to what we believe to be reasonable, and not in violation of the model
prior.

Note that the choice of η aﬀects only sampling eﬃciency, not correctness (as long as it is
non-zero for all possible xi). However, when we choose pool states in the ensemble method, we
cannot use current values of θ, since this would make an ensemble update non-reversible. This
restriction does not apply to the single-sequence method since in this case ¯T is null.

8 Performance comparisons on a

population dynamics model

We test the performance of the proposed methods on the Ricker population dynamics model,
described by Wood (2003). This model assumes that a population of size Ni (modeled as a
real number) evolves as Ni+1 = rNi exp(−Ni + ei), with ei independent with a Normal(0, σ2)
distribution, with N0 = 1. We don’t observe this process directly, but rather we observe Yi’s
whose distribution is Poisson(φNi). The goal is to infer θ = (r, σ, φ). This is considered to be a
fairly complex inference scenario, as evidenced by the application of recently developed inference
methods such as Approximate Bayesian Computation (ABC) to this model.
(See Fearnhead,

10

Prangle (2012) for more on the ABC approach.) This model can be viewed as a non-linear state
space model, with Ni as our state variable.

MCMC inference in this model can be ineﬃcient for two reasons. First, when the value of σ2
in the current MCMC iteration is small, consecutive Ni’s are highly dependent, so the distribution
of each Ni, conditional on the remaining Ni’s and the data, is highly concentrated, making it hard
to eﬃciently sample state sequences one state at a time. An MCMC method based on embedding
an HMM into the state space, either the single-sequence method or the ensemble method, can
potentially make state sequence sampling more eﬃcient, by sampling whole sequences at once.
The second reason is that the distribution of θ, given a single sequence of Ni’s and the data, can
be concentrated as well, so we may not be able to eﬃciently explore the posterior distribution of θ
by alternately sampling θ and the Ni’s. By considering an ensemble of sequences, we may be able
to propose and accept larger changes to θ. This is because the posterior distribution of θ summed
over an ensemble of state sequences is less concentrated than it is given a single sequence.

To test our MCMC methods, we consider a scenario similar to those considered by Wood
(2010) and Fearnhead and Prangle (2012). The parameters of the Ricker model we use are
r = exp(3.8), σ = 0.15, φ = 2. We generated 100 points from the Ricker model, with yi only
observed from time 51 on, mimicking a situation where we do not observe a population right from
its inception.

We put a Uniform(0, 10) prior on log(r), a Uniform(0, 100) prior on φ, and a Uniform[log(0.1), 0]
prior on log(σ). Instead of Ni, we use Mi = log(φNi) as our state variables, since we found that
doing this makes MCMC sampling more eﬃcient. With these state variables, our model can be
written as

M1 ∼ N (log(r) + log(φ) − 1, σ2)

Mi|Mi−1 ∼ N (log(r) + Mi−1 − exp(Mi−1)/φ, σ2),
i = 51, . . . , 100

Yi|Mi ∼ Poisson(exp(Mi)),

i = 2, . . . , 100

(19)
(20)
(21)

Furthermore, the MCMC state uses the logarithms of the parameters, (log(r), log(σ), log(φ)).

For parameter updates in the MCMC methods compared below, we used independent normal
proposals for each parameter, centered at the current parameter values, proposing updates to
all parameters at once. To choose appropriate proposal standard deviations, we did a number
of runs of the single sequence and the ensemble methods, and used these trial runs to estimate
the marginal standard deviations of the logarithm of each parameter. We got standard deviation
estimates of 0.14 for log(r), 0.36 for log(σ), and 0.065 for log(φ). We then scaled each estimated
marginal standard deviation by the same factor, and used the scaled estimates as the proposal
standard deviations for the corresponding parameters. The maximum scaling we used was 2,
since beyond this our proposals would often lie outside the high probability region of the marginal
posterior density.

We ﬁrst tried a simple Metropolis sampler on this problem. This sampler updates the latent
states one at a time, using Metropolis updates to sample from the full conditional density of each

11

state Mt, given by

p(m1|y51, . . . , y100, m−1) ∝ p(m1)p(m2|m1)
p(mi|y51, . . . , y100, m−i) ∝ p(mi|mi−1)p(mi+1|mi),
p(mi|y51, . . . , y100, m−i) ∝ p(mi|mi−1)p(yi|mi)p(mi+1|mi),

2 ≤ i ≤ 50

p(m100|y51, . . . , y100, m−100) ∝ p(m100|m99)p(y100|m100)

51 ≤ i ≤ 99

(22)
(23)
(24)
(25)

We started the Metropolis sampler with parameters set to prior means, and the hidden states to
randomly chosen values from the pool distributions we used for the embedded HMM methods
below. After we perform a pass over the latent variables, and update each one in turn, we perform
a Metropolis update of the parameters, using a scaling of 0.25 for the proposal density.

The latent states are updated sequentially, starting from 1 and going up to 100. When
updating each latent variable Mi, we use a Normal proposal distribution centered at the current
value of the latent variable, with the following proposal standard deviations. When we do not
observe yi, or yi = 0, we use the current value of σ from the state times 0.5. When we observe

yi > 0, we use a proposal standard deviation of 1/(cid:112)1/σ2 + yi (with σ from the state). This choice

can be motivated as follows. An estimate of precision for Mi given Mi−1 is 1/σ2. Furthermore,
Yi is Poisson(φNi), so that Var(φNi) ≈ yi and Var(log(φNi)) = Var(Mi) ≈ 1/yi. So an estimate
for the precision of Mi given yi is yi. We combine these estimates of precisions to get a proposal
standard deviation for the latent variables in the case when yi > 0.

We ran the Metropolis sampler for 6, 000, 000 iterations from ﬁve diﬀerent starting points.
The acceptance rate for parameter updates was between about 10% and 20%, depending on the
initial starting value. The acceptance rate for latent variable updates was between 11% and 84%,
depending on the run and the particular latent variable being sampled.

We found that the simple Metropolis sampler does not perform well on this problem. This
is most evident for sampling σ. The Metropolis sampler appears to explore diﬀerent regions of
the posterior for σ when it is started from diﬀerent initial hidden state sequences. That is, the
Metropolis sampler can get stuck in various regions of the posterior for extended periods of time.
An example of the behaviour of the Metropolis sampler be seen on Figure 1. The autocorrelations
for the parameters are so high that accurately estimating them would require a much longer run.

This suggests that more sophisticated MCMC methods are necessary for this problem. We
next looked at the single-sequence method, the ensemble method, and the staged ensemble
method.

All embedded MCMC-based samplers require us to choose pool states for each time i. For
the i’s where no yi’s are observed, we choose our pool states by sampling values of exp(Mi) from
a pseudo-prior η for the Poisson mean exp(Mi) — a Gamma(k, θ) distribution with k = 0.15 and
θ = 50 — and then taking logarithms of the sampled values. For the i’s where we observe yi’s we
choose our pool states by sampling values of exp(Mi) from the conditional density of exp(Mi)|yi
with η as the pseudo-prior. Since Yi|Mi is Poisson(exp(Mi)), the conditional density of exp(Mi)|yi
has a Gamma(k + yi, θ/(1 + θ)) distribution.

It should be noted that since we choose our pool states by sampling exp(Mi)’s, but our model
is written in terms of Mi, the pool density κi must take this into account. In particular, when yi

12

Figure 1: An example run of the simple Metropolis method.

Figure 2: An example ensemble method run, with 120 pool states and proposal scaling 1.4.

13

03,000,0006,000,00010−1100101102103iteration  rsigmaphi050,000100,00010−1100101102103iteration  rsigmaphiis unobserved, we have

κi(mi) =

1

Γ(k)θk exp(kmi − exp(mi)/θ), −∞ < mi < ∞

(26)

and when yi is observed we replace k with k + yi and θ with θ/(1 + θ). We use the same way of
choosing the pool states for all three methods we consider.

The staged ensemble MCMC method also requires us to choose a portion of the sequence to
use for the ﬁrst stage update. On the basis of several trial runs, we chose to use the last 20 points,
i.e. n1 = 81.

As we mentioned earlier, when likelihood evaluations are computationally inexpensive relative
to sequence updates, we can do multiple parameter updates for each update of the hidden state
sequence, without incurring a large increase in computation time. For the single-sequence method,
we do ten Metropolis updates of the parameters for each update of the hidden state sequence. For
the ensemble method, we do ﬁve updates of the parameters for each update of the ensemble. For
staged ensemble MCMC, we do ten parameter updates for each update of the ensemble. These
choices were based on numerous trial runs.

We thin each of the single-sequence runs by a factor of ten when computing autocorrelation
times — hence the time per iteration for the single-sequence method is the time it takes to do a
single update of the hidden sequence and ten Metropolis updates. We do not thin the ensemble
and staged ensemble runs.

To compare the performance of the embedded HMM methods, and to tune each method, we
looked at the autocorrelation time, τ , of the sequence of parameter samples, for each parameter.
The autocorrelation time can be thought of as the number of samples we need to draw using our
Markov chain to get the equivalent of one independent point (Neal (1993)). It is deﬁned as

τ = 1 + 2

ρk

(27)

∞(cid:88)

k=1

K(cid:88)

where ρk is the autocorrelation at lag k for a function of state that is of interest. Here, ˆρk =
ˆγk/ˆγ0, where ˆγk is the estimated autocovariance at lag k. We estimate each ˆγk by estimating
autocovariances using each of the ﬁve runs, using the overall mean from the ﬁve runs, and then
averaging the resulting autocovariance estimates. We then estimate τ by

ˆτ = 1 + 2

ˆρk

(28)

Here, the truncation point K is where the remaining ˆρk’s are nearly zero.

k=1

For our comparisons to have practical validity, we need to multiply each estimate of autocor-
relation time estimate by the time it takes to perform a single iteration. A method that produces
samples with a lower autocorrelation time is often more computationally expensive than a method
that produces samples with a higher autocorrelation time, and if the diﬀerence in computation
time is suﬃciently large, the computationally cheaper method might be more eﬃcient. Compu-
tation times per iteration were obtained with a program written in MATLAB on a Linux system
with an Intel Xeon X5680 3.33 GHz CPU.

14

Method

Pool
states Scaling

Acc.
Rate

Single-

sequence

Ensemble

Staged

Ensemble

10

20

40

60

80
40

60

80

120

180
40

60

80

120

180

Iter-
ations
400,000

400,000

0.25

12%

200,000

200,000

200,000
100,000

100,000

100,000

100,000

13%

11%

16%

14%

12%

100,000
30, 15% 100,000

27, 18% 100,000

30, 25% 100,000

25, 29% 100,000

23, 32% 100,000

0.6

1

1

1.4

1.8
1

1.4

1.4

1.8

2

Time /
iteration

r

ACT

σ

φ

0.09

0.17

0.31

0.47

0.61
0.23

0.34

0.47

0.76

1.26
0.10

0.14

0.21

0.29

0.45

4345

2362

7272

779

427

329

294
496

187

107

52

35
692

291

187

75

48

1875

1849

187

155

134
335

115

55

41

27
689

373

104

59

44

1317

879

869
897

167

90

45

29
1201

303

195

70

52

ACT × time
φ
r
654

σ
213

391

132

132

155

179
114

64

50

40

44
69

41

39

22

22

319

58

73

82
77

39

26

31

34
69

52

22

17

20

314

408

413

530
206

57

42

34

37
120

42

41

20

23

Table 1: Comparison of autocorrelation times.

For each number of pool states considered, we started the samplers from ﬁve diﬀerent initial
states. Like with the Metropolis method, the parameters were initialized to prior means, and the
hidden sequence was initialized to states randomly chosen from pool distribution at each time.
When estimating autocorrelations, we discarded the ﬁrst 10% of samples of each run as burn-in.

An example ensemble run is shown in Figure 2. Comparing with Figure 1, one can see that the
ensemble run has an enormously lower autocorrelation time. Autocorrelation time estimates for
the various ensemble methods, along with computation times, proposal scaling, and acceptance
rates, are presented in Table 1. For the staged ensemble method, the acceptance rates are shown
for the ﬁrst stage and second stage. We also estimated the parameters of the model by averaging
estimates of the posterior means from each of the ﬁve runs for the single-sequence method with
40 pool states, the ensemble method with 120 pool states, and the staged ensemble method with
120 pool states. The results are presented in Table 2. The estimates using the three diﬀerent
methods do not diﬀer signiﬁcantly.

Method

Single-Sequence

Ensemble

Staged Ensemble

r

44.46 (± 0.09)
44.65 (± 0.09)
44.57 (± 0.04)

σ

0.2074 (± 0.0012)
0.2089 (± 0.0009)
0.2089 (± 0.0010)

φ

1.9921 (± 0.0032)
1.9853 (± 0.0013)
1.9878 (± 0.0015)

Table 2: Estimates of posterior means, with standard errors of posterior means shown in brackets.

15

From these results, one can see that for our Ricker model example, the single-sequence method
is less eﬃcient than the ensemble method, when both methods are well-tuned and computation
time is taken into account. We also found that the the staged ensemble method allows us to
further improve performance of the ensemble method. In detail, depending on the parameter one
looks at, the best tuned ensemble method without staging (with 120 pool states) is between 1.9
and 12.0 times better than the best tuned single-sequence method (with 40 pool states). The
best tuned ensemble method with staging (120 pool states) is between 3.4 and 20.4 times better
than the best single-squence method.

The large drop in autocorrelation time for σ for the single-sequence method between 20 and
40 pool states is due to poor mixing in one of the ﬁve runs. To conﬁrm whether this systematic,
we did ﬁve more runs of the single sequence method, from another set of starting values, and
found that the same problem is again present in one of the ﬁve runs. This is inidicative of a risk
of poor mixing when using the single-sequence sampler with a small number of pool states. We
did not observe similar problems for larger numbers of pool states.

The results in Table 1 show that performance improvement is greatest for the parameter φ.
One reason for this may be that the posterior distribution of φ given a sequence is signiﬁcantly
more concentrated than the marginal posterior distribution of φ. Since for a suﬃciently large
number of pool states, the posterior distribution given an ensemble approximates the marginal
posterior distribution, the posterior distribution of φ given an ensemble will become relatively
more diﬀuse than the posterior distributions of r and σ. This leads to a larger relative performance
improvement when sampling values of φ.

Evidence of this can be seen on Figure 3. To produce it, we took the hidden state sequence and
parameter values from the end of one of our ensemble runs, and performed Metropolis updates
for the parameters, while keeping the hidden state sequence ﬁxed. We also took the same hidden
state sequence and parameter values, mapped the hidden sequence to an ensemble of sequences
by generating a collection of pool states (we used 120) and peformed Metropolis updates of the
parameter part of the ensemble, keeping the pool states ﬁxed. We drew 50, 000 samples given a
single ﬁxed sequence and 2, 000 samples given an ensemble.

Figure 3: An illustration to aid explanation of relative performance. Note that the ﬁxed sequence
dots are smaller, to better illustrate the diﬀerence in the spread between the ﬁxed sequence and
two other distributions.

16

20304050607080900.10.20.30.40.50.60.70.8rsigma20304050607080901.51.61.71.81.922.12.22.32.42.5rphi  marginalfixed ensemblefixed sequence0.10.20.30.40.50.60.70.81.51.61.71.81.922.12.22.32.42.5sigmaphiVisually, we can see that the posterior of θ given a single sequence is signiﬁcantly more
concentrated than the marginal posterior, and the posterior given a ﬁxed ensemble of sequences.
Comparing the standard deviations of the posterior of θ given a ﬁxed sequence, and the marginal
posterior of θ, we ﬁnd that the marginal posterior of φ has a standard deviation about 21 times
larger than the posterior of φ given a single sequence. The marginal posteriors for r and σ have
a posterior standard deviation larger by a factor of 5.2 and 6.0. The standard deviation of the
posterior given our ﬁxed ensemble of sequences is greater for φ by a factor of 11, and by factors
of 4.3 and 3.2 for r and σ. This is consisent with our explanation above.

We note that the actual timings of the runs are diﬀerent from what one may expect.

In
theory, the computation time should scale as nL2, where L is the number of pool states and n
is the number of observations. However, the implementation we use, in MATLAB, implements
the forward pass as a nested loop over n and over L, with another inner loop over L vectorized.
MATLAB is an interpreted language with slow loops, and vectorizing loops generally leads to
vast performance improvements. For the numbers of pool states we use, the computational cost
of the vector operation corresponding to the inner loop over L is very low compared to that of the
outer loop over L. As a result, the total computational cost scales approximately linearly with
L, in the range of values of L we considered. An implementation in a diﬀerent language might
lead to diﬀerent optimal pool state settings.

The original examples of Wood and Fearnhead and Prangle used φ = 10 instead of φ = 2.
We found that for φ = 10, the ensemble method still performs better than the single sequence
method, when computation time is taken into account, though the diﬀerence in performance is
not as large. When φ is larger, the observations yi are larger on average as well. As a result,
the data is more informative about the values of the hidden state variables, and the marginal
posteriors of the model parameters are more concentrated. As a result of this, though we would
still expect the ensemble method to improve performance, we would not expect the improvement
to be as large as when φ = 2.

Finally, we would like to note that if the single-sequence method is implemented already, im-
plementing the ensemble method is very simple, since all that is needed is an additional call of the
forward pass function and summing of the ﬁnal forward probabilities. So, the performance gains
from using an ensemble for parameter updates can be obtained with little additional programming
eﬀort.

9 Conclusion

We found that both the embedded HMM MCMC method and its ensemble extension perform
signiﬁcantly better than the ordinary Metropolis method for doing Bayesian inference in the
Ricker model. This suggests that it would be promising to investigate other state space models
with non-linear state dynamics, and see if it is possible to use the embedded HMM methods we
described to perform inference in these models.

Our results also show that using staged proposals further improves the performance of the
ensemble method. It would be worthwhile to look at other scenarios where this technique might

17

be applied.

Most importantly, however, our results suggest that looking at multiple hidden state sequences
at once can make parameter sampling in state space models noticeably more eﬃcient, and so
indicate a direction for further research in the development of MCMC methods for non-linear,
non-Gaussian state space models.

Acknowledgements

This research was supported by the Natural Sciences and Engineering Research Council of
Canada. A. S. is in part funded by an NSERC Postgraduate Scholarship. R. N. holds a Canada
Research Chair in Statistics and Machine Learning.

References

Fearnhead, P., Prangle, D. (2012) “Constructing summary statistics for approximate Bayesian
computation: semi-automatic approximate Bayesian computation”, Journal of the Royal Sta-
tistical Society, Series B, vol. 74, pp. 1-28.

Neal, R. M. (2010) “MCMC Using Ensembles of States for Problems with Fast and Slow Variables
such as Gaussian Process Regression”, Technical Report No. 1011, Department of Statistics,
University of Toronto.

Neal, R. M. (2003) “Markov Chain Sampling for Non-linear State Space Models using Embedded
Hidden Markov Models”, Technical Report No. 0304, Department of Statistics, University of
Toronto.

Neal, R. M., Beal, M. J., and Roweis, S. T. (2004) “Inferring state sequences for non-linear
systems with embedded hidden Markov models”, in S. Thrun, et al (editors), Advances in
Neural Information Processing Systems 16, MIT Press.

Neal, R. M. (1993) “Probabilistic Inference Using Markov Chain Monte Carlo Methods”, Tech-

nical Report CRG-TR-93-1, Dept. of Computer Science, University of Toronto.

Steven L. Scott (2002) “Bayesian Methods for Hidden Markov Models: Recursive Computing in
the 21st Century”, Journal of the American Statistical Association. vol. 97, no. 457, pp. 337-
351.

Wood, S. (2010) “Statistical inference for noisy nonlinear ecological dynamic systems”, Nature.

vol. 466, pp. 1102-1104.

18

