Abstract

The ExpectationMaximization EM algorithm is an iterative pro-
cedure for maximum likelihood parameter estimation from data
sets with missing or hidden variables . It has been applied to
system identication in linear stochastic state-space models, where
the state variables are hidden from the observer and both the state
and the parameters of the model have to be estimated simulta-
neously 	. We present a generalization of the EM algorithm for
parameter estimation in nonlinear dynamical systems. The expec-
tation" step makes use of Extended Kalman Smoothing to estimate
the state, while the maximization" step re-estimates the parame-
ters using these uncertain state estimates. In general, the nonlinear
maximization step is dicult because it requires integrating out the
uncertainty in the states. However, if Gaussian radial basis func-
tion RBF approximators are used to model the nonlinearities,
the integrals become tractable and the maximization step can be
solved via systems of linear equations.

 Stochastic Nonlinear Dynamical Systems

We examine inference and learning in discrete-time dynamical systems with hidden
state xt, inputs ut, and outputs yt. The state evolves according to stationary
nonlinear dynamics driven by the inputs and by additive noise

xt+ = f xt; ut + w



All lowercase characters except indices denote vectors. Matrices are represented by

uppercase characters.

where w is zero-mean Gaussian noise with covariance Q.  The outputs are non-
linearly related to the states and inputs by

yt = gxt; ut + v



where v is zero-mean Gaussian noise with covariance R. The vector-valued nonlin-
earities f and g are assumed to be dierentiable, but otherwise arbitrary.

Models of this kind have been examined for decades in various communities. Most
notably, nonlinear state-space models form one of the cornerstones of modern sys-
tems and control engineering. In this paper, we examine these models within the
framework of probabilistic graphical models and derive a novel learning algorithm
for them based on EM. With one exception, this is to the best of our knowledge
the rst paper addressing learning of stochastic nonlinear dynamical systems of the
kind we have described within the framework of the EM algorithm.

The classical approach to system identication treats the parameters as hidden vari-
ables, and applies the Extended Kalman Filtering algorithm described in section 
to the nonlinear system with the state vector augmented by the parameters .
This approach is inherently on-line, which may be important in certain applications.
Furthermore, it provides an estimate of the covariance of the parameters at each
time step. In contrast, the EM algorithm we present is a batch algorithm and does
not attempt to estimate the covariance of the parameters.

There are three important advantages the EM algorithm has over the classical ap-
proach. First, the EM algorithm provides a straightforward and principled method
for handing missing inputs or outputs. Second, EM generalizes readily to more
complex models with combinations of discrete and real-valued hidden variables.
For example, one can formulate EM for a mixture of nonlinear dynamical systems.
Third, whereas it is often very dicult to prove or analyze stability within the
classical on-line approach, the EM algorithm is always attempting to maximize the
likelihood, which acts as a Lyapunov function for stable learning.

In the next sections we will describe the basic components of the learning algorithm.
For the expectation step of the algorithm, we infer the conditional distribution of the
hidden states using Extended Kalman Smoothing section . For the maximization
step we rst discuss the general case section  and then describe the particular
case where the nonlinearities are represented using Gaussian radial basis function
RBF;  networks section .

 Extended Kalman Smoothing

Given a system described by equations  and , we need to infer the hidden
states from a history of observed inputs and outputs. The quantity at the heart
of this inference problem is the conditional density P xtju; : : : ; uT ; y; : : : ; yT , for
  t  T , which captures the fact that the system is stochastic and therefore our
inferences about x will be uncertain.

The Gaussian noise assumption is less restrictive for nonlinear systems than for linear

systems since the nonlinearity can be used to generate non-Gaussian state noise.

The authors have just become aware that Briegel and Tresp this volume have applied
EM to essentially the same model. Briegel and Tresps method uses multilayer perceptrons
MLP to approximate the nonlinearities, and requires sampling from the hidden states to
t the MLP. We use Gaussian radial basis functions RBFs to model the nonlinearities,
which can be t analytically without sampling see section .

It is important not to confuse this use of the Extended Kalman algorithm, to simul-
taneously estimate parameters and hidden states, with our use of EKS, to estimate just
the hidden state as part of the E step of EM.

For linear dynamical systems with Gaussian state evolution and observation noises,
this conditional density is Gaussian and the recursive algorithm for computing its
mean and covariance is known as Kalman smoothing , . Kalman smoothing is
directly analogous to the forwardbackward algorithm for computing the conditional
hidden state distribution in a hidden Markov model, and is also a special case of
the belief propagation algorithm.

For nonlinear systems this conditional density is in general non-Gaussian and can
in fact be quite complex. Multiple approaches exist for inferring the hidden state
distribution of such nonlinear systems, including sampling methods  and varia-
tional approximations . We focus instead in this paper on a classic approach from
engineering, Extended Kalman Smoothing EKS.

Extended Kalman Smoothing simply applies Kalman smoothing to a local lineariza-
tion of the nonlinear system. At every point ~x in x-space, the derivatives of the
vector-valued functions f and g dene the matrices, A~x  @f
,
respectively. The dynamics are linearized about ^xt, the mean of the Kalman lter
state estimate at time t:

@xx=~x

and C~x  @g

@xx=~x

xt+ = f ^xt; ut + A^xt xt (cid:0) ^xt + w:



The output equation  can be similarly linearized. If the prior distribution of the
hidden state at t =  was Gaussian, then, in this linearized system, the conditional
distribution of the hidden state at any time t given the history of inputs and outputs
will also be Gaussian. Thus, Kalman smoothing can be used on the linearized system
to infer this conditional distribution see gure , left panel.

 Learning

The M step of the EM algorithm re-estimates the parameters given the observed
inputs, outputs, and the conditional distributions over the hidden states. For the
model we have described, the parameters dene the nonlinearities f and g, and the
noise covariances Q and R.

Two complications arise in the M step. First, it may not be computationally fea-
sible to fully re-estimate f and g. For example, if they are represented by neural
network regressors, a single full M step would be a lengthy training procedure using
backpropagation, conjugate gradients, or some other optimization method. Alter-
natively, one could use partial M steps, for example, each consisting of one or a few
gradient steps.

The second complication is that f and g have to be trained using the uncertain state
estimates output by the EKS algorithm. Consider tting f , which takes as inputs
xt and ut and outputs xt+. For each t, the conditional density estimated by EKS is
a full-covariance Gaussian in xt; xt+-space. So f has to be t not to a set of data
points but instead to a mixture of full-covariance Gaussians in input-output space
Gaussian clouds" of data. Integrating over this type of noise is non-trivial for
almost any form of f . One simple but inecient approach to bypass this problem
is to draw a large sample from these Gaussian clouds of uncertain data and then t
f to these samples in the usual way. A similar situation occurs with g.

In the next section we show how, by choosing Gaussian radial basis functions to
model f and g, both of these complications vanish.

The forward part of the Kalman smoother is the Kalman lter.

 Fitting Radial Basis Functions to Gaussian Clouds

We will present a general formulation of an RBF network from which it should be
clear how to t special forms for f and g. Consider the following nonlinear mapping
from input vectors x and u to an output vector z:

z =

I

Xi=

hi ix + Ax + Bu + b + w;



where w is a zero-mean Gaussian noise variable with covariance Q. For example,
one form of f can be represented using  with the substitutions x  xt, u  ut,
and z  xt+; another with x  xt; ut, u  ;, and z  xt+. The parameters
are: the coecients of the I RBFs, hi; the matrices A and B multiplying inputs
x and u, respectively; and an output bias vector b. Each RBF is assumed to be a
Gaussian in x-space, with center ci and width given by the covariance matrix Si:

ix = jSij(cid:0)= exp(cid:0)




x (cid:0) ciS(cid:0)

i

x (cid:0) ci :



The goal is to t this model to data u; x; z. The complication is that the data
set comes in the form of a mixture of Gaussian distributions. Here we show how to
analytically integrate over this mixture distribution to t the RBF model.

Assume the data set is:

P x; z; u =



J Xj

Njx; z u (cid:0) uj:



That is, we observe samples from the u variables, each paired with a Gaussian
cloud" of data, Nj, over x; z. The Gaussian Nj has mean j and covariance
matrix Cj.

Let ^zx; u = PI

i= hi ix + Ax + Bu + b, where  is the set of parameters
= fh : : : hI ; A; B; bg. The log likelihood of a single data point under the model
is:

(cid:0)

z (cid:0) ^zx; u Q(cid:0) z (cid:0) ^zx; u (cid:0)

ln jQj + const:







The maximum likelihood RBF t to the mixture of Gaussian data is obtained by
minimizing the following integrated quadratic form:

min
;Q

ZxZz


Xj
:

Njx; z z (cid:0) ^zx; uj Q(cid:0) z (cid:0) ^zx; uj dx dz + J ln jQj	=
;

We rewrite this in a slightly dierent notation, using angled brackets hij to denote
expectation over Nj, and dening

: 

h
  x x : : : I x x u  :

I A B b

 h

 : : : h

Then, the objective can be written

min
;Q

Xj z (cid:0)  Q(cid:0)z (cid:0)  j + J ln jQj	=

;
:

:



Taking derivatives with respect to , premultiplying by (cid:0)Q(cid:0), and setting to zero

gives the linear equations Pjhz (cid:0) ij = , which we can solve for  and Q:
^ = 
@Xj

hij
A

hzij
A

hzij
A

hzzij (cid:0) ^Xj


@Xj


@Xj

(cid:0)

;

^Q =


J

:

	

In other words, given the expectations in the angled brackets, the optimal parame-
ters can be solved for via a set of linear equations. In appendix A we show that these
expectations can be computed analytically. The derivation is somewhat laborious,
but the intuition is very simple: the Gaussian RBFs multiply with the Gaussian
densities Nj to form new unnormalized Gaussians in x; y-space. Expectations un-
der these new Gaussians are easy to compute. This tting algorithm is illustrated
in the right panel of gure .

xt+1

+

Gaussian
evidence

for

t

xt

+

Gaussian
evidence
from t
-1

xt-1

linearize

models

xt

Gaussian
evidence
from
t   +1

xt+2

+

inputs and outputs

ut ,

yt
at time t

i

n
o
s
n
e
m
d

i

xt+1


t

u
p

t

u
o

input dimension

Figure :
Illustrations of the E and M steps of the algorithm. The left panel shows
the information used in Extended Kalman Smoothing EKS, which infers the hidden
state distribution during the E-step. The right panel illustrates the regression technique
employed during the M-step. A t to a mixture of Gaussian densities is required;
if
Gaussian RBF networks are used then this t can be solved analytically. The dashed line
shows a regular RBF t to the centres of the four Gaussian densities while the solid line
shows the analytic RBF t using the covariance information. The dotted lines below show
the support of the RBF kernels.

 Results

We tested how well our algorithm could learn the dynamics of a nonlinear system
by observing only its inputs and outputs. The system consisted of a single input,
state and output variable at each time, where the relation of the state from one time
step to the next was given by a tanh nonlinearity. Sample outputs of this system
in response to white noise are shown in gure  left panel.

We initialized the nonlinear model with a linear dynamical model trained with
EM, which in turn we initialized with a variant of factor analysis. The model
was given  RBFs in xt-space, which were uniformly spaced within a range which
was automatically determined from the density of points in xt-space. After the
initialization was over, the algorithm discovered the sigmoid nonlinearity in the
dynamics within less than  iterations of EM gure , middle and right panels.

Further experiments need to be done to determine how practical this method will
be in real domains.

3

2

1

0

1

2

3

4

3

2

1

0

0

100

200

300

400

500

600

700

800

900

1000

a

s
t

u
p
n

i

b

s
t
u
p
u
o

t

1

2

3

0

NLDS

LDS

400

450

500

550

600

650

d
o
o
h

i
l

e
k
L

i



g
o
L

)
1
+
t
(
x

3

2.5

2

1.5

1

0.5

0

0.5

1

1.5

2
2

50

60

70

1.5

1

0.5

0

x(t)

0.5

1

1.5

2

2.5

100

200

300

400

500
time

600

700

800

900

1000

700

0

10

20

30

40

Iterations of EM

Figure : left: Data set used for training rst half and testing rest, which consists
of a time series of inputs, ut a, and outputs yt b. middle: Representative plots of
log likelihood vs iterations of EM for linear dynamical systems dashed line and nonlinear
dynamical systems trained as described in this paper solid line. Note that the actual
likelihood for nonlinear dynamical systems cannot generally be computed analytically;
what is shown here is the approximate likelihood computed by EKS. The kink in the solid
curve comes when initialization with linear dynamics ends and the nonlinearity starts to
be learned. right: Means of xt; xt+ Gaussian posteriors computed by EKS dots,
along with the sigmoid nonlinearity dashed line and the RBF nonlinearity learned by
the algorithm. At no point does the algorithm actually observe xt; xt+ pairs; these are
inferred from inputs, outputs, and the current model parameters.

 Discussion

This paper brings together two classic algorithms, one from statistics and another
from systems engineering, to address the learning of stochastic nonlinear dynam-
ical systems. We have shown that by pairing the Extended Kalman Smoothing
algorithm for state estimation in the E-step, with a radial basis function learning
model that permits analytic solution of the M-step, the EM algorithm is capable of
learning a nonlinear dynamical model from data. As a side eect we have derived
an algorithm for training a radial basis function network to t data in the form of
a mixture of Gaussians.

Our initial approach has three potential limitations. First, the M-step presented
does not modify the centres or widths of the RBF kernels. It is possible to compute
the expectations required to change the centres and widths, but it requires resort-
ing to a partial M-step. For low dimensional state spaces, lling the space with
pre-xed kernels is feasible, but this strategy needs exponentially many RBFs in
high dimensions. Second, EM training can be slow, especially if initialized poorly.
Understanding how dierent hidden variable models are related can help devise
sensible initialization heuristics. For example, for this model we used a nested ini-
tialization which rst learned a simple linear dynamical system, which in turn was
initialized with a variant of factor analysis. Third, the method presented here learns
from batches of data and assumes stationary dynamics. We have recently extended
it to handle online learning of nonstationary dynamics.

The belief network literature has recently been dominated by two methods for
approximate inference, Markov chain Monte Carlo  and variational approxima-
tions . To our knowledge this paper is the rst instance where extended Kalman
smoothing has been used to perform approximate inference in the E step of EM.
While EKS does not have the theoretical guarantees of variational methods, its
simplicity has gained it wide acceptance in the estimation and control literatures
as a method for doing inference in nonlinear dynamical systems. We are currently
exploring generalizations of this method for learning nonlinear multilayer belief net-

works.

Acknowledgements: ZG would like to acknowledge the support of the CITO Ontario
and the Gatsby Charitable Fund. STR was supported in part by the NSF Center for
Neuromorphic Systems Engineering and by an NSERC Canada 	 Award.

A Expectations Required to Fit the RBFs

The expectations we need to compute for equation 	 are hxij, hzij, hxxij, hxzij , hzzij ,
hixij, hx ixij, hz ixij, hix xij.

Starting with some of the easier ones that do not depend on the RBF kernel :

hxij = x
j
hxxij = x
hzzij = z

j x;T
j z;T

j + C xx
j + C zz

j

j

hzij = z
j
hxzij = x

j z;T

j + C xz

j

Observe that when we multiply the Gaussian RBF kernel ix equation  and Nj we
get a Gaussian density over x; z with mean and covariance

ij = Cij C (cid:0)

j j + S(cid:0)

i ci




and

Cij = C (cid:0)

j + S(cid:0)

i




 
(cid:0)

;

and an extra constant due to lack of normalization,

ij = (cid:0)dx=jSij(cid:0)=jCjj(cid:0)=jCij j= expf(cid:0)ij =g

i S(cid:0)
where ij = c
other expectations:

i ci + 

j C (cid:0)

j j (cid:0) 

ij C (cid:0)

ij ij . Using ij and ij , we can evaluate the

hixij = ij ;

hx ixij = ij x
ij ;

and

hz ixij = ij z
ij :

Finally, hix xij = (cid:0)dx jCj j(cid:0)=jSij(cid:0)=jSj(cid:0)=jCij j= expf(cid:0)ij=g, where

Cij = C (cid:0)

j + S(cid:0)



i + S(cid:0)





 
(cid:0)

and ij = Cij C (cid:0)

j j + S(cid:0)



i ci + S(cid:0)

 c


;

and ij = c

i S(cid:0)

i ci + c

 S(cid:0)

 c + 

j C (cid:0)

j j (cid:0) 

ij C (cid:0)

ij ij .

