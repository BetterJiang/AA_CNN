References

Extracting and Composing Robust Features

with Denoising Autoencoders

Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Pascal Vincent,

Universit´e de Montr´eal, LISA Lab

July 2008

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

The problem

References

Building good predictors on complex domains
means learning complicated functions.

These are best represented by multiple levels of non-linear operations
i.e. deep architectures.

Deep architectures are an old idea: multi-layer perceptrons.

Learning the parameters of deep architectures proved to be
challenging!

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Training deep architectures: attempted solutions

References

Solution 1: initialize at random, and do gradient
descent (Rumelhart, Hinton and Williams, 1986).
→ disappointing performance. Stuck in poor solutions.

Solution 2: Deep Belief Nets (Hinton, Osindero and Teh, 2006):
initialize by stacking Restricted Boltzmann Machines, ﬁne-tune with
Up-Down.
→ impressive performance.

Key seems to be good unsupervised layer-by-layer
initialization. . .

Solution 3: initialize by stacking autoencoders, ﬁne-tune with
gradient descent. (Bengio et al., 2007; Ranzato et al., 2007)
→ Simple generic procedure, no sampling required.
Performance almost as good as Solution 2

. . . but not quite. Can we do better?

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Training deep architectures: attempted solutions

References

Solution 1: initialize at random, and do gradient
descent (Rumelhart, Hinton and Williams, 1986).
→ disappointing performance. Stuck in poor solutions.

Solution 2: Deep Belief Nets (Hinton, Osindero and Teh, 2006):
initialize by stacking Restricted Boltzmann Machines, ﬁne-tune with
Up-Down.
→ impressive performance.

Key seems to be good unsupervised layer-by-layer
initialization. . .

Solution 3: initialize by stacking autoencoders, ﬁne-tune with
gradient descent. (Bengio et al., 2007; Ranzato et al., 2007)
→ Simple generic procedure, no sampling required.
Performance almost as good as Solution 2

. . . but not quite. Can we do better?

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Training deep architectures: attempted solutions

References

Solution 1: initialize at random, and do gradient
descent (Rumelhart, Hinton and Williams, 1986).
→ disappointing performance. Stuck in poor solutions.

Solution 2: Deep Belief Nets (Hinton, Osindero and Teh, 2006):
initialize by stacking Restricted Boltzmann Machines, ﬁne-tune with
Up-Down.
→ impressive performance.

Key seems to be good unsupervised layer-by-layer
initialization. . .

Solution 3: initialize by stacking autoencoders, ﬁne-tune with
gradient descent. (Bengio et al., 2007; Ranzato et al., 2007)
→ Simple generic procedure, no sampling required.
Performance almost as good as Solution 2

. . . but not quite. Can we do better?

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Training deep architectures: attempted solutions

References

Solution 1: initialize at random, and do gradient
descent (Rumelhart, Hinton and Williams, 1986).
→ disappointing performance. Stuck in poor solutions.

Solution 2: Deep Belief Nets (Hinton, Osindero and Teh, 2006):
initialize by stacking Restricted Boltzmann Machines, ﬁne-tune with
Up-Down.
→ impressive performance.

Key seems to be good unsupervised layer-by-layer
initialization. . .

Solution 3: initialize by stacking autoencoders, ﬁne-tune with
gradient descent. (Bengio et al., 2007; Ranzato et al., 2007)
→ Simple generic procedure, no sampling required.
Performance almost as good as Solution 2

. . . but not quite. Can we do better?

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Can we do better?

References

Open question: what would make a good unsupervised criterion for
ﬁnding good initial intermediate representations?

Inspiration: our ability to “ﬁll-in-the-blanks” in sensory input.
missing pixels, small occlusions, image from sound, . . .

Good ﬁll-in-the-blanks performance ↔ distribution is well captured.
→ old notion of associative memory (motivated Hopﬁeld
models (Hopﬁeld, 1982))

What we propose:
unsupervised initialization by explicit ﬁll-in-the-blanks training.

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

The denoising autoencoder

References

Clean input x ∈ [0, 1]d is partially destroyed,
yielding corrupted input: ˜x ∼ qD(˜x|x).

xx

˜x is mapped to hidden representation y = fθ(˜x).

From y we reconstruct a z = gθ0(y).

Train parameters to minimize the cross-entropy “reconstruction
error” LIH(x, z) = IH(BxkBz), where Bx denotes multivariate Bernoulli
distribution with parameter x.

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

The denoising autoencoder

References

qD

˜x

xx

Clean input x ∈ [0, 1]d is partially destroyed,
yielding corrupted input: ˜x ∼ qD(˜x|x).

˜x is mapped to hidden representation y = fθ(˜x).

From y we reconstruct a z = gθ0(y).

Train parameters to minimize the cross-entropy “reconstruction
error” LIH(x, z) = IH(BxkBz), where Bx denotes multivariate Bernoulli
distribution with parameter x.

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

The denoising autoencoder

References

y

fθ

qD

˜x

xx

Clean input x ∈ [0, 1]d is partially destroyed,
yielding corrupted input: ˜x ∼ qD(˜x|x).

˜x is mapped to hidden representation y = fθ(˜x).

From y we reconstruct a z = gθ0(y).

Train parameters to minimize the cross-entropy “reconstruction
error” LIH(x, z) = IH(BxkBz), where Bx denotes multivariate Bernoulli
distribution with parameter x.

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

The denoising autoencoder

References

y

gθ0

fθ

qD

˜x

xx

z

Clean input x ∈ [0, 1]d is partially destroyed,
yielding corrupted input: ˜x ∼ qD(˜x|x).

˜x is mapped to hidden representation y = fθ(˜x).

From y we reconstruct a z = gθ0(y).

Train parameters to minimize the cross-entropy “reconstruction
error” LIH(x, z) = IH(BxkBz), where Bx denotes multivariate Bernoulli
distribution with parameter x.

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

The denoising autoencoder

References

y

gθ0

LH(x, z)

fθ

qD

˜x

xx

z

Clean input x ∈ [0, 1]d is partially destroyed,
yielding corrupted input: ˜x ∼ qD(˜x|x).

˜x is mapped to hidden representation y = fθ(˜x).

From y we reconstruct a z = gθ0(y).

Train parameters to minimize the cross-entropy “reconstruction
error” LIH(x, z) = IH(BxkBz), where Bx denotes multivariate Bernoulli
distribution with parameter x.

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

The input corruption process qD(˜x|x)

References

qD

˜x

xx

Choose a ﬁxed proportion ν of components of x at random.

Reset their values to 0.

Can be viewed as replacing a component considered missing by a
default value.

Other corruption processes are possible.

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Form of parameterized mappings

References

We use standard sigmoid network layers:
)

y = fθ(˜x) = sigmoid( W|{z}
gθ0(y) = sigmoid( W0|{z}

˜x + b|{z}
y + b0|{z}

d0×d

d0×1

).

d×d0

d×1

Denoising using classical autoencoders was actually introduced much
earlier (LeCun, 1987; Gallinari et al., 1987), as an alternative to Hopﬁeld
networks (Hopﬁeld, 1982).

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Form of parameterized mappings

References

We use standard sigmoid network layers:
)

y = fθ(˜x) = sigmoid( W|{z}
gθ0(y) = sigmoid( W0|{z}

˜x + b|{z}
y + b0|{z}

d0×d

d0×1

).

d×d0

d×1

Denoising using classical autoencoders was actually introduced much
earlier (LeCun, 1987; Gallinari et al., 1987), as an alternative to Hopﬁeld
networks (Hopﬁeld, 1982).

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Learning deep networks
Layer-wise initialization

References

y

gθ0

LH(x, z)

fθ

qD

˜x

xx

z

1 Learn ﬁrst mapping fθ by training as a denoising autoencoder.
2 Remove scaﬀolding. Use fθ directly on input yielding higher level

representation.

by training denoising autoencoder on

3 Learn next level mapping f (2)

θ
current level representation.
Iterate to initialize subsequent layers.

4

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Learning deep networks
Layer-wise initialization

References

y

gθ0

LH(x, z)

fθ

qD

˜x

xx

z

1 Learn ﬁrst mapping fθ by training as a denoising autoencoder.
2 Remove scaﬀolding. Use fθ directly on input yielding higher level

representation.

by training denoising autoencoder on

3 Learn next level mapping f (2)

θ
current level representation.
Iterate to initialize subsequent layers.

4

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Learning deep networks
Layer-wise initialization

References

fθ

xx

1 Learn ﬁrst mapping fθ by training as a denoising autoencoder.
2 Remove scaﬀolding. Use fθ directly on input yielding higher level

representation.

by training denoising autoencoder on

3 Learn next level mapping f (2)

θ
current level representation.
Iterate to initialize subsequent layers.

4

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Learning deep networks
Layer-wise initialization

References

fθ

xx

1 Learn ﬁrst mapping fθ by training as a denoising autoencoder.
2 Remove scaﬀolding. Use fθ directly on input yielding higher level

representation.

by training denoising autoencoder on

3 Learn next level mapping f (2)

θ
current level representation.
Iterate to initialize subsequent layers.

4

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Learning deep networks
Layer-wise initialization

References

g (2)
θ0

LH

f (2)
θ

qD

fθ

xx

1 Learn ﬁrst mapping fθ by training as a denoising autoencoder.
2 Remove scaﬀolding. Use fθ directly on input yielding higher level

representation.

by training denoising autoencoder on

3 Learn next level mapping f (2)

θ
current level representation.
Iterate to initialize subsequent layers.

4

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Learning deep networks
Layer-wise initialization

References

f (2)
θ

fθ

xx

1 Learn ﬁrst mapping fθ by training as a denoising autoencoder.
2 Remove scaﬀolding. Use fθ directly on input yielding higher level

representation.

by training denoising autoencoder on

3 Learn next level mapping f (2)

θ
current level representation.
Iterate to initialize subsequent layers.

4

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Learning deep networks
Layer-wise initialization

References

f (2)
θ

fθ

xx

1 Learn ﬁrst mapping fθ by training as a denoising autoencoder.
2 Remove scaﬀolding. Use fθ directly on input yielding higher level

representation.

by training denoising autoencoder on

3 Learn next level mapping f (2)

θ
current level representation.
Iterate to initialize subsequent layers.

4

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Learning deep networks
Supervised ﬁne-tuning

References

Initial deep mapping was learnt in
an unsupervised way.
→ initialization for a supervised
task.

Output layer gets added.

Global ﬁne tuning by gradient
descent on supervised criterion.

f (3)
θ

f (2)
θ

fθ

x

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Learning deep networks
Supervised ﬁne-tuning

References

Initial deep mapping was learnt in
an unsupervised way.
→ initialization for a supervised
task.

Output layer gets added.

Global ﬁne tuning by gradient
descent on supervised criterion.

f (3)
θ

f (2)
θ

fθ

x

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

TargetLearning deep networks
Supervised ﬁne-tuning

References

Initial deep mapping was learnt in
an unsupervised way.
→ initialization for a supervised
task.

Output layer gets added.

Global ﬁne tuning by gradient
descent on supervised criterion.

f sup
θ

f (3)
θ

f (2)
θ

fθ

x

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Targetsupervised costPerspectives on denoising autoencoders
Manifold learning perspective

References

˜x
gθ0(fθ(˜x))

x

qD(˜x|x)

˜x

x

Denoising autoencoder can be seen as a way to learn a manifold:

Suppose training data (×) concentrate near a low-dimensional manifold.

Corrupted examples (.) are obtained by applying corruption process
qD(eX|X ) and will lie farther from the manifold.
The model learns with p(X|eX ) to “project them back” onto the manifold.

Intermediate representation Y can be interpreted as a coordinate system
for points on the manifold.

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Perspectives on denoising autoencoders
Information theoretic perspective

References

Consider X ∼ q(X ), q unknown. eX ∼ qD(eX|X ). Y = fθ(eX ).

It can be shown that minimizing the expected reconstruction error
amounts to maximizing a lower bound on mutual information
I(X ; Y ).

Denoising autoencoder training can thus be justiﬁed by the objective
that hidden representation Y captures as much information as
possible about X even as Y is a function of corrupted input.

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Perspectives on denoising autoencoders
Generative model perspective

References

Denoising autoencoder training can be shown to be equivalent to
maximizing a variational bound on the likelihood of a generative
model for the corrupted data.

Y

Y

˜X

X

˜X

X

variational model

generative model

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

datahiddenfactorscorrupteddataobservedhiddenfactorscorrupteddataobserveddataBenchmark problems
Variations on MNIST digit classiﬁcation

References

basic: subset of original MNIST digits: 10 000 training samples, 2 000 validation
samples, 50 000 test samples.

rot: applied random rotation (angle be-
tween 0 and 2π radians)

bg-rand: background made of random
pixels (value in 0 . . . 255)

bg-img: background is random patch
from one of 20 images

rot-bg-img: combination of rotation and
background image

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Benchmark problems
Shape discrimination

References

rect: discriminate between tall and wide rectangles on black background.

rect-img: borderless rectangle ﬁlled with random image patch. Background is a
diﬀerent image patch.

convex: discriminate between convex and non-convex shapes.

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Experiments

References

We compared the following algorithms on the benchmark problems:

SVMrbf : suport Vector Machines with Gaussian Kernel.
DBN-3: Deep Belief Nets with 3 hidden layers (stacked Restricted
Boltzmann Machines trained with contrastive divergence).
SAA-3: Stacked Autoassociators with 3 hidden layers (no
denoising).
SdA-3: Stacked Denoising Autoassociators with 3 hidden layers.
Hyper-parameters for all algorithms were tuned based on classiﬁcaiton
performance on validation set. (In particular hidden-layer sizes, and ν for
SdA-3).

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Performance comparison
Results

References

Dataset

SVMrbf

DBN-3

SAA-3

SdA-3 (ν)

SVMrbf (ν)

basic

rot

3.03±0.15

3.11±0.15

3.46±0.16

2.80±0.14 (10%)

3.07 (10%)

11.11±0.28

10.30±0.27

10.30±0.27

10.29±0.27 (10%)

11.62 (10%)

bg-rand

14.58±0.31

6.73±0.22

11.28±0.28

10.38±0.27 (40%)

15.63 (25%)

bg-img

22.61±0.37

16.31±0.32

23.00±0.37

16.68±0.33 (25%)

23.15 (25%)

rot-bg-img

55.18±0.44

47.39±0.44

51.93±0.44

44.49±0.44 (25%)

54.16 (10%)

rect

2.15±0.13

2.60±0.14

2.41±0.13

1.99±0.12 (10%)

2.45 (25%)

rect-img

24.04±0.37

22.50±0.37

24.05±0.37

21.59±0.36 (25%)

23.00 (10%)

convex

19.13±0.34

18.63±0.34

18.41±0.34

19.06±0.34 (10%)

24.20 (10%)

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Performance comparison
Results

References

Dataset

SVMrbf

DBN-3

SAA-3

SdA-3 (ν)

SVMrbf (ν)

basic

rot

3.03±0.15

3.11±0.15

3.46±0.16

2.80±0.14 (10%)

3.07 (10%)

11.11±0.28

10.30±0.27

10.30±0.27

10.29±0.27 (10%)

11.62 (10%)

bg-rand

14.58±0.31

6.73±0.22

11.28±0.28

10.38±0.27 (40%)

15.63 (25%)

bg-img

22.61±0.37

16.31±0.32

23.00±0.37

16.68±0.33 (25%)

23.15 (25%)

rot-bg-img

55.18±0.44

47.39±0.44

51.93±0.44

44.49±0.44 (25%)

54.16 (10%)

rect

2.15±0.13

2.60±0.14

2.41±0.13

1.99±0.12 (10%)

2.45 (25%)

rect-img

24.04±0.37

22.50±0.37

24.05±0.37

21.59±0.36 (25%)

23.00 (10%)

convex

19.13±0.34

18.63±0.34

18.41±0.34

19.06±0.34 (10%)

24.20 (10%)

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Performance comparison
Results

References

Dataset

SVMrbf

DBN-3

SAA-3

SdA-3 (ν)

SVMrbf (ν)

basic

rot

3.03±0.15

3.11±0.15

3.46±0.16

2.80±0.14 (10%)

3.07 (10%)

11.11±0.28

10.30±0.27

10.30±0.27

10.29±0.27 (10%)

11.62 (10%)

bg-rand

14.58±0.31

6.73±0.22

11.28±0.28

10.38±0.27 (40%)

15.63 (25%)

bg-img

22.61±0.37

16.31±0.32

23.00±0.37

16.68±0.33 (25%)

23.15 (25%)

rot-bg-img

55.18±0.44

47.39±0.44

51.93±0.44

44.49±0.44 (25%)

54.16 (10%)

rect

2.15±0.13

2.60±0.14

2.41±0.13

1.99±0.12 (10%)

2.45 (25%)

rect-img

24.04±0.37

22.50±0.37

24.05±0.37

21.59±0.36 (25%)

23.00 (10%)

convex

19.13±0.34

18.63±0.34

18.41±0.34

19.06±0.34 (10%)

24.20 (10%)

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Performance comparison
Results

References

Dataset

SVMrbf

DBN-3

SAA-3

SdA-3 (ν)

SVMrbf (ν)

basic

rot

3.03±0.15

3.11±0.15

3.46±0.16

2.80±0.14 (10%)

3.07 (10%)

11.11±0.28

10.30±0.27

10.30±0.27

10.29±0.27 (10%)

11.62 (10%)

bg-rand

14.58±0.31

6.73±0.22

11.28±0.28

10.38±0.27 (40%)

15.63 (25%)

bg-img

22.61±0.37

16.31±0.32

23.00±0.37

16.68±0.33 (25%)

23.15 (25%)

rot-bg-img

55.18±0.44

47.39±0.44

51.93±0.44

44.49±0.44 (25%)

54.16 (10%)

rect

2.15±0.13

2.60±0.14

2.41±0.13

1.99±0.12 (10%)

2.45 (25%)

rect-img

24.04±0.37

22.50±0.37

24.05±0.37

21.59±0.36 (25%)

23.00 (10%)

convex

19.13±0.34

18.63±0.34

18.41±0.34

19.06±0.34 (10%)

24.20 (10%)

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Performance comparison
Results

References

Dataset

SVMrbf

DBN-3

SAA-3

SdA-3 (ν)

SVMrbf (ν)

basic

rot

3.03±0.15

3.11±0.15

3.46±0.16

2.80±0.14 (10%)

3.07 (10%)

11.11±0.28

10.30±0.27

10.30±0.27

10.29±0.27 (10%)

11.62 (10%)

bg-rand

14.58±0.31

6.73±0.22

11.28±0.28

10.38±0.27 (40%)

15.63 (25%)

bg-img

22.61±0.37

16.31±0.32

23.00±0.37

16.68±0.33 (25%)

23.15 (25%)

rot-bg-img

55.18±0.44

47.39±0.44

51.93±0.44

44.49±0.44 (25%)

54.16 (10%)

rect

2.15±0.13

2.60±0.14

2.41±0.13

1.99±0.12 (10%)

2.45 (25%)

rect-img

24.04±0.37

22.50±0.37

24.05±0.37

21.59±0.36 (25%)

23.00 (10%)

convex

19.13±0.34

18.63±0.34

18.41±0.34

19.06±0.34 (10%)

24.20 (10%)

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Performance comparison
Results

References

Dataset

SVMrbf

DBN-3

SAA-3

SdA-3 (ν)

SVMrbf (ν)

basic

rot

3.03±0.15

3.11±0.15

3.46±0.16

2.80±0.14 (10%)

3.07 (10%)

11.11±0.28

10.30±0.27

10.30±0.27

10.29±0.27 (10%)

11.62 (10%)

bg-rand

14.58±0.31

6.73±0.22

11.28±0.28

10.38±0.27 (40%)

15.63 (25%)

bg-img

22.61±0.37

16.31±0.32

23.00±0.37

16.68±0.33 (25%)

23.15 (25%)

rot-bg-img

55.18±0.44

47.39±0.44

51.93±0.44

44.49±0.44 (25%)

54.16 (10%)

rect

2.15±0.13

2.60±0.14

2.41±0.13

1.99±0.12 (10%)

2.45 (25%)

rect-img

24.04±0.37

22.50±0.37

24.05±0.37

21.59±0.36 (25%)

23.00 (10%)

convex

19.13±0.34

18.63±0.34

18.41±0.34

19.06±0.34 (10%)

24.20 (10%)

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Performance comparison
Results

References

Dataset

SVMrbf

DBN-3

SAA-3

SdA-3 (ν)

SVMrbf (ν)

basic

rot

3.03±0.15

3.11±0.15

3.46±0.16

2.80±0.14 (10%)

3.07 (10%)

11.11±0.28

10.30±0.27

10.30±0.27

10.29±0.27 (10%)

11.62 (10%)

bg-rand

14.58±0.31

6.73±0.22

11.28±0.28

10.38±0.27 (40%)

15.63 (25%)

bg-img

22.61±0.37

16.31±0.32

23.00±0.37

16.68±0.33 (25%)

23.15 (25%)

rot-bg-img

55.18±0.44

47.39±0.44

51.93±0.44

44.49±0.44 (25%)

54.16 (10%)

rect

2.15±0.13

2.60±0.14

2.41±0.13

1.99±0.12 (10%)

2.45 (25%)

rect-img

24.04±0.37

22.50±0.37

24.05±0.37

21.59±0.36 (25%)

23.00 (10%)

convex

19.13±0.34

18.63±0.34

18.41±0.34

19.06±0.34 (10%)

24.20 (10%)

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Performance comparison
Results

References

Dataset

SVMrbf

DBN-3

SAA-3

SdA-3 (ν)

SVMrbf (ν)

basic

rot

3.03±0.15

3.11±0.15

3.46±0.16

2.80±0.14 (10%)

3.07 (10%)

11.11±0.28

10.30±0.27

10.30±0.27

10.29±0.27 (10%)

11.62 (10%)

bg-rand

14.58±0.31

6.73±0.22

11.28±0.28

10.38±0.27 (40%)

15.63 (25%)

bg-img

22.61±0.37

16.31±0.32

23.00±0.37

16.68±0.33 (25%)

23.15 (25%)

rot-bg-img

55.18±0.44

47.39±0.44

51.93±0.44

44.49±0.44 (25%)

54.16 (10%)

rect

2.15±0.13

2.60±0.14

2.41±0.13

1.99±0.12 (10%)

2.45 (25%)

rect-img

24.04±0.37

22.50±0.37

24.05±0.37

21.59±0.36 (25%)

23.00 (10%)

convex

19.13±0.34

18.63±0.34

18.41±0.34

19.06±0.34 (10%)

24.20 (10%)

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Learnt ﬁlters
0 % destroyed

References

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Learnt ﬁlters
10 % destroyed

References

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Learnt ﬁlters
25 % destroyed

References

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Learnt ﬁlters
50 % destroyed

References

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Conclusion and future work

References

Unsupervised initialization of layers with an explicit denoising
criterion appears to help capture interesting structure in the input
distribution.

This leads to intermediate representations much better suited for
subsequent learning tasks such as supervised classiﬁcation.

Resulting algorithm for learning deep networks is simple and
improves on state-of-the-art on benchmark problems.

Although our experimental focus was supervised classiﬁcation, SdA
is directly usable in a semi-supervised setting.

Future work will investigate the eﬀect of diﬀerent types of corruption
process.

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

References

THANK YOU!

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

Performance comparison

Dataset

SVMrbf

SVMpoly

DBN-1

DBN-3

SAA-3

SdA-3 (ν)

basic

rot

3.03±0.15

3.69±0.17

3.94±0.17

3.11±0.15

3.46±0.16

2.80±0.14 (10%)

11.11±0.28

15.42±0.32

14.69±0.31

10.30±0.27

10.30±0.27

10.29±0.27 (10%)

bg-rand

14.58±0.31

16.62±0.33

9.80±0.26

6.73±0.22

11.28±0.28

10.38±0.27 (40%)

bg-img

22.61±0.37

24.01±0.37

16.15±0.32

16.31±0.32

23.00±0.37

16.68±0.33 (25%)

rot-bg-img

55.18±0.44

56.41±0.43

52.21±0.44

47.39±0.44

51.93±0.44

44.49±0.44 (25%)

rect

2.15±0.13

2.15±0.13

4.71±0.19

2.60±0.14

2.41±0.13

1.99±0.12 (10%)

rect-img

24.04±0.37

24.05±0.37

23.69±0.37

22.50±0.37

24.05±0.37

21.59±0.36 (25%)

convex

19.13±0.34

19.82±0.35

19.92±0.35

18.63±0.34

18.41±0.34

19.06±0.34 (10%)

red when conﬁdence intervals overlap.

References

References

Bengio, Y., Lamblin, P., Popovici, D., and Larochelle, H. (2007).

Greedy layer-wise training of deep networks.
In NIPS 19.

Gallinari, P., LeCun, Y., Thiria, S., and Fogelman-Soulie, F. (1987).

Memoires associatives distribuees.
In Proceedings of COGNITIVA 87, Paris, La Villette.

Hinton, G. E., Osindero, S., and Teh, Y. (2006).

A fast learning algorithm for deep belief nets.
Neural Computation, 18:1527–1554.

Hopﬁeld, J. J. (1982).

Neural networks and physical systems with emergent collective
computational abilities.
Proceedings of the National Academy of Sciences, USA, 79.

LeCun, Y. (1987).

Mod`eles connexionistes de l’apprentissage.
PhD thesis, Universit´e de Paris VI.

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

References

Ranzato, M., Poultney, C., Chopra, S., and LeCun, Y. (2007).

Eﬃcient learning of sparse representations with an energy-based model.
In et al., J. P., editor, Advances in Neural Information Processing Systems
(NIPS 2006). MIT Press.

Rumelhart, D. E., Hinton, G. E., and Williams, R. J. (1986).

Learning representations by back-propagating errors.
Nature, 323:533–536.

Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol

Extracting and Composing Robust Features with Denoising Autoencoders

