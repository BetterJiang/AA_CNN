Neural Networks 22 (2009) 544–557

Contents lists available at ScienceDirect

Neural Networks

journal homepage: www.elsevier.com/locate/neunet

2009 Special Issue
A new learning paradigm: Learning using privileged information
Vladimir Vapnik∗, Akshay Vashist

NEC Labs America, 4 Independence Way, Princeton, NJ 08540, United States

a r t i c l e

i n f o

a b s t r a c t

Article history:
Received 19 March 2009
Received in revised form 25 May 2009
Accepted 25 June 2009

Keywords:
Machine learning
SVM
SVM+
Hidden information
Privileged information
Learning with teacher
Oracle SVM

In the Afterword to the second edition of the book ‘‘Estimation of Dependences Based on Empirical
Data’’ by V. Vapnik, an advanced learning paradigm called Learning Using Hidden Information (LUHI) was
introduced. This Afterword also suggested an extension of the SVM method (the so called SVMγ + method)
to implement algorithms which address the LUHI paradigm (Vapnik, 1982–2006, Sections 2.4.2 and 2.5.3
of the Afterword). See also (Vapnik, Vashist, & Pavlovitch, 2008, 2009) for further development of the
algorithms.

In contrast to the existing machine learning paradigm where a teacher does not play an important
role, the advanced learning paradigm considers some elements of human teaching. In the new paradigm
along with examples, a teacher can provide students with hidden information that exists in explanations,
comments, comparisons, and so on.

This paper discusses details of the new paradigm1 and corresponding algorithms, introduces some
new algorithms, considers several specific forms of privileged information, demonstrates superiority of
the new learning paradigm over the classical learning paradigm when solving practical problems, and
discusses general questions related to the new ideas.

© 2009 Elsevier Ltd. All rights reserved.

1. Introduction: What does it mean ‘‘To Learn using privileged
information’’ ?

The existing machine learning paradigm considers a simple
scheme: given a set of training examples find in a given collection
of functions the one that in the best possible way approximates the
unknown decision rule. In such a paradigm a teacher does not play
an important role.

In human learning, however, the role of a teacher is very
important: along with examples a teacher provides students with
explanations, comments, comparisons, and so on. In this paper
we introduce elements of human teaching in machine learning.
We consider an advanced learning paradigm called learning using
privileged information (LUPI), where at the training stage a teacher
gives some additional information x∗ about training example x; this
privileged information will not be available at the test stage (Vapnik,
1982–2006). We will develop the LUPI paradigm for support vector
machine type of algorithms, and will demonstrate the superiority
of the advanced learning paradigm over the classical one.

Formally, the classical paradigm of supervised machine learning

is described as follows: given a set of pairs (training data)
(x1, y1), . . . , (x(cid:96), y(cid:96)),

xi ∈ X , yi ∈ {−1, 1},

∗ Corresponding author. Tel.: +1 609 750 0170.

E-mail addresses: vlad@nec-labs.com, vapnik@att.net (V. Vapnik),

vashist@nec-labs.com (A. Vashist).
1 In this article we changed the terminology. We will call this paradigm Learning
Using Privileged Information (LUPI) (instead of LUHI) since the word privilege better
reflects the core idea of the new paradigm.

0893-6080/$ – see front matter © 2009 Elsevier Ltd. All rights reserved.
doi:10.1016/j.neunet.2009.06.042

generated according to a fixed but unknown probability measure
P(x, y), find among a given set of functions f (x, α), α ∈ Λ the
function y = f (x, α∗) that minimizes the probability of incorrect
classifications (incorrect values of y). In this paradigm the vector
xi ∈ X is description of the example and yi is its classification.
The goal is to find the function y = f (x, α∗) that guarantees the
smallest probability of incorrect classifications.

The LUPI paradigm can be described as follows: given a set of

triplets
(x1, x∗

1, y1), . . . , (x(cid:96), x∗

(cid:96), y(cid:96)),

xi ∈ X , x∗

i ∈ X∗, yi ∈ {−1, 1},

generated according to a fixed but unknown probability measure
P(x, x∗, y) find among a given set of functions f (x, α), α ∈ Λ the
function y = f (x, α∗) that guarantees the smallest probability of
incorrect classification.

In the LUPI paradigm we have exactly the same goal as in the
classical paradigm i.e., to find the best function in the admissible
set of classification functions. However during the training
stage we are given an additional privileged information (triplets
(x, x∗, y) instead of pairs (x, y) as in the classical paradigm). The
additional information x∗ ∈ X∗ belongs (generally speaking) to the
space X∗ which is different from the space X.

Since the additional information is available at the training
stage but it is not available for the test set we call it privileged
information and the new machine learning paradigm learning

