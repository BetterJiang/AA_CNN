(V)

two

LEARNING  INTERNAL  REPRESENTATIONS

BERROR  PROPAGATION

David  E. Ruineihart,  Geoffrey  E.  Hint..,

and  Ronald  J. Williams

0 

4 

September  1985

ICS  Report  8506

COGNITIVE 

SCIENCE

IaQ  I

INSTITUTE  FOR  COGNITIVE  SCIENCE

UNIVERSITY  OF CALIFORNIA,  SAN  DIEGO 

862 18 

LA JOLLA, CALIFORNIA  92093
120,

4-

U-

LEARNING  INTERNAL  REPRESENTATIONS

BY  ERROR  PROPAGATION

David  E.  Rumelhart,  Geoffrey  E. Hinton,

and Ronald  J.  Williams 

DTIC

September  1985 

ICS  Report  M50  SLD

AL"LECT
FEB 20  M

David  E.  Rumelhart 

Institute for Cognitive Science 

University of  California, San Diego 

Geoffrey E.  Hinton

Department of Computer  Science

Carnegie-Mellon University

Ronald  J. Williams

Institute for Cognitive Science 

University of California, San Diego 

Di' 
_

AL

xow"d  io n  publ@
DkltAtfikuim 

fi1Id

To  be published  in  D.  E.  Rumelhart  &  i.  L.  McClelland  (Eds.),  Parallel Distributed
Processing:  Explorations  in  the  Microstructure of  Cognition.  Vol.  1:  Foundations.
Cambridge,  MA:  Bradford  Books/MIT  Press.

This research  wa  supported  by Contract  NOD14.45-K0450,  NR 667-58 with the Personnel  Lad Training  Research  Pro-
gams  of  the Office  of  Naval  Research  and  by  grants  from  the  System  Development  Foundation.  Requests  for rm-
prints siould  be  seat  to  David  E.  Ramdhut,  Institute for  Cognitive  Science,  C4)13;  University  of California,  San
Diego; La Jolla, CA 92093.
Copyright  0  1985 by David  B.  Rumeliat,  Geoffrey E.  finton. and  Ronald i. Williams

U P.

Unclassified

SECURITY  CLASSIFICATION  OF  THIS  PAGE

REPORT  DOCUMENTATION  PAGE

la.  REPORT  SECURITY  CLASSIFICATION 

Unclassified 

2a. SECURITY  CLASSIFICATION  AUTHORITY 

2b.  DECLASSIFICATION  I DOWNGRADING  SCHEDULE 

lb  RESTRICTIVE  MARKINGS

3. DISTRIBUTION/AVAILABILITY OF REPORT

Approved for  public  release;
distribution unlimited.

,,

4. PERFORMING  ORGANIZATION  REPORT  NUMBER(S) 

S. MONITORING  ORGANIZATION  REPORT  NUMBER(S)

ICS  8506

6a.  NAME  OF  PERFORMING  ORGANIZATION 

Institute  for  Cognitive 
Science 

I

6b.  OFFICE  SYMBOL 

(If  applicable)

6c. ADDRESS (City,  State, and ZIP Code) 

C-015
University  of  California, San Diego
La Jolla,  CA 92093

Ba.  NAME  OF  FUNDING/SPONSORING 

ORGANIZATION 
Personnel  & Training  Researc 

8b. OFFICE  SYMBOL 

(If applicable)

8c.  ADDRESS  (City,  State, and ZIP Code) 

Code  1142  PT 
Office  of  Naval Research 
800 N.  Quincy St.,  Arlington,  VA  22217-5000 

11.  TITLE  (Include Security  Classification)

7a  NAME  OF  MONITORING ORGANIZATION

7b.  ADDRESS  (City,  State,  and  ZIP Code)

9.  PROCUREMENT 

INSTRUMENT 

IDENTIFICATION  NUMBER

N00014-85-K-0450

10. SOURCE  OF  FUNDING  NUMBERS
PROGRAM 
ELEMENT  NO. 

PROJECT 
NO. 
NR 667-548

TASK 
NO. 

WORK UNiT
ACCESSION  NO

Learning  Internal  Representations by Error  Propagation

12.  PERSONAL  AUTHOR(S)

David  E. Rumelhart, Geoffrey  E. Hinton, and  Ronald  J. Williams

13a.  TYPE  OF  REPORT 

Technical 

13b.  TIME  COVERED 

FROMMar  85 

TO  Sept  8 

14.  DATE  OF  REPORT  (ear,  Month, Day)  S. PAGE COUNT

September  1985 

34

16  SUPPLEMFNTARY  NOTATION 

To  be  published  in  J. L.  McClelland,  D.  E. Rumelhart,  &  the  PDP  Research  Group,
Parallel  Dislribuled  Processing:  Exploratiois  in the  Microstrucure  of  Cognkion:  Vol  1.  Founsdations.  Cambridge,  MA:
Bradford  nlooks/Mnr  Press.

17. 

COSATI CODES 

FIELD 

GROUP 

SUB-GROUP 

18. SUBJECT TERMS  (Continue  on  reverse  if  necessary  and  identify  by  block  number)

-learning;  networks;  perceptrons;  adaptive  systems;

learning machines;  back propagation

19. ABSTRACT (Continue  on  reverse  if necessary  and  identify  by  block  number)

This  paper  presents  a generalization  of  the  perceptron  learning  procedure  for  learning  the correct
sets  of  connections  for  arbitrary  networks.  The  rule,  called  the  generalized  delta  rule,  is  a  simple
scheme  for implementing  a  gradient  descent  method  for finding  weights  that  minimize  the sum  squared
error  of  the  system's  performance.  The  major  theoretical  contribution  of  the  work  is  the  procedure
called  error  propagation,  whereby  the  gradient  can  be  determined  by individual  units  of  the  network
based  only on  locally  available  information.  The  major  empirical  contribution  of the work  is  to show
that thc  problem  of local  minima is not  serious  in  this application  of gradient  descent.  i

20. DISTRIBUTION/AVAILABILITY  OF ABSTRACT 

QUNCLASSIFIED/UNLIMITED 

0  SAME  AS  RPT. 

21.  ABSTRACT  SECURITY  CLASSIFICATION

0  DTIC  USERS 

Unclassified

22a  NAME  OF  RESPONSIBLE  INDIVIDUAL 

22b.  TELEPHONE  (Include  Area Code)  22c. OFFICE  SYMBOL

DO  FORM  1473,  84 MAR 

83 APR edition  may be used until exhausted. 

All other editions are obsolete. 

SECURITY  CLASSIFICATION  OF  THIS  PAGE
Unclassified

Contents

THE  PROBLEM .................................................................................
THE GEN4ERALIZED  DELTA  RULE........................................................ 

The  delta rule and gradient  descent................................................ 
The  delta rule for semilinear activation functions in feedforward networks. 

S[MULATION  RESULTS  ..................................................................... 

A  useful activation function .......................................................... 
The learning rate..................................................................... 
Symmetry  breaking................................................................... 

The  XOR  Problem........................................................................ 
Parity ................................................................................... 
The  Encoding  Problem................................................................... 
Symmetry  ............................................................................... 
Addition  ................................................................................ 

Negation  Problem.................................................................... 

*The 

The  T-C  Problem  ..........................................................................
More  Simulation  Results................................................................. 
SOME  FURTHER  GENERALIZATIONS  ................................................... 
The  Generalized  Delta  Rule  and  Sigma-Pi  Units  .................................... 
Recurrent  Nets......................................................................... 

Leff nng to be a shift register ...................................................... 
Learning to complete  sequences ..................................................... 

CONCLUSION................................................................................... 
REFERENCES................................................................................ 

4
4
5
8
8
9
10
10
12
14
17
18
21
22
26
26
26
2
29
30
31
33

Uiannoun'ced 

13

Learning Internal Representations
by  Error Propagation

DAVID  E.  RUMELHART,  GEOFFREY  E.  HINTON,  and  RONALD  J. WILLIAMS

THE  PROBLEM

We now  have  a  rather good  understanding  of simple two-layer  associative  networks  in  which
a  set  of input  patterns arriving  at  an  input  layer are mapped  directly to  a set  of output  patterns
at  an  output  layer.  Such  networks  have  no  hidden  units.  They  involve  only  input and  owput
units.  In  these  cases  there  is  no  internal represenatmon.  The  coding  provided  by  the  external
world  must  suffice.  These  networks  have  proved  useful  in  a  wide  variety  of applications  (cf.
Chapters  2,  17,  and  18).  Perhaps  the essential  character of such  networks  is that  they  map  simi-
lar  input  patterns  to  similar  output  patterns.  This  is what  allows  these  networks  to  make  rea-
sonable  generalizations  and  perform  reasonably  on  patterns  that  have  never  before  been
presented.  The  similarity  of  patterns  in  a  PDP  system  is  determined  by  their  overlap.  The
overlap  in  such  networks  is  determined  outside  the  learning  system  itself-by  whatever  pro-
duces  the patterns.

The constraint  that  similar  input  patterns  lead  to  similar outputs  can  lead  to  an  inability  of
the  system  to  learn  certain  mappings  from  input  to  output.  Whenever  the  representation  pro-
vided  by  the  outside  world  is  such  that  the  similarity  structure  of  the  input  and  output  pat-
tcrns  are  very  different,  a  network  without  internal  representations  (i.e.,  a  network  without
hidden  units) will  be  unable  to  perform  the necessary  mappings.  A  classic  example  of this  case
is  the  exclusive-or  (XOR)  problem  illustrated  in  Table  1.  Here  we  see  that  those  patterns
which  overlap  least  arc supposed  to  generate  identical  output  values.  This  problem  and  many
others  like  it  cannot  be  performed  by  networks  without  hidden  units  with  which  to  create

TABLE  I

Input Patterns 

Output oPatterns

01 

-0

2 

RUMELHART.  HrwrON. and  WILLIAMS

TABLE  2

Input Patterns 

Output  Patterns

00 
010 

11 

-

0
1.

0

their  own  internal  representations  of the  input  patterns.  It  is  interesting  to  note  that  had  the
input  patterns contained  a  third  input  taking  the value  1 whenever  the first  two have  value  1 as
shown  in  Table  2,  a  two-layer  system would  be  able to  solve  the problem.

Minsky  and  Papert  (1969)  have  provided  a  very  careful  analysis  of  conditions  under  which
such  systems  are  capable  of  carrying  out  the  required  mappings.  They  show  that  in  a  large
number  of  interesting  cases,  networks  of  this  kind  are  incapable  of  solving  the  problems.  On
the other  hand,  as  Minsky  and  Papert  also  pointed  out,  if there is  a  layer of simple  perceptron-
like  hidden  units,  as  shown  in  Figure  1, with  which  the  original  input  pattern  can  be  aug-
mented,  there  is  always  a  recoding  (i.e.,  an  internal  representation)  of the input  patterns  in  the
hidden  units  in  which  the  similarity  of  the  patterns  among  the  hidden  units  can  support  any
required  mapping  from  the  input  to  the output  units.  Thus,  if we  have  the  right  connections
from  the  input  units  to  a  large  enough  set  of  hidden  units, we  can  always  find  a  representation

Output  Patterns

Internal
O"  *Representation

Units

Input Patterns

FIGURE  1.  A  multilayer  network.  In  this case  the  information  coming  to  the input  units is  receded  into an  inter-
nal  representation  and  the outputs  are  generated  by  the internal  representation  rather than by  the original  pattern.
Input patterns can  always  be  encoded,  if there are enough  hidden units,  in a form  so  that the  appropriate output pat-
tern  can  be  generated  from  any input pattern.

6 

M

LEARNING  miNLRNAL  REPRE  ENTATIONS 

3

that  will  perform  any  mapping  from  input  to  output  through  these  hidden  units.  In  the case
of the XOR  problem,  the  addition  of  a  feature  that  detects  the conjunction  of the  input  units
changes  the  similarity  structure  of the  patterns  sufficiently  to  allow  the solution  to  be  learned.
As  illustrated  in  Figure  2,  this can  be  done  with  a  single  hidden  unit.  The  numbers  on  the
arrows  represent  the  strengths  of  the  connections  among  the  units.  The  numbers  written  in
the  circles  represent  the  thresholds  of  the  units.  The  value  of  +1.5  for  the  threshold  of  the
hidden  unit  insures  that  it  will  be  turned  on  only when  both input  units  are  on. The  value  0.5
for  the  output  unit  insures  that  it  will  turn  on  only  when  it  receives  a  net  positive  input
greater  than  0.5.  The  weight  of  -2  from  the hidden  uait  to  the  output  unit  insures  that  the
output  unit  will  not  come  on  when  both  input  units  arc on.  Note  that  from  the point  of view
of the output  unit,  the  hidden unit  is treated  as  simply another  input  unit.  It  is  as  if the input
patterns consisted  of three rather  than  two  units.

The  existence  of  networks  such  as  this  illustrates  the  potential  power  of  hidden  units  and
internal  representations.  The  problem,  as  noted  by  Minsky  and  Papert,  is  that  whereas  there is
a  very simple  guaranteed  learning  rule for all  problems that  can  be  solved  without  hidden  units,
namely,  the perceptron  convergence  procedure  (or  the  variation  due  originally  to  Widrow  and
Hoff,  1960,  which  we call  the  delta  rule;  see  Chapter  11),  there  is  no  equally powerful  rule  for
learning  in  networks  with  hidden  units.  There  have  been  three  basic  responses  to  this  lack.
One  response  is  represented  by  competitive  learning  (Chapter  5)  in  which  simple  unsupervised
learning rules  are  employed  so  that  useful  hidden  units develop.  Although  these  approaches  are
promising,  there  is  no  external  force  to  insure that  hidden  units  appropriate  for  the  required
mapping  are  developed.  The  second  response  is  to  simply  asswne  an  internal  representation
that,  on  some  a  priori  grounds,  seems  reasonable.  This  is the  tack  taken  in  the chapter on  verb
learning  (Chapter  18)  and  in  theinteractive  activation  model  of  word  perception  (McClelland
&  Rumelhart,  1981;  Rumelhart  &  McClelland,  1982).  The  third  approach  is  to  attempt  to
develop  a  learning  procedure  capable  of  learning  an  internal  representation  adequate  for  per-
forming  the  task  at  hand.  One  such  development  is  presented  in  the  discussion  of  Boltzmann
machines  in  Chapter  7.  As  we  have  seen,  this  procedure  involves  the  use  of stochastic  units,
requires  the network  to  reach  equilibrium  in  two different  phases,  and  is  limited  to  symmetric
networks.  Another  recent  approach,  also  employing  stochastic  units,  has  been  developed  by
Barto  (1985)  and  various  of  his  colleagues  (cf.  Barto  &  Anandan,  1985). 
In  this  chapter  we

.5  Output  Unit

+1 

-21 

+1

Hidden  Unit

S  +1 

+1

Input  Units

FIGURE  2.  A  simple  XOR  network  with one  hidden  unit.  See  text  for  explanation.

d 

'% .. 

- P I  .

4 

RUMELHAxr,  HmroN, and  WILLIAMS

present  another  alternative  that  works  with  deterministic  units,  that  involves  only local  compu-
tations,  and  that  is  a  clear  generalization  of the  delta  rule.  We  call  this  the  generalized delta
rule.  From  other  considerations,  Parker  (1985)  has  independently  derived  a similar  generaliza-
tion,  which  he  calls  learning-logic.  Le Cun  (1985)  has  also  studied  a  roughly  similar  learning
scheme.  In  the  remainder  of  this  chapter  we  first  derive  the  generalized  delta  rule,  then  we
illustrate  its  use  by  providing  some  results  of  our  simulations,  and  finally  we  indicate  some
further  generalizations  of the basic  idea.

THE GENERALIZED  DELTA  RULE

The  learning  pro cedure  we  propose  involves  the presentation  of  a set  of  pairs  of  input  and
output  patterns.  The  system  first  uses  the  input  vector  to  produce  its own  output  vector  and
then  compares  this  with  the desired output, or target vector.  If there  is  no  difference,  no  learn-
ing takes  place.  Otherwise  the  weights  are changed  to  reduce  the  difference.  In  this case,  with
no  hidden  units,  this  generates  the  standard  delta  rule  as  described  in  Chapters  2  and  11.  The
rule  for changing  weights following presentation  of  input/output  pair p  is given  by

AP-J, =  *I(tpj  - Op,)  ip, =  napjipt 

(1)

where  tj  is the  target  input  for  jth component  of  the output  pattern  for  pattern  p,  o, 
jth element  of  the  actual  output  pattern  produced  by  the  presentation  of input  pattern p,  ipi
is  the  value  of the  ith  element  of  the input  pattern  8,j  =  tj  - opj, and  Awj,  is the change  to
be made  to  the weight  from  the i th to  the j th unit  following presentation  of pattern  p.

is  the

The  delta  rule  and  gradient descent.  There  are  many  ways  of  deriving  this  rule.  For
present  purposes,  it  is  useful  to  see  that  for  linear  units  it  minimizes  the  squares  of  the
differences  between  the  actual  and  the  desired  output  values  summed  over  the  output  units
and  all  pairs  of  input/output  vectors.  One  way  to  show  this is  to  show  that  the derivative  of
the error  measure  with  respect  to  each  weight  is  proportional  to  the  weight  change  dictated  by
the  delta  rule,  with  negative  constant  of  proportionality.  This  corresponds  to  performing
steepest  descent  on  a surface  in  weight  space  whose height  at  any point  in  weight  space  is equal
to  the  error  measure.  (Note  that  some  of the  following  sections  are  written  in  italics.  These
sections  constitute  informal  derivations  of  the  claims  made  in  the surrounding  text  and  can  be
omitted  by  the reader  who  finds such  derivations  tedious.)

To be  more specific, then, let

E  1 ,  t-opj ) 

(2)

*- 

be  our  measure  of  the  error on  input/output pa. err p  and  let  E  = 
be  our  overall measure of  the
bEp 
error.  We  wish to show that the delta rule implements a  gradient descent in E  when the  units are linear.  We
will proceed by  simply showing that

.. 

a• 

.

8pjipi,

* 

which  is  proportional to  A.  w,, as prescribed by  the delta rule.  When  there are no hidden units it  is straight-
forward to compute  the  relevant derivative.  For this purpose we  use  the  chain rule to write the derivative as
the product of  two parts. the  derivative of  the  error with  respect to the output  of  the  unit times the derivative

:(k 

L  1

of the outpit  with respect  to the  weight.

BEp  =  2E,  Bop 
1Rwj 
CIopj  awj,

LEARNING 

IRnA  11±PREMSEWATIONS

(3)

The  first part  tells how  the  error changes with the output of  the jth unit and  the  second part tells  how much
changing wj1  changes that outWt.  Now, the derivatives are easy to compute.  First,from Equation 2

.
aopj

(t - o,)- 

8 

(4)

Not  surprisingly,  the  contribution  of  unit  uj  to the  error  is  simply proportional  to  &.  Moreover.  sinLe  we
have linear units.

from which  we  conclude that

Thus, substituting back  into Equation  3. we  see  that

* 

BEp 

Bw

as desired.  Now, combining  this with  the observation that

' 

BE 

BE,

(6)

should  lead  us to conclude  that the  net change  in wj, after one  complete  cycle of pattern presentations is pro-
portional  to this  derivative and  hence  that  the  delta rule  implements  a gradient descent  in E. 
In fact, this  is
strictly true only  if  the  values of  the weights are  not changed  during  this cycle.  By changing  the  weights after
each pattern is presented  we  depart to  some  extent from  a true gradient  descent  in E.  Nevertheless, pro-
vided  the  learning rate (i.e..  the  constant of proportionality)  is safficiently small, this departure  will be  negli-
gible  and the  delta rule  will implement  a  very  close approximation  to gradient  descent  in sum-squared  error.
In particular,  with  small  enough  learning  rate. the  delta ride will find  a set  of weights minimizing  this  error
function.

The  delta rule for  semilinear activation functions  in  feedforward  networks.  We  have
shown  how  the  standard  delta  rule  essentially  implements  gradient  descent  in  sum-squared
error  for  linear  activation  functions.  In  this  case,  without  hidden  units,  the  error  surface  is
shaped  like  a  bowl  with  only  one  minimum,  so  gradient  descent  is  guaranteed  to  find  the  best
set  of  weights.  With  hidden  units,  however,  it  is  not  so  obvious  how  to  compute  the  deriva-
tives,  and  the  error surface  is  not  concave  upwards,  so  there  is  the danger  of  getting  stuck  in
local  minima.  The  main  theoretical  contribution  of  this  chapter  is  to  show  that  there  is  an
efficient  way  of  computing  the  derivatives.  The  main  empirical  contribution  is  to  show  that
the apparently  fatal  problem  of  local  minima  is  irrelevant  in  a  wide  variety of  learning  tasks.

At  the  end  of  the chapter  we  show  how  the generalized  delta  rule  can  be applied  to arbitrary
networks,  but,  to  begin  with,  we  confine  ourselves  to  layered feedforward networks.  In  these
networks,  the  input  units  are  the  bottom  layer  and  the  output  units  are  the top  layer.  There
can  be  many  layers  of  hidden  units  in  between,  but  every  unit  must  send  its  output  to  higher
layers  than  its  own  and  must  receive  its  input  from  lower  layers  than  its  own.  Given  an  input
vector,  the  output  vector  is  computed  by  a  forward  pass  which  computes  the  activity  levels  of
each  layer  in  turn  using the  already computed  activity  levels  in  the earlier  layers.

Since  we  are  primarily  interested  in  extending  this  result  to  the  case  with  hidden  units  and
since,  for  reasons  outlined  in  Chapter  2,  hidden  units  with  linear  activation  functions  provide

6 

RUMELHART,  HIjTON, and  WILUAMIS

no  advantage,  we  begin  by  generalizing our analysis  to  the set  of nonlinear  activation  functions
which  wz  call  semilinear (see  Chapter  2).  A  semilinear  activation  function  is  one in  which  the
output  of a  unit  is  a differentiable  function  of the net  total  input,

,etpj  = 

wjto,,, 

(7)

where  oj  =  it  if unit  i  is  an  input  unit.  Thus,  a semilinear  activation  function  is  one in which

o, j  =  f  j (net,,) 

(8)

is  differentiable.  The  generalized  delta  rule  works  if the  network  consists  of units  hav-
and  f 
ing  semilinear  activation  functions.  Notice  that  linear  threshold  units  do  not  satisfy  the
requirement  because  their derivative  is infinite  at  the  threshold  and  zero  elsewhere.

To get  the correct generalization  of  the  delta  rule, we  must set

A,  wo,, 

-

"-_
aw1,

where  E 
is the  same  sum-squared  error  function  defined  earlier.  As  in  the  standard  delta  rule it  is again
useful  to  see  this  derivative  as  resulting from  the  product  of  two  parts:  one  part  reflecting  the  change  in
error  as  a function of  the  change  in  the  net  input  to the  unit  and  one  part  representing  the  effect  of  changing
a particular  weight  on  the  net input.  Thus we  can  write

,' 

* 

aOE'  8 
a 8Wj 

E, 

8 netp 
8 netj  8w,

By  Equation  7  we see  that  the  second factor  is

anet~j 

1 

= 

-

=  Op,.

Now  let us define

aEP
anetp,

bpi 

(9)

(10)

(By  comparing  this  to  Equation  4.  note  that  this  is consistent  with  the  definition  of  8p  used  in  the  original
delta rule for  linear  units since  Oj  =  netj  when  unit  Uj  is linear.) Equation  9  thus has  the  equivalent form

8E  P  p 

iO  P

This  says that  to implement  gradient  descent in E  we should make  our weight  changes according  to

just as  in  the  standard  delta  rule.  The  trick  is to figure  out  what  8P,  should  be for  each  unit  ua  in the  net-
work.  The  interesting  result,  which  we  now  derive, is that  there  is a  simple  recursive computation of  these  8's
which  can be  implemented  bZ  propagating error  signals backward  through the  network.

2";a 

To  compute  8, 

netvj

,  we  apply the  chain  rule  to write this partial  derivative  as the product  of two

factors, one factor  reflecting the  change  in error  as a function of  the output  of the  unit  and  one  reflecting  the

* 

N

LEARNING  ITRNAl- a1PRESEPrAIONS 

7

change in the output as a function of changes in the  input.  Thus,  we  have

8Ep  = 
Bne,, 

8Ep  Bop 
)op0 anefpj

Let us  compute  the second factor.  By Equation 8  we see  that

(12)

One~p  =f "1(netpl )"

a 

_

which  is simply  the derivative  of the squashing function f  j  for the  j th unit, evaluated  at  the net  input netp  to
that  unit.  To  compute  the first factor,  we  consider  two cases.  First, assume  that  unit  uj  is an output  unit of
the  network.  In this case, it follows from the definition  of Ep that

±_P 

(t -

which is the  same  result as we  obtained  with the  standard  delta rule.  Substituting for the  two factors in Equa-
tion 12.  we  get

5,,  =  (t,,  - opj )f  'j (ne t, 

(3

for any  output  unit Uj.  If  Uj is  not  an output  unit we  use the  chain  rule  to write

* 

P 

An, 

._ BE, 

I- 

I 

111Wkj 

f'ap 

c.ntp 

80,1 

kc1netk 

~8,,&WIk1

k  C1ne PA 

k

In this case,  substituting for the  two factors in Equation  12 yields

whenever  u1  is  not an  output  unit.  Equations  13  and  14  give  a recursive procedure for computing  the  8's for
all units  in the  network,  which  are  then  used  to compute  the  weight  changes  in the  network according  to Equa-
tion 11.  This procedure  constitutes the  generalized delta  rule for a feedforward  network of  semilinear  units.

These  results  can  be  summarized  in  three  equations.  First,  the  generalized  delta  rule  has
exactly  the  same  form  as  the  standard  delta  rule  of  Equation  1.  The  weight  on  each  line
should  be  changed  by  an  amount  proportional  to  the product  of an  error signal,  8,  available  to
the  unit  receiving  input  along  that  line  and  the  output  of  the  unit  sending  activation  along
that  line.  In  symbols,

Ap wj  =  1OpjOpt.

The  other  two  equations  specify  the  error  signal.  Essentially,  the  determination  of  the  error
signal  is  a  recursive  process  which  starts  with  the  output  units.  If  a  unit  is  an  output  unit,  its
error signal  is  very  similar  to the standard  delta rule.  It  is  given  by

'.'."" 

8p, =  (toj  - op/)f " (net,,)

* 

where  f  "j(netij) is  the  derivative  of  the  semilinear  activation  function  which  maps  the  total
input  to  the unit  to  an  output  value.  Finally,  the error  signal  for  hidden  units  for  which  there
is  no  specified  target  is  determined  recursively  in  terms  of  the  error  signals  of  the  units  to

i%A, 

. "'s% 

.-, .' .- '  .

.. " . , . ,' . , 

'  . : 

. , ' , , .. ."", 

, 

%  ",  , ., , ..' 

' ,  . -, . ' ',, , " ,. , ,, - , , , #"  ,,

8 

RUIGELHART.  HwqroN,  and  wiaLuAws

which  it  directly connects  and  the  weights of those  connections.  That  is,

bj, =f  "j (nej),)  w Wkj

k

whenever  the unit is  not an  output  unit.

The  application  of  the  generalized  delta  rule,  thus,  involves  two  phases:  During  the  first
phase  the  input  is  presented  and  propagated  forward  through  the network  to compute  the out-
put  value  oj  for  each  unit.  This  output  is  then  compared  with  the  targets,  resulting  in  an
error  signal  6,j  for  each  output  unit.  The  second  phase  involves  a  backward  pass  through  the
network  (analogous  to  the  initial  forward  pass)  during which  the  error  signal  is  passed  to each
unit  in  the  network  and  the  appropriate  weight  changes  are  made.  This second,  backward  pass
allows  the  recursive  computation  of 8  as  indicated  above.  The  first  step  is  to  compute  8 for
each  of  the  output  units.  This  is  simply  the  difference  between  the  actual  and  desired  output
values  times  the  derivative  of  the  squashing  function.  We  can  then  compute  weight  changes
for  all  connections  that  feed  into  the  final  layer.  After  this  is  done,  then  compute  a's  for  all
units  in  the  penultimate  layer.  This  propagates  the errors  back  one  layer,  and  the same  process
can  be  repeated  for  every  layer.  The  backward  pass  has  the  same  computational  complexity  as
the forward  pass,  and  so  it  is not  unduly  expensive.

We  have  now  generated  a  gradient  descent  method  for  finding  weights  in  any  feedforward
network  with  semilinear  units.  Before  reporting our results with  these  networks, it  is useful  to
note  some  further  observations.  It  is  interesting  that  not  all  weights  need  be  variable.  Any
number  of weights  in  the  network  can  be  fixed.  In  this case,  error is still propagated  as  before;
the  fixed  weights  are  simply  not  modified.  It  should  also  be  noted  that  there  is no  reason  why
some  output  units  might  not  receive  inputs  from  other  output  units  in  earlier  layers.  In  this
case,  those  units  receive  two  different  kinds of error:  that  from  the direct  comparison  with  the
target  and  that  passed  through  the other output  units whose  activation  it  affects.  In  this  case,
the correct  procedure  is  to  simply  add  the weight  changes  dictated  by the  direct  comparison  to
that  propagated  back  from the  other output  units.

SIMULATION  RESULTS

We  now  have  a  learning procedure  which  could,  in  principle,  evolve  a  set  of  weights  to  pro-
duce  an  arbitrary  mapping  from  input  to  output.  However,  the procedure  we have  produced  is
a gradient  descent  procedure  and,  as  such,  is  bound  by  all  of the problems  of any  hill  climbing
procedure--namcly,  the problem  of local  maxima  or (in  our case)  minima.  Moreover,  there  is a
question  of  how  long  it  might  take  a  system  to  learn.  Even  if  we  could  guarantee  that  it
would  eventually  find  a  solution,  there  is the  question  of whether  our  procedure could  learn  in
a  reasonable  period  of  time.  It  is  interesting  to  ask  what  hidden  units  the  system  actually
develops  in  the solution  of  particular  problems.  This  is the question  of what  kinds  of internal
representations  the  system  actually  creates.  We  do  not  yet  have  definitive  answers  to  these
questions.  However,  we  have  carried  out  many  simulations  which  lead  us  to  be  optimistic
about  the  local  minima  and  time  questions  and  to  be surprised  by  the  kinds of representations
our  learning  mechanism  discovers.  Before  proceeding  with  our  results,  we  must  describe  our
simulation  system  in  more  detail. 
In  particular,  we  must  specify  an  activation  function  and
show  how  the system  can  compute the derivative  of this function.

A useful  activation function.  In  our above  derivations  the derivative  of  the  activation  func-
tion  of  unit  u,  f  "J(netj), always  played  a  role.  This  implies  that  we  need  an  activation  func-
tion  for  which  a  derivative  exists.  It  is  interesting  to  note  that  the  linear  threshold  function,
on  which  the  perceptron  is  based,  is  discontinuous  and  hence  will  not  suffice  for  the  general-
ized  delta  rule.  Similarly,  since  a  linear  system  achieves  no  advantage  from  hidden  units,  a

-

ono

LIEARMW;~ i0flhINAL REMISLFGA11ONS 

'

linear  activation  function  will not suffice  either.  Thus, we need  a  continuous,  nonlinear  activa-
tion  function.  In  most  of  our  experiments  we  have  used  the  logistic activation  function  in
which

o  = 

-
1+e

1 

( 

°,

(15)

where  Oj  is  a  bias  similar  in  function  to  a  threshold.  I In  order  to  apply  our  learning rule,  we
need  to  know  the  derivative  of  this  function  with  respect  to  its  total  input,  Mtj,  where
netpj  =  Ywjjoj  +  Oj.  It  is  easy  to show  that  this derivative  is  given  by

¢= 

o,,(I - opj).

Thus, for the  logistic activation  function,  the error signal,  8,j,  for an  output  unit  is given  by

_aj  =  (tpj  - os)o,,(I  - opj).

and  the error for an  arbitrary  hidden  Nj  is given  by

=  opj)( 

-
-

Wkj

It  should  be  noted  that  the  derivative,  opj(1  - oj),  reaches  its  maximum  for  opj  =  0.5  and,
1, approaches  its minimum  as  opj  approaches  zero  or one.  Since  the  amount  of
since  0,,  o,, 
change  in  a  given  weight  is  proportional  to  this  derivative,  weights  will  be  changed  most  for
those units  that  are  near  their  midrange  and,  in  some  sense,  not  yet  committed  to being either
on  or off.  This  feature, we  believe,  contributes to  the stability of the learning of the system.

One  other  feature  of  this activation  function  should  be  noted.  The system  can  not  actually
reach  its  extreme  values  of  1 or  0  without  infinitely  large  weights.  Therefore,  in  a  practical
learning  situation  in  which  the  desired  outputs  are  binary  {0,1),  the  system  can  never  actually
achieve  these  values.  Therefore,  we  typically  use  the  values  of  0.1  and  0.9  as  the  targets,  even
though  we will talk  as if values of (0,1)  are  sought.

The  learndng rate.  Our learning  procedure  requires  only that  the  change  in  weight  be  pro-
portional  to  E,/aw.  True  gradient  descent  requires  that  infinitesimal  steps  be  taken.  The
constant  of  proportionality  is  the  learning  rate in  our procedure.  The  larger this  constant,  the
larger  the  changes  in  the  weights.  For  practical  purposes  we  choose  a  learning  rate  that  is  as
large  as  possible  without  leading  to  oscillation.  This  offers  the most  rapid  learning.  One  way
to  increase  the  learning  rate  without  leading  to  oscillation  is  to  modify  the  generalized  delta
rule to  include a  momentum  term.  This  can  be  accomplished  by  the following  rule:

Aw1,(n+1)  =  qb(pjo,,)  + aAwjj(n) 

(16)

where  the  subscript  n  indexes  the presentation  number,  q) is  the  learning  rate,  and  a  is  a con-
stant  which  determines  the effect  of past  weight  changes on  the current  direction of  movement
in  weight  space.  This provides  a  kind  of  momentum  in  weight  space  that  effectively  filters  out
high-frequency  variations  of the  error-surface  in  the weight  space.  This  is useful  in  spaces con-
taining  long  ravines  that  are  characterized  by  sharp  curvature  across  the  ravine  and  a  gently
sloping  floor.  The sharp  curvature  tends  to  cause  divergent  oscillations  across  the  ravine.  To
prevent  these  it  is  necessary  to  take  very  small  steps,  but  this  causes  very  slow  progress  along
the  ravine.  The  momentum  filters  out  the high  curvature  and  thus  allows the  effective  weight

Note  that  the  values  of  the  bias.  0,,  ca  be  learned  just  like any  other  weights.  We  simply  imagine  that  9,  is the

weight  from  a unit  that  is always on

10 

RUMELHART.  IUTON. and  WILLIAMS

steps  to  be  bigger.  In  most  of our  simulations  a  was  about  0.9.  Our experience  has  been  that
we  get  the  same  solutions  by  setting  a  = 0  and  reducing  the  size  of  -q, but  the  system  learns
much  faster  overall  with  larger  values  of a  and  -q.

Symmetry  breaking.  Our  learning  procedure  has  one  more  problem  that  can  be  readily
overcome  and  this  is  the  problem  of  symmetry  breaking.  If  all  weights  start  out  with  equal
values  and  if  the  solution  requires  that  unequal  weights  be  developed,  the  system  can  never
learn.  This is  because  error  is propagated  back  through  the  weights in  proportion  to  the values
of the  weights.  This  means  that  all  hidden  units connected  directly  to  the  output  inputs  will
get  identical  error  signals,  and,  since  the  weight  changes  depend  on  the  error  signals,  the
weights  from  those  units  to  the  output  units  must  always  be  the same.  The  system  is  starting
out  at  a  kind  of  local maximum,  which  keeps  the  weights  equal,  but  it  is  a  maximum  of  the
error  function,  so  once  it  escapes  it  will  never  return.  We  counteract  this  problem  by  starting
the  system  with  small  random  weights.  Under  these  conditions  symmetry problems  of this  kind
do  not  arise.

The XOR  Problem

* 

It  is  useful  to  begin  with  the  exclusive-or  problem  since  it  is  the  classic  problem  requiring
hidden  units  and  since  many  other difficult  problems  involve  an  XOR  as  a  subproblem.  We
have  run  the  XOR  problem  many  times  and  with  a  couple  of  exceptions  discussed  below,  the
system  has  always  solved  the  problem.  Figure  3  shows  one  of  the  solutions  to  the problem.

6.3  Output  Unit

V42

-4.2 
/ 

/ 

/ 
-9.41
A 

/\

.

.2

-6.4 

-6.4

Input  Units

Hidden  Unit

FIGURE  3.  Observed  XOR  network.  The  connection  weights  are written  on  the arrows  and  the  biases  are written
in  the circles.  Note  a postive  bias means that  the  unit  is  on unless  turned  off.

i% 

V

LEARN 

& iB 

AL  1EIReSIATiONS 

1t

solution  was  reached  after  558 sweeps  through  the  four stimulus  patterns  with  a  learning
Iis 
rate of  Yj  =  0.5. 
In  this case,  both  the  hidden  unit  and  the output  unit  have  positive biases so
they are  on  unless  turned  off.  The hidden  unit  turns on  if neither input  unit  is  on.  When  it  is
on,  it  turns off  the  output  unit.  The  connections  from  input  to  output  units  arranged  them-
selves  so  that  they turn  off  the output  unit  whenever both  inputs  are  on.  In  this case,  the  net-
work  has  settled to  a solution  which is  a  sort  of mirror image  of the one illustrated  in  Figure 2.
We  have  taught  the  system  to  solve  the  XOR  problem  hundreds  of  times.  Sometimes  we
have  used  a  single  hidden  unit  and  direct  connections  to  the  output  unit  as  illustrated  here,
and  other  times  we  have  allowed  two  hidden  units  and  set  the  connections  from  the  input
units  to  the  outputs  to  be  zero,  as  shown  in  Figure  4.  In  only  two  cases  has  the  system
encountered  a  local minimum  and  thus  been  unable  to  solve  the  problem.  Both  cases  involved
the  two  hidden  units  version  of  the  problem  and  both  ended  up  in  the  same  local  minimum.
Figure  5  shows  the  weights  for the local  minimum.  In  this case,  the system  correctly responds
to  two  of  the  patterns-namely,  the  patterns  00  and  10.  In  the cases  of the other  two  patterns
11  and  01,  the  output  unit  gets  a  net  input  of  zero.  This  leads  to  an  output  value  of  0.5  for
both  of  these  patterns.  This  state  was  reached  after  6,587  presentations  of each  pattern  with
q=0.25.2  Although  many  problems  require more  presentations  for learning  to occur,  further  tri-
als  on  this  problem  merely  increase  the  magnitude  of  the  weights  but  do  not  lead  to  any
improvement  in  performance.  We  do  not  know  the  frequency  of such  local  minima,  but  our
experience  with  this  and  other  problems  is  that  they  are  quite  rare.  We  have  found  only  one
other situation  in  which  a  local  minimum  has occurred  in  many  hundreds  of problems  of vari-
ous sorts.  We will discuss  this  case below.

The  XOR  problem  has  proved  a  useful  test  case  for  a number  of  other  studies.  Using  the
architecture  illustrated  in  Figure  4,  a  student  in  our  laboratory,  Yves  Chauvin,  has  studied  the
effect  of varying  the  number of  hidden  units and  varying  the learning  rate  on  time  to  solve  the
problem.  Using  as  a  learning criterion  an error of 0.01  per pattern,  Yves found  that the average

FIGURE  4.  A  simple  architecture for  solving  XOR  with  two  hidden  units  and  no  direct  connections  from  input  to
output.

2  if  we  set  vi 

0.5  or  above,  the  system  escapes  this minimum.  In  general,  however,  the  best  way  to  avoid  local

minima is  probably to use  very  small  values  of  I1.

&XI.

12 

RUMELHART.  HMNTON,  and  WILLIAMS

---.

4

8

/

-4.5 

5.3

2.0 

-.1

-2.0 

8

1  4.3 

9.2

FIGURE  5.  A  network  at  a  local  minimum  for the  exclusive-or  problem.  The dated  lines  indicate negative  weights.
Note  that  whenever  the right-most  input  unit  is  on  it  turns on  both bidden  units.  The  weights  connecting  the  bidden
units  to  the  output  are  arranged  so  that when  both  hidden  units  are  on.  the  output  unit  gets  a  net  input  of  zero.
This leads  to  an  output value  of 0.5.  In the other cases  the network  provides  the correct  answer.

number  of presentations  to  solve  the problem  with  -q =  0.25 varied  from about  245 for the  case
with  two  hidden  units  to  about  12D  presentations  for 32  hidden  units.  The  results can  be  sum-
marized  by  P  =  280  - 331og 2H,  where  P  is  the  required  number  of  presentations  and  H  is  the
number  of hidden  units  employed.  Thus,  the  time  to  solve  XOR  is  reduced  linearly  with  the
logarithm  of  the number  of  hidden  units.  This result  holds  for values  of H  up  to about  40  in
the  case  of  XOR.  The  general  result  that  the  time  to  solution  is  reduced  by  increasing  the
number  of bidden  units has  been observed  in  virtually all of  our simulations.  Yves  also studied
the time  to solution  as  a  function  of learning rate  for  the case  of eight  hidden  units.  He  found
an  average  of  about  450  presentations  with  il  = 0.1  to  about  68  presentations  with  71  = 0.75.
He  also  found  that  learning  rates  larger  than  this  led  to  unstable  behavior.  However,  within
this  range  larger  learning  rates  speeded  the learning  substantially.  In  most  of our problems  we
have employed  learning rates of -q =  0.25 or smaller  and  have had  no  difficulty.

Parity

One  of  the problems  given  a good  deal  of discussion  by Minsky  and  Papert  (1969)  is the  par-
ity  problem,  in  which  the output  required  is  1 if  the  input  pattern  contains  an  odd  number  of
Is  and  0  otherwise.  This  is  a very  difficult  problem  because  the  most  similar  patterns  (those
which  differ  by  a  single  bit)  require  different  answers.  The  XOR  problem  is  a  parity problem
with  input  patterns  of  size  two.  We  have  tried  a  number  of  parity  problems  with  patterns
ranging  from  size  two  to  eight.  Generally  we  have  employed  layered  networks  in  which  direct
connections  from  the  input  to  the  output  units  are  not  allowed,  but  must  be  mediated
through  a  set  of hidden  units.  In  this  architecture,  it  requires  at  least  N  hidden  units to  solve
parity  with  patterns  of  length  N.  Figure  6  illustrates  the  basic  paradigm  for  the  solutions

*. 

%P

LEARNIG 

MIRENAL  REPRESENT AMNOS 

13

-.5  .

.5 

-. 5 

.-

~cally, 

~units 

FIGURE  6.  A  paradigm  for  the solutions  to the  parity problem  discovered  by  the tearming  system.  See  tent  for cz-
planation.

discovered  by  the  system.  The  solid  lines  in  the  figure  indicate  weights  of  +1  and  the  dotted
lines  indicate  weights  of  -1. Ile numbers in  the circles  represent  the biases  of the  units.  Basi-
the  hidden  units  arranged  themselves  so  that  they  count  the  number  of  inputs.  In  the
diagram,  the one  at  the far left  comes  on  if one  or more input  units are  on,  the next  comes  on
if  two  or  more  are  on,  etc.  All  of  the  hidden  units  come  on  if  all  of  the  input  lines  arc on.
Ile  first  m  hidden  units  come  on  whenever  nt bits  are on  in  the  input pattern.  Ile  hidden
units  then  connect  with  alternately  positive  an~d  negative  weights.  In  this  way  the  net  input
from  the  hidden  units  is  zero  for  even  numbers  and  +1  for  odd  numbers.  Table  3  shows  the
actual  solution  attained  for  one  of  our  simulations  with  four  input  lines  and  four  hidden
units.  This  solution  was  reached  after 2,825  preentations  of each  of  the  sixteen  patterns with
q=  0.5.  Note  that  the  solution  is  roughly  a  mirror  image  of that  shown  in  Figure 6  in  that
the  number  of hidden  units turned  on  is  equal  to  the number  of zero  input  values  rather than
the  number of  ones.  Beyond  that  the  principle  is  that  shown  above.  It  should  be  noted  that
the internal  representation  created  by  the learning  rule  is  to  arrange that the  number of hidden
units  that come  on  is  equal  to  the number of  zeros  in  the  input  and  that the particular hidden
that  come  on  depend  only  on  the  number,  not  on  which  input  units  are  on.  This  is
exactly  the  sort  of  recoding  required  by  parity.  It  is  not  the  kind  of  representation  readily
discovered  by  unsupervised  tearming schemes  such  as competitive  learning.

TABLE  3

Input  Units 

Patterns 

Value

0 

1 
2 
3 
4 

-. 

.. 

1011 
1010 
OD010 
0000 

-. 

0

1
0
1
0

14 

RUMELHART.  HINTON,  sad  WILLIAMS

log  2 Hidden  Units

) 

•  a  •N 

Input Units

FIGURE  7.  A  network  for solving  the encoder  problem.  In this problem there  axe  N  orthogonal  input patterns each

paired with  one  of N  orthogonal  output patterns.  There are  only  IogN"2  hidden  units.  Thus.  if the  hidden units take
on  binary values,  the hidden  units  must  form  a binary  number  to  encode  each  of  the input  patterns.  This  is  exactly
what  the  system  learns to  do.

The  Encoding  Problem

Ackley,  Hinton,  and  Sejnowski  (1985)  have  posed  a  problem  in  which  a  set  of  orthogonal
input  patterns  are  mapped  to  a set  of orthogonal  output  patterns through  a small  set  of hidden
units.  In  such  cases  the  internal  representations  of the  patterns  on  the  hidden  units  must  be
rather  efficient.  Suppose  that  we  attempt  to  map  N  input  patterns  onto  N  output  patterns.
Suppose  further that  log2N  hidden  units  are provided. 
In  this case,  we  expect  that  the system
will  learn  to  use  the hidden  units  to  form  a  binary code with  a distinct  binary pattern  for  each
of  the  N  input  patterns.  Figure  7 illustrates  the  basic  architecture  for  the  encoder  problem.
Essentially,  the  problem  is  to  learn  an  encoding  of  an  N  bit  pattern  into  a  log9N  bit  pattern
and  then  learn  to  decode  this  representation  into  the  output  pattern.  We  have  presented  the
system  with  a  number  of  these  problems.  Here  we  present  a  problem  with  eight  input  pat-
terns,  eight  output  patterns,  and  three  hidden  units.  In  this case  the required  mapping  is  the
identity mapping  illustrated  in  Table  4.  The  problem  is simply  to  turn  on  the same  bit  in  the
output  as  in  the  input.  Table  5 shows  the  mapping  generated  by  our  learning  system  on  this
example.  It  is  of  some  interest  that  the system  employed  its  ability  to  use  intermediate  values
in  solving  this  problem.  It  could,  of  course,  have  found  a  solution  in  which  the  hidden  units

Q-"m

TABLE  4

Input Patterns 

Output Patterns

01O000O0 
00100000 
o00000 
00001000 
0000D100 
O0O010 
000001 

-

-
-
-

-
-

020000
O0100000
00010000
0000100
O00010
00000010
00000001

LEARNWD4  OJ'RNA. 

PACMESE1? AfONS 

,

TABLE  S

Hidden  Unit 

Patterns 

.5 
0 
I  1 
I 
0 
.5 
1 
0 

0 
1 

0 
0 
0 
1 
I 
1  1 
0 
1 
0 
.S 
0 
.5 

Input 

Patterns 

1O0000"0 
01000W0 
0010000 
00010000 
0ooloo0 
00000100 
O00000 
00000001 

-
-
-
-

-
-
-

Output
Patterns

10000000
01000000
001000
00010000
ooo10oo
00000100
00000010
00000001

-
-

-

-
-. 

took  on  only  the  values  of  zero  and  one.  Often  it  does  just  that,  but  in  this  instance,  and
many others,  there  are  solutions that  use  the intermediate  values,  and  the learning system  finds
them  even  though  it  has  a  bias  toward  extreme  values.  It  is  possible  to  set  up problems  that
require the  system  to  make  use  of  intermediate  values  in  order  to  solve  a  problem.  We  now
turn  to such  a case.

Table  6 shows  a  very simple problem  in  which we  have  to convert  from  a  distributed represen-
tation over two  units  into  a  local representation over  four units.  The  similarity  structure  of  the
distributed  input  patterns is simply not  preserved  in  the  local  output  representation.

We  presented  this  problem  to our learning  system  with  a  number  of constraints which  made
it  especially  difficult.  The  two  input  units  were  only  allowed  to  connect  to  a  single  hidden
unit  which,  in  turn,  was allowed  to connect  to four  more hidden  units. Only these  four hidden
units  were  allowed  to  connect  to  the four  output  units.  To  solve  this  problem,  then,  the sys-
tem  must  first  convert  the  distributed  representation  of  the  input  patterns  into  various  inter-
mediate  values  of the  singleton  hidden  unit  in  which  different  activation  values  correspond  to
the  different  input  patterns.  These  continuous  values  must  then  be converted  back  through
the  next  layer  of  hidden  units-first  to  another  distributed  representation  and  then,  finally,  to
a  local  representation.  This  problem  was  presented  to  the  system  and  it  reached  a  solution
after  5,226  presentations  with  -n =  0.05. 3 Table  7  shows  the  sequence  of  representations  the

TABLE  6

Input  Patterns 

Output Patterns

00 
01 
10 
11 

-

1000
0100
OD010
0001

TABLE  7

Input 
Patterns 

Singietoo 

Hidden  Unit 

Remaining 

Hidden  Units 

Output
Patterns

10 
11 
00 
01 

-

0 
.2 
.6 
1 

-
-

1  0  -

1 

1 
1  00 
.5  0  0 
0 

.3- 

0  0  1-. 

0010
0001
1000
0100

3 Relatively small  learning  rates  make  units employing intermediate  values  easier to  obtain.

16 

RUMELLART,  HX[DMN.  and  WILLIAMS

system  actually  developed  in  order to  transform  the patterns  and  solve  the problem.  Note each
of  the  four  input  patterns  was  mapped  onto  a  particular  activation  value  of the  singleton  hid-
den  unit.  These  values  were  then  mapped  onto distributed  patterns  at  the next  layer  of hidden
units  which  were  finally  mapped  into  the  required  local  representation  at  the output  level. 
In
principle,  this  trick  of  mapping  patterns  into  activation  values  and  then  converting  those
activation  values  back  into patterns  could  be  done  for  any number  of patterns,  but  it  becomes
increasingly  difficult  for  the  system  to  make  the  necessary  distinctions  as  ever  smaller
differences  among  activation  values  must  be distinguished.  Figure  8  shows the  network  the sys-
tem  developed  to  do  this  job.  The  connection  weights  from  the  hidden  units  to  the  output
units  have  been  suppressed  for  clarity.  (The  sign  of  the  connection,  however,  is  indicated  by
the  form  of  the  connection-e.g.,  dashed 
lines  mean  inhibitory  connections).  The  four
different  activation  values  were  generated  by  having  relatively  large  weights  of  opposite  sign.
One  input  line  turns  the  hidden  unit  full  on,  one  turns  it  full  off.  The  two  differ  by  a  rela-
tively  small  amount  so  that  when  both  turn  on,  the unit  attains  a  value  intermediate  between  0
and  0.5.  When  neither  turns  on,  the  near  zero  bias  causes  the  unit  to  attain  a  value  slightly
over  0.5.  The  connections  to  the  second  layer  of  hidden  units  is  likewise  interesting.  When
the  hidden  unit  is  full  on,  the  right-most  of  these  hidden  units  is  turned  on  and  all  others
turned  off.  When  the  hidden  unit  is  turned  off,  the  other  three  of these  hidden  units are  on
and  the left-most  unit  off.  The  other  connections  from  the singleton  hidden  unit  to  the  other
hidden  units  are  graded  so  that  a  distinct  pattern  is  turned  on  for  its other  two  values.  Here
we have  an  example  of the flexibility  of  the learning system.

Our  experience  is  that  there  is  a  propensity  for  the  hidden  units  to  take  on  extreme  values,
but,  whenever  the  learning  problem  calls  for  it,  they  can  learn  to  take  on  graded  values.  It  is
likely  that  the  propensity  to  take  on  extreme  values  follows  from  the  fact  that  the  logistic  is  a
sigmoid  so  that  increasing  magnitudes  of  its  inputs  push  it  toward  zero  or one.  This  means
that  in  a  problem  in  which  intermediate  values  are  required,  the incoming  weights must  remain
of  moderate  size.  It  is  interesting  that  the  derivation  of  the  generalized  delta  rule  does  not
depend  on  all  of  the units having  identical  activation  functions.  Thus,  it would  be  possible  for
some  units,  those  required  to  encode  information  in  a  graded  fashion,  to be  linear while  others
might  be  logistic.  The  linear  unit  would  have  a  much  wider  dynamic  range  and  could  encode
more  different  values.  This  would  be  a  useful  role  for  a  linear  unit  in  a  network  with  hidden
units.

+3 

4Units

Output

Ile , 

\

+2 

+2 

+ 

.

Hidden
Units

~ ~  6 

+9

-/ 

+4

Ax 

Input
Units

FIGURE  3.  11c  network  illustrating  the  use  of  intermediate  values  in  solving  a  problem.  See  text  for  explanation.

LEARNDA1G  D4'IIRNAL  EPbIBSENTATXONS 

17

Symmetry

Another  interesting  problem  we  studied  is  that  of classifying  input  strings  as  to  whether  or
not  they  are symmetric  about  their  center.  We  used  patterns  of  various  lengths  with  various
numbers  of  hidden  units.  To  our  surprise,  we  discovered  that  the  problem  can  always  be
solved  with  only  two  hidden  units.  To  understand  the  derived  representation,  consider  one of
the  solutions  generated  by  our  system  for  strings  of  length  six.  This  solution  was  arrived  at
after  1,208  presentations  of  each  six-bit  pattern  with  -q =  0.1.  The  final  network  is  shown  in
Figure  9.  For  simplicity  we  have  shown  the  six  input  units  in  the  center  of  the  diagram  with
one  hidden  unit  above  and  one  below.  The  output  unit,  which  signals  whether  or  not  the
string  is symmetric  about  its center,  is shown  at  the far right.  The  key  point  to see  about  this
solution  is  that  for  a  given  hidden  unit,  weights  that  are  symmetric  about  the  middle are  equal
in  magnitude  and  opposite  in  sign.  That  means  that  if a  symmetric  pattern  is  on,  both  hidden
units  will  receive  a  net  input  of  zero  from  the  input  units,  and,  since the  hidden  units have  a
negative  bias,  both  will  be off.  In  this case,  the output  unit,  having  a  positive bias, will  be on.
The  next  most  important  thing  to note  about  the  solution  is  that  the  weights  on  each  side of
the  midpoint  of the  string are  in  the  ratio of  1:2.4.  This  insures that  each  of the eight  patterns
that  can  occur on  each  side  of the  midpoint  sends  a  unique  activation  sum  to  the hidden  unit.
This  assures  that  there  is  no  pattern  on  the  left  that  will  exactly  balance  a  non-mirror-image
pattern  on  the  right.  Finally,  the  two  hidden  units have  identical  patterns  of weights  from  the
input  units  except  for  sign.  This  insures  that  for  every  nonsymmetric  pattern,  at  least  one  of
the two hidden  units  will come  on  and  turn  on the output  unit.  To  summarize,  the network  is
arranged  so  that  both  hidden  units  will  receive  exactly  zero  activation  from  the  input  units
when  the  pattern  is  symmetric,  and  at  least  one  of  them  will  receive  positive  input  for  every
nonsymmetric  pattern.

' Hidden  Unit

-3.18 

+ 6a2 

-1236/ 

+12.56  \.623 

+3.17 

N-

Output

6 

3\ 

I 

/ 

/

l, 

10 

-9.4

.

Hidden  Unit

FIGURE  9.  Network  for solving the  symmetry  problem.  The  six  open  circles  represent  the  input  units.  There  are
two  hidden  units,  one  shown  above  and  one  below  the input  units.  The  output  unit  is shown  to the  far  left.  See
text  for explanation.

18 

RUMELHART.  HiDroN,  and  WMLLA.MS

This  problem  was  interesting  to  us  because  the  learning  system  developed  a  much  more
elegant  solution  to  the problem  than  we had  previously  considered.  This  problem  was  not  the
only  one  in  which  this  happened.  The  parity  solution  discovered  by  the  learning  procedure
was  also  one  that  we  had  not  "'scovered prior  to  testing  the  problem  with  our  learning  pro-
cedure.  Indeed,  we  frequently  discover  these  more  elegant  solutions  by  giving  the  system  more
hidden  units  than  it  needs  and  observing  that it  does  not  make  use  of some  of those  provided.
Some  analysis  of  the  actual  solutions  discovered  often  leads  us  to  the  discovery  of  a  better
solution  involving  fewer  hidden  units.

Addition

Another  interesting  problem  on  which  we  have  tested  our  learning  algorithm  is  the  simple
binary  addition  problem.  This  problem  is  intcresting  because  there  is  a  very  elegant  solution  to
it,  because  it  is  the  one  problem  we  have  found  where  we  can  reliably  find  local  minima  and
because  the  way  of  avoiding  these  local  minima  gives  us  some  insight  into  the  conditions  under
which  local  minima  may  be  found  and  avoided.  Figure  10  illustrates  the  basic  problem  and  a
minimal  solution  to  it.  There  are  four  input  units,  three  output  units,  and  two  hidden  units.
The  output  patterns  can  be  viewed  as  the  binary  representation  of  the  sum  of  two  two-bit
binary  numbers  represented  by  the  input  patterns.  The  second  and  fourth  input  units  in  the
correspond  to  the  low-order  bits  of  the  two  binary  numbers  and  the  first  and  third
units  correspond  to  the  two  higher  order  bits.  The  hidden  units  correspond  to  the  carry bits

* Odiagram 

Output  Units

.

"\\-2 

Hidden

Units

Input  Units

FIGURE  10.  Minimal  network  for  adding  two  two-bit  binary  numbers.  There  are  four  input  units,  three  output
units, and  two  hidden  units.  The  output  patterns  can be  viewed  as the  binary  representation  of  the  sum  of two  two-
bit  binary  numbers  represented  by  the  input patterns.  The  second  and  fourth  input  units  in  the  diagram  correspond
to  the  low-order  bits  of  the  two  binary  numbers,  and  the  firm  and  third  units  correspond  to  the  two  higher  order
bits.  The  hidden  units  correspond  to  the  carry  bits  in  the  summation.  The  hidden  unit  on  the  far  right  comes  on
when  both  of  the  lower  order  bits in  the  input  pattern  are  turned  on.  and  the  one on  the  left  comes on  when  both
higher  order  bits  are  turned  on  or  when  one  of  the  higher  order  bits  and  the  other  hidden  unit  is  turned  on.  The
weights  on  all  lines  are  assumed  to  be  +1  except  where  noted.  Negative  connections  are  indicated  by  dashed  lhoes.
As  usual,  the biases  are indicated  by the  numbers in  the circles.

wegt*nalfie 

r 

s1e 

t 

e+ 

et 

hr 

oe.Ngaie€netou 

r 

niae 

b 

ahdfns

*  -third 

LEARNl'  W'IEMRNAk  kVLPk .sVNtA  'lNOS  19

in  the  summation.  Thus  the  hidden  unit  on  the  far  right  comes  on  when  both  of  the  lower
order  bits  in  the  input  pattern  are  turned  on,  and  the  one  on  the  left  comes  on  when  both
higher  order  bits  are  turned  on  or when  one  of  the higher order bits  and  the other hidden  unit
is  turned  on. 
In  the  diagram,  the  weights  on  all  lines  are  assumed  to  be  +1  except  where
noted.  Inhibitory connections  are  indicated  by  dashed  lines.  As  usual,  the biases  are  indicated
by  the  numbers  in  the circles.  To understand  how  this network  works, it  is  useful  to note  that
the  lowest  order  output  bit  is  determined  by  an  exclusive-or  among  the  two  low-order  input
bits.  One  way  to  solve  this XOR  problem  is  to  have  a  hidden  unit  come  on  when  both  low-
order  input  bits  are  on  and  then  have  it  inhibit  the  output  unit.  Otherwise  either  of  the low-
order  input  units  can  turn  on  the  low-order  output  bit.  The  middle  bit  is  somewhat  more
difficult.  Note  that  the  middle  bit  should  come  on  whenever  an  odd  number  of  the  set  con-
taining the  two  higher  order  input  bits  and  the lower order  carry  bit  is  turned  on.  Observation
will  confirm  that  the  network  shown  performs  that  task.  The  left-most  hidden  unit  receives
inputs  from  the  two  higher  order  bits  and  from  the  carry  bit.  Its bias  is such  that  it  will come
on  whenever  two  or  more  of  its  inputs  are  turned  on.  The  middle  output  unit  receives  positive
inputs  from  the  same  three  units  and  a  negative  input  of  -2  from  the  second  hidden  unit.
This  insures  that  whenever  just  one  of  the  three  are  turned  on,  the  second  hidden  unit  will
remain  off  and  the  output  bit  will  come  on.  Whenever  exactly  two  of  the  three  are  on,  the
hidden  unit  will  turn  on  and  counteract  the  two  units  exciting  the output  bit,  so  it  will  stay
off.  Finally,  when  all  three  are  turned  on,  the  output  bit  will  receive  -2  from its carry  bit  and
+3  from  its other three  inputs.  The  tiet  is  positive,  so  the  middle  unit  will  be  on.  Finally,  the
output  bit  should  turn  on  whenever  the  second  hidden  unit  is  on-that  is,  whenever
there  is  a  carry  from  the  second  bit.  Here  then  we  have  a  minimal  network  to  carry  out  the
job  at  hand.  Moreover,  it  should  be  noted  that  the concept  behind  this  network  is  generaliz-
able  to  an  arbitrary  number  of  input  and  output  bits.  In  general,  for adding  two  m  bit  binary
numbers we  will  require  2m  input  units,  m  hidden  units,  and  m +1 output  units.

Unfortunately,  this  is  the  one  problem  we  have  found  that  reliably  leads  the  system  into
local  minima.  At  the  start  in  our  learning  trials  on  this  problem  we  allow  any  input  unit  to
connect  to  any  output  unit  and  to  any  hidden  unit.  We  allow  any  hidden  unit  to  connect  to
any  output  unit,  and  we  allow  one  of  the  hidden  units  to  connect  to  the  other  hidden  unit,
but,  since  we  cart  have  no  loops,  the connection  in  the  opposite  direction  is  disallowed.  Some-
times  the  system  will  discover  essentially  the  same  network  shown  in  the  figure.  Often,  how-
ever,  the  system  ends  up  in  a  local  minimum.  The  problem  arises  when  the  XOR  problem  on
the  low-order  bits  is  not  solved  in  the  way  shown  in  the diagram.  One  way  it  can  fail  is  when
the "higher"  of  the two  hidden  units  is  "selected"  to  solve  the  XOR  problem.  This is  a  problem
because  then  the  other  hidden  unit  cannot  "see"  the  carry  bit  and  therefore  cannot  finally  solve
the problem.  This  problem  seems  to stem  from  the  fact  that  the  learning  of the second  output
bit  is  always  dependent  on  learning  the  first  (because  information  about  the carry  is  necessary
to  learn  the  second  bit)  and  therefore  lags  behind  the  learning  of  the  first  bit  and  has  no
influence  on  the  selection  of  a  hidden  unit  to  solve  the  first  XOR  problem.  Thus,  about  half
of  the  time  (in  this  problem)  the  wrong  unit  is  chosen  and  the  problem  cannot  be  solved.  In
this  case,  the system  finds  a  solution  for  all  of the  sums  except  the  11+11  -
110  (3+3  = 6)  case
in  which  it  misses  the  carry  into  the  middle  bit  and  gets  11+11  -
100  instead.  This  problem
differs  from  others  we  have  solved  in  as  much  as  the hidden  units  arc  not  "equipotential" here.
In  most  of  our  other  problems  the  hidden  units  have  been  equipotential,  and  this problem  has
not  arisen.

It  should  be  noted,  however,  that  there  is  a  relatively  simple  way  out  of  the  problem-

namely,  add  some  extra  hidden  units.  In  this  case  we  can  afford  to  make  a  mistake  on  one or
more  selections  and  the system  can  still solve  the  problems.  For the problem  of adding two-bit

4 The  network  is the  same  except  for  the  highet  order  bit.  The  highest  order  bit  is  always on  whenever  three or
more  of  the  input  units  are  on.  This  is  always  learned  first  and  always  learned  with  direct  connections  to the  input
units.

t/

-

-

,4.-

-, 

"EHidden 

' 0 -

%Input 

,  "FIGURE 

4

20 

RUMELHART,  HDITON,  and  WILLIAMs

numbers  we  have  found  that  the  system  always  solves  the problem  with  one extra  hidden  unit.
With  larger  numbers  it  may  require  two  or three  more.  For  purposes  of  illustration,  we  show
the  results  of  one  of our runs  with  three  rather than  the  minimum  two  hidden  units.  Figure  11
shows  the  state  reached  by  the  network  after  3,020  presentations  of  each  input  pattern  and
with  a  learning  rate  of  71 = 0.5.  For convenience,  we  show  the  network  in  four  parts.  In  Fig-
ure  11A  we  show  the connections  to  and  among  the  hidden  units.  This  figure  shows  the  inter-
nal  representation  generated  for  this  problem.  The  "lowest'  hidden  unit  turns  off  whenever
either  of  the  low-order  bits  are  on.  In  other  words  it  detects  the  case  in  which  no  low-order
bit  is  turn  on.  The  'highest'  hidden  unit  is  arranged  so  that  it  comes  on  whenever  the  sum  is
less  than  two.  The  conditions  under  which  the  middle  hidden  unit  comes  on  are  more  com-
plex.  Table  8  shows  the patterns of hidden  units  which  occur  to  each  of the  sixteen  input  pat-
terns.  Figure  1IB  shows  the  connections  to  the  lowest  order  output  unit.  Noting  that  the
relevant  hidden  unit  comes on  when  neither  low-order  input  unit  is  on,  it  is  clear  how  the sys-
tem  computes  XOR.  When  both  low-order inputs  are  off,  the output  unit  is  turned  off  by  the

A 

, , 

Output  Units 
o.o,.
00000

B

Output  Units

009

I--.Units 

x ,(  .

y 

..x \5 

4

//

Input  Units 

Output  Units 

.7

,  ,0 

Hidden
Hidden'
U n i t s

Input  Units

Output  Units

,14 

Units 

0nUnits

Hidden 

\ 

4 
+ 

Hidden

Unit

+S+ 

6-2 

Units 

2 

+2\ddbb

Input  Units

11.  Network  found  for  the  mmmation  problem.  A:  The  connections  from  the  input  units  to  the  three
hidde  units  and  the connections  among  the hidden  units.  f:  The  connections  from  the  input  and  hidden  units  to
the  lowest order  output  unit.  C:  The  connections  from  the  input  and  hidden  units  to  the  middle  output  unit.  D:
The  connections  from  the input and  hidden  units  to the highest  order output  unit.

' "%,3' 

,''.',  "I".",".,  ,.'. 

L 

g ' 

-." , ""''%.,"  ,-'%''" ' . -.-''''''''''''',  '_',.">-,"'"''''''.-

-

-

LEARNIWP  (MkNhA~L  Rt , 

!bBSI ^I ONS 

L

TABLE  8

Input 
Patterns 

Ifidden  Unit 

Patterns 

Output
Patterns

+ 

.
-

-

00 +  O0 
00+01 
00+  10 
00+  11 
01  +00 
01  +01 
01 +10 
01  + 11 
0  + ODIi 
10+01 
10+  10 
-
10+  11  -
11  + O0 
-
11  +01 
11  +10 
11 + 1I 

II 
110 
011 
010 
110 
010 
010 
000 

011 
001 
000 
010 
000 
000 
000 

-
-

-
-
-

-
-
010 

-
-
-
-

-

000
001
010
011
001
010
011
100
01
01Oi
100
101
011
100
101
110

hidden  unit.  When  both  low-order  input  units are  on,  the output  is  turned  off  directly  by  the
input  units.  If  just  one  is  on,  the  positive  bias  on  the  output  unit  keeps  it  on.  Figure
lIC gives  the  connections  to  the middle  output  unit,  and  in  Figure  IID  we  show  those  connec-
tions  to  the  left-most,  highest  order  output  unit.  It  is  somewhat  difficult  to  see  how  these
connections  always  lead  to  the  correct  output  answer,  but,  as  can  be  verified  from  the  figures,
the network  is  balanced  so  that  this works.

It  should  be  pointed  out  that  most  of  the problems  described  thus  far  have  involved  hidden
units  with  quite  simple  interpretations.  It  is much  more  often  the  case,  especially  when  the
number  of  hiddcn  units  exceeds  the  minimum  number  required  for  the  task,  that  the hidden
units  are  not  readily  interpreted.  This  follows  from  the  fact  that  there  is  very  little  tendency
for  localist representations  to  develop.  Typically  the  internal  representations  are  distributed
and  it  is  the pattern of  activity  over  the  hidden  units,  not  the  meaning  of  any  particular  hidden
unit  tha  is  important.

The  Negation  Problem

Consider  a  situation  in  -which  the  input  to  a  system  consists  of  patterns  of n  +1  binary values
and  an  output  of  n  values.  Suppose  further  that  the  general  rule  is  that  n  of  the  input  units
should  be  mapped  directly  to  the  output  patterns.  One  of  the  input  bits,  however,  is  special.
It  is  a  negation  bit.  When  that  bit  is  off,  the  rest  of  the  pattern  is  supposed  to  map  straight
through,  but  when  it  is  on,  the  complement  of  the  pattern  is  to  be  mapped  to  the  output.
Table  9 shows  the  appropriate  mapping.  In  this  case  the  left  element  of  the  input  pattern  is
the  negation  bit,  but  the  system  has  no  way  of  knowing  this  and  must  learn  which  bit  is  the
negation  bit. 
In  this  case,  weights  were  allowed  from  any  input  unit  to  any  hidden  or output
unit  and  from  any  hidden  unit  to  any  output  unit.  The system  learned  to set  all  of the weights
to  zero  except  those  shown  in  Figure  12.  The  basic  structure  of the  problem  and  of the  solu-
tion  is  evident  in  the  figure.  Clearly  the  problem  was  reduced  to  a  set  of three  XORs  between
the  negation  bit  and  each  input.  In  the case  of the  two  right-most  input  units,  the  XOR prob-
lems  were  solved  by  recruiting  a  hidden  unit  to  detect  the  case  in  which  neither the  negation
unit  nor  the  corresponding  input  unit  was  on. 
In  the  third  case,  the  hidden  unit  detects  the
case  in  which  both the negation  unit  and  relevant  input  were  on.  In  this  case  the  problem  was
solved  in  less  than  5.000  passes  through  the stimulus  set  with 

=  0.25.

" "1 

'- 

* @two 

... 

,1% .,..  ..  ,  ,-e  ", 

.
,  <, ,. .2  c.r . "  ,  ".,.

,  ,  ,,,.,  . ,  ", 

,  +  ,, 

-. 

.
.

. ., . ,. x .r  .,,,  ..  + 

'- 

.

.

.

.

.

- '' ' '',

22 

RUMELHART. KinNo,  and  WULIAMS

TABLE 9

Input Patterns 

Output Patterns

-
-
-
-
-

-

-

-. 

-

-

-

000 
0010 
0011 
0100 
0101 
0110 
0111 
1000 
1001 
1010 
1011 
1100 
1101 
1110 
1111 

001
010
Oil
100
101
110
111
111
110
101
100
i 011
010
001
000

0 

The T-C  Problem

Most  of  the  problems  discussed  so  far  (except  the  symmetry  problem)  are  rather  abstract
mathematical  problems.  We  now  turn  to  a  more  geometric  problem-that  of  discriminating
between  a  T  and  a  C-independent  of translation  and  rotation.  Figure  13  shows  the  stimulus
patterns  used  in  these  experiments.  Note,  these  patterns  are  each  made  of  five  squares  and
differ from  one  another  by  a  single  square.  Moreover,  as  Minsky  and  Papert  (1969)  point  out,
when  considering  the  set  of  patterns  over  all  possible  translations  and  rotations  (of  90",  180",
and  270*),  the  patterns  do  not  differ  in  the  set  of  distances  among  their  pairs  of squares.  To
see  a  difference  between  the  sets  of  patterns  one  must  look,  at  least,  at  configurations  of  tri-

.1 

.4 

+4 

+

.

./  I 

t'- 

.41

+4 

I

/  -

+

6.I. 

Io

FIGURE  12.  The  solution  discovered  for  the negation  problan.  le rigbt-most  unit is the negation  unit.  The  prob-
lem has been  reduced  and solved  as three  exclusive-on  between  the negation  unit  and each  of  the other three units.

..t''N?

LEARNDCG  NTERNAL  REPRESENTATIONS 

23

('I

)number 

FIGURE  13.  The stimulus  set  for  the  T-C  problem.  The  set  consists  of  a  block  T  and  a  block  C  in  each  of  four
orientations.  One  of  the eight  patterns is presented on  each  trial.

plets  of  squares.  Thus  Minsky  and  Pattern  call  this  a  problem  of  order  three. 5 In  order  to
facilitate  the  learning,  a  rather different  architecture  was employed  for  this problem.  Figure  14
shows  the  basic  structure  of  the  network  we  employed.  Input  patterns  were  now  conceptual-
ized  as  two-dimensional  patterns  superimposed  on  a  rectangular  grid.  Rather  than  allowing
each  input  unit  to  connect  to  each  hidden  unit,  the  hidden  units  themselves  were  organized
into  a  two-dimensional  grid  with  each  unit  receiving  input  from  a  square  3x3  region  of  the
input  space. 
In  this  sense,  the  overlapping  square  regions  constitute  the  predefined  receptive
field  of  the  hidden  units.  Each  of  the hidden  units,  over  the  entire  field,  feeds  into  a  single
output  unit  which  is  to  take  on  the value  1 if  the input  is  a T  (at  any  location  or orientation)
and  0 if  the  input  is  a  C.  Further,  in  order  that  the learning  that  occurred  be  independent  of
where  on  the  field  the  pattern  appeared,  we  constrained  all  of  the  units  to  earn  exactly  the
same  pattern  of  weights.  In  this  way  each  unit  was  constrained  to  compute  exactly  the  same
function  over  its  receptive  field-the  receptive  fields  were  constrained  to  all  have  the  same
shape.  This  guarantees  translation  independence  and  avoids  any  possible  'edge  effects'  in  the
learning.  The  learning  can  readily  be  extended  to  arbitrarily  large  fields  of  input  units.  This
constraint  was  accomplished  by simply  adding  together  the weight  changes dictated  by  the delta
rule  for  each  unit  and  then  changing  all  weights  exactly  the  same  amount. 
In  this  way,  the
whole  field  of  hiddcn  units  consists  simply  of replications  of  a  single  feature  detector  centered
on  different  regions  of the  input  space,  and  the learning  that  occurs  in one  part  of  the field  is
automatically  generalized  to  the rcst  of  the field. 6

We  have  run  this  problem  in  this  way  a  number  of  times.  As  a  result,  we  have  found  a
of  solutions.  Perhaps  the  simplest  way  to  understand  the  system  is  by  looking  at  the
form  of  the  receptive  field  for  the hidden  units.  Figure  15  shows several  of  the receptive  fields
we  have  seen. 7  Figure  15A  shows  the  most  local  representation  developed.  This  on-center-off-

'Terry  Sejoowski  pointed  out  to  us  that  the T-C  problem  was  difficult  for models  of  this  sort to  learn  and there-

fore  worthy  of  study.

S6 

A  similar  procedure  hu been  employed  by  Fukushima  (1980)  in  his  naoogitrom and  by  Kienker.  Sejnowski.  lio-

ton.  and  Schumacher  (1965).

7 The  ratios of  the weights  are  about  right.  The  actual  values  can  be  larger or  smaller  than  the values  given  in  the

figure.

.~~ 

~ 

~ 
~** 

--

%- 

-. 

N-4*~.. 

24 

RLUMELHART.  INUTON,  add  WILLIAMS

Output
Unit

Units

Units

0Hidden
0 

o 
03 0 

O 

0 

DO

O 

0 

0 

1

I 

aInput

FIGURE  14.  The  network  for solving  Che  T-C  problem.  Sac tet  for explanation.

surround detector  turns out  to  be  an  excellent  T detector.  Since,  as  illustrated,  a  T  can  extend
into  the on-center  and  achieve  a  net  input  of  +1, this detector  will be  turned  on  for a T  at  any
orientation.  On  the  other hand,  any C  extending  into  the center  must cover  at  least  two  inhibi-
tory cells.  With  this  detector  the bias  can  be  set  so  that only  one  of the whole  field  of inhibi-
tory units  will  come  on  whenever  a  T  is  presented  and  none  of the  hidden  units  will  be  turned
on  by  any  C.  This  is  a  kind  of protrusion detector  which  differentiates  between  a  T  and  C  by
detecting the  protrusion  of  the T.

The  receptive  field  shown  in  Figure  15B  is  again  a  kind  of T  detector.  Every  T  activates one
of the  hidden  units by  an  amount  +2  and  none of the hidden  units receives  more  than  +1 from
any  of  the  C's.  As  shown  in  the  figure,  T's  at  90*  and  27(r  send  a  total of  +2  to  the  hidden
units  on  which  the  crossbar  lines  up.  The  T's  at  the  other  two  orientations  receive  +2  from
the  way  it  detects  the  vertical  protrusions  of  those  two  characters.  Figure  15C  shows  a  more
distributed  representation.  As  illustrated  in  the  figure,  each  T  activates  five  different  hidden
units  whereas  each  C  excites  only  three  hidden  units. 
is
differentiating  between  the  characters  on  the basis  of  the protruding  end  of the  T  which  is  not
shared  by  the C.

In  this  case  the  system  again 

Finally,  the  receptive  field  shown  in  Figure  15D  is  even  more  interesting.  In  this  case  every
hidden  unit  has  a  positive  bias  so  that  it  is  on  unless  turned  off.  The  strength  of  the  inhibi-
tory weights  are such  that  if a  character  overlaps  the receptive  field  of a  hidden  unit,  that  unit
turns  off.  The  system  works  because  a  C  is  more  compact  than  a  T  and  therefore  the T  turns
off  more  units  that  the  C.  The  T  turns off 21  hidden  units,  and  the C  turns off  only  20.  This
In  each  case,  the  solution  was  reached  in  from  about
is  a  truly  distributed  representation. 

........ 

A 

LEARNMIG 

TMri.NAL  REPRESENrArIONS 

............. 

......

25

1  2-1 
1 -1  1

B

.......  .......
-1 

1-1

C 

....... 

.......

1 -+2+-1

~-2-2 

D 

-2  -2  -2

-2

-2 

-2  -2

~detector. 

FIGURE  15.  Receptive  fields found  in  different  runs of  the  T-C  problem.  A:  An  on-center-off-surround  receptive
field  for  detecting  T's. 8:  A  vertical  bar  detector  which  responds  to T's  more strongly  than  C's.  C:  A  diagonal  bar
A  T  activates  five  such  detectors  whereas  a  C  activates  only  three  such  detectors.  1):  A  compactness

detector.  This  inhibitory  receptive  field  turns  off whenever  an  input  coven  any region  of  its  receptive  field.  Since
the C  is more  compact  than  the T  it  turns off 20  such  detectors  whereas  the T  turns off 21  of them.

5,000  to  10,000 presentations  of tfie  set  of  eight  patterns.'

It  is  interesting  that  the  inhibitory  type  of receptive  field  shown  in  Figure  15D  was  the  most
common  and  that  there  is  a  predominance  of  inhibitory  connections  in  this and  indeed  all  of
our simulations.  This  can  be  understood  by  considering  the  trajectory  through  which  the  learn-
ing typically  moves.  At  first,  when  the  system  is  presented  with  a  difficult  problem,  the  initial
random  connections  are  as  likely  to  mislead  as  to  give  the  correct  answer. 
In  this  case,  it  is
best  for the output  units  to  take  on  a  value  of  0.5  than  to  take  on  a  more  extreme  value.  This
follows  from  the  form  of  the  error  function  given  in  Equation  2.  The  output  unit  can  achieve
a  constant  output  of  0.5  by  turning  off  those  units  feeding  into  it.  Thus,  the  first  thing  that
happens  in  virtually  every  difficult  problem  is  that  the  hidden  units  are  turned  off.  One  way

I  Since  translation  independence  was  built  into the learning  procedure,  it  makes no  difference  where  the input  oc-
curs;  the same  thing  will  be  learned whcever  the pattern  is  presented.  Thus,  there  are  only eight distinct  patterns  to
be  presented  to the system.

-!- 

.

.

-

-

-- 

-

-

'' 

.

A7

26 

RUMEUIART,  IURTON,  and  WILLIAMS

to  achieve  this  is to  have  the  input  units inhibit  the hidden  units.  As  the system  begins to  sort
things  out  and  to learn  the  appropriate  function  some of the connections  will  typically go  posi-
tive,  but  the majority  of the connections  will  remain  negative.  This  bias for solutions  involving
inhibitory  inputs  can  often  lead  to  nonintuitive  results  in  which  hidden  units  are  often  on
unless  turned  off  by  the  input.

More  Simulation  Results

We  have  offered  a  sample  of  our  results  in  this section. 

In  addition  to  having  studied  our
learning  system  on  the  problems discussed  here,  we  have  employed  back  propagation  for  learn-
ing  to  multiply  binary  digits,  to  play tic-tac-toe,  to distinguish  between  vertical  and  horizontal
lines,  to  perform  sequences  of  actions,  to  recognize  characters,  to  associate  random  vectors,
and  a  host  of  other  applications.  In  all  of  these  applications  we  have  found  that  the general-
izcd  delta  rule  was  capable  of  generating  the kinds  of  internal  representations  required  for the
problems  in  question.  We  have  found  local  minima  to  be  very  rare  and  that  the  system  learns
in  a  reasonable  period  of  time.  Still  more  studies  of  this  type  will  be  required  to  understand
precisely  the conditions  under which  the  system  will  be  plagued  by  local  minima.  Suffice  it  to
say  that  the  problem  has  not  been  serious  to  date.  We  now  turn  to a  pointer to  some  future
developments.

SOME  FURTHER  GENERALIZATIONS

We have  intensively  studied  the learning  characteristics  of the  generalized  delta  rule  on feed-
forward  networks  and  semilinear  activations  functions.  Interestingly  these  are  not  the  most
general  cases  to  which  the  learning  procedure  is  applicable.  As  yet  we  have only  studied  a few
examples  of  the  more  fully  generalized  system,  but  it  is relatively  easy  to apply  the same  learn-
ing  rule  to  sigma-pi  units  and  to  recurrent  networks.  We  will  simply  sketch  the  basic  ideas
here.

The  Generalized  Delta  Rule  and  Sigma-Pi  Units

It  will  be  rccallcd  from Chapter  2 that  in  the case  of sigma-pi  units we  have

0i  ~f J(wit Ioi) 

(17)

where  i  varies  over  the  set  of conjuncts  feeding  into  unit  j  and  k  varies  over the  elements  of
the conjuncts.  For simplicity  of exposition,  we  restrict  ourselves  to  the case  in  which  no  con-
In  this  case  we  can  notate  the  weight  from  the  con-
juncts  involve  more  than  two  elements. 
junction  of  units i  and  j  to  unit  k  by  wiJk.  The  weight  on  the direct  connection  from  unit  i
to unit  j  would,  thus,  be  wj1 , and  since  the relation  is  multiplicative,  wk,  =  wkji.  We can  now

0 

S.,

LEARNCM  WERMAL  KEPESIMATIONS 

27

rewrite  Equation  17  as

We now  set

Taking  the  derivative  and  simplifying,  we  get  a  rule  for sigma-pi  units  strictly  analogous  to  the

rule for semilinear  activation  functions:

AP wii  = 

, 01 o.

We  can  see  the  correct  form  of  the  error signal,  8,  for this case  by  inspecting  Figure  16.  Con-
sider the  appropriate  value  of 81  for unit sh  in  the  figure.  As  before,  the correct  value  of 81  is
given  by  the sum  of the  B's  for all of  the units  into  which  u,  feeds,  weighted  by  the  amount  of
effect  due  to  the activation  of u,  times  the derivative  of  the activation  function.  In  the  case of
semilinear  functions,  the  measure  of  a  unit's  effect  on  another  unit  is  given  simply  by  the
weight  w  connecting  the  first  unit  to  the  second. 
In  this  case,  the  %'s effect  on  uk  depends
not  only on  wtij,  but  also  on  the value  of uj.  Thus,  we have

8, 

f  ',(net, )Y, 8 

,,0

Uk 

U

'".  wk 

.. 

-W'h

U k

Wi 

II

Wj5.g

UU 

IUh

FIGURE  16.  The  generalized  delta  rule for  sigma-pi  units.  The products of  activation  values  of  individual  units  c-
tivate  output units.  See  text  for explanation  of  how  the & values  am computed  in  this can.

28 

RUMELHART,  Hm1TON,  and WILLIAMS

if a, is  not  an  output  unit  and,  as  before,

8, =  f I  (ne,)(1  -o,)

if it  is an  output  unit.

Recurrent  Nets

We  have  thus  far  restricted  ourselves  to feedforward  nets.  This  may  seem  like  a  substantial
restriction,  but  as  Minsky  and  Papert  point  out,  there  is,  for  every  recurrent  network,  a  feed-
forward  network  with  identical  behavior  (over  a  finite  period  of  time).  We  will  now  indicate
how  this  construction  can  proceed  and  thereby  show  the  correct  form  of  the  learning rule  for
the  recurrent  network.  Consider  the  simple  recurrent  network  shown  in  Figure  17A.  The
same  network  in  a  feedforward  architecture 
is  shown  in  Figure  17B.  The  behavior  of  a

B 

U I'M 

W 2

U2

Time

U  2

W2

IN 12 

W2 2 

.

A

I

Ut 

222

FIGURE  17.  A  comparison  of a recurrent  network  and a feedforward  network  with  identical  behavior.  A:  A  com-
pletely  connected  recurrent  network  with  two  units. 8:  A  feedforward  network  which  behaves the  ame  as  the  re-
In  this case.  we  have  a separate  unit  for each  timee  step  and we  require  that  the weights  connecting
current  network. 
each  layer  of  units to the  net be  the same  for all  layers.  Moreover,  they must  be  the same  as  the  analogous  weights
ia  the recurrent  case.

12

LEARN0JC4G  On-'PRiAL  ic.Pkkit 

ATIONS 

29

recurrent  network  can  be  achieved  in  a  feedforward  network  at  the  cost  of  duplicating  the
hardware  many  times  over  for the  feedforward  version  of the  network. 9 We  have  distinct  units
and  distinct  weights  for  each  point  in  time.  For naming  convenience,  we  subscript  each  unit
with  its  unit  number  in  the  corresponding  recurrent  network  and  the  time  it  represents.  As
long  as  we  constrain  the  weights  at  each  level  of  the  feedforward  network  to  be  the  same,  we
have  a  feedforward  network  which  performs  identically  with  the  recurrent  network  of  Figure
17A.  The  appropriate  method  for maintaining  the constraint  that  all  weights  be equal  is  simply
to keep  track  of the changes  dictated  for each  weight  at  each  level  and  then change  each  of the
weights  according  to  the  son of  these  individually  prescribed  changes.  Now,  the  general  rule
for determining  the change  prescribed  for  a  weight  in  the system  for a particular  time  is  simply
to  take  the  product  of  an  appropriate  error  measure  5  and  the  input  along  the  relevant  line
both  for  the  appropriate  times.  Thus,  the  problem  of  specifying  the  correct  learning  rule  for
recurrent  networks  is  simply  one of  determining  the  appropriate  value  of  8  for each  time.  In  a
feedforward  network  we  determine  8  by  multiplying  the  derivative  of the  activation  function
by  the sum  of  the 8's  for  those  units it  feeds  into  weighted  by  the connection  strengths.  The
same  process  works  for  the  recurrent  network-except  in  this  case,  the  value  of 8  associated
with  a  particular  unit  changes  in  time  as  a  unit  passes  error  back,  sometimes  to  itself.  After
each  iteration,  as  error  is  being passed  back  through  the network,  the change  in weight  for that
iteration  must  be  added  to  the  weight  changes  specified  by  the  preceding  iterations  and  the
sum  stored.  This  process  of passing  error  through  the  network  should  continue  for  a  number
of  iterations  equal  to  the  number  of  iterations  through  which  the  activation  was  originally
passed.  At  this point,  the  appropriate  changes to  all  of the  weights  can  be made.

In  general,  the  procedure  for a  recurrent  network  is  that  an  input  (generally  a  sequence)  is
presented  to  the  system  while  it  runs for  some number  of  iterations.  At  certain  specified  times
during the  operation  of the  system,  the output  of certain  units are  compared  to  the target  for
that  unit  at  that  time  and  error  signals  are  generated.  Each  such  error  signal  is  then  passed
back  through  the  network  for a number  of iterations  equal  to  the number  of iterations  used  in
the  forward  pass.  Weight  changes  are  computed  at  each  iteration  and  a  sum  of  all  the weight
changes  dictated  for  a  particular  weight  is saved.  Finally,  after  all  such  error  signals  have  been
propagated  through  the  system,  the  weights  are  changed.  The  major  problem  with  this  pro-
cedure  is  the  memory  required.  Not  only  does  the  system  have  to  hold  its  summed  weight
changes  while  the  error  is  being propagated,  but  each  unit  must  somehow  record  the sequence
of  activation  values  through  which  it  was  driven  during  the  original  processing.  This  follows
from  the  fact  that  during  each  iteration  while  the error  is  passed  back  through  the system,  the
current  8  is  relevant  to  a  point  earlier  in  time  and  the  required  weight  changes  depend  on  the
activation  levels  of  the units  at  that  time.  It  is  not  entirely  clear  how  such  a  mechanism  could
be  implemented  in  the  brain.  Nevertheless,  it  is  tantalizing  to  realize  that  such  a  procedure  is
potentially  very  powerful,  since  the  problem  it  is  attempting  to  solve  amounts  to  that  of
finding  a  sequential  program  (like  that  for  a  digital  computer)  that  produces  specified  input-
sequence/output-sequence  pairs.  Furthermore,  the  interaction  of  the  teacher  with  the  system
can  be  quite  flexible,  so  that,  for example,  should  the system  get  stuck  in  a  local  minimum,  the
teacher  could  introduce  "hints" in  the  form  of desired  output  values  for  intermediate  stages  of
processing.  Our  experience  with  recurrent  networks  is  limited,  but  we  have  carried  out  some
experiments.  We  turn  first  to  a  very simple  problem  in  which  the system  is  induced  to  invent  a
shift  register  to  solve  the problem.

Learning to  be  a  shift  register.  Perhaps  the  simplest  class  of  recurrcnt  problems  we  have
studied  is  one  in  which  the  input  and  output  units  are one  and  the same  and  there  are  no  hid-
den  units.  We  simply present  a  pattern  and  let  the  system process  it  for  a period  of time.  The
state  of  the  system  is  then  compared  to  some  target  state.  If  it  hasn't  reached  the target  state

9 Note  that  in  this discussion,  and  indeed  in  out  entire development  here,  we  have  masumed  a discrete  time  system

with  synchronous update  and  with each  connection  involving a unit delay.

* 

.. 

*- 

Vz 

x-  T ~It~.  % 1_1  m'4  F.1KT13*W 

wn 

A' 

J1 

1~~- 1 

1.  VW7XZ  7 

A- 

W  J 

vl  w-j~;r_-lw-1 

'JW  ?  4C.- 

'

30  RUMELHART,  HITON, and  WILLIAMS

at  the  designated  time,  error  is  injected  into  the  system  and  it  modifies  its  weights.  Then  it  is
shown  a  new  input  pattern  and  restarted.  In  these  cases,  there is  no constraint  on  the connec-
tions  in  the  system.  Any  unit  can  connect  to  any  other  unit.  The  simplest  such  problem  we
have  studied  is  what  we  call  the  shift register  problem.  In  this  problem,  the  units are  concep-
tualized  as  a  circular  shift  register.  An  arbitrary  bit  pattern  is  first  established  on  the  units.
They  are  then  allowed  to  process  for  two  time-steps.  The  target  state,  after  those  two  time-
steps,  is  the  original  pattern  shifted  two  spaces  to  the  left.  The interesting  question  here  con-
cerns  the  state  of  the  units  between  the  presentation  of  the  start  state  and  the  time  at  which
the  target  state  is  presented.  One  solution  to  the problem  is  for  the system  to  become  a  shift
register  and  shift  the pattern exactly  one  unit  to  the left  during each  time  period.  If the system
did  this  then  it  would  surely  be  shifted  two  places  to  the  left  after  two  time  units.  We  have
tried  this  problem  with  groups  of  three  or  five  units  and,  if  we  constrain  the  biases  on  all  of
the  units to  be  negative  (so  the units  are off  unless turned  on), the system  always  learns  to be  a
shift  register  of  this  sort.1°  Thus,  even  though  in  principle  any  unit  can  connect  to  any  other
unit,  the  system  actually  learns  to  set  all  weights  to  zero  except  the  ones  connecting  a  unit  to
its  left  neighbor.  Since  the target  states  were determined  on  the  assumption  of a  circular  regis-
tcr,  the left-most  unit  developed  a strong  connection  to  the  right-most  unit.  The  system  learns
this  relatively  quickly.  With  71  =  0.25  it  learns  perfectly  in  fewer  than  200 sweeps  through  the
set  of  possible  patterns  with  either three- or five-unit  systems.

The  tasks  we  have  described  so  far  are  exceptionally  simple,  but  they  do  illustrate  how  the
algorithm  works  with  unrestricted  networks.  We  have  attempted  a  few  more  difficult  prob-
lems  with  recurrent  networks.  One  of  the  more  interesting  involves  learning  to  complete
sequences  of  patterns.  Our final  example  comes  from  this domain.

Learning to complete sequences.  Table  10 shows  a set  of 25 sequences  which  were chosen  so
that  the first  two  items of a  sequence  uniquely  determine the  remaining  four.  We  used  this set
of  sequences  to  test  out  the  learning  abilities  of  a  recurrent  network.  The  network  consisted
of  five  input  units  (A,  B,  C,  D,  E),  30  hidden  units,  and  three output  units  (1, 2,  3).  At  Time
1, the  input  unit  corresponding  to  the  first  item  of  the  sequence  is  turned  on  and  the  other
input  units  are  turned  off.  At  Time  2,  the  input  unit  for  the  second  item  in  the  sequence  is
turned  on  and  the others  are  all  turned  off.  Then  all  the  input  units  are  turned  off  and  kept
off  for  the  remaining  four  steps  of the  forward  iteration.  The  network  must  learn  to  make  the
output  units  adopt  states  that  represent  the  rest  of  the  sequence.  Unlike  simple  feedforward
networks  (or  their  iterative  equivalents),  the  errors  are  not  only  assessed  at  the  final  layer  or
time.  The  output  units must  adopt  the  appropriate  states  during the forward  iteration,  and  so
during  the  back-propagation  phase,  errors  are  injected  at  each  time-step  by  comparing  the
remembered  actual  states of the output  units with  their  desired  states.

TABLE  10

25 SEQUENCES  TO BE  LEARNED

AA1212 
BA2312 
CA3112 
DA2112 
EA1312 

AB1223 
BB2323 
CB3123 
DB2123 
EB1323 

AC1231 
SC2331 
CC3131 
DC2131 
EC3331 

AD1221 
BD2321 
CD3121 
DD2121 
ED1321 

AE1213
BE2313
CE3113
DE2113
EE1313

t0  if  the  constraint  that  bims  be  negative  is  not  imposed,  othe  solutions are  possible.  These  solutions  can  involve
the  units  paining through  the  complements  of the  shifted  pattern  or  even  through  more  complicated  intermediate
sidae. 
These  trajectories are  interesting in that  they  match  a simple  shift register  on  all even  numbers  of shifts, but
do  not  match  following an  odd number  of shifts.

LEARNI, 

0"1'13NA;  mpSkLimm-ATiONs 

31

The  learning  procedure  for  recurrent  nets places  no constraints  on  the allowable  connectivity
structure'  For the  sequence  completion  problem,  we  used  one-way  connections  from the  input
units  to  the  hidden  units  and  from  the  hidden  units  to  the  output  units.  Every  hidden  unit
had  a  one-way  connection  to  every  other  hidden  unit  and  to  itself,  and  every  output  unit  was
also  connected  to every  other output  unit and  to  itself.  All  the  connections  started  with  small
random  weights  uniformly  distributed  between  -0.3  and  +0.3.  All  the  hidden  and  output
units started  with  an  activity level  of  0.2  at  the beginning  of  each  sequence.

We  used  a  version  of  the  learning  procedure  in  which  the  gradient  of the  error with  respect
to  each  weight  is computed  for a  whole  st  of  examples  before  the weights  are  changed.  This
means  that  each  connection  must  accumulate  the sum  of  the  gradients  for  all  the examples  and
for  all  the time  steps  involved  in  each  example.  During  training, we used  a  particular  set  of  20
examples,  and  after  these  were learned  almost  perfectly  we  tested  the network  on  the remaining
examples  to  see  if  it  had  picked  up  on  the  obvious  regularity  that  relates  the  first  two  items  of
a  sequence  to  the subsequent  four.  The  results  are shown  in  Table  11.  For four out  of  the  five
test  sequences,  the  output  units  all  have  the  correct  values  at  all  times  (assuming  we  treat
values  above  0.5  as  1 and  values  below  0.5  as  0).  The  network  has  clearly  captured  the rule  that
the  first  item  of  a  sequence  determines  the  third  and  fourth,  and  the  second  determines  the
fifth  and  sixth.  We  repeated  the  simulation  with  a  different  set  of  random  initial  weights,  and
it  got  all  five  test  sequences  correct.

The  learning  required  260  sweeps  through  all  20  training  sequences.  The errors  in  the  output
units  were  computed  as  follows:  For  a  unit  that  should  be  on, there  was  no  error  if  its activity
level  was above  0.8,  otherwise  the  derivative  of  the error  was  the  amount  below  0.8.  Similarly,
for  output  units  that  should  be  off,  the  derivative  of  the  error  was  the  amount  above  0.2.
After  each  sweep,  each  weight  was  decremented  by  .02  times  the  total  gradient  accumulated  on
that  sweep  plus 0.9  times  the previous  weight  change.

We  have  shown  that  the  learning procedure  can  be used  to  create  a network  with  interesting
sequential  behavior,  but  the  particular problem  we  used  can  be  solved  by  simply  using  the  hid-
den  units to  create  "delay  lines" which  hold  information  for a  fixed  length  of time  before  allow-
ing  it  to  influence  the  output.  A  harder  problem  that  cannot  be  solved  with  delay  lines  of
fixed  duration  is  shown  in  Table  12.  The output  is  the same  as before,  but  the two  input  items
can  arrive  at  variable  times  so  that  the  item  arriving  at  time  2,  for  example,  could  be  either  the
first  or  the  second  item  and  could  therefore  determine  the  states  of  the output  units  at  either
the  fifth  and  sixth  or  the  seventh  and  eighth  times.  The  new  task  is  equivalent  to  requiring  a
buffer  that  receives  two  input  "words" at  variable  times  and  outputs  their  "phonemic  realiza-
tions"  one  after  the  other.  This  problem  was  solved  successfully  by  a  network  similar  to  the
one  above  except  that  it  had  60 hidden  units  and  half  of their  possible  interconnections  were
omitted  at  random.  The  learning  was much  slower,  requiring  thousands of sweeps  through  all
136 training  examples.  There  were  also  a  few  more  errors  on  the  14  test  examples,  but  the  gen-
eralization  was still  good  with  most  of the test  sequences  being completed  perfectly.

CONCLUSION

Minsky  and  Papert  (1969)  in  their  pessimistic  discussion  of  pcrceptrons  finally,  near the  end

of their  book, discuss  multilayer machines.  They  state:

The  pcrceptron  has  shown  itself  worthy  of  study  despite  (and  even  because  of!)  its
its
severe  limitations. 

that  attract  attention:  its  linearity; 

It  has  many  features 

tt  The  constraint  in  feedforward  networks is  that  it  must  be  possible to  arrange  the units  into layers  such  that  units
In  recurrent  nctworks this  amounts  to  the  constraint that  during

do  not  influence  units in  the same  or  lower  layers. 
the forward  iteration,  future states must  not  affect  past  ones.

, 

% 

%  %

32 

RUMELHART,  HWNTON.  and  WILLIAMS

PERFORMANCE  OF TILE  NETWORK ON  FIVE  NOVEL TEST SEQUENCES

TABLE  11

Input  Sequence 
Desired  Outputs 

Actual  States of:

Output Unit  1 
Output  Unit  2 
Output Unit  3 

Input Sequence 
Desired Outputs 

Actual  States  of:

Output  Unit  1 
Output  Unit  2 
Output  Unit  3 

Input  Sequence 

Desired  Outputs 

Actual  States of:

Output  Unit  1 
Output  Unit  2 
Output  Unit  3 

Input  Sequence 

Desired  Outputs 

Actual  States  of:

Output  Unit  1 
Output  Unit  2 
Output  Unit  3 

Input  Sequence 

Desired Outputs 

Actual  States of:

Output  Unit  1 
Output  Unit  2 
Output  Unit  3 

A 

-

0.2 
0.2 
0.2 

B 
-

0.2 
0.2 
0.2 

C 

-

0.2 
0.2 
0.2 

D 

-

0.2 
0.2 
0.2 

E 

-

0.2 
0.2 
0.2 

D 
-

0.12 
0.16 
0.07 

E 
-

0.12 
0.16 
0.07 

A 

-

0.12 
0.16 
0.07 

B 

-

0.12 
0.16 
0.07 

C 

-

0.12 
0.16 
0.07 

1 

0.90 
0.13 
0.08 

-
2 

0.20 
0.80 
0.02 

-

3 

0.19 
0.19 
0.80 

-

2 

0.16 
0.80 
0.20 

-

1 

0.80 
0.20 
0.07 

-

2 

0.22 
0.82 
0.03 

-
3 

0.25 
0.05 
0.79 

-

1 

0.80 
0.00 
0.13 

-

1 

0.79 
0.15 
0.01 

-

3 

0.09 
0.13 
0.94 

-

2 

0.11 
0.88 
0.01 

-
1 

0.48 
0.04 
0.48 

-

1 

0.87 
0.13 
0.01 

-

2 

0.07 
0.87 
0.13 

-

3 

0.27 
0.01 
0.76 

-

1

0.83
0.03
0.22

-

3

0.26
0.09
0.53

-

2

0.11
0.70
0.25

-

3

0.11
0.05
0.96

-

1

0.78
0.02
0.13

TABLE  12

SIX  VARIATIONS  OF TIlE SEQUENCE  EA1312  PRODUCED  BY
PRESENTING  THE  FIRST TWO  ITEMS  AT  VARIABLE  TIMES

EA--1312 
-EA-1312 

E-A-1312 
-E-A1312 

E--A1312
-- EA1312

Note:  With  thes  temporal  variations,  the 25 sequences shown  in
Table  10 can  be  used  to generate  150 different  sequences.

intriguing  learning  theorem;  its  clear  paradigmatic  simplicity  as  a  kind  of parallel  com-
putation.  There  is  no  reason  to  suppose  that  any  of  these  virtues  caery  over  to  the
many-layered  version.  Nevertheless.  we  consider  it  to  be  an  important  research  problem
to  elucidate  (or  reject)  our  intuitive  judgement  that  the  extension  is  sterile.  Perhaps

.N'

% a 

4, 

, 

LEARNIDG  NrEQA.  TPkR-SENTATIUN, 

33

some  powerful  convergence  theorem  will  be  discovered,  or some  profound  reason  for
theorem  for  the  multilayered  machine
the  failure  to  produce  an  interesting  *learning 
will  be found.  (pp. 231-232)

Although  our  learning  results  do  not  guaantee  that  we  can  find  a  solution  for  all  solvable
problems,  our  analyses  and  results  have shown  that  as  a  practical  matter,  the error  propagation
In  short,  we  believe  that  we  have  answered
scheme  leads  to  solutions  in  virtually  every  case. 
Minsky  and  Papert's  challenge  and  have found  a  learning  result  sufficiently  powerful  to  demon-
strate  that  their  pessimism  about  learning  in multilayer  machines  was misplaced.

One way  to  view  the procedure  we have  been  describing  is  as  a parallel  computer  that,  having
been  shown  the  appropriate  input/output  exemplars  specifying  some  function,  programs  itself
to  compute  that  function  in  general.  Parallel  computers  are  notoriously  difficult  to  program.
Here  we  have  a  mechanism  whereby  we  do  not  actually  have  to  know  how  to  write  the  pro-
gram  in  order  to  get  the system  to  do  it.  Parker  (1985)  has emphasized  this point.

On  many occasions  we  have  been  surprised  to  learn  of  new  methods  of  computing  interest-
ing  functions  by  observing  the  behavior  of  our  learning  algorithm.  This  also  raised  the  ques-
In  most  of  the  cases  presented  above,  we  have  presented  the  system
tion  of  generalization. 
It  is  interesting  to  ask  what  would  happen  if  we  presented
with  the  entire  set  of  exemplars. 
only  a  subset  of  the  exemplars  at  training  time  and  then  watched  the  system  generalize  to
In  small  problems  such  as  those  presented  here,  the  system  sometimes
remaining  exemplars. 
finds  solutions  to  the problems  which do  not  properly  generalize.  However,  preliminary  results
on  larger  problems  are  very  encouraging  in  this  regard.  This  research  is  still  in  progress  and
cannot  be  reported  here.  This is  currently  a very  active  interest  of  ours.

Finally,  we  should  say  that  this  work  is  not  yet  in  a  finished  form.  We  have  only  begun  our
study  of  recurrent  networks  and  sigma-pi  units.  We  have  not  yet  applied  our  learning  pro-
cedure  to  many  very  complex  problems.  However,  the  results  to  date  are  encouraging  and  we
are  continuing  our work.

REFERENCES

Ackley,  D.  H.,  Hinton,  G.  E.,  &  Sejnowski,  T.  J.  (1985).  A  learning  algorithm  for

Boltzmann  machines.  Cognitive Science, 9,  147-169.

Barto,  A.  G..  Learning by  statistical cooperation of  self-interested neuron-like computing  elements
(COINS  Tech.  Rep.  85-11).  Amherst:  University  of  Massachusetts,  Department  of  Com-
puter  and  Information  Science.

Barto,  A.  G.,  &  Anandan,  P.  (1985).  Pattern  recognizing  stochastic  learning  automata.  IEEE

Transactions on Systems, Man, and Cybernetics.

Fukushima,  K.  (1980).  Ncocognitron:  A  self-organizing  neural  network  model  for  a  mechan-
ism  of  pattern  recognition  unaffected  by  shift  in  position.  Biological Cybernetics, 36,  193-
202.

Kienker,  P.  K.,  Scjnowski,  T.  J.,  Hinton,  G.  E.,  &  Schumacher,  L.  E.  (1985).  Separating

figure from ground with a parallel network.  Unpublished  manuscript.

Le  Cun,  Y.  (1985,  June).  Une  procedure  d'apprentissage  pour  reseau  a  scuil  assymetrique  [A
learning  procedure  for  assymetric  threshold  network].  Proceedings of  Cognitiva 85,  599-604.
Paris.

McClelland,  J.  L.,  &  Rumelhart,  D.  E.  (1981).  An  interactive  activation  model  of  context
effects  in  letter  perception:  Part  1. An  account  of  basic  findings.  Psychological Review,  88,
375-407.

Minsky,  M.  L.,  &  Papert,  S.  (1969).  Perceptrons.  Cambridge,  MA:  MIT  Press.
Parker,  D.  B.  (1985).  Learning-4ogic (TR-47).  Cambridge,  MA:  Massachusetts  Institute  of  Tech-

nology,  Center  for  Computational  Research  in  Economics  and  Management  Science.

V 

-"A

34 

RUMELRART,  HITON, and WILL"IS

Rumelhart,  D.  E.,  &  McClelland,  J.  L.  (1982).  An  interactive  activation  model  of  context
effects  in  letter  perception:  Part  2.  The  contextual  enhancement  effect  and  some  tests  and
extensions  of  the model.  Psychological Review,  89, 60-94.
Widrow,  G.,  &  Hoff,  M.  E.  (1960).  Adaptive  switching  circuits.  Institute  of Radio Engineers,

Western Electronic Show  and Convention, Convention Record, Part 4, 96-104.

A.V

4'O

*La 

%. 

* 

ICS  Technical  Report List

The  following  is  a  list  of  publications  by  people  in  the  Institute  for  Cognitive  Science.  For
reprints,  write  or call:

Institute  for  Cognitive Science,  C-015
University  of  California,  San  Diego

Jolla,  CA  92093

(619)  452-6771

8301.  David  Zipser.  The  Representation of  Location.  May  1983.

8302.  Jeffrey  Elman  and  Jay  McClelland. 

Speech  Perception as  a  Cognitive  Process:  The
Interactive Activation  Model.  April  1983.  Also  published  in  N.  Lass  (Ed.),.Speech  and
language: Volume  10,  New  York:  Academic  Press,  1983.

8303.  Ron  Williams.  Unit Activation Rules for Cognitive Networks.  November  1983.

8304.  David  Zipser.  The Representation of  Maps.  November  1983.

8305.  The  HMI  Project.  User Centered System  Design:  Part 1,  Papers for the  CHI  '83  Confer-
ence  on Human Factors in Computer Systems.  November  1983.  Also  published  in  A.  Janda
(Ed.),  Proceedings of  the  CHI  '83  Conference  on  Human Factors in  Computing  Systems.
New  York:  ACM,  1983.

vArtificial 

8306.  Paul  Smolcnsky.  Harmony  Theory:  A  Mathematical Framework for  Stochastic  Parallel
Processing.  December  1983.  Also  published  in Proceedings of  the National Conference on

Intelligence, AAAI-83,  Washington  DC,  1983.

8401.  Stephen  W.  Draper  and  Donald  A.  Norman.  Software Engineering for  User  Interfaces.

0January 
*- 

-C: 
* 

1984.  Also  published  in  Proceedings of  the  Seventh  International Conference on

Software Engineering, Orlando,  FL,  1984.

interaction, 

in  human-machine 

8402.  The  UCSD  HMI  Project.  User  Centered  System  Design:  Part 11,  Collected  Papers.
March  1984.  Also  published  individually  as  follows:  Norman,  D.A.  (in  press),  Stages and
levels 
International Journal  of  Man-Machine  Studi,,s;
Draper,  S.W.,  The  nature  of  expertise  in  UNIX;  Owen,  D.,  Users  in  the  real  world;
O'Malley,  C.,  Draper,  S.W.,  &  Riley, M.,  Constructive  interaction:  A  method  for study-
ing  user-computer-user  interaction;  Smolensky,  P.,  Monty,  M.L.,  &  Conway,  E.,  For-
malizing  task  descriptions  for command  specification  and  documentation;  Bannon,  LJ.,
&  O'Malley,  C.,  Problems  in  evaluation  of  human-computer  interfaces:  A  case  study;
Riley,  M.,  &  O'Malley,  C.,  Planning  nets:  A  framework  for  analyzing  user-computer
interactions;  all  published  in  B.  Shackel  (Ed.),  INTERACT 
'84,  First Conference  on

%IW4f 

%

Human-Computer Interaction, Amsterdam:  North-Holland,  1984;  Norman,  D.A.,  &  Draper,
S.W.,  Software  engineering  for  user  interfaces,  Proceedings of  the  Seventh  International
Conference on Software Engineering, Orlando,  FL,  1984.

8403.  Steven  L.  Greenspan  and  Eric  M.  Segal.  Reference  Comprehension: A  Topic-Comment
Analysis of  Sentence-Picture Verification.  April  1984.  Also  published  in Cognitive Psychol-
ogy,  16,  556-606,  1984.

8404.  Paul  Smolcnsky  and  Mary  S.  Riley.  Harmony Theory:  Problem Solving, Parallel Cognitive
Models,  and Thermal Physics.  April  1984.  The  first  two  papers  are  published  in  Proceed-
ings of  the Sixth Annual Meeting of  the Cognitive Science Society, Boulder,  CO, 1984.

8405.  David  Zipser.  A  Computational Model of Hippocampus Place-Fields. April  1984.

8406.  Michael  C.  Mozer.  Inductive Information Retrieval Using Parallel Distributed Computation.

May  1984.

8407.  David  E.  Rumelhart  and  David  Zipser.  Feature Discovery by  Competitive Learning.  July

1984.  Also  published  in Cognitive Science, 9, 75-112,  1985.

8408.  David  Zipser.  A Theoretical Model of Hippocampal Learning During Classical Conditioning.

December  1984.

8501.  Ronald  J. Williams.  Feature Discovery Through Error-Correction Learning.  May  1985.

8502.  Ronald  J. Williams.  Inference of Spatial Relations by  Self-Organizing Networks.  May  1985.

8503.  Edwin  L.  Hutchins,  James  D.  Hollan,  and  Donald  A.  Norman.  Direct Manipulation
Interfaces.  May  1985.  To  be  published  in  D.  A.  Norman  &  S.  W.  Draper (Eds.),  User
Centered System  Design:  New  Perspectives in  Human-Computer Interaction. Hillsdale,  NJ:
Erlbaum.

8504.  Mary  S.  Rilcy.  User Understanding.  May  1985.  To  be  published  in  D.  A.  Norman  &  S.
W.  Draper  (Eds.),  User  Centered System  Design: New  Perspectives in  Human-Computer
Interaction.  Hillsdale,  NJ:  Erlbaum.

8505.  Liam  J.  Bannon.  Extending  the  Design Boundaries of  Human-Computer  Interaction.  May

1985.

8506.  David  E.  Rumelhart,  Geoffrey  E.  Hinton,  and  Ronald  J. Williams.  Learning Internal
Representations  by  Error  Propagation.  September  1985.  To  be  published  in  D.  E.
Rumelhart  &  J. L.  McClelland  (Eds.),  Parallel Distributed Processing: Explorations in the
Microstructure of  Cognition.  Vol.  ):  Foundations.  Cambridge,  MA:  Bradford  Books/MIT
Press.

1n-

* 

i 

* 

Earlier  Reports  by  People  in  the Cognitive  Science Lab

The following  is a list  of publications by people  in  the  Cognitive  Science  Lab  and  the  Institute
for Cognitive  Science.  For reprints,  write or call:

Institute for Cognitive  Science,  C-015
University of California,  San Diego
La Jolla, CA  9293
(619)  452-6771

ONR-8001.  Donald  R.  Gentner, Jonathan  Grudin,  and  Eileen  Conway.  Finger Movements  in

Transcription Typing.  May  1980.

ONR-8002.  James  L.  McClelland  and  David  E.  Rumelhart.  An Interactive Activation Model of
in

the  Effect  of  Context  in  Perception:  Part I.  May  1980.  Also  published 
Psychological Review, 88.5,  pp. 375-401,  1981.

ONR-8003.  David  E.  Rumelhart  and  James  L.  McClelland.  An Interactive Activation Model of
July  1980.  Also  published  in

the  Eff ect  of  Context  in  Perception:  Part 11. 
Psychological Review, 89,  1, pp. 60-94,  1982.

ONR-8004.  Donald  A.  Norman.  Errors in Human Performance.  August  1980.
ONR-8005.  David  E.  Rumelhart  and  Donald  A.  Norman.  Analogical Processes in Learning.
September  1980.  Also published  in  J. R.  Anderson  (Ed.),  Cognitive skills and their
acquisition.  Hillsdale,  NJ: Erlbaum,  1981.

ONR-8006.  Donald  A.  Norman  and  Tim  Shallice.  Attention  to Action:  Willed and Automatic

Control of Behavior.  December  1980.

ONR-8101.  David  E.  Rumelhart.  Understanding Understanding. January  1981.
ONR-8102.  David  E.  Rumelhart  and  Donald  A.  Norman.  Simulating a  Skilled  Typist:  A
in

Study  of  Skilled  Cognitive-Motor  Performance.  May  1981.  Also  published 
Cognitive Science, 6,  pp.  1-36,  1982.

ONR-8103.  Donald  R.  Gentner.  Skilled Finger Movements  in Typing.  July 1981.
ONR-8104.  Michael  I.  Jordan.  The  Timing of Endpoints in Movement.  November  1981.
ONR-8105.  Gary  Perlman.  Two Papers in Cognitive Engineering: The  Design of  an Interface to
a  Programming System  and  MENUNIX:  A  Menu-Based  Interface  to  UNIX  (User
Manual).  November  1981.  Also  published  in  Proceedings of  the  1982  USENIX
Conference, San  Diego,  CA,  1982.

ONR-8106.  Donald  A.  Norman  and  Diane  Fisher.  Why  Alphabetic Keyboards Are Not Easy to
Use:  Keyboard Layout  Doesnt Much  Matter.  November  1981.  Also  published  in
Human Factors, 24,  pp. 509-515,  1982.

ONR-8107.  Donald  R.  Gentner.  Evidence Against a Central Control Model of  Timing in Typing.
December  1981.  Also  published  in  Journal of  Experimental Psychology: Human
Perception and Performance. 8. pp.  793-810,  1982.

ow

ONR-8201.  Jonathan  T.  Grudin  and  Serge  Larochelle.  Digraph Frequency Effects  in Skilled

Typing.  February 1982.

ONR-8202.  Jonathan  T. Grudin.  Central Control of  Timing in Skilled Typing.  February  1982.
ONR-8203.  Amy  Geoffroy  and  Donald  A.  Norman.  Ease of  Tapping the Fingers in a Sequence

Depends on the Mental Encoding.  March  1982.

ONR-8204.  LNR  Research  Group.  Studies of Typing from the LNR Research Group: The  role of
context, differences in skill level, errors, hand movements, and a computer simulation.
May  1982.  Also  published  in  W.  E.  Cooper  (Ed.),  Cognitive  aspects of  skilled
typewriting.  New  York:  Springer-Verlag,  1983.

ONR-8205.  Donald  A.  Norman.  Five  Papers on Human-Machine Interaction.  May  1982.  Also
published  individually  as  follows:  Some  observations  on  mental  models,  in  D.
Gentner  and  A.  Stevens  (Eds.),  Mental models,  Hillsdale,  NJ:  Erlbaum,  1983;  A
psychologist  views  human  processing-  Human  errors  and  other  phenomena
suggest  processing  mechanisms,  in  Proceedings of  the International Joint Conference
on  Artificial Intelligence, Vancouver,  1981;  Steps  toward  a  cognitive  engineering:
Design  rules  based  on  analyses  of  human  error,  in  Proceedings of  the  Conference
on Human Factors in Computer Systems,  Gaithersburg,  MD,  1982;  The  trouble  with
UNIX, 
in  Datwnation, 27,12,  November  1981,  pp.  139-150;  The  trouble  with
networks,  in  Datamation, January  1982,  pp.  188-192.
ONR-8206.  Naomi  Miyake.  Constructive Interaction. June  1982.
ONR-8207.  Donald  R.  Gentner.  The Development of  Typewriting Skill.  September  1982.  Also
published  as  Acquisition  of  typewriting  skill,  in Acta Psychologica, 54,  pp.  233-248,
1983.

ONR-8302.  David  E.  Rumelhart  and  Donald  A.  Norman.  Representation in  Memory.  June
1983.  To  appear  in  R.  C.  Atkinson,  G.  Lindzey,  &  R.  D.  Luce  (Eds.),  Handbook
of  experimental psychology.  New  York:  Wiley  (in  press).

ONR-8208.  Gary  Perlman.  Natural Artificial Languages:  Low-Level  Processes.  December  1982.
Also  published  in  The  International Journal of Man-Machine Studies, 20, pp.  373-419,
1984.

ONR-8301.  Michael  C.  Mozer.  Letter  Migration  In  Word  Perception.  April  1983.  Also
in  Journal  of  Experimental  Psychology:  Human  Perception  and

published 
Performance. 9, 4, pp. 531-546,  1983.

ONR  DISTREBUTION  LIST

10 

C

a 

L

r 

m 

0 

c 

'4 

z0 

.-

CU 

.

61no 

2 

0-  L 

0 
L;L 
ac 
6 
u1 

a 

%,a 
Le. 
a1 
93 

a- 

a. 

v 

L. 

;  *1 

'0 

L.'a0 
-- 

0 

a. 

L.45to

06 6 
10 044 c 

04  .
h4 

660- : 

@ 
.

0 

044. 

1- 

0' 

0.0 

.9 

0 

-
c) 

...

S1 

a-02a

6- 

-C
5116

& 
1--C 

us~ 

0 " 
c 
4

c

SI) 

-

0, 

C21- 

.500 

a~ 

0U 

C 
a 

~

0  2
04  a.L 
0 

' 

-

064 

C 

404 

-

.

£~~~ LOj 
0 

6 

.C-C9 
,..

100 

4- 

.2L 

-

0 v 

r 
0052. 

I 
-0~4. 
6I .060 
04  IsID L.  62 
cc  1-0 
* 
-, 
0 

.
.14 
0'. 
c  va 

4.00; 

C 

0 
a  *C 
00  V 
6 
1. 
0 
.- 
0 
00 

.0 

.

0  we-4 

04,60 
46 
,01C 

4 

a0600 
.00S 
-

1:5.1 
0 

0 

O  L 

.6 
L2. 

066 
C 

a 

* 

mw 06.  M 
.

Z 
mo 
4. 
0.4 
W 

C 
) 
C4  2  5- 

0 

LO 
O 
IV 
400 
,.1 
a  w24U. in. -3
.20 

00 

0 C 

6 

0 

61C 

4  L 

0 

4 
toS 
0 
-

0 
L.6 1,  L50  00 

m-0 

UN~ 

61. 

10

C4 
£  -CcI 
0C1. 
L 

.0. 

C

o-

O4

-ft"1

)460

CL 

14 
1-0-

1  AU

tP 

0 
21  .

-
0 6 
0 

'0 

£ 

N 
a 
3 
04OO 
13  n-to 

7 0 
.- 

L50 

0

CO 

C .0 

0 

44 
1- 
0 

0 

0- 
2z 

~ 

61- 

O 

T2 
Cm 
60mr? 

0 

V 

0 

000 

1-.40..4V 

L1 

00O 

9 

111 
C' 

0 

L  II  U  OM4 

200. 
000 

c10 

a 

0 

-3 

0 .4 
00 Vi 

*2 

M, .C  C 

v  u- 

00. 
PI

CL.. 
C 
*-L 

0 

.

4 

0

-

o- 
2a0 

600 .
' 

-

. .. 

0 
; 

04 

0411 

60 
-0 

go 
6 X 

0 

CL 

4

L

U% 

0

6
4.

-

*, 
1 

020 
000 

20
2

s-I 

4 
N.  a5 

-

C 

0 
a144 

04.4 

to4 

U.  WL 

1.4O

a.CO  C0 

u6.-  a  b 

C!  00 

1.0 

1-L.1 1- 

06

U, 

i 

C 

L 

-

low 

I4. 

C 
6 

N 

0- 

2,- 

v60 

v 
C-L 0 

0- 

> 
006- 

C 
W 

2.4 

C.C

0-

LC00- 

53~~

N

U 

0 4 
6 

6 

o 

4 

1 
ti.  C- 
a 0 
a  0 

60-0 
0 
.. 
4 

C0 a, 
.4U 
.1 
0 
a, 

s 

Cw44

04 
.1 
t 
000. 

0 
0 

- c 

-'6 

01 aO 

.04 
L 
CO 0  a6 

.2 =0 

ft 
6 
600 

4S0 

N:44 
CU4.4 

0 
6>.C- 
0. 

&060.0V210 
) 

a 

ION 

0 
.
5 

0 

a0 .4 

0. 
0 
COO 

00 

.-
L 100 
1.0 

0 
0 

S44 

1.2102. 0. 

0 

O 

00 

1-44. 

0 

-C"- 

V.6 

6t 

41-44- m 

1.. 

cO  0  0U 
52 
2 

a 
4..0 
6 

0.24 t: 
CW 
4 

00 
V 

C 

-

.4 

Q 
x5 

.10  0 
0 

0 

4 
6 
-5.L 
" 
.41 

0 

41 
-. 
>0 

.
(06 
02  V 
of62. 
0.0 

C 
K5 
0.0 

* 

* 

44 
2. 
44 

20 

0 

V 
C-6 

004 
>0 
-.
:20

0' 

.2 

0 
w. 
' 
I  02-CO 

1.0 

* 

00- 

C4 
a 

E
00'
2
CL

0-

-
Nl 

.0 
0  0  v

0

0 
"0o
.

g1 

a-4610

t.  ON 

0 ON 
E' 
CN0 

*L 

> 

v-2 
0 

U 

0.

£44 
.0 
)10 
104 
2 

44 
S) 

.

i 

-~.L  0

L

1- 

L 
I4
0140 

.4 

v  1 .
0041 

31 

L. 
0= 

0. 

.0.l- 

c 

O>' 

C 

2 

4.14  O'S 

1E 

II 

2 

0 

2.0 

UMll1 
C 

NW 
N 

00C 
L.  002 

0 

-6

0

,u 

0 

c2  II.Lle'

CL C. 

-

CS 

n0  a01- 

0. C.0 

4144 

to 

* 

06 
£0 

0 

00 

, 
00a 

00.I' 
Za,21 

~ 

6 

o 06 

f" 

1 
0 

.
.-. 
6 
a..1 

.

0 

.
N 

r4 

~  ~ 

go 

4 
00 
0 

2 
N 
A11 C0 
0N 

~ 

0 

20 

-

60 

0= 
.4 

C 

*40 

2. 
r4 

' 

0a0402 

0 
6 
44005. 
1)0-. 

;1 

:.S 

C 
02 

L..00.4
.4 
-4 

C 

6.30 

600. 

1-0 

20 

.4 
62441 

A.40 

024. 

to

" 

4 

M 

-C- 

om4

1-4 
44C 
.s1 

* 
0001. 

10 

.. 

N 

0
60
0  o- 
00 

U.  C444 

0  .4. 
O4 
c4 

-l.0 

N 
c 

1 
00 

0 

0 

N 

C4. 

-
C. 
.
s6 

L 
-
call4 

1.4 
.4 

Ic

CO 

u- 

021 

4 
60.N0

N 

40 
.4 
c6 
046 
1- 
64OC 
0,24060 

-60 
m1CO 

1 

06 

6 

a-. CM 

0 

4s
1
005
0 
0 
L0. 
aI

NC
0

4 
Cn

6 

Ca

6

ONR OITFRIBUTION  LIST

0%0

tA 

m 1 

0. 

e. 

aC  C4 

0 

0.. a4
=m' 

-.

4.  00 
4.4 

t  .~ 

a 

F.F

.-

4 

4.r 

4 

c-4 

oO. 
a 
m 

> 

0 

C 
.

. -) 

a8 

8  4  0 

4 

0 .

0 

.

0  00 
c 

o> N 

a 4>2

.

0 
0.D4 

840 

.oi 

0Q 
wS 

O
t
o- 

v-~ 
.40>4 
4

CO  C  ' 

M08 

a-4.4 

o

0 

1. 

wN-

o  m 
0 
C4 

'o1 

vc 

1  0 
4..- 

A 
04. 

u  p.. 
4- 

.0C  'a  cu 

0  ~04 

c 

-

u 

~ 

~ 
4 ~  - 8 4 

a4 

.

S 

2 

; 

0L 

0O 

.0 

;W  r 

.

r 

01N

.

4

L-. 

0 

ca 

z  u>4 

0 

p 

2 

C 
L  C 64 
03 

6 

E
U 
>,U4,4-5 
Q0um 
,u 

O

.0M 

C  A

4L 

0~4 

V. 
L  0> 

to 
0-..c 

0W 

0. 

0 
w4 

0> 
0 

In4 

44 

8- 

4. 

.w

4

4k 

0  0 
L. 
am- 

m0. 
0 (, 
Mc. 

.8 ~ 

CIO0  n  C,4c 

4. 
40 

08  > 
4  >. 
a~L0 C4 U 

=1 

XC 

to 
04 
.84 
.0 
4.-  40 0 
o.'8 

4  48  4U > 
-
C 
84 
.
a.-4 4 

CL0
. ON 
c4  -
0440 

% 

404 

L0 
.4 

4 
to4 

08. 

.L.. 
0O~' W 
84. 

004 
.48 

.4 

11. 

4 

14- 

-C 

C 
C0' 
0 

.4 
C 
a-4 
84  84. 
r)O 
a. 

0, 

4.0.. 

4 

840 
a 

a4 

a 
L-c 

0 

0 

0>  00
L400

40a,- 

4l08

4.40

'8

1n~-. r 

a.84. 
C8. 

4L.. 

IEO 

a840

g.448 o 

34 

84  W-. 
.0 

080 

uJF o1 
4 
C 

84 

.

c.a.-.. 

8to4 
I 

m484. W0. 

10
I

8.4

L4 0... a04 

4'8 

.40 

0 

.L0a0o21 

aL0.0. 

448  04  0 

00

-

4 

u. 

0~  o.4w 

48 
4.0 

10 

>. 
0 
0 
-. 
> 

m* 

Cm1 
84 
-4. 
14  0 

L 

4. 
0 "1 
4 
4. 
54.844

00 

CC 

0~ 0~4 

40 

840--C

084~1 

.448 

0 

O 

US 

z4 E 

4 

Cn
e 
0

.4 

cc 

84 

-

O

3

aa

t-
C1. 

0 

020C

8.

'Q-4~~> 

a444>.0  m 

Z8S0  E.4 'mt 
a  L8 

a0- 

u20 

4I4 

.484 

t-.4. 

04.. 

@1 

.

.. 

loW04.T41 

O 

L 
0-4.1' cw 
=-
00.. 

C44
10C. 

u4.0~ D 

444a 

0. 

081c 

4. 

08. 

> 

40- 

C-40 

044 c.444  .0c 

4

A=A 

Go 

Q0Q 

3a 

00 
08M 

m4u8a> 

84 

n4> 

a888 c84 V) 

0480

S080.0 

'A.84 

0-04 

a14! 

08 

0.  00. 

C( 

02 

L  C0 

L4L 

4. 

44 

4.L.8 

0~ 

Cm40 

~ 

~ 

1 
-C48 

0 

02
..

.4 

0 

4

04. 

a 

4  s,'8 

cjC 
8 

-

0 
0  .
0. 
to8 .48 

8444044%~~ 

t.00-

0 

4 
4 

.4 

0. 
4  8 

>4  L 

O 

C  4UY 

N41 

r

L8 

48
8

L 

4.LU 

>  .0 

844 

8 

4 

cv  ~  ~ 

.L 

U- 

C-l 

.

.

4

CL4.. 

4..4C~ ~~~~~ 

0C 
@1.8 

.1 

E4-4.~ 

4.0 

4 

.8 
.444 

0 >48 0 
14 
L4 

.~ a448 
0 

= 

448 

CC2  0

4  2 

..

o.

.......... 

0 

.

0 

.

0 

0..4 

..

4 

4  .

AL.4 

48

00

@0 

2% 

c40 
-0 

.0  -U 
I  1 
-4- 

in 
I~~~e 

-. L. 
10 

r.  14 

0 

A'sL 

C; C.0 

0 

~~~ 

~ 

a 

-.. 

0 

O 

a-.L0 
.O  83 

u 

40 

~ 

L6 
-
-C-.-

-K0' 
U0 

.4 

MS 
w05O~ 

; 

.
C,

CUi 
-. 

4a0
0  C 

-

cc 

USN 

-

01 

ONR  DISTRIUTION  LIST

1 

0 

r 

l

11 

4 
.0 

2 

a 
.
Lm  40

000

C

0.

OC

On -UC

SE 

N -

N0"

0  01 

.M 

o00L 

Z.0.. 
.SS  6 

CP 

0L).co0 

xS!t-.- 

.0 

0 

22, 

CEOO 

~~SC 

6 

i L 
L 
A.  I- 

1C 
U 

COC 

.

u. zO 
0 

-?  .0. 

8 

SACQ 

A 0. 

M 

A 
CS."O 

, 

*C 

1U0Oj

.0a 

Mcu  W, 

W)  0 
-
*. 
0 

:-4 v. 

C 

0  =cA 

-2c A 

0 

m 

.

0

Mc 

C
A
L  A0 
(00

*0  :9. 

:6:0 

.0 

cu~ 

L.4f 
50  A 

C 

IS.0 

Lt. 

U0 a 

0. 
0. SO 

9 

11 

00 

1. 

05. 

.

0- 

*C MM0~f 

0S 
0.I 
L  f  4 

I. 

05 

DO W 

L 

5 

-. 

a 

0 

s

00 

0  6L, 

S 

L 
b.

c
0 

t

*O 

L  ~

*4V0 
Lovu 
0

L* 

c 

A 

0 

g 

0x 0 

.
b4 

0 

.

0 

40: 
to 
or 
g. 0  :0 
-LC 
.w 

M 

S.. 

UN 
a 

M0 

0 

;0. 

LO, 

_0,00  cC 
r 

-

.
q40 
A 

60 

M Z0 

C 

.00.. 

1.- 
td 0 

CL- 
0.. =0  " 

Lo 
A  0N 

NC 

a*-.0 

&- 
F0 12-0 chO do  ALU 

.0.C  LA  I 

A  .- 

=41 

0aZ. 

0  0 

r 

I. 

S 
L0 
at 
u 
a 

0,.0 

- a 

0 

LS 0mc "M400 

0 L= 

V3  000 a40 
c. a0 c- a. 
On  o-~ 
55 
0 
..

.0 

C 

4 
'a40 
N 
4X( 

-% 

D.  0. 0o 

00 
c 

q- 

40. 

4 

0.

0 

~.'o 

I&AN 

Lt;Cc

.0 

3M 

.*US 

c  0 

LI 
055 

-y 

0
COE-MN S

C

a.-0 

L

-6LO

a0 
0.40 

0, 
I. 
0.U.0 
= 

c.-0.a60
40C 
it.0 

* 

0.0 

V  CtL  C  S.0@

ms 

*O 

C 
0.0.O5 

0. 

0 
40=4I

L0

00i

.

I 

.

00.4 

0, 

c 
00 C2 

SO cA M0 

a- *LO.0 

M 

.00  0 

.60. 

c0 
w  0 

0 
00.c..N

2Sm~  104 
03-.. 

N 

.0 

.

0C.
C 

CO 

10 

..

O4

L 

*0 

_1 

to 

Z00

40  6. 

*0C*..-

L.0I

.0 c 

C0Ma.

0.. 

0m 
2%  4 

SC c 

mMO 
MC 

0' 

0  c 

N 

0 

0 

O 

E00 
MS 0 

00 

=.C 

0. 

3M3 

(.7 
c 

U 

0. 

M 

x 

c  0 

M.c00- 0 0 
.-
06 

c 
r 

It  O L  C',

.

0L 

-0 

0 

SO0

.0

40 o
40.0

cc;

r0 

AL C0 

40% 

uS4  m0  U  N 

L ~ 

0 
CC 

.c" 

-a  ; 

A 

0 

0 c  96-4 

.

1.0 
auO0 
w0 L 

0d 

0 

-K 

L. 

C 

U40 
.0 

L.  C0  60 M0 jr. 

a 

c 

c 

v(0*a 

* 

ito.. 

00 

C 

-.

4,- 

.C L 

0 

"C' 

IN 

0 

0 
(..00

660-

CC 

.

300 

L4 

' 

.

0 

-M

L 

0

.00 

cc~"n 

c 

0..0

C 

S 

0 

00. 

'. 

UP0

0 

' 

C.A 
0 
.

C 

0 

MC 

Mm 

I 

A"- 
O  MOO 

0. 
V0 
0O 06 
4 
LCC0 

a 

0. 

.

r4 

5 
4  0 

L.  0.0  v 
0.04 

;; 

.00.00 

.
u00 

C.0 
.A500 
u 

a  "0 0. 

Ca  r 

a 

3 
L 

:1 
N 

- A 

C' 
M 

v  0 
.0 
"5. 10 
C 
1

-

ON 00 
6 
I

C 

R- 

6 
V0r.0

46004. 
65a 

0 
40 

.0 
0 

;0(0

O .0 
CS

V 

.0..
L0 
a.
640

0. 

0CS

0 0 

00.  L 

~ 

.0 

L00C 

40 

V.,  00000 
S.

0  

.
0. 

A 

xq 

400. 
.4 

.

4 

-

ua 

PCC0o 
00 

.a 

M  r

MM 

&C 

.0 
0 

*O  O 

0

LO 

0..0. MO  0 

0

* 

0 
c006 

0  w- 

0 

0

-C 

C3 

A  4  0 

A 

I 

5 

a 

-4 

a- 

-a-W a-

.

'S-&~ 

W3 

.

.

:

c 

a. 

ua

Ot4R DESTRIUYION  LIST

00

0 

.

-

MW 

04 

c 

44. 0 
>0 
Q 
: 

L 

0 

a 
.U 

0

L 
C 

uL.0c
V 

N4 

0 

Z 

NI 

N 

.4 
-
j 

..

t 

-

40.

1 

co 

x

1

c 

*I 

0 

a 

c

X4. , 

*r 

0 
01 

4J 

' 

0 

0 

0 
.4 

4 

6 

C.0 
64 

NN 
0 

04 

0  46 

* 

4. 

0 

.0 

0U 

2 

0 

00 U 

.

4 

U 

00 

C 

4 
-- 41464 
a4 

CO 

Wu-4Z
01
0

-

4 

V  '

.0  0 

,4 

14 0 

aO  ,- 

,-.24.4. 
4-C 

O 
a  04. c.  w2 

I040. a 

-

000 

1 

.

-L4 

W- 
... 

In 

C. 

0 

0 
0 

4c.0 

44 

00 

a4 

O 

O 

a4 

I44  Ica 

04N 

0 

44.4 

.0 

r 0 
a4 

00 

0 

0 
04 
U0 
0 

6... 

Q0  440. 

44 
Z 
44 
4 

0 

a 
L 
O 

IQ 

O 

0440 
a4 a 

.

v 
0~

1.4 LW 
L4-- Z44. -400 04.0. 
W.4 

0 

>C 

0  0* 
.s >0 
-C 

X 

on00 

10 
44
040 
W,4 C 
L
4-4
OM 

W
A".. 
0

0.. 

8. 

o. 

14  14, 

a  >4CQ)0

0.4 

c~ 

-0k 

0

.X0* 

0

6o
>0
a4V4 

0 

- 0 

1.N 

aa-

0 

Zo. 

0 

1,O

046.  ~  V 
44  ~

NJ6 
.40 

9o 

1 

.

A~-0 
44L-
0  0 

0
*

6
.42 

C, 

0- 

00 
L 

N 
Uk 

3C 

> 

P-9 

0 

0 

0- 

.

m 
-l. 

0- 

i 
00.- 
v0U 

r-4) 
r 

L 
.'

0 
00 
N 

0  a4 04.4 

r 

. >4 

C 

-* 

t 

a 

0 

V0 

2 

.I
r. 

6 

0 

.4 N 

-

0 be 

-

.. 4- 0 

~4~* 

ca4.40.4 444  2 

2 

4.0 a 

0 

24  0 
a 

-
L0 

44 

46 
O 

0 
c40 

M  04 
CL6 W-.0 

04 

0 
0L 
a4.400 

I's0.- 

*. 

0 

44 

0 
10 

-

4 

.0 

0.SL 
2 

M  C L. 

2  ' 

.1 

-
440 

62 

-4 

'r- S  2000'44 A 00'0 

40

NL 

.4 

ol 

6" 

W04 

r 

0 

N9  M44 L 

c. 

C.6 

.

41 

-

0 
N44 

-. 

C1 

V  CIII  0 

0 

00...  6444 

0 
6 

.
V 

L. V 

-a 

2. 

L 

44~; 

4>.0 
4-6r.  LII 
0.A4 
020 I 

.. 45~2.0 

no 
3t 

04 

cL 

0 

0 

444,

4- 
0It A 

A0v* 

0

00

.L 

C 

0L 

.04.. 

to- 
o  c0  M 

4 

-0 

III.  a4 

0 >.4f 

0 

4.

L 
644a

044 
4- 40 > 0 

>400 
04 
N. 
20O 

004 
>4 
J 
LW 

a4- I2 

4 

'n 

D% *0..-  0 

u. 

k 

K00

0 

,a-4 

r- 

C 
M 

r 

m 

44. 

6 

064 
04 

.

0-.  A4 

0>0 

0...C42 

No. 
C 

c  L0 

III. 

04  M 

o 
-

2 

.-0 
.

444u4 

4) 

-0.0 

00 
0 
> 
a4W. 
Mo 
6.4. 

1... 

40 

04 

.. 
L4.-0 0  0
004 
V 
4-  44  .-92 
a. 
0 

a. 

0.  SO- U 
6L 

*0-40 

.0.4 
"I.  I- 

0  6.  0  4 

.. 0.4 
0 43  .

aLa  II.4V

0.-k 

-

4 

N4 

41 4. 2. 

0 

S 
IN 

o 
.C  4)r0 

4 

a"-44za
44. 

.
O  4 
o 

00. 

u  0 

c 
aQ 

6 

ac 

oa0t 

m 

X

*  400

v

.

4.  4W
64- 

a. 

>O

.L:,-

0 

l

V- W3 

00 

u 

4 .

o 

M 

aI

0 

0.>u0 

x 04 

c244 
4- 

6 
0.1 

6 

4-0 

44 
* 

.-. 

4. 
.42 

4- 

W44 

4444 

4. 

404640

00  6 
4c  V 

0.-0 

4.

64. 

4-04 

04-0 ~ 

~ 

A: 
COO v 

.0 

~ 

SO 
4 
c4 

-.
244 

~ 

.0 
NN  0 

00 

V 

S 

C  0) 

0 
0 

4444 

-

04.40 A 
v- 
4 
WO. 
40 

-
5 

4 

a-4 
24 
,~ 
0 
O 

0 
N 
N 

0 
4  -
1  04  Sc 

0''o-04 
-
0 

M.0 

.

:4CO 

4444 

4 

-

4

V

W

-
5 

-
0

4

C 

c 

-

44.. 

.4.. 

>444. 

m4- 

14 

40: 

4.f 

00 

a40 
204.44 
M- 
.44 

001 
l,  4 
-, 
2-  I.JO 

O 

4- 

U 

' 

u~ 
0 

,I 

1 
-.

; 
44  Z44. 
i  M0 

.-.

m, 

C.44 

c-c. 

, 

0c 
.

3~4 .. 6 

.40t ; 

., 

a- 

IS.4.4a

0I, 

O 

0 

0

04444 

m 

0. 

.-

>..O 

.- 4 

64 

-

4.4)-4 

04

N.

46 

0.4 

CLl.  I 

-u 

kca 

44 

~-4* 

.N 

.4 

644 
L 

-

A-iE 

Al.Z 

I  AU~4 

11. 

.

0 

-W  2 

a 

c  a 

a

%404

ONR  DISTRIBUTON  LEST

cmm 

-.

0 

-

.

a 

0 

0

.0 10
a6 0

.0

o 

.

f 

40 

9. 

.! 0 
cA.0 

cc 

c 

0 

4.. 

a4 

a 

, 
60E 0 c0 
0M 

0

0 

1.  0
0 
00 

&3  a 

1 

n 
0 

40 

' 

4. 

044 

1. 

.0 

IO 

. 0

vi.  a 

1 

0.coo 

I 

0

-0 41m 

00 

1- a 

.3C 

Z;C v4C 

n 

.,  - 0 

c c.4I

.4 .

40 

1 

4  6 

c0L 

C 

. 4 0 L, 
6. 

U 

. . 4 4 

". 
C4..- C4'. 

2  1  0  40 

13, 

6.".01 

I.. 

4  I 

0  0 a 

L 6  02 

0 

0  . 4 
0 
0  C.40 o, 

m40 

0 

00 a-
L  WC 0.1

0

:D 

a0M0.aI 

=w 

44064 

ca.. 

.9 .. I 

,-3U m  m  A. 

Q 

0- 

0"

00
Ur

'a~6 

'a 

,%,44

0~~~ 

0. 

0 

0 
0  6  60 
I0 
o. 
00 

0  ~ ~ 

.1- 

0 

~ 

00 
to 
60m 
0L1 

~  ~ 

..

.0 

o  F 
U 00 
1. 
0 
.- 
0 4. 24.4 -
A.OCI 

10 

0 

:: 
's404 
01 

LU 
0.E401.  0: 

L00-0. 

.0.0-2 

0   ( 

0.4 

0  QUNo 
CC 
1 
-4..4 
000 
%. 

~~  ~ 

0 
C. ,0 

L 
W43. 

0: 

*c 

21.29- 0. 

6.. 

u60 'a.- 

0 

10 
0c 
04..1 
"0  00 G, 

16- 

It.44 -1440 

416 

.4.0 

W' 

v.02 

41.0 

0 
z 
u4~1 v41. U% 
> 
a 

U 

o. 
0L.  .) 
0-1 
C, 
1. 
4 
.0A414.I 
1 
660 

.I 

.

44 
>4 

01 

U

0 

v

a 04 

6I.

3 

4*4~ 
.44. 
0 

aM 

4 
0 
U 
0.- 

N410 
M 

.
1 
U 

.
v 
14 
-
0 

0 

.
0 

, 

6.- 
44.044 
6104 
664 
O 

C41.. I  W6S 
) 
-

00 
lot>o 
O 

vCN 
N4.I~C  4.o4  *0 a 

x.. 
O 
.

6 

0 0  Z  .

.

.0 

6 

0  0C 
1 

0 
X4 1 
.41 
.0 
46 
01 
W2-4a; 
* 0 
4J3.4~ 

0...  -
04 
21
0 
>1 

0 

0  -

00

0  001
64. 

26 
2 

42

r. 

40-
U416

.
14

1.

a,
.

0- 

L1.UC2L0  : 60 
60. 

0  L 
0.1 

CL,4#0-v.c 

x 
0 

c  I1IU1 
00411 
240 

L 
0 
.4 

0z 

S. 
t. V 
60  4 
04 
..

1 

C4 

.

00 

0 

0.0 
000 
4 0 
.01. L0.1 

U 
0. 

0 
I~ 
0.4 
41 
1. 
-. SI4 0  a)0 

CM 

0  .D 

-* 

U.M- 

104102 

EJ.0 M0 

.0401 
0 

I-CW44

0. 6  ~

1. 

-I 

04.0
0.0 

c00

w  m

*6 
I

.

6 
a~~4 tol C 

.- 

0 

00

04 

z 

a. 
4.2 

0m 
1 
M2 
Z434 
>  4. 

44 ~ 

IL211C 

a4016 

000 

0% 

W0 

0 

a. 
W6; 

Ot 

66)6 
61. 0- 

n0 

~ 

610 

a 

~ 

2  21, 

0. 

0 
-C 
1.6 

4 

0,  60 
U0- 

r4 U 

.
U  C4 

1 
A.41. 

000 

4M0 

.4-4 
0  4  6 

U 

.

01
0. I

U 
EL 
0 
44 
c 
444. 
60 

>.4. 
a0 
6 
C 

&0 
m1 

0-4mc 

t. 
0.4 

1 

.1 

414  1.0)4 
r!1 

O 

0 
U.  9-- 
.o 

-0 

-: 

n 

.

SCM 
-

6 

0.-4; 

wU0 

A  to 
044 
010. 

-

4LM 
606C 

A64C 

m 
-. 
CY4 

0 
0 
C 
wo4. 

0

4
14  0 
a 
4
a4 00 
Ul 
44 

V  0, 

4412. 

2 

'a. 
.04. 

A~ 

a.6  00 

0606 
0  0 
6.4 

41 
a40C 
00.W" 
w0IS  "  a 
6- 
1  Nf 
M01.1 M 
cc 

-

NAM 
6 

a0C 
6 
c 

CL. 

C 

104.  N1  2 
M 

01-1  O 
-

.1 
6L0 

0C  04 
1.4 

4.4 
L660 

lb

0
44. 

0.4 

2  0 

4.1. 

.060 &6 

c 

444 
c 

0 

.

-

40 

A140  .

41.0

0
x0 -
0
-C

c0 .
1
0  U
40
.40 
V 0  0 

.

0

.60 
2

w0 

44 

-o 

CO.' 

4100 

62  *0 

0 

0 

C01 

60 

0.  60 

C;

U4 

0 

v104 

0..11 
000 

00

I,~I 

* 

cm~4 

6& 

.0 

0 
01 
k 
46 
I-0- 

0  1  4  6 
.
0O.60 

~ 

0. 
(I 

0

1. 

00 

06 
10 

0 

0 

L4 .
0  0 

0 

-0 

a  v4 & 

04( 
0 

00 

00a1 0 
1-1 
LI6 

* 

0 

~ 0I44 

.I 

4 6 0 

1044 
0-4-0 

C 

0 
6 
02  2 

441. 
.600 

4 
a4 
10 

L0 

0  0 
0 
00 

u4 40 
.

.0 
641 

0. 

0 

I  1 

0  04  4

.4

0 

09 

0A
U

0 

1. 
6 

a .

0 

a 

6 

16C 
.43. 

0 
0  0 

.0 

0 

614 

0 0 
4 
4. 

0  0 
6 

a; 

41 

4 
0- 

4,

.
ci 
.
0 

U 

0 
0 
0' 
44 
r I 

.0 

1. 
6. 
0 

0 

.0 

0 
w 
00  1. 
60 
114 
-C 1 
-

U 

0. 
a4 

41 T 
0 
44o
4- 

>

00u
c 

a

62.0 

N

-4

0~ 
444044  0C 

.

2. 
.

.

.

.

.

.

.

L 

.

.

.

o

.

.

.

.

ONR  DISTRIBUTION  LIST

00

03 

o 

0 

.

0 

0 
.
>4 

0 
0 
33 
33 

0

0

0
.
3

03 

300 

S 

0- 
0 

= 

s, 

.
0 

o
0) 
0 

*J 

.a 
0

0

-

5.

033.
0 

t. 

04

3

3

0 

0 
c 
0 

r3 

0  3 

0 

4 

6.4 

w( 

-x 

-3  0 
C 

a0 

31 0  .

: 

3 0.3.  xU t 
0. %.043 W 

0 

VO  .4 

I-  cc 
4, 

33 

* * 
>33-3 

0 

5 
>-  'o 
0  03  .3  0 
-

r4 

.' 

0 

=  u 

W" 

.. 1034.
0 
.

0430 

0 

) 

4333..~ ~~~~~~~~~~  0304.3J 

30 0- 
3 

0 
sa> 
-03.. 
3. 

34.* 

E 

* 

o 

a343 

IQ04 

m.0~ w3  9m1  x3  W 

.03. 

3 0 

3.  3C 

00333 

L3  I 
I 

.

3  30  3 

&3.. 

r-303  OZ  w 

3.3 

3 

3.'2.O3 
00.43. 

043 

oLo, 
3Z

0m 

c 

0 

4 

C
vm 

0 

A 

8 

0c0 

cm3  :!w.4

0 

u 
.
m4 0 
3 
430  4, 

043 0- 

0  m-30 

33 
43 

2. 
34 
U,- 

..

.4 

43 

.3 
30 o30 w 
>3N 

I  a- 

0. 
.

43> 

C,4 

.0 > 
V)33 .3. 

cn 
3.. 
c sa- 
o4 

-

0 

a4434 

6 

o 
n3.0 

)0 

- 0 

34o 

a  0 

0. 

4  a 

&.3 

3 
0 

W 
).4 

0 
.Lo 
43 

u4 3.4 LA 

CC  C~ 

4 

a>  .30 

3g 3c 

,--a 
033 
.43 

5, 

'a3 >504>v 

03 

5 
34 

4334 

333 

3> 
a 

..

*3 

a-34003.3 

,-3 

=43 

0
.

L34 
>0 
0. 

5 

43 

3000 

00, 

.- 30 

m343 

43. 
a~.3. A~.u 

-'a0 53 
>33 
W33 C. 

0.3 
.0i0 
v 

4.0 

N 

34> 

a.43.3 v'. 

!03 

3 

A34 m 

3 

00 

:a 
.
3)  *C30
3.
0( 
4
C0 
12.31 
34
3

a-

.

3
.0 

-

wa 

43 
0 
3.0 
0 
.4.8( 
4 
.40

-
c 43 

03 

.

z 
N.3 

0 

0 

~ 

30*3 * 
3.43.0. 
4300~~~~~~t 

.34>* 

mO..3 

~ 

* 

a 

A3 

0m3.31.3

.

M0.  936 .0. 
m3 
a...0 

.O).s  'a3 

-- 

a 

053 

M.4 

.

3.4 

>.C.. 
33334 

344. 
3-s 

2 

.. 
303 
.53 

3. 

>. 

00 

~ 

0  m 

33.V 
.>s. 
04 
3933 

C

3- 
.30 
3-

3 

0 
.3..-

.*

334 

.0 

N 

4' 

in 

0 

3-- 

34 

(3- 
3 

c- 

Lu 

00 

-

go! 

>353 

0 

333 

-0.  00 

-0 
3 
O- 

c 

1.3 

W)-0aaLWI

0 

0 

e. 34 
o0  o  o, 

043:43 

?  ,34 
M034 

0 

>> 

4.343 

F443 a ON 
3O.4 

.30 

--. 

.43400 
043 
0.3 

a..5  .03 
z 
03 

> 

4. 
0) no 

M033. 

0 
43 
0)O Q34 a43.0  u53 

> 
ar~ 
-0 
I-  t- 

I3 
33 

u-0.3 m 
33 
.0 
a 

C3. 

3433 
430 

nV 

nU 

L 

x 

c  u 
4.

53 

3. 

N

>40 

3 

V 

.

0 L4

5 

404 
V.40 
V 

-

0

N 

um 

=

L

~

3.
34

ao

In4 

3 

1330 

3 

3> 

.

30 

3...- 

.33 

3.34 

3 

13 

.

0 .

3300. 

.034 

33.40 

3 

0. 

0 3 

4 

> 

03.3  344 

433 

43

,. 

m3 

A-3- 

.

\, 

00

*~ 

0 

30 

30 

r

V* 

03 
r *3 
34 

uc

.34 
mc 
0 
.

*S 

0 

L0 

0 

w 

-3 

43 

*3 

30 

-

L 

a3 0
*3 I4 

o

w.  m 

L 

43Z 

3403 

303)3.~ 

43 
N 
V333
0 

3 3  

.

3 
333  3433 

4305',~ 
C'S 
43 
4 

~~~~~~~  3033 

4. 

0 

.0 

~~~~~ 

v0 
003 
03 

N 
.
3 

e3 030 
30 
3 
31*331 
3..0 

>.0 

33. 

£3  03 

03 

'

.

w

C

0 

34 

0 

3.

00:1 
-
3)3 
33 
a3 

0.3. 

.

A0 
>3330 
034 

033 
0 
.0 

0..* 
.3434 
033
034. 

0

-

0 

L 

3
34 
44

A00 
33
a3.* 

