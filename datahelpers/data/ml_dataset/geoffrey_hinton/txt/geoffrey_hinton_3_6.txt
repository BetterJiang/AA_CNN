AISTATS 2005

Proceedings of the
Tenth International Workshop on
Artiﬁcial Intelligence and Statistics

Edited by

Robert Cowell
City University, London

Zoubin Ghahramani
University College London

January 6-8, 2005
The Savannah Hotel, Barbados

Published by The Society for Artiﬁcial Intelligence and
Statistics

The web site for the AISTATS 2005 workshop may be found at

http://www.gatsby.ucl.ac.uk/aistats/

from which individual papers in these proceedings may be downloaded, together with
a bibtex ﬁle with details all of the workshop papers. Citations of articles that appear
in the proceedings should adhere to the format of the following example:

References

[1] Shivani Agarwal, Sariel Har-Peled, and Dan Roth. A uniform convergence bound
for the area under the ROC curve.
In Robert G. Cowell and Zoubin Ghahra-
mani, editors, Proceedings of the Tenth International Workshop on Artiﬁcial In-
telligence and Statistics, Jan 6-8, 2005, Savannah Hotel, Barbados, pages 1–8. So-
ciety for Artiﬁcial Intelligence and Statistics, 2005.
(Available electronically at
http://www.gatsby.ucl.ac.uk/aistats/)

Copyright Notice:

c(cid:1)2005 by The Society for Artiﬁcial Intelligence and Statistics

This volume is published electronically by The Society for Artiﬁcial Intelligence and
Statistics. The copyright of each paper in this volume resides with its authors. These
papers appear in these electronic conference proceedings by the authors’ permission
being implicitly granted by their knowledge that they would be published electronically
by The Society for Artiﬁcial Intelligence and Statistics on the AISTATS 2005 workshop
web site according to the instructions on the AISTATS 2005 workshop Call For Papers
web page.

ISBN 0-9727358-1-X

Contents

Preface v
Acknowledgements vi

A Uniform Convergence Bound for the Area Under the ROC Curve

Shivani Agarwal, Sariel Har-Peled and Dan Roth

On the Path to an Ideal ROC Curve: Considering Cost Asymmetry
in Learning Classiﬁers

Francis Bach, David Heckerman and Eric Horvitz

On Manifold Regularization

Misha Belkin, Partha Niyogi and Vikas Sindhwani

Distributed Latent Variable Models of Lexical Co-occurrences

John Blitzer, Amir Globerson and Fernando Pereira

On Contrastive Divergence Learning

Miguel ´A. Carreira-Perpi˜n´an and Geoﬀrey Hinton

OOBN for Forensic Identiﬁcation through Searching a DNA proﬁles’ Database

David Cavallini and Fabio Corradi

Active Learning for Parzen Window Classiﬁer

Olivier Chapelle

Semi-Supervised Classiﬁcation by Low Density Separation

Olivier Chapelle and Alexander Zien

Learning spectral graph segmentation

Timoth´ee Cour, Nicolas Gogin and Jianbo Shi

A Graphical Model for Simultaneous Partitioning and Labeling

Philip J. Cowans and Martin Szummer

Restructuring Dynamic Causal Systems in Equilibrium

Denver Dash

Probability and Statistics in the Law

Philip Dawid

Eﬃcient Non-Parametric Function Induction in Semi-Supervised Learning

Olivier Delalleau, Yoshua Bengio and Nicolas Le Roux

i

1

9

17

25

33

41

49

57

65

73

81

89

96

Structured Variational Inference Procedures and their Realizations

Dan Geiger and Chris Meek

Kernel Constrained Covariance for Dependence Measurement

Arthur Gretton, Alexander Smola, Olivier Bousquet, Ralf Herbrich, Andrei Be-
litski, Mark Augath, Yusuke Murayama, Jon Pauls, Bernhard Sch¨olkopf and
Nikos Logothetis

Semisupervised alignment of manifolds

Jihun Ham, Daniel Lee and Lawrence Saul

Learning Causally Linked Markov Random Fields

Geoﬀrey Hinton, Simon Osindero and Kejie Bao

Hilbertian Metrics and Positive Deﬁnite Kernels on Probability Measures

Matthias Hein and Olivier Bousquet

Fast Non-Parametric Bayesian Inference on Inﬁnite Trees

Marcus Hutter

Restricted concentration models – graphical Gaussian models with concentration
parameters restricted to being equal

Søren Højsgaard and Steﬀen Lauritzen

Fast maximum a-posteriori inference on Monte Carlo state spaces

Mike Klaas, Dustin Lang and Nando de Freitas

Generative Model for Layers of Appearance and Deformation

Anitha Kannan, Nebojsa Jojic and Brendan Frey

104

112

120

128

136

144

152

158

166

Toward Question-Asking Machines: The Logic of Questions and the Inquiry Calculus

174

Kevin Knuth

Convergent tree-reweighted message passing for energy minimization

Vladimir Kolmogorov

Instrumental variable tests for Directed Acyclic Graph Models

Manabu Kuroki and Zhihong Cai

Estimating Class Membership Probabilities using Classiﬁer Learners

John Langford and Bianca Zadrozny

Loss Functions for Discriminative Training of Energy-Based Models

Yann LeCun and Fu Jie Huang

Probabilistic Soft Interventions in Conditional Gaussian Networks

Florian Markowetz, Steﬀen Grossmann, and Rainer Spang

Unsupervised Learning with Non-Ignorable Missing Data

Benjamin M. Marlin, Sam T. Roweis and Richard S. Zemel

ii

182

190

198

206

214

222

Regularized spectral learning

Marina Meil˘a, Susan Shortreed and Liang Xu

Approximate Inference for Inﬁnite Contingent Bayesian Networks

Brian Milch, Bhaskara Marthi, David Sontag, Stuart Russell, Daniel L. Ong
and Andrey Kolobov

Hierarchical Probabilistic Neural Network Language Model

Frederic Morin and Yoshua Bengio

Greedy Spectral Embedding

Marie Ouimet and Yoshua Bengio

FastMap, MetricMap, and Landmark MDS are all Nystrom Algorithms

John Platt

Bayesian Conditional Random Fields

Yuan Qi, Martin Szummer and Tom Minka

Poisson-Networks: A Model for Structured Poisson Processes
Shyamsundar Rajaram, Graepel Thore and Ralf Herbrich

Deformable Spectrograms

Manuel Reyes-Gomez, Nebojsa Jojic and Daniel Ellis

Variational Speech Separation of More Sources than Mixtures

Steven J. Rennie, Kannan Achan, Brendan J. Frey and Parham Aarabi

230

238

246

253

261

269

277

285

293

Learning Bayesian Network Models from Incomplete Data using Importance Sampling 301

Carsten Riggelsen and Ad Feelders

On the Behavior of MDL Denoising

Teemu Roos, Petri Myllym¨aki and Henry Tirri

Focused Inference

Romer Rosales and Tommi Jaakkola

Kernel Methods for Missing Variables

Alex J. Smola, S. V. N. Vishwanathan and Thomas Hofmann

Semiparametric latent factor models

Yee Whye Teh, Matthias Seeger and Michael I. Jordan

Eﬃcient Gradient Computation for Conditional Gaussian Models

Bo Thiesson and Chris Meek

Very Large SVM Training using Core Vector Machines

Ivor Tsang, James Kwok and Pak-Ming Cheung

iii

309

317

325

333

341

349

Streaming Feature Selection using IIC

Lyle H. Ungar, Jing Zhou, Dean P. Foster and Bob A. Stine

Defensive Forecasting

Vladimir Vovk, Akimichi Takemura and Glenn Shafer

357

365

Inadequacy of interval estimates corresponding to variational Bayesian approximations 373

Bo Wang and D. M. Titterington

Nonlinear Dimensionality Reduction by Semideﬁnite Programming and Kernel
Matrix Factorization

Kilian Weinberger, Benjamin Packer, and Lawrence K. Saul

An Expectation Maximization Algorithm for Inferring Oﬀset-Normal
Shape Distributions

Max Welling

Learning in Markov Random Fields with Contrastive Free Energies

Max Welling and Charles Sutton

Robust Higher Order Statistics

Max Welling

Online (and Oﬄine) on an Even Tighter Budget

Jason Weston, Antoine Bordes and Leon Bottou

Approximations with Reweighted Generalized Belief Propagation

Wim Wiegerinck

Recursive Autonomy Identiﬁcation for Bayesian Network Structure Learning

Raanan Yehezkel and Boaz Lerner

Dirichlet Enhanced Latent Semantic Analysis

Kai Yu, Shipeng Yu and Volker Tresp

Gaussian Quadrature Based Expectation Propagation

Onno Zoeter and Tom Heskes

381

389

397

405

413

421

429

437

445

iv

Preface

The Society for Artiﬁcial Intelligence and Statistics (SAIAS) is dedicated to facilitating in-
teractions between researchers in AI and Statistics. The primary responsibility of the society
is to organize the biennial International Workshops on Artiﬁcial Intelligence and Statistics,
as well as maintain the AI-Stats home page and mailing list on the Internet. The tenth such
meeting took place in January 2005 in Barbados, a new venue for this conference and the ﬁrst
time it had been held outside of the United States of America. Details about the conference
may be found at http://www.gatsby.ucl.ac.uk/aistats/.
Papers from a large number of diﬀerent areas at the interface of statistics and AI were
presented at the workshop. In addition to traditional areas of strength at AISTATS, such
as probabilistic graphical models and approximate inference algorithms, the workshop also
beneﬁtted from high quality presentations in a broader set of new topics, such as semi-
supervised learning, kernel methods, spectral learning, dimensionality reduction, and learning
theory, to name a few. This diversity contributed to a strong and stimulating programme.
A novel feature of this workshop were prizes awarded to students for Best Student Papers.
Three awards were made to Francis Bach, Philip J. Cowans and Kilian Weinberger. This was
made possible by a donation from the NITCA at the Australian National University.
There were approximately 150 submissions. Almost every paper was assigned three reviewers,
other than the program chairs. On the basis of these reviews, 21 papers were selected for
presentation in the plenary session and 36 were selected for the poster sessions, based on their
interest and relevance to the conference and on their originality and clarity of exposition. In
deciding on which papers to accept we drew heavily on the reviews of the program committee.
The standard was rigorous and impartial, and we note in passing that several members of the
program committee had papers rejected.
The United States was the country with the most submissions (57) with Canada (17) and the
United Kingdom (14) being the next largest contributing countries. Most of the remaining
submissions came from Europe, with submissions from Belgium, Denmark, Finland, France,
Germany, Ireland, Italy, Slovakia, Slovenia, Spain, Switzerland and The Netherlands. Papers
submitted from outside of Europe and North America originated from Algeria, Australia,
Brazil, Chile, Hong Kong, Iran, Israel, Japan, Malaysia and Russia. This range of countries
emphasizes the truly international character of the conference. It is worth noting that several
papers had their co-authors based in diﬀerent countries.
Equal acceptance criteria were used for all submissions, and our decision of how each paper
was presented was aimed at creating a varied programme rather than drawing a distinction
between poster papers and plenary papers. Accordingly, in these proceedings we have ordered
all of the papers alphabetically by the lead author’s name. The conference web page may be
consulted to see how individual papers were presented.

Robert Cowell and Zoubin Ghahramani, Program Chairs

v

Acknowledgements

The volume would not exist without the help of many people: the authors, the reviewers, the
participants, the sponsors, and the Society for Artiﬁcial Intelligence and Statistics.
We should like to thank our invited speakers: Craig Boutilier, of the Department of Com-
puter Science University of Toronto, who talked about “Regret-based Methods for Decision
Making and Preference Elicitation”; Nir Friedman, of the School of Computer Science and
Engineering, Hebrew University, who described “Probabilistic Models for Identifying Regula-
tion Networks: From Qualitative to Quantitative Models”; Tom Minka, of Microsoft Research
(Cambridge, UK), who spoke about “Some Intuitions About Message Passing”, and Steﬀen
Lauritzen, of the Department of Statistics at the University of Oxford, who talked about
“Identiﬁcation and Separation of DNA Mixtures using Peak Area Information”. Regrettably,
our ﬁfth invited speaker, Tommi Jaakkola of the MIT Computer Science and Artiﬁcial Intel-
ligence Laboratory was unable to attend the meeting.
We are also very grateful to all authors: authors of plenary papers, poster papers and those
authors whose papers, though submitted, were not included in the conference program, which
resulted in work of such a high standard.
We would like to thank our sponsors, NITCA at the Australian National University for the
prize money for the Best Student Paper awards, and also Microsoft Research and the European
PASCAL initiative for donations towards the running costs of the conference.
We would also like to thank Mrs. Faye Wharton-Parris of Premier Events, who took care
among other things of local arrangements such as collecting registration fees, organizing ac-
commodation and transportation between hotels, multimedia hire and wireless networking
within the conference room. Her company’s professional services ensured that the day-to-day
running of the conference went smoothly.
Special thanks also to Katherine Heller at the Gatsby Unit, who designed and maintained
the website, and helped with numerous aspects of the conference organization; to Daryl
Pregibon at Google who handled ﬁnances for the deposits; and to Chani Johnson and others
of Microsoft Research, who maintained the Conference Management Toolkit with which the
reviewing process was coordinated.
Finally, we would especially like to thank the members of the program committee and a
few external reviewers for agreeing to give up their time to review papers. The thorough
and conscientious reviews of their allocated papers, which they carried out in a short period
of time, ensured a high standard of presentations for the conference. The members of the
program committee are listed on the following page.

vi

Program Committee

David Madigan, Rutgers University
Chris Meek, Microsoft Research
Marina Meil˘a, University of Washington
Tom Minka, Microsoft Research
Quaid Morris, University of Toronto
Iain Murray, Gatsby Unit
Kevin Murphy, MIT
Petri Myllym¨aki, University of Helsinki
Nuria Oliver, Microsoft Research
Manfred Opper, University of Southampton
Fernando P´erez-Cruz, Gatsby Unit
John Platt, Microsoft Research
Thomas Richardson, University of Washington
Imre Risi Kondor, Columbia University
Michal Rosen-Zvi, University of California, Irvine
Sam Roweis, University of Toronto
Lawrence Saul, University of Pennsylvania
Dale Schuurmans, University of Alberta
Paola Sebastiani, Boston University

Yasemin Altun, Brown University
Hagai Attias, Golden Metallic, Inc.
Francis Bach, University of California, Berkeley
Matthew Beal, SUNY Buﬀalo
Yoshua Bengio, University of Montreal
Christopher Bishop, Microsoft Research
David Blei, University of California, Berkeley
Olivier Bousquet, Pertinence
Wray Buntine, HIIT
Olivier Chapelle, Max Planck Institute
Guido Consonni, University of Pavia
Greg Cooper, University of Pittsburgh
Adrian Corduneanu, MIT
Denver Dash, Intel Research
Phil Dawid, University College London
Nando de Freitas, University of British Columbia
Vanessa Didelez, University College London
Michael Duﬀ, Trinity College
Nir Friedman, Hebrew University of Jerusalem
Dan Geiger, Technion - Israel Inst. of Technology Matthias Seeger, University of California, Berkeley
Lise Getoor, University of Maryland
Paolo Giudici, University of Pavia
Tom Griﬃths, Stanford University
Peter Grunwald, CWI, Netherlands
Carlos Guestrin, Carnegie Mellon University
David Heckerman, Microsoft Research
Ralf Herbrich, Microsoft Research
Tom Heskes, University of Nijmegen
Thomas Hofmann, Brown University
Chris Holmes, University of Oxford
Tommi Jaakkola, MIT
Nebojsa Jojic, Microsoft Research
Anitha Kannan, University of Toronto
Uﬀe Kjærulﬀ, Aalborg University
John Laﬀerty, Carnegie Mellon University
John Langford, TTI - Chicago
Neil Lawrence, University of Sheﬃeld
Guy Lebanon, Carnegie Mellon University
Juan Lin, Rutgers University

Prakash Shenoy, University of Kansas
Yoram Singer, Hebrew University of Jerusalem
Jim Smith, University of Warwick
Alex Smola, Australian National University
Bo Thiesson, Microsoft Research
Henry Tirri, University of Helsinki
Volker Tresp, Siemens Research
Linda van der Gaag, University of Utrecht
Vladimir Vovk, Royal Holloway University of London
Martin Wainwright, University of California, Berkeley
Max Welling, University of California, Irvine
Jason Weston, NEC Labs America
Joe Whittaker, Lancaster University
Yee Whye Teh, University of California, Berkeley
Chris Williams, University of Edinburgh
John Winn, Microsoft Research
Eric Xing, Carnegie Mellon University
Xiaojin Zhu, Carnegie Mellon University

vii

A Uniform Convergence Bound for the Area Under the ROC Curve

Shivani Agarwal, Sariel Har-Peled and Dan Roth

Department of Computer Science

University of Illinois at Urbana-Champaign

201 N. Goodwin Avenue
Urbana, IL 61801, USA

{sagarwal,sariel,danr}@cs.uiuc.edu

Abstract

The area under the ROC curve (AUC) has been
advocated as an evaluation criterion for the bi-
partite ranking problem. We study uniform con-
vergence properties of the AUC; in particular, we
derive a distribution-free uniform convergence
bound for the AUC which serves to bound the
expected accuracy of a learned ranking function
in terms of its empirical AUC on the training se-
quence from which it is learned. Our bound is ex-
pressed in terms of a new set of combinatorial pa-
rameters that we term the bipartite rank-shatter
coefﬁcients; these play the same role in our result
as do the standard VC-dimension related shatter
coefﬁcients (also known as the growth function)
in uniform convergence results for the classiﬁca-
tion error rate. A comparison of our result with
a recent uniform convergence result derived by
Freund et al. [9] for a quantity closely related to
the AUC shows that the bound provided by our
result can be considerably tighter.

1 INTRODUCTION

In many learning problems, the goal is not simply to clas-
sify objects into one of a ﬁxed number of classes; instead, a
ranking of objects is desired. This is the case, for example,
in information retrieval problems, where one is interested
in retrieving documents from some database that are ‘rele-
vant’ to a given query or topic. In such problems, one wants
to return to the user a list of documents that contains rele-
vant documents at the top and irrelevant documents at the
bottom; in other words, one wants a ranking of the docu-
ments such that relevant documents are ranked higher than
irrelevant documents.

The problem of ranking has been studied from a learning
perspective under a variety of settings [4, 10, 6, 9]. Here
we consider the setting in which objects come from two
categories, positive and negative; the learner is given exam-
ples of objects labeled as positive or negative, and the goal
is to learn a ranking in which positive objects are ranked

higher than negative ones. This captures, for example, the
information retrieval problem described above; in this case,
training examples consist of documents labeled as relevant
(positive) or irrelevant (negative). This form of ranking
problem corresponds to the ‘bipartite feedback’ case of [9];
we therefore refer to it as the bipartite ranking problem.

Formally, the setting of the bipartite ranking problem is
similar to that of the binary classiﬁcation problem.
In
both problems, there is an instance space X and a set
of two class labels Y = {−1, +1}. One is given
a ﬁnite sequence of labeled training examples S =
((x1, y1), . . . , (xM , yM )) ∈ (X × Y)M , and the goal is to
learn a function based on this training sequence. However,
the form of the function to be learned in the two problems is
different. In classiﬁcation, one seeks a binary-valued func-
tion h : X→Y that predicts the class of a new instance in
X . On the other hand, in ranking, one seeks a real-valued
function f : X → R that induces a ranking over X ; an in-
stance that is assigned a higher value by f is ranked higher
than one that is assigned a lower value by f.

The area under the ROC curve (AUC) has recently gained
attention as an evaluation criterion for the bipartite ranking
problem [5]. Given a ranking function f : X→R and a
data sequence T = ((x1, y1), . . . , (xN , yN )) ∈ (X × Y)N
containing m positive and n negative examples, the AUC
of f with respect to T , denoted ˆA(f; T ), can be expressed
as the following Wilcoxon-Mann-Whitney statistic [5]:

ˆA(f ; T ) =

X

1

mn

X

(cid:16)

(cid:17)

{i:yi=+1}

{j:yj =−1}

I{f (xi)>f (xj )} +

1
2

I{f (xi)=f (xj )}

,

(1)

where I{·} denotes the indicator variable whose value is
one if its argument is true and zero otherwise. The AUC of
f with respect to T is thus simply the fraction of positive-
negative pairs in T that are ranked correctly by f, assuming
that ties are broken uniformly at random.1

The AUC is an empirical quantity that evaluates a ranking
function with respect to a particular data sequence. What

1In [5], a slightly simpler form of the Wilcoxon-Mann-

Whitney statistic is used, which does not account for ties.

1does the empirical AUC tell us about the expected perfor-
mance of a ranking function on future examples? This is
the question we consider. The question has two parts, both
of which are important for machine learning practice. First,
what can be said about the expected performance of a rank-
ing function based on its empirical AUC on an indepen-
dent test sequence? Second, what can be said about the
expected performance of a learned ranking function based
on its empirical AUC on the training sequence from which
it is learned? The ﬁrst question is addressed in [1]; we ad-
dress the second question in this paper.

We start by deﬁning the expected ranking accuracy of a
ranking function (analogous to the expected error rate of a
classiﬁcation function) in Section 2. Section 3 contains our
uniform convergence result, which serves to bound the ex-
pected accuracy of a learned ranking function in terms of its
empirical AUC on a training sequence. Our uniform con-
vergence bound is expressed in terms of a new set of combi-
natorial parameters that we term the bipartite rank-shatter
coefﬁcients; these play the same role in our result as do
the standard shatter coefﬁcients (also known as the growth
function) in uniform convergence results for the classiﬁca-
tion error rate. Properties of the bipartite rank-shatter coef-
ﬁcients are discussed in Section 4. Section 5 compares our
result with a recent uniform convergence result derived by
Freund et al. [9] for a quantity closely related to the AUC.
We conclude with some open questions in Section 6.

2 EXPECTED RANKING ACCURACY

We begin by introducing some notation. As in classiﬁca-
tion, we shall assume that all examples are drawn randomly
and independently according to some (unknown) underly-
ing distribution D over X ×Y. The notation D+1 and D−1
will be used to denote the class-conditional distributions
DX|Y =+1 and DX|Y =−1, respectively. We use an under-
line to denote a sequence, e.g., y ∈ Y N to denote a se-
quence of elements in Y. We shall ﬁnd it convenient to de-
compose a data sequence T = ((x1, y1), . . . , (xN , yN )) ∈
(X × Y)N into two components, TX = (x1, . . . , xN ) ∈
X N and TY = (y1, . . . , yN ) ∈ Y N . Several of our re-
sults will involve the conditional distribution DTX|TY =y
for some label sequence y = (y1, . . . , yN ) ∈ Y N ; this
distribution is simply Dy1 × . . . × DyN .2 As a ﬁnal note
of convention, we use T ∈ (X × Y)N to denote a gen-
eral data sequence (e.g., an independent test sequence), and
S ∈ (X × Y)M to denote a training sequence.

2Note that, since the AUC of a ranking function f with respect
to a data sequence T ∈ (X × Y)N is independent of the actual
ordering of examples in the sequence, our results involving the
conditional distribution DTX|TY =y for some label sequence y =
(y1, . . . , yN ) ∈ Y N depend only on the number m of positive
labels in y and the number n of negative labels in y. We choose to
state our results in terms of the distribution DTX|TY =y ≡ Dy1 ×
+1 × Dn−1.
. . . × DyN only because this is more general than Dm

:
Deﬁnition 1 (Expected ranking accuracy). Let f
X→R be a ranking function on X . Deﬁne the expected
ranking accuracy (or simply ranking accuracy) of f, de-
(cid:27)
noted by A(f), as follows:

(cid:26)

A(f ) = EX∼D+1,X0∼D−1

I{f (X)>f (X0)} +

I{f (X)=f (X0)}

.

1
2

The ranking accuracy A(f) deﬁned above is simply the
probability that an instance drawn randomly according to
D+1 will be ranked higher by f than an instance drawn
randomly according to D−1, assuming that ties are broken
uniformly at random. The following simple lemma shows
that the empirical AUC of a ranking function f is an unbi-
ased estimator of the expected ranking accuracy of f:
Lemma 1. Let f : X→R be a ranking function on X , and
let y = (y1, . . . , yN ) ∈ Y N be a ﬁnite label sequence.
Then

n ˆA(f ; T )
o

ETX|TY =y

= A(f ) .

Proof. Let m be the number of positive labels in y, and n
the number of negative labels in y. Then from the deﬁnition
of empirical AUC (Eq. (1)) and linearity of expectation, we
have
ETX|TY =y
1

n ˆA(f ; T )
o
X

X

n

EXi∼D+1,Xj∼D−1

I{f (Xi)>f (Xj )}

=

mn

{i:yi=+1}

{j:yj =−1}

o

ut

X

X

{i:yi=+1}

{j:yj =−1}

A(f )

=

1

mn

= A(f ) .

+

1
2

I{f (Xi)=f (Xj )}

3 UNIFORM CONVERGENCE BOUND

We are interested in bounding the probability that the em-
pirical AUC of a learned ranking function fS with re-
spect to the (random) training sequence S from which it is
learned will have a large deviation from its expected rank-
ing accuracy, when the function fS is chosen from a pos-
sibly inﬁnite function class F. The standard approach for
obtaining such bounds is via uniform convergence results.
In particular, we have for any  > 0,

(cid:12)(cid:12)(cid:12) ≥ 
n(cid:12)(cid:12)(cid:12) ˆA(fS; S) − A(fS)
(cid:26)

o

P

≤ P

sup
f∈F

(cid:12)(cid:12)(cid:12) ˆA(f ; S) − A(f )
(cid:12)(cid:12)(cid:12) ≥ 

(cid:27)

.

Therefore, to bound probabilities of the form on the left
hand side above, it is sufﬁcient to derive a uniform conver-
gence result that bounds probabilities of the form on the
right hand side. Our uniform convergence result for the
AUC is expressed in terms of a new set of combinatorial
parameters, termed the bipartite rank-shatter coefﬁcients,
that we deﬁne below.

2(cid:2)Bf (x, x

0

)(cid:3)

Deﬁnition 2 (Bipartite rank matrix). Let f : X→R be
a ranking function on X , let m, n ∈ N, and let x =
n) ∈ X n. Deﬁne the
(x1, . . . , xm) ∈ X m, x0 = (x0
bipartite rank matrix of f with respect to x, x0, denoted by
Bf (x, x0), to be the matrix in {0, 1
2 , 1}m×n whose (i, j)-th
element is given by

1, . . . , x0

1
2

ij

j )}

I{f (xi)=f (x0

= I{f (xi)>f (x0

j )} +
for all i ∈ {1, . . . , m}, j ∈ {1, . . . , n}.
Deﬁnition 3 (Bipartite rank-shatter coefﬁcient). Let F
be a class of real-valued functions on X , and let m, n ∈ N.
Deﬁne the (m, n)-th bipartite rank-shatter coefﬁcient of F,
denoted by r(F, m, n), as follows:

(cid:12)(cid:12)(cid:8)Bf (x, x

0

) | f ∈ F(cid:9)(cid:12)(cid:12) .

r(F , m, n) =

max

x∈X m,x0∈X n

Clearly, for ﬁnite F, we have r(F, m, n) ≤ |F| for all
m, n. In general, r(F, m, n) ≤ 3mn for all m, n. In fact,
not all 3mn matrices in {0, 1
2 , 1}m×n can be realized as
bipartite rank matrices. Therefore, we have
r(F , m, n) ≤ ψ(m, n) ,

where ψ(m, n) is the number of matrices in {0, 1
2 , 1}m×n
that can be realized as a bipartite rank matrix. The number
ψ(m, n) can be characterized in the following ways (proof
omitted due to lack of space):

Theorem 1. Let ψ(m, n) be the number of matrices in
{0, 1
2 , 1}m×n that can be realized as a bipartite rank
matrix Bf (x, x0) for some f : X→R, x ∈ X m, x0 ∈ X n.
Then

1. ψ(m, n) is equal to the number of complete mixed
acyclic (m, n)-bipartite graphs (where a mixed
graph is one which may contain both directed and
undirected edges, and where we deﬁne a cycle in such
a graph as a cycle that contains at least one directed
edge and in which all directed edges have the same
directionality along the cycle).
{0, 1
of the forms shown in Table 1.

to the number of matrices in
2 , 1}m×n that do not contain a sub-matrix of any

2. ψ(m, n) is equal

We discuss further properties of the bipartite rank-shatter
coefﬁcients in Section 4; we ﬁrst present below our uniform
convergence result in terms of these coefﬁcients. The fol-
lowing can be viewed as the main result of this paper. We
note that our results are all distribution-free, in the sense
that they hold for any distribution D over X × Y.

Table 1: Sub-matrices that cannot appear in a bipartite
rank matrix.

(cid:2)1
(cid:2)1
(cid:2)½

½

0

1

(cid:3)(cid:2)½
(cid:3)(cid:2)1
(cid:3)(cid:2)½

½

0

1

0
1
0
½
½
0

(cid:3)(cid:2)1
(cid:3)(cid:2)½
(cid:3)(cid:2)½

½

0

½

(cid:3)(cid:2)1
(cid:3)(cid:2)½
(cid:3)(cid:2)0

0

(cid:3)(cid:2)1
(cid:3)(cid:2)½
(cid:3)(cid:2)0

½

(cid:3)(cid:2)½
(cid:3)(cid:2)0
(cid:3)(cid:2)0

0

0
1
½
½

0
½
0

½

½

0
½
½
½
1
½
½

1

½
1
0
½
1
0

0
1
½
½
1
½

½
1

1
0

1
1
½

(cid:3)(cid:2)½
(cid:3)(cid:2)½
(cid:3)(cid:2)0

0

1

½

(cid:3)(cid:2)½
(cid:3)(cid:2)0
(cid:3)(cid:2)½

½

1

½

0
½
1
0
½
½

(cid:3)(cid:2)1
(cid:3)(cid:2)0
(cid:3)(cid:2)½

0

1

½

(cid:3)(cid:2)1
(cid:3)(cid:2)0
(cid:3)(cid:2)½

½

½

1

½
½
1
½
½
0

0
1
½
0
1
½

(cid:3)
(cid:3)
(cid:3)

½
1
1
0
½
½

Theorem 2. Let F be a class of real-valued functions on
X , and let y = (y1, . . . , yM ) ∈ Y M be any label sequence
of length M ∈ N. Let m be the number of positive labels
in y, and n = M − m the number of negative labels in y.
Then for any  > 0,

(cid:26)

(cid:12)(cid:12)(cid:12) ˆA(f ; S) − A(f )
(cid:12)(cid:12)(cid:12) ≥ 

(cid:27)

PSX|SY =y

sup
f∈F

≤ 4 · r(F , 2m, 2n) · e

−mn2/8(m+n) .

The proof is adapted from uniform convergence proofs for
the classiﬁcation error rate (see, for example, [2, 8]). The
main difference is that since the AUC cannot be expressed
as a sum of independent random variables, more powerful
inequalities are required. In particular, a result of Devroye
[7] is required to bound the variance of the AUC that ap-
pears after an application of Chebyshev’s inequality, and
McDiarmid’s inequality [12] is required in the ﬁnal step of
the proof where Hoeffding’s inequality sufﬁced in the case
of classiﬁcation. Details are given in Appendix A.

We note that the result of Theorem 2 can be strengthened
so that the conditioning is only on the numbers m and n of
positive and negative labels, and not on the speciﬁc label
vector y.3 From Theorem 2, we can derive a conﬁdence
interval interpretation of the bound as follows:
Corollary 1. Let F be a class of real-valued functions on
X , and let y = (y1, . . . , yM ) ∈ Y M be any label sequence
of length M ∈ N. Let m be the number of positive labels
in y, and n = M − m the number of negative labels in y.
Then for any 0 < δ ≤ 1,

(
s

sup
f∈F

(cid:12)(cid:12)(cid:12) ˆA(f ; S) − A(f )
(cid:12)(cid:12)(cid:12) ≥
8(m + n)(cid:0)ln r(F , 2m, 2n) + ln(cid:0) 4

(cid:1)(cid:1)

)

≤ δ .

δ

PSX|SY =y

mn

Proof. This follows directly from Theorem 2 by setting 4 ·
r(F, 2m, 2n) · e−mn2/8(m+n) = δ and solving for . ut

As in the case of the large deviation bound of [1], the con-
ﬁdence interval above can be generalized to remove the
conditioning on the label vector completely (we note that
Theorem 2 cannot be generalized in this manner):
Theorem 3. Let F be a class of real-valued functions on
X , and let M ∈ N. Then for any 0 < δ ≤ 1,
s

(
8(cid:0)ln r (F , 2ρ(SY )M, 2(1 − ρ(SY ))M ) + ln(cid:0) 4

(cid:12)(cid:12)(cid:12) ˆA(f ; S) − A(f )
(cid:12)(cid:12)(cid:12) ≥

PS∼DM

(cid:1)(cid:1)

)

sup
f∈F

δ

≤ δ ,

ρ(SY )(1 − ρ(SY ))M

where ρ(SY ) denotes the proportion of positive labels in
SY .

3Our thanks to an anonymous reviewer for pointing this out.

34 PROPERTIES OF BIPARTITE

RANK-SHATTER COEFFICIENTS

As discussed above, we have r(F, m, n) ≤ ψ(m, n),
where ψ(m, n) is the number of matrices in {0, 1
2 , 1}m×n
that can be realized as a bipartite rank matrix. The number
ψ(m, n) is strictly smaller than 3mn, but is still very large;
in particular, ψ(m, n) ≥ 3max(m,n).
(To see this, note
that choosing any column vector in {0, 1
2 , 1}m and repli-
cating it along the n columns or choosing any row vector
2 , 1}n and replicating it along the m rows results in
in {0, 1
a matrix that does not contain a sub-matrix of any of the
forms shown in Table 1. The conclusion then follows from
Theorem 1 (Part 2).) For the bound of Theorem 2 to be
meaningful, one needs an upper bound on r(F, m, n) that
is at least slightly smaller than emn/8(m+n). Below we pro-
vide one method for deriving upper bounds on r(F, m, n);
taking Y∗ = {−1, 0, +1}, we extend slightly the standard
shatter coefﬁcients studied in classiﬁcation to Y∗-valued
function classes, and then derive an upper bound on the
bipartite rank-shatter coefﬁcients r(F, m, n) of a class of
ranking functions F in terms of the shatter coefﬁcients of a
class of Y∗-valued functions derived from F.
Deﬁnition 4 (Shatter coefﬁcient). Let Y∗ = {−1, 0, +1},
and let H be a class of Y∗-valued functions on X . Let
N ∈ N. Deﬁne the N-th shatter coefﬁcient of H, denoted
by s(H, N), as follows:
s(H, N ) = max
x∈X N

(h(x1), . . . , h(xN )) | h ∈ Ho(cid:12)(cid:12)(cid:12) .

(cid:12)(cid:12)(cid:12)n

Clearly, s(H, N) ≤ 3N for all N. Next we deﬁne a series
of Y∗-valued function classes derived from a given ranking
function class. Only the second function class is used in
this section; the other two are needed in Section 5. Note
that we take

 +1

0
−1

if u > 0
if u = 0
if u < 0 .

sign(u) =

Deﬁnition 5 (Function classes). Let F be a class of real-
valued functions on X . Deﬁne the following classes of Y∗-
valued functions derived from F:

n ¯f : X→Y∗ | ¯f (x) = sign(f (x))
for some f ∈ Fo
n ˜f : X × X→Y∗ | ˜f (x, x
for some f ∈ Fo
n ˇfz : X→Y∗ | ˇfz(x) = sign(f (x) − f (z))
for some f ∈ F, z ∈ Xo

0

(2)
) = sign(f (x) − f (x
0

))

(3)

(4)

¯F =

1 .

˜F =

2 .

ˇF =

3 .

Theorem 4. Let F be a class of real-valued functions on
X , and let ˜F be the class of Y∗-valued functions on X ×X
deﬁned by Eq. (3). Then for all m, n ∈ N,
r(F , m, n) ≤ s( ˜F , mn) .

Proof. For any m, n ∈ N, we have4
r(F , m, n)

max

x∈X m,x0∈X n

I{f (xi)>f (x0

j )} +

I{f (xi)=f (x0

j )}

1
2

(cid:21) (cid:12)(cid:12)(cid:12)(cid:12) f ∈ F
(cid:27)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:27)(cid:12)(cid:12)(cid:12)(cid:12)
(cid:21) (cid:12)(cid:12)(cid:12) ˜f ∈ ˜F

(cid:12)(cid:12)(cid:12)(cid:12)(cid:26)(cid:20)
(cid:12)(cid:12)(cid:12)(cid:12)(cid:26)(cid:20)
(cid:12)(cid:12)(cid:12)nh ˜f (xi, x
(cid:12)(cid:12)(cid:12)nh ˜f (xij, x
(cid:12)(cid:12)(cid:12)n(cid:16) ˜f (x1, x

I{ ˜f (xi,x0
0
j)

=

=

=
≤

max

x∈X m,x0∈X n

max

x∈X m,x0∈X n

max

X,X0∈X m×n

max

=
x,x0∈X mn
= s( ˜F , mn) .

I{ ˜f (xi,x0

j )=0}

1
2

j )=+1} +

i (cid:12)(cid:12)(cid:12) ˜f ∈ ˜Fo(cid:12)(cid:12)(cid:12)
i (cid:12)(cid:12)(cid:12) ˜f ∈ ˜Fo(cid:12)(cid:12)(cid:12)

0
ij)

0
0
1), . . . , ˜f (xmn, x
mn)

(cid:17) (cid:12)(cid:12)(cid:12) ˜f ∈ ˜Fo(cid:12)(cid:12)(cid:12)

ut

Below we make use of the above result to derive a polyno-
mial upper bound on the bipartite rank-shatter coefﬁcients
for the case of linear ranking functions. We note that the
same method can be used to establish similar upper bounds
for higher-order polynomial ranking functions and other al-
gebraically well-behaved function classes.
Lemma 2. For d ∈ N, let Flin(d) denote the class of linear
ranking functions on Rd:

f : Rd→R | f (x) = w·x + b

for some w ∈ Rd, b ∈ Ro

.

n
Then for all N ∈ N,

Flin(d) =

s( ˜Flin(d), N) ≤ (2eN/d)d.

n ˜f : Rd × Rd→Y∗ | ˜f (x, x

0

Proof. We have,
˜Flin(d) =

) = sign(w·(x − x
0

for some w ∈ Rdo

.

))

1), . . . , (xN , x0

i) deﬁnes a hyperplane (xi − x0

N ) be any N points in Rd × Rd,
Let (x1, x0
and consider the ‘dual’ weight space corresponding to w ∈
Rd. Each point (xi, x0
i) in
this space; the N points thus give rise to an arrangement of
N hyperplanes in Rd. It is easily seen that the number of
sign patterns ( ˜f(x1, x0
N )) that can be real-
ized by functions ˜f ∈ ˜F is equal to the total number of
! 
dX
faces of this arrangement [11], which is at most [3]

1), . . . , ˜f(xN , x0
 
!

d − k

≤ (2eN/d)d .
k=0
ut
Since the N points were arbitrary, the result follows.
Theorem 5. For d ∈ N, let Flin(d) denote the class of lin-
ear ranking functions on Rd (deﬁned in Lemma 2 above).
Then for all m, n ∈ N,

dX

dX

 

!

i=d−k

N
i

N
i

2i

i=0

=

i

r(Flin(d), m, n) ≤ (2emn/d)d.

Proof. This follows immediately from Theorem 4 and
ut
Lemma 2.
4We use the notation [aij] to denote a matrix whose (i, j)th
element is aij. The dimensions of such a matrix should be clear
from context.

4Figure 1: A comparison of our uniform convergence bound with that of [9] for the class of linear ranking functions on R.
The plots are for δ = 0.01 and show how the conﬁdence interval width  given by the two bounds varies with the sample
size M, for various values of m/(m + n). In all cases where the bounds are meaningful ( < 0.5), our bound is tighter.

5 COMPARISON WITH BOUND OF

FREUND ET AL.

Freund et al. [9] recently derived a uniform convergence
bound for a quantity closely related to the AUC, namely the
ranking loss for the bipartite ranking problem. As pointed
out in [5], the bipartite ranking loss is equal to one minus
the AUC; the uniform convergence bound of [9] therefore
implies a uniform convergence bound for the AUC.5 Al-
though the result in [9] is given only for function classes
considered by their RankBoost algorithm, their technique
is generally applicable. We state their result below, using
our notation, for the general case (i.e., function classes not
restricted to those considered by RankBoost), and then of-
fer a comparison of our bound with theirs. As in [9], the
result is given in the form of a conﬁdence interval.6
Theorem 6 (Generalization of [9], Theorem 3). Let F
be a class of real-valued functions on X , and let y =
(y1, . . . , yM ) ∈ Y M be any label sequence of length
M ∈ N. Let m be the number of positive labels in y, and
n = M − m the number of negative labels in y. Then for
(
any 0 < δ ≤ 1,
s

(cid:12)(cid:12)(cid:12) ≥
(cid:12)(cid:12)(cid:12) ˆA(f ; S) − A(f )
s
ln s( ˇF , 2n) + ln(cid:0) 12

ln s( ˇF , 2m) + ln(cid:0) 12

PSX|SY =y

)

sup
f∈F

(cid:1)

(cid:1)

≤ δ ,
2
where ˇF is the class of Y∗-valued functions on X deﬁned
by Eq. (4).

+ 2

m

n

δ

δ

5As in the AUC deﬁnition of [5], the ranking loss deﬁned in

[9] does not account for ties; this is easily remedied.

6The result in [9] was stated in terms of the VC dimension,
but the basic result can be stated in terms of shatter coefﬁcients.
Due to our AUC deﬁnition which accounts for ties, the standard
shatter coefﬁcients are replaced here with the extended shatter co-
efﬁcients deﬁned above for Y∗-valued function classes.

The proof follows that of [9] and is omitted. We now
compare the uniform convergence bound derived in Sec-
tion 3 with that of Freund et al. for a simple function
class for which the quantities involved in both bounds
(namely, r(F, 2m, 2n) and s( ˇF, 2m), s( ˇF, 2n)) can be
characterized exactly. Speciﬁcally, consider the function
class Flin(1) of linear ranking functions on R, given by

Flin(1) = {f : R→R | f(x) = wx + b

for some w ∈ R, b ∈ R} .
Although Flin(1) is an inﬁnite function class, it is easy to
verify that r(Flin(1), m, n) = 3 for all m, n ∈ N. (To see
this, note that for any set of m + n distinct points in R,
one can obtain exactly three different ranking behaviours
with functions in Flin(1): one by setting w > 0, another by
setting w < 0, and the third by setting w = 0.) On the
other hand, s( ˇFlin(1), N) = 4N + 1 for all N ≥ 2, since
ˇFlin(1) = ¯Flin(1) (see Eq. (2)) and, as is easily veriﬁed, the
number of sign patterns on N ≥ 2 distinct points in R that
can be realized by functions in ¯Flin(1) is 4N + 1. We thus
get from our result (Corollary 1) that

(cid:1)(cid:1)

(cid:12)(cid:12)(cid:12) ˆA(f ; S) − A(f )
(cid:12)(cid:12)(cid:12) ≥
s
8(m + n)(cid:0)ln 3 + ln(cid:0) 4
(cid:12)(cid:12)(cid:12) ˆA(f ; S) − A(f )
(cid:12)(cid:12)(cid:12) ≥
(cid:1)
ln(8n + 1) + ln(cid:0) 12

s

mn

δ

δ

δ

+ 2

n

)

≤ δ ,

)

(cid:1)

≤ δ .

(

(

PSX|SY =y

sup

f∈Flin(1)

s

PSX|SY =y

sup

f∈Flin(1)

ln(8m + 1) + ln(cid:0) 12

2

m

and from the result of Freund et al. (Theorem 6) that

The above bounds are plotted in Figure 1 for δ = 0.01 and
various values of m/(m + n). As can be seen, the bound
provided by our result is considerably tighter.

56 CONCLUSION & OPEN QUESTIONS

References

We have derived a distribution-free uniform convergence
bound for the area under the ROC curve (AUC), a quan-
tity used as an evaluation criterion for the bipartite rank-
ing problem. Our bound is expressed in terms of a new
set of combinatorial parameters that we have termed the
bipartite rank-shatter coefﬁcients. These coefﬁcients de-
ﬁne a new measure of complexity for real-valued function
classes and play the same role in our result as do the stan-
dard VC-dimension related shatter coefﬁcients in uniform
convergence results for the classiﬁcation error rate.
For the case of linear ranking functions on R, for which
we could compute the bipartite rank-shatter coefﬁcients ex-
actly, we have shown that our uniform convergence bound
is considerably tighter than a recent bound of Freund et al.
[9], which is expressed directly in terms of standard shatter
coefﬁcients from results for classiﬁcation. This suggests
that the bipartite rank-shatter coefﬁcients we have intro-
duced may be a more appropriate complexity measure for
studying the bipartite ranking problem. However, in or-
der to take advantage of our results, one needs to be able
to characterize these coefﬁcients for the class of ranking
functions of interest. The biggest open question that arises
from our study is, for what other function classes F can
the bipartite rank-shatter coefﬁcients r(F, m, n) be char-
acterized? We have derived in Theorem 4 a general upper
bound on the bipartite rank-shatter coefﬁcients of a func-
tion class F in terms of the standard shatter coefﬁcients of
the function class ˜F (see Eq. (3)); this allows us to estab-
lish a polynomial upper bound on the bipartite rank-shatter
coefﬁcients for linear ranking functions on Rd and other
algebraically well-behaved function classes. However, this
upper bound is inherently loose (see proof of Theorem 4).
Is it possible to ﬁnd tighter upper bounds on r(F, m, n)
than that given by Theorem 4?

Our study also raises several other interesting questions.
First, can we establish analogous complexity measures and
generalization bounds for other forms of ranking problems
(i.e., other than bipartite)? Second, do there exist data-
dependent bounds for ranking, analogous to existing mar-
gin bounds for classiﬁcation? Finally, it also remains an
open question whether tighter generalization bounds for the
AUC can be derived using different proof techniques.

Acknowledgements
We would like to thank Thore Graepel and Ralf Herbrich
for discussions related to this work and for pointing out to
us the graph-based interpretation of bipartite rank matrices
used in Theorem 1. We are also very grateful to an anony-
mous reviewer, and to Thore Graepel and Ralf Herbrich
again, for helping us identify an important mistake in an
earlier version of our results. This research was supported
in part by NSF ITR grants IIS 00-85980 and IIS 00-85836
and a grant from the ONR-TRECC program.

[1] Shivani Agarwal, Thore Graepel, Ralf Herbrich, and
Dan Roth. A large deviation bound for the area under
the ROC curve. In Advances in Neural Information
Processing Systems 17. MIT Press, 2005. To appear.

[2] Martin Anthony and Peter Bartlett. Learning in Neu-
ral Networks: Theoretical Foundations. Cambridge
University Press, 1999.

[3] R. C. Buck. Partition of space. American Mathemat-

ical Monthly, 50:2541–544, 1943.

[4] William W. Cohen, Robert E. Schapire, and Yoram
Singer. Learning to order things. Journal of Artiﬁcial
Intelligence Research, 10:243–270, 1999.

[5] Corinna Cortes and Mehryar Mohri. AUC optimiza-
tion vs. error rate minimization. In Advances in Neu-
ral Information Processing Systems 16. MIT Press,
2004.

[6] Koby Crammer and Yoram Singer. Pranking with
ranking. In Advances in Neural Information Process-
ing Systems 14, pages 641–647. MIT Press, 2002.

[7] Luc Devroye. Exponential inequalities in nonpara-
metric estimation.
In G. Roussas, editor, Nonpara-
metric Functional Estimation and Related Topics,
NATO ASI Series, pages 31–44. Kluwer Academic
Publishers, 1991.

[8] Luc Devroye, L´aszl´o Gy¨orﬁ, and G´abor Lugosi.
A Probabilistic Theory of Pattern Recognition.
Springer-Verlag, New York, 1996.

[9] Yoav Freund, Raj Iyer, Robert E. Schapire, and
Yoram Singer. An efﬁcient boosting algorithm for
combining preferences. Journal of Machine Learn-
ing Research, 4:933–969, 2003.

[10] Ralf Herbrich, Thore Graepel, and Klaus Obermayer.
Large margin rank boundaries for ordinal regression.
Advances in Large Margin Classiﬁers, pages 115–
132, 2000.

[11] Jiˇr´ı Matouˇsek.

Lectures on Discrete Geometry.

Springer-Verlag, New York, 2002.

[12] Colin McDiarmid. On the method of bounded dif-
In Surveys in Combinatorics 1989, pages

ferences.
148–188. Cambridge University Press, 1989.

A Proof of Theorem 2

Our proof makes use of the following two results [12, 7]
that bound the probability of a large deviation and the vari-
ance, respectively, of any function of a sample for which a
single change in the sample has limited effect:

6Theorem 7 (McDiarmid, 1989). Let X1, . . . , XN be in-
dependent random variables with Xk taking values in a set
Ak for each k. Let φ : (A1 × ··· × AN )→R be such that

(cid:12)(cid:12)(cid:12)φ(x1, . . . , xN ) −

sup
xi∈Ai,x0

k∈Ak

0
φ(x1, . . . , xk−1, x
k, xk+1, . . . , xN )

Then for any  > 0,

P{|φ(X1, . . . , XN ) − E{φ(X1, . . . , XN )}| ≥ }
−22/PN

≤ 2e

k=1 c2

k .

(cid:12)(cid:12)(cid:12) ≤ ck .

Theorem 8 (Devroye, 1991; Devroye et al., 1996, Theo-
rem 9.3). Under the conditions of Theorem 7,

Var{φ(X1, . . . , XN )} ≤ 1
4

c2
k .

NX

k=1

The following lemma establishes that a change in a single
instance in a data sequence has a limited effect on the AUC
of a ranking function with respect to the data sequence:
Lemma 3. Let f : X→R be a ranking function on X and
let y = (y1, . . . , yN ) ∈ Y N be a ﬁnite label sequence. Let
m be the number of positive labels in y and n the number of
negative labels in y. Let φ : X N→R be deﬁned as follows:

φ (x1, . . . , xN ) = ˆA (f ; ((x1, y1), . . . , (xN , yN ))) .

Then for all xi, x0

(cid:12)(cid:12)φ(x1, . . . , xN ) − φ(x1, . . . , xk−1, x

k ∈ X ,

k, xk+1 . . . , xN )(cid:12)(cid:12) ≤ ck ,

0

where ck = 1/m if yk = +1 and ck = 1/n if yk = −1.

Proof. For each k such that yk = +1, we have

(cid:12)(cid:12)φ(x1, . . . , xN ) − φ(x1, . . . , xk−1, x

k, xk+1 . . . , xN )(cid:12)(cid:12)

0

I{f (xk)>f (xj )} +

I{f (xk)=f (xj )}

=

1

mn

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) X

{j:yj =−1}

(cid:18)(cid:16)
−(cid:16)

1
2

1
2

≤

=

n

1

mn
1
m

.

The case yk = −1 can be proved similarly.

ut

We are now ready to give the main proof:

Proof (of Theorem 2). The proof is adapted from proofs of
uniform convergence for the classiﬁcation error rate given
in [2, 8]. It consists of four steps.

Step 1. First symmetrization by a ghost sample.
For each k ∈ {1, . . . , M}, deﬁne the random variable
˜Xk such that Xk, ˜Xk are independent and identically dis-
tributed. Let ˜SX = ( ˜X1, . . . , ˜XM ), and denote by ˜S the

.

2

sup
f∈F

(cid:27)

(cid:26)

PSX|SY =y

(cid:27)
S; S)−
S be a ﬁxed

joint sequence ( ˜SX , y). Then for any  > 0 satisfying
mn2/(m + n) ≥ 2, we have
(cid:26)

sup
f∈F
≤ 2PSX
To see this, let f∗
A(f∗
function in F otherwise. Then

˜SX|SY =y
S ∈ F be a function for which | ˆA(f∗
(cid:26)

(cid:12)(cid:12)(cid:12) ˆA(f ; S) − A(f )
(cid:12)(cid:12)(cid:12) ≥ 
(cid:12)(cid:12)(cid:12) ˆA(f ; S) − ˆA(f ; ˜S)
(cid:12)(cid:12)(cid:12) ≥ 
S)| ≥  if such a function exists, and let f∗
(cid:27)
(cid:12)(cid:12)(cid:12) ˆA(f ; S) − ˆA(f ; ˜S)
(cid:12)(cid:12)(cid:12) ≥ 
(cid:12)(cid:12)(cid:12) ≥ 
n(cid:12)(cid:12)(cid:12) ˆA(f
o
(cid:12)(cid:12)(cid:12) ≥ 
nn(cid:12)(cid:12)(cid:12) ˆA(f
o∩
(cid:12)(cid:12)(cid:12) ≤ 
n(cid:12)(cid:12)(cid:12) ˆA(f
(cid:12)(cid:12)(cid:12) ≤ 
n(cid:12)(cid:12)(cid:12) ˆA(f
oo

S; ˜S) − A(f
∗
S )|≥}×
S; ˜S) − A(f
∗

˜SX|SY =y
≥ PSX
≥ PSX

S; S) − ˆA(f
∗
S; S) − A(f
∗

= ESX|SY =y

P ˜SX|SX ,SY =y

S ;S)−A(f∗

oo

˜SX|SY =y

˜SX|SY =y

∗
S; ˜S)

I{| ˆA(f∗

sup
f∈F

PSX

n

∗
S)

∗
S)

∗
S)

(5)

2

2

2

.

2

The conditional probability inside can be bounded using
Chebyshev’s inequality (and Lemma 1):

P ˜SX|SX ,SY =y

S; ˜S) − A(f
∗

∗
S)

n(cid:12)(cid:12)(cid:12) ˆA(f

≤ 1
4

n ˆA(f
n(cid:12)(cid:12)(cid:12) ˆA(f
(cid:26)

o

(cid:12)(cid:12)(cid:12) ≤ 

2

n ˆA(f∗

S; ˜S)

o

.

.

≥ 1 − Var ˜SX|SX ,SY =y

2/4

o
(cid:16) 1

m + n
4mn

n

=

m

m

+ n

(cid:18)

∗
S; ˜S)

(cid:17)2(cid:19)
(cid:16) 1
(cid:17)2
(cid:12)(cid:12)(cid:12) ≤ 
o ≥ 1− m + n
(cid:27)
(cid:12)(cid:12)(cid:12) ˆA(f ; S) − ˆA(f ; ˜S)
(cid:12)(cid:12)(cid:12) ≥ 
n
n(cid:12)(cid:12)(cid:12) ˆA(f
(cid:26)

o
(cid:12)(cid:12)(cid:12) ≥ 
o
(cid:12)(cid:12)(cid:12) ≥ 
(cid:12)(cid:12)(cid:12) ˆA(f ; S) − A(f )

I{| ˆA(f∗
S ;S)−A(f∗
S; S) − A(f
∗

S )|≥}

∗
S)

2

sup
f∈F

ESX|SY =y

PSX|SY =y

PSX|SY =y

(cid:27)

.

sup
f∈F
≥ 1
2
1
=
2
≥ 1
2

This gives
mn2 ≥ 1
P ˜SX|SX ,SY =y
whenever mn2/(m + n) ≥ 2. Thus, from Eq. (5) and the
deﬁnition of f∗

S; ˜S) − A(f
∗

∗
S)

S, we have

2

2

,

Now, by Lemma 3 and Theorem 8, we have

Var ˜SX|SX ,SY =y

of

all

set

the

Step 2. Second symmetrization by permutations.
Let ΓM be
of
permutations
{X1, . . . , XM , ˜X1, . . . , ˜XM} that swap Xk and
˜Xk,
for all k in some subset of {1, . . . , M}. In other words, for
all σ ∈ ΓM and k ∈ {1, . . . , M}, either σ(Xk) = Xk, in
which case σ( ˜Xk) = ˜Xk, or σ(Xk) = ˜Xk, in which case
σ( ˜Xk) = Xk. Denote σ(SX) = (σ(X1), . . . , σ(XM )),
and σ( ˜SX) = (σ( ˜X1), . . . , σ( ˜XM )). Now, deﬁne

(cid:17)
(cid:17)(cid:19)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

I{f (x0

k)>f (xj )} +

I{f (x0

k)=f (xj )}

PSX

˜SX|SY =y

7βf (SX , ˜SX ) ≡
1

X

X

mn

{i:yi=+1}

{j:yj =−1}

(cid:18)(cid:16)
−(cid:16)

I{f (Xi)>f (Xj )} +

I{f (Xi)=f (Xj )}

1
2

I{f ( ˜Xi)>f ( ˜Xj )} +

1
2

I{f ( ˜Xi)=f ( ˜Xj )}

(cid:17)
(cid:17)(cid:19)

.

Then clearly, since Xk, ˜Xk are i.i.d. for each k, for any
σ ∈ ΓM we have that the distribution of

sup
f∈F

(cid:12)(cid:12)(cid:12)βf (SX , ˜SX )
(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)βf (σ(SX ), σ( ˜SX ))
(cid:12)(cid:12)(cid:12) .

sup
f∈F

is the same as the distribution of

2

P

= P

sup
f∈F

sup
f∈F

(cid:27)

Therefore, using U(D) to denote the uniform distribu-
tion over a discrete set D, we have the following (note
that except where speciﬁed otherwise, all probabilities and
expectations below are with respect to the distribution
(cid:26)
(cid:27)
(cid:12)(cid:12)(cid:12) ˆA(f ; S) − ˆA(f ; ˜S)
(cid:12)(cid:12)(cid:12) ≥ 
DSX ˜SX|SY =y):
(cid:26)
(cid:12)(cid:12)(cid:12) ≥ 
(cid:12)(cid:12)(cid:12)βf (SX , ˜SX )
(cid:26)
(cid:12)(cid:12)(cid:12)βf (σ(SX ), σ( ˜SX ))
(cid:12)(cid:12)(cid:12) ≥ 
X
n
X
 1
X
(cid:26)

(cid:27)
o

(cid:27)(cid:27)
(cid:12)(cid:12)(cid:12) ≥ 
(cid:12)(cid:12)(cid:12)βf (σ(SX ), σ( ˜SX ))
(cid:27)
(cid:12)(cid:12)(cid:12) ≥ 
(cid:12)(cid:12)(cid:12)βf (σ(x), σ(˜x))

2}
I{supf∈F|βf (σ(SX ),σ( ˜SX ))|≥ 

2}
I{supf∈F|βf (σ(SX ),σ( ˜SX ))|≥ 

≤

max

x,˜x∈X M

Pσ∼U (ΓM )

1
|ΓM|
1
|ΓM|

Pσ∼U (ΓM )

|ΓM|

σ∈ΓM

σ∈ΓM

σ∈ΓM

(cid:26)

(cid:26)

sup
f∈F

sup
f∈F

= E

= E

=

=

P

E

2

2

sup
f∈F

2

2

.

Step 3. Reduction to a ﬁnite class.

We wish to bound the quantity on the right hand side
above. From the deﬁnition of bipartite rank matrices (Def-
inition 2), it follows that for any x, ˜x ∈ X M , as f ranges
over F, the number of different random variables

(cid:12)(cid:12)(cid:12)
(cid:12)(cid:12)(cid:12)βf (σ(x), σ(˜x))

is at most the number of different bipartite rank matrices
Bf (z, z0) that can be realized by functions in F, where
z ∈ X 2m contains xi, ˜xi for i : yi = +1 and z0 ∈ X 2n
contains xj, ˜xj for j : yj = −1. This number, by def-
inition, cannot exceed r(F, 2m, 2n) (see the deﬁnition of
bipartite rank-shatter coefﬁcients, Deﬁnition 3). Therefore,
the supremum in the above probability is a maximum of at
most r(F, 2m, 2n) random variables. Thus, by the union
bound, we get for any x, ˜x ∈ X M ,

(cid:26)

sup
f∈F

Pσ∼U (ΓM )

(cid:27)
(cid:12)(cid:12)(cid:12) ≥ 
(cid:12)(cid:12)(cid:12)βf (σ(x), σ(˜x))
n(cid:12)(cid:12)(cid:12)βf (σ(x), σ(˜x))
(cid:12)(cid:12)(cid:12) ≥ 

Pσ∼U (ΓM )

2

o

.

2

≤ r(F , 2m, 2n) · sup
f∈F

Step 4. McDiarmid’s inequality.
Notice that for any x, ˜x ∈ X M , we can write
Pσ∼U (ΓM )

o

n(cid:12)(cid:12)(cid:12)βf (σ(x), σ(˜x))
(cid:12)(cid:12)(cid:12) ≥ 
= PW∼U(QM
(cid:26) ˜xk,

2

2
where W = (W1, . . . , WM ), ˜W = ( ˜W1, . . . , ˜WM ) and

k=1{xk,˜xk})

n(cid:12)(cid:12)(cid:12)βf (W , ˜W )
(cid:12)(cid:12)(cid:12) ≥ 

o

,

xk,

if Wk = xk
if Wk = ˜xk

˜Wk =
Now, for any f ∈ F,
EW∼U(QM

o
βf (W , ˜W )
since for all i : yi = +1 and j : yj = −1,
EWi∼U ({xi,˜xi}),Wj∼U({xj ,˜xj})

n
n

k=1{xk,˜xk})

.

= 0 ,

=

1
4

= 0 ,

I{f (Wi)>f (Wj )} − I{f ( ˜Wi)>f ( ˜Wj )}

 (cid:0)I{f (xi)>f (xj )} − I{f (˜xi)>f (˜xj )}(cid:1) +
(cid:0)I{f (˜xi)>f (xj )} − I{f (xi)>f (˜xj )}(cid:1) +
(cid:0)I{f (xi)>f (˜xj )} − I{f (˜xi)>f (xj )}(cid:1) +
(cid:0)I{f (˜xi)>f (˜xj )} − I{f (xi)>f (xj )}(cid:1)!
n

I{f (Wi)=f (Wj )} − I{f ( ˜Wi)=f ( ˜Wj )}

o

o

and similarly,

EWi∼U ({xi,˜xi}),Wj∼U({xj ,˜xj})

= 0 .

Also, it can be veriﬁed that for any f ∈ F, a change in
the value of a single random variable Wk can bring about a
change of at most 2/m in the value of

βf (W , ˜W )

for k : yk = +1, and a change of at most 2/n for k : yk =
−1. Therefore, by McDiarmid’s inequality (Theorem 7), it
follows that for any f ∈ F,
PW∼U(QM

n(cid:12)(cid:12)(cid:12)βf (W , ˜W )
(cid:12)(cid:12)(cid:12) ≥ 

k=1{xk,˜xk})

o

2

m )2+n( 2

n )2)

≤ 2e
= 2e

−22/4(m( 2
−mn2/8(m+n) .

(cid:12)(cid:12)(cid:12) ˆA(f ; S) − A(f )
(cid:12)(cid:12)(cid:12) ≥ 

(cid:27)

(cid:26)

Putting everything together, we get that

PSX|SY =y

sup
f∈F

≤ 4 · r(F , 2m, 2n) · e

−mn2/8(m+n) ,

for mn2/(m + n) ≥ 2.
In the other case, i.e., for
mn2/(m + n) < 2, the bound is greater than one and
ut
therefore holds trivially.

8On the Path to an Ideal ROC Curve:

Considering Cost Asymmetry in Learning Classiﬁers

Francis R. Bach∗

Computer Science Division

University of California

Berkeley, CA 94720
fbach@cs.berkeley.edu

Abstract

Receiver Operating Characteristic (ROC)
curves are a standard way to display the per-
formance of a set of binary classiﬁers for all
feasible ratios of the costs associated with
false positives and false negatives. For lin-
ear classiﬁers, the set of classiﬁers is typically
obtained by training once, holding constant
the estimated slope and then varying the in-
tercept to obtain a parameterized set of clas-
siﬁers whose performances can be plotted in
the ROC plane. In this paper, we consider
the alternative of varying the asymmetry of
the cost function used for training. We show
that the ROC curve obtained by varying the
intercept and the asymmetry—and hence the
slope—always outperforms the ROC curve
obtained by varying only the intercept.
In
addition, we present a path-following algo-
rithm for the support vector machine (SVM)
that can compute eﬃciently the entire ROC
curve, that has the same computational prop-
erties as training a single classiﬁer. Finally,
we provide a theoretical analysis of the rela-
tionship between the asymmetric cost model
assumed when training a classiﬁer and the
cost model assumed in applying the classiﬁer.
In particular, we show that the mismatch
between the step function used for testing
and its convex upper bounds usually used for
training leads to a provable and quantiﬁable
diﬀerence around extreme asymmetries.

1 INTRODUCTION

Receiver Operating Characteristic (ROC) analysis has
seen increasing attention in the recent statistics and

∗ This work was done during a summer internship at

Microsoft Research.

David Heckerman & Eric Horvitz

Microsoft Research
Redmond, WA 98052

{heckerman,horvitz}@microsoft.com

machine-learning literature (Pepe, 2000, Provost and
Fawcett, 2001, Flach, 2003). The ROC is a represen-
tation of choice for displaying the performance of a
classiﬁer when the costs assigned by end users to false
positives and false negatives are not known at the time
of training. For example, when training a classifer for
identifying cases of undesirable unsolicited email, end
users may have diﬀerent preferences about the likeli-
hood of a false negative and false positive. The ROC
curve for such a classiﬁer reveals the ratio of false neg-
atives and positives at diﬀerent probability thresholds
for classifying an email message as unsolicited or nor-
mal email.

In this paper, we consider linear binary classiﬁca-
tion of points in an Euclidean space—noting that it
can be extended in a straightforward manner to non-
linear classiﬁcation problems by using Mercer ker-
nels (Sch¨olkopf and Smola, 2002). That is, given data
x ∈ Rd, d > 1, we consider classiﬁers of the form
f (x) = sign(w>x + b), where w ∈ Rd and b ∈ R are re-
ferred to as the slope and the intercept. To date, ROC
curves have been usually constructed by training once,
holding constant the estimated slope and varying the
intercept to obtain the curve. In this paper, we show
that, while the latter procedure appears to be the most
practical thing to do, it may lead to classiﬁers with
poor performance in some parts of the ROC curve.

The crux of our approach is that we allow the asym-
metry of the cost function to vary—i.e., we vary the
ratio of the cost of a false positive and the cost of a
false negative. For each value of the ratio, we obtain
a diﬀerent slope and intercept, each optimized for this
ratio. In a naive implementation, varying the asymme-
try would require a retraining of the classiﬁer for each
point of the ROC curve, which would be computation-
ally expensive. In Section 3.1, we present an algorithm
that can compute the solution of an SVM (Sch¨olkopf
and Smola, 2002) for all possible costs of false posi-
tives and false negatives, with the same computational
complexity as obtaining the solution for only one cost

9function. The algorithm extends to asymmetric costs
the algorithm of Hastie et al. (2005) and is based on
path-following techniques that take advantage of the
piecewise linearity of the path of optimal solutions.
In Section 3.2, we show how the path-following algo-
rithm can be used to obtain the best possible ROC
curve (in expectation). In particular, by allowing both
the asymmetry and the intercept to vary, we can ob-
tain provably better ROC curves than by methods that
simply vary the intercept.

In Section 4, we provide a theoretical analysis of the
link between the asymmetry of costs assumed in train-
ing a classiﬁer and the asymmetry desired in its appli-
cation. In particular, we show that—even in the popu-
lation (i.e., inﬁnite sample) case—the use of a training
loss function which is a convex upper bound on the
true or testing loss function (a step function) creates
classiﬁers with sub-optimal accuracy. We quantify this
problem around extreme asymmetries for several clas-
sical convex-upper-bound loss functions—the square
loss and the erf loss, an approximation of the logistic
loss based on normal cumulative distribution functions
(also referred to as the “error function”, and usually
abbreviated as erf). The analysis is carried through
for Gaussian and mixture of Gaussian class-conditional
distributions (see Section 4 for more details). As we
shall see, the consequences of the potential mismatch
between the cost functions assumed in testing versus
training underscore the value of using the algorithm
that we introduce in Section 4.3. Even when costs are
known (i.e., when only one point on the ROC curve
is needed), the classiﬁer resulting from our approach
which builds the entire ROC curve is never less accu-
rate and can be more accurate than one trained with
the known costs using a convex-upper-bound loss func-
tion.

2 PROBLEM OVERVIEW

Given data x ∈ Rd and labels y ∈ {−1, 1}, we consider
linear classiﬁers of the form f (x) = sign(w>x + b),
where w is the slope of the classiﬁer and b the in-
tercept. A classiﬁer is determined by the parameters
(w, b) ∈ Rd+1. In Section 2.1, we introduce notation
and deﬁnitions; in Section 2.2, we lay out the necessary
concepts of ROC analysis. In Section 2.3, we describe
how these classiﬁers and ROC curves are typically ob-
tained from data.

2.1 ASYMMETRIC COST AND LOSS

FUNCTIONS

Positive (resp. negative) examples are those for which
y = 1 (resp. y = −1). The two types of misclassiﬁ-
cation, false positives and false negatives, are assigned

two diﬀerent costs, and the total expected cost is equal
to
R(C+, C−, w, b) = C+P {w>x + b < 0, y = 1}

+C−P {w>x + b > 0, y = −1}
If we let φ0−1(u) = 1u<0 be the 0-1 loss, we can write
the expected cost as
R(C+, C−, w, b) = C+E{1y=1φ0−1(w>x + b)}

+C−E{1y=−1φ0−1(−w>x − b)}
where E denotes the expectation with respect to the
joint distribution of (x, y). The expected cost deﬁned
using the 0-1 loss is the cost that end users are usu-
ally interested in during the use of the classiﬁer, while
the other cost functions that we deﬁne below are used
solely for training purposes. The convexity of these
cost functions makes learning algorithms convergent
without local minima, and leads to attractive asymp-
totic properties (Bartlett et al., 2004).

A traditional set-up for learning linear classiﬁers from
labeled data is to consider a convex upper bound φ on
the 0-1 loss φ0−1, and use the expected φ-cost :
Rφ(C+, C−, w, b) = C+E{1y=1φ(w>x + b)}

+C−E{1y=−1φ(−w>x − b)}
We refer to the ratio C+/(C− +C+) as the asymmetry.
We shall use training asymmetry to refer to the asym-
metry used for training a classiﬁer using a φ-cost, and
the testing asymmetry to refer to the asymmetric cost
characterizing the testing situation (reﬂecting end user
preferences) with the actual cost based on the 0-1 loss.
In Section 4, we will show that these may be diﬀerent
in the general case.

We shall consider several common loss functions. Some
of the loss functions (square loss, hinge loss) lead
to attractive computational properties, while others
(square loss, erf loss) are more amenable to theoret-
ical manipulations (see Figure 1 for the plot of the
loss functions, as they are commonly used and deﬁned
below1):

• square loss : φsq(u) = 1

2 (u − 1)2; the classiﬁer is

equivalent to linear regression,

• hinge loss : φhi(u) = max{1 − u, 0}; the classi-
ﬁer is the support vector machine (Sch¨olkopf and
Smola, 2002),

: φerf (u) = 2(cid:2) u

2 ψ(cid:0) u

2(cid:1) − u

2(cid:1)(cid:3),
2 + ψ0(cid:0) u

where ψ is the cumulative distribution of the
standard normal distribution,
: ψ(v) =

i.e.
e−t2/2dt, and ψ0(v) = 1√2π

e−v2/2.

• erf loss

1√2πR v

−∞

1Note that by rescaling, all of these loss functions can
be made to be an upper bound on the 0-1 loss which is
tight at zero.

105

4

3

2

1

0

−2

0

2

4

5

4

3

2

1

0

−2

0

2

4

Figure 1: Loss functions: (left) plain: 0-1 loss, dotted:
hinge loss, dashed: erf loss, dash-dotted: square loss.
(Right) plain: 0-1 loss, dotted: probit loss, dashed:
logistic loss.

The erf loss provides a good approximation of the
logistic loss log(1 + e−u) as well as its derivative,
and is amenable to closed-form computations for
Gaussians and mixture of Gaussians (see Section 4
for more details). Note that the erf loss is diﬀer-
ent from the probit loss − log ψ(u), which leads to
probit regression (Hastie et al., 2001).

2.2 ROC ANALYSIS

The aim of ROC analysis is to display in a single graph
the performance of classiﬁers for all possible costs of
misclassiﬁcation.
In this paper, we consider sets of
classiﬁers fγ(x), parameterized by a variable γ ∈ R (γ
can either be the intercept or the training asymmetry).

For a classiﬁer f (x), we can deﬁne a point (u, v) in the
“ROC plane,” where u is the proportion of false posi-
tives u = P (f (x) = 1|y = −1), and v is the proportion
of true positives v = P (f (x) = 1|y = 1).

When γ is varied, we obtain a curve in the ROC plane,
the ROC curve (see Figure 2 for an example). Whether
γ is the intercept or the training asymmetry, the ROC
curve always passes through the point (0, 0) and (1, 1),
which corresponds to classifying all points as negative
(resp. positive).

The upper convex envelope of the curve is the set of
optimal ROC points that can be achieved by the set
of classiﬁers; indeed, if a point in the envelope is not
one of the original points, it must lie in a segment
between two points (u(γ0), v(γ0)) and (u(γ1), v(γ1)),
and all points in a segment between two classiﬁers can
always be attained by choosing randomly between the
two classiﬁers (note that this classiﬁer itself is not a
linear classiﬁer; this performance can only be achieved
by a mixture of two linear classiﬁers).

Denoting p+ = P (y = 1) and p− = P (y = −1),
the expected (C+, C−)-cost for a classiﬁer (u, v) in
the ROC space,
is simply p+C+(1 − v) + p−C−u,
and thus optimal classiﬁers for the (C+, C−)-cost can
be found by looking at lines of slope that are nor-
mal to (p−C−, −p+C+)—and thus proportional to

v
1

s
e
v
i
t
i
s
o
p
 
e
u
r
t

a

c

b

v
1

s
e
v
i
t
i
s
o
p

 
e
u
r
t

a

0

false positives

1

u

0

false positives

1

u

(Left) ROC curve:

(dashed) convex envelope.

Figure 2:
(plain) regular ROC
curve;
The points a
and c are ROC-consistent and the point b is ROC-
inconsistent. (Right) ROC curve and dashed equi-cost
lines: All lines have direction (p+C+, p−C−), the plain
line is optimal and the point “a” is the optimal classi-
ﬁer.

(p+C+, p−C−)—and which intersects the ROC curve
and are as close as the point (0, 1) as possible (see
Figure 2).

A point (u(γ), v(γ)) is said to be ROC-consistent if
it lies on the upper convex envelope; In this case,
the tangent direction (du/dγ, dv/dγ) deﬁnes a cost
(C+(γ), C−(γ)) for which the classiﬁer is optimal
(for the testing cost, which is deﬁned using the 0-
1 loss), by having (p+C+(γ), p−C−(γ)) proportional
to (du/dγ, dv/dγ). This leads to an optimal testing
C+(γ)+C−(γ) =
asymmetry β(γ), deﬁned as β(γ) =

C+(γ)

1+

p+
p−

1

dv

dγ (γ)/ du

dγ (γ)

.

If a point (u(γ), v(γ)) is ROC-inconsistent, then the
quantity β(γ) has no meaning, and such a classiﬁer is
generally useless, because, for all settings of the mis-
classiﬁcation cost, that classiﬁer can be outperformed
by the other classiﬁers or a combination of classiﬁers.

In Section 4, we relate the optimal asymmetry of cost
in the testing or eventual use of a classifer in the real
world, to the asymmetry of cost used to train that
classiﬁer; in particular, we show that they diﬀer and
quantify this diﬀerence for extreme asymmetries (i.e.,
close to the corner points (0, 0) and (1, 1)). This anal-
ysis highlights the value of generating the entire ROC
curve, even when only one point is needed, as we will
present in Section 4.3.

2.3 LEARNING FROM DATA

Given n labelled data points (xi, yi), the empirical cost
is equal to:

n #{yi(w>xi + b) < 0, yi = 1}
n #{yi(w>xi + b) < 0, yi = −1}

φ(yi(w>xi + b))

φ(yi(w>xi + b)),

while the empirical φ-cost is equal to

+ C−

bR(C+, C−, w, b) = C+
bRφ(C+, C−, w, b) = C+

n Pi∈I+
n Pi∈I−

+ C−

11where I+ = {i, yi = 1} and I− = {i, yi = −1}.
When learning a classiﬁer from data, a classical
setup is to minimize the sum of the empirical φ-cost
and a regularization term 1
2n ||w||2, i.e., to minimize

2n ||w2||.

bJφ(C+, C−, w, b) = bRφ(C+, C−, w, b) + 1

Note that the objective function is no longer homo-
geneous in (C+, C−); the sum C+ + C− is referred
to as the total amount of regularization. Thus,
two end-user–deﬁned parameters are needed to train
the total amount of regulariza-
a linear classiﬁer:
tion C+ + C− ∈ R+, and the asymmetry
∈
In Section 3.1, we show how the minimum of
[0, 1].

C++C−

C+

bJφ(C+, C−, w, b), with respect to w and b, can be com-

puted eﬃciently for the hinge loss, for many values of
(C+, C−), with a computational cost that is within a
constant factor of the computational cost of obtaining
a solution for one value of (C+, C−).
Building an ROC curve from data
If a suﬃ-
ciently large validation set is available, we can train
on the training set and use the empirical distribution
of the validation data to plot the ROC curve. If suf-
ﬁcient validation data is not available, then we can
use 10 random half splits of the data, train a classi-
ﬁer on one half and use the other half to obtain the
ROC scores. Then, for each value of the parameter
γ that deﬁnes the ROC curve (either the intercept or
the training asymmetry), we average the 10 scores. We
can also use this approach to obtain conﬁdence inter-
vals (Flach, 2003).

3 BUILDING ROC CURVES FOR

THE SVM

In this section, we will present an algorithm to com-
pute ROC curves for the SVM that explores the two-
dimensional space of cost parameters (C+, C−) eﬃ-
ciently. We ﬁrst show how to obtain optimal solutions
of the SVM without solving the optimization problems
many times for each value of (C+, C−). This method
generalizes the results of Hastie et al. (2005) to the
case of asymmetric cost functions. We then describe
how the space (C+, C−) can be appropriately explored
and how ROC curves can be constructed.

3.1 BUILDING PATHS OF CLASSIFIERS

Given n data points xi, i = 1, . . . , n which belong to
Rd, and n labels yi ∈ {−1, 1}, minimizing the regu-
larized empirical hinge loss is equivalent to solving the
following convex optimization problem (Sch¨olkopf and
Smola, 2002):

min

w,b,ξPi Ciξi + 1

2 ||w||2 s.t. ∀i, ξi > 0,

∀i, ξi > 1 − yi(w>xi + b)

where Ci = C+ if yi = 1 and Ci = C− if yi = −1.
The dual problem is the following:

max
α∈Rn

− 1

2 α> Diag(y)K Diag(y)α + 1>α

s.t. α>y = 0 and ∀i, 0 6 αi 6 Ci

Following Hastie et al. (2005), from the KKT optimal-
ity conditions, for an optimal set of primal-dual vari-
ables (w, b, α), we can separate data points into three
disjoint sets: M = {i, αi ∈ [0, Ci], yi(w>xi + b) = 1},
L = {i, αi = Ci, yi(w>xi + b) < 1}, R = {i, αi =
0, yi(w>xi + b) > 1}.

These sets are usually referred to as active sets (Boyd
and Vandenberghe, 2003).
If the sets M, L and R
are known, then it is straightforward to show that,
in the domain where the active sets remain constant,
the optimal primal-dual variables (w, α, b) are aﬃne
functions of (C+, C−). This implies that the optimal
variables (w, α, b) are piecewise aﬃne continuous func-
tions of the vector (C+, C−), with “kinks” where the
active sets change.

Following a path The active sets remain the same
as long as all constraints deﬁning the active sets are
satisﬁed, i.e., (a) yi(w>xi + b) − 1 is positive for all
i ∈ R and negative for all i ∈ L, and (b) for each
i ∈ M, αi remains between 0 and Ci. This deﬁnes
a set of linear inequalities in (C+, C−). The facets of
the polytope deﬁned by these inequalities can always
be found in linear time in n, when eﬃcient convex hull
algorithms are used (Avis et al., 1997). However, when
we only follow a straight line in the (C+, C−)-space,
the polytope is then a segment and its extremities are
trivial to ﬁnd (also in O(n)).

Following Hastie et al. (2005), if a solution is known for
one value of (C+, C−), we can follow the path along a
line, by simply monitoring which constraint is violated
ﬁrst and changing the active sets accordingly.

Path initialization Hastie et al. (2005) requires
that the training datasets are balanced in order to
avoid solving a quadratic program to enter the path,
i.e., if n+ (resp. n−) is the number of positive (resp.
negative) training examples, then they require that
n+ = n−.
In our situation, we can explore the two
dimensional space (C+, C−). Thus, the requirements
become C+n+ = C−n− along the path. We can start
the path by following the line C+n+ = C−n− and
avoid the need to solve a quadratic program.

Computational complexity As shown by Hastie
et al. (2005), if the appropriate online linear algebra
tools are used, the complexity of obtaining one path of
classiﬁers across one line is the same as obtaining the
solution for one SVM using classical techniques such
as sequential minimal optimization (Platt, 1998).

12C−

C+n+=C−n−

C+

Figure 3: Lines in the (C+, C−)-space. The line
C+n+ = C−n− is always followed ﬁrst; then several
lines with constant C+ + C− are followed in parallel,
around the optimal line for the validation data (bold
curve).

3.2 CONSTRUCTING THE ROC CURVE

Given the tools of Section 3.1, we can learn paths of
linear classiﬁers from data. In this section, we present
an algorithm to build ROC curves from the paths. We
do this by exploring relevant parts of the (C+, C−)
space, selecting the best classiﬁers among the ones that
are visited.

We assume that we have two separate datasets, one
for training and one for testing. This approach gener-
alizes to cross-validation settings in a straightforward
manner.

+, C 1

+, rC 1

Exploration phase
In order to start the path-
following algorithm, we need to start at C+ = C− = 0
and follow the line C+n+ = C−n−. We follow this line
up to a large upper bound on C+ + C−. For all clas-
siﬁers along that line, we compute a misclassiﬁcation
+, C 0
cost on the testing set, with given asymmetry (C 0
−)
(as given by the user, and usually, but not necessarily,
close to a point of interest in the ROC space). We then
compute the best performing pair (C 1
−) and we se-
lect pairs of the form (rC 1
−), where r belongs to
a set R of the type R = {1, 10, 1/10, 100, 1/100, . . . }.
The set R provides further explorations for the total
amount of regularization C+ + C−.
Then, for each r, we follow the paths of direction
(1, −1) and (−1, 1) starting from the point (rC 1
−).
Those paths have a ﬁxed total amount of regulariza-
tion but vary in asymmetry. In Figure 3, we show all
of lines that are followed in the (C+, C−) space.
Selection phase After the exploration phase, we
have |R| + 1 diﬀerent lines in the (C+, C−) space: the
line C−n− = C+n+, and the |R| lines C+ + C− =
r(C 1
−), r ∈ R. For each of these lines, we know
the optimal solution (w, b) for any cost settings on that
line. The line C−n− = C+n+ is used for computa-
tional purposes (i.e., to enter the path), so we do not
use it for testing purposes.

+ + C 1

+, rC 1

From R lines in the (C+, C−)-plane, we build the three
ROC curves shown in Figure 4, for a ﬁnite sample

1

0.8

0.6

0.4

0.2

s
e
v
i
t
i
s
o
p
e
u
r
t

 

0
0

1

s
e
v
i
t
i
s
o
p
e
u
r
t

 

0.8

0.6

0.4

0.2

0
0

0.2

0.4

0.6

false positives

0.2

0.4

0.6

false positives

0.8

1

0.8

1

Figure 4: Two examples of ROC curves for bimodal
class conditional densities, varying intercept (dotted),
varying asymmetry (plain) and varying both (dashed).
(Top) obtained from 10 random splits, using the data
shown on the left side (one class is plotted as circles,
the other one as crosses), (Bottom) obtained from pop-
ulation densities (one class with plain density contours,
the other one with dotted contours).

problem and for an inﬁnite sample problem (for the
inﬁnite sample, the solution of the SVM was obtained
by working directly with densities):

• Varying intercept: we extract the slope w corre-
sponding to the best setting (C 1
−), and vary
the intercept b from −∞ to ∞. This is the tradi-
tional method for building an ROC curve for an
SVM.

+ + C 1

+ + C 1

• Varying asymmetry: we only consider the line
C+ + C− = C 1
− in the (C+, C−)-plane; the
classiﬁers that are used are the optimal solutions
of the convex optimization problem. Note that for
each value of the asymmetry, we obtain a diﬀerent
value of the slope and the intercept.

• Varying intercept and asymmetry: for each of the
points on the R lines in the (C+, C−)-plane, we
discard the intercept b and keep the slope w ob-
tained from the optimization problem; we then use
all possible intercept values; this leads to R two-
dimensional surfaces in the ROC plane. We then
compute the convex envelope of these, to obtain a
single curve.

Since all classiﬁers obtained by varying only the in-
tercept (resp. the asymmetry) are included in the set
used for varying both the intercept and the asymme-
try, the third ROC curve always outperforms the ﬁrst
two curves (i.e., it is always closer to the top left cor-
ner). This is illustrated in Figure 4.

Intuitively, the ROC curve obtained by varying the
asymmetry should be better than the ROC generated
by varying the intercept because, for each point, the
slope of the classiﬁer is optimized. Empirically, this is
generally true, but is not always the case, as displayed

13in Figure 4. This is not a small sample eﬀect, as the
inﬁnite sample simulation shows. Another troubling
fact is that the ROC curve obtained by varying asym-
metry, exhibits strong concavities, i.e., there are many
ROC-inconsistent points: for those points, the solution
of the SVM with the corresponding asymmetry is far
from being the best linear classiﬁer when performance
is measured with the same asymmetry but with the
exact 0-1 loss. In addition, even for ROC-consistent
points, the training asymmetry and the testing asym-
metry diﬀer. In the next section, we analyze why they
may diﬀer and characterize their relationships in some
situations.

4 TRAINING VS. TESTING

ASYMMETRY

We observed in Section 3.2 that the training cost asym-
metry can diﬀer from the testing asymmetry. In this
section, we analyze their relationships more closely for
the population (i.e., inﬁnite sample) case. Although
a small sample eﬀect might alter some of the results
presented in this section, we argue that most of the
discrepancies come from using a convex surrogate to
the 0 − 1 loss.

The Bayes optimal classiﬁer for a given asymmetry
is the (usually non-linear) classiﬁer with
(C+, C−),
minimal expected cost. A direct consequence of results
in Bartlett et al. (2004) is that, if the Bayes optimal
classiﬁer is linear, then using a convex surrogate has
no eﬀect, i.e., using the expected φ-cost will lead to
the minimum expected cost. Thus, if the Bayes op-
timal classiﬁer is linear, then, in the population case
(inﬁnite sample), there should be no diﬀerence. How-
ever, when the Bayes optimal classiﬁer is not linear,
then we might expect to obtain a diﬀerence, and we
demonstrate that we do have one and quantify it for
several situations.

Since we are using population densities, we can get
rid of the regularization term and thus only the asym-
metry will have an inﬂuence on the results, i.e., we
can restrict ourselves to C+ + C− = 1. We let
γ = C+/(C+ + C−) = C+ denote the training asym-
metry. For a given training asymmetry γ and a loss
function φ, in Section 2.2, we deﬁned the optimal test-
ing asymmetry β(γ) for the training asymmetry γ. In
this section, we will refer to the β(γ) simply as the
testing asymmetry.

Although a diﬀerence might be seen empirically for all
possible asymmetries, we analyze the relationship be-
tween the testing cost asymmetry and training asym-
metry in cases of extreme asymmetry, i.e., in the ROC
framework, close to the corner points (0, 0) and (1, 1).
We prove that, depending on the class conditional den-

sities, there are two possible diﬀerent regimes for ex-
treme asymmetries: either the optimal testing asym-
metry is more extreme, or it is less extreme. We also
provide, under certain conditions, a simple test that
can determine the regime given class conditional den-
sities.

In this section, we choose class conditional densities
that are either Gaussian or a mixture of Gaussians, be-
cause (a) any density can be approximated as well as
desired by mixtures of Gaussians (Hastie et al., 2001),
and (b) for the square loss and the erf loss, they en-
able closed-form calculations that lead to Taylor ex-
pansions.

4.1 OPTIMAL SOLUTIONS FOR

EXTREME COST ASYMMETRIES

We assume that the class conditional densities are mix-
tures of Gaussian, i.e., the density of positive (resp.
negative) examples is a mixture of k+ Gaussians, with
+ and covariance matrix Σi
means µi
+, and mixing
weights π+
i , i ∈ {1, . . . , m+} (resp. k− Gaussians,
− and covariance matrix Σi
with means µi
−, and mix-
ing weights π+
, i ∈ {1, . . . , m−} ). We denote p+ and
−
p− as the marginal class densities, p+ = P (y = 1),
p− = P (y = −1). We assume that all mixing weights
πi
± are strictly positives and that all covariance matri-
ces Σi

± have full rank.

In the following sections, we provide Taylor expansions
of various quantities around the null training asymme-
try γ = 0. They trivially extend around the reverse
asymmetry γ = 1. We start with an expansion of the
unique global minimum (w, b) of the φ-cost with asym-
metry γ. For the square loss, (w, b) can be obtained in
closed form for any class conditional densities so the
expansion is easy to obtain, while for the erf loss, an
asymptotic analysis of the optimality conditions has
to be carried through, and is only valid for mixture of
Gaussians (see Bach et al. (2004) for proofs).

Proposition 1 (square loss) Under previous as-
sumptions, we have the following expansions:

w = 2

p+
p−
b = −1 +

γΣ−1
−
p+
p−

(µ+ − µ−) + O(γ2)
γ[2 − 2µ>

−(µ+ − µ−)] + O(γ2)

where m = µ+ − µ−, and Σ± and µ± are the class
conditional means and variances.

Proposition 2 (erf loss) Under previous assump-
tions, we have the following expansions:

w = (2 log(1/γ))−1/2eΣ−(˜µ+ − ˜µ−) + o(cid:16)log(1/γ)−1/2(cid:17)
b = − (2 log(1/γ))1/2 + o(cid:16)log(1/γ)1/2(cid:17)

14combinations of the mixture means and covariances,
i.e., there exists strictly positive weights ˜πi
±, that sum
± and

where ˜m = ˜µ+ − ˜µ−, and eΣ± and ˜µ± are convex
to one for each sign, such that eΣ± = Pi ˜πi
˜µ± =Pi ˜πi

±µi
±.
The weights ˜πi
± can be expressed as the solution of a
convex optimization problem (see Bach et al. (2004)
for more details). When there is only one mixture
component (Gaussian densities), then ˜π1

±Σi

± = 1.

1

0.8

0.6

0.4

0.2

y
r
t

e
m
m
y
s
a

 

g
n

i
t
s
e

t

0
0

1

0.8

0.6

0.4

0.2

y
r
t

e
m
m
y
s
a

 

g
n

i
t
s
e

t

0
0

y
r
t

e
m
m
y
s
a

 

g
n

i
t
s
e

t

1

0.8

0.6

0.4

0.2
0

1

0.8

0.6

0.4

0.2

y
r
t

e
m
m
y
s
a

 

g
n

i
t
s
e

t

0
0

1

1

0.2

0.4

0.6

0.8

training asymmetry

0.2

0.4

0.6

0.8

training asymmetry

0.2

0.4

0.6

0.8

training asymmetry

0.2

0.4

0.6

0.8

training asymmetry

1

1

4.2 EXPANSION OF TESTING

ASYMMETRIES

Using the expansions of Proposition 1 and 2, we can
readily derive an expansion of the ROC coordinates
for small γ, as well as the testing asymmetry β(γ).
We have (see Bach et al. (2004) for proofs):

testing asym-
Figure 5: Training asymmetry vs.
(Left) Gaussian class condi-
metry, square loss:
tional densities, (right) testing asymmetry vs. train-
the values
ing asymmetry;
Σi−
of (m>Σ−1
m)−1 are
−
−
0.12, -6, 3, -0.96.

from top to bottom,
Σi+
m)−1 − (m>Σ−1
−

+ Σ−1
−

Σ−1
−

Proposition 3 (square loss) Under previous as-
sumptions, we have the following expansion:

log(cid:18) p−

p+

(β(γ)−1−1)(cid:19) =

+γ2 

p2
−
8p2

1
Σi−
−

m>Σ−1
−

m

Σ−1
−

m! + o(1/γ2) (1)

−

m>Σ−1
−

1
Σi+

+ Σ−1
−

where i− (resp. i+) is one of the negative (resp. posi-
tive) mixture component.

Proposition 4 (erf loss) Under previous assump-
tions, we have the following expansion:

Σi+

Σi−
−

• if m>Σ−1
−

Σ−1
−

+ Σ−1
−

m < m>Σ−1
−

m , then
from the expansion in Eq. (1) and Eq. (2), we see
that the testing asymmetry tends to 0 exponen-
tially fast, in particular, the derivative dβ/dγ is
null at γ = 0, meaning, that the testing asymme-
try is signiﬁcantly smaller than the training asym-
metry, i.e., less extreme.

• if m>Σ−1
−

Σi+

Σi−
−

Σ−1
−

+ Σ−1
−

m = m>Σ−1
−

m, then
the asymptotic expansion does not provide any
information relating to the behavior of the test-
ing asymmetry. We are currently investigating
higher-order expansions in order to study the be-
havior of this limiting case. Note that when the
two class conditional densities are Gaussians with
identical covariance (a case where the Bayes op-
timal classiﬁer with symmetric cost is indeed lin-
ear), we are in the present case.

The strength of the eﬀects we have described above
depends on the norm of m = µ+ − µ−: if m is large,
i.e., the classiﬁcation problem is simple, then those ef-
fects are less strong, while when m is small, they are
stronger.
In Figure 5, we provide several examples
for the square loss, with the two regimes and diﬀerent
strengths. It is worth noting, that, although the theo-
retical results obtained in this section are asymptotic
expansions around the corners (i.e., extreme asymme-
tries), the eﬀects also remain valid far from the corners.

Σi+

+ Σ−1
−

We thus must test to identify which regime we are
in, namely testing for the sign of m>Σ−1
m =
−
m>Σ−1
m. This test requires knowledge of the
−
class conditional densities; it can currently always be
performed in closed form for the square loss, while for
the erf loss, it requires to solve a convex optimization
problem, described by Bach et al. (2004).

Σ−1
−

Σi−
−

1
Σi−

−

˜m

˜m>eΣ−1
˜m! + o(log(1/γ)) (2)

− eΣ−1

−

log(cid:18) p−

p+

(β(γ)−1−1)(cid:19) = 2 log(1/γ) 
+eΣ−1

˜m>eΣ−1

1
Σi+

−

−

−

where i− (resp. i+) is one of the negative (resp. posi-
tive) mixture component.

The rest of the analysis is identical for both losses
and thus, for simplicity, we focus primarily on the
square loss. For the square loss, we have two diﬀerent
regimes, depending on the sign of m>Σ−1
m −
−
m>Σ−1
−

+ Σ−1
−

Σ−1
−

Σi−
−

Σi+

m:

• if m>Σ−1
−

Σi+

Σi−
−

Σ−1
−

+ Σ−1
−

m > m>Σ−1
−

m, then
from the expansion in Eq. (1) and Eq. (2), we see
that the testing asymmetry tends to 1 exponen-
tially fast. Because this is an expansion around
the null training asymmetry, the ROC curve must
be starting on the bottom right part of the main
diagonal and the points close to γ = 0 are not
ROC-consistent, i.e., the classiﬁers with training
asymmetry too close to zero are useless as they
are too extreme.

15Dataset
Pima

Breast

Ionosphere

Liver

Ringnorm

Twonorm

Adult

γ
0.68
0.99
0.82
0.32
0.94
0.16
0.70

one asym.
41 ± 0.4
0.9 ± 0.03
10 ± 0.5
27 ± 1.8
6.3 ± 0.06
15 ± 0.2
12.8 ± 0.8

all asym.
22 ± 1
0.09 ± 0.04
4 ± 0.8
23.8 ± 0.02
4.3 ± 0.1
1.2 ± 0.2
11.5 ± 0.3

Table 1: Training with the testing asymmetry γ vs.
training with all cost asymmetries: we report valida-
tion costs obtained from 10 half-random splits (pre-
multiplied by 100). Only the asymmetry with the
largest diﬀerence is reported. Given an asymmetry
γ we use the cost settings C+ = 2γ, C− = 2(1 − γ)
(which leads to the misclassiﬁcation error if γ = 1/2).

4.3 BUILDING THE ENTIRE ROC
CURVE FOR A SINGLE POINT

As shown empirically in Section 3.2, and demonstrated
theoretically in this section, training and testing asym-
metries diﬀer; and this diﬀerence suggests that even
when the user is interested in only one cost asymmetry,
the training procedure should explore more cost asym-
metries, i.e. build the ROC curve as presented in Sec-
tion 3.2 and chose the best classiﬁer as follows: a given
asymmetry in cost for the test case leads to a unique
slope in the ROC space, and the optimal point for this
asymmetry is the point on the ROC curve whose tan-
gent has the corresponding slope and which is closest
to the upper-left corner.

We compare in Figure 1, for various datasets and linear
classiﬁers, the performance with cost asymmetry γ of
training a classiﬁer with cost asymmetry γ to the per-
formance of training with all cost asymmetries. Using
all asymmetries always perform better than assuming
a single asymmetry—we simply have more classiﬁers
to choose from. In Figure 1, we report only the perfor-
mance for the cost asymmetries which show the great-
est diﬀerences, showing that in some cases, it is very
signiﬁcant, and that a simple change in the training
procedure may lead to substantial gains.

5 CONCLUSION

We have presented an eﬃcient algorithm to build ROC
curves by varying the training cost asymmetries for
SVMs. The algorithm is based on the piecewise lin-
earity of the path of solutions when the cost of false
positives and false negatives vary. We have also pro-
vided a theoretical analysis of the relationship between
the potentially diﬀerent cost asymmetries assumed in
training and testing classiﬁers, showing that they diﬀer
under certain circumstances. We have characterized

key relationships, and have worked to highlight the
potential value of building the entire ROC curve even
when a single point may be needed. Such an approach
can lead to a signiﬁcant improvement of performance
with little added computational cost. Finally, we note
that, although we have focused in this paper on the
single kernel learning problem, our approach can be
readily extended to the multiple kernel learning set-
ting (Bach et al., 2005) with appropriate numerical
path following techniques.

Acknowledgments

We thank John Platt for sharing his experiences and
insights with considerations of cost functions in train-
ing and testing support vector machines.

References

D. Avis, D. Bremner, and R. Seidel. How good are con-
vex hull algorithms ? In Computational Geometry:
Theory and Applications, volume 7, 1997.

F. R. Bach, D. Heckerman, and E. Horvitz. On the
path to an ideal ROC curve: Considering cost asym-
metry in learning classiﬁers. Technical Report MSR-
TR-2004-124, Microsoft Research, 2004.

F. R. Bach, R. Thibaux, and M. I. Jordan. Computing
regularization paths for learning multiple kernels. In
NIPS 17, 2005.

P. L. Bartlett, M. I. Jordan, and J. D. McAuliﬀe. Large
margin classiﬁers: convex loss, low noise, and con-
vergence rates. In NIPS 16, 2004.

S. Boyd and L. Vandenberghe. Convex Optimization.

Cambridge Univ. Press, 2003.

P. A. Flach. The geometry of ROC space: understand-
ing machine learning metrics through ROC isomet-
rics. In ICML, 2003.

T. Hastie, S. Rosset, R. Tibshirani, and J. Zhu. The
entire regularization path for the support vector ma-
chine. JMLR, 5:1391–1415, 2005.

T. Hastie, R. Tibshirani, and J. Friedman. The Ele-
ments of Statistical Learning. Springer-Verlag, 2001.

M. S. Pepe. Receiver operating characteristic method-
ology. J. Am. Stat. Assoc., 95(449):308–311, 2000.

J. Platt. Fast training of support vector machines us-
ing sequential minimal optimization.
In Advances
in Kernel Methods: Support Vector Learning, Cam-
bridge, MA, 1998. MIT Press.

F. Provost and T. Fawcett. Robust classiﬁcation for
imprecise environments. Machine Learning, 42(3):
203–231, 2001.

B. Sch¨olkopf and A. J. Smola. Learning with Kernels.

MIT Press, 2002.

16On Manifold Regularization

Mikhail Belkin, Partha Niyogi, Vikas Sindhwani

Department of Computer Science

  misha,niyogi,vikass @cs.uchicago.edu

University of Chicago

Abstract

We propose a family of learning algorithms
based on a new form of regularization that
allows us to exploit the geometry of the
marginal distribution. We focus on a semi-
supervised framework that incorporates la-
beled and unlabeled data in a general-
purpose learner. Some transductive graph
learning algorithms and standard meth-
ods including Support Vector Machines and
Regularized Least Squares can be obtained
as special cases. We utilize properties of
Reproducing Kernel Hilbert spaces to prove
new Representer theorems that provide the-
oretical basis for the algorithms. As a re-
sult (in contrast to purely graph based ap-
proaches) we obtain a natural out-of-sample
extension to novel examples and are thus
able to handle both transductive and truly
semi-supervised settings. We present exper-
imental evidence suggesting that our semi-
supervised algorithms are able to use unla-
beled data effectively. In the absence of la-
beled examples, our framework gives rise
to a regularized form of spectral clustering
with an out-of-sample extension.

submanifold of the ambient space.
Within this general framework, we propose two spe-
ci(cid:2)c families of algorithms:
the Laplacian Regular-
ized Least Squares (hereafter LapRLS) and the Lapla-
cian Support Vector Machines (hereafter LapSVM).
These are natural extensions of RLS and SVM respec-
tively. In addition, several recently proposed trans-
ductive methods (e.g., [18, 17, 1]) are also seen to be
special cases of this general approach. Our solution
for the semi-supervised case can be expressed as an
expansion over labeled and unlabeled data points.
Building on a solid theoretical foundation, we obtain
a natural solution to the problem of out-of-sample ex-
tension (see also [6] for some recent work).When all
examples are unlabeled, we obtain a new regularized
version of spectral clustering.
Our general framework brings together three distinct
concepts that have received some independent recent
attention in machine learning: Regularization in Re-
producing Kernel Hilbert Spaces, the technology of
Spectral Graph Theory and the geometric viewpoint
of Manifold Learning algorithms.

2 The Semi-Supervised Learning

Framework

1 Introduction

The problem of learning from labeled and unlabeled
data (semi-supervised and transductive learning) has
attracted considerable attention in recent years (cf.
[11, 7, 10, 15, 18, 17, 9]). In this paper, we consider this
problem within a new framework for data-dependent
regularization. Our framework exploits the geome-
try of the probability distribution that generates the
data and incorporates it as an additional regulariza-
tion term. We consider in some detail the special case
where this probability distribution is supported on a

First, we recall the standard statistical framework of
learning from examples, where there is a probability

. Unlabeled examples are simply
.

distribution on according to which training
examples are generated. Labeled examples are
	
pairs drawn from
	 drawn from the marginal distribution of
One might hope that knowledge of the marginal

can be exploited for better function learning (e.g. in
classi(cid:2)cation or regression tasks). Figure 1 shows
how unlabeled data can radically alter our prior be-
lief about the appropriate choice of classi(cid:2)cation func-
tions. However, if there is no identi(cid:2)able relation be-

17Figure 1: Unlabeled data and prior beliefs

smoothly along the geodesics in the intrinsic geome-

	 , the knowledge

is unlikely to be of much use. Therefore, we
will make a speci(cid:2)c assumption about the connection
between the marginal and the conditional. We will as-
are close in the in-
, then the conditional distribu-

tween
 and the conditional

of
sume that if two points		 
trinsic geometry of
tions!
	" and!
the conditional probability distribution!
try of

	# are similar. In other words,
	$ varies

We utilize these geometric ideas to extend an estab-
lished framework for function learning. A number of
popular algorithms such as SVM, Ridge regression,
splines, Radial Basis Functions may be broadly in-
terpreted as regularization algorithms with different
empirical cost functions and complexity measures in
an appropriately chosen Reproducing Kernel Hilbert
Space (RKHS).

.

, there is an asso-

. Given a set of labeled examples

an unknown function by minimizing

For a Mercer kernel%'&(')+*,
ciated RKHS-). of functions/*0 with the corre-
sponding norm121
!	$34(35 ,687:9(<;";<;=4> the standard framework estimates
?@
7BACED(FHGJI
KLMON
!	$3[4

is some loss function, such as squared loss
for RLS or the soft margin loss func-
tion for SVM. Penalizing the RKHS norm imposes
smoothness conditions on possible solutions. The
classical Representer Theorem states that the solution

!Y32Z
to this minimization problem exists in-). and can be

UWVX1

written as

where

8T



(1)

(2)

!	

3SR

?@

!	\7

3
%^!	$34	$

3SR

]

the problem is reduced to optimizing

Therefore,
over the (cid:2)nite dimensional space of coef(cid:2)cients
which is the algorithmic basis for SVM, Regularized
Least Squares and other regression and classi(cid:2)cation
schemes.
Our goal is to extend this framework by incorporating
additional information about the geometric structure

3 ,

3SR

(4)

.

(3)

]

!jU

is suf-
.

!	$34(3_

. Given this setup one

is an appropriate penalty term that

that, we introduce an additional regularizer:

can prove the following representer theorem:

above exists and admits the following representation

controls the complexity of the function in the ambient

. We would like to ensure that the
solution is smooth with respect to both the ambient
. To achieve

The proof of this theorem runs over several pages and
is omitted for lack of space. See [4] for details includ-
ing the exact statement of the smoothness conditions.
.
Therefore we must attempt to get empirical estimates

UaVcdY1
3SR
. HereV
d controls the complexity of the function
@ to the optimization problem in Eqn 3

_%h
	4ci
Op

of the marginal
space and the marginal distribution2
`UaVcbO1
7BACED(FHGJI
K(LM
where 1
should re(cid:3)ect the intrinsic structure of
space whileV
in the intrinsic geometry of
Theorem 2.1. Assume that the penalty term1
1`d
(cid:2)ciently smooth with respect to the RKHS norm 1
Then the solution?
!	\7fecg
	
%^!	
wherekl7Bm4noo
is the support of the marginal2
In most applications, however, we do not know
of1
d . Note that in order to get such empirical esti-
support of 
is a compact submanifold k
In that case, a natural choice for 1
1<d
7rts
?z . The optimization problem be-
gwvyx
is u
?@
7{ACED(FHGJI
K(LM|N
3JR
T
?z
gwv[x
The termu
graph Laplacian ([1]). Thus, given a set of>
examples 
!	$34(3y
P
ples  
P
	c
7{ACED(FHGJI
K(LM|N

4
Vcd
e~g
?z may be approximated on
and a set of unlabeled exam-

mates it is suf(cid:2)cient to have unlabeled examples.
A case of particular recent interest is when the

the basis of labeled and unlabeled data using the
labeled

, we consider the following optimiza-

!	$34(3

U}V
v[x

tion problem :

comes

!	

(5)

(6)

.

3JR

3JR

U}Vcb1

Uh>y

?


18

.
9
>
P
Q
3
3

?
?
1

.
T
?

P
Q
]

?
@
N
9
>
P
Q

T
?
?
1

.
?
1

d
?
1

d

b

?
?
1
.
?
@
]

P
Q
3
3
 

?
1
q

?
g
?

x
g
9
>
P
Q
3
3

?
b
1
?
1

.
U
g
?

x
g
g
?

x
g
P


R

R

?
@
9
>
P
Q

T
?
?
1

.
U
V
d

?
edge weights in the data adjacency graph. Here, the



, and
P

	
7/+Zf where 
P
is given by3S327
#P


is the graph

 are the
 . The
3

normalizing coef(cid:2)cient
is the natural scale fac-
tor for the empirical estimate of the Laplace operator.
On a sparse adjacency graph it may be replaced by

where

!	"=";";<;=
7'
Laplacian given by 
diagonal matrix
P
3!

3

 .

The following simple version of the representer the-
orem shows that the minimizer has an expansion in
terms of both labeled and unlabeled examples and is
a key to our algorithms.
Theorem 2.2. The minimizer of optimization problem 6
admits an expansion

?@

!	\7

PS
3SR

%^!	

4	$

(7)

in terms of the labeled and unlabeled examples.

The proof is a variation of the standard orthogonality
argument, which we omit for lack of space.

amples are (i) heat kernel (ii) iterated Laplacian (iii)
kernels in geodesic coordinates. The above kernels
are geodesic analogs of similar kernels in Euclidean
(denoted by

Remarks : (a) Other natural choices of11
d exist. Ex-
space. (b) Note that%
restricted tok
) is also a kernel de(cid:2)ned onk with an associated
RKHS-
of functions k
*
(?
is?
restricted tok
suggest 1
7w1
1=.\
as a reasonable choice for 1
d , it turns out, that for
the minimizer?
@ of the corresponding optimization
problem we get 1
71
1".
differentV

, yielding the same
solution as standard regularization, although with a

. While this might
)

3 Algorithms

.

We now present solutions to the optimization prob-
lem posed in Eqn (6). To (cid:2)x notation, we assume we

have> labeled examples 
!	
examples 
. We use%

P
P

4

note the kernel function or the Gram matrix.

interchangeably to de-

and unlabeled



3JR

3.1 Laplacian Regularized Least Squares

(LapRLS)

The Laplacian Regularized Least Squares algorithm
solves Eqn (6) with the squared loss function:

7
(3Z

of the form given by (7), the objective function can
be reduced to a convex differentiable function of the

 . Since the solution is

	34(3

>U^ -dimensional expansion coef(cid:2)cient vector


	35

(8)

 whose minimizer is given by :
P
";";<;"
¤
7:_%UWVcb8>y ¡U
% £¢
Here, K is the
>U¥¡h
>U¦ Gram matrix over la-
beled and unlabeled points; Y is an 
>XU dimen-
sional label vector given by -¤
4¨<;";<;=4¨
~#<;";<;=
is an
>U©|}
>ªU© diagonal matrix given by
and
-B7«i(6¬Y­9(<;";";<9(E¨";<;";=E¨Y with the (cid:2)rst> diagonal
Note that when Vcd®7¯¨ , Eqn (8) gives zero coef(cid:2)-

cients over unlabeled data. The coef(cid:2)cients over la-
beled data are exactly those for standard RLS.

V~d`>
!Uh>y
7§

entries as 1 and the rest 0.

3.2 Laplacian Support Vector Machines (LapSVM)

:

Laplacian SVMs solve the optimization problem in
Eqn. 6 with the soft margin loss function de(cid:2)ned as

(9)

(10)

, where

%h

Z°9Y£Ua9 . In-

!	$3[4Y3¡

°7±FA²
¨ª"9Zh(3

troducing slack variables, using standard Lagrange
Multiplier techniques used for deriving SVMs [16],
we (cid:2)rst arrive at the following quadratic program in


	34(3
> dual variables³
º¹
³´7{FA²
µL#¶·
3JR
subject to the contraints :
(3
³37+¨ª®¨¼»½³$3»
3SR
6t79(<;S;J;
Vcd
%¾
 ¡U
!Uh>y
Here, Y is the diagonal matrix¤
3 , K is the Gram
3S3
7{
if687^À and	
>º
>cU  matrix given by -
3 is a
7¿9
labeled example, andj3
7B¨ otherwise. To obtain the
P`
Á
 U

optimal expansion coef(cid:2)cient vector
, one
has to solve the following linear system after solving
the quadratic program above :

matrix over both the labeled and the unlabeled data;
L is the data adjacency graph Laplacian; and J is an

!Uh>y
One can note that when V

Eqns (10,11), give zero expansion coef(cid:2)cients over the
unlabeled data. The expansion coef(cid:2)cients over the
labeled data and the Q matrix are as in standard SVM,
in this case. Laplacian SVMs can be easily imple-
mented using standard SVM software and packages
for solving linear systems.
The Manifold Regularization algorithms and some
connections are presented in the table below. For
Graph Regularization and Label Propagation see [12,
3, 18].

% 
7Â¨ , the SVM QP and

7:

(11)

19
?
?
?

3

R





R

Q

]
3
3
%
g
g
?
1
d
?

g

g
?
1
?
@
1
d
?
@
3
3
P

	



R

R

T
?
?
]
7

]
]

]
@


P
T
?
?
 
P
Q

³
3
Z
9
¸
³
³
P


P
>
¹
7
¤
¸
V
b
¸


¢



¤
3

]
@

]
@
¸
V
b
¸
V
d


¢



¤
³
´
d
Manifold Regularization Algorithms

Input:
Output:

Step 1

Step 2
Step 3

Step 4
Step 5

Step 6

4

&Y


3JR
*,

is a diagonal matrix given by

, unlabeled examples 

P
> labeled examples 
PS
!	
	
Estimated function?
Ã Construct data adjacency graph withy>5U nodes using, e.g,Ä nearest neighbors. Choose
edge weights
 , e.g. binary weights or heat kernel weights
7BÅ
¢tÆ5Ç<È[¢Ç"É"Æ
Ã Choose a kernel function%h!	º . Compute the Gram matrix%)3
7B%h
	3_4	
Ã Compute graph Laplacian matrix : 
7ÍÎZh where
P
 .
H3J3º7Ï
3
Ã ChooseVcb andVcd .
@ using Eqn (8) for squared loss (Laplacian RLS) or using Eqns (10,11) together
Ã Compute
Ã Output function?
	 .
!	\7
¨ Manifold Regularization
d°Ð
7¼¨
d°Ñ
*,¨
7¼¨

Standard Regularization (RLS or SVM)
Out-of-sample extension for Graph Regularization (RLS or SVM)
Out-of-sample extension for Label Propagation (RLS or SVM)
Hard margin (RLS or SVM)

with the SVM QP solver for soft margin loss (Laplacian SVM).

Connections to other algorithms

EÊËEÌ .
 .

%h
	

P
3SR

bhÐ
¨hV
bhÐ
¨hV
7¼¨hV
7B¨©V
*,¨hV

4 Related Work

In this section we survey various approaches to semi-
supervised and transductive learning and highlight
connections of Manifold Regularization to other algo-
rithms.
Transductive SVM (TSVM) [16], [11]: TSVMs are
based on the following optimization principle :

K(LM|N

ACED(FHGSI
·ÔÓ~Õ
ÔÖÔÖÔÖ
P
PS
3SR

4

3SRÙ

·ÔÓY×ºØ
_9Z 

92Z¾


	

!	
Uf1

@ are

which proposes a joint optimization of the SVM ob-
jective function over binary-valued labels on the unla-
beled data and functions in the RKHS. Here,
parameters that control the relative hinge-loss over la-
beled and unlabeled sets. The joint optimization is
implemented in [11] by (cid:2)rst using an inductive SVM
to label the unlabeled data and then iteratively solv-
ing SVM quadratic programs, at each step switching
labels to improve the objective function. However
this procedure is susceptible to local minima and re-
quires an unknown, possibly large number of label
switches before converging. Note that even though
TSVM were inspired by transductive inference, they
do provide an out-of-sample extension.

Semi-Supervised SVMs (SÚ VM) [5] : SÚ VM incorpo-

rate unlabeled data by including the minimum hinge-
loss for the two choices of labels for each unlabeled

example. This is formulated as a mixed-integer pro-
gram for linear SVMs in [5] and is found to be in-
tractable for large amounts of unlabeled data. The
presentation of the algorithm is restricted to the lin-
ear case.
Measure-Based Regularization [9]: The conceptual
framework of this work is closest to our approach.
The authors consider a gradient based regularizer
that penalizes variations of the function more in high
density regions and less in low density regions lead-
ing to the following optimization principle:

?@


	

	$

3JRÙÜT
!	
vyx

is the density of the marginal distribution
. The authors observe that it is not straightforward
, whose associ-
. Thus, in
the absence of a representer theorem, the authors pro-

ºU
4
7¼A(C4DYFHGSI
K(LÛ
zyÝ
vyx
!	$i(	
whereÝ
to (cid:2)nd a kernel for arbitrary densitiesÝ
zyÝ
ated RKHS norm isu

	$
pose to perform minimization over the linear spaceÞ
uses the gradientx
!	
? over a submanifold.
data truly lies on or near a submanifoldk

generated by the span of a (cid:2)xed set of basis functions
chosen apriori. It is also worth noting that while [9]
in the ambient space, we use
the penalty functional associated with the gradient
In a situation where the
, the dif-
ference between these two penalizers can be signi(cid:2)-
cant since smoothness in the normal direction to the
data manifold is irrelevant to classi(cid:2)cation or regres-
sion. The algorithm in [9] does not demonstrate per-

!	$i(	

!	

203
3
P


R

s
3
3



R

]
@


]
@
3
3
V
V
d
V
b
¨
V
b
d
V
b
d
?
@
7

Ò
Ò
P
Q
3
?
3

U
Ø
@
Q

3
?
3

?
1

.
Ø

Ø
P
Q

?
3
3
V
e

?
x
?


?
x
?
?
x
g
formance improvements in real world experiments.
Graph Based Approaches See e.g.,
[7, 10, 15, 17,
18, 1]: A variety of graph based methods have been
proposed for transductive inference. However, these
methods do not provide an out-of-sample extension.
In [18], nearest neighbor labeling for test examples
is proposed once unlabeled examples have been la-
beled by transductive learning.
In [10], test points
are approximately represented as a linear combina-
tion of training and unlabeled points in the feature
space induced by the kernel. We also note the very
recent work [6] on out-of-sample extensions for semi-
supervised learning. For Graph Regularization and
Label Propagation see [12, 3, 18]. Manifold regular-
ization provides natural out-of-sample extensions to
several graph based approaches. These connections
are summarized in the Table on page 5.
Other methods with different paradigms for using
unlabeled data include Cotraining [8] and Bayesian
Techniques, e.g., [14].

5 Experiments

We performed experiments on a synthetic dataset
and two real world classi(cid:2)cation problems arising
in visual and speech recognition.
Comparisons
are made with inductive methods (SVM, RLS). We
also compare with Transductive SVM (e.g.,
[11])
based on our survey of related algorithms in Section
4. For all experiments, we constructed adjacency
Software and
Datasets for these experiments are available at
http://manifold.cs.uchicago.edu/manifold regularization.
More detailed experimental results are presented in
[4].

graphs with ß nearest neighbors.

>7¨;

7¨;

¨já

#PS
¨(¨jác±å=æ

was set for inductive methods following experiments
reported in [13]. For manifold regularization, we

ing set and 2 of these were randomly labeled. The re-
maining images formed the test set. Polynomial Ker-

images for each
digit in the USPS training set (preprocessed using

of handwritten digits. The (cid:2)rstàY¨(¨
PCA to9<¨Y¨ dimensions) were taken to form the train-
nels of degree 3 were used, andV>â7w¨ª;
7ã9<¨j
chose to split the same weight in the ratio 9w& ä
so that V
¨à~á . The observa-

tions reported in this section hold consistently across
a wide choice of parameters.
In Figure 4, we com-
pare the error rates of Laplacian algorithms, SVM and
TSVM, at the precision-recall breakeven points in the
ROC curves (averaged over 10 random choices of la-
beled examples) for the 45 binary classi(cid:2)cation prob-
lems. The following comments can be made: (a) Man-
ifold regularization results in signi(cid:2)cant improve-
ments over inductive classi(cid:2)cation, for both RLS and
SVM, and either compares well or signi(cid:2)cantly out-
performs TSVM across the 45 classi(cid:2)cation problems.
Note that TSVM solves multiple quadratic programs
in the size of the labeled and unlabeled sets whereas
LapSVM solves a single QP in the size of the labeled
set, followed by a linear system. This resulted in sub-
stantially faster training times for LapSVM in this ex-
periment. (b) Scatter plots of performance on test and
unlabeled data sets con(cid:2)rm that the out-of-sample ex-
tension is good for both LapRLS and LapSVM. (c)
Finally, we found Laplacian algorithms to be signif-
icantly more stable with respect to choice of the la-
beled data than the inductive methods and TSVM, as
shown in the scatter plot in Figure 4 on standard devi-
ation of error rates. In Figure 5, we plot performance
as a function of number of labeled examples.

5.1 Synthetic Data : Two Moons Dataset

5.3 Spoken Letter Recognition

The two moons dataset is shown in Figure 2. The best
decision surfaces across a wide range of parameter
settings are also shown for SVM, Transductive SVM

and Laplacian SVM. The dataset contains¸
ples with only9

labeled example for each class. Fig-
ure 2 demonstrates how TSVM fails to (cid:2)nd the op-
timal solution. The Laplacian SVM decision bound-
ary seems to be intuitively most satisfying. Figure 3
shows how increasing the intrinsic regularization al-
lows effective use of unlabeled data for constructing
classi(cid:2)ers.

¨Y¨ exam-

5.2 Handwritten Digit Recognition

In this set of experiments we applied Laplacian SVM

(cid:2)cation problems that arise in pairwise classi(cid:2)cation

and Laplacian RLSC algorithms to àjá binary classi-

This experiment was performed on the Isolet
database of letters of the English alphabet spoken in
isolation (available from the UCI machine learning

subjects who spoke the name of each letter of the En-

isolet5. For the purposes of this experiment, we chose
speakers (isolet1) forming a

repository). The data set contains utterances of 9#á¨
glish alphabet twice. The speakers are grouped intoá
sets ofç(¨ speakers each, referred to as isolet1 through
to train on the (cid:2)rst ç(¨
training set of9`á(ß(¨ examples, and test on isolet5 con-
taining 9`á(á(ä examples (1 utterance is missing in the
task of classifying the (cid:2)rst9<ç
phabet from the last 9<ç . The experimental set-up is
eredç(¨ binary classi(cid:2)cation problems corresponding
¸ utterances
toç(¨ splits of the training data where allá

database due to poor recording). We considered the
letters of the English al-

meant to simulate a real-world situation: we consid-

21Ø
b
P


Figure 2: Two Moons Dataset: Best decision surfaces using RBF kernels for SVM, TSVM and Laplacian SVM.
Labeled points are shown in color, other points are unlabeled.
Transductive SVM

Laplacian SVM

SVM

2.5

2.5

2.5

2

1.5

1

0.5

0

−0.5

−1

−1.5

−1

0

1

2

2

1.5

1

0.5

0

−0.5

−1

−1.5

−1

0

1

2

2

1.5

1

0.5

0

−0.5

−1

−1.5

−1

0

1

2

Figure 3: Two Moons Dataset: Laplacian SVM with increasing intrinsic regularization.

SVM

Laplacian SVM

Laplacian SVM

2

1

0

−1

−1
 g

0

1
A = 0.03125  g

2
I = 0

2

1

0

−1

2

1

0

−1

2

I = 0.01

−1
 g

0

1
A = 0.03125  g

2
I = 1

−1
 g

0

1
A = 0.03125  g

Figure 4: USPS Experiment - Error Rates at Precision-Recall Breakeven points for 45 binary classi(cid:2)cation prob-
lems

RLS vs LapRLS

RLS
LapRLS

10

20

30

40

45 Classification Problems

Out−of−Sample Extension

20

15

10

5

0

15

10

5

t

s
e
a
R

 
r
o
r
r

E

)
t
s
e
T
(
 

S
L
R
p
a
L

20

15

10

5

0

15

10

5

t

s
e
a
R

 
r
o
r
r

E

)
t
s
e
T
(
 

M
V
S
p
a
L

0

0

5

10

15

LapRLS (Unlabeled)

0

0

5

10

15

LapSVM (Unlabeled)

SVM vs LapSVM

TSVM vs LapSVM

SVM
LapSVM

10

20

30

40

45 Classification Problems

Out−of−Sample Extension

t

s
e
a
R

 
r
o
r
r

E

20

15

10

5

0

15

TSVM
LapSVM

10

20

30

40

45 Classification Problems

Std Deviation of Error Rates

v
e
D
d
S

t

 

10

 
)
x
(
 

M
V
S
T

 
,
 
)
o
(
 

M
V
S

5

0

0

2

LapSVM Std Dev

4

6

22e
t
a
R

 
r
o
r
r

E
 
e
g
a
r
e
v
A

9

8

7

6

5

4

3

2

1

0

2  

4  

e
t
a
R

 
r
o
r
r

E
 
e
g
a
r
e
v
A

10

9

8

7

6

5

4

3

2

1

0

2  

4  

Figure 5: USPS Experiment - Mean Error Rate at Precision-Recall Breakeven points as a function of number of
labeled points (T: Test Set, U: Unlabeled Set)

RLS vs LapRLS

SVM vs LapSVM

RLS (T)
RLS (U)
LapRLS (T)
LapRLS (U)

SVM (T)
SVM (U)
LapSVM (T)
LapSVM (U)

Number of Labeled Examples

8   16  32  64  128

Number of Labeled Examples

8   16  32  64  128

Figure 6: Isolet Experiment - Error Rates at precision-recall breakeven points of 30 binary classi(cid:2)cation problems

RLS vs LapRLS

SVM vs TSVM vs LapSVM

)
t

e
s
 

l

d
e
e
b
a
n
u
(
 

l

t

e
a
R

 
r
o
r
r

E

)
t
e
s
 
t
s
e
t
(
 
s
e
t
a
R

 
r
o
r
r

E

28

26

24

22

20

18

16

14

35

30

25

0

20

0

RLS
LapRLS

)
t
e
s
 

l

l

d
e
e
b
a
n
u
(
 
s
e
a
R

t

 
r
o
r
r

10
Labeled Speaker #

20

RLS vs LapRLS

30

RLS
LapRLS

E

)
t
e
s
 
t
s
e
t
(
 
s
e
t
a
R

 
r
o
r
r

E

SVM
TSVM
LapSVM

0

10
Labeled Speaker #

20

30

SVM vs TSVM vs LapSVM

SVM
TSVM
LapSVM

40

35

30

25

20

15

40

35

30

25

20

10
Labeled Speaker #

20

30

0

10
Labeled Speaker #

20

30

of one speaker were labeled and all the rest were left
unlabeled. The test set is composed of entirely new
speakers, forming the separate group isolet5.

(

(this was the best value among several settings with

fully supervised problem using standard SVM). For

the best value among several settings with respect to
splits). For Laplacian

We chose to train with RBF kernels of widthè¼7é9`¨
respect to á -fold cross-validation error rates for the
SVM and RLSC we setV>ê7Î¨ª;
7w9<¨ ) (this was
¨já
mean error rates over the ç(¨
RLS and Laplacian SVM we setVbt>87
¨(¨já .
#P
7f¨;
å=æ

In Figure 6, we compare these algorithms. The fol-
lowing comments can be made:
(a) LapSVM and
LapRLS make signi(cid:2)cant performance improvements
over inductive methods and TSVM, for predictions on
unlabeled speakers that come from the same group
as the labeled speaker, over all choices of the labeled

speaker. (b) On Isolet5 which comprises of a separate
group of speakers, performance improvements are
smaller but consistent over the choice of the labeled
speaker. This can be expected since there appears to
be a systematic bias that affects all algorithms, in fa-
vor of same-group speakers. For further details, see
[4].

5.4 Regularized Spectral Clustering and Data

Representation

When all training examples are unlabeled, the op-
timization problem of our framework, expressed in
Eqn 6 reduces to the following clustering objective
function :

FHGJI
K(LM

VX1

(12)

23Ø
P


N
?
1

.
U

?



?
Figure 7: Two Moons Dataset: Regularized Clustering

2

1

0

−1

2

1

0

−1

2

1

0

−1

−1

 g

0

1
A = 1e−06  g

2
I = 1

−1

 g

0

1
A = 0.0001  g

2
I = 1

−1

 g

1
0
A = 0.1  g
I = 1

2

is a regularization parameter that
controls the complexity of the clustering function. To
avoid degenerate solutions we need to impose some
additional conditions (cf. [2]).
It can be easily seen
that a version of Representer theorem holds so that

å"ë

å=æ

where V7
the minimizer has the form?
VX1

7¯A(C4DYFGJI
Nï<ðYñ
íî

substituting back in Eqn. 12, we come up with the fol-
lowing optimization problem:

%h
	

"ìE By

3SR

is the vector of all ones and

is the corresponding Gram matrix.

whereó
<;";<;=
and%
Letting be the projection onto the subspace of
orthogonal to %©ó , one obtains the solution for the

constrained quadratic problem, which is given by the
generalized eigenvalue problem

7Í

(13)

!V%U+%

%¾ô7Bõª°%
7¿ô

ô
, whereô

is the
The (cid:2)nal solution is given by
eigenvector corresponding to the smallest eigenvalue.
The framework for clustering sketched above pro-

vides a regularized form spectral clustering, whereV

controls the smoothness of the resulting function in
the ambient space. We also obtain a natural out-of-
sample extension for clustering points not in the origi-
nal data set. Figure 7 shows the results of this method
on a two-dimensional clustering problem.
By taking multiple eigenvectors of the system in
Eqn. 13 we obtain a natural regularized out-of-sample
extension of Laplacian eigenmaps [1]. This leads to
new method for dimensionality reduction and data
representation. Further study of this approach is a di-
rection of future research.
Acknowledgments. We are grateful to Marc Coram,
Steve Smale and Peter Bickel for intellectual support
and to NSF funding for (cid:2)nancial support. We would
like to acknowledge the Toyota Technological Insti-
tute for its support for this work.

References

[1] M. Belkin, P. Niyogi, Using Manifold Structure for Par-

tially Labeled Classi(cid:2)cation, NIPS 2002.

[2] M. Belkin, P. Niyogi, Laplacian Eigenmaps for Di-
mensionality Reduction and Data Representation, Neural
Computation, June 2003

[3] M. Belkin, I. Matveeva, P. Niyogi, Regression and Regu-

larization on Large Graphs, COLT 2004.

[4] M. Belkin, P. Niyogi, V. Sindhwani, Manifold Regu-
larization : A Geometric Framework for Learning From
Examples, Technical Report, Univ. of Chicago, Depart-
ment of Computer Science, TR-2004-06. Available at :
http://www.cs.uchicago.edu/research/publications/
techreports/TR-2004-06

[5] K. Bennett and A. Demirez, Semi-Supervised Support

Vector Machines, NIPS 1998

[6] Y. Bengio, O. Delalleau and N.Le Roux, Ef(cid:2)cient Non-
Parametric Function Induction in Semi-Supervised Learn-
ing, Technical Report 1247, DIRO, University of Mon-
treal, 2004.

[7] A. Blum, S. Chawla, Learning from Labeled and Unlabeled

Data using Graph Mincuts, ICML 2001.

[8] A. Blum, T. Mitchell, Combining Labeled and Unlabeled

Data with Co-Training, COLT 1998

[9] O. Bousquet, O. Chapelle, M. Hein, Measure Based Reg-

ularization, NIPS 2003

[10] Chapelle, O., J. Weston and B. Schoelkopf, Cluster Ker-

nels for Semi-Supervised Learning, NIPS 2002.

[11] T. Joachims, Transductive Inference for Text Classi(cid:2)cation

using Support Vector Machines, ICML 1999.

[12] A. Smola and R. Kondor, Kernels and Regularization on

Graphs, COLT/KW 2003.

[13] B. Schoelkopf, C.J.C. Burges, V. Vapnik, Extracting Sup-

port Data for a Given Task, KDD95.

[14] M. Seeger Learning with Labeled and Unlabeled Data,

Tech Report. Edinburgh University (2000)

[15] Martin Szummer, Tommi Jaakkola, Partially labeled

classi(cid:2)cation with Markov random walks, NIPS 2001,.

[16] V. Vapnik,

Statistical Learning Theory, Wiley-

Interscience, 1998.

[17] D. Zhou, O. Bousquet, T.N. Lal, J. Weston and B.
Schoelkopf, Learning with Local and Global Consistency,
NIPS 2003.

[18] X. Zhu, J. Lafferty and Z. Ghahramani, Semi-supervised
learning using Gaussian (cid:2)elds and harmonic functions,
ICML 2003.

24

@
7



]
3
3
]
ò
î
.

ò
R

?
1

.
U

?



?
]
]

]





]
Distributed Latent Variable Models of Lexical Co-occurrences

John Blitzer

Department of Computer
and Information Science
University of Pennsylvania

Philadelphia, PA 19104

Amir Globerson

Interdisciplinary Center
for Neural Computation
The Hebrew University
Jerusalem 91904, Israel

Fernando Pereira

Department of Computer
and Information Science
University of Pennsylvania

Philadelphia, PA 19104

Abstract

Low-dimensional representations for lex-
ical co-occurrence data have become in-
creasingly important
in alleviating the
sparse data problem inherent in natural lan-
guage processing tasks. This work presents
a distributed latent variable model for in-
ducing these low-dimensional representa-
tions. The model takes inspiration from
both connectionist language models [1, 16]
and latent variable models [13, 9]. We give
results which show that the new model sig-
niﬁcantly improves both bigram and trigram
models.

1 Introduction

Data sparseness is a central problem in machine learn-
ing for natural-language processing tasks such as pars-
ing, language modeling, machine translation, and au-
tomatic summarization [5, 10, 3]. All these tasks use
sparse data to estimate lexical co-occurrence probabil-
ities. One example is modeling the probability p(wjh)
that a word w occurs in the context of some other word
or words h.

The most common way of dealing with the sparse data
problem is to interpolate the full context with shorter
contexts, combining the full and shortened statistics
into a smoother overall estimate (see [4]). Interpola-
tion models are simple and reasonably effective, but
they fail to take into account useful regularities across
contexts.

An effective approach to capturing those regularities
is to map contexts into low-dimensional representa-

tions, and then use those representations to predict w.
Two lines of work which have used these ideas are
latent variable models and distributed connectionist
models.

In latent variable models, one introduces an unob-
served discrete random variable with low cardinality,
which represents an underlying class of contexts, and
separates the context from the word w. The parame-
ters of the model are then estimated via EM or related
algorithms [13, 9].

Distributed models map contexts to continuous low
dimensional vectors g(h) 2 <n. The distribution
p(wjh) is then modeled as a non linear function of
g(h). Recent work by Bengio et al. [1] and by Xu et
al. [16] has shown that this approach yields state of
the art performance.

The multidimensional representation of distributed
models is attractive, since it can be thought of as rep-
resenting different, possibly independent, properties
of the context. On the other hand, in latent models
the intermediate representation has a clear probabilis-
tic interpretation.

In this work, we suggest a model that combines the
advantages of the above approaches by using a vector
of discrete latent variables. Our latent variable model
can be nicely described as a directed graphical model,
which also encompasses single latent variable models
such as the aggregate Markov model (AMM) of Saul
and Pereira [13]. Because it uses a vector of latent
variables, it also extends naturally to more general n-
grams. We show empirically that our model signiﬁ-
cantly outperforms the AMM on a verb-object bigram
modeling task, and we further demonstrate improved
performance over a standard baseline for trigram lan-

25guage modeling.

The rest of the paper is organized as follows. Section
2 reviews the AMM and introduces the distributed la-
tent variable model. Section 3 describes the EM algo-
rithms for optimizing the model. Section 4 describes
our experimental procedures and results. We conclude
in Section 6.

2 Distributed Latent Variable Models

In what follows, we describe a model for the proba-
bility of observing a word w given a history of previ-
ous words h. We begin with a single word history, in
order to compare to standard latent models, and then
discuss extensions to multivariate histories. The sim-
plest, non-distributed, latent model assumes the ex-
istence of a low cardinality hidden variable z which
separates w and h in the sense that it makes them con-
ditionally independent

p(w; hjz) = p(wjz)p(hjz)

.

The corresponding graphical model is the Bayes net
in Figure 1. The conditional probability of w given h
is obtained by marginalizing over z:

p(wjh) = X

z

p(zjh) (cid:1) p(wjz)

.

The parameters of this model are p(zjh) and p(wjz).
The expression for the conditional distribution sug-
gests that z can be thought of as a clustering of h,
from which w is then predicted.

Saul and Pereira [13] used this model for language
modeling, where they called it the aggregate Markov
model (AMM). Hofmann and Puzicha [9] studied it as
a special case of what they call “aspect” models. The
AMM also falls under the rubric of mixture models.
The distribution p(wjh) can be thought of as a mixture
of jzj low-dimensional distributions, p(wjz), each of
which has mixing weight p(zjh). We will make use of
this view of the latent variable model in our analysis.

To use the advantages of a distributed model, we now
assume that the latent variable is a vector of m binary
latent variables (bits)1 b = (b1; : : : ; bm). As in the
previous latent variable model, the latent variables are
assumed to separate h and w.

1Using binary latent variables simpliﬁes the notation, exposi-

tion, and implementation without real loss of generality.

h

z

w

Figure 1: AMM graphical model

A desired property of a distributed model is that its
vector elements model independent properties of their
inputs. This can be achieved in our model by con-
straining the variables bi to be conditionally indepen-
dent given h. The above requirement can be repre-
sented graphically using the Bayes net of Figure 2. To
further exploit the distributed nature of b, we use the
following multinomial logistic (also known as condi-
tional maximum entropy) model for p(wjb)

p(wjb) =

1

Z(b)

exp

m

X

i=1

 (bi; w)

(1)

with separate interaction potentials  (bi; w) for each
variable bi. As in standard condtional maximum en-
tropy models, we assume  (bi; w) is an arbitrary, real-
valued function of bi and w.
We refer to the above model as the distributed Markov
model (henceforth DMM). The distribution it induces
is speciﬁed as follows:

p(wjh) = X

b

p(bjh) (cid:1) p(wjb)

= X

b

m

Y

i=1

p(bijh) (cid:1)

1

Z(b)

exp

m

X

i=1

 (bi; w)

.

The parameters of the model are the binomial param-
eters p(bijh), and the real-valued functions  (bi; w).
The distribution p(wjh) can be seen to be a mixture of
2m components. However, the DMM has only O(m)
parameters. This should be contrasted with the AMM
which needs O(2m) parameters to model a mixture
of the same size. When the latent variable has a dis-
tributed nature, we expect the DMM model to outper-
form the standard mixture model, since its fewer pa-

26h

b1

b2

. . .

bm

w

Figure 2: Graphical model corresponding to the distributed latent
variable model.

h1

h2

b1

b2

. . .

bm

cn

. . .

c2

c1

w

Figure 3: Graphical model corresponding to the multivariate his-
tory DMM

rameters make it less likely to overﬁt. This is indeed
seen in the experiments described later.

2.1 Multivariate Histories

The distributed model is easily extended to multi-
word histories. For ease of exposition, we discuss here
the two-word history (trigram) case. Each word in the
history is encoded with a separate vector of latent vari-
ables as shown in the graphical model of of Figure 3.

We denote latent variables encoding h1 and h2 by
b = (b1; : : : ; bm) and c = (c1; : : : ; cn) respectively.
The distribution p(wjb; c) is assumed to factor with
respect to the latent variables as in Equation 1. The in-
teraction potentials for c will be denoted by  (ci; w).
The resulting distribution p(wjh1; h2) is a mixture of
2m+n elements, with O(m + n) parameters. The vec-
tors b and c might have different lengths, allowing us
to use more latent variables for more recent history
elements, for example.

3 Learning Distributed Models

We now discuss the estimation of the parameters spec-
ifying the distributed model, from a given training
set. We focus on the two-word history case. Since
the model is a mixture distribution, its parameters
may be estimated using the expectation-maximization
algorithm [7]. Applications of EM to learning sin-
gle latent variable models are described by Saul and
Pereira [13], and Hofmann and Puzicha [9].

the iteration t of

In what follows we denote by (cid:2)(t)
the full pa-
rameter set at
the EM algo-
rithm. Recall that the free parameters are the bino-
mial parameters p(bijh1); p(cjjh2) and the functions
 (bi; w);  (cj ; w). We denote all parameters at time
t with a superscript t.

In the E step of the algorithm, posterior probabilities
of the latent variables are calculated given the model
(cid:2)(t). For the DMM, this posterior is 2

p(t+1)(b; cjw; h; (cid:2)(t)) /

p(t)(wjb; c)p(t)(bjh1)p(t)(cjh2)

Observe that, because of the DMM’s factored form,
the posterior can be computed as a normalized prod-
uct of mixture weights and mixture components. Be-
cause of this, the histories h and predicted words w
decouple, and we can compute the partition function
Z(b; c) independently of h. Thus the E step for the
model requires O(L (cid:1) 2m+n) time, where L refers to
the total number of training instances. This can be
signiﬁcantly smaller than the required time for other
distributed models.

From this, we construct
the joint distribution
p(t+1)(h; w; b; c) over the observed and latent vari-
ables

p(t+1)(h; w; b; c) / p(t+1)(b; cjh; w; (cid:2)(t))p0(h; w)

where p0(h; w) is the empirical distribution of the ob-
served variables.

The M step uses the above posteriors to estimate a new
parameter set (cid:2)(t+1). The parameters p(t+1)(bijh1)
and p(t+1)(cjjh2) are easily obtained by marginaliza-
tion and conditionalization from p(t+1)(h; w; b; c).

The parameters  (bi; w);  (cj ; w) have no closed-
form expression, due to the dependencies between

2We use h to denote (h1; h2) for brevity

27the latent variables induced by the partition function
Z(b; c). However, as is standard for conditional max-
imum entropy models like that of Equation 1, the ex-
pected complete data log-likelihood is maximized for
the values of the parameter vector  (t+1) that satisfy
the marginal constraints

q(w; bi) = p(t+1)(w; bi)
q(w; cj) = p(t+1)(w; ci)

where

q(w; b; c) = p(wjb; c;  (t+1))p(b; c)

is the model-expected marginal count of w and b; c.
The above equations can be solved iteratively for
 (t+1)(w; bi) with generalized iterative scaling (GIS)
[6], which uses the following parameter update

(cid:1) (t+1)(w; bi) =

1
C

log

p(t+1)(w; bi)

q(w; bi)

where C is an upper bound on the number of terms in
the exponent in Equation 1. Similar updates are used
for  (w; ci).

3.1 Overrelaxed Updates and Regularization

In this section we discuss brieﬂy two practical issues
related to the learning algorithm.

First, both GIS and EM are known to be slow to con-
verge, so that the doubly-iterative EM algorithm pro-
posed in the previous section is impractically slow
without modiﬁcation. To make the algorithm practi-
cal, we use only a few GIS steps per EM step and
then apply an adaptive, overrelaxed update [12]. For
large models, this modiﬁed update gives convergence
in under 75 iterations, whereas the standard EM up-
date does not.

Secondly, while both latent variable models are in-
tended to smooth a conditional distribution, they can
also overﬁt their training data, in particular when the
number of mixture components is large. Because of
this, we sometimes use a deterministic annealing vari-
ant of EM [9, 14], where a free parameter correspond-
ing to temperature is optimized on heldout data.

4 Experimental Evaluations

it to single latent variable models. We then apply it to
the more complex task of trigram modeling.

4.1 Modeling Verb Object Association

We begin with modeling the co-occurrence of bigrams
composed of verbs followed by objects. The task is to
obtain a model of the conditional distribution p(ojv)
of seeing an object given the preceding verb.

Our data come from a subset of the Penn Treebank
Wall Street Journal Corpus [11]. This is a set of one
million words of Wall Street Journal text, where each
sentence is annotated with its syntactic structure in
the form of a parse tree. The data are extracted from
the parse trees by ﬁnding all right branching parent-
modiﬁer pairs where the parent is tagged as a verb
and the child is tagged as a noun.
Instances of the
data then correspond roughly to verbs and objects,
both direct and indirect, but also can include other
nouns such as predicate nominals and the subjects in
subject-verb inversions. The data contain 50,205 such
verb-object pairs, and there are 5191 unique verbs and
8470 unique nouns, so the matrix is quite sparse. In
order to avoid the problem of unseen words, we col-
lapsed all low-count words into a single token. The
count threshold for this normalization also affects the
sparseness of the matrix, and we performed experi-
ments which varied it.

The dataset was divided into 9-1 training-test splits,
and we further divided the training set to give us held-
out data on which to optimize model free parameters.

We use a bigram model smoothed by deleted interpo-
lation as a baseline. This model gives the probability
of an object given a verb as:

pinterp
BG (ojv) = (cid:21)1pM L(ojv) + (cid:21)2pM L(o) + (cid:21)3pU (2)

Here the weights (cid:21)i are positive and sum to 1. The
three distributions interpolated are the maximum like-
lihood bigram, unigram, and uniform distributions.
Following Jelinek [10], we bin the histories based on
frequency and set the weights to maximize the likeli-
hood of heldout data.

Given a distributed model pDM (ojv) we interpolate it
with the baseline by adding the term (cid:21)4pDM (ojv) to
Equation 2 and determining the weights as above.

To evaluate our distributed latent variable model we
ﬁrst apply it to modeling bigrams, in order to compare

The baseline and distributed models are evaluated us-
ing data predictive perplexity. For a model p(ojv),

28l

y
t
i
x
e
p
r
e
P

1750

1700

1650

1600

1550

1500

1450
8

Unknown Threshold = 5

BG
AMM
DMM

Unknown Threshold = 2

BG
AMM
DMM

1650

1600

1550

1500

1450

l

y
t
i
x
e
p
r
e
P

32

64

128

Number of Mixture Components

512

1400
8

32

64

128

Number of Mixture Components

512

Figure 4: Perplexity Results for all three latent variable models for varying numbers of mixture components with two unknown word
thresholds. An AMM with k mixture components has a latent class variable that takes on k values. A DMM with k mixture components
has log(k) binary latent variables

Table 1: Percentage improvement over the baseline smoothed bi-
gram model for the best latent variable models of each type. UNK
refers to the unknown word threshold.

% Improve

over BG UNK=2 UNK=5

AMM 8.6%
DMM 12.8%

7.6%
12.5%

n Pv;o c(o; v) log p(ojv)i.

the perplexity on a test set of verbs and objects is
Ptest = exph (cid:0) 1
Here c(o; v) refers to the count of a verb-object bi-
gram, and n is the total number of bigrams in the cor-
pus.

Figure 4 gives perplexity results for the latent vari-
able models with varying numbers of mixture com-
ponents. The latent variable models are trained with
annealed EM as described in Section 3.1, and the per-
plexities reported are for interpolated models as de-
scribed above.

While the single latent variable model (AMM) does
give better results for 8 mixture components, the dis-
tributed model consistently outperforms it for all other
numbers of mixture components. It is also worthwhile
to note that the AMM overﬁts its training data, even
when annealed, while the distributed model shows no
sign of overﬁtting, even when the number of mixture
components becomes quite large. This is because the
distributed model has a much more compact represen-
tation for the same number of mixture components.
As mentioned before, the number of parameters in the

distributed model scales logarithmically in the num-
ber of mixture components, but it scales linearly for
the AMM.

As Table 1 shows, the best distributed models can im-
prove the baseline by nearly 13%. In the next section,
we examine the kinds of lexical “clusterings” discov-
ered by the AMM and DMM.

4.1.1 Analysis of Lexical Co-occurrence

Clusterings

One way to analyze the latent variable models is to
examine the distributions p(zjv), p(ojz) for the AMM
and p(bjv), p(ojb) for the DMM. In the AMM, verbs
v for which p(^zjv) is high can be thought of as be-
longing to the ^z cluster. Similarly, objects o for which
p(oj^z) is high can be thought of as belonging to the
^z cluster. Since the latent variable models here are
mixture models, analyzing verbs and objects as be-
longing to one single cluster can hide some subtleties.
Nonetheless, examining the parameters in this way
provides us with useful insight into their representa-
tions of lexical co-occurrences

Table 2 shows one such “clustering” of the 200 most
frequent verbs and 200 most frequent objects induced
by the 32-class AMM on the verb-object data. For
verbs and objects v and o, we assign them to the
cluster ^z corresponding to ^z = argmax
p(zjv) and

^z = argmax

p(ojz) respectively. We display the top

z

z

8 clusters, sorted by the highest p(zjv) value for verbs
in the cluster.

29Class
1
2
3
4
5
6
7
8

p(zjv)
named
been, become, told, asked
put, build
did, do
are, used
called, ﬁnd, know
consider, approved, following
give, gives, giving, given, lost

p(ojz)
chairman, president
issue
funds, system
it, business, something
issues
what
plan, bid, program, changes, proposal, bill
support, right, money

Table 2: 8 classes induced by the 32 class AMM. The ﬁrst column shows the verbs for which this class is the most probable. The second
column shows the nouns which are most probable given this class.

Class
1
2
3
4
5
6
7
8

p(ojb)
executive
point, %, cents, points

p(bjv)
said, says, were
held, dropped, yield, rose, grew
ended, ending, began, sent, reached Nov., report, March, agreement, June
is, be, been, named, become
closed
set, consider, begin, rejected, made
told, asked, help, called, tell
did, does, do, play, call, know

director, chairman, president, part, reason
year, Tuesday, week, Wednesday, yesterday
acquisition, sale, plan, plans
us, investors, people, him, me
you, what, work, role, something

Table 3: 8 classes induced by the 5 variable DDM. The ﬁrst column shows the verbs for which this class is the most probable. The
second column shows the nouns which are most probable given this class.

Table 3 gives a similar clustering induced by the 5-
variable DMM. The 8 clusters are chosen in the same
fashion. Both models ﬁnd some reasonable clusters
of verbs and objects, but the AMM clusters are a little
less sharply deﬁned, and it induces some clusters that
seem quite counterintuitive. The word “issue” is in a
separate cluster from “issues,” for instance.

4.2 Trigram Language Modeling

In this section, we evaluate our distributed latent vari-
able model on trigram language modeling. Trigram
models are widely used in speech recognition because
they are easy to build and efﬁcient to apply. Trigram
language models also usually generalize in a straight-
forward way to longer contexts. Our data for this ex-
periment also come from the treebank portion of the
Wall Street Journal restricted to 10,000 distinct words.
The dataset is described more completely in [17] and
contains sections for training, optimizing free parame-
ters parameters and testing. For these experiments, we
do not anneal either model. Instead we regularize the
models by stopping the EM algorithm when the mod-
els begin to overﬁt development data. For this data,
annealing is not effective at regularizing the AMM,
and annealing the DMM did not make a signiﬁcant
difference after interpolation.

Figure 5(a) gives perplexity results for distributed

models with varying numbers of latent variables per
word. It is natural to suppose that w2 is the more effec-
tive predictor of w3, and this is indeed shown in these
experiments. In fact for all but the 10-bit case, it is
always better to allocate all of them to the most recent
word in the history. Even then, the models show little
sign of saturating the amount of information present
in either of the histories.

We also compared our model with an interpolated
Kneser-Ney trigram model. The interpolated Kneser-
Ney model is one of the most effective trigram lan-
guage models, and Chen and Goodman demonstrate
that a variant of this model consistently outperforms
all other interpolation and backoff smoothing tech-
niques [4] 3. We use the Good-Turing estimate of the
parameters of the Kneser-Ney model and we combine
the AMM and DMM with it by linearly interpolating
the two trained models. As before, we set the weights
to maximize the likelihood of heldout data.

Figure 5(c) shows learning curves for the distributed
model when interpolated with the trigram baseline de-
scribed above. Again we compare with an aggregate
Markov model. This time, the AMM is used only
to smooth the distribution p(w3jw2). As with the
verb-object bigram results, we compare two models

3This variant, modiﬁed Kneser-Ney, can achieve a perplexity

of 143.9 on this dataset.

30(a) Perplexities of models with different
numbers of latent variables

b(w2)
3
4
5
6
7
8
9
10

c(w1)
2
346
317
300
285
277
270 X
X
X

1
361
329
310
292
280
273
261 X
X

0
379
336
315
295
283
274
269
263 X

4
344
316
296

3
343
321
299
283 X
273 X
X
X
X

146

144

142

140

138

136

l

y
t
i
x
e
p
r
e
P

134
8

16

Trigram Model Smoothing Results

Kneser−Ney
AMM
DMM

512

1024

256
32
Number of Mixture Components

128

64

(c) Learning curves for DMM and AMM models

with varying numbers of mixture components

Figure 5: Results of trigram language modeling experiments

with identical numbers of mixture components. For
each bit count, we choose the DMM with the low-
est heldout data perplexity. For all but 10 bits (1024
mixture components), this corresponds to allocating
all bits to the most recent word. While the DMM
slightly outperforms the AMM for larger numbers of
mixture components, both models improve similarly
(6.6 versus 6.8%) on the Kneser-Ney baseline. One
explanation for the difference between these results
and the verb-object bigram results is the difference in
data sparseness. The AMM quickly overﬁts the verb-
object data, but it is much harder to overﬁt the 10,000-
word vocabulary trigram data.

5 Related Work and Discussion

Aside from Saul and Pereira [13], there is also other
work on applying ideas similar to ours to language
modeling. Wang et al.
[15] investigate a language
model based on what they call the latent maximum
entropy principle. Like our distributed models, latent
maximum entropy models are mixture models. Sim-
ilarly, like our factored form from Equation 1, latent
maximum entropy models are maximum entropy for
a ﬁxed posterior distribution over their hidden fea-
tures. However, unlike our model, the Wang et al.
[15] model is not distributed and uses a single latent
variable.

The models which are most similar in spirit to ours
are the connectionist models of Bengio [1] and Xu
[17]. These models combine a neural network with a
softmax output for probabilities. They are not sparse,

and because of this, they must use O(H (cid:1) V ) time per
epoch, where H refers to the number of unique histo-
ries and V refers to the vocabulary size. For most cor-
pora, this number is prohibitively large. Finally, we
recently introduced a much faster model which com-
bines dimensionality reduction for continuous embed-
ding of histories with a hierarchical mixture of experts
for faster normalization [2].

Our distributed latent variable model is fully proba-
bilistic, and its factored form allows it to avoid the
prohibitively large O(H (cid:1) V ) calculation of the earlier
connectionist models. Recall that the DMM requires
time O(L (cid:1) 2m+n). Since L is typically close to H (for
our trigram data, L is 1 million and H is 600,000), this
results in much faster training times when m and n
are small. When m and n are large, though, the DMM
also faces speed issues. The coupling of the latent
variables forces us to sum over all mixture compo-
nents when computing the expectations in the E-step.
While this is possible for 1024-component mixtures,
it becomes too large for more mixture components on
larger corpora.

In terms of model form and inference, our model is
closely related to the factorial hidden Markov model
[8]. The factors of the factorial HMM correspond to
our latent bits, but there are two major differences be-
tween the two models: The factorial HMM is a gener-
ative model in which the observed variables at a time
slice are generated from the factors. By contrast, our
DMM assumes that the the latent bits are distributed
conditioned on a history. Furthermore, the factorial

31[3] P. Brown, S. A. D. Pietra, V. J. D. Pietra, and R. L. Mercer.
The mathematics of statistical machine translation. Compu-
tational Linguistics, 19(2):263–311, 1993.

[4] S. Chen and J. Goodman. An empirical study of smoothing
techniques for language modeling. In Proceedings of ACL,
1996.

[5] M. Collins. Head-driven Statistical Models for Natural Lan-
guage Parsing. PhD thesis, University of Pennsylvania,
1999.

[6] J. Darroch and D. Ratcliff. Generalized iterative scaling
for log-linear models. The Annals of Mathematic Statistics,
43:1470–1480, 1972.

[7] A. Dempster, N. Laird, and D. Rubin. Maximum likelihood
from incomplete data via the EM algorithm. Journal of the
Royal Statistical Society, 39:1–38, 1977.

[8] Z. Ghahramani and M. I. Jordan. Factorial hidden markov

models. Mach. Learn., 29(2-3):245–273, 1997.

[9] T. Hofmann and J. Puzicha.

Statistical models for co-

occurrence data. Technical Report AIM-1625, MIT, 1998.

[10] F. Jelinek. Statistical Methods for Speech Recognition. The

MIT Press, 1997.

[11] M. P. Marcus, B. Santorini, and M. A. Marcinkiewicz.
Building a large annotated corpus of english: The penn tree-
bank. Computational Linguistics, 19(2):313–330, 1994.

[12] R. Salakhutdinov and S. Roweis. Adaptive overrelaxed
In Proceedings of ICML,

bound optimization methods.
2003.

[13] L. Saul and F. Pereira. Aggregate and mixed-order Markov
models for statistical language processing. In Proceedings
of EMNLP, 1997.

[14] N. Ueda and R. Nakano. Deterministic annealing variant
In Advances in Neural Information

of the EM algorithm.
Processing Systems 7, 1995.

[15] S. Wang, D. Schuurmans, F. Peng, and Y. Zhao. Semantic n-
gram language modeling with the latent maximum entropy
principle. In Proceedings of AISTATS, 2003.

[16] P. Xu, A. Emami, and F. Jelinek. Training connectionist
models for the structured language model. In Proceedings
of EMNLP, 2003.

[17] P. Xu and F. Jelinek. Random forests in language modeling.

In Proceedings of EMNLP, 2004.

[18] J. Yedidia, W. Freeman, and Y. Weiss. Understanding belief
propagation and its generalizations. In IJCAI 2001 Distin-
guished Lecture track.

HMM explicitly models the dependencies between
hidden variables at different time slices, whereas we
do not. Ghahramani and Jordan give a mean-ﬁeld ap-
proximation to the posterior for their factorial HMM.
Unfortunately, the introduction of the mean ﬁeld pa-
rameters in our model recouples h and w, resulting
in exactly the O(H (cid:1) V ) computation we avoided by
specifying its factored form.

6 Conclusion

We presented a distributed latent variable model for
lexical co-occurrence data. Using the framework of
graphical models, we derived an EM algorithm and
compared the learned models with the single latent
variable aggregate Markov model [13]. The result
was that the distributed latent variable model signif-
icantly outperforms the single latent variable AMM
and is able to improve signiﬁcantly on both bigram
and trigram baselines.

As mentioned in the previous section, our model re-
quires time exponential in the number of latent vari-
ables in order to perform exact inference. For 9 bi-
nary latent variables, this is not large, but for models
with many variables, this number quickly becomes too
large. This is due to the directed nature of our graphi-
cal model. It is worth mentioning that it is also possi-
ble to use undirected graphical models to represent the
essential conditional independences expressed in this
model. We are currently investigating such models to-
gether with approximate inference techniques [18] to
make learning and inference practical.

Acknowledgements

We would like to thank Lawrence Saul and Naftali
Tishby for valuable discussions throughout the course
of this work. We thank Peng Xu for help preprocess-
ing the data for the trigram language modeling exper-
iments. Blitzer and Pereira are partially supported by
DARPA under SRI subcontract NBCHD030010.

References

[1] Y. Bengio, R. Ducharme, P. Vincent, and C. Janvin. A neural
probabilistic language model. Journal of Machine Learning
Research, 3:1137–1155, 2003.

[2] J. Blitzer, K. Weinberger, L. Saul, and F. Pereira. Hierarchi-
cal distributed representations for statistical language mod-
eling. In Advances in Neural Information Processing Sys-
tems 17, 2004.

32On Contrastive Divergence Learning

Miguel (cid:19)A. Carreira-Perpi~n(cid:19)an(cid:3)

Geo(cid:11)rey E. Hinton

Dept. of Computer Science, University of Toronto

6 King’s College Road. Toronto, ON M5S 3H5, Canada

Email: fmiguel,hintong@cs.toronto.edu

Abstract

where the learning rate (cid:17) need not be constant. The
average log-likelihood is:

(ML)

learning

of
Maximum-likelihood
Markov random (cid:12)elds is challenging because
it requires estimates of averages that have an
exponential number of terms. Markov chain
Monte Carlo methods typically take a long
time to converge on unbiased estimates, but
Hinton (2002) showed that if the Markov
chain is only run for a few steps, the learning
can still work well and it approximately
minimizes a di(cid:11)erent function called \con-
trastive divergence" (CD). CD learning has
been successfully applied to various types of
random (cid:12)elds. Here, we study the properties
of CD learning and show that it provides
biased estimates in general, but that the bias
is typically very small. Fast CD learning
can therefore be used to get close to an ML
solution and slow ML learning can then be
used to (cid:12)ne-tune the CD solution.

Consider a probability distribution over a vector x (as-
sumed discrete w.l.o.g.) and with parameters W

p(x; W) =

1

Z(W)

e(cid:0)E(x;W)

(1)

where Z(W) = Px e(cid:0)E(x;W) is a normalisation con-
stant and E(x; W) is an energy function. This class
of random-(cid:12)eld distributions has found many practical
applications (Li, 2001; Winkler, 2002; Teh et al., 2003;
He et al., 2004). Maximum-likelihood (ML) learning of
the parameters W given an iid sample X = fxngN
can be done by gradient ascent:

n=1

W((cid:28) +1) = W((cid:28) ) + (cid:17)

@L(W; X )

@W

(cid:12)(cid:12)(cid:12)(cid:12)W((cid:28) )

(cid:3)Current address: Dept. of Computer Science & Elec-
trical Eng., OGI School of Science & Engineering, Oregon
Health & Science University. Email: miguel@cse.ogi.edu.

L(W; X ) = 1

N PN

n=1 log p(xn; W) = hlog p(x; W)i0

= (cid:0) hE(x; W)i0 (cid:0) log Z(W)

where h(cid:1)i0 denotes an average w.r.t. the data distribu-
tion p0(x) = 1
n=1 (cid:14)(x (cid:0) xn). A well-known di(cid:14)-
culty arises in the computation of the gradient

N PN

@L(W; X )

@W

@W (cid:29)
= (cid:0)(cid:28) @E(x; W)

0

@W (cid:29)
+ (cid:28) @E(x; W)

1

where h(cid:1)i1 denotes an average with respect to the
model distribution p1(x; W) = p(x; W). The average
h(cid:1)i0 is readily computed using the sample data X , but
the average h(cid:1)i1 involves the normalisation constant
Z(W), which cannot generally be computed e(cid:14)ciently
(being a sum of an exponential number of terms). The
standard approach is to approximate the average over
the distribution with an average over a sample from
p(x; W), obtained by setting up a Markov chain that
converges to p(x; W) and running the chain to equilib-
rium (for reviews, see Neal, 1993; Gilks et al., 1996).
This Markov chain Monte Carlo (MCMC) approach
has the advantage of being readily applicable to many
classes of distribution p(x; W). However, it is typically
very slow, since running the Markov chain to equilib-
rium can require a very large number of steps, and no
foolproof method exists to determine whether equilib-
rium has been reached. A further disadvantage is the
large variance of the estimated gradient.

To avoid the di(cid:14)culty in computing the log-likelihood
gradient, Hinton (2002) proposed the contrastive di-
vergence (CD) method which approximately follows
the gradient of a di(cid:11)erent function. ML learning min-
imises the Kullback-Leibler divergence

KL (p0kp1) = X

x

p0(x) log

p0(x)

p(x; W)

:

CD learning approximately follows the gradient of the

33di(cid:11)erence of two divergences (Hinton, 2002):

CDn = KL (p0kp1) (cid:0) KL (pnkp1) :

In CD learning, we start the Markov chain at the data
distribution p0 and run the chain for a small number
n of steps (e.g. n = 1). This greatly reduces both
the computation per gradient step and the variance
of the estimated gradient, and experiments show that
it results in good parameter estimates (Hinton, 2002).
CD has been applied e(cid:11)ectively to various problems
(Chen and Murray, 2003; Teh et al., 2003; He et al.,
2004), using Gibbs sampling or hybrid Monte Carlo as
the transition operator for the Markov chain. How-
ever, it is hard to know how good the parameter esti-
mates really are, since no comparison was done with
the real ML estimates (which are impractical to com-
pute). There has been a little theoretical investigation
of the properties of contrastive divergence (MacKay,
2001; Williams and Agakov, 2002; Yuille, 2004), but
important questions remain unanswered: Does it con-
verge? If so how fast, and how are its convergence
points related to the true ML estimates?

In this paper we provide some theoretical and empir-
ical evidence that contrastive divergence can, in fact,
be the basis for a very e(cid:11)ective approach for learn-
ing random (cid:12)elds. We concentrate on Boltzmann ma-
chines, though our results should be more generally
valid. First, we show that CD provides biased esti-
mates in general: for almost all data distributions, the
(cid:12)xed points of CD are not (cid:12)xed points of ML, and
vice versa (section 2). We then show, by comparing
CD and ML in empirical tests, that this bias is small
(sections 3{4) and that an e(cid:11)ective approach is to use
CD to perform most of the learning followed by a short
run of ML to clean up the solution (section 5).

To eliminate sampling noise from our investigations,
we use fairly small models (with e.g. 48 parameters)
for which we can compute the exact model distribution
and the exact distribution at each step of the Markov
chain at each stage of learning. Throughout, we take
ML learning to mean exact ML learning (i.e., with n !
1 in the Markov chain) and CDn learning to mean
learning using the exact distribution of the Markov
chain after n steps. The sampling noise in real MCMC
estimates would create an additional large advantage
that favours CD over ML learning, because CD has
much lower variance in its gradient estimates.

units x = (x1; : : : ; xv)T that encode a data vector, and
h hidden units y = (y1; : : : ; yh)T ; all units are binary
and take values in f0; 1g.

Fully visible Boltzmann machines have h = 0 and
the visible units are connected to each other. The en-
ergy is then E(x; W) = (cid:0) 1
xT Wx, where W = (wij)
2
is a symmetric v (cid:2) v matrix of real-valued weights (for
simplicity, we do not consider biases). We denote such
a machine by VBM(v). In VBMs, the log-likelihood
has a unique optimum because its Hessian is negative
de(cid:12)nite. Since @E=@wij = (cid:0)xixj, ML learning takes
the form

w((cid:28) +1)

ij

= w((cid:28) )

ij + (cid:17) (cid:0)hxixji0 (cid:0) hxixji1(cid:1)

while CDn learning takes the form

w((cid:28) +1)

ij

= w((cid:28) )

ij + (cid:17) (cid:0)hxixji0 (cid:0) hxixjin(cid:1) :

Here, pn(x; W) = pn = Tnp0 is the nth-step distri-
bution of the Markov chain with transition matrix1 T
started at the data distribution p0.

(Smolensky,
Restricted Boltzmann machines
1986; Freund and Haussler, 1992) have connections
only between a hidden and a visible unit,
i.e.,
they form a bipartite graph. The energy is then
E(x; y; W) = (cid:0)yT Wx, where we have v visible units
and h hidden units, and W = (wij) is an h (cid:2) v ma-
trix of real-valued weights. We denote such a machine
by RBM(v; h). By making h large, an RBM can be
given far more representational power than a VBM,
but the log-likelihood can have multiple maxima. The
learning is simpler than in a general Boltzmann ma-
chine because the visible units are conditionally inde-
pendent given the hidden units, and the hidden units
are conditionally independent given the visible units.
One step of Gibbs sampling can therefore be carried
out in two half-steps: the (cid:12)rst updates all the hid-
den units and the second updates all the visible units.
Equivalently, we can write T = TxTy where tx;j;i =
p(x = jjy = i; W) and ty;i;j = p(y = ijx = j; W).

Since @E=@wij = (cid:0)yixj, ML learning takes the form
(cid:0) hyixji1(cid:17)

ij + (cid:17) (cid:16)Dhyixjip(yjx;W)E0

= w((cid:28) )

w((cid:28) +1)

ij

while CDn learning takes the form

w((cid:28) +1)

ij

= w((cid:28) )

ij + (cid:17) (cid:16)Dhyixjip(yjx;W)E0

(cid:0) hyixjin(cid:17) :

1 ML and CD learning for two types

2 Analysis of the (cid:12)xed points

of Boltzmann machine

We will concentrate on two types of Boltzmann ma-
chine, which are a particular case of the model of
eq. (1).
In Boltzmann machines, there are v visible

A probability distribution over v units is a vector of
2v real-valued components (from 0 to 2v (cid:0) 1 in bi-

1Here and elsewhere we omit the dependence of T on

the parameter values W to simplify the notation.

34: xi (cid:21) 0; P2v

nary notation) that lives in the 2v{dimensional sim-
plex (cid:1)2v = fx 2 R2v
i=1 xi = 1g. Each
coordinate axis of R2v
corresponds to a state (binary
vector). We write such a distribution as p((cid:1)), when em-
phasising that it is a function, or as a vector p, when
emphasising that it is a point in the simplex. We de(cid:12)ne
a Markov chain through its transition operator, which
is a stochastic 2v (cid:2) 2v matrix T. We use the Gibbs
sampler as the transition operator because of its sim-
plicity and its wide applicability to many distributions.
For Boltzmann machines with (cid:12)nite weights, the Gibbs
sampler converges to a stationary distribution which
is the model distribution p(x; W). For an initial dis-
tribution p we then have pn = Tnp for n = 1; 2; : : : ;
and p(x; W) = p1 = T1p for any p 2 (cid:1)2v , i.e.,
T1 = p11T where 1 is the vector of ones.

PSfrag replacements

VBMs or RBMs de(cid:12)ne a manifold M within the sim-
plex, parameterised by W, with wij 2 R (we ignore
the case of in(cid:12)nite weights, corresponding to distribu-
tions in the intersection of M and the simplex bound-
ary). The learning (ML or CD) starts at a point in
M and follows the (approximate) gradient of the log-
likelihood, thus tracing a trajectory within M.

For ML with gradient learning, the (cid:12)xed points are the
zero-gradient points (maxima, minima and saddles),
which satisfy hgi0 = hgi1 where g = @E=@W. For
n-step CD, the (cid:12)xed points satisfy hgi0 = hgin. In this
section we address the theoretical question of whether
the (cid:12)xed points of ML are (cid:12)xed points of CD and vice
versa. We show that, in general,

9p0 : hgi0 = hgi1 6= hgi1
9p0 : hgi0 = hgi1 6= hgi1 :

We give a brief explanation of a framework for
analysing the (cid:12)xed points of ML and CD; full details
appear in Carreira-Perpi~n(cid:19)an and Hinton (2004). The
idea is to (cid:12)x a value of the weights and so a value of the
moments (de(cid:12)ned below), determine which data dis-
tributions p0 have such moments (i.e., the opposite of
the learning problem) and then determine under what
conditions ML and CD agree over those distributions.
Call G the jWj (cid:2) 2v matrix of energy derivatives, de-
(cid:12)ned by

Gix = (cid:0)

@E
@wi

(x; W)

where we consider W as a column vector with jWj
elements and the state x takes values 0; 1; : : : ; 2v (cid:0) 1
in the case of v binary variables. We can then write
the moments s = (cid:10)(cid:0) @E
@W(cid:11)p = (cid:0) hgip of a distribution
p as s = Gp, i.e., s is a linear function of p. Call T
the transition matrix for the sampling operator with
stationary distribution p1 (so we have p1 = Tp1).
In general, both G and T are functions of W.

p = (0001)T

w = 1

1
4

1
4

1
4

1
4

1000

w = 0

0010

w = (cid:0)1

1
3

1
3

1
3 0

0100

Figure 1: The simplex in 4 dimensions of the VBM(2).
The model has a single parameter W = w 2 ((cid:0)1; 1).
The tetrahedron represents the simplex, i.e., the set
fp 2 R4 : 1T p = 1; p (cid:21) 0g. The tetrahedron corners
correspond to the pure states, i.e., the distributions
that assign all the probability to a single state. The red
vertical segment is the manifold of VBMs, i.e., the dis-
tributions reachable by a VBM(2) for w 2 ((cid:0)1; 1).
The ML estimate of a data distribution is its orthog-
onal projection on the model manifold. The CD esti-
mate only agrees with the ML one for data distribu-
tions in the 3 shaded planes in the inset.

Now consider a (cid:12)xed value of W and let p1 be its
associated model distribution. Thus its moments are
s1 = Gp1. We de(cid:12)ne two sets P0 and P1 that depend
on s1. First, the set of data distributions p0 that have
those same moments s1 is:

P0 =

8
<
:

p0 2 R2v

:

Gp0 = s1
1T p0 = 1

p0 (cid:21) 0

:

9
=
;

Each distribution in P0 gives a (cid:12)xed point of ML. Like-
wise, de(cid:12)ne the set of data distributions p0 whose dis-
tribution p1 = Tp0 ((cid:12)rst step in the Markov chain,
i.e., what CD1 uses instead of p1) has the same mo-
ments as s1:

P1 =

8
<
:

p0 2 R2v

:

GTp0 = s1

1T p0 = 1

p0 (cid:21) 0

:

9
=
;

Both P0 and P1 are nonempty since p1 is in both.
Now we can reformulate the problem in terms of the
sets P0 and P1. For example, a distribution with p0 2
P0 and p0 =2 P1 satis(cid:12)es hgi0 = hgi1 6= hgi1 and thus
gives a (cid:12)xed point of ML but not of CD (that is, the
CD learning rule would move away from such a p1).

35In general (and ignoring technical details regarding the
inequality p0 (cid:21) 0), P0 and P1 are linear subspaces of
the same dimension because G is full rank (the mo-
ments are l.i.) and T is generally full rank. Thus we
cannot generally expect P0 = P1, so points with CD
bias are the rule; points in P0 \ P1 have no CD bias
but are the exception (the intersection being a lower-
dimensional subspace). We can make the statement
precise for a given model. For example, for VBM(2)
with Gibbs sampling we have G = (0 0 0 1) (G hap-
pens to be independent of W for VBMs), we can com-
pute T and we can work out the set P0 \ P1 for ev-
ery s1 value. The resulting set, which contains all the
data distributions for which ML and CD have the same
(cid:12)xed points (i.e., no bias), is the union (intersected
with the simplex) of the 3 planes: p11 = 0; p11 =
1
4 ; 3p01 + p11 = 1, where we write a distribution as
a 4-dimensional vector p = (p00 p01 p10 p11)T , corre-
sponding to the probabilities of the 4 states 00; : : : ; 11
(see (cid:12)g. 1). This set has measure zero in the simplex,
so CD is biased for almost every data distribution.

A reachable distribution p0 2 M is a (cid:12)xed point for
both CD and ML, as it is invariant under T (Hinton,
2002). This is consistent with the above argument,
as p0 = p1 2 P0 \ P1. The distributions of practi-
cal interest are typically unreachable because real data
are nearly always more complicated than our compu-
tationally tractable model of it.

In summary, we expect that for almost every data
distribution p0, the (cid:12)xed points of ML are not (cid:12)xed
points of CD and vice versa. This means that, in gen-
eral, CD is a biased learning algorithm. Our argu-
ment can be applied to models other than Boltzmann
machines, transition operators other than Gibbs sam-
pling, and to n > 1 (writing Tn instead of T). What
determines whether CD is biased are the hyperplanes
de(cid:12)ned by the matrices G and GT. However, non-
trivial models (i.e., de(cid:12)ning a lower-dimensional man-
ifold) may exist for which CD is not biased; an exam-
ple is Gaussian Boltzmann machines (Williams and
Agakov, 2002) and Gaussian distributions, at least in
2D (Carreira-Perpi~n(cid:19)an and Hinton, 2004).

This analysis does not imply that CD learning con-
verges (to a stable (cid:12)xed point); at present, we do not
have a proof for this. But if CD does converge, as
it appears to in practice and in all our experiments,
it can only converge to a (cid:12)xed point. Naturally, ML
does converge to its stable (cid:12)xed points (maxima) from
almost everywhere, since it follows the exact gradient
of an objective function; in the noisy sampling case
that is used in practice,
it also converges provided
the learning rate (cid:17) follows a Robbins-Monro sched-
ule (Benveniste et al., 1990), since the rule performs
stochastic gradient learning.

3 Experiments with fully visible BMs

Since CD is biased with respect to ML for almost all
data distributions, we now investigate empirically the
magnitude of the bias. In all experiments in the pa-
per, ML and CD are tested under exactly the same
conditions (unless otherwise stated). Both ML and
CD learning use the same initial weight vectors, the
same constant learning rate (cid:17) = 0:9 and the same
maximum of 10 000 iterations (which is rarely reached
for VBMs), stopping when kek1 < 10(cid:0)7 (where e =
hxixji0 (cid:0) hxixji1 is the gradient vector for ML, and
e = hxixji0 (cid:0) hxixji1 is the approximate gradient for
CD1). All the experiments use n = 1 step of Gibbs
sampling with (cid:12)xed ordering of the variables for CD
learning, because this should produce the greatest bias
(since CD (cid:0)(cid:0)(cid:0)(cid:0)!
ML). Although each of our simu-
n!1
lated models is necessarily small, our empirical results
hold for a range of model sizes and conditions, which
suggests they may be more generally valid.

In this section we consider fully visible Boltzmann
machines, denoted VBM(v), which have a single ML
It appears that CD has a single conver-
optimum.
gence point too:
for v = 2 we can prove this, and
for v 2 f3; : : : ; 10g we checked empirically by running
CD from many di(cid:11)erent initial weight vectors that it
always converged to the same point (up to a small
numerical error). Thus, we assume that CD has a
unique convergence point for VBM(v). This allows us
to characterise the bias for this model class by sam-
pling many data distributions and computing the con-
vergence point of ML and of CD.

For a given value of v we sampled a number (as large
as computationally feasible) of data distributions uni-
formly distributed in the simplex in 2v variables (see
Carreira-Perpi~n(cid:19)an and Hinton, 2004 for details of how
to generate these samples). Then we ran ML and CD
starting with W = 0 because small weights give faster
convergence on average. The results for experiments
for v 2 f2; : : : ; 10g were qualitatively similar. For
v = 2 it was feasible to sample 104 data distributions
and the results are summarised in (cid:12)gures 2{5.

The histograms in (cid:12)gs. 2{3 show the bias is very small
for most distributions. Fig. 4 shows that the KL error
(for both ML and CD) is small for data distributions
near the simplex centre. For less vague data distribu-
tions there is more variability, with some distributions
having a low error and some having a much higher
one. Generally speaking, the distributions having the
highest KL error for ML (i.e., the distributions that
are modelled worst by the VBM) are also the ones
that have the highest bias. Most of these lie near the
boundaries of the simplex, particularly near the cor-
ners. However, not all corners and boundaries are far

36400

300

200

100

0

0

400

300

200

100

0

0

0.1

0.2

0.3

0.1

0.2

0.3

PSfrag replacements

ML

0.7

0.8

0.9

PSfrag replacements

CD

3500

3000

2500

2000

1500

1000

500

0

0

0.002

0.004

0.006

0.008

0.01

0.012

0.014

Bias KL (pML; pCD)

0.5

0.4

0.6
KL (p0kpML)

Figure 3: Histogram of the symmetrised KL diver-
gence for VBM(2) between the model distributions
found by ML and CD for all 104 data distributions.
This shows that the bias of CD is almost always very
small (< 5% of the KL error obtained by ML for the
same distribution; data not shown). However, data
distributions do exist that have a relatively large bias.

0.5

0.4

0.6
KL (p0kpCD)

0.7

0.8

0.9

2:

Histograms

of KL (p0kpML)

for VBM(2) after

and
Figure
learning on 104
KL (p0kpCD)
data distributions, where pML and pCD are the
convergence points for ML and CD, respectively. The
performance of CD is very close to ML on average.

PSfrag replacements

from the model manifold; this depends on the geome-
try of the model. In (cid:12)g. 4 (for v = 2) we can discern
the geometry of the simplex in (cid:12)g. 1. The discontinu-
ity in the slope at a Euclidean distance kp0 (cid:0) uk just
less than 0:3 corresponds to the radius of the inscribed
sphere. The branch in the scatterplot which has low
error corresponds to the direction passing through the
centre and the simplex corner corresponding to the
delta distribution of the (1; 1) state (i.e., along the
VBM manifold). The other branch which has high
error and more data points corresponds to the direc-
tions passing through the centre and any of the other
3 corners (i.e., away from the VBM manifold).

As v increases, most of the volume of the simplex con-
centrates at a distance intermediate between the cor-
ners and the centre, close to the radius of the inscribed
hypersphere. Consequently, a (cid:12)nite uniform sample
contains essentially no points near the boundaries of
the simplex, which produce the highest bias. For large
v, CD has very small bias for nearly all randomly cho-
sen data distributions. Only those rare distributions
near the simplex boundaries produce a signi(cid:12)cant bias,
but these are important in practice: real-world distri-
butions are often near the boundaries (though not as
far as the corners) because large parts of the data space
have negligible probability.

Fig. 5 shows some typical learning curves. Both CD
and ML decrease in a similar way, converging at the
same rate ((cid:12)rst-order), taking the same number of it-
erations to converge to a given tolerance. CD yields a

)
(cid:1)
k
0
p
(
L
K

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

Euclidean distance p0 $ simplex centre

Figure 4: KL error for ML KL (p0kpML) (red (cid:14)) and
for CD KL (p0kpCD) (black +) vs Euclidean distance
kp0 (cid:0) uk between the data distribution and the uni-
form distribution (centre of the simplex). This Eu-
clidean distance gives a linear ordering of the data
distributions (lowest Euclidean distance: p0 is the uni-
form distribution, kp0 (cid:0) uk = 0; highest: p0 is one of
1 (cid:0) 2(cid:0)v). For
the corners of the simplex, kp0 (cid:0) uk =
clarity, not all 104 distributions are plotted.

p

higher KL error. In the lower example, the CD curve
increases slightly at the end, suggesting it came close
to the ML optimum but then moved away.

In summary, we (cid:12)nd the CD bias to be very small for
most distributions and to be highest (but still small)
with real-world distributions (near the simplex bound-
ary). This bias is small in relative terms (compared to
the KL error for ML) and absolute terms (compared
to the simplex dimensions). CD and ML converge at
about the same rate, but an ML iteration costs much

37CD
ML

102

CD
ML

10−0.07

10−0.08

)
(cid:1)
k
0
p
(
L
K

PSfrag replacements

10−0.09

100

101

10−0.5

)
(cid:1)
k
0
p
(
L
K

PSfrag replacements

10−0.51

100

101

Number of iterations

Figure 5: Learning curves for ML and CD for 2 ran-
domly chosen data distributions. Axes are in log scale.

more than a CD one in a MCMC implementation.

4 Experiments with restricted BMs

RBMs are practically more interesting than VBMs,
since they have a higher representational power. They
also introduce a new element that complicates our
study: the existence of multiple local optima of ML
and CD. This prevents the characterisation of the bias
over a large number of data distributions. Instead, we
can only a(cid:11)ord to select one data distribution (or a
few) and try to characterise the set of all optima of
ML and CD.

Given a data distribution, we generate a collection of
60 random initial weight vectors W and compute all
the optima of ML and CD that are reachable from any
of the initial weight vectors or from the optima found
by the other learning method. This requires iterat-
ing over the current set of optima with ML and CD,
until no new optima are found. The result is a bipar-
tite, self-consistent convergence graph where an arrow
A ! B indicates that ML optimum A converges to CD
optimum B under CD, or CD optimum A converges to
ML optimum B under ML. Using many di(cid:11)erent initial
weight vectors should give a representative collection

of optima and a Good-Turing estimator (Good, 1953)
can be used as a coarse indicator of how many op-
tima we missed. The graph depends on how we decide
whether two very similar optima are really the same.
The threshold and number of parameter updates have
to be carefully chosen so that truly di(cid:11)erent optima
are not confused but two discoveries of the same op-
timum are not considered di(cid:11)erent. We found that
using the symmetrised KL distance with a threshold
of 0:01 worked well with 105 parameter updates.

We ran experiments for various values of v and h and
various data distributions. Fig. 6 summarises the re-
sults for one representative case, corresponding to:
v = 6, h = 4. The data distribution was generated
from a data set of 4 binary vectors by adding an ex-
tra count of 0:1 to each possible binary vector and
renormalising (thus it is close to the simplex bound-
ary). We used 105 iterations and 60 di(cid:11)erent initial
weight vectors: 20 random N (0; (cid:27) = 0:1), 20 random
N (0; (cid:27) = 1) and 20 random N (0; (cid:27) = 10). We found
27 ML optima and 28 CD optima, and missed about
3 and 4, respectively (Good-Turing estimate).

Panel A shows a 2D visualisation of ML optima (red (cid:14))
and CD optima (black +), i.e., the visible-unit distri-
butions pML and pCD, and their convergence relations.
The blue I is the data distribution p0 (of the visi-
ble variables). To avoid cluttering the plot, pairs of
arrows A (cid:28) B are drawn as a single line without ar-
rowheads A | B. Note that many such lines are too
short to be distinguished. The 2D view was obtained
with SNE (Hinton and Roweis, 2003) which tries to
preserve the local distances. Using a perplexity of 3
to determine the local neighborhood size, SNE gives
a better visualisation than projecting onto the (cid:12)rst 2
principal components.

This panel shows an important and robust phenome-
non: ML and CD optima typically come in pairs that
converge to each other. The CD optimum always has
a greater or equal KL error than its associated ML op-
timum but the di(cid:11)erence is small. These pairs are to
be expected for CDn when n is large because CD be-
comes ML as n ! 1. However they occur very often
even for n = 1, as shown. Panels B{C show that the
choice of initial weights has a much larger e(cid:11)ect on the
KL error than the CD bias.

5 Using CD to initialise ML

The previous experiments show that CD takes us close
to an ML optimum, but that a small bias remains. An
obvious way to eliminate this bias is to use increasing
values of n as training progresses. In this section we
explore a crude version of this strategy: run CD until
it is close to convergence then use a short run of ML

389   

9   

14  

13  

14  

12  

15  
13  

23  
22  

26  

28  

25  

24  

25  

27  

26  

21  
21  

20  

12  

10  

4   

7   

8   

2   

11  

11  

6   

7   

27  

24  

23  

10  

)
(cid:1)
k
0
p
(
L
K

3   

1   

2   

5   

PSfrag replacements

15  

1   

6   

5   

4   

8   

3   

CD
CD−ML
ML

ML (104 its.)

ML (103 its.)

2.5
2.4
2.3
2.2
2.1
2
1.9
1.8
1.7
1.6
1.5
1.4
1.3
1.2
1.1

1

0.9

0.8

0.7

0.6

0.5

CD (104 its.)

100

101

103
102
CPU cost

104

105

Figure 7: Learning curves for CD-ML and ML, where
each ML iteration is scaled to cost as much as 20 CD
iterations. The axes have a log scale, so CD-ML is an
order of magnitude faster for about the same (cid:12)nal KL.

to reduce the bias. We call this strategy CD-ML. We
use a data distribution which is more representative of
a real problem. It is located on the simplex boundary
and derived from the statistics of all 3 (cid:2) 3 patches in
11000 16 (cid:2) 16 images of handwritten digits from the
USPS dataset. The 256 intensity levels are thresholded
at 150 to produce 9-dimensional binary vectors (thus
v = 9). p0 is the normalised counts of each of these
binary vectors in the 2 156 000 patches.

We used 60 di(cid:11)erent initial weight vectors: 20 ran-
dom N (0; (cid:27) = 1
3 ), 20 random N (0; (cid:27) = 1) and 20
random N (0; (cid:27) = 3). For each starting condition, two
types of learning were used: ML learning for 104 iter-
ations; and CD learning for 104 iterations, followed by
a shorter run of ML learning. We ran experiments for
h 2 f1; : : : ; 8g and found that there is a unique ML
optimum and several CD optima of varying degrees of
bias. If CD learning was followed by 1 000 iterations of
ML, all the CD optima converged to the ML optimum.

Fig. 7 shows the learning curves (i.e.,
the error
KL (p0k(cid:1)) as a function of estimated CPU time) for
the di(cid:11)erent methods with h = 8: CD (blue line), the
short ML run (1 000 iterations) following CD (green
line) and ML (red line), for a selected starting condi-
tion. We assume that each ML iteration costs 20 times
as much as each CD iteration (a reasonable estimate
for the size of this RBM). CD-ML reaches the same
error as ML but at a small fraction of the cost. Note
how sharply the CD-ML curve drops when we switch
to ML, suggesting good performance can be achieved
with very few of the expensive ML iterations.

A

16  

17  

16  

17  

18  

18  

19  

19  

20  

22  

)
D
C
p
k
0
p
(
L
K

B

0.6

0.5

0.4

0.3

0.2

0.1

PSfrag replacements

0

0

30

25

20

15

10

5

0

0

30

25

20

15

10

5

0

0

0.1

0.2

0.3

0.4

0.5

0.6

KL (p0kpML)

ML

CD

0.1

0.2

0.3

0.4

0.5

0.6

KL (p0kpML)

0.1

0.2

0.3

0.4

0.5

0.6

KL (p0kpCD)

C

PSfrag replacements

Figure 6: Empirical study of the convergence points of
ML and CD for RBM(6; 4) with a single data distri-
bution. A: 2D SNE visualization of the points (ML:
red (cid:14); CD: black +), and convergence relations among
them with ML and CD (a line without an arrowhead
stands for two arrows (cid:28), to avoid clutter). B: KL er-
ror of CD vs ML from the same initial weight vectors,
for 60 random initial weight vectors. C: histograms of
the KL error of ML and CD.

396 Conclusion

Our (cid:12)rst result is negative:
for two types of Boltz-
mann machine we have shown that, in general, the
(cid:12)xed points of CD di(cid:11)er from those of ML, and thus
CD is a biased algorithm. This might suggest that
CD is not a competitive method for ML estimation of
random (cid:12)elds. Our remaining, empirical results show
otherwise: the bias is generally very small, at least
for Gibbs sampling, since CD typically converges very
near an ML optimum. And this small bias can be elim-
inated by running ML for a few iterations after CD,
i.e., using CD as an initialisation strategy for ML, with
a total computation time that is much smaller than
that of full-(cid:13)edged ML (which will also have slight bias
because the Markov chain cannot be run forever).

The theoretical analysis of CD is di(cid:14)cult because of
the complicated form that the p1 (or pn) distribution
takes; p1 is a moving target that changes with W in a
complicated way, and depends on the sampling scheme
used (e.g. Gibbs sampling). As a result, very few the-
oretical results about CD exist. MacKay (2001) gave
some examples of CD bias, but these used unusual
sampling operators. Our analysis applies to any model
and operator (through the G and T matrices), in par-
ticular generally applicable operators such as Gibbs
sampling. Williams and Agakov (2002) showed that,
for 2D Gaussian Boltzmann machines, CD is unbiased
and typically decreases the variance of the estimates.
Yuille (2004) gives a condition for CD to be unbiased,
though this condition is di(cid:14)cult to apply in practice.

One open theoretical problem is whether the exact ver-
sion of CD converges (we believe that it does). As-
suming we can prove convergence for the exact case,
the right tools to use to prove it in the noisy case
are probably those of stochastic approximation (Ben-
veniste et al., 1990; Yuille, 2004).

Acknowledgements

This research was funded by NSERC and CFI. GEH
is a fellow of CIAR and holds a CRC chair.

References

A. Benveniste, M. M(cid:19)etivier, and P. Priouret. Adap-
tive Algorithms and Stochastic Approximations.
Springer-Verlag, 1990.

M. (cid:19)A. Carreira-Perpi~n(cid:19)an and G. E. Hinton. On con-
trastive divergence (CD) learning. Technical report,
Dept. of Computer Science, University of Toronto,
2004. In preparation.

H. Chen and A. F. Murray. Continuous restricted
Boltzmann machine with an implementable train-

ing algorithm. IEE Proceedings: Vision, Image and
Signal Processing, 150(3):153{158, June 20 2003.

Y. Freund and D. Haussler. Unsupervised learning
of distributions on binary vectors using 2-layer net-
works. In NIPS, pages 912{919, 1992.

W. Gilks, S. Richardson, and D. J. Spiegelhalter, edi-
tors. Markov Chain Monte Carlo in Practice. Chap-
man & Hall, 1996.

I. J. Good. The population frequencies of species
and the estimation of population parameters.
Biometrika, 40(3/4):237{264, Dec. 1953.

X. He, R. S. Zemel, and M. (cid:19)A. Carreira-Perpi~n(cid:19)an. Mul-
tiscale conditional random (cid:12)elds for image labeling.
In CVPR, pages 695{702, 2004.

G. Hinton and S. T. Roweis. Stochastic neighbor em-

bedding. In NIPS, pages 857{864, 2003.

G. E. Hinton. Training products of experts by mini-
mizing contrastive divergence. Neural Computation,
14(8):1771{1800, Aug. 2002.

S. Z. Li. Markov Random Field Modeling in Image

Analysis. Springer-Verlag, 2001.

D. J. C. MacKay.

Failures of

the one-step
learning
at
http://www.inference.phy.cam.ac.uk/mackay/
abstracts/gbm.html, 2001.

algorithm.

Available

online

R. M. Neal. Probabilistic inference using Markov
chain Monte Carlo methods. Technical Report
CRG{TR{93{1, Dept. of Computer Science, Uni-
versity of Toronto, Sept. 1993.
Available on-
line at ftp://ftp.cs.toronto.edu/pub/radford/
review.ps.Z.

P. Smolensky.

Information processing in dynamical
systems: Foundations of harmony theory. In D. E.
Rumelhart and J. L. MacClelland, editors, Par-
allel Distributed Computing: Explorations in the
Microstructure of Cognition. Vol. 1: Foundations,
chapter 6. MIT Press, 1986.

Y. W. Teh, M. Welling, S. Osindero, and G. E. Hinton.
Energy-based models for sparse overcomplete repre-
sentations. Journal of Machine Learning Research,
4:1235{1260, Dec. 2003.

C. K. I. Williams and F. V. Agakov. An anal-
ysis of contrastive divergence learning in Gauss-
ian Boltzmann machines.
Technical Report
EDI{INF{RR{0120, Division of Informatics, Uni-
versity of Edinburgh, May 2002.

G. Winkler.

Image Analysis, Random Fields and
Springer-

Markov Chain Monte Carlo Methods.
Verlag, second edition, 2002.

A. Yuille. The convergence of contrastive divergences.

To appear in NIPS, 2004.

40OOBN FOR FORENSIC IDENTIFICATION THROUGH

SEARCHING A DNA PROFILES' DATABASE

David Cavallini

Fabio Corradi

Department of Statistics G. Parenti

Department of Statistics G. Parenti

University of Florence (Italy)

cavallin@ds.uni.it

University of Florence (Italy)

corradi@ds.uni.it

Abstract

In this paper we evaluate forensic identication
hypotheses conditionally to the characteristics
observed both on a crime sample and on individ-
uals contained in a database. First we solve the
problem via a computational ecient Bayesian
Network obtained by transforming some rec-
ognized conditional specic independencies into
conditional independencies. Then we propose
an Object Oriented Bayesian Network represen-
tation, rst considering a generic characteristic,
then inheritable DNA traits. In this respect we
show how to use the Object Oriented Bayesian
Network to evaluate hypotheses concerning the
possibility that some unobserved individuals, ge-
netically related to the individuals proled in the
database, are the donors of the crime sample.

1

INTRODUCTION

Bayesian Networks (BN) are a powerful and com-
pact representation of complex statistical models that
exploit some recognized conditional
independencies
among random variables. A BN is dened as a pair
of objects: a Directed Acyclic Graph (DAG) whose
nodes represent discrete random variables, and a set
of Conditional Probability Tables (CPT) which denes
the conditional distributions of each vertex given the
parents.

One of the reasons to represent a statistical model as
a BN is the possibility to use well-established and ef-
fective algorithms to solve the inferential issue, i.e. to
compute the distribution of some variables of inter-
est conditionally to the evidence by using one of the
available propagation algorithms (e.g. Jensen, 2001).

A limit in the representation of a BN arises when the
number of random variables in the model increases due
to some features of the problem.

Typically, this happens for time series models where a
certain structure, a time-slice, is replicated over time,

so that links between random variables in dierent
time slices are established. This also occurs when we
are interested in the relations between sets of random
variables and when some specied relations between
the sets must be taken into account.
In the former
case the model increases its dimensions over time, in
the latter its growth depends on the number of sets
involved.

In this respect, a new approach, stemmed from the
Object Oriented language, has been introduced in the
last few years. This modelling tool, called Object Ori-
ented Bayesian Network, provides a useful technique
capable of building a BN by merging pieces of simple
BNs. Each item is an instantiation of a well-dened
class which can be modied in order to accomplish the
maintenance requirements. An update in the structure
or in the CPTs of a class is automatically extended
to all instantiations of that class. The subject is de-
veloped in Koller and Pfeer (1997) and Bangso and
Wuillemin (2000).

Here, we specically deal with the forensic identica-
tion problem arising when a crime sample has been
found but there is no clue about its origin. Searching
a database (DB) of previously collected items is a com-
mon practice and the scope of this analysis is to assess
the probability for each member of the database to be
the origin of the trace. The problem has found consid-
erable attention in the literature, but only not inherita-
ble characteristics were considered, see e.g. Stockmarr
(1999), Donnelly and Friedman (1999), Dawid (2001)
and Meester and Sjerps (2003).

The aim of this paper is to show how this dimension-
dependent problem, once opportunely formulated as
a BN, can be eectively tackled. First, we provide a
theoretical contribution transforming some recognized
conditional specic independencies (Geiger and Heck-
erman, 1996) into conditional
independencies, Sec-
tion (2). Then, since the resulting BN shows many
dierent repetitive structures, we propose an OOBN
solution. The use of OOBN to model genetic data

41for identication was previously experienced by Dawid
(2003) with special attention to the possibility of mu-
tations.

The DB search problem is rst developed for a not
inheritable characteristic, but our real aim is to con-
sider more complex genetic traits in order to extend
the search to the relatives of the individuals proled
in the database, providing hints also when no match
between the crime sample and one (or more) of the
database members is found, Section (3.2).
In Sec-
tion (4) we provide the results of a simulation study
based on a real database, emphasizing some computa-
tional issues. Finally we draw some conclusions.

2 EQUIVALENT BN FOR THE DB

SEARCH PROBLEM

Let X the discrete population characteristic (or at-
tribute) considered for the forensic identication prob-
lem. With X we indicate the set of the m states of
X. The parameter θx, with x ∈ X , is the probabil-
ity that X is in state x, that is P (X = x) = θx and
x∈X θx = 1. Uncertainty about these probabilities,
derived from an inference process, could be introduced
but this will not be considered here.

P

Let N the size of the reference population and
n the number of the individuals in the DB. For
each of them we dene a random variable Xj with
j ∈ J = {1, 2, . . . , n}. Also, we dene Xc, the
characteristic related to the crime scene, and the hy-
pothesis variable H which has n + 1 states. The rst
n of them represent the originator status of each indi-
vidual, i.e. H = j, with j ∈ J , means that the origin
of the trace is the j-th individual in the DB, while
the last, H = r, is referred to the hypothesis that the
trace's donor is outside the DB.

To specify the DB search model we adopt some com-
mon and reasonable assumptions:

i. the individual characteristics in the DB are jointly

independent;

ii. the individual characteristics are jointly indepen-
i.e. X ⊥⊥ H

dent of the hypothesis variable,
where X = {Xj : j ∈ J };

iii. if the individual j
is the originator of the
trace the crime sample is observed without error
Xj ≡ Xc | H = j;

iv. for H = r the individual attributes are jointly
independent of the characteristic involved in the
| H = r and
crime scene,
P (Xc = x | H = r ) = θx with x ∈ X ;

i.e., X ⊥⊥ Xc

. . .

'OOOOOOOOOOOOOO
????????
woooooooooooooo
0123X2
0123X1
0123Xn

7654
7654
7654
0123Xc
7654

 !"#H
'&%$

Figure 1: A DAG for the DB search problem.

0123X1
7654

. . .

7777777
zttttttttttt
 !"#H

'&%$
*TTTTTTTTTTTTTTTTTTTTT
(QQQQQQQQQQQQQQQQ
tjjjjjjjjjjjjjjjjjjjjj
7777777
0123Xn
0123X2
zttttttttttt

7654
0123
7654
7654
7654
7654
0123
0123
0123Xc
7654

. . .

¯Hn

¯H1

¯H2

Figure 2: The augmented DAG obtained from Figure (1).

v. no other clue is available in advance, so the prior
probability on H is P (H = j) = 1/N and
P (H = r) = 1 − n/N .

The graphical structure, depicted in Figure (1), de-
rives only from the assumptions (i) and (ii) while the
CPTs are specied according to the assumptions (iii)-
(v ). Note that (iii) and (iv ) imply a whole set of
n + 1 independence statements:
for each value of H
a dierent assertion of independence holds. This form
of independence is known as Conditional Specic Inde-
pendence (CSI) (Geinger and Heckerman, 1996), which
diers from the usual denition of conditional indepen-
dence since, in the latter, the independence assertions
between variables do not vary according to the values
of the conditioning sets.

The proposed network does not feature any conditional
independence, so, for some evidence, the probability
updating does not take advantage of the graphical rep-
resentation. Moreover, the size of the CPT of Xc in-
creases exponentially according to the number of in-
dividuals in the DB, so that the propagation becomes
rapidly unfeasible. Our scope is to provide a more ef-
cient solution by introducing a set of instrumental
nodes in order to allow local computations. The result
is attained in three steps.

¯H = (cid:8) ¯Hj : j ∈ J(cid:9) is added and a new network is

Step 1. First, a set of binary random variables

dened on the augmented domain, as in Figure (2).

The marginal distribution of the variables Xj and H
does not change with respect to the original network

42'


w
*
(


z
t
z


and the remaining CPTs are dened as follows:

ˆP ( ¯Hj = 1 | H = i) =

(1)

( 1 if j = i
( P (Xc | Xj, H = j)

0 otherwise

P (Xc | H = r)

ˆP (Xc | X, ¯H = ¯h) =

if ¯h = 1j
if ¯h = 0
(2)
where 0 and 1j are vectors of size n. Each element of
0 is 0 while the i-th element of 1j is 0 ∀i 6= j and 1 for
i = j.
The CPTs for each node ¯Hj, specied as in (1), are
the probabilistic translation of the deterministic logi-
cal if-then relation, i.e., ∀j if H = j then ¯Hj = 1
and ∀i 6= j, ¯Hi = 0. Thus, each variable ¯Hj repre-
sents the originator status for the j-th individual and
the deterministic relation is a consequence of the as-
sumption that the characteristic observed on the crime
scene was left by only one individual belonging to the
reference population.

It is easy to prove that:

ˆP (Xc, X, ¯H, H) =

X

¯H

nX

j=1

ˆP (Xc, X, ¯H = 1j, H)+

ˆP (Xc, X, ¯H = 0, H) = P (Xc, X, H).

(3)

Since the hypotheses are mutually exclusive, all con-
gurations of ¯H not equal to the 1js and 0 have zero
probability to realize. For this reason, in the marginal-
ization (3), we consider only the relevant congura-
tions of ¯H.
The main consequence of the above mentioned result
concerns the updating of the query variable H. In fact,
for any evidence on X and Xc, the posterior probabil-
ity of the hypotheses variable can be calculated indif-
ferently by using the BNs of Figure (1) or Figure (2).

Step 2. Here a divorcing technique (Jensen, 2001)
is applied. The idea is to introduce a set of mediat-
ing variables between parents and children in a large
converging connection to lead some parents to divorce.
The main advantage of this method is the reduction of
the computational eorts because the original clique,
{X, Xc, H}, is broken into a tree of smaller cliques.
A reasonable way to divorce the parents of node Xc in
Figure (2)'s network is to add n mediating variables
Z = {Zj : j ∈ J }, which take values in X , so that each
pair of variables Xj and Hj are married. Figure (3)
illustrates the DAG after divorcing. There, the node
X ?
c represents the characteristic related to the crime

¯H2

¯H1

. . .

*VVVVVVVVVVVVVVVVVV
55555
zvvvvvvvv
 !"#H
'&%$
55555
55555
55555
0123X1
0123X2
0123Xn
					
					
					
7654
0123
7654
7654
0123
7654
7654
0123
7654
'PPPPPPPPPPP
ujjjjjjjjjjjjjj
()*+Z1
()*+Z2
0123Zn
/.-,
/.-,
7654
7654
0123

X ?
c

¯Hn

Figure 3: The augmented DAG of Figure (2) after the
divorce.

scene which has been redened for convenience.
In
c takes values in X ? = X ∪ {NA} where
particular X ?
the state labelled NA is an instrumental event to make
the conditional distribution of X ?
c well dened also for
Z values dierent from those allowed in this context.
The Z can be considered as private copies of the crime
sample, reproducing its value for each of the members
of the DB.
The CPTs specication of the nodes X, ¯H and H re-
mains unchanged with respect to the BN of Figure (2).
Imposing the CSI conditions

∀j, Zj ⊥⊥ Xj | ¯Hj = 0,

(4)

the rest of CPTs are specied as follows
˜P (Zj = x | ¯Hj = 0) = θx

˜P (Zj = x | Xj = ˆx, ¯Hj = 1) =

( 1 if x = ˆx
( 1 if ¯x = NA or ∀j, ¯x = zj

0 if x 6= ˆx

(5)

(6)

0 otherwise

˜P (X ?

c = ¯x | Z = z) =

(7)

where ¯x ∈ X ? and x, ˆx, zj ∈ X .
The following proposition provides the probabilistic
relation between the networks in Figure (2) and Fig-
ure (3).
PROPOSITION 2.1 For each x ∈ X and for a
given quantity C(x), depending on x, the following re-
lation holds:

ˆP (Xc = x, X, ¯H, H) =

C(x) ·X

Z

Proof in the Appendix.

˜P (X ?

c = x, X, ¯H, H, Z)

(8)

43z

*


'






u
¯H1

*VVVVVVVVVVVVVVVVVV
55555
zvvvvvvvv
 !"#H
'&%$
55555
55555
55555
0123Xn
0123X2
0123X1
					
					
					
7654
0123
7654
7654
0123
7654
7654
0123
7654
0123Zn
()*+Z2
()*+Z1
7654
/.-,
/.-,

. . .

¯Hn

¯H2

¯H r
1

¯H1

7654
0123
7654
0123

F(1)

¯H r
2

¯H2

7654
0123
7654
0123

F(2)

sggggggggggggggggggggg
woooooooooo

 !"#H
'&%$

. . .

. . .

¯H r
n

'OOOOOOOOOO
7654
0123
7654
0123

F(n)

¯Hn

. . .

Figure 4: The network obtained by dropping the X ?
c node
and the related incidental arcs from the DAG in Figure (3)

Finally, combining (3) with (8), we obtain the main
result:

P (Xc = x, X, H) =

C(x) ·X

Z, ¯H

˜P (X ?

c = x, X, ¯H, H, Z)

(9)

The above equation establishes that for calculating the
posterior probability of the hypotheses variable H we
can use the network of Figure (4) instead of that in
Figure (3).

Step 3. As explained in the proof of PROPOSI-
TION 2.1, during the propagation each valid evidence
on X ?
c is transferred to all mediating variables. So, op-
erationally, we build a new DAG merely by dropping
the node X ?
c as well as its incidental arcs, Figure (4).
Moreover, we use the characteristic observed on the
crime scene for evidencing each vertex Zj.

3 OOBN FOR THE DB SEARCH

The graph depicted in Figure (4) is conspicuous for
its repetitive structure. For each individual prole in
the DB the same BN is built and all the networks are
mixed by the hypotheses variable H which is the only
parent of every ¯Hj. Therefore, a set of conditional
independence assertions appears, i.e., given H, each
triple (Zj, ¯Hj, Xj) is independent of the rest of the
variables so that, for calculating the posterior distri-
butions of H, local computations are allowed.

3.1 NOT INHERITABLE TRAITS

A more compact representation can be achieved by
transforming the proposed network into the OOBN
framework. As in Bangso and Wuillemin (2000), we
dene a class, F, containing a simple BN, ¯H → Z ←
X, where the node ¯H is an input node while X and
Z are interior nodes. For each instantiation of the
class F(j), with j ∈ J , we build a binary random vari-
j which is referenced node of F(j). ¯H. They
able ¯H r
are connected through a reference link (⇒), that is
j ⇒ F(j). ¯H. Moreover, a set of arcs from the gen-
¯H r

Figure 5: The OOBN representation for the DB search
problem derived from Figure (4).

eral hypotheses variable H pointing towards each ref-
erenced node is drawn. Finally, the CPTs related to
the variables ¯H r
Figure (5) illustrates the OOBN representation for the
DB search problem as the basic model to solve the
forensic identication issue.

j are specied as in (1).

3.2

INHERITABLE DNA TRAITS

A DNA prole involves measurements on several well-
specied locations of the DNA, called loci. For each
locus we observe a genotype i.e. two alleles, one inher-
ited from the father and the other from the mother,
even if their origin is not distinguishable. For a generic
locus we dene two random variables A0 and A1 whose
states, a1, a2, . . . , am, are the inherited alleles. In ad-
dition, we consider a further random variable X whose
states represent the genotypes, i.e., an ordered pair of
alleles (at, au) with t ≤ u. In this paper we assume
Hardy-Weinberg (H-W) conditions and linkage equi-
librium. H-W implies that parents are not related so
that the inherited alleles in a genotype are indepen-
dent. Linkage equilibrium refers to the independence
among loci in the same individual. This is justied
since the loci considered for identication are chosen
far enough in the genome to make plausible that they
are generated by dierent meiosis processes.

The genetic inheritance allows us to consider, as the
possible donors of the crime sample, also individuals
never typed but related to the DB members. In this
way the no-match case, the most common in prac-
tice, but unfortunately the less useful, could originate
compatible unobserved individuals, i.e. those having a
positive probability for the characteristic observed on
the crime sample, conditional to all the available evi-
dence. For instance, a DB member not matching the
crime sample but sharing at least one allele for each
considered locus has a compatible child.
Here, we consider a pedigree, F, constituted by a
generic individual (i), their parents (0 and 1), their
child (c), their partner (p) and their brother (b). Note

44z

*






s
w
'






that Labels 0 and 1 refer to a generic parent and not
specically to the mother or father because this infor-
mation is not available. Since each pedigree is built
around a member of the DB we call it a rst-degree-
relative pedigree. This choice is essentially due to the
fact that, in the expectation of a signicant hint about
the trace's donor, we cannot explore too far from each
individual in the DB. Renements of the search could
be achieved if familiar connections between the DB
members were known. This kind of information is not
usually recorded in a DB but, if available, could be
exploited to relate two or more familiar classes with
suitable links.

j shown

In this new perspective, the variables H and H r
in Figure (5) have a new meaning.
The j-th state of H, with j ∈ J, refers to the hypothe-
sis that the donor of the trace belongs to the family of
the j-th individual of the DB, while H = r concerns
the possibility that the trace was left by someone not
included in the considered families. Every variable ¯H r
takes values in ¯F = F ∪ r. The state r concerns the
hypothesis that the trace is left by none of the consid-
ered family's members, while the statement ¯H r
j = q,
with q ∈ F means that the donor of the trace is the
q-th member of the jth family.

j

Since, by denition, we have no clue about the donor
of the trace, all the considered individuals are assumed
to have the same prior probability to be the searched
person. Within each family we assume that six persons
are the possible suspects but, obviously, some of them
might be ruled out if, e.g., they were in jail or dead.
To rene the analysis we dene an indicator variable
Jh,j ∈ {0, 1} for the relevance of the q-th person in
q∈F Jq,j we
indicate the number of the relevant persons in the j-th
family. The prior on H is P (H = j) = kj/N , and

the j-th family. Moreover, with kj = P

P ( ¯H r

j = q | H = i) =



Jq,j/kj

1

0

if j = i and q 6= r
if j 6= i and q = r

otherwise

(10)

where i, j ∈ J and q ∈ F.
For inheritable DNA traits the class F includes the
rst-degree-relative pedigree and the set of hypothe-
ses variables related to a generic family. Considering
the Allele Network proposed by Lauritzen and Shee-
han (2003), we provide an OOBN representation of F
through dening two other classes: the Individual (I)
and the Segregation (S) class.
The individual class I is represented in Figure (6). If
no information about the individual's parents is avail-

Ao
0

0

Ao
1

1

˜H

7654
0123
7654
0123
??????
0123Ai
0123Ai

7654
7654
 !"#X
'&%$
 !"#Z
/.-,
()*+
'&%$
??????
()*+A1
()*+A0

/.-,
/.-,
()*+At
/.-,

Figure 6: The individual class

Figure 7: The segregation class

0 and Ai

able, the allele input nodes Ai
1 depend on the
reference population parameters, otherwise they are
determined by the transmitted alleles. Another input
node is the binary random variable ˜H representing the
originator status of a generic individual. To provide
the transmission of the individual genetic characteris-
tics to the child, a copy of the alleles is expressed as
output nodes (Ao
1) and the other vertexes X
and Z being interior nodes. The variable X denotes
the observable genotype and its CPT is specied as
follows

0 and Ao

( 1

P (X = (ar, au) | A0

i = ah, A1

i = at) =

if (h = r and t = u) or (h = u and t = r)

0 otherwise.

(11)

The segregation class, Figure (7), has two alleles as
input nodes and provides the selection mechanism to
generate the transmitted allele At via the following
CPT, which reects the rst Mendelian law:

P (At = ar | A0 = at, A1 = au) =
1

if r = t = u
if (r = t and r 6= u) or (r = u and r 6= t)



0.5

0

otherwise.

(12)

On the whole the family class F is dened by a set
of instantiations of I, I(q), and S, S(q, t), with q, t ∈
F and q 6= t. The index q is referred to the donor
while t denotes the member who receives the allele in
the segregation. The links among the instantiations of

45O
O

O
O



/
/


˜H r
0

7654
0123
/.-,
()*+

I(0)

˜H

¯H

,YYYYYYYYYYYYYYYYYY
tjjjjjjjjjj
/.-,
()*+

0

Ao
0

0123Ai
7654
7654
0123

1

Ao
1

0123Ai
7654
7654
0123

˜H r
1

7654
0123
/.-,
()*+

I(1)

˜H

0

Ao
0

0123Ai
7654
7654
0123

1

Ao
1

0123Ai
7654
7654
0123

()*+A1
()*+A0
/.-,
/.-,
()*+At S(0,i)
#GGGGGGGGGGGGGGGGGG
/.-,
0123Ai
7654
7654
0123

Ao
0

0

˜H r
i

()*+A1
()*+A0
/.-,
/.-,
()*+At S(1,i)

/.-,
//////
//////
7654
0123
0123Ai
/.-,
()*+
7654
7654
0123

I(i)

Ao
1

˜H

1

Figure 8: The family class F when F = {0, 1, i}.

the basic classes, I and S, are drawn according to the
biological relationships and each input node I(q). ˜H has
its own referenced vertex ˜H r
q . All of them are mixed
by the input node ¯H and the related CPTs are built
as follows

P ( ˜H r

q = 1 | ¯H = u) =

(13)

( 1

if q = u

0 otherwise

with u ∈ ¯F and q ∈ F. In Figure (8) we give a repre-
sentation of F, assuming, to simplify the picture, that
F = {0, 1, i}.
The OOBN specied above deals with a single specic
locus and it aims at the evaluation of the marginal
posteriors for all the identication hypotheses.

In forensic practice, about 13-15 loci are usually typed
for each individual and the support to the hypotheses
is required conditionally to all the evidence.

Fortunately, this evaluation can be performed by us-
ing the results of the locus-specic nets, since linkage
equilibrium still holds conditionally to the crime sam-
ple and the identication hypotheses.
In fact, given
an individual, the genotype distribution in a specic
locus assumes the value of the genotype observed on
the crime sample with probability one if identication
is assumed; otherwise it follows the reference popula-
tion distribution i.e. it never depends on the genotypes
observed on other loci.

To give details, dene: L = {1, 2, . . . , k} the set of
the loci; x = {x1, . . . , xk} the genotypes observed on
the DB members and xc = {xc,1, . . . , xc,k} the crime
samples observed on the considered loci.

If linkage equilibrium holds, the posterior of the identi-
cation hypothesis expressed in odds form, concerning,
e.g., the q-th individual of the j-th family is:

P (H r
P (H r

j = q | x, xc)
j 6= q | x, xc)
kY

=

i=1

j = q)
j 6= q)

P (xi | xc,i, H r
P (xi | xc,i, H r

· P (H r
P (H r

j = q)
j 6= q) ,
j 6= q). The
since ∀i, P (xc,i | H r
rst term on the RHS of (14) is the likelihood ratio
(LR) and can be evaluated making use of the results
provided by each locus-specic net after propagation,
in fact, ∀i ∈ L

j = q) = P (xc,i | H r

(14)

P (xi | xc,i, H r
P (xi | xc,i, H r

=

j = q)
j 6= q)
P (H r
P (H r

j = q)
j 6= q)

· P (H r
P (H r

j 6= q | xi, xc,i)
j = q | xi, xc,i) .

(15)

Merits and diculties to provide results as posteriors
or LRs are discussed below.

1) The posterior probability of the hypothesis directly
provides an answer to the uncertainty about the origin
of the crime sample. Since a posterior requires the elic-
itation of a prior, this forces to deeply understand the
meaning of each hypothesis, avoiding misunderstand-
ing. This is a real problem as reveals the controversy
between Stockmarr (1999), Dawid (2001) and Meester
and Sjerps (2003): there the problem concerned the
choice among hypotheses that sound logical. In this
work both positions are represented: the Stockmarr's
hypothesis is represented by the event H 6= r and con-
siders the presence of the originator of the trace in the
(augmented) DB; The Dawid's individual hypotheses
are represented by the set of the H r
j s. A possible draw-
back in the use of the posterior is that a large popula-
tion size often implies very small (marginal) priors for
each of the identication hypotheses so that small pos-
teriors are likely to be obtained, wrongly suggesting a
failure of the identication trial.

2) The LR is the measure usually provided to eval-
uate the evidence in a court; it does not imply any
choice about priors and can be combined by the judge
with others LRs obtained using dierent sources of ev-
idence. An LR typically emphasizes a discover, even

46













#

t
,


Table 1: The rank distributions of the LR supporting
the correct identication hypothesis.

Table 2: Parameter estimates of the CPU time pro-
posed model

Rank
1◦
2◦
3◦
4◦
5◦
6◦
7◦
≤ 8◦

Child
Brother
54.99% 61.89%
16.24% 10.71%
4.26%
7.53%
2.36%
4.17%
2.08%
2.90%
1.81%
1.27%
1.63%
1.45%
10.73% 15.98%

if the result might be of dicult interpretation, since
the LR is not expressed in a normalized form.

4 APPLICATIONS

Now let us give account of a simulation study on a real
DB containing 1102 observations on 10 loci. What is
involved is how eective is the DB search in retrieving
the origin of the simulated crime samples.

To produce the rst simulation, we generated for each
observed individual two crime samples obtained re-
spectively sampling from the posterior marginal dis-
tribution of the child's and brother's genotypes. We
call them the Child Crime Sample (CCS) and Brother
Crime Sample (BCS).

Consider rst the CCS. For each considered rst-
degree-relative pedigree we evaluate the hypothesis
concerning the identication of the family originat-
ing the child. Obviously we expect that the LRs, or
the posteriors, evaluated for the family from which the
CCS was generated has one of the highest values. Sim-
ilar computations are provided if the BCSs are used,
and the results are in Table (1).

Concerning the identication of a child, in over 85%
of the cases, the LR corresponding to the originating
family ranks in the top ve highest positions; the iden-
tication of a brother is slightly less successful, since
in this case the same gure is just over 80%. In real
cases, it seems safe to suggest that the the results' eval-
uation should include a comparison between the LRs
or the posteriors for the families exhibiting the highest
values associated to a careful investigative work.

As a comment, it must be noted that our simulation is
disadvantaged with respect to real cases. For instance,
when we sample a BCS we do not know the relatives'
genotypes as the nature knows but our knowledge is re-
stricted to the brother posterior distribution, typically
over-dispersed. In real cases, brothers' genotypes are
often very similar:
for each locus, if one of the par-
ents is homozygote the probability that brothers share

CPU

α

Pentium IV -10.93
-11.75

AMD64

β

1.82
1.84

θ

0.01
0.01

one allele is equal to one and the probability they are
identical is equal to 0.5.

A further simulation experiment has been achieved,
making use of dierent DB sizes in the range 5000 −
50000, and loci with a number of alleles varying in the
range 5− 20. We estimate the dependence of the CPU
times (t) required to perform the search with respect to
the DB size (n) and the alleles' number (a) according
to the model log(t) = α+β·log(n)+θ·log(a)+e where
e is the stochastic error with zero mean. Results are
in Table (2).

Clearly the estimation of the βs and the θs produced
very similar results and the dierence in technology is
provided by α. Note that there is a very slight depen-
dence on the number of the alleles, due to the adoption
of an allele recoding strategy (Lauritzen and Sheehan,
2003).
Instead the dependence of t on the DB size
is less then quadratic, making the search feasible also
when very large DB are involved.

5 CONCLUSIONS

The use of BN to provide an evaluation of the LR for
forensic identication purposes is a new but already
well-established approach, see Dawid (2003), Mortera
and al. (2003) and Corradi et al. (2003).

Here, the BN technology is invoked when there is no
clue about the origin of the trace, but a list of well
identied individuals, not apparently related to the
crime, is available in the DB. This result is all the
more eective when an augmented DB is introduced,
having assumed that all its members belong to the
population of the crime sample's possible donors, even
if some of them are not observed. In this new perspec-
tive the OOBN approach provides the most striking
solution: the familiar, the individual and the segrega-
tion classes of hierarchy provide a concise representa-
tion of the repetitive part of the problem, saving eorts
when maintenance operations are required. This could
happen, for instance, when we want to introduce the
possibility of a mutation in the alleles transmission: in
this case a slight modication of the segregation class
produces the result. At the same time the proposed
solution leaves some room to operate on the single in-
stance of the classes. This is compulsory for our prob-
lem since we are required not to consider as possible

47originator of the crime sample those individuals in the
augmented DB who are not included in the donors'
population since e.g. dead or in jail.
In the OOBN
environment this can be realized just by intervening
on the hypotheses input nodes concerning each family
and detailed for each considered members.

PROOF OF PROPOSITION 2.1
The joint marginal distribution of {X, ¯H, H} is the
same in the two BNs of Figure (2) and Figure (3) so
(8) becomes

ˆP (Xc = x,| X, ¯H) =

C(x) ·X

c = x,| Z) · nY

˜P (X ?

Z

j=1

˜P (Zj | Xj, ¯Hj).

(16)

c receives an evidence x ∈ X it
When the variable X ?
is easy to show that after the reduction (7) can be
written as product of n potential φj, that is

ˆP (X ?

c = x | Z) =

where

φj(Zj = ˆx) =

nY

φj(Zj)

j=1

( 1 if ˆx = x

0 otherwise

(17)

(18)

with ˆx ∈ X .
The equation (18), which denes a nding on Zj, es-
tablishes that all mediating variables take value x with
probability 1. So, combining equations (17) and (18)
with (16) we obtain

ˆP (Xc = x,| X, ¯H) = C(x) · nY

˜P (Zj = x | Xj, ¯Hj).

j=1

If ¯H = 1j then from (2) and (4) we have

P (Xc = x,| Xj, H = j) = C(x)·

˜P (Zi = x | ¯Hi = 0) · ˜P (Zj = x | Xj, ¯Hj = 1).

Y

i6=j

(20)
The third part of RHS of (20) involves n − 1 terms.
From (5), each of them is equal to θx so, considering
(6) and assumption (iii) we obtain C(x) = θ1−n
The same result is achieved for ¯H = 0 as well. In fact,
in that case, considering (2) and (4), the equation (19)
becomes

P (Xc = x,| H = r) = C(x) · nY

˜P (Zj = x | ¯Hj = 0).

x

.

j=1

(21)

Finally, from condition (iv ) and equation (5) we obtain
again C(x) = θ1−n

.

x

REFERENCES

O. Bangso and P-H. Wuillemin (2000). Top-down
Construction and Repetitive Structures Representa-
tion in Bayesian Networks. In Proceedings of the Thir-
teenth International Florida Articial Intelligence So-
ciety Conference, 282-286. AAAI Press.

F. Corradi and G. Lago and F. M. Stefanini
(2003). The Evaluation of DNA Evidence in Pedigrees
Requiring Population Inference. Journal of the Royal
Statistical Society, A166, 425-440.

A. P. Dawid (2001). Comment on Stockmarr's Like-
lihood Ratios for Evaluating DNA Evidence When the
Suspect is Found Through a Database Search. In Bio-
metrics, 57, 976-980.

A. P. Dawid (2003). An Object Oriented Bayesian
Network for Estimating Mutation Rates. In Proceeed-
ings of the Ninth International Workshop on Arti-
cial Intelligence and Statistics, January 3-6 2003, Key
West, Florida, edited by Christopher M. Bishop and
Brendan J. Frey.

P. Donnelly and R.D. Friedman (1999). DNA
Database Searches and the Legal Consumption of Sci-
ence Evidence. Michigan Law Review, 974, 931-984.

D. Geiger and D. Heckerman (1996). Knowledge
Representation and Inference in Similitary Networks
and Bayesian Multinets. Articial Intelligence, 82, 45-
74.

F.V. Jensen (2001).Bayesian Network and Decision
Graphs. Springer-Verlag, New York.

(19)

D. Koller and A. Pfeer (1997). Object-Oriented
Bayesian Network. Proceedings of Thirteenth Confer-
ence on Uncertainty in Articial Intelligence, 302-313.

S. L. Lauritzen and N. A. Sheehan (2003).
Graphical models for genetic analyses. Statistical Sci-
ence, 18, 489-514.

R. Meester and M. Sjerps (2003). The Evidential
Value in the DNA Database Search Controversy and
the Two Stain Problem Biometrics, 59, 727-732

J. Mortera and A. P. Dawid and S. L. Lauritzen
(2003). Probabilistic expert system for DNA mixture
proling. Theoretical Population Biology, 63, 191-205.

A. Stockmarr (1999). Likelihood Ratios for Eval-
uating DNA Evidence When the Suspect is Found
Through a Database Search Biometrics, 55, 671-677

48 
		! "	#%$

&')(

*,+&-.-/0	#

132547684:9<;>=@?BADCE9F2:259

G0HJI>KLMHJNPORQ3STNVUXWZY[WZ\DW^]_7`bacYd`bLd`beYMO&HJL8fhgFiV]a^NP]jW^YMO&U

]&m3HNnNPUoW^a#pbqnrPsJtu<swv
xy
\ninYzNneb]&N8rP{|]a^m3HJNFg
}F~nwVbbZPVF~<~F<VJVFP"7DDTD

kFl

|Dn!

lnl

\nW

a^`binLd]m`_HbOWZYdb]Lz]Ha^NPYdNneYMUH

aZ`bHORP] 
xn]
]&a)i<g¡m¢YdNPYdm¢Yz£&YzNne¤ DYza^]OWZLdgHJN]UXWZY[¥
YzNW^PYzU
m3HwWZ]>`_#WZn]>]&I
]OW^] WZ]UoW3]&aZa^`ba¦§xn]¡m3HJYzN
W^Yzm3HJLM­§UXWZaZHJW^]eg®YMU3WZPHwW
 DYd¨©Oj\nLdWXgªYdN«WZnYMU¬o`
aZ`iPHinYdLzYdW^Yz]U!Nn]] 
WZ`¯iV]#]UoW^Yzm¢HJW^] 3HO¥
`b\DW
O&\naZHJW^]Ldgb¦±°²]³U^\nebe]UoW0n]a^]® nY[´µ]&aZ]&N<W¶m¢]&W^D¥
`D nU
_7`ba3]UoW^Yzm¢HJW^YzNne·W^P`bU^]¡]&¨©OjYz]&N<W^Lzg¦«STNªW^PYzU
O&`N<W^]&I<WrnWZn]@K!Ha^£]&N¡¸"YdNP n`w¸¹O&LzHbU^U^YdºP]&aYMU#O&`ND¥
U^Yz n]&aZ] i]O&H\PU^]Y[W|YzU#iV`W^0U^Ydm
a^`biPHw¥
inYzLzYzUoW^YMOJ¦"xn]¯HNPHJLzgDUoYMU"`J_]jI
]&aZYdm¢]NbWRHJL.a^]Uo\nLdWZU
nYzePLdYze<WZU#W^VHwWa^]e\nLMHJaZYz£HwWZYd`bNYzU»H>Q]&gYzNneaZ]j¥
 DYz]&N<W"_7`baW^nYMUUoW^aRHwW^]egb¦

Lz]@HNP 

½b¾

Dn¿"À#Á#nÂo¿

`bYdN<WZU

]a^FYMUo] 0_7aRHJm¢]&¸`aZQµrµW^n]3eb`bHL!YzU|WZ`
STN²W^n]©UoWZHNP nHaZ ²Uo\
]UoW^Yzm3HwWZ]|H_7\nNPOjW^Yz`N¡iPHU^] ¤`N>H@eYz]N©WZaZHYdNnYzNne
Uo]&W¦hÃ)ÄjÅ
YzU»HNÑ]jIFWZ]&NPU^Yd`bNÑ`_W^nYMU|_7aRHJm¢]&¸`aZQ¸"n]&aZ]
ÆÈÇÊÉË©ÌdËRÍwÎÏPÇÊÏFÐ
W^P]@Lz]Ha^NnYzNne>m¢HbORnYzNn]
 n`<]U|Nn`JW»`NnLzgaZ]Oj]Ydb]W^P]@WZaZHYdNn¥
YzNne
HUZUoYz]Ldgbr<iP\DW#O&HN¡HLzU^`
ORP`<`<Uo])W^P]
`YzN<WZUWZ`
i])YzNPOjLz\P D] ©YzN©WZn]#WZaZHYdNPYdNne
Uo]&W¦!ÒNHOjW^Yz])Ld]HJaZNn]&ahm¢Hg
UoWZHJa^W@¸"YdW^ªH¶U^m3HJLzLEWZaZHYdNPYdNne²Uo]&W¢HNP HJW
]HORYdW^]aZHJW^Yz`N
O&Ha^]&_7\nLzLdg3U^]&Lz]OWRUE`bNn]`baU^]&b]&aRHJL
`YzN<WZUh_7`ah¸"nYzOR¤Y[W"HU^QDU
W^P]LzHiV]LzUWZ`©H@F\nm3HN>]&I
]&a^W¦
xn]m3HYdN©m¢`W^YzHJW^Yz`N¢_7`baEHOjW^Yz]Lz]Ha^NnYzNneYMU!WZPHwWY[WE\VUo\D¥
]&a^W
HJLzLzg@aZ]Ó<\nYza^]UBW^Yzm¢])HJNV VÔ`ba!m
`bNn]&g@_7`aEW^n]#<\Pm¢HN3]jI
W^`@LzHiV]LHN3]jInHJm
Lz])HNP ¢WZn`bU^]aZ]U^`\naROj]UUoP`\nLM 3Nn`Whi]
¸HUoW^] 
WZ`¯LMHJi]&LNn`ND¥ÕYzND_7`aZm3HwW^Yz]"UZHJm
Lz]UrbiP\DWhi])U
]N<W
`N¡YzNbWZ]&aZ]UoW^YzNne¢`Nn]U&¦
Ö)l
]a^Yzm¢]&N<WZHLØÙ#]UoYzeNÛÚ:ÜP] D`ba^`wµrÞÝß<stàYzU
WZUEW^`¯ºVNP 
OjLz`bU^]&Lzg
a^]LzHJW^] @WZ`@HOjW^Yz]"Lz]Ha^NnYzNneHbUYdWhHwW^W^]m
`YzN<WZU»U^\PORW^VHwW|W^n]@Ha^YMHJNVOj]`_!W^n]
]UoW^Yzm3HwWZ]
H¤U^]jW»`J_
YMUhm¢YzNnYzm
Yz£&] ¦!STN>O&`N<W^aRHUoWEWZ`WZnYMU@¬^iPHwWRORP­_7`ba^m@\nLMHwW^Yz`Nár
`J_ÊW^]N©aZ]j_7]&aRU!WZ`HJN¤YdNPO&a^]m¢]&N<WZHL
W^P]W^]a^m
ÆÈÇÊÉËÌdËRÍwÎÏPÇÊÏFÐ
UoW^aRHwW^]eg¢Ú:â"`wg»ã«G0OfHJLzLd\nmrJtJubunÝbä
e<H¸HPr
tJubuuPäJfh`bnN]jWHJLÈ¦drDÝßß<åDä
\nNne|ã«æYzg`ebY5r<ÝßbßbånäGÑHO&çHgbr
ÝßbßbtJiVà¦

\neYzgbHm¢H#ã

WZYdm3HJLØ×I

Åoê

Íë&ËRì

ÏµË

a^`
ÌîÇÊÏ<Ð

lnl

ëjË&ÌdË

ÎÆ#úVË

ÎhûÑÍ

ÇÊÏËjë

`YzN<W»U^\PORWZPHwW|W^n]
]jI
a^`<HOR¢PHbUhHLzU^`¯i]&]&N¡Uo\Pee]UXWZ] ¢YzNÑÚ

HbOWZYdb]Ld]HJaZNnYzNne©Ú:HLzU^`
°²]#¸"YzLdLOj`NVOj]&N<WZaZHJW^]"`N
èPéé
àjïWZn]@Lz]Ha^NP]&a)OHJN0`bNnLzgÓ<\n]a^g
O&HLdLz] 
ÌîÇÊÏFÐ
Æ5ÇÊÉwË
ë&Íwí
`bYdN<WZUE¸"nYMOR
i]&Lz`NPeW^`¯H»LMHJaZe]"\nNPLzHJ¥
W^P]LzHiV]LzU`J_8Uo`bm¢]
i]&Lz] ¯U^]jW¦Bæ#`JW^]W^PHJWBYzNW^PYzUBUXWRHJNP PHJaR  D]jºPNPY[WZYd`bN¯`J_
`F`Ld¥
iPHbUo] ªHbOWZYdb]Ld]HJaZNnYdNPePrhW^n]ÑU^]HaZORªYMU3eaZ]&] DgµïÑHwW©]HOR
YdW^]&aRHwWZYd`bN8r8WZn]©eb`bHJLYMUWZ`ºPNP «é
`YzNbW¯¸"PYzOR·¸"YzLdLha^]&¥
U^\nL[W!YzNWZn]"Uom3HLdLz]UoW!]jI
]OWZ] @e]&NP]&aRHJLzYd£HwW^Yz`N]&aZa^`ba.¸"n]N
H P D] ¤W^`¢WZn]»W^aRHJYzNnYzNne3Uo]&W¦
`<Uo] ¶_7`a¢HOWZYdb]
xn]a^]©VHU@iV]]&NwHJaZYz`\PUn]&\naZYMUXWZYzO
Lz]HJaZNnYzNnePrFU^\POR>HbU#ð
Ú5ò8]¸"YzUãó{»HJLz]r
Ë&ÎÆTÍwÇÊÏPÆÈñ@ëjÍJí
Ú5ÜnaZ]&\nNV «]jWHJLÈ¦dr
ÝßbßJôFà¢`a
ÉË&ÎRëÇ
Ïë
Ë²í@ÇÊÏVÇÊí@ÇdõÍwÆÈÇ
Ýßbß<sDäbx.`Nne
ãöç»`LzLd]arFtJuuPÝàj¦.÷`w¸]&b]&arYM D]HLdLzgr<WZn])HYdm
YMUWZ`>ORn`F`bU^]WZn]
]OjW^] W^]UoW»]&a^¥
aZ`aYMU¯m¢YdNPYdm¢Yz£&] «Ú5â"`wg¶ãøG0OfHJLzLd\nmr!tJubunÝàj¦
\VOR·HN
lPl
ORn`nN>ãfh`nN8r
tJubuu<àµYdN@W^P]O&`N<W^]&I<W`J_áùVðèèPé
Lz]Ha^Nn¥
ÄRü
YzNnePrin\nW|WZn]3HJ\DWZn`aRU|HJaZe\n] W^PHJWY[W¸`\nLM 0i]
O&`m
\D¥
WZHJW^Yz`NPHLdLzg©YzN<W^aRHOWRHJinLz]¦
Lz]j¥
÷`w¸]&b]&a®W^nYMUÞ¬o`
O&LzHbU^U^YdºP]&a§YzN
m¢]&N<W^] ÿ_7`a
ÚÈfhVH
]ao_7`ba^m¢] ©W^]a^aZYdiPLdgb¦
Lz]&m¢]&ND¥
STN3WZnYzU
WZHJW^Yz`N¶`J_WZnYzU»HbOW^Yz]@Ld]HJaZNnYzNne>UoW^aRHwWZ]&eg D`F]U|Nn`W|¸`aZQDU
HJNV 
]&aZ<YMU^] 
Lz]HJaZNnYzNne¢HJNP ¡aZ]&e\PLzHa^Yz£HJW^Yz`N8¦
aZ]U^]&N<WRU
xn]
]OW^] 
W^P]UoW^aRHwWZ]&ebg)¸"nYMOR¢Oj`NVUoYMUXWRUáYzN
m
YzNnYzm¢Yd£YdNne)W^P]]&I
LzgY[W|W^`>W^P]
W^]UXW»]&aZaZ`a)HNP ÑU^]OjW^Yz`NÑp¡U^n`w¸Un`w¸¹WZ`¡H
K!HJaZ£&]N¸"YdNV D`w¸®OjLMHUZU^Y[ºP]a¦
Nn]`J_nWZn]haZ]HbUo`bN_7`a!O&`NPU^Yz D¥
nYMUXWZYzOHwWZ] 
]&aZYzNneW^PYzUUoYzm
OjLMHUZU^Y[ºP]am¢Ydeb<WYdN<W^aZ`D D\PO&]H3inYMHU"YzN`\Pa#HJNPHLdgDU^YzU`J_HOj¥
W^Yz])Ld]HJaZNnYzNneP¦BSTN¤U^]OWZYd`bN3ôPr<¸h]
aZ`w]&¥
m¢]&N<W"W^VHwWWRHJQ]UYdN<WZ`©HO&O&`\nN<WW^P]¯\nNnLMHJi]&Lz] 
`YzNbWRU"_7`ba
W^P]hOjLMHUZU8O&`NP DYdW^Yz`NVHJLb n]&NPU^Y[WXg|]UoW^Yzm3HwWZ]UrHNP |ºPNPHLdLzgrwU^]Oj¥
W^Yz`N0å@YzNbWZa^`D D\VOj]U"H
aZ`bHbORn]UhiPHU^] >`NaZ]&eb\nLzHa^Yz£HJW^Yz`N8¦
æ`W^]W^VHwW!_7`a!O&`NF]NnYd]NPOj]brw]jI
]&aZYdm¢]&N<WRHJLDaZ]U^\nL[WRUB¸"YdLzLni]
]ahYzN¡`aR D]&aEW^`¢HUZUo]U^UhYdm¢m¢]j¥
aZ]U^]&N<W^] ©HJLzLHJLz`NneW^n]
 DYMHwWZ]&Lzg3W^n]

k 
]ar<¸h])YdNFb]UoW^YzebHwWZ]¸"FgWZn]|NPHJYz]Yzm
U^]&m¢Yd¥ÕU^\

lnl
Lz])OjLMHUZU^Y[ºP]aYMUWZPHwWhHm¢`aZ]#Uo`

]aYzU»`ba^e<HJNnYz£&] ÑHU)_7`bLdLz`w¸U&ï»U^]OWZYd`bN·t

U^\neeb]UoW>WX¸`®aZ]&m¢] nYd]U>iVHU^] Ø`bN

G0UHNP ,K!HJaZ£&]&NÞ¸"YzNP D`w¸

]&a^_7`aZm3HJNPO&]»`J_!H@NP]&¸

aZ`bHbORýPHU³i]&]&NþYdm

]&LzLd]brPtJuubpnrFORPH

W^]&a"q<àrFin\DWYdW

W^Yzm¢HLz­H

lnl

aZ`

`bU^]#H»ºPaRUXWYdm

m¢]&W^n`D ¦

49l
l
H
l
l
l
l
l
l
l
l
¼
¾
l
l
l
l
l
l
l
l
l
l
l
l
l
Í
Ä
k
Ö
k
Ì
Ä
è
l
l
l
l
l
l
Ï
Ä
è
é
è
Í
Ä
é
Ï
l
l
k
H
k
Ä
Æ
é
l
l
l
l
l
l
l
H
l
l
l
l
H
l
l
l
Ö
l
l
l
l
l
l
l
l
l
H
l
l


nÂÞ!nÂ	

8

¾

W^Yzm¢HLHOjW^Yz]¢Ld]HJaZNnYzNne¡UoW^aRHwWZ]&ebg¡¸]

xn]¢`
aZ]U^]&N<Wn]&aZ]
ORn`nN³ãfh`nN8r
PHbUi]&]N³ D]U^O&a^YziV] ·_7`a@YdNVUXWRHJNPO&]¤YzN
tJubuuPäbâ"`wg
ãGÑOfHJLzLz\nmrFtuunÝà¦.SÕWOj`bNPU^YzUoWZUEYdN©Ó<\n]a^gFYzNne
W^P]¤LMHJi]&LE`_W^n]
`baZHJW^] ÑYzN§W^P]
]OW^] ©WZ]UoW]&aZa^`ba¦
W^aRHJYzNnYzNne3Uo]&Wrn¸"YzLzLg<Yz]&LM >W^n]Lz`w¸]UoW]&I

`YzN<WrBW^VHwW@`bNPOj]¤YdNPO&`a

Lz]U¦

¸"YdW^

WZn]

tD¦"ÜBYdI¡H

`_.WZn]Nn]¸

WZaZHYdNPYdNne3U^]jW

Ú7]àfh`bm

\DW^]W^n]§]&I

`bUoW^]a^Yz`a

aZ`iVHJinYzLdYdWXg

Ú:Oà>×hUXWZYdm3HJW^]

WZn]ýOjLMHUZUoYdºP]a

eb]&Nn]aZHLdYz£HJW^Yz`N

W^n]ýHb n DYdW^Yz`NPHL

Ú: Và>×hUXWZYdm3HJW^]W^n]

`YzNbW\PNP D]&aW^n]Fg

Ú7ià>â]jW^aRHJYzN
`YzN<W¦

`bYdN<WZU#HJNP >e]&WWZn]Fg

]OjW^] ¹e]&NP]&aRHJLzYd£HwW^Yz`N

WZPHwWWZn]¹e]&NP]&aRHJLzYd£HwW^Yz`N

ÚÈà !²i]¢W^n]3WZaZHYdNPYdNneUZHJm

`bU^]
]&aZa^`ba³`_ÑW^P]¹_7\nNPOWZYd`bN
Lz]HJaZNn] `NWZnYMU#WZaZHYdNPYdNneU^]jW|OHJN¶iV]
]UoW^Yzm3HwW^] ¦ò8]&W|\PU
 D]
]NP nU"HJLMU^`@`bN¤WZn]»Ld]HJaZNnYdNPe
HLdeb`aZY[WZnm©à¦xn]»`
WZYdm3HJL
HOjW^Yz]»Lz]HJaZNnYzNne¢UXWZaZHJW^]&ebg©¸`\nLM ¤i]»W^P]»_7`LzLd`w¸"YzNnePr
Ý¦"x.aZHYdN0W^n]
OjLMHUZUoYdºP]&a)\PU^YdNne¤W^n]¢Oj\Pa^aZ]&N<WWZaZHYdNnYzNne¡Uo]&W

ò8]&W
 D]Nn`JWZ]>iFg"Ú#¤àU^\PORªHJN®]UXWZYdm3HJW^]·Ú7¸"nYMOR8rE`_)Oj`b\naRUo]br
`W^n]UoYMU'&
`_%$
!¦
`bYdN<W)²YdN¡WZn]\nNnLMHJi]&Lz] U^]jW
`YzNbW
ÚnàYzNW^P]
Ú:H<à>ÜBYdIH¢LMHJi]&L*>HNP H n ¡WZn]
]&aZaZ`a+"Ú#-,
Ú nàoàj¦

.3Ú 0/
`W^n]UoYMU1&
!¦
!nà	"Ú#+,ÑÚ nàoàj¦
"435687
`YzNbW:©¸"nYMORVHU.W^n]Lz`w¸¥

aZ`inLz]&m3U"¸"YdW^WZnYMU#UoW^aRHwW^]egb¦hc]U^Yz n]
\DWZHJW^Yz`NPHL. DYd¨©Oj\nLdW^Yz]U
Ú:HJW|H©ºPaZUoW)U^Ydeb<WrµH3Ld`W)`_a^]&¥
YzU
à¦æ`W^]3WZPHwWYzN·W^P]

]UXWE]&I
WZaZHYdNnYzNne3U^]jW¦
xn]a^]¯Ha^]¯U^]&b]&aRHJL
Oj`bm
W^aRHJYzNnYzNnebUHJaZ]3Nn]O&]UZU^Ha^gnàráW^n]¤_7\nNP nHm¢]&N<WZHL
n`w¸ÿW^`ÑO&`m
aZ]UoW`J_W^n]
HU
\DW
Ün`ba.O&LzHbU^U^Y[ºO&HwWZYd`bN8rW^n]
Oj`bm

áà
.3Ú/
 DYza^]OWZLdg²Ú:â"`wg¤ãÞG0OfHJLzLd\nmrVtuuPÝä=<F\]jW#HL5¦zrVtJubup<à!WZ`

\DW^]>"r
.3Ú/
&
"?
QP
O
$@
DC!E*
¸"n]a^];!E*SUTVTUTN
&
.3Ú/
!·Lz]Ha^Nn] ²`N·W^P]
`bYdN<W«ebYdb]&N²W^n]¤_7\nNPOjW^Yz`NW&

_7`aW^n]
W^aRHJYzNnYzNne3Uo]&W¦
×EÓ¦"ÚXÝàO&HN>i]¯Uo]]&NHUWZn]]&m

YzU¯W^n]¡Uo]&W@`_\PNnLzHiV]Ld]  nHJWZH0HNP 
a^`biPHJiPYdLzY[WXg

]&arP¸]¯¸"YzLdL.a^]&_7]&aYzNP DYd´]a^]N<W^Lzg¤WZ`

pn¦#fhn`F`<Uo]E_7`aLzHiV]LdYzNne#W^n]

]OW^] 3e]Nn]&aRHJLzYz£HwWZYd`bN¢]&aZa^`ba

\DWZ];"ýHJNP 

aZ`iPHinYzLdYdWXg¦
`<UXWZ]&aZYd`ba

à
YMU©HJN]UXWZYdm3HwWZ]0`J_|W^P]

aZ`iVHJinYzLdYdWXg»O&HJNiV]h\PUo] 

`bUoW^]a^Yz`a`ba"`\DW

YzaZYzOHJLOj`b\nN<W^]&a

HJNV 3H n ¢YdWEWZ`

.¢Ú 0/

9&

.3Ú 0/



m3HwI

7JILKNM

!nà	R

ÚXÝà

HJa^W`_

]&aZa^`ba

aZ`inLz]&m

ÝHG

`<UXWZ]&aZYd`ba

ZG²Ha^em3HJI[.3Ú/



!nàV/]\L.3Ú/



!nà\^.3Ú áà

tYXX

lnl

À#¿

¸"nYMOR

¸h`b\nLM i]

WZn]WZn]e]Nn]&aRHJLzYz£HwWZYd`bN]a^aZ`aYd_

Ú5tbà

 O

Ú Õà

HJNV ¤iFg>cHgb]Ua^\PLd]

0X!FFÂ	ef
8

LzgWZnYzU!UoW^aRHwWZ]&ebg|¸"YdW^
WZn]"K!HJaZ£&]&N¸"YdND¥

xn]e`<HJLFYMUáWZ`H
 D`w¸OjLMHUZUoYdºP]&a¦BSTN>WZnYMUO&HbUo]brD¸h]»PHb]

&
\L.3Ú/
!nà@¸h]a^]¤W^n]>W^aZ\n]Oj`bNP DYdW^Yz`NPHL nYzUoW^aZYdiP\DW^Yz`N³`J_
©ebYdb]&N]!¦
ba0

¾dc
nà
.3Ú/
/hgUiN/L
.3Ú/
áà
ÚpÊàqØ]jI

7Qm
70n
ÚÕà
ÚÕà
uSvJtxw0uàT
rGspt/D/

jkl/
 O
oC*
ÚG/D/

SÕWYzU|WZF\PU
\DWZ]
W^n]3]UXWZYdm3HwWZ] ¶e]Nn]&aRHJLd¥
Yz£HwWZYd`bN«]&aZa^`ba3\PU^YdNne
WZYdm3HJL|HOj¥
ÚXÝà¤HJNP 
W^Yz])Ld]HJaZNnYzNneUoW^aRHwW^]eg¢ D]UZOjaZYziV] ©HJi`w]b¦Bxn])a^]HU^`N¢_7`ba
Oj`bNPU^Yz D]a^YzNneWZnYzU
U^Ydm
Lz]>O&LzHbU^U^Y[ºV]&a¯¸"YdW^®HbOWZYdb]©Ld]HJaZNnYzNne
YMU»W^PHJW]Ó<\PHJW^Yz`NÚ:p<à»eYz]U DYdaZ]OjW^LzgÑHJN·]UXWZYdm3HwWZ]©`J_W^P]
`bUoW^]&aZYz`a
aZ`iVHJinYzLdYdWXg³HNP ³W^PHJW>YdW> D`F]U¤Nn]&] «HOj`<UXWZLdg
aZ]jW^aRHJYzNnYzNne
¸"n]&NH
`bYdN<WYMUH P D] ¤W^`
W^P]»W^aRHJYzNnYdNPe¢U^]jW¦

¸"n]a^]
W^`3HN¡YzaZa^]Ld]HN<Wm@\nL[WZY

YzOHJLzLdg@H¯{»HJ\PUZUoYMHJN
Q]a^NP]&LD`J_W^P]"_7`aZm

LdYMO&HJW^Yz]¯Oj`bNPUoWZHJN<Wàr

`<U^U^YzinLd]
WZ`O&`m

]&a^_7`aZm

W^n]¶`

YMUWXg

Ú:p<à

Ú7\

yz

CE9<;4#{9l|4}U~

x¸`¢ PHwWZHbUo]&WZUPHb]|i]&]N\PUo] ©_7`baW^n]]&I
U^\nL[WRU
aZ]HJL|¸`aZLz «`bNn]r|HJNP ØW^n]· D]&WZHJYzLMU>`_¯W^P]²]&I
U^]jW^\

aZ]U^]&N<WZ] ²YdN·WZnYMU
Ha^]»HUYzNP DYMO&HJW^] >i]&Lz`w¸¦

]a^Yzm¢]&N<WZHLa^]&¥
]aïHNHJa^W^YdºVOjYMHJLE`Nn]©HNP ·H
]a^Yzm¢]&N<WZHL

35

30

25

20

15

10

5

0
0

5

10

15

20

25

30

35

Ü.Yze\Pa^]¯tDï!x.`wg

aZ`inLz]&mï!ORn]ORQ]&ai`bHaZ ¡ nHwWRHU^]jW

[l



2:9l{

CB;
xnYMU¢YzU¢H²m¢`D DY[ºV] ³]&aRU^Yd`bN`J_)W^n]¡W^`wg
aZ`iPLd]m
Lz`JW^W^] ¡YzN
ºPeb\naZ]3tnr8YdWOj`NVUoYMUXWRU»`J_"HORn]ORQb]&a»iV`<HJaR r8¸"n]a^]¢YzN
]HOROjLz\PUoW^]&arDWZn]
`YzNbWRUHJaZ] DaRH¸"NHbO&O&`aR DYdNPeWZ`©H
\nNPY[_7`ba^m
`YzN<WYzU

\PU^] ¡YdN§Út<F\¡]&W#HJLÈ¦drtJuubpbàj¦Ò)U

 DYMUXWZa^Yzin\DWZYd`bNHJNP ²WZn]¤NF\nm@iV]a`J_

50 
¾
Â
l
l
Ú
k
l
l
l
l
k
\
l
¥
l
l
l
l
l
(
l
l
l
l
l
&
&
(
!
à
l
l
(
l
l
2
&
(
l
l
2
"
3
l
l
l
l
&
&
(
!
l
H
l
&
l
l
l
l
l
l
Ý
A
B
F
(
A
(
l
l
l
(
l
l
Ý
/
&
(
&
(
(
_
`
Â
¾
c
&
Ý

B
C
&
6
7
m
C
7
n
6
!
n

n
l
l
l
n
l
l
l
l
l
l
l
l
l
l
l
l
H
l
l
l
l
l
l
l
l
r
o
r
r
e
 
t
s
e
T

0.5

0.4

0.3

0.2

0.1

0

Random
Error reduction
Max Uncertainty

5

10

Labeled set size

15

20

r
o
r
r
e

 
t
s
e
T

0.55

0.5

0.45

0.4

0.35

0.3

0.25

0.2

0.15

Random
Error reduction
Max Uncertainty

5

10

15

20
Labeled set size

25

30

ÜBYdeb\naZ]3Ýïhx.]UoW#]a^aZ`aRU"HORnYz]&b] >iFg¡p©HbOWZYdb]Ld]HJaZNnYdNPe¢UoW^aRHwWZ]&ebYd]U"`N¡W^P]¯W^`wg
Ú7aZYze<WRà

aZ`inLz]&m±Ú7Lz]j_ÊWRà#HJNP ¡WZn] 

 nHJWZHiPHU^]

tD¦

tJu§UZHJm

LzHiV]Ld] 

a^`binLd]mrVt
aZHNP D`bm

`NP]O&`NPU^YzUoW^YzNne»`J_8sJtßnÝhW^aRHJYzNnYdNPe»UZHJm

HLzU^`¯ DaRH¸"N
aRHJNV D`m¢Lzgi]jWX¸]&]&NÑÝHJNP ¢ô<un¦!t»LzHiV]Ld] 
`YzN<WZUÚ7`NP]ENn]ebHwWZYdb]hHNP `NP]
`bU^Y[WZYdb]à8Ha^]hUo]Ld]OW^] 
aRHJNP n`m¢LdgªHJNP 
Lz]U¤Ha^]0ORP`bU^]&N«YzNPOjaZ]&m¢]&Nn¥
WRHJLzLdgWZ`>i]@LMHJi]&Lz] 8¦¯xá]UXW»]&aZa^`baZU)HJaZ]@O&`m
\DWZ] 0`bN
`YzNbWRUhHNP ¤Hb]&aRHJeb] @`w]&a)Ýubu»W^aZY[¥
WZn])NP`ND¥TÓ<\n]&aZYd] 
HLzU¦.Ò)U.YzNÚ

]UXWZYdm3HwWZ]¸HbUhºnID] HwW)w
44}2:A~U~4	A

<F\]&WHL5¦zrbtuup<àrW^n]wHJaZYMHJNPO&]E`J_VQ]&aZNn]L
}4

xn]¤aZ]HLE¸`aZLz · nHJWZHJiVHU^]©YzUW^P]
Lz]UHNP 
tuu<s©WZ]UoW`Nn]U&¦xn]3WZaZHYdNPYdNne¶U^Hm
Ld]UPH]3i]&]N
Ld]U"]HbOR8¦hxP]
 DYzFYz n] `N0tp3Uo\niVUo]&WZU`_pPÝs@]&IDHm
WRHU^Q¤YMU"W^`©O&LzHbU^U^Yd_7g> DYzeYdWZUu3W^`3ô©HJe<HJYzNPUoW)å@W^`©ßn¦Ò#U
_7`ba"W^n]¯W^`wg
`bYdN<WRUHJaZ]
U^]&Lz]OjW^] ®HJNP pbu0UZHJm
Lz]U
HJm¢`Nne0W^n]¡pnÝåa^]m¢HYdNn¥
YzNne©HJaZ]Ó<\n]&aZYd] >_7`a"WZn]&YzaLMHJi]&LMU&¦ExP]¯¸"Yz DW^`J_BW^P]
rw¸"nYMOR
e<H]©WZn]iV]UXW
]&a^¥
FYMUo] _7aRHJm¢]¸h`ba^Qµ¦áæ#`JW^]WZPHwWEW^nYMU!YMUHOjW^\PHLdLzg@H|]a^g
U^m3HJLzLnwHJLz\n]HJNP 
WZn]aZ]U^\nLdW^YzNneOjLMHUZUoYdºP]&a!i]&VH]UEHJLd¥
m¢`bUoWHU»Ý&¥ÈNn]HJaZ]UoWNP]&YzeFiV`baOjLMHUZUoYdºP]a¦
]&aZYdm¢]NbWRHJLa^]Uo\PL[WRU@Ha^]

K!Ha^£]&N¯OjLMHUZU^Y[ºP]aá¸HUBUo]&W.WZ`fw

]&a^_7`aZm3HJNPO&]>YzNªH²UoWZHJNV nHJaR ®U^\

tåv
ÕÚ:uTdÝà

×!I
a^`wFYM D] §YzNºVe\naZ]0ÝrE¸"n]&aZ]
W^P]§m
]&W^n`D ¹ D]U^O&a^YziV] YdNW^PYzU0U^]OjW^Yz`N,Ú7]NbWZY[WZLd] 
Ó<\n]a^Yz]U¯HNP ·WZ`0W^P]

UoWZHJNV nHJaR %$&!'(")*!+,).-®UoW^aRHwW^]eg¸"nYMOR
U^]&Lz]OjWZU¡W^P]
YÈ¦
aZ`iPHinYzLdYdWXg®Ú:p<à)YzU»WZn]3Nn]HJaZ]UoW)_7aZ`m
]b¦3¸"n`bU^]¢`\DW
ÝÔtD¦
>UXWZaZHJW^]&ebgÑHJaZ]¢a^]HJLzLdg
xn]3aZ]U^\nLdWZU»_7`baW^n]/0#1
`YzNbWZYdNPePïYdW¯YzUNP`JW¯m\VOR²i]jW^W^]aW^PHN2!"#+3$ÿ`bN
 DYMU^H
aZ`iPLd]m¡¦
HJNP >YMUW^]a^aZYdiPLd]»`N>W^P]»W^`wg

`YzNbWY"_7`a¯¸"nYMOR²W^n]3Lz]Ha^NP]&a»YzUW^n]©m¢`<UXW\nNPO&]&a^WZHYdN8r

HJaZ] ²WZ` !"#"$

wà»YzU
Oj`bm

lnl

\DW

aZ]U^]&N<W^] ®YzN®WZn]

xn]Oj`bN54X]OjW^\naZ]¤`_¸"<g·YdW@_:HYdLz] ®YzU@i]O&H\PU^]©W^P]¡UoW^aRHwW^¥
]&ebg
]NP nU¢n]H<¥
YzLdg`bNÑaZ]&LzYzHinLd]
]UoW^Yzm3HwWZ]U|`J_WZn]
a^`biPHJinYzLzY[WZYd]U
Ú:]à"HNP ¡]Ó<\PHJW^Yz`N§ÚXÝàoà¦Ün`ba"W^nYMU"aZ]HJ¥
ÚÊWZnaZ`\neb>WZn]UoW^]
U^`N8rV¸h]¯¸"YzLzL8W^aZg¡YdNWZn]¯aZ]UoW#`J_W^P]
]&a#W^`©VH]m¢`aZ]

aZ]&FYd`b\PU¢Uo]OWZYd`bNª D]
`<UXWZ]&aZYd`ba

.3Ú/

WYzNUo]OW^Yz`N¡ôP¦

aZ]&LzYzHinLd]Ñ]UoW^Yzm¢HJW^]U&r)in\DW>NP`JW^]ÑW^PHJW¡YzNØm¢`bUoW¡OHU^]Ur"W^P]
 D]OjYMUoYz`N>_7\nNPOjW^Yz`NeYz]N>iFg¤Ha^em3HJI
\nNPORVHJNneb] ²Ú7]jInO&]
tàj¦

ºPaZUoW¢`iPU^]&aZwHwW^Yz`N§¸"PYzOR®U^n`w¸UW^PHJW@WZn] D]&NPU^YdWXg§]Uo¥
W^Yzm3HwWZ]U¤Ha^]ÑNn`JW¤b]&aZg®aZ]&LzYzHinLz]0YzU©W^n]0_7`LzLd`w¸"YzNnePï¶_7`a>H
eYz]N

áà¸"YdLzL8aZ]&m3HJYzN
.3Úáà3OHJNª]&YdW^n]a3iV]]UXWZY[¥
`YzN<W;!rEWZn]wHJLz\n]`J_
Ú
.3Ú/
Dà
.©ÚnàqóÝJvS$
Ú Õà
DC*
<ÂX>d
ábnÂÞB

À)


W^P]
`YzN<WZU*:µ`baHbU
`bN¡W^n]LMHJi]&Lz] 
K!HJaZ£&]&N>¸"YdNV D`w¸
wHJLz\n]U"OHJN¡iV]¯Ó<\nYdW^]¯ nY[´µ]&aZ]&N<W¦

m3HwWZ] ØHbUÑÝSv76

K!Ha^£]&N«¸"YzNP D`w¸`NØHLdL

`YzNbWRU;:ÕäPHNP >W^n`<Uo]»WX¸`

oC*

À#ÂTnÂo¿

Á#FÂ

à98

Ò#Um
]N<W^Yz`Nn] >HiV`wb]rFW^P]¯UXWRHJNP nHaZ ¡K!HJaZ£&]N©¸"YzNP D`w¸]Uo¥
W^Yzm3HwWZ`a`_VWZn]OjLMHUZU!Oj`bNP DYdW^Yz`NPHLP D]&NVUoYdW^Yz]U n`<]U!Nn`W!WZHJQb]
YzNbWZ`3HO&O&`\nN<WW^P]\nNnLMHJi]&Lz] 

`bYdN<WRU&¦!STN`JWZn]&a"¸`aR nUr

X!Fµ¿
¾

¿EÂ

n

X>



áÀ

óÝà?

.3Ú

.¢Ú 
.YMUWZn]K!HJaZ£&]&N|¸"YzNP D`w¸§]UoW^Yzm3HwWZ`a8`bNW^n]hLzHiV]Ld] 

¸"n]a^]
HJNV ¤\nNPLzHiV]Ld] 
°²]¯¸"YdLzLá DYMUZOj\PUZUWX¸`3¸HgDUhW^`¤U^`Lz]|WZn]¬^O&`N<W^aRH DYMOWZYd`bNP­
aZ]&]HJLz] ¤i<g¤]Ó<\PHwWZYd`bN²Ú:ô<àj¦

CB
+GÝàA@
.3ÚÕà

`YzN<WZU¦

Ú7ôFà

|*~U}&;wAn4#|.9HJI)AD;5K9l|JL34 |MH

DFEG
xn]#ºPaZUoWhYM D]HYzUhNn`WEW^`@]UoW^Yzm3HwW^]#iV`W^>O&LzHbU^UhOj`bNP DYdW^Yz`NPHL
 D]NPUoYdW^Yz]UYzNP D]
]NP D]&N<WZLdgbrDin\DWYdN¡Uo\POR¡H¯¸Hg
W^PHJW]Ób\VHJLd¥
YdWXg>Ú7ôFàBn`LM nU¦STNÚ
NPYdQµrPÝßßbqbàrY[WE¸HU!U^n`w¸"N@W^PHJWW^P]
HU¤H³Uo`bLd\nW^Yz`N
K!HJaZ£&]N¸"YdNP n`w¸]UoW^Yzm¢HJW^`ba>O&HN«iV]·U^]&]&N
W^Yzm¢Yd£HwWZYd`bN
`J_HJN3`
a^`binLd]mÿO&`NPU^YzUoW^YzNne»`J_8HU^m¢`<`W^nNP]UZU
W^]a^mÿHJNP ¢H)W^]a^möºPWoW^YzNne»WZn] nHwWRH@Ú7W^n]0N
]&aZa^`ba.i]jWX¸]&]N
W^P]]&m
YzaZYzOHJL DYzUoW^aZYzin\DW^Yz`N0_7\nNPOWZYd`bNÑHJNV W^n]@]UoW^Yzm3HwW^] 
`NP]à¦

51l
k
K
k
l
l
l
l
l
u



|
 
k
K
k
l
l
l
l
l
l
u

u
l
l
l
l
l
l
l
l
 
k
K
k
l
l
l
l
l
l
l
l
H
l
&
l
Ò
l
6
A
n

l
6
7
&
&
6
!
n
8
l
<
=
¾
¾
¾


Á
¾

¾
l
&
&
B
l
=


L
l
 
H
l
l
l
u
l
WZnYzUø`biPUo]a^wHJW^Yz`N8rÿY[W¸HUøUo\nebe]UXWZ] 

`bN
]&LzLd]br"tuubpnrfhVH

cHU^] 
ÚÈfhVH
U^\
]a^FYMUo] ¡Ld]HJaZNnYdNPe¢W^`3]jI
Oj`bNPUoW^aRHJYzNbWYzN²W^n]3`
UoW^aRHJYzNn] ¡K!HJaZ£&]N¤¸"YzNP D`w¸

YzN
WZ]&a¡sà
YdNWZn]0Oj`bNbWZ]jIFW©`J_U^]&m¢Y[¥
LzYMOjYdW^Lzg¡Hb n ]Ó<\PHLdYdWXg¶Ú:ô<àHU#H
aZ`iPLd]mHJNP ¶WZnYzUOj`Nn¥
]UXWZYdm3HJW^]|W^\naZNPU"`b\DWW^`3i]

W^Yzm¢Yd£HwW^Yz`N

]¦

Ú5åbà

687

óÝàq

öÝà
.¢ÚáàUG

. "Ú 

.3Ú Q
.3Úáà
.ªuPr<YdWm¢Ydeb<WPH

.3ÚTà
.ÿYzUW^n]¯ DYd´µ]&aZ]&NPO&]¯iV]&WX¸h]]&N¡W^P]¯Ld]&_ÊW)HJNV >aZYze<W
.3Ú
?nà

¸"n]a^]
PHNP UoYM D]`_áÚ7ôFàrY5¦
°«YdW^¯WZnYMU.NP]&¸§]UoW^Yzm3HwWZ]h`_POjLMHUZUáOj`bNP DYdW^Yz`NPHL< n]&NPU^Y[WXgbrnÚ7ôFà
i]Oj`bm¢]UNn`w¸HJN]Ó<\PHLdYdWXg¦
÷`w¸]&b]&arWZnYMU§m¢`F nY[ºVOHwWZYd`bNÿaRHJYMUo]U¶HNn`JWZn]&a
¸"n]N
]&N>W^PHJW"W^n]»`\nW
HJiPYdLzY[WXg
W^PYzUOHU^]r¸]
 D]OjYM D] ÑW^`>W^Pa^]Uon`bLz 0W^n]¢`b\DW
Ý¦
Òm¢Yz P DLd]#¸HgU^`Lz\DWZYd`bN@YMUW^`¯Hb n 
`NnLzgH|_7aRHOjW^Yz`N
`J_
]b¦W^`¢a^]
YÈ¦
 	
¸"n]a^]

áà@YzU
Nn`·Lz`Nneb]&a
iV]&WX¸h]]&N³u²HJNV 

YMUORn`bU^]&N>iV]&WX¸h]]&Nu¢HJNP ²Ýb¦

a^`binLd]mï
\DW
aZ`in¥
Ýb¦STN
\nW|WZ`u¤`ba

LMHOj]»]Ób\VHwW^Yz`N·Ú5åbàiFgr

¹ÝàF?


óÝàq

.3Ú 

.3Ú

Ú/

.¢r

 	

à





Ú:v<à

Ú

lnl

r
o
r
r
e

 
t
s
e
T

0.21

0.2

0.19

0.18

0.17

0.16

0.15

0.14

0.13

 0  

Adjusted PW
Random
Max Uncertainty







Level of adjustement g





 1  

a^`

lPl
\nW

YzNÚ:vbà#Hw_ÊWZ]&a)pbu

ÜBYdeb\naZ]pnïxá]UXW|]&aZa^`baHU)H¢_7\nNPOjW^Yz`N0`_
`YzNbWRU"¸]&aZ]|Hb n D] ¡YzN¤WZn]LMHJi]&Lz] Uo]&W`J_	 
Ò#U
Lz`JW^W^] ÑYdN0ºPe\naZ]pPrPWZn]&aZ]@OHJN0i]@H¤]&aZgUoYzeNnYdºVOHJN<W
YMU©ORn`<Uo]N³H
a^`wb]&m¢]&N<W3¸"n]&N
Yzm
aZYzHJW^]&Lzg¦«÷#`w¸¥
]&b]&arbYdWYzUNn`WO&Ld]HJan`w¸«Y[W"U^n`\nLM ©i]»ORn`bU^]&N8¦!Ò#LzU^`Pr<W^P]
_:HOjW!`J_VVH<YzNne#W^`|W^naZ]U^n`bLz ¯W^n]"`b\DW
a^`biPHJinYzLzY[WZYd]U.i]j¥
O&H\PU^]W^P]&g¤Ha^])Nn`JW"HJLz¸HgDUEiV]&WX¸h]]&N>u
HJNV 0Ý#YMUNn`JW]a^g
UZHwW^YMUo_:HOWZ`aZg¦ªÜn\DWZ\na^]aZ]U^]HaZORYzNPO&Ld\P n]U
W^P]0 D]&aZYdwHJW^Yz`N
HJN¡Yzm
DFE
ÒUo]Oj`NV ©YM D]H@YzUEW^`
\PU^]|HLdLWZn]
lnl
`J_WZn]¤OjLMHUZU nYzUoW^aZYdiP\DW^Yz`NØÚÈtà¦ÜBYzaZUoWr!U^\
LMHJi]&LMU`J_BW^P]¯\nNnLMHJi]&Lz] 
OjLMHUZU"K!HJaZ£&]N©¸"YzNP D`w¸]UoW^Yzm¢HJW^]»¸`\nLM ¤ebYdb]

HJNPU^Yz`N
`bU^]¢W^PHJWW^P]
`YzN<WZU¸]&aZ]QFNn`w¸"N8¦xn]&N8rVW^P]

a^`wb] ¡Oj`NVUXWZaZHYdNn] ¤K!Ha^£]&N¤¸"YzNP D`w¸

9<259H³C
`YzN<WZUYzN¤WZn])]&I

|1}?.9*|B2:A

CAb|*~4

]UoW^Yzm3HwW^]b¦

4#|4}U~

yz

.¢Ú

/

!E*

O

àq

ÚÈàNT

7n

oC*O

ÚÈsà

LMHJi]&Lz] 

`YzN<WZUrD¸h]»WZn]&NPHb]

.3Ú qÿÝL/
Ú

Èà#HJNP YzN<W^]j¥
àNT

eaRHwWZYdNPe`w]&a»WZn]>ORP`YMOj]©`_WZn]©\nNPQ<NP`w¸"N§LzHiV]LzU`J_"W^P]
\nNnLMHJi]&Lz] 

STN<W^aZ`D D\POjYzNne3WZn]wHa^YMHJinLz]Uq
DC*

`bYdN<WZUHa^]h`J_O&`\naRU^]\nNnQFNn`w¸"N8r
`YzNbWRU8HJaZ]U^]jW8YzN»W^nYMUáU^]OjW^Yz`N|W^`u`baÝrHOOj`aR DYzNne

.3Ú
óÝàq
xn] _7`baáWZn]\nNnLMHJi]&Lz] 
in\DW)¸h]¯¸"YzLzL.U^]&]n`w¸W^`3]UXWZYdm3HJW^]WZn]&m¦"xn]!=!_7`baW^P]
]¦"=*óÚ ?ØÝàQvJtD¦
W^`
WZn]LzHiV]LzU)XrnYÈ¦
]Ó<\PHJW^Yz`NÚÈsàeYz]U

Ú 


à&%
W^VHwW¸]»OHJN¡a^]¸"a^YdW^]»YzNm¢HJW^aZY[I>Nn`JWRHwW^Yz`NHU

æ`w¸ªNn`W^]"WZPHwWEiFg
Oj`NV DY[WZYd`bNnYzNne`N
W^P]O&`NP nY[WZYd`bNPHJL
K!HJaZ£&]N¤¸"YzNP D`w¸

.3Ú $#>óÝL/

aZ`iPHinYdLzYdWXg`\DW
m
`D D]L5r

`YzNbW\nNP n]&aW^P]

	#Jà

oC*
oC*

\DW!`J_VH

Ú

YMUH3 DYMHJeb`NPHLm¢HJW^aZY[I¡¸"Y[WZ

¸"n]a^]Y

à¦

Ú 

¸Hg§W^`·]UoW^Yzm3HwWZ]

YMU
W^`§]ND_7`aROj]¡WZPHwW+
_7`ba
¦cg® D`YzNne·Uo`VrWZn]m
`D D]L"YzU
LzY[W^W^YzNne]Ó<\PHJW^Yz`N³Ú5qbà#iV]&WX¸h]]&N²LzHiV]Ld] ÑHNP 

]HbOR®\nNPLzHiV]Ld] 
Oj`bn]&aZ]&N<W¦
\nNnLMHJi]&Lz] ¡inLz`DORQDU&rFWZnYzU#Oj`NVUXWZaZHYdN<W¸"a^YdW^]U

kFl

'#b
D:6*)

Ú:q<à
HNP 

`YzN<W;
à@^O

@ZÚ 
?ØÝàQvJtnrD¸h]»e]&W
Ú23>GÚ 
@^O
8dÚ#
m3HwWZ] ¡YdN§Út<F\>]&W#HJLÈ¦drPtuup<à¦

¸"nYMOR¤YMU]jInHOjW^Lzg
P`w¸«W^n]|`\nW

à@^O

¸"n]a^]¶W^n]·U^\niPUZOjaZY
W^P]ÑLMHJi]&Lz] «HJNV «\nNnLMHJi]&Lz] «YzNP DYMOj]U&¦óÒ#NP ØU^YdNVOj]
Ú21

WRU.-HJNV 0/¹UXWRHJNP 

]OjW^Yz]Ldg_7`ba

,

Ú21

?ØÚ#
Ú 

,XÚ21
\DW

@^O

a^]U

à@O
@^O
?ØÝàQvJt

,;
?ØÝàQvJt

aZ`iVHJinYzLdYdW^Yz]UHJaZ]#]UXWZY[¥

\nW

a^`biPHJinYzLzY[WZYd]U
xnYMU·¸Hg¹`_>]UoW^Yzm3HwWZYdNne`J_>W^n]`b\DW
`NVOj]¡Y[W¢YzU
gFYd]Lz ³ DYza^]OW^LzgHJN³HOWZYdb]>Lz]Ha^NPYdNne¶HJLze`aZYdW^nm
a^]Uo]N<W^] ÑYdN²Uo]OWZYd`bN²tD¦
Oj`bminYzNn] 0¸"YdW^¶W^n]
_7aRHJm¢]&¸`aZQ
YdN,Ú
xnYMUHJLze`ba^YdW^nm
¸HUU^\neeb]UoW^] 
]&aZYzm
]N<WZHJLaZ]U^\nL[WRUWZn]&aZ]&YzN>Ha^]|Ó<\nY[WZ])Yzm
aZ]Uo¥
HJNV 3W^P])]&I
]ao_7`ba^m3HNPOj]UYzU
LMHJNPHJW^Yz`N·_7`aW^n]Uo]>e`F`D 
U^Ydb]¦0ÒN®]jI
YzN3W^nYMUHJLd¥
W^VHwWEWZn]&aZ]YMUhH
Lz]Ha^NPYdNne¯UoW^]
ëjË&í
Ç
e`ba^YdW^Pm¡¦²STNP D]] rhOj`NVUoYM D]&a¢HJN®\nNnLMHJi]&Lz] 
un¦
xn]&N8r
¸"nYMOR
W^P]@Oj`bNPUoW^aRHJYzNn] K!HJaZ£&]N>¸"YzNP D`w¸¹]UXWZYdm3HwWZ`a¸"YzLzL.Oj`ba^aZ]OjW
W^P]¢O&LzHbU^U»O&`NP DYdW^Yz`NVHJL! D]&NVUoYdWXg0]UoW^Yzm3HwWZ]U|iFg0H n DYzNne¡W^P]
UZHJm¢]HLd\P]
U^]&m¢Y[¥TU^\
iV]&WX¸h]]&N²u
HJNV Ý¢HO&O&`aR DYzNne©WZ`>¸"PHJW|YMU)W^n]¢m¢`bUoW¬oLzYdQb]&LzgF­¤LzHiV]L`J_

<µ<\]jW0HL5¦zr»tuubpbà
`YzN<W5)_7`ba
GÝà54
àQvJtÑW^`§i`JWZ`J_#WZn]&mr¸"n]a^]HU
W^P]

]a^FYMUo] 0`bNn]@¸"YzLzLORP`<`<Uo]¢H>HLd\P]6

.3Ú

.3Ú

ðè
Ýà.4

.3Ú 

Ë&ÎÉÇMë&ËRì

ÜBYdeb\naZ]0ôOj`bNDºPaZm¢U©W^PHJW>U^YdebNnY[ºO&HJN<W©Yzm
YzNP D]&] ¯`biDWZHYdNn] \PU^YdNPeW^PYzU.m¢]jW^P`F >Ú7aZ]j_7]a^aZ] YzNWZn]
HU87

a^`wb]&m¢]&N<WRU©HJaZ]
Ld`W

9:7<;>="

Fà¦

$

52l
l
l
l
l
l
&
&
?
Ý
t



B
&
l

l
l
&
.
l

l
&
.


&


t














l
k
K
k
¦
l
l


l
l
l
l

|



l
l
l
&
O
A
Ý
6
A
B
7
m
C
l
&
Ý
6
A
B


n

l
l
l
l
l
&
6
A


n

#
à
6
A
n

#
B
B
(
%

M

n
(


n

)
n

)

n
)
Ò
(


B


l

(
M

n
@
(
@
M

n
,
(
l
l
(
(
@

M

n
à
@
à
M

M

n
à
,

G
n
@
:
M

n

l
l
l
l
l
l
l
l
l
Å
ë
l
l




l



¦
l
l

7
r
o
r
r
e

 
t
s
e
T

0.5

0.4

0.3

0.2

0.1

0

Semi−supervised
Random
Max Uncertainty

5

10

Labeled set size

15

20

ÜBYdeb\naZ]|ôVïâ"]U^\nLdWZU"`bN¤WZn]»W^`wg¡ nHwWRHJiPHbUo])_7`aWZn]¯m¢]jWZn`D 
 D]U^O&a^YziV] 0YzNÑWZnYMUUo]OW^Yz`NªÚ7
Fàr8¸"PYzOR¶¸HbU
ºPaRUXW"YzN<W^aZ`F n\POj] >YzN§Ú

9:7<;>=+

$

<F\¡]jW#HL5¦zrPtJubupbà
;J{
t

B2:A
_7`a#W^n]
LMHJi]&Lz] 

}4



{An;#4 |

DFE 
°²]@Nn`w¸öO&`NPU^Yz n]&a)W^n]6
wHJaZYzHinLz]U¦
Ün`ba#H
ºnID] wHLd\n]`J_W^n]]OjW^`ba
HJiPYdLzY[WZYd]U¯`bN§W^n]>\nNnLMHJi]&Lz] 
aZ]&FYz`\PUU^]OWZYd`bNi<g

`YzN<WZU»HU_7a^]]

rPWZn]

aZ`in¥
`YzN<WZU
HJaZ]3eYz]&NárHbU¯YzN§W^P]

`bUoW^]a^Yz`a

\nW

àN

N)Ú

,T

à@^O

Ú:ß<à
WZYdm¢Yz£HwWZYd`bN
HJNP H·¬ZOj`bn]&a^¥

@ZÚ23GªÚ#

à@^O

@Fà

Ú#

HUµWZn]EU^`Lz\DW^Yz`N`_DHN»`

°²]EUo\Pee]UXWWZ`"ºPNP 
aZ`inLz]&møOj`bNPUoYMUoW^YzNne3`J_H¢LzYdQb]&LzYdn`F`D >W^]a^m
]&NVOj]­@WZ]&aZm¡¦
ÜBYdaRUoW^LzgrVO&`NP nY[WZYd`bNnYdNPe©`NWZn]¯YzN
aZ`iPHinYzLdYdW^Yz]U


\DWRU)HNP `NWZn]`b\DW
,XrnW^n]Lz`e¥ÈLzYdQb]&LzYdP`<`D ¤`J_áWZn]LMHJi]&LMU"YzU


!4

Lz`e

@<àq

!/

*



Lz`e9.3ÚL
oC*

ÝHG



Lz`eÚXÝHG

HNP (B

`bUZU^YdinLz]¡W^`·e]&W

¸"nYMORUon`b\nLM ¤i]m3HwIDYdm¢Yz£&] ¦
HJaZ]]UoW^Yzm3HwW^]@`J_W^P]
]Oj`NV DLdgbrPNn`W^]WZPHwW|iV`W^
aZ`iVHJinYzLdYdW^Yz]U¤HJNP YM D]HLdLzg³W^n`<Uo]WX¸`b]OWZ`aRU
`bUoW^]&aZYz`a
U^n`\nLM i]@YM D]NbWZYzOHJLÈ¦|cg D]&ºPNnYdW^Yz`N0`_W^n]
ORn`YMOj]@`J_
¦×E]N¶WZn`\Pe§YdWYzU
YzNØÚ:ßbàjr¸h]3PHb]©HJLza^]H Dg
rh`bNn]O&HJN³W^aZg§WZ`§m
YzNnYzm¢Yd£]
Yzm
¦xn]Yda nYzUZOjaZ]
HNPOjg
HJNP 
W^P]¤ DYd´]a^]NPOj]©i]jWX¸]&]N
H·m¢]HU^\naZ]`J_n`w¸
YzNPO&`n]a^]NbW3WZn]0m¢`D D]&L
YMU©Uo`bm¢]&n`w¸
YMU&¦
YzNPOj]"i`JWZ3]OjW^`baZUHJaZ]HOjW^\PHLdLzg¯]UXWZYdm3HwWZ]UHiV`b\DW!W^P]
\PU^]©WZn]>ç»\nLzLziPHORQ<¥Tò8]&YzinLz]&a nYdb]&aZe]&NVOj]r¸"nYMORYMUYzN§WZnYzU
O&HbUo]brD\nNP D]aHJNYzNP D]

]&NV D]&NPO&]¯HUZUo\Pm

Oj`bNP DYdW^Yz`NPHL DYMUXWZa^Yzin\DWZYd`bN8r[.3Ú /


à

,EHNP 

B

DC%

Lz`e

N)Ú

SÕ_

W^Yz`N8r

áàjrYdW©Uo]]&m3U3NPHJW^\naRHJLWZ`
ÝHG
?¶ÚXÝG
ÝHG(B
=

HJNPU^Yz`N

àFLz`e

,Ha^]@OjLz`bU^]]&NP`\neb8rH3ºPaZUoW)`baZ n]&a#]&I

eYz]U

ÚoÝu<à

,:à

`<Uo]br
rHJNP 0\PUoYzNne©iPLd`DORQ¡m¢HJW^aZY[I

\na

,5à

N)Ú

m

W^`¤O&`m

DC*
3YG

ò8]&W#\PU)Uo]]¯n`w¸
YM D]&N<W^YdW^Yz]U#HU¸]&LzL8HUÚ:ß<àrn¸]»e]&W

,
¸"n]a^],Ú
¸]¯YdN<WZa^`D D\PO&]1


,Ú
,	
,4G
^¦"Ün`ba"W^nYMU
R

G(B
ÚoÝHG
7	
m
\DWZ]!*G
TÚ23G
8zÚ
8zÚ
,B¸"nYzORm¢YzNnYdm¢Yz£&]U
à?,Ú
,.W^naZ`\neb>]Ó<\PHwWZYd`bN²Ú5ßbà¦

=G

G

@J@

N)Ú

,:

,,

,,

,,

Ú

à

K\nWoW^YzNne³]&]a^g<WZnYdNPe·W^`eb]jWZn]&ar¸]ÑUo\Pee]UXW¤W^`§ºPNV «W^P]
]OWZ`a

lPl

WZY[¥

aZ`iPLd]m

@3_7a^`bm

]NP DYdIµ¦

HU"U^n`w¸"N¡YdNH

HJNV ©WZ`3e]jW
æ`W^]3WZPHwW@W^n]¤m
YzNnYzm¢Yd£HwW^Yz`N§`_¯ÚXÝu<à»YMUH0O&`NF]&IÑ`
m¢Yd£HwWZYd`bN
\D¥
Ò#UEHUoYM D]aZ]&m3HJaZQµrw`Nn]"m¢Yze<Wi]¸h`ba^aZYz] @i<gW^n]O&`m
Lz]jIDYdWXg)`_DW^nYMUBm
]&W^n`D ¯HbUá¸]&LzLbHbU.U^`m¢]`W^D¥
WZHJW^Yz`NPHL<O&`m
]a¦hSTNP D]&] rVHJW#]HbORY[WZ]&aRHwW^Yz`Nár
aZ]U^]&N<WZ] ¡YdNWZnYMU
]&aRU
HJNV 
_7`aE]HOR3O&HNP DYM nHwWZ]rbW^n]
a^`bnYdiPY[WZYdb]
Yd_
Ú7iVà|YzN§Uo]OW^Yz`N·tàjrá¸"nYMOR¶¸`\PLz ¶iV]
Ú:UoW^]
 nHwWZ]U.¸h]a^] D`NP]ENPHYdb]&Lzg¦.÷#`w¸h]]ar\PUoYzNne)aZHNnQ<¥
W^P`bU^]E\
 nHwWZ]UHJNP ¢inLz`DORQ@m3HJW^aZY[I
Yz D]N<W^YdW^Yz]Ur<`bNn]#OHJN©Oj`bm
¥
`NP]\
\DWZ]3]j¨©OjYz]&N<WZLdgÑW^n]3Nn]¸ÿebaZHb DYz]&N<WZU»HJNV ²÷#]UZUoYMHJN²`J_W^P]
`i4X]OWZYdb]_7\nNVOW^Yz`N·ÚXÝubà¸"n]&NH¯LMHJi]&Lz] 
`bYdN<WYzUH P D] ¦
ÜnaZ`m
YzUU^Yzm\nLMHwWZ] ¶YdN·`aR D]a#WZ`

.Nn]&] 
W^`¯i]#aZ]j¥Õ]UoW^Yzm3HwWZ] 

 nHwWZ]
]&aZYdm¢]NbWRHJLha^]Uo\nLdWZU@\PU^YdNPe0W^PYzU
Uo`_ÊW@m3HJaZeYzN·_7`aZm\PLzHJ¥
a^]Uo]NbWZ] ¤YdN¤WZHJiPLd]¢Ý»HJNP ¤`N¤i`JWZ¡ PHwWZHiPHU^]UhYdW
¦xnYzUm¢Yze<WiV]i]O&H\PU^]EWZn`bU^] PHwWZHbUo]&WZUBHJaZ]
`bUoWZHL nHJWZHbUo]&WrFH¯PHaZ ¢m3HJaZeYzN
]&a^_7`aZm3U#i]jW^W^]&a|WZPHJN²H>U^`J_ÊW»m3HJaZeYzN0`Nn]à¦¯÷#`w¸¥
]&aZYdm¢]&N<W3WZnYzU

×!I
W^Yz`N¡HJaZ]
 DYM NP`JWn]&L
Nn`WhaZ]HJLzLzg@Nn`bYzU^gÚÊ_7`baEWZn]
k 
]&b]&arEYzNª_7\DW^\naZ]]jI
HJLze`ba^YdW^Pmý`NNn`YMU^g¤ nHwWRHU^]jWRU&¦
Ýu
tJun¦
ÝåD¦

Ýubuu
tDÝb¦
Ýån¦

÷)HJaR ¤m3HJaZeYzN

tDÝb¦
Ýån¦

]&aZYdm¢]NbWRU&r¸]¡¸"YzLzL]jI

fhn]ORQ]&ai`bHaZ 

W^n]a^]bráH>æ#]&¸WZ`N
,T¦

tun¦
Ývn¦

UUXWZ]

xBHJinLz]ÑÝbï©xá]UXW¢]&aZa^`baHU
H_7\PNPOWZYd`bN®`J_#W^n]Uo`_ÊW@m3HJaZeYzN
HaZHm
]&W^]a
`YzN<WZU©_7`a©WZn]¶ORP]ORQ]a
i`bHJaR ¡ nHwWRHU^]jWHJNP ¡pu@_7`ba0 

HJ_ÊW^]&a¶ÝuÓ<\n]a^Yz] 

Ø¾

4
8nF!Â

fh`NVUoYM D]&a¯W^n]©]&InHJm
Ó<\nYdW^]¯U^Ydm¢YzLzHaW^`¢W^P]`Nn]YzN§Ú

Lz]

¿h


8VÂX¿
n¿E#)ÂoÂTnÂ
á
<F\]jW#HL5¦zrPtJubupbàHNP 

a^]Uo]N<W^] ²YzN·ºPe\Pa^]¤ånr.¸"nYMOR·YzU
YzORQ

53
7

}

|

l
(
,
l
l
l
l
(
M

n
M

M

n
,
(
(
,
l
l
l
l
l
(
(
!
B
Ý
?
t


?
t


à
%
(
,
k
(
(
l
l
(
@
(
@

B
(
@
l
(
,

B
(
,
(
,
B
(
,
l
k
l
l
n
(
,
(
,
!
B


F


B
R


F


R
T
(
B
(
l
n
(
B
(
4
!
B
Ú




à
u




à
(
(
B
(

à
%
6
m



M


T
l
B
l
l

M

n
B


M

n
à
F
(
,
(
@


,
@

M


@
,
à
(
,
:


M

à
M

(

(
G


(
,
(
,
M

à
M

(
,
(
(
l
l
l
l
l
l
H
l
l
l
l
l
l
l
l
\
l
(
l
l
l
l
G
l
l
l
Ý
q
ß
å
å
 
k
K
k
å
v
å
t
l


l
k
K
k

¾


l
l
l
`bYdN<W#YzNW^P]@OjLz\PUoW^]a#`NaZYze<WPHJNV UoYM D]¦"xn]NW^P]
`YzNbW@W^`¶iV]Ld`bNne0WZ`Ñ]&YdW^P]&a@O&LzHbU^UYzU
`YzNbWRU&¦
`bYdN<W"YzUNn]Ha^]aE_7aZ`mýWZn]¯OjYzaROjLz]rFW^P]
aZ`iPHinYzLdYdWXgÑ]UXWZYdm3HwWZ] ·iFg·K!HJaZ£&]&N²¸"YzNP D`w¸Þ`J_

`NP]
aZ`iPHinYzLdYdWXgÑ_7`ba¯WZnYzU
]a^gU^m3HJLzL.i]OHJ\PU^]YdWYzU#_:HJa|_7aZ`m
÷`w¸]&b]&ar<U^YzNPOj]|W^P]
`bUoW^]&aZYz`a
YdWZU"LMHJi]&Li]&YzNne©H¢OjYzaZO&Ld]»YMUHJLzm¢`bUoWÝ¦

iV`W^¶LzHiV]Ld] 

ÜBYdeb\naZ]|åDï!xn]|\nNnLMHJi]&Lz] 
`bYdN<WRUh`bN3W^P])aZYdeb<WhPHNP ¤U^Yz n]
¸"YzLdLµNn`Wi]»Ób\P]&aZYd] ©i]O&H\PU^]#WZn]&g©Ha^]
Ú7m3HgFiV]|¸"a^`bNneLzgnà
i]&LzYd]] >WZ`
i]¯OjYzaROjLz]U¦
STN<W^\nYdW^Yz]Ldgbr|W^nYMUYMUNn`JWb]&aZg
Lz]HJaZNnYzNne³HLdeb`aZY[WZnm
OjLz\PUoW^]a¦²xnYzU
YMU`bNn]¤`_"W^n]
lPl
W^P]
`a"P`w¸

U^HJW^YMUX_:HbOWZ`aZgï³W^P]HOWZYdb]
WZnYzU
aZ`inLz]&m±`DO&O&\na^aZYzNne0YzNW^P]
G0OfHJLd¥
aZ`iPHinYdLzYdW^Yz]U
in\DW¢YdebNn`aZ]UW^P]&Yza
wHa^YMHJNPO&]

Lz\nmrFtuunÝbäL<F\3]jWHJLÈ¦drFtJuubpbà.YMUW^PHJWEYdWE\PU^]U]UXWZYdm3HJW^]U`J_

a^]Uo]N<W^] 
HJi`w]HU¸]&LzLnHUYzNÚ:â"`wg@ã

aZ]&LzYzHinLd])W^P`bU^]]UoW^Yzm¢HJW^]U"HJaZ]¦

a^`<HOR
`bUoW^]a^Yz`a

¸"YdLzL»Nn`JWUo]Ld]OWH

`YzN<W>_7aZ`m

|*~U}&;wAn4#|.9HJI)AD;5K9l|JL34 |MH

 EG
xn]"Oj`bNPUoW^aRHJYzNn] @K!HJaZ£&]&N@¸"YdNV D`w¸³U^`Lz]U8WZnYzU
a^`binLz]&mHbU
YzN¤aZ]&eYz`NVU`J_áW^n]»U
HOj])¸"n]&aZ]WZn]&aZ]»HJaZ]#\nNnLMHJi]&Lz] > nHwWRH
¸"nYMOR®HJaZ]3_:Ha_7aZ`m±W^P]>LMHJi]&Lz] §`bNn]UrY[W¢YzNPOjaZ]HbUo]UW^P]
4X`YzN<W# D]&NVUoYdWXg>]UXWZYdm3HJW^]U#HJNP >W^P]¯HJm¢`\nN<WiFg¤¸"PYzORYdW#YzU
YzNPOjaZ]HbUo] §YzU@WZn]U^Hm
]¤_7`a¢i`JW^ªOjLMHUZUo]U&¦xF\PU@YzN®WZnYzU
O&HbUo]brFW^n]
 E
SÕ_W^n]a^]YMU!HJN
\nNPOj]aoWRHJYzN<WXg¯HJi`\DW!WZn]
YdWXg©`J_H
xn]a^]¢HJaZ]
U^]&b]&aRHJL
ÜBYdaRUoWrLd]&W©\PU3YzNbWZa^`D D\VOj]W^P]Ld`be²aRHwWZYd`·`_#W^P]
aZ`iPHinYzLdYdW^Yz]Ur

`<UXWZ]&aZYd`ba
a^`biPHJinYzLd¥
\PUoP] ¤W^`w¸HJaR nU#ÝwÔJtn¦
`<U^U^YzinYdLzYdW^Yz]U)_7`aHORPYd]<YzNne¤W^nYMU»e`<HJLÈ¦
`<UXWZ]&aZYd`ba

9B2:AD;w4.K4 |M

`YzN<WrFW^PYzU`bNn]Uon`b\nLM ©i]

aZ`iVHJinYzLdYdWXg3YMU"Nn]Ha_7a^`bm

`bUoW^]a^Yz`a

ÝÔtD¦

ÚoÝÝà

«Lz`e

.3Ú%¹ÝL/
Õà
5à
+GÝL/
.3Ú 

BAH.;w4¡CE9l|.AP2}

xn]ºVaZUoW§Yz D]H¹YzU²WZ`öYdN<WZa^`D D\PO&]«H
Ó<\PHb DaZHJW^YMO¯aZ]&eb\nLzHa^Yz£HJW^Yz`N¡W^]a^m`bNÞYzN0W^P]@`bi
4X]Oj¥
WZYdb]3_7\nNPOjW^Yz`N§¸]3¸HNbWWZ`0m¢YdNPYdm¢Yz£&]¦¡STN·W^PYzU¸Hgbr
WZn]
¸"nYMORHJaZ]3Nn`W@Oj`bNPUXWZaZHYdNP] ²iFg²U^`m¢]©`W^n]a
WZ]&aZm¢U)¸"YzLdLBPH]
Uom3HLdL.HLd\P]U|HJNP WZF\PU&rWZn]
O&`aZa^]&¥

`bNP DYzNne

Nn]Ha^]ah_7aZ`mÝÔJtn¦

~4#|F

lPl

}?B96nAD;w45Ab|Fb9

`<Uo]¡W^VHwW¢W^n]a^]YMU¢H·{»H\PUo¥
U^YzHN³]a^aZ`a
`NªWZn]HLd\P]`J_HJNP ®W^PHJW©¸h]QFNn`w¸
YdWZU)wHJaZYzHNPOj]	
@¦xn]&N¶G0HOçHg¶Ú:GÑHO&çHgbr8ÝßbßbtHbà
U^\neeb]UoWZUhW^`3aZ]

LzHbOj]

!iFg

?Ú

vJq

`bUoW^]a^Yz`a

,ÝL/

iV]¶]UoW^Yzm¢HJW^] Ú7\

W^`ªHm@\nL[WZY[¥
`_PW^P]

YMU¶HLdm¢`<UXWÑ\PNPORPHJNPe] 8¦

àEYzU"U^m3HJLzL5rnW^n]

aZ`in¥
÷#`w¸h]]arYd_©Y[W²YzU
YMUUom3HJLzLÈrb¸"nYMOR©m¢]HNPUEW^PHJW

cg> n`YzNne3Uo`VrDY[_Ú
HinYdLzYdWXg
LMHJaZe]brJW^P]&N©WZn]#NP]&¸
 D]UoYzaZ] >]j´µ]OW¦
xn]¶wHJaZYzHNPOj]²O&HJN
LzYMO&HwWZYdb]O&`NPUoWZHN<WRàáW^PHNnQDU.W^`|W^n]"÷#]UZUoYMHJN
`bi
4X]OjW^Yz]
_7\nNPOjW^Yz`N·HwW»W^n]3`
W^Yzm3HJL!wHJLz\n]brEÚ

à#YMU#OjLz`bU^]&a#W^`¶ÝJvJtn¦xnYMU#YMU]&IDHbOWZLdg¡W^P]


.3Ú 
o
9	.25AD;w4Kb9"H2I)AD;5K9l|JL34 |MH
Lz]U!HNP $

Nn]ebHJW^Yz]`Nn]U&rwWZn]UoWZHJNn¥
`bU^Y[WZYdb]]jInHJm
 nHaZ ¯¸Hg)W^`)]UoW^Yzm¢HJW^]EW^n]aZHJW^Yz``J_DWZn]
`<UoYdW^Yz]OjLMHUZU
YMU>W^`ª\PUo]²H³c]&WZH
W^n]·OjLMHUZU
a^`biPHJinYzLzY[WXgbr
¸"nYMORLd]H nUWZ`
W^n]»_7`bLdLz`w¸"YdNPe
]UXWZYdm3HJW^]r
cHU^] ²`bN·W^nYMU¯`biPUo]a^wHJW^Yz`N8r.`Nn]¤OHJN§]UXWZYdm3HwWZ]3W^P]
`bUoW^]a^Yz`a
aZ`iVHJinYzLdYdWXg¯\PU^YzNne»W^n])K!HJaZ£&]&N
¸"YzNP D`w¸ª]Uo¥
WZYdm3HwWZ]¯HUr

°«P]&N¹`iPU^]&aZFYdNPe

!bE*
E!bE

a^Yz`a¡`N

?
?³t
¸"n]a^]
YzU"H¢U^m¢HLdL8O&`NPUoWZHN<WWZ`3iV]¯ORP`bU^]&N8¦

j	#bà

Ú	#bà


öÝl/

6

.3Ú

C%

Ú

7Qm

ÚoÝtbà

aZ]

a^Yz`a

aZ]jWRHwW^Yz`N»YzN»W^]a^m3U`_

xn`<Uo]|W^Pa^]]|m¢]&W^n`D nU"aZ]Ó<\nYzaZ]|H¢Oj`bNPUoWZHJN<WW^`¢i]¯ORn`bU^]&Nár
¸"nYMOR
aZ]U^]&N<WRU©WZn]²Hm¢`\nN<W`J_aZ]&eb\nLzHa^Yz£HJW^Yz`N8¦Þ°²]
 D]OjYM D] ²WZ`0W^P]¤Oj`bNPUoYM D]aW^n]>LzHbUXW@`Nn]©i]OHJ\PU^]PHUH
m¢`aZ] DYza^]OWáYzN<W^]&a
a^`biPHJinYzLzY[WXgb¦
ÒLMU^`PrwYdWBm¢Yze<WBi]YdN<WZ]&aZ]UoW^YzNneWZ`|ORn`F`<Uo]"HbU.W^`|m
YzNnYzm¢Yd£]
W^P]¤çò« DYz]&aZe]NPOj]¢i]jWX¸]&]N¶WZn]¤ D]NPU^Y[WXg¶]UoW^Yzm¢HJW^] ¶`bN
W^P]#\nNnLMHJi]&Lz] 
?t
D¦
Yz£&] P­" D]&NPU^YdWXg)`bN)WZn]LMHJi]&Lz] 
a^]Uo]NbWZ] ®YdN³ºPe\Pa^]¡v
xn]aZ]U^\nL[WRU
`J_WZn]]jI
U^n`w¸WZPHwW!WZnYzUaZ]&eb\nLMHJaZYd£HwW^Yz`N@YzU]&IFW^aZ]&m¢]&Lzg¯\PU^]j_7\nLÈr]U
]j¥
]&a^_7`aZm¢] 
OjYMHJLzLzg¢_7`aW^n]
`<`ba^Lzg¸"Y[WZn`\DW¶a^]e\nLMHJaZYd£HwWZYd`bNÞÚ5Uo]]®Uo]OWZYd`bNópbà¦xP]
9:7<;>=+
tªi]j¥
PHb]U#HLzU^`¤m@\POR0i]jW^W^]&a»¸"YdW^¶a^]e\nLMHJaZYd£HwWZYd`bN8¦)æ#`JW^]@W^P]
Lz`FOHJLhm¢HJIDYdm@\nm
Lz`JW`_"ºPe\naZ]¤vP¦0xnYzUYzU
Ó<\nYdW^]¯U^\na

ÚáàhHJNP ¢WZn]¤¬^a^]e\nLMHJa^¥
Ú áà

a^YMUoYzNne¢HJNP ¡aZ]Ó<\nYza^]Uh_7\naoWZn]&a"YzNF]UXWZYde<HwW^Yz`Ná¦

«m¢]jWZn`D ö D]UZOjaZYziV] 

`bYdN<WZUr6

UXWZaZHJW^]eg¢¸"nYMOR

YzNöUo]OWZYd`bNôV¦

YzN§WZn]¤aZYdeb<W

]a^Yzm¢]&N<WZU



oC*

DC%

`YzN<WZUr

.

0^Á#FÂX¿

aZ`wFYz D] ØHJN

]&a
`bUoW^]a^Yz`a

a^`biPHJinYzLzY[WZYd]U¢]UoW^Yzm¢HJW^]U3`NWZn]

HJNPHLdgDU^YzU>`J_¯WZn]·YdN P\n]&NVOj]²`J_
xnYMU
]ao¥
aZ]&LzYzHinLd]
HJa^W^YMOj\nLMHJarYdWU^n`w¸] 
_7`aZm3HJNPO&]`J_áHN¤HOjW^Yz]Lz]Ha^NP]&a¦áSTN
W^VHwWa^]e\nLMHJaZYd£HwWZYd`bN|U^]&]m¢UáW^`)iV]Hb]&aZg)\VUo]&_7\nLFYdNneba^] DYz]&N<W
YzN>WZn`bU^]»]UoW^Yzm3HwW^Yz`NVU&¦
]ao¥
ÜBYdeb\naZ]»sU^n`w¸UW^PHJW\PU^YzNne¯WZnYzUaZ]&eb\nLzHa^Yz£HJW^Yz`N8rW^n]
_7`aZm3HJNPO&]UHbORnYd]] ÑHJaZ]¢Nn`JW_:Ha»_7a^`bmW^P]3iV]UXWHbORnYd]<¥
HJiPLd]¯`bNn]U#YdNWZn]@OHU^]¯`J_WZn]¯WZ`wg
aZ`iPLd]m¡rHJNP HLzU^`3_7`ba
W^P]
xn]|Oj`NVOjLz\PUoYz`NVUE DaRH¸"N
_7a^`bmÿWZn])HNPHJLzgDUoYMU!YzN3W^PYzU
U^n`\nLM ³iV]\PU^]j_7\PL"W^`Hb nH

]a
W¢WZnYzU¤HOWZYdb]Ld]HJaZNnYdNPe²UoW^aRHwW^¥

 PHwWZHiPHU^]»Hw_ÊW^]apu¢Ó<\n]&aZYz]U¦

54l
l
l
l
l
l
l
l
l
l
H
l
l
l
=


L
l
l
l
l

l
l
l
l
l
l
l


T




U
l



k
\
l




Ý

à
u

T

l
l





l
l
l

à
u

M

¦


L
$
E
l
l
M
l
l
l
!

u
¦
l
l
&
1

n
6
n

#
à

l
l
l
l
l
A
n
l
6
!
n
l
l
l

l
l
7

$

7
l
l

=
¿
¾
¾
l
H
l
l
l
l
l
l
l
l
 
k
K
k
l
H
l
l
0.25

0.2

0.15

r
o
r
r
e

 
t
s
e
T

0.1

 0  

Error reduction
Semi−supervised

   
	 

Amount of regularization e

 

 

 1  

 10 

r
o
r
r
e

 
t
s
e
T

0.22

0.21

0.2

0.19

0.18

0.17

0.16

0.15

0.14

0.13

0.12

 0  

  

ÜBYdeb\naZ]vnï×I
_7\nNPOjW^Yz`N`J_

]&aZYzm
]N<WZU`bNW^P]@ORn]ORQ]&a#iV`<HJaR  nHwWRHU^]jW
Ú:Ld]&_ÊWRà)HJNP 0`N9 

\PU^] >WZ`
]UXWZYdm3HJW^] >WZn]a^]e\nLMHJaZYz£&] 

`<UXWZ]&aZYd`ba

a^`biPHJiPYdLzY[WXg0ÚoÝtbà¦

Error reduction
Semi−supervised

 	 

Amount of regularization e

 

 

 1  

 10 

Ú:a^Yze<Wà¦)xP]¯W^]UXW|]&aZa^`baYMU

Lz`JW^W^] 0HU)H

Error reduction
Semi−supervised
Oracle
Random

r
o
r
r
e

 
t
s
e
T

0.5

0.4

0.3

0.2

0.1

0

Error reduction
Semi−supervised
Oracle
Random

0.55

0.5

0.45

0.4

0.35

0.3

0.25

0.2

0.15

r
o
r
r
e
 
t
s
e
T

5

10

Labeled set size

15

20

5

10

15

20
Labeled set size

25

30

ÜBYdeb\naZ]>sFï@K]ao_7`ba^m3HNPOj]U|HbORnYz]&] ²`N²W^n]©W^`wg
7<;>="
HORPYd]]ïYdW]UoW^Yzm3HwW^]UW^n]»WZ]UoW]&aZa^`ba|ÚoÝà\PU^YzNne
W^n]

>\PU^]@H¤a^]e\nLMHJaZYd£HwWZYd`bN

HJaRHJm¢]jWZ]&a

a^`binLz]&m
ÆÈÎ

;,Ýu

]&ebg0WZ`0m¢`aZ]©Uo`
]OjW^`baG0HORnYzNn]U`a#{»HJ\VU^U^YzHN>KEa^`DOj]U^U^]U¦

nYMUXWZYzOHwW^] ·OjLMHUZUoYdºP]&aRUU^\PORHU

lnl

`a^W

I»;

Ú:Ld]&_ÊWRàHJNP 
!#
Ú:U^]&]@HLzU^`©ºVe\naZ]vbàj¦|xP]
LzHiV]LzU`J_áWZn]\nNnLMHJi]&Lz] U^]jW¦

Ú7aZYze<WRàj¦c`W^

&)3#1

$
@UXWZaZHJW^]eg¡YzU#W^n]
i]UoW|`bNn]O&HN

3¤HJNV 

À#Â



\DW^YzNne²W^P]0Uo]Oj`NV ® D]a^YzwHwW^Yz]U
`J_

xn]»_7\nNVOW^Yz`NVHJLÚXÝubàYMU"H¢Oj`NFb]jI3_7\nNPOjW^Yz`N`_
STNP D]] rOj`bm
]HbUog»WZ`|ORP]ORQ»W^VHwW

N#rhYdW3YzU
NÑYMU!H|Oj`NVO&H]E_7\nNPOjW^Yz`N8¦fh`NPO&]&aZNnYzNne
r.¸"nYMOR¶O&HN
i]»U^n`w¸"N¤W^`¢iV]O&`NF]&I3W^PHNnQDUEWZ`
W^n]|_7`LzLz`w¸"YdNne
Lz]&m¢m3H





ÞráHLdLWZn]
W^]&aZm3UHJaZ]@`_EWZn]
_7`aZm
G
ÏVÉË! Ï
{®A
9l{
ÍwÏµì#ªÇMë>Í
èPé
ëÇÊÆÈÇÊÉË
ÏVÉË! '&
#¶ÇMë

ÄRé
ÍwÉwË

ÇMë©Í

ÄRé

ÄRé

ÏµËÕÐbÍJÆ5ÇÊÉwË

ÆÈÇ

ÆÈÇ

!%$

Ë&Ï

)(

xn]¯÷#]UZUoYMHJN¡`J_

YMU

*5u

*5u

*5u

àjÚ

à,+[
/"Ú:Y[W¤UZHwWZYzUoºP]U/]NPUo]N
ZÚXÝHG
u&Ý1:

àq

¸"nYMORYzU"H¢U^\nm
lPl
°²]>WZn]&NH
_7\nNPOjW^Yz`N
]Ó<\PHLdYdWXgnàHJNP >W^P]¯Oj`NVO&H]#_7\nNPOjW^Yz`N

`bU^Y[WZYdb]¯ D]jºPNPY[WZ]m¢HJW^aZYzO&]U.-@¦
aZ]&FYd`b\PU
Ld]m¢m¢H¶¸"YdW^ªW^n]O&`NF]&I
U¢YdND¥

`_
Ldg·WZn]

rYdN

WZYdm¢Yz£&YzNne§`N

STNPUoW^]H ª`J_»`
W^Yzm
Yz£&]¢`bN
Lz]H PUBW^`¯HJN¢\nNVOj`NVUXWZaZHYdNn] `
YMU]HU^Yz]&aW^`3U^`Lz]»NF\nm¢]&aZYzOHJLzLdgb¦
æ`W^]»WZPHwWiFg¤ D`bYdNPe@WZnYMUORPHJNPe]»`J_BHa^YMHJiPLd]brFW^n]`bi
4X]Oj¥
W^Yz]©_7\nNPOWZYd`bN§YzUNn`JW
Oj`NFb]jI¶HN<gFm¢`aZ]¦¡÷`w¸]&b]&aráUoYzNPO&]

aRHOjW^YMOj]¸]
à
Ú5Uo]]¢HLzU^`·ÚXÝÝà¦
xnYzU
a^`binLd]mó¸"nYMOR

(10
vDÚXÝfG
W^Yzm¢Yd£HwWZYd`bN

/6
ÿLz`e

Õà¦

55l
k
K
k
l
l
l
l
 
k
K
k
7

9
7
l
M


ð
Ë
l
k
\
 



¾
(
,
¦
l

m

m


M

m


(
é
Ï
Å

ð
Ï
Ä
é
Ï
é
Ï
"
!
Ï
Ä

ð
Ï
Ä
é
Ï
é
Ï
"
Æ
ü
(
u
v
(
u
v
#
(
u
#

t
(
#
(
G
(
u
#
u
#
?
t
#

Ú
#
*
(
G
(
*
#
#
*
(
G
(
*
#
l
l
(
Ú
(
à

)


)

)
#
Ú
(
l
8
!
l
`
l






l
l
x.`NneVr

Î^ÍwÌ

lPl
éÄ

ìwÉwÍwÏ
lnl

a^`IDYzm3HwW^Yz`Ná¦"Ã
ËjëZëÇÊÏFÐ
ñëÆÕË&íë

\nNPePrµç¢¦Vç¢¦zrVã,æYzg`beYÈrVK¦.ÚoÝßbßbåàj¦"Ò#OWZYdb]¯Lz]HJaZNnYzNne3_7`ba
_7\nNPOWZYd`bNÑH
Ëjë¯ÇÊÏ*Ë
¦<åJßpFvbuubàj¦Dxn]GSXx
í¢ÍJÆ5Ç
Ï+Î
KaZ]UZU&¦
¦zrbã
HOWZYdb]©Lz]HJaZNnYzNne¸"YdW^®H
W^Yz`N8¦,Déwð
û0Í
ô<åDvv<à¦
NnYdQµr
°«YdLz]&g¡ã

`a^W]OjW^`ba!m¢HbORnYzNn]
LzYzOHwW^Yz`NVUW^`0W^]jIFW¢OjLMHUZUoYdºVO&HJ¥
lnl
ÄZüÚ
ÇÊÏË*.ËRÍwÎÏPÇÊÏFÐ
/`bnN

ç»`bLdLz]&arÙ@¦PÚ5tuuPÝà¦
ÎÏÍJÌ

ÍwÌËRÍwÎÏVÇÊÏ<Ð

¦BÚXÝßbßq<à¦)ù

ÆTÍwÆÈÇMëRÆÈÇ

Ëë&ËRÍwÎ

lnl
ÄZü

`bNPU&¦

µü

lnl

Îñ

<F\8r.-¦zrPò.Hw´µ]&a^WXgr

/P¦zrDã{|PHnaZHm3HJNnYÈr<B¦Ú5tJubup<à¦fh`bm
¥

inYdNPYdNne>HOWZYdb]Ld]HJaZNnYzNne©HJNP U^]&m¢Yd¥ÕU^\
\PUoYzNnee<HJ\PUZUoYMHJNºP]&LM nUHNP 
PHJaZm¢`NnYMOh_7\nNPOjW^Yz`NPU¦
µü
Î0	wë
ËjÌzËZì©Æ
Ë&ÌdËRì3%
ÍwÆTÍ3ÇÊÏÑûÑÍ

]&aZ<YMU^] ¡Ld]HJaZNnYzNne
û/
é
ÏVÆ5ÇÊÏ
ÏPÌzÍ
ÄRü
ÇÊÏË4.ËRÍwÎÏVÇÊÏ<Ð¡ÍwÏì %@ÍJÆÕÍ3ûÇÊÏPÇÊÏ<Ð

üPéZè®é

í.Í

é21

ðDð

W^PYzU#YzU)H¢m
`bNn`JWZ`NnYMO»WZaZHNPUX_7`ba^m3HJW^Yz`N8rDYdW)YMU"]HbUog¤W^`¤U^n`w¸
W^VHwWÑWZn]_7\PNPOWZYd`bNóYzU²Ó<\PHU^YMOj`NFb]jIÿÚ5ch`wgD öã
HJNV D]&ND¥
i]&aZen]br!tuubpbàrBHJNP ®O&HJN·WZF\PU¯i]¤m¢YzNnYdm¢Yz£&] §]j¨©OjYz]&N<WZLdg
ÚÊWZn]&aZ]YMUNn`¢Ld`DO&HL8m¢YdNPYdm3Hbàj¦

n

« 





8b


c`wgD r



4
á

¦zrhã

HNP D]&NFi]&aZen]brò¦ÚÈtJuubpbàj¦é

í@ÇdõÍwÆÈÇ
]LdLz]r
ÎÇÊÏ

¦fHJm@inaZYz Deb]
¦Ú5tuubpbà¦EùVðèbèné
Æ5ÇÊÉwËÆ

 #NnYz]&aRU^Y[WXg¤KEa^]U^U¦
ÄZü
ÎÇ

fhPH
ÎÆÉË
Æ5Ç
ÏPÇÊÏFÐ3ÍwÏµì
Ù#`DOWZ`aRHJL8 DYMUZUo]aoWRHwW^Yz`NárFòáSXKEvP¦

Î»í¢Í

ÍbìÍ

ÌzË

ÏVÉË! 

éRè

ÆÈÇ

ÇÊÏËjë
Î
	JÏ

ðPÄ&Å
Ïì
ÌdËRì&Ð<Ë

fh`PN8r<Ù@¦bÒ¦drn{|PHnaRHJm3HJNnYÈrl<¦dr<ã

Ò#OWZYdb]Ld]HJaZNnYzNne·¸"Y[WZØUXWRHwW^YMUoW^YMO&HJL#m
`D D]LzU¦¹Ã
ÇÊÏË
ñëÆÕË&í@ë
sFÝtbà¦!xn]GSXxKaZ]UZU&¦
¦)ÚXÝßFsJtbà¦µü

Ün] D`aZ`wµr

ÆÈÇÊí¢ÍJÌ)Ë) 

/b`aR nHN8rbG§¦bS¦VÚoÝßß<åàj¦
ìwÉwÍwÏ
Ëë
lnl
¦<swu<å

ËjÎÇÊí3Ë&ÏPÆ5ë

ËjëRëÇÊÏ<Ð

Îí3ÍwÆÈÇ

ÏÎ

Î^ÍJÌ

éÄ

Îñ

éRè

æ]&¸`aZQµï!Ò#O&Hb D]&m¢YMO»KaZ]UZU&¦

ÜnaZ]&\PNP r
¦dr

PHJm¢Yzar×¦zrhã

]\nNnePr÷¯¦
]&Lz]OjW^Yz]¯UZHJm
ûÑÍ

ÚXÝßbß<sà¦
m
YdWoWZ]&]¯HLdeb`aZY[WZnm¦

xYMU^<iFgbrhæ¯¦
¦zr
LzYdNPe
\VUoYzNne¢W^P]¯Ób\P]&aZg©iFg>Oj`bm
¥
rJráÝppÝvbqn¦
ÄZü
ÇÊÏËáËRÍJÎÏPÇÊÏ<Ð
ò8]¸"YzUrEÙ@¦drã{»HLd]brE°ö¦ÚXÝßßô<à¦x.aRHJYzNnYdNPe0W^]&IFW3O&LzHbU^U^Yd¥

ºP]&aRU¤iFg«\nNVOj]&a^WZHYdN<WXgU^Hm
ÏPÆTË&ÎÏÍwÆÈÇ

ÍJÏì&%@Ë&ÉË&Ì

ÍJÌ
ÄRü
¦Pp'µÝtàj¦

ü¤Ã
Æ5ÎÇ:Ë&ÉÍJÌ

ÏVÏ
Ëë&ËRÍwÎ
lnl

LdYzNneV¦
Ã 
í3ËjÏVÆ@ÇÊÏ

ÏµÍwÌ
éRè

éÄ
Î
"!

ËRËRìwÇÊÏFÐwë
$#
é
Îí¢ÍJÆ5Ç

G0HbO&çHgr<Ù¦µÚXÝßß<tJHbàj¦xP]#]&FYM D]&NVOj]"_7aRHJm¢]&¸`aZQ@H
ÆÕÍJÆ5Ç

W^`ÑO&LzHbU^U^Y[ºO&HwWZYd`bN¶NP]jWX¸`aZQFU¦
sJtJunsJpvn¦

Î^ÍwÌ

Ë

é

èµð

ËjÎ^Ë&Ï

lnl

LzYd] 
r(nr

G0HbO&çHgr¡Ù¦ÚoÝßß<twiVàj¦
r(PrVåJßbu'FvbuJôV¦

_7\nNPOWZYd`bNPU|_7`a»HOjW^Yz]¢ nHwWRH¤U^]&Lz]OjW^Yz`N8¦
ÆÕÍJÆ5Ç

STND_7`aZm3HwWZYd`bND¥ÈiVHU^] ,`i4X]OWZYdb]
èðDÅ

ÎZÍwÌ

@Ë

é

ÏµÍwÌ

Î
ÄRü

ÏPÆTË&ÎÏÍwÆÈÇ

â"`wgbrFæ¦drVãG0OfHJLzLd\nmrnÒ¦8Ú5tJubunÝà¦xá`w¸HJaR 3`

W^Yzm¢HL8HOj¥
LdYzNne¶]UoW^Yzm¢HJW^Yz`N`_]&aZa^`ba
!é
Ë&Î

W^Yz]¤Lz]Ha^NPYdNne0W^naZ`\nebU^Hm
a^] D\POWZYd`bN8¦
éÄ
ËRËRìwÇÊÏFÐwë
ÇÊÏË.ËRÍwÎÏPÇÊÏFÐ
ËjÏ
ÏÑûÑÍ
fh`nN8rÙ¦Ú5tuububà¦ò8]U^U#YzU#m¢`aZ]ïhÒ)OWZYdb]
ORn`bnN8rµ{
¦drµã
lnl
`a^Wb]OjW^`am3HORPYdNn]U&¦
Ld]HJaZNnYdNPe@¸"YdW^U^\
éÄ
Î
ËRËRìwÇÊÏ<ÐJë
é
ÄRü
ÏPÆTËjÎÏµÍwÆÈÇ
ÇÊÏË)áËRÍJÎÏ
ÏµÍwÌ
Ï¢ûÑÍ
lnl
HJN¯ÜnaRHJNVOjYMU^O&`PrfÒïG0`aZebHJN»çHJ\n_Ê¥
¦qpbß'Fqôbv<à¦
ÇÊÏ<Ð
m¢HNnN8¦
\nebYdg<HJm3HnrG§¦zrã
Ld]HJaZNnYdNPe_7`ba"`
ÆÕÍJÆ5Ç

e<H¸HPr&÷¯¦<Ú5tJubuu<à¦wSTNPO&a^]m
]N<WZHJLbHOWZYdb]
èðDÅ

WZYdm3HJLáe]&NP]&aRHJLzYd£HwW^Yz`Ná¦

rtßubß'DtßJô<un¦

Ë&Î^Ë&Ï

Î^ÍJÌ

Ë

é



56 
¾
¿
c




¾

¾
k
 
Å
é
Ï
l
Ö
Ä
Æ
é

é
Ï
è
Ä
Ç
è
$
è
ð
è
é
é
¦
Ä
ð

Ï

é
é
ù
Ú
 
Ë
é
é

è
¦
k
k
k
k
l
l
é

Æ
ü
Ë
Æ
ð

é
û
ù
Ï

Ä
Ë
é
Ï
#

Ï

é
é
Ï
#
Ë
Å
Ú
ð
í
é
Ï
ð
í
é
Ï
l
l
é

Æ
ü
Ë

é
Ï

Å
Ä
Ë
é
¦
k
é

Æ
ü

é
Ï

Ä
Ë
é
Å
Ú
k
k
Ö
l
ð
í
é
Ï
r

k
Ä
ð

Ï

é
Î
Å
é
ù
Ú
k
k
\
é

#
¦
 
H
l
 
Ä
Ë
é
¦
k
l



é
Ï
Ë
í

Î
é
ê
Å
ê
¦
Semi-Supervised Classiﬂcation by Low Density Separation

Olivier Chapelle, Alexander Zien

Max Planck Institute for Biological Cybernetics

72076 T˜ubingen, Germany

Abstract

We believe that the cluster assumption is key
to successful semi-supervised learning. Based
on this, we propose three semi-supervised al-
gorithms: 1. deriving graph-based distances
that emphazise low density regions between
clusters,
followed by training a standard
SVM; 2. optimizing the Transductive SVM
objective function, which places the decision
boundary in low density regions, by gradient
descent; 3. combining the ﬂrst two to make
maximum use of the cluster assumption. We
compare with state of the art algorithms and
demonstrate superior accuracy for the latter
two methods.

1

INTRODUCTION

The goal of semi-supervised classiﬂcation is to use un-
labeled data to improve the generalization. The cluster
assumption states that the decision boundary should
not cross high density regions, but instead lie in low
density regions. We believe that virtually all successful
semi-supervised algorithms utilize the cluster assump-
tion, though most of the time indirectly.

For instance, manifold learning algorithms (e.g., [1])
construct decision functions that vary little along the
manifolds occupied by the data. Often, diﬁerent
classes form separate manifolds. Then, manifold learn-
ing indirectly implements the cluster assumption by
not cutting the manifolds.

The Transductive SVM [20] implements the cluster as-
sumption more directly by trying to ﬂnd a hyperplane
which is far away from the unlabeled points. In our
opinion, the rationale for maximizing the margin is
very diﬁerent for the labeled and unlabeled points:

† For the labeled points, it implements regulariza-
Intuitively, the large margin property

tion [20].

makes the classiﬂcation robust with respect to
perturbations of the data points [6].

† For the unlabeled points, the margin maximiza-
tion implements the cluster assumption. It is not
directly related to regularization (in this respect,
we have a diﬁerent view than Vapnik [20]). Con-
sider for instance an example where the cluster
assumption does not hold: a uniform distribution
of input points. Then the unlabeled points con-
vey almost no information, and maximizing the
margin on those points is useless (and can even
be harmful).

TSVM might seem to be the perfect semi-supervised
algorithm, since it combines the powerful regulariza-
tion of SVMs with a direct implementation of the clus-
ter assumption. However, its main drawback is that
the objective function is non-convex and thus di–-
cult to minimize. Consequently, optimization heuris-
tics like SVMlight [12] sometimes give bad results and
are often criticized. The main points of this paper are:

† The objective function of TSVM is appropriate,
but diﬁerent ways of optimizing it can lead to
very diﬁerent results. Thus, it is more accurate
to criticize a given implementation of the TSVM
rather than the objective function itself.

† The search for a low density decision boundary is
di–cult. The task of the TSVM algorithm can be
eased by changing the data representation.

To substantiate our claims, we develop and assess cor-
responding algorithms. Firstly, we propose a graph-
based semi-supervised learning method exploiting the
cluster assumption. Secondly, it is shown that a gra-
dient descent on the primal formulation of the TSVM
objective function performs signiﬂcantly better then
the optimization strategy pursued in SVMlight [12].
Finally, by combining these two ideas in one algorithm,
we are able to achieve clearly superior generalization
accuracy.

572 ALGORITHMS

Let the given data consist of n labeled data points
xi; 1 • i • n, and m unlabeled data points xi; n + 1 •
i • n + m. For simplicity, we assume that the labels
yi; 1 • i • n; are binary, i.e. yi = §1; for multi-class
problems, we use the one-against-rest scheme that is
common for SVMs (e.g., [17]).

In the following sections, we describe two diﬁerent
ways to enforce the cluster assumption in SVM classi-
ﬂcation and how they can be implemented.

2.1 GRAPH-BASED SIMILARITIES

Let the graph G = (V; E) be derived from the data
such that the nodes are the data points, V = fxig.
If sparsity is desired, edges are placed between nodes
that are nearest neighbors (NN), either thresholding
the degree (k-NN)1 or the distance (†-NN). Many semi-
supervised learning methods operate on nearest neigh-
bor graphs, see e.g. [1, 14, 18, 23, 22]. Usually they do
not require the data points themselves, but only their
pairwise distances along the edges. In the following we
assume that the edges (i; j) 2 E are weighted by Eu-
clidean distances d(i; j) := jjxi ¡ xjjj2 (missing edges
correspond to d(i; j) = 1), although other distances
are possible as well.

Many graph-based semi-supervised algorithms work
by enforcing smoothness of the solution with respect
to the graph, i.e. that the output function varies lit-
tle between connected nodes. Here we use the graph
to derive pairwise similarities between points, thereby
\squeezing" the distances in high density regions while
leaving them in low density regions. This idea has been
proposed before, e.g. in [5, 21] and [4, section 3]. It
has been implemented and used in Isomap [19], cluster
kernels [7], and connectivity clustering [10].

2.1.1 Motivation

According to the cluster assumption, the decision
boundary should preferably not cut clusters. A way
to enforce this for similarity-based classiﬂers is to as-
sign low similarities to pairs of points that lie in diﬁer-
ent clusters. To do so, we construct a Parzen window
density estimate with a Gaussian kernel of width 1p
(cid:190),
2

^p(x0) =

1
p
…(cid:190)

n+m

X

i=1

exp(cid:181)¡

jjx0 ¡ xijj2

(cid:190)2

¶ :

in diﬁerent clusters, every such curve has to traverse a
density valley. We can thus deﬂne the similarity of two
points by maximizing over all continuous connecting
curves the minimum density along the connection, but
this is hard to compute.

Two observations, illustrated in Figure 1, allow to ap-
proximate the above similarity with paths on a graph:
(a) An optimal connecting curve can be well approxi-
mated by conjoining short line segments that directly
connect points. (b) The minimum density is assumed
at the middle of a line segment, and dominated by the
closest points.

y
t
i
s
n
e
d

(a)

(b)

distance along path

Figure 1: Optimal connecting curves are well approx-
imated by paths of short distance edges on a graph.

2.1.2 A density-sensitive distance measure

Formally, we deﬂne p 2 V l to be a path of length
l =: jpj on a graph G = (V; E), if (pk; pk+1) 2 E for
1 • k < jpj. A path p is said to connect the nodes p1
and pjpj; let Pi;j denote the set of all paths connecting
xi and xj. We obtain

max
p2Pi;j

min
k<jpj

^p(cid:181) 1
2

(xpk + xpk+1)¶

… c ¢ exp"¡

· k(xi; xj):

1

2(cid:190)2 (cid:181) min

p2Pi;j

d(pk; pk+1)¶2# (1)

max
k<jpj

This k, called \connectivity kernel", is positive deﬂnite
and was suggested for clustering previously [10].

The kernel values do not depend on the length of the
paths, which may lead to the connection of otherwise
separated clusters by single outliers (\bridge" points).
To avoid this problem, we \soften" the max in Equa-
tion (1) by replacing it with

smax‰(p) :=

1
‰

ln

0
@1 +

jpj¡1

X

k=1

‡e‰d(pk;pk+1) ¡ 1·

1
A :

(2)

If two points are in the same cluster, it means that
there exists a continuous connecting curve that only
goes through regions of high density; if two points are

1made symmetric by including (j; i) in E if (i; j) 2 E

Equation (1) is recovered by taking ‰ ! 1. If ‰ ! 0,
smax‰(p) becomes simply the sum of original distances
along the path p 2 Pi;j. Due to the triangular inequal-
ity, this is never less than d(i; j), so that in a full graph
with Euclidean distances the minimum path distance

58becomes jjxi ¡ xjjj2. Thus, the standard Gaussian
RBF kernel is recovered, and no use is made of the un-
labeled data. However, for a sparse graph computing
the minimum path distance when ‰ ! 0 is equivalent
to Isomap [19].

The proposed method can be summarized as follows:

1. Build nearest neighbor graph G from all (labeled

and unlabeled) data.

2. Compute the n £ (n + m) distance matrix D‰ of

minimal ‰-path distances according to

D‰

i;j =

1
‰2 ln

0
1 + min
@
p2Pi;j

jpj¡1

X

k=1

‡e‰d(pk;pk+1) ¡ 1·

2

1
A

from all labeled points to all points.

3. Perform a non-linear transformation on D‰ to get

kernel K,

Ki;j = expˆ¡

!

D‰
i;j
2(cid:190)2

The linear case corresponds to (cid:190) = 1 and K =
¡ 1
2 H nD‰H n+m, with H p being the p £ p center-
ing matrix (as in Multidimensional Scaling [8]):
H p

ij = 1i=j ¡ 1i•n=n.

4. Train an SVM with K and predict.

2.1.3 Comments

A few comments can be made on these steps.

1- The use of a sparse graph G is merely a way to save
computation time. This is in contrast to some other
graph-based methods, that require sparseness for de-
tecting the manifold structure (e.g. Isomap). In our
method, the sparse graph is always seen as an approx-
imation to the full graph. However, the accuracy of
this approximation depends on the value of the soft-
ening parameter ‰: for ‰ ! 0, the direct connection
is always shortest, so that every deletion of an edge
can cause the corresponding distance to increase. For
‰ ! 1, shortest paths almost never contain any long
edge, so that long edges can safely be deleted.

2- For large values of ‰, the distances between points
in the same cluster are decreased. In contrast, the dis-
tances between points from diﬁerent clusters are still
dominated by the gaps between the clusters and, as a
result, those gaps become more pronounced.

Instead of Equation (2), it is possible to use other inter-
polations between the max and the mean such as the

Minkowski metric, ‡Pjpj¡1

k=1 d(pk; pk+1)‰+1·1=(‰+1)

.

3- K is in general not positive deﬂnite (p.d.), except
for ‰ = 0 (standard RBF) and ‰ = 1 (then D‰ is an
ultrametric and thus negative deﬂnite [10], yielding a
p.d. kernel [17]). In practice, negative eigenvalues can
be observed, but they are few and small in absolute
value, as documented in Table 1. In our experiments,
the SVM training still converges quickly. Moreover,
recent papers have argued in favor of the use of non-
positive deﬂnite kernels for learning [11, 16].

‰
”

0
0

0.5
0.19

1

2

4

2.96

4.66

1.89

8 1
0

0.02

Table 1: Empirically found weight on the Coil20
the negative eigenvalues as percent-
dataset of
age of
:=
the weight of all
100Pi max(0; ¡‚i)=Pi j‚ij.

eigenvalues,

”

2.2 MARGIN MAXIMIZATION

The Transductive Support Vector Machine (TSVM),
ﬂrst introduced in [20] and implemented by [3, 12],
aims at minimizing the following functional,

min

1
2

w2 + C

n

X

i=1

»i + C ⁄

n+m

X

i=n+1

»i;

under the constraints:

yi

(w ¢ xi + b) ‚ 1 ¡ »i
jw ¢ xi + bj ‚ 1 ¡ »i

1 • i • n
n + 1 • i • n + m

:

This can be rewritten without constraint as the mini-
mization of

1
2

w2 + C

n

X

i=1

L(yi(w ¢ xi + b)) + C ⁄

n+m

X

i=n+1

L(jw ¢ xi + bj);

(3)

with L(t) = max(0; 1 ¡ t).

Unfortunately, the last term makes this problem non-
convex and di–cult to solve [3, 12]. The implemen-
tation of TSVM that we propose in this paper is to
perform a standard gradient descent on (3). However,
since this latter is not diﬁerentiable, we replace it by

1
2

w2 + C

n

X

i=1

L2(yi(w ¢ xi + b))+ C ⁄

n+m

X

i=n+1

L⁄(w ¢ xi + b);

(4)

with L⁄(t) = exp(¡3t2) (c.f. Figure 2).

To enforce that all unlabeled data are not put in the
same class, we add the additional constraint,

1
m

n+m

X

i=n+1

w ¢ xi + b =

1
n

n

X

i=1

yi:

(5)

59This is in analogy to the treatment of the min-cut
problem in spectral clustering, which is usually re-
placed by the normalized cut to enforce balanced so-
lutions [13].

Finally, note that unlike traditional SVM learning al-
gorithms, which solve the problem in the dual, we di-
rectly solve the problem in the primal. If we want to
use a non-linear kernel, it is possible to compute the
coordinates of each point in the kernel PCA basis [17].
More directly, one can compute the Cholesky decom-
position of the Gram matrix, K = ~X ~X > and minimize
(4) with xi · ( ~Xi;1 : : : ~Xi;n+m).

s
s
o
L

1

0.8

0.6

0.4

0.2

0
−2

Standard TSVM
Gaussian approximation

−1

0

Signed output

1

2

Figure 2: TSVM cost functions for unlabeled data.

We decided to initially set C ⁄ to a small value and
increase it exponentionally to C; thereby following
SVMlight. Note that the choice of setting the ﬂnal
value of C ⁄ to C is somewhat arbitrary.
Ideally, it
would be preferable to consider this value as a free
parameter of the algorithm.

2.3

IMPLEMENTATION

From the methods discussed above, we derive three
algorithms:

1. graph, training an SVM on a graph-distance de-

rived kernel;

2. rTSVM, training a TSVM by gradient descent;

3. LDS (Low Density Separation), combining both of

the previous algorithms.

For SVM, we use the Spider2 machine learning package
for matlab. For rTSVM, a conjugate gradient descent
method was used.3

The distance computation for graph can be carried out
using the shortest path algorithm by Dijkstra [9]. For
LDS, the full (n + m) £ (n + m) matrix D‰ of pairwise
distances has to be computed.

104

103

102

101

100

i

s
m
h
c
a
o
J
 
M
V
S
T

105

104

103

102

i

s
m
h
c
a
o
J
 
M
V
S
T

100

102
TSVM Grad

104

101

101

102

103

TSVM Grad

104

105

Figure 3: Each point represents the values of the objec-
tive function reached by the TSVM and rTSVM for some
value of C, (cid:190). Points above the diagonal mean that
rTSVM found a better local minimum. Left: Coil20
dataset, right: g10n (both described below).

Since the derived kernel is (in general) not positive def-
inite, we can apply Multidimensional Scaling (MDS)
[8] to ﬂnd a Euclidean embedding of D‰ before apply-
ing rTSVM. The embedding found by the classical MDS
are the eigenvectors corresponding to the positive
eigenvalues of ¡HD‰H, where Hij = –ij ¡ 1=(n + m).
For computational reasons, we decided to take only
the ﬂrst p eigenvectors such that

p

X

i=1

‚i ‚ (1 ¡ –)X max(0; ‚i)

and ‚p • –‚1; (6)

with decreasing eigenvalues ‚1 ‚ : : : ‚ ‚n+m.

We compare our algorithms to one state of the art su-
pervised method, SVM, and to two state of the art semi-
supervised methods, the TSVM optimization scheme
as implemented in SVMlight [12] and a graph-based
manifold learning, which is closely related to those in
[1, 22, 23]. More precisely, we estimate the labels of
the unlabeled points by minimizing the functional

n

X

i=1

(fi ¡ yi)2 +

‚

Pi;j wij

n+m

X

i;j=1

(fi ¡ fj)2wij ;

(7)

where wij = exp(¡jjxi ¡ xjjj2=2(cid:190)2) if xi is among
the k nearest neighbors of xj (or vice-versa), and 0
otherwise. This methods depends on the sparsity of
the graph.

Figure 3 compares how both implementations of
TSVM are able to minimize the cost function (3). Note
that our proposed implementation does not minimize
(3), but the diﬁerentiable approximation (4) and for
this reason it has a disadvantage in the comparison
shown in Figure 3. Nevertheless, on average it pro-
duces better values of the objective function, which
translate, as we will see later, into better test errors.

2available at http://www.kyb.tuebingen.mpg.de/bs/

2.3.1 Computational Complexity

people/spider

3available at http://www.kyb.tuebingen.mpg.de/bs/

people/carl/code/minimize

We implement the search for the next-closest un-
explored node in Dijkstra’s algorithm with a prior-

60ity queue based on a binary heap. This results in
O (jEj log(n + m)) run time for computing the path
distances of one labeled point to all other points. Thus,
the entire matrix D‰ costs O (nk(n + m) log(n + m))
on a k-NN graph.

The time complexity of a gradient descent algorithm
is approximately equal to that of evaluating the cost
function multiplied by the square of the number of
variables. For rTSVM , this amounts to O ¡(n + m)3¢.
The MDS is of the same time complexity, since it com-
putes the eigendecomposition of an (n + m) £ (n + m)
matrix. For both algorithms, the complexity can be
reduced if one considers only the ﬂrst p eigenvectors.

While rTSVM needs to store the entire kernel matrix
(on both labeled and unlabeled points), for graph an
n £ (n + m) part is su–cient. Memory can be re-
duced to the n£ n part required for SVM training, but
the (worst case) time required to compute individual
shortest paths is as much as is required for computing
all paths from a single source to all targets. For both
SVM and TSVM, in practice only parts of the kernel ma-
trices have to be (computed and) stored, because of
the sparsity of the solution.

For training the manifold algorithm as given in Eq. 7,
a sparse (n+m)£(n+m) matrix needs to be stored and
inverted. Due to the use of a k-NN graph, the matrix
has about k(n + m) entries (at most 2k(n + m)).

2.3.2 Parameters

For each algorithm, the values for a number of param-
eters have to be ﬂxed. In practical applications, this
is usually done by cross-validation (CV). While this is
no major problem for two parameters (like the SVMs
have), it is impractical for the ﬂve parameters of the
graph algorithm. To reduce this number, we ﬂx three
of them in advance, as shown in the table:

algorithm free parameters; [ﬂxed parameters]
SVM
TSVM
manifold
rTSVM
graph
LDS

(cid:190), C
(cid:190), C
(cid:190), k, ‚
(cid:190), C
C, ‰; [(cid:190) = 1, k = n + m, – = 0:1]
C, ‰; [(cid:190) = 1, k = n + m, – = 0:1]

ues reasonably well. This can be seen on the right of
(c): almost the same results were obtained with and
without MDS. It seems safe to discard the eigenvectors
corresponding to small (positive) eigenvalues (c.f. left
side of the plot (c)). In the rest of the experiments,
we set – = 0:1.

To determine good values of the remaining free pa-
rameters (eg, by CV), it is important to search on the
right scale. We therefore ﬂx default values for C and
(cid:190) that have the right order of magnitude. In a c-class
problem, we use the 1=c quantile of the pairwise dis-
tances D‰
i;j of all data points as the default for (cid:190). The
default for C is the inverse of the empirical variance s2
of the data in feature space, which can be calculated
by s2 = 1
n2 Pij Kij from a n£n kernel ma-
trix K. Below, all values for these parameters will be
given relative to the respective default values, making
them comparable for diﬁerent data sets.

n Pi Kii ¡ 1

2.3.3

LDS algorithm

The ﬂnal LDS algorithm is summarized in Figure 1.
Note that slight changes are required for the extreme
settings of ‰: for ‰ = 0, steps 1 to 3 have to be replaced
by simply running the shortest path algorithm on
d(i; j) to compute di;j; for ‰ = 1, a modiﬂed version
of Dijkstra that keeps track of maximum distances in-
stead of sums along paths must be used. A matlab im-
plementation of LDS can be obtained at http://www.
kyb.tuebingen.mpg.de/bs/people/chapelle/lds/.

3 EXPERIMENTAL RESULTS

3.1 DATA SETS

In order to get a good picture of the eﬁectiveness of
the algorithms, we compare their generalization per-
formance on two artiﬂcial and three real world data
sets with diﬁerent properties.

data set
g50c
g10n
Coil20
Text
Uspst

classes
2
2
20
2
10

dims
50
10
1024
7511
256

points
550
550
1440
1946
2007

labeled
50
50
40
50
50

Figure 4 demonstrates that for LDS the parameter ﬂx-
ing proposed above leads only to a minor loss in ac-
curacy. As shown in (a), a fully connected graph is
good (for the optimum value of ‰). As shown in (b),
(cid:190) = 1 (i.e. no further non-linear transformation) is
good (again, for the optimum value of ‰). In general
the resulting kernel will not be positive deﬂnite (ex-
cept for ‰ = 0 and ‰ = 1, see also Table 1). As shown
in (c), the SVM seems to handle negative eigenval-

The artiﬂcial data sets are inspired by [2]: the data
are generated from two standard normal multi-variate
Gaussians. In g50c, the labels correspond to the Gaus-
sians, and the means are located in 50-dimensional
space such that the Bayes error is 5%.
In contrast,
g10n is a deterministic problem in 10 dimensions,
where the decision function traverses the centers of
the Gaussians (thus violating the cluster assumption),
and depends on only two of the input dimensions.

61r
o
r
r
e
 
t
s
e
T

0.3

0.25

0.2

0.15

0.1

0.05

10 NN
100 NN
Fully connected

  0

0.5

  1

  2

  4

  8

 16

 32

Inf

r
o
r
r
e
 
t
s
e
T

0.3

0.25

0.2

0.15

0.1

0.05

Default s
 = ¥

10−1

10−2

10−3

e
c
n
e
r
e

f
f
i

 

d
d
e
r
a
u
q
s
 
n
a
e
M

(a)

(b)

  0

0.5

  1

  2

  4

  8

 16

 32

Inf

10−4

100

101

102

103

1/d

(c)

Figure 4: In(cid:176)uence of parameter choice on the test error of LDS on the Coil20 data: (a) the graph structure;
(b) (cid:190); and (c) the approximation accuracy of the MDS. Plot (c) shows the square diﬁerence between the test
error achieved with and without MDS, averaged over diﬁerent values of C and ‰.

Algorithm 1 LDS algorithm
Require: ‰, C
# Compute ‰-distances:
1: Build a fully connected graph with edge lengths wij = exp(‰d(i; j)) ¡ 1.
2: Use Dijkstra’s algorithm [9] to compute the shortest path lengths dSP (i; j) for all pairs of points.
3: Form the matrix D of squared ‰-path distances by Dij = ‡ 1
# Perform multidimensional scaling:
4: U ⁄U > = ¡HDH, where Hij = –ij ¡ 1=(n + m).
5: Find the threshold p such that (6) holds.
6: The new representation of xi is ~xik = Uik
# Train TSVM:
7: for i=0 to 10 do
8:
9: Minimize by gradient descent (3) under constraint (5).
10: end for

‰ log(1 + dSP (i; j))·2

Set C ⁄ = 2i¡10C

p

‚k; 1 • k • p.

.

The real world data sets consist of two-class and multi-
class problems.
In Coil20, the data are gray-scale
images of 20 diﬁerent objects taken from diﬁerent an-
gles, in steps of 5 degrees [15]. The Text dataset are
the classes mac and mswindows of the Newsgroup20
dataset preprocessed as in [18]. Finally, our Uspst
set contains the test data part of the well-known USPS
data on handwritten digit recognition.

3.2 EXPERIMENTS

For each of the data sets, 10 diﬁerent splits into labeled
and unlabeled points were randomly generated. We
took care to include at least one point of each class in
the labeled set (two for Coil20).

We used a diﬁerent model selection strategy for LDS
than for the other algorithms. For LDS, we carry out 5-
fold cross-validation (CV) on the training set for each
split, thereby simulating the real world application sce-
nario. Note that all data (training and test) can be
(and is) used as unlabeled data. The reported test

errors are obtained after training the selected model
on the entire training set. For the other algorithms,
we are interested in the best possible performance, and
simply select the parameter values minimizing the test
error. In both cases, we select combinations of values
on a ﬂnite grid as follows:

parameter
width (cid:190)
exponent ‰
penalty C
degree k
regulariz. ‚

values

2¡3; 2¡2; 2¡1; 20; 21; 22; 23

0; 20; 21; 22; 23; 24; +1

10¡1; 100; 101; 102

10; 100; all

4¡2; 4¡1; 40; 41; 42

Although LDS and graph work with any kernel, we here
ﬂx the linear kernel ((cid:190) = 1; c.f. section 2.3.2).

3.3 RESULTS

The results are presented in Table 2. Except for the
data set g10n, LDS always achieves lower test errors
with empirically found parameter settings than all the

62r
r
s
Coil20
g50c
g10n
Text
Usps

r
o
r
r
e
 
n
o
i
t
a
d

i
l

a
v
 
s
s
o
r
C

0.6

0.5

0.4

0.3

0.2

0.1

0

 0 

 1 

 2 

 4 

 8 

16 

Inf

Figure 5: Cross-validation error (with standard devi-
ation error bars) as a function of the parameter ‰.

other algorithms are capable of achieving, even when
optimal parameter settings are known. This clearly
demonstrates the superiority of LDS.

Although rTSVM always performs better (and usually,
signiﬂcantly better) than TSVM, it still fails to reach
the level of manifold on the Coil20 data set. But
this shortcoming is eliminated by making use of the
graph transform of the distances.

To better understand the role of the distance trans-
form, we depict the 5-fold cross validation error for
the best value of C, averaged over the 10 splits, as a
function of ‰ in Figure 5. We can distinguish three
cases: the minimum is (i) at or close to 0; (ii) at or
close to 1; or (iii) somewhere in between.

(i) Linear classiﬂers are optimal by construction for
the artiﬂcial data, and likely to be optimal for Text
due to the high dimensionality. For g50c and Text,
‰ > 0 does not substantially help rTSVM, but does not
hurt either. Only for g10n, where the cluster assump-
tion does not hold, increasing ‰ immediatly increases
the test error. (ii) In Coil20, the points of each class
lie eqi-distantly on a ring. With ‰ = 1, all their
pairwise distances are reduced to the distance of two
neighboring points. Note that there is no noise which
could cause unwanted bridging between two classes.
(iii) Perhaps the most interesting case is Uspst, with
an optimum of ‰ = 4. While there deﬂnitely are clus-
ters corresponding to the classes, there seem to exist
outliers that would, for too large ‰, lead to erroneous
merging of clusters.

As the optimum value of ‰ seems to correspond to fea-
tures of the data set, prior knowledge on the data could
possibly be used to narrow the range to be searched.

4 CONCLUSIONS

The TSVM objective function could, at a ﬂrst sight,
be interpreted as a straight-forward extension of the
maximum margin principle of SVM to unlabeled data.
We conjecture that it actually implements two diﬁer-
ent principles: the regularization by margin maximiza-
tion on the labeled points, and the cluster assumption
by margin maximization on the unlabeled points. The
latter does not lead to smoother decision functions,
but it enforces that the decision boundary lies in low
density regions.

The strength of our gradient descent approach might
be that it directly optimizes the objective according
to the cluster assumption: to ﬂnd a decision bound-
ary that avoids high density regions.
In contrast,
TSVM (SVMlight implementation) might suﬁer from
the combinatorial nature of its approach. By decid-
ing, from the very ﬂrst step, on the putative label of
every point (even though with low conﬂdence), it may
lose important degrees of freedom at an early stage,
and get trapped in a bad local minimum.

The pairwise distances computed by the graph algo-
rithm attempt to re(cid:176)ect the cluster assumption: dis-
tances of points from the same cluster are shrunk,
while for points in diﬁerent clusters they are dom-
inated by the inter-cluster distance. Used with an
SVM, this clearly improves over standard (Euclidean)
distances, but not over other semi-supervised methods.

The combination of the graph distance computation
with the TSVM training yields a clearly superior semi-
supervised algorithm. Apparently the preprocessed
distances make it less likely for the TSVM to get stuck
in very suboptimal local minima. Probably the prepro-
cessing widens small density valleys so that they are
more readily found by local searches.

Although manifold learning indirectly exploits the
cluster assumption, as argued above, another feature
may contribute to its successes. If the intrinsic dimen-
sionality of the data manifolds is much smaller than
that of the input space, restricting the learning process
to the manifolds can alleviate the \curse of dimension-
ality". We plan to investigate how much performance
can be gained in this manner.

Future work will be on a thorough comparison of dis-
criminative semi-supervised learning methods. We ob-
serve that the time (and to some degree, also space)
complexities of all methods investigated here prohibit
the application to really large sets of unlabeled data,
say, more than a few thousand. Thus, work should
also be devoted to improvements of the computational
e–ciency of algorithms, ideally of LDS.

63r
data set
Coil20
g50c
g10n
Text
Uspst

manifold

proposed methods

methods from literature
SVM
24.64%
8.32%
9.36%
18.87%
23.18%

graph rTSVM
LDS
TSVM
6.43% 17.56% 4.86%
6.20% 26.26%
5.80% 5.62%
8.32%
17.30%
6.87%
9.36%
9.82%
9.72%
30.64% 14.36%
5.71% 5.13%
7.44% 10.48%
11.71%
21.30% 26.46% 16.92% 17.61% 15.79%

Table 2: Mean test error rates. Note that model selection was done by cross-validation for LDS whereas by
minimizing the test error for the other methods. Bold numbers are statistically signiﬂcantly (95% conﬂdence)
better compared to all other methods.

Acknowledgements

We thank Bernhard Sch˜olkopf and Matthias Hein for
valuable comments.

References

[1] M. Belkin, I. Matveeva, and P. Niyogi. Regu-
larization and semi-supervised learning on large
graphs. In COLT, 2004.

[2] Y. Bengio and Y. Grandvalet. Semi-supervised
learning by entropy minimization. In NIPS, vol-
ume 17, 2004.

[3] K. Bennett and A. Demiriz. Semi-supervised sup-
port vector machines. In NIPS, volume 12, 1998.

[4] O. Bousquet, O. Chapelle, and M. Hein. Measure

based regularization. In NIPS, 2004.

[5] O. Chapelle. Support Vector Machines: Induction
Principle, Adaptive Tuning and Prior Knwoledge.
PhD thesis, LIP 6, 2003.

[6] O. Chapelle, J. Weston, L. Bottou, and V. Vap-
In NIPS, vol-

nik. Vicinal risk minimization.
ume 13, 2000.

[7] O. Chapelle, J. Weston, and B. Sch˜olkopf. Clus-
ter kernels for semi-supervised learning. In NIPS,
volume 15, 2002.

[12] T. Joachims. Transductive inference for text
classiﬂcation using support vector machines. In
ICML, pages 200{209, 1999.

[13] T. Joachims. Transductive learning via spectral

graph partitioning. In ICML, 2003.

[14] R. I. Kondor and J. Laﬁerty. Diﬁusion kernels on
graphs and other discrete structures. In ICML,
2002.

[15] S. A. Nene, S. K. Nayar, and H. Murase.
Columbia object image library (coil-20). Techni-
cal Report CUCS-005-96, Columbia Univ., USA,
February 1996.

[16] C. S. Ong, X. Mary, S. Canu, and A. J. Smola.
In ICML,

Learning with non-positive kernels.
pages 639{646, 2004.

[17] B. Sch˜olkopf and A. J. Smola. Learning with Ker-

nels. MIT Press, Cambridge, MA, 2002.

[18] M. Szummer and T. Jaakkola. Partially labeled
In

classiﬂcation with markov random walks.
NIPS, volume 14, 2001.

[19] J. B. Tenenbaum, V. de Silva, and J. C. Langford.
A global geometric framework for nonlinear di-
mensionality reduction. Science, 290(5500):2319{
2323, 2000.

[20] V. Vapnik. Statistical Learning Theory. John Wi-

[8] T. F. Cox and M. A. Cox. Multidimensional Scal-

ley & Sons, 1998.

ing. Chapman & Hall, 1994.

[9] E. W. Dijkstra. A note on two problems in con-
nection with graphs. Numerische Math., 1:269{
271, 1959.

[10] B. Fischer, V. Roth, and J. M. Buhmann. Clus-
tering with the connectivity kernel. In NIPS, vol-
ume 16, 2004.

[11] B. Haasdonk. Feature space interpretation of
IEEE TPAMI,

SVMs with indeﬂnite kernels.
2004. In press.

[21] P. Vincent and Y. Bengio. Density-sensitive met-
rics and kernels. Presented at the Snowbird
Learning Workshop, 2003.

[22] D. Zhou, O. Bousquet, T. Lal, J. Weston, and
B. Sch˜olkopf. Learning with local and global con-
sistency. In NIPS, volume 16, 2003.

[23] X. Zhu, Z. Ghahramani, and J. Laﬁerty. Semi-
supervised learning using gaussian ﬂelds and har-
monic functions. In ICML, 2003.

64Learning spectral graph segmentation

Timoth´ee Cour

Computer and Information Science

University of Pennsylvania

Nicolas Gogin
Computer Science
Ecole Polytechnique

Jianbo Shi

Computer and Information Science

University of Pennsylvania

Philadelphia, PA 19104

91128 Palaiseau Cedex, FRANCE

Philadelphia, PA 19104

Abstract

We present a general graph learning algo-
rithm for spectral graph partitioning, that
allows direct supervised learning of graph
structures using hand labeled training exam-
ples. The learning algorithm is based on
gradient descent in the space of all feasible
graph weights. Computation of the gradient
involves ﬁnding the derivatives of eigenvec-
tors with respect to the graph weight matrix.
We show the derivatives of eigenvectors exist
and can be computed in an exact analytical
form using the theory of implicit functions.
Furthermore, we show for a simple case, the
gradient converges exponentially fast. In the
image segmentation domain, we demonstrate
how to encode top-down high level object
prior in a bottom-up shape detection process.

1 INTRODUCTION

Image segmentation and data clustering are two fun-
damental operations in computer vision and machine
learning. Let I = {x1, ..., xn} be a set of feature vec-
tors representing n image pixels or data points. The
image segmentation process partitions pixels into K
disjoint groups. In a 2-way segmentation, we seek an
output vector SEG(I) = {y1, ..., yn} ∈ {0, 1}n, such
that a segmentation goodness measure is optimized.
We deﬁned segmentation as a mapping from xi to
yi ∈ {0, 1} to purposely hint its potential connection
to a supervised learning method we should propose.
Our goal is to teach the image segmentation through a
set of hand labeled training examples. Given a set of
image/segmentation pairs {Ii, SEG∗(Ii)}, the system
will learn to adjust so that the computed segmenta-
tion SEG(Ii) is close to SEG∗(Ii). With a supervised
image segmentation, we are able to encode top-down
object familiarity prior in a bottom-up distributed pro-

cess. In this paper, we will demonstrate a system that
can detect and segment rectangular shaped objects in
a clutter image background by learning from examples.

1

To appreciate why learning image segmentation is dif-
ﬁcult, we summarize below its basic principles. Seg-
mentation algorithms are deﬁned by the clustering cri-
teria and computational process to optimize it. For
example, in the Markov Random Field (MRF) for-
mulation, the criteria is to maximize P (SEG(x)|x) =
Z exp(P−f (yi, yj|x)), where f (yi, yj|x), called clique
potential, speciﬁes a local measure of grouping pixel
i with j. While each f (yi, yj|x) can be easily cor-
rupted, the global optimum of P (SEG(x)|x) must bal-
ance preferences on all pairs of f (yi, yj|x) and there-
fore is stable. Spectral graph partitioning, such as
Normalized Cut (Ncut)[6][5], has been developed as a
computationally eﬃcient alternative to MRF. Image
segmentation is mapped to a graph partitioning prob-
lem, where the graph consists of the pixels/data points
as nodes, and the weighted graph edges W (i, j) serve
as the equivalent of Clique Potential f (yi, yj|x). The
global segmentation criterion Ncut seeks a balanced
segmentation and grouping of the pixels. Computa-
tionally the solution is derived from the eigenvectors
of W y = λDy, where D is the degree matrix. As in
the MRF case, the eigenvectors are implicitly related
to the input weight matrix W , and are quite insensitive
to random perturbation of W .

While global decision process from local feature com-
parison brings a stable segmentation,
it makes the
learning segmentation a diﬃcult task. Treating any
segmentation learning algorithm as a black box, one
must be able to back-trace error on the output of
global segmentation to the input local clique potential
or pair-wise weight matrix. Since the global decision
is only implicitly related to the input, it is hard to ex-
plicitly assign a blame to a particular clique potential
or weight matrix entry. To account for segmentation
error on just one pixel, we would potentially need to
adjust all possible pairs of clique potential or weight

65Image

Model

Image

Ncut

Model

Ncut

Hand Segmentation

P*[I]

(A)

Hand Segmentation

(B)

Figure 1: Two alternative algorithms for learning spectral graph partitioning.
(A) methods of Meila-Shi[4]
optimizes the graph weight W (I, Θ) by minimizing the KL-divergence between an equivalent random walk matrix
P (I, Θ) and the target P ∗(I, Θ). (B) Our method directly optimize the error on the output Ncut segmentation
vector XN cut[W (I, Θ)] by gradient descent in the space of all feasible graph weights using explicit computation
of the derivatives of eigenvectors.

matrix entries!

Meila-Shi[4] ﬁrst studied the problem of learning spec-
tral graph cuts with supervised training data. Their
proposed algorithm learned the graph weight Wij by
minimizing the KL-divergence between an equivalent
random walk matrix Pij and the target P ∗
ij derived
from the hand labeled segmentation. However the for-
mulation provides no explicit constraints on the Ncut
eigenvector itself. Bach-Jordan[1] formulated a direct
optimization of W with respect to its Ncut eigenvec-
tor. They transform the implicit relationship between
W and Ncut eigenvector into an explicit one by mak-
ing a diﬀerentiable approximation of eigenvector using
power method. The resulting computation of deriva-
tives of eigenvector is however complex and can be
computationally unstable.

We present in this paper a direct method for learn-
ing spectral graph cut, based on eﬃcient computation
of derivatives of Ncut eigenvectors in exact analytical
form. We show that there is an explicit computation
that assigns the segmentation error to the input graph
weight matrix. This capability allows us to design pa-
rameterized graphs that can encode and detect com-
plex objects. The paper is organized as follows. We
describe in Sec. 2 the structure of the graph we use
for image and shape segmentation. Sec. 3 describes
the learning algorithm and its convergence properties.
We show our results in Sec. 4.

2 PROBLEM SETUP

We will demonstrate a learnable segmentation al-
gorithm for detecting and segmenting desired ob-
ject shape such as a rectangle in an image. The
shape detection-segmentation process begins with
edge detection.
Each edge i is parametrized by
(xi, yi, θi), its location and orientation. Denote F (I) =
{e1, ..., ek|ei = (xi, yi, θi)} the set of edges detected for
image I, and F the complete set of possible edges de-

tected in all images. The goal of the segmentation
algorithm is to group the edges which form a rectan-
gle, and separate them from background edge clutters,
as shown in Fig. 11.

While a rectangle is a relatively simple shape, its as-
pect can be quite ﬂexible with variable aspect ratio
in x, y, and variable orientation. Assuming we have
quantized the orientation into Nangle angles, for an
image size of Npixel × Npixel a brute force method
would need to search over O(N 4
pixelNangle possible
conﬁgurations (for a 100 × 100 image with 10 ori-
entations quantization, we have 1 billion conﬁgura-
tions!). One way to avoid this large scale search is
to decompose the rectangles into simple local conﬁg-
urations (corners, lines, parallel lines), and combine
them by checking their global consistency. This data-
driven bottom-up process only needs to check roughly
O(Nedge) = O(|F (I)|) local conﬁgurations (assuming
a ﬁxed neighborhood size). The global integration can
be carried out in the grouping framework of graph par-
titioning such as Ncut, which has empirically a running
time of O(N 1.5
edge). Furthermore, the decomposition of
a shape into local edge relationships also makes the
detection more robust to image background clutter.

2.1 LOCAL SHAPE CONFIGURATIONS

We need to deﬁne functions on local conﬁguration
goodness, with the hope of discriminating rectangu-
lar object vs. background. Since we are using ori-
ented edges, we can favor convex conﬁgurations and
penalize concave or other impossible conﬁgurations,
as illustrated in Fig. 2. The function that assesses
the goodness of a particular conﬁguration is denoted
as clique potential: f (e1, . . . , eK ) is high only when
(e1, . . . , eK ) form a familiar conﬁguration. The prob-
lem of designing this clique potential can be quite
complex in general. For example, consider the case
of binary relationships: we need to ﬁnd a poten-
tial function for all possible pairs of edges (e1, e2):

66background. A direct thresholding technique would
fail here. Another example is provided by Fig. 4,
where a local approach would favor the wrong edge
orientation. As in the case of image segmentation, lo-
cal grouping measures need to be aggregated to form a
global segmentation decision. We will see in the next
section how to formulate this precisely in graph frame-
work, through Spectral Graph Partitioning.

Figure 4: Each edge has 2 hypothesized opposite po-
larities. We want to inhibit clutter edges and recover
correct polarity. Left: local segmentation of edges pro-
duces the wrong polarity for one edge (barred), group-
ing it with clutter. Right: global aggregation of edge
aﬃnities yields a correct grouping and inhibits clutter.

2.3 SPECTRAL GRAPH PARTITIONING

FORMULATION

Such local relationships between image features are
well captured by the notion of graph G = hV, Wi.
The graph nodes V consist of the image edge fea-
tures F = {ei}, and the graph edges are the rela-
tionships between the edge features with aﬃnity ma-
trix W ∈ Rn×n deﬁned by Wij = f (ei, ej). Higher-
order edge feature relationships can be translated into
binary aﬃnities by summing over cliques: Wij =
Pi1=i,i2=j,i3,...,iK
f (ei1 , ..., eiK ), as illustrated in Fig.
3. We denote V (I) the image edge features, F (I),
detected in I; W (I) = W (V (I), V (I)), the subgraph
aﬃnity induced by image features in I.

Let us recall our goal: we want to partition the graph
nodes V (I) into two groups, using an indicator vec-
tor X: Xi = 1 if detected feature V (I)i belongs to
foreground, and Xi = −1 if it belongs to background.
The segmentation process should ensure that edge fea-
tures (nodes) grouped together have high mutual aﬃn-
ity, and nodes in diﬀerent sets have low aﬃnity. We
will use the Normalized Cuts (Ncut) criterion for the
segmentation process. Ncut criterion can be opti-
mized by ﬁnding the second generalized eigenvector
of (W (I), D(I)) (D(I) is the degree matrix of W (I)):

W (I)X(I) = λ2D(I)X(I)

(2)

X(I) is then thresholded to determine the fore-
ground/background labelling. Note that, the solu-
tion we obtain for X(I) is an implicit function of the
weight matrix W (I), which is deﬁned by the local

Figure 2: Diﬀerent oriented edge conﬁgurations and
associated clique potential. Left: three edges form-
ing a convex object (likely to be found in rectangle
shapes). Middle: concave conﬁguration (unlikely in
rectangular shapes). Right:
impossible conﬁguration
(very unlikely to be found in any object).

Figure 3: Properties of the clique potential/aﬃnity
matrix. Left and middle:
translation and rotation
invariance, f (x1, y1, θ1; x2, y2, θ2) = ¯f (x2 − x1, y2 −
y1, θ1, θ2) and, f (z1, θ1; z2, θ2) = ¯¯f ((z2 − z1)e−iθ1 , θ2 −
θ1). Right: summing up ternary aﬃnities to obtain a
binary aﬃnity, f (e1, e2) = Pi f3(e1, e2, ei).

f (e1, e2) = f (x1, y1, θ1, x2, y2, θ2). The function takes
4-dimensional
inputs, and even in the simple case
of 10x10 possible edge locations, with 4 orientations
{π/2, 2π/2, 3π/2, 4π/2}, that makes 160,000 diﬀerent
values to design through learning. To make the learn-
ing problem more managable, we use the following pa-
rameterization that induces translational invariance:
f (x1, y1, θ1; x2, y2, θ2) = ¯f (x2 − x1, y2 − y1, θ1, θ2) (1)
If in addition we also require invariance by rotation,
the use of complex numbers comes in handy, with z =

x+iy we obtain f (z1, θ1; z2, θ2) = ¯¯f ((z2−z1)e−iθ1 , θ2−
θ1). These invariance properties are illustrated in Fig.
3.

2.2 GLOBAL SHAPE DETECTION FROM

LOCAL CONFIGURATIONS

With local edge clique function we could eliminate
wrong patterns of edges, retrieve the correct edge ori-
entation when ambiguous, and enhance good conﬁg-
urations. However, there are many ambiguous cases
in which local properties are insuﬃcient to decide the
foreground/background labeling. Think about a weak
edge at object boundary, or a strong clutter edge in the

67Figure 5: The XOR function. Suppose we have a face
detection graph with nodes: Left Nose (LN), Right
Nose (RN), Face (F), and Non-Face(NF). The Hebbian
learning rule, based on feature coocurrence, would ﬁnd
the following weights: W (LN, F ) = W (RN, F ) =
W (LN, N F ) = W (RN, N F ) = 1
2 , making it impos-
sible to distinguish between a Face and a Non-Face.
The graph learning algorithm we propose does not suf-
fer from this.

clique potentials, f (ei, ej). However, its computation
is tractable and, as we shall see, we can apply pertur-
bation theory to analyze their eﬀect on the segmenta-
tion task. This last point is essential:
it means that
we can assign a blame to the local graph structure, by
looking at the global segmentation result. Hence the
system is not a black box anymore, we can train it.

3 LEARNING THE GRAPH

STRUCTURE

As we have seen, the design of the clique potential is
as crucial to the segmentation as it complex. In the
Ncut formulation, whether we use a parameterization
of the aﬃnity matrix W (Θ) or a direct representation
through its coeﬃcients Wij, real image segmentation
tasks will require a large number of parameters to be
optimized. Hence the need for a principled algorithm
to learn the clique potential.

3.1 WHY ARE SIMPLE LEARNING

SCHEMES INSUFFICIENT

One natural idea in learning the graph clique potential
is simply to measure the coocurrence of image features
accross a set of training images, in accordance to the
Hebbian rule. This rule strengthens the weight Wij if
feature i and feature j are strongly correlated, accord-
ing to: Wij = PI V (I)iV (I)j in our notation. Though
intuitive, this rule is insuﬃcient for our problem. Fig.
5 illustrates a typical situation that the Hebbian rule
is unable to handle, namely the XOR boolean func-
tion. More generally, the Hebbian rule cannot learn
non-linearly separable functions. We have shown in
[2]1 that our system does not have this limitation and
it could learn XOR.

1http://www.seas.upenn.edu/∼timothee/research.html

3.2 PRINCIPLE OF LEARNING

The Maximum Likelihood formulation (ML) tries to
adjust the clique potential so that it maximally ex-
plains the data (the set of training images). However,
this formulation doesn’t take into account the graph
inference procedure I → X(I), as a result, it can pro-
duce a probability distribution that cannot be infer-
enced eﬃciently. We use a diﬀerent approach. We
adjust the clique potential so that the output of the
system gets closer to the desired segmentation. In the
following, we assume we are given a set of images I
with a target segmentation X ∗(I).

3.3 COST FUNCTION FOR LEARNING

Deﬁnitions Xp[W ], λp are the pth largest eigenvec-
tor, eigenvalue of W X = λDW X with kXp[W ]k = 1
and DW = diag(W 1). Xp[W ] is uniquely deﬁned
up to polarity, which we disambiguate using a ﬁxed
vector Y and forcing sign(Y T Xp[W ]) = +1. This
is possible only when Y T Xp[W ]
6= 0. We also re-
quire λp be unique. To satisfy these constraints, we
will restrict our attention to weight matrices W in a
certain subset S2,X ∗(I)
of symmetric matrices, where
Sp,Y
n = {W ∈ Sn : W 1 > 0, ker(W − λpDW ) 6⊂ Y ⊥,
λp single}. Note that if W ∈ Sn and W 1 > 0, W has
probability 1 of being in the feasible space. What’s
more, S2,X ∗(I)
is open, which implies that any small
perturbation of W is allowed.
Deﬁne the one-target energy function:

n

n

E(W, I) =

1
2kX2[W (I)] − X ∗(I)k2, for W ∈ S2,X ∗(I)
(3)

n

The multi-target energy function is deﬁned as E(W ) =
PI E(W, I), for W ∈ ∩I S2,X ∗(I)
. This error energy
function has the following property, which will be use-
ful later on when we try to learn the graph network.

n

Prop. 3.1 (E(W, I) has no local minimum) The
single target energy function has all its local minima
in S2,X ∗
n T {W : λ2(W ) 6= −1} equal to the global
minimum, 0.

The proof, in [2], shows that at a critical point, the
error vector X2 − X ∗(I) is in the kernel of a certain
matrix of rank n-1. This shows in fact that X2 −
X ∗(I) is proportional to X2, which ﬁnally leads to
X2 = X ∗(I).

3.4 GRADIENT DESCENT ALGORITHM

We minimize the error energy over W by gradi-
∂X2
ent descent: ∆W = −η ∂E
∂W . When
W is parameterized by Θ, we have instead ∆Θ =

∂W = −η ∂E

∂X2

68∂X2

∂X2
∂W

∂W
−η ∂E
∂Θ . In the case of rectangle detection, the
parameters Θ consist of all the values of the function
f (ei, ej) = ¯f (x2 − x1, y2 − y1, θ1, θ2), which is a 4 di-
mensional lookup table.

The main diﬃculty is to study how the Ncut eigenvec-
tor, X2[W (Θ)], varies with the graph weight matrix
W (Θ). We will write down a continuous-time PDE
describing evolution of the error energy on X2[W (Θ)]
with respect to Θ. We show that this PDE has an ex-
act analytical form, and the resulting PDE converges.
We have also proved the convergence rate is exponen-
tial for a simple case[2]. This result shows that we can
minimize the error energy over W or Θ by gradient
descent.

Theorem 3.2 (Derivative of Ncut eigenvector)
The map W → (Xp, λp) is C∞ over Sp,Y
n , and we
can express the derivatives over any C 1 path W (t)
as:

dXp[W (t)]

dt

dλp
dt

= −(W − λpDW )†
(W ′ − λpD′
W −
X T
p (W ′ − λpD′
p DW Xp

X T

=

dλp
dt

DW )Xp

W )Xp

We obtain an analog theorem for the derivative of
standard eigenvectors, by simply replacing DW
with In. The proof in [2] uses the implicit function
theorem to show Xp[W ] is C∞, then diﬀerentiates
p + (W ′ −
W Xp = λpDW Xp to obtain (W − λpDW )X ′
λpD′

pDW )Xp = 0.

W − λ′

Computation of the partial derivatives ∂X2
∂W alone re-
quires O(n3) time because of the pseudo-inverse term
(W − λpDW )† in each gradient direction. We remove
this bottleneck by ﬁrst left-multiplying by ∂E
. We in-
∂X2
troduce Y = −(W − λ2DW )†(X2 − X ∗(I)), which we
showed how to compute eﬃciently in [2], and obtain a
O(n2) gradient update rule:

∂E
∂W ij

= X2,iYj + X2,jYi − λ2(X2,iYi + X2,jYj)

with λ′

2ij =

2ijY T DW X2

−λ′
2X2,iX2,j − λ2(X2,i
2 DW X2

X T

2 + X2,j

2)

0.5

0

−0.5
−1

0.8

0.6

0.4

0.2

0

−0.2

−0.4

−0.6

−0.8
−1

−0.6

−0.34

−0.08

0.18

0.44

Point set 1
Point set 2

Energy map − Gradient descent

start
end
intermediate

−0.5

0

0.5

1

0

1.4

2.8

4.2

5.6

Energy map − Gradient descent

0

10

20

30

40

start
end
intermediate

Point set 1
Point set 2

−0.5

0

0.5

1

0

10

20

30

40

0.3

0.25

0.2

0.15

0.1

0.05

0

−0.05

−0.1

−0.15

−0.2
0

0.3

0.25

0.2

0.15

0.1

0.05

0

−0.05

−0.1

−0.15

−0.2
0

Indicator Vectors

Target
Start
End

20

40

60

80

100

Indicator Vectors

Target
Start
End

20

40

60

80

100

(A) Point set (B) Error Energy (C) Ncut eigenvector

Figure 6: Learning point set clustering. W (i, j) =
exp(−σx(x(i) − x(j))2) + exp(−σy(y(i) − y(j))2). A) 2D
layout of the points. The ﬁrst set is the cross set and
the second is the star set. The resulting clustering can
be identiﬁed by the red and black colors. B) Energy
landscape of E(σx, σy), and gradient path taken by Eq.4,
). C) Target vector comparing with
( ˙σx,
initial and ﬁnal learned Ncut vector. The graph nodes are
ordered according to their x-axis position (ﬁrst row), and
to their distance to origin (second row).

˙σy) = −( ∂E
∂σx

, ∂E
∂σy

imply that of W (t). Indeed, one can construct func-
tions for which gradient descent leads to limit cycle
oscillations. The following proposition shows that this
cannot happen here.

n

Prop. 3.3 (Exponential convergence of E(W, I))
The 1-target energy PDE ˙W = − ∂E
∂W either converges
to a global energy minimum W∞, or it escapes any
compact K ⊂ S2,X ∗
. In the ﬁrst case, E(W (t)) → 0
exponentially.
∂W k ≥ b√E, leading to
dtE(W (t)) ≤ −b2E,

Our proof in [2] shows that k ∂E
the convergence of W (t), and then d
which shows the exponential decay of E(W (t)).

n

Pathological non-convergence cases. As stated in
the proposition, W (t) could potentially hit the bound-
ary of S2,X ∗
. This arises in 2 pathological cases: 1)
λ2(t) → 1 or λ2(t)− λ3(t) → 0, and 2) DW (t)(i, i) → 0
for some i. Note that X ∗(I)T X2[W (t)] → 0 can-
not happen, because initially X ∗(I)T X2[W (t)] > 0
and E(W, I) decreases. There are ways to alleviate
those problems through weight parameterization, but
in practice they only occur when learning a lot of tar-
get vectors.

3.5 PROPERTIES OF THE LEARNING

ALGORITHM

4 RESULTS

Empirically, we observe that E(W (t)) converges to
0 exponentially fast when W (t) follows the gradient
path, even if the number of training examples grows
as O(n). We will prove this fact in the case of a single
target. The convergence of E(W (t)) however does not

4.1 POINT SET CLUSTERING

In experiment 1, ﬁgure 6, we examine our spectral
graph learning algorithm on simple 2D point set clus-
tering examples. The graph weight matrix Wij =

69Target vector

Input image

Ncut vector 
best scale

Ncut vector  
multiscale

Ncut vector

after multiscale learning

Figure 7: A simple example of multiscale learning. The
input image is 40 by 40 and 4 narrow scales are used. The
best result (minimum of energy) with one scale is displayed
as well as the result with all four scales set up with the same
weight, and with the learned weight. The use of multiscale
enable to segment correctly the inside of the G. The lowest
energy is achieved after learning.

exp(−σx(xi − xj)2) + exp(−σy(yi − yj)2) has two pa-
rameters σx, σy which we aim to optimize. We update
(σx, σy) as follows:

∆σx = −η(X − X ∗)T ∂X
∆σy = −η(X − X ∗)T ∂X

∂σx

∂σy

(4)

(5)

We use directly the derivatives given in Sec. 3.4 with
the following expressions of W ′:

∂wij
∂σx
∂wij
∂σy

= −(xi − xj)2 e−σx(xi−xj )2
= −(yi − yj)2 e−σy(yi−yj )2

(6)

(7)

The experiments on simple clustering show a fast con-
vergence of the gradient descent. We also tested the
algorithm with radial distributed point sets.

4.2 MULTISCALE IMAGE

SEGMENTATION

In this experiment, we focus on an application of spec-
tral learning in image segmentation. The aim is to
provide a powerful tool to ﬁnd the best scales of edge
extraction in Ncut segmentation[3]. Basically the idea
of multiscale segmentation is to use several edge scales
ﬁnd a consistent segmentation of the image across
scales. The simultaneous use of various scale levels
is interesting for complex and big images which mixes
textures with sharp and soft contours.
In those im-
ages, meaningful boundaries may exist at weak con-
tours or between textures that do not rise to edges.
Using simultaneously several scales of edges enable to
face this problem. The global aﬃnity matrix is the
sum of r-aﬃnity matrices at diﬀerent scales:

W (I)

i,j =

k

X

r=1

αr exp (−σr∆(r)

i,j (I))

(8)

where ∆(r)
i,j (I) is a matrix of the same size as W which
expresses a distance measure in a speciﬁc scale. Learn-
ing on the α coeﬃcients of the scales enables to select

A

B

Figure 8: A: Training. Row 1: training input vector. Row
2: Ncut vector after learning. Row 3: target vector. B:
Testing. Row 1: testing input vector, Row 2: Ncut vector
after learning. For each edge, 2 polarities are hypothesized
(only 1 is displayed in Row 1 of Training/Testing). Notice
that after learning, not only clutter edges are suppressed
but also the correct edge polarities are recovered.

the scales and to set up the weighting coeﬃcients when
more than two scales are required. Learning on σ coef-
ﬁcients enables to ﬁnd the sensitivity to edge strength
at a given scale.

The update rules for αr, σr are as following:

∆αr = −ηY (

∆σr = −ηY (

∂W
∂αr − λ
∂W
∂σr − λ

∂D
∂αr −
∂D
∂σr −

∂λ
∂αr
∂λ
∂σr

D)X (9)

D)X (10)

Figure 9: The learned shift-invariant graph clique
function ¯f (x2 − x1, y2 − y1, θ1, θ2) with θ1 = 0, and
θ2 = π/2. Each 2D function corresponds to a ﬁxed
(θ1, θ2) pair. The clique function learns to favor good
continuation of the edges with (θ1 = 0, θ2 = 0),
(θ1 = π/2, θ2 = π/2), and corner conﬁgurations (θ1 =
π/2, θ2 = 0), (θ1 = 0, θ2 = π/2)

704.3 SHAPE DETECTION

We ﬁrst generate random rectangles in synthetic im-
ages of 100 by 100, see Fig. 8. The edges extracted, ei
are speciﬁed by its quantized location (xi, yi), orien-
tation θi, and polarity pi. Three graph weight clique
potential functions are implemented:

1. unconstrained f (e1, e2) = f (x1, y1, θ1, x2, y2, θ2)
2. translational invariant f (e1, e2) = ¯f (x2 − x1, y2 −

y1, θ1, θ2)

3. translational invariant with ternary clique poten-
N Pk g(x1 − xk, y1 − yk, x2 −

tial f (e1, e2) = 1
xk, y2 − yk, θ1, θ2, θk).

We apply the following graph learning algorithms to
train segmentation algorithm to detect rectangles.

1. Generate random rectangles with one noise-
free and one noisy version per example.
Generate a random aﬃnity matrix W to
start with

2. For each image I, extract edge features from
the noisy image to compute subgraph V (I),
and compute target X ∗(I) from the noise-
free image

3. initialize E = 0; for each image I,

(a) W (I) = W (V(I), V(I)), using one of
the clique potential function f (ei, ej)
described above.
(b) Compute X2(I),

second generalized

eigenvector of (W (I), DW (I))

(c) Update W (I) with gradient update and

propagate updating to each f (ei, ej)

(d) Update E := E + EI with the partial

energy EI = 1

2||X2(I) − X ∗(I)||2
4. Go back to step 3 until E < threshold

Fig.8 display the results of the training and testing us-
ing shift-invariant clique function ¯f . Figure 4.2 shows
the shift-invariant clique function learned on a pair of
horizontal and vertical edges.

4.4 COMPARISON BETWEEN THE

DIFFERENT CLIQUE POTENTIAL
FUNCTIONS

We have applied the three methods to random rectan-
gles in 100 by 100 images. The unconstrained aﬃnity
matrix has 40000 entries, shift-invariant clique func-
tion ¯f has 1444 entries and triplet clique function g
has 1042568 entries. Several simulations have been run

i

i

i

e
s
o
n
 
g
n
n
a
m
e
r
 
f
o
 
e
g
a
t
n
e
c
r
e
P

200

150

100

50

0
100

No constraint
Translation invariance
Translation invariance on triplet nodes

101

102

size of training set

103

104

Figure 10: Square shape detection and enhancement.
For each simulation, the table indicates the percentage
of remaining noise (100 is the initial amount of noise)
on 2000 testing examples. These results have been
obtained for diﬀerent sizes of training set, according
to three methods: 1- learning on full aﬃnity matrix,
2- invariance by translation, 3- mean on third node
with invariance by translation.

for each training set and the result displayed in ﬁg.10
have been averaged. We noticed a very low standard
deviation on our training sets.

We see that the best results are achieved with the
triplet clique method involving summation of ternary
aﬃnities over a third node. With only 20 training
examples, an average of 75% of the noise was elimi-
nated in the 2000 testing examples. We achieved the
best result with a training data set of 500 squares.
15 iterations were enough to reach energy conver-
gence and it took 4 minutes. This fast convergence
can be explained by the averaging on a third node:
when the aﬃnity between two nodes is updated, all
ternary aﬃnities involving this pair are updated in a
single pass. Also, ternary clique potentials carry out a
stronger, more robust cue than binary aﬃnities.

4.5 RECTANGLE DETECTION ON REAL

IMAGES

This rectangle detection algorithm can be applied di-
rectly on real images, ﬁg.12. We just have to adapt
the ﬁlter parameters to have a good edge extraction.
The amount of noise on real images turns out to be
frequently below the one we used in the learning step,
thus giving those encouraging results.

References

[1] Francis R. Bach and Michael I. Jordan. Learning
spectral clustering. Advances in Neural Informa-
tion Processing Systems (NIPS), 2003.

71Figure 11: Examples of rectangle detection on real images.
Left: edges detected, with arrows indicating orientation (2
opposite polarity hypothesis for each edge). Right: seg-
mentation of foreground edges (in red) versus background
clutter edges (in dark).

[2] Timothee Cour and Jianbo Shi. A learnable spec-
tral memory graph for recognition and segmenta-
tion. Technical Report MS-CIS-04-12, University
of Pennsylvania CIS Technical Reports, Philadel-
phia, PA, June 2004.

Learning to detect natural

[3] Charless Fowlkes, David Martin, and Jitendra Ma-
lik.
image bound-
aries using local brightness, color and texture cues.
IEEE Transactions on Pattern Analysis and Ma-
chine Intelligence(PAMI), 26(5):530–549, 2004.

[4] Marina Meila and Jianbo Shi. Learning segmenta-
tion with random walk. Advances in Neural Infor-
mation Processing Systems (NIPS), 2001.

[5] Andrew Y. Ng, Michael Jordan, and Yair Weiss.
On spectral clustering: Analysis and an algorithm.
Advances in Neural Information Processing Sys-
tems (NIPS), 2002.

[6] Jianbo Shi and Jitendra Malik.

Normalized
cuts and image segmentation.
IEEE Transac-
tions on Pattern Analysis and Machine Intelli-
gence(PAMI), 22(8):888–905, 2000.

Figure 12: Rectangle detection on real images. First col-
umn: image; second column: edges detected; third column:
rectangle detection using the graph. Graph weights are
learned with random rectangles in background noise.

72A Graphical Model for Simultaneous Partitioning and Labeling

Philip J. Cowans

Cavendish Laboratory, University of Cambridge,

Cambridge, CB3 0HE, United Kingdom

Martin Szummer
Microsoft Research

Cambridge, CB3 0FB, United Kingdom

pjc51@cam.ac.uk

szummer@microsoft.com

Abstract

In this work we develop a graphical model for
describing probability distributions over la-
beled partitions of an undirected graph which
are conditioned on observed data. We show
how to eﬃciently perform exact inference in
these models, by exploiting the structure of
the graph and adapting the sum-product and
max-product algorithms. We demonstrate
our approach on the task of segmenting and
labeling hand-drawn ink fragments, and show
that a signiﬁcant performance increase is ob-
tained by labeling and partitioning simulta-
neously.

1 INTRODUCTION

Probabilistic models are usually deﬁned over the
Cartesian product of a number of discrete or contin-
uous one-dimensional spaces. For example, models
performing joint binary classiﬁcation of N objects are
deﬁned over {−1, +1}N . While in many cases it is in-
tractable to explicitly enumerate all possible conﬁgura-
tions, in the case of graphical models where the proba-
bility distribution factors according to the structure of
an undirected graph, message passing techniques such
as the sum-product and max-product algorithms can
be used to render the computation feasible.
In this work, we extend the graphical model formal-
ism to the case of probability distributions deﬁned
over labeled partitions of an undirected graph; in other
words, possible divisions of the graph into sets of ver-
tices referred to as parts, where each part is assigned a
label. An example of a labeled partition is given in Fig-
ure 1. Note that the number of parts varies between
partitions and is usually unknown in advance. Our
method represents partitions directly, rather than in-
corporating part identiﬁers into the labels. We thereby
avoid the degeneracy that diﬀerent permutations of

part identiﬁers represent the same partition (see Sec-
tion 3.4 for a comparison of the two approaches). In
this work we restrict ourselves to binary labels, but
the method can be generalized straightforwardly to
larger label sets. Conversely, unlabeled partitioning
may be viewed as a special case with just one label.
Our model is similar to the Conditional Random Field
(CRF) [2], and allows the probability distribution to
be conditioned on arbitrary observed data. This model
is widely applicable to joint segmentation and classi-
ﬁcation tasks, which are common in computer vision,
handwriting recognition, speech and natural language
processing. The Markov Random Field (MRF), which
is an undirected graphical model whose potential func-
tions do not depend on observed data, is for the pur-
poses of this paper a special case of the CRF, and can
also be extended in the way described below.
Previously, probabilistic models have been used for
graph partitioning, but by using Monte Carlo tech-
niques rather than exact inference [1]. Liu [4] has
performed partitioning, but not using a probabilistic
framework. Other work [7] has extended the CRF to
perform multiple inference tasks simultaneously, but
has not considered partitioning of non-linear graphs.
We begin by describing the full probabilistic model,
then consider representations for labeled partitions
and eﬃcient algorithms for performing the necessary

Figure 1: An example of a labeled partition. Vertices
are partitioned as follows: (1, 2, +), (3, 4,−), (5, 6,−),
(7, +), where the last symbol in each group indicates
the label assigned to that part.

423156773inference tasks. Finally, we describe the application
of our model to the task of parsing hand-drawn ink
diagrams.

2 THE PROBABILISTIC MODEL
Let G be an undirected graph consisting of vertices V
and edges E. We assume that G is triangulated, so that
every cycle of length greater than three is spanned by
a chord. This can always be achieved by adding edges,
but usually at the expense of increasing the maximum
clique size, and therefore computational complexity.
Let S be a partition of G, that is, a set of non-empty
subsets of V, such that each vertex in V is a member
of precisely one subset. Each subset is referred to as a
part of G. In this paper, the term partition will always
refer to a contiguous partition:
Deﬁnition 1. A partition of G is contiguous if and
only if all parts are internally connected.
In other
words, if i and j are vertices contained within the same
part, there exists a path on G between i and j entirely
contained within that part.
A labeled partition of G is represented by Y = (S, y),
where S describes the partition and y ∈ {−1, +1}M
is a vector containing the labels associated with each
part. For example, a partition of three elements into
two parts could be S = {{1}{2, 3}}, y = [+1,−1]. Let
Y be the set of all possible labeled partitions of G. Note
that M, the length of y, is dependent on S. Let ti be
the index of the part to which vertex i is assigned, so
that yti is the label given to that vertex.
In this work, the conditional probability distribution
over Y has the form P (Y | x, θ) =

Y

1

Z (θ)

i∈V

ψ(1)

i

(Y, x; θ) Y

i,j∈E

ij (Y, x; θ) ,
ψ(2)

(1)

i

where x is the observed data, θ is a vector repre-
senting the model parameters collectively, and Z (θ)
is a normalization constant. ψ(1)
are unary potentials
deﬁned for each vertex, and ψ(2)
ij are pairwise poten-
tials deﬁned for each edge. The unary potentials in-
troduce a data-dependent bias towards assigning one
label or the other to each vertex. The pairwise poten-
tials model the compatibility between the parts and
labels of neighboring vertices, and are also data de-
pendent. The dependence of these potentials on x is
through feature vectors, gi and f ij, deﬁned for each
vertex i and edge (i, j) respectively. The potentials
then have the form

(
φ (w+ · gi (x))
φ (w− · gi (x))

(Y, x, θ) =

ψ(1)

i

if yti = +1
if yti = −1

,

(2)

where φ (·) is a non-linear mapping, and w+ and w−
are vectors of feature weights depending on the label
of the appropriate vertex. In this work, we will always
use an exponential non-linearity, φ : x 7→ exp (x), al-
though in general other functions may be used. The
pairwise potentials are deﬁned by

φ(cid:0)vss · f ij (x)(cid:1)
φ(cid:0)vsd · f ij (x)(cid:1) if ti 6= tj, yti = ytj
φ(cid:0)vdd · f ij (x)(cid:1) if ti 6= tj, yti 6= ytj

if ti = tj, yti = ytj

ij (Y, x, θ) =
ψ(2)

(3)
where vss, vsd and vdd are vectors of feature weights to
be used when i and j belong to the same part, diﬀer-
ent parts with the same label, and diﬀerent parts with
diﬀerent labels respectively. The fourth case, corre-
sponding to vertices with diﬀerent labels in the same
part, does not occur by deﬁnition. The parameters
in θ are therefore (w+, w−, vss, vsd, vdd). Note that
there is a redundancy in the weight vectors. In prac-
tice, w− and vdd were constrained to be 0.

2.1 TRAINING

The overall goal of the model above is to predict la-
beled partitions of unseen data. In order to do this, we
must ﬁrst estimate the model parameters, θ. These
parameters are learned from example data. Given a
labeled training examples, (x,Y), the posterior prob-
ability of the parameters is given using Bayes’ rule,

P (θ | x,Y) ∝ P (Y | x, θ) · P (θ) ,

(4)

where P (θ) is a prior distribution over the weights.
The model is trained by ﬁnding the maximum a pos-
teriori weights using a quasi-Newton gradient ascent
algorithm (speciﬁcally, the BFGS method). A signiﬁ-
cant advantage is that the model is convex in the pa-
rameters, meaning that we are guaranteed to ﬁnd the
global maximum using gradient ascent. The gradient
of the log posterior, LP, with respect to a parameter
θk is given by

LP =X

(cid:18) ∂

i∈V

∂θk

∂
∂θk

log (P (θ))

(5)

(cid:29)(cid:19)

log ψ(1)

i −

log ψ(1)

i

(cid:28) ∂

∂θk
+ ∂
∂θk

if θk is a parameter of the unary potentials. The gradi-
ents with respect to parameters of the pairwise poten-
tials have a similar form. It is straigtforward to gener-
alize this expression to handle multiple training exam-
ples. The brackets, h···i, in the second terms repre-
sent expectations with respect to the distribution over
Y given by the current parameter values. This requires
the computation of marginal probability distributions
for individual vertices and pairs of vertices connected

74by an edge. Furthermore, the optimization algorithm
needs to evaluate (1) explicitly, which in turn requires
evaluation of the partition function,

Z (θ) =X

Y

Y

i∈V

(Y, x; θ) Y

i,j∈E

ψ(1)

i

ij (Y, x; θ) . (6)
ψ(2)

Both of these tasks involve summations over subsets
of possible labeled partitions. This summation can be
performed eﬃciently by message passing using a modi-
ﬁed version of the sum-product algorithm. The details
of this algorithm will be given in Section 3 below.

2.2

INFERENCE

In general, we are interested in using the trained model
to group and label unseen data. This is achieved by
ﬁnding the most probable conﬁguration,
Y MAX = arg maxY

(Y, x; θ) Y

Y

ψ(1)

i

i,j∈E

ij (Y, x; θ) .
ψ(2)
(7)

i∈V

As with the partition function, this maximization can
be performed eﬃciently using a version of the max-
product algorithm.

3 OPERATIONS OVER LABELED

PARTITIONS

In Section 2, it was shown that an important part of
both the training and inference processes is the enu-
meration of all possible labeled partitions, in order to
either sum or maximize over them. As in the more
usual case of labeling vertices, explicit enumeration
of all possible values is prohibitively expensive. How-
ever, as we show below, we are able to exploit the
structure of the graph to signiﬁcantly reduce the com-
putational cost, rendering exact inference tractable in
many cases. The derivation below follows the condi-
tions for the possibility of local computation provided
by Shenoy and Shafer [5]. An alternative derivation
however is possible following Lauritzen [3].
If G is a subset of V, we use YG ∈ YG to denote a la-
beled partition of the corresponding induced subgraph.
We deﬁne consistency as follows:
Deﬁnition 2. Labeled partitions YG and YH, of sub-
graphs G and H respectively, are consistent, denoted
YH v YG, if and only if:
1. All vertices appearing in G ∩ H, are assigned the

same label by YG and YH, and

2. All pairs of vertices appearing in G ∩ H are in
the same part in YG if and only if they are in the
same part in YH.

The notation ˆYG (YG∪H) is used to denote the unique
labeled partition of G which is consistent with YG∪H.
The maximal cliques of G are deﬁned in the usual
way, and are denoted C1, . . . , CN . If b and t are two
cliques, and b contains all vertices from t which appear
in cliques other than t, then b is said to be a branch
and t is the corresponding twig.
Following the framework of Shenoy and Shafer, we in-
troduce the notion of a valuation ψ on a subset of V.
In the case of standard belief propagation, valuations
are functions assigning a real, non-negative value to
possible conﬁgurations of subsets of the variables. In
this work, a valuation on a subset G will be deﬁned as
a function mapping YG to the non-negative real num-
bers. VG is the set of all valuations on G. In the case
where the valuation is over the whole of G, the range of
the valuation will be interpreted as being proportional
the probability of the corresponding labeled partition.
In the case of valuations deﬁned over subsets of V the
valuations are referred to as potentials of which those
deﬁned in (1) are an example. We deﬁne two opera-
tions on valuations:

1. Combination: Suppose G and H are subsets of
V and ψG and ψH are valuations on those subsets.
The operation of combination deﬁnes a mapping
⊗ : VG × VH 7→ VG∪H, such that

ψG ⊗ ψH (YG∪H) ,

(cid:16) ˆYG (YG∪H)

ψG

(cid:17) · ψH

(cid:16) ˆYH (YG∪H)
(cid:17)

.

(8)

2. Marginalization: Suppose G and H are subsets
of V such that G ⊆ H, and ψG and ψH are val-
uations as before. Marginalization is a mapping
↓: VH 7→ VG such that

H (YG) , X

↓G

ψ

YHvYG

ψH (YH) .

(9)

NO

A valuation over the whole graph is said to factor if
it can be written as the combination of valuations on
the cliques,

ψ (Y) =

ψi (Yi) ,

(10)

i=1

where i runs over the cliques in G. As combination
allows products of valuations over subsets of a clique
to be written in terms of a single valuation over the
whole clique, the model given in (1), excluding the
partition function, is in this form. Before demonstrat-
ing the possibility of eﬃcient local computation, we
ﬁrst demonstrate that three axioms due to Shenoy and
Shafer are satisﬁed:

75Axiom 1. Commutativity and associativity of
combination. If G, H and K are subsets of V, for
any valuations ψG, ψH and ψK, we have ψG ⊗ ψH =
ψH ⊗ ψG and ψG ⊗ (ψH ⊗ ψK) = (ψG ⊗ ψH) ⊗ ψK.

Proof. Follows directly from the deﬁnition of combi-
nation.

Axiom 2. Consonance of marginalization, If G,
H and K are subsets of V such that K ⊆ G ⊆ H, for
any valuations ψG, ψH and ψK,

= ψ

↓K
H .

(11)

ψ

↓G
H

(cid:16)
(cid:17)↓K
= X
= X

YGvYK

YHvYK

Proof. Writing the marginalization explicitly,
ψH (YH)

ψ

↓G
H

X

(cid:17)↓K

(cid:16)

YHvYG
ψH (YH) = ψ

↓K
H ,

(12)

where the second line follows as for any YH v YK there
is a unique YG such that YG v YK and YH v YG, and
for any YH 6v YK, no such YG exists.
Axiom 3. Distributivity of marginalization over
combination, If G and H are subsets of V, for any
valuations ψG and ψH, (ψG ⊗ ψH)↓G = ψG⊗(ψ
↓G∩H
).
H

Proof. Performing an explicit expansion gives

(ψG ⊗ ψH)↓G = X

(cid:16) ˆYG (YG∪H)
(cid:17)·
(cid:16) ˆYH (YG∪H)
(cid:17)
(cid:16) ˆYH (YG∪H)
(cid:17)

ψH

ψH

ψG

YG∪HvYG

= ψG (YG) · X
= ψG (YG) · X

YG∪HvYG

YHv ˆYG∩H (YG)

ψH (YH) ,

(13)

which is equal to ψG ⊗ (ψ

↓G∩H
H

) by deﬁnition.

3.1 THE SUM-PRODUCT ALGORITHM

In the next two sections we develop an extension of
the sum-product algorithm suitable for probability dis-
tributions over partitions. As with the more usual
form of this algorithm, our method exploits the known
structure of G by passing messages containing the re-
sults of local computations. Our goal is to compute
sums over a subset of all possible partitions, such as
those needed for the partition function, as given in
(6). This task should be contrasted with that of the
usual sum-product algorithm [3], which sums over as-
signments of labels to the vertices. Since we sum over

a diﬀerent domain we will need to modify the mes-
sages passed and the ranges of summation. Later, in
Section 3.3, we will also adapt the max-product algo-
rithm for labeled partitions. Consider a sum of form:

P ∗ (Y) = (P ∗ (Y))↓C1 ,

(14)

fs (Y1) = X

YvY1

where P ∗ is a (possibly unnormalized) probability
distribution1 over labeled partitions of G. Let the
cliques be numbered C1, . . . , CN , such that C1 is the
clique containing the vertices onto which we wish to
marginalize and such that for all k, Ck is a twig in the
graph C1 ∪ C2 ∪ . . . ∪ Ck. Such an ordering is always
possible if G is triangulated. According to Axiom 2,
this can be expressed as

(cid:16)
(P ∗ (Y))↓V\CN(cid:17)↓C1
(cid:17)↓V\CN(cid:17)↓C1
(cid:16)(cid:16) NO
(cid:17) ⊗(cid:16)
(cid:16)(cid:16) N−1O

ψi (Yi)

ψi (Yi)

i=1

i=1

fs (Y1) =

=

=

(15)

ψN (YN )↓CN∩V(cid:17)(cid:17)↓C1

.

In the last step, Axiom 3 has been used. CN is a twig
by construction. Let CB be a corresponding branch,
then CN ∩ V = CN ∩ CB, hence

(cid:16)(cid:16) N−1O

i=1
i6=B

ψi (Yi)

(cid:17) ⊗ ψB (YB)⊗
ψN (YN )↓CN∩CB(cid:17)(cid:17)↓C1

(cid:16)

.

(16)

fs (Y1) =

In other words, the problem can be converted to an
equivalent marginalization over a graph with one less
clique in which the potential for CB has been replaced
according to:

ψB ← ψB ⊗(cid:16)

(cid:17)

↓CN∩CB
N

ψ

.

(17)

By repeatedly eliminating cliques in this way we can
systematically remove cliques until there is only one
remaining, C1. Any further summation which is re-
quired (either to give marginals over a smaller subset
of vertices, or to calculate the partition function) can
be performed explicitly.

3.2 MESSAGE PASSING

The result of the elimination illustrated in (17) can
be interpreted in terms of a message passed from CN

1While our method is applicable to any summation of
this form, we will focus on the application to probability
distributions in this paper.

76to the rest of the graph. Messages are passed between
cliques along edges in a junction tree [3]. Let µi→j (Yj)
be the message passed from Ci to Cj. The form of the
message is a list of labeled partitions of the intersection
Ci ∩ Cj, each of which has an associated scalar value.
The messages are updated iteratively according to the
rule:

µi→j (Yj) ← X

ψi (Yi) Y

µk→i (Yi) ,

(18)

YivYj

k∈N (i)

k6=j

(a)

Potential

(cid:0)ti = tj , yi = yj
(cid:0)ti 6= tj , yi = yj
(cid:0)ti 6= tj , yi 6= yj

(cid:1)
(cid:1)
(cid:1)

ψij
ψij
ψij

Value

0.6
0.4
0.2

(b)

Partition

Label Value

(123)
(123)
(12)(3)
(12)(3)

.
.
.

+
-

+, +
+, -

.
.
.

0.216
0.216
0.096
0.024

.
.
.

(1)(2)(3)

-,-,-

0.064

(c)

with the outgoing messages from a clique being up-
dated once all incoming messages from the other neigh-
boring cliques N (·) have been received. As the junc-
tion tree has no cycles, this process will terminate after
a ﬁnite number of iterations. Having updated all of the
messages, it is then possible to ﬁnd fs using
µk→1 (Y1) .

fs (Y1) = ψ1 (Y1) Y

(19)

k∈N (1)

Having deﬁned the algorithm formally, it is useful to
also give an intuitive interpretation. The message
passed from Ci to Cj can be interpreted as a state-
ment summarizing the values of the ‘upstream’ poten-
tials for labeled partitions which are consistent with
each labeled partition of the separator between Ci and
Cj. See Figure 2 for an example of the message pass-
ing process. As is the case with the usual form of the
sum-product algorithm, the same messages are used
in computing diﬀerent marginals. Marginal distribu-
tions for all cliques can be found simultaneously with
a single bidirectional pass of the message update rule.

3.3 THE MAX-PRODUCT ALGORITHM

Just as is the case for the usual form of the sum-
product algorithm, it is possible to replace the summa-
tion in (14) with a maximization to obtain the max-
product algorithm. This is equivalent to a redeﬁnition
of marginalization to represent the maximum valua-
tion consistent with the sub-partition rather than the
sum over all valuations. This algorithm is used to com-
pute maximizations, for example the conﬁguration of
C1 in the most probable labeled partition,
P ∗ (Y) .

Y MAX

(20)

= arg maxY1

maxYvY1

1

In the context of probabilistic inference, this is nec-
essary when searching for the most probable conﬁg-
uration. Message passing is done in the same way as
described above, with a modiﬁed message update rule.

µi→j (Yj) ← maxYivYj

µk→i (Yi) .

(21)

ψi (Yi) Y

k∈N (i)

k6=j

Partition

Label Value

(23)
(23)

.
.
.

(2)(3)

+
-
.
.
.
-,-

(d)

0.336
0.336

.
.
.

0.272

(a) The
Figure 2: An example of message passing.
junction tree corresponding to G. (b) The potentials,
in this case uniform and independent of data for clar-
ity. (c) The clique potential for the clique consisting
of vertices 1, 2 and 3. (d) The message passed from
(123) to (234), concerning labeled partitions of vertices
2 and 3.

Having updated all of the messages, Y MAX
found using

1

can be

Y MAX

1

= arg maxY1

µk→1 (Y1) .

(22)

ψ1 (Y1) Y

k∈N (1)

To ﬁnd the global maximum conﬁguration, we repeat
the above for all possible roots, and reconstruct the
global partition as the union of the local conﬁgurations
(which will be consistent with one another).
Again, it is instructive to consider the intuitive mean-
ing of the messages.
In this case they can be inter-
preted as statements about the maximum value that
can be achieved ‘upstream’ as a function of the clique
separator conﬁguration. When the next cluster com-
putes its maximum conﬁguration, the contribution of
downstream potentials can therefore be incorporated
from the messages rather than having to be recom-
puted from scratch each time.

3.4 EDGE-DUAL REPRESENTATION

Let us consider two alternative representations which
cast the inference task so that it can be solved us-
ing the standard forms of the sum-product and max-
product algorithms. In the ﬁrst of these techniques,
rather than working with partitions, a ‘part ID’ is as-
signed to each vertex. The corresponding partition is
therefore deﬁned so that contiguous regions with the
same part ID are assigned to the same part. To allow

1,2,32,3,44,53,4,677for labeled partitions, a separate set of part IDs must
be reserved for each label.
This approach has several problems. Firstly, we must
ensure that enough part IDs are available to realize
all possible partitions. Depending on the structure of
G, a lower bound on the minimum number required
is the size of the largest clique.
In practice the re-
quired number will be greater than this. In general,
this means that inference will be signiﬁcantly slower
than the equivalent binary labeling problem.
A more serious drawback of this approach is that it in-
troduces bias into the results; ﬁnding the most proba-
ble assignment of part IDs is not equivalent to ﬁnding
the most probable partition; the latter marginalizes
over the multiple assignments of IDs which correspond
to the same partition.
An alternative representation which avoids these prob-
lems is to use indicator variables, ˇx (Y), for each edge
in G. For binary labels, these variables are over a set
of six values: two states corresponding to segments
belonging to the same part with each label, and four
corresponding to diﬀerent parts with all four combi-
nations of labels. To construct a graphical model for
these variables, we deﬁne the edge-dual graph:
Deﬁnition 3. For any graph G,
the edge-dual
G. Vertices in ˇG are connected by an edge if and only
if all vertices connected to their corresponding edges in
G belong to the same clique.

graph, ˇG =(cid:0) ˇV, ˇE(cid:1) contains one vertex for each edge in

An example of an edge-dual graph is shown in Figure 3.
Every labeled partition of G corresponds to a unique
conﬁguration of the edge-dual vertices, but there are
conﬁgurations of the edge-dual vertices which do not
correspond to labeled partitions. Hence,
Deﬁnition 4. A conﬁguration of the edge-dual ver-
tices is valid if and only if it corresponds to a labeled
partition of G.

Invalid conﬁgurations arise when pairwise constraints
yield contradictory information; following one path be-
tween two vertices on G indicates that they are in the
same part, whereas another path indicates that they

Figure 3: An example of an undirected graph (circular
vertices and light lines) and the corresponding edge-
dual graph (square vertices and heavy lines).

are not, or their labels disagree. It is possible to es-
tablish the validity of a conﬁguration using only cal-
culations local to cliques on ˇG.
Suppose P ∗ (ˇx (Y)) is a probability distribution over
labeled partitions of G as represented by the edge-
dual variables. We are generally interested in opera-
tions such as the summation of P ∗ over all partitions.
Rather than expressing the summation in terms of par-
titions, we can work directly with ˇx, provided that the
summation is limited to those conﬁgurations which are
valid. This can be achieved by introducing an indica-
tor function, I (ˇx), which takes the value 1 if ˇx is valid

and 0 otherwise,X

P ∗ (ˇx (Y)) =X

Y

ˇx

I (ˇx) · P ∗ (ˇx) .

(23)

There is a one-to-one correspondence between cliques
in G and ˇG, so functions which factor according to G
also factor according to ˇG. If P ∗ factors, we can write

X

P ∗ (ˇx (Y)) =X

(cid:18)Y

Y

ˇx

i

(cid:19)

Ii (ˇxi) · ˇψi (ˇxi)

,

(24)

where i ranges over the cliques of ˇG. In (24), the lo-
cal nature of I has been used to factor it as well as
P ∗. The result is a sum over a function which factors
according to ˇG, so it can be found using the standard
sum-product algorithm.
As there is a one-to-one correspondence between valid
edge-dual conﬁgurations, and labeled partitions of G,
this algorithm is in many respects equivalent to that
presented in Section 3.1. However, in two important
respects it is less eﬃcient. Firstly, as the sum includes
edge-dual conﬁgurations which are invalid, the num-
ber of terms in the sum is signiﬁcantly greater. Sec-
ondly, it is necessary to determine the validity of the
current conﬁguration for each term, which introduces
additional overhead. The algorithm presented in Sec-
tion 3.1 may be regarded as an eﬃcient implementa-
tion of this algorithm, where the validity of conﬁgura-
tions is precomputed, and only those which are valid
are included in the sum.

3.5 COMPLEXITY

The dominant factor in the complexity of the mes-
sage passing algorithm is the time taken to process all
possible partitions of the largest clique. Table 1 lists
the number of possible conﬁgurations for the various
cases. It can be seen from the table that the method
described in Section 3 oﬀers a considerable improve-
ment in the complexity of the calculations.

78Table 1: Sizes of the message tables for each of the
methods. (a) Unlabeled Partitions (these are the Bell
numbers).
(b) Binary labeled partitions (c) Binary
labeled edge-dual representation. (d) Binary labeled
part IDs (lower bound).

Clique Size

(a)
(b)
(c)
(d)

2
2
6
6
16

3
5
22
216
216

4
15
94

46656
4096

5
52
454

6.0 × 107
1.0 × 105

6

203
2430

4.7 × 1011
3.0 × 106

n

Bell no. Bn
A001861 [6]
6n(n−1)/2

(2n)n

Table 2: Labeling errors for the three models. Results
are the mean of three cross-validation splits. Relative
diﬀerences are shown between models L and LI, and
between LI and PLI. The mean relative diﬀerences are
aggregations of the diﬀerences for each split, rather
than the diﬀerences between the means for individual
models. This is to reduce the eﬀect of systematic vari-
ation between splits.

L
LI

% ∆ LI/L

PLI

% ∆ PLI/LI

8.5%
4.5%

−48.9% ± 24.9%

2.6%

−42% ± 8%

Figure 4: An example of an undirected graph con-
structed from the input data in which each vertex rep-
resents an ink fragment.

4 APPLICATION TO INK DATA

In this section we apply the algorithm developed in
Section 3 to the task of parsing hand-drawn ink dia-
grams, focusing on the particular problem of grouping
electronic ink strokes into perceptually salient objects
and labeling the resulting groups. We demonstrate our
approach on organization charts such as that shown in
Figure 5, where objects are labeled as either contain-
ers or connectors. However, the method is general and
may be applied to a wide variety of related problems.

Figure 5: Example labelings and groupings:
the
most probable partition and labeling using model PLI.
Heavy lines indicate fragments which have been classi-
ﬁed as containers and lighter lines indicate connectors.
Groups of fragments which belong to the same part
are outlined using a dashed box. (Image rotated from
original.)

tion. This approach gave a mean tree-width of 4.0
when applied to our training database. By modify-
ing the algorithm to constrain the tree-width, an ad-
justable compromise between speed and accuracy can
be obtained.

4.1 PRE-PROCCESSING

4.2 FEATURES AND PRIORS

The input data is a set of ink strokes, which may span
multiple objects. The ﬁrst stage is to split the strokes
into fragments, which are assumed to belong to a single
object, by dividing each stroke into sections which are
straight to within a given tolerance.
Having fragmented the strokes, we build an undirected
graph, G, containing one vertex for each ink fragment
(See Figure 4). This is the graph which will be parti-
tioned to obtain the grouping of ink fragments. In our
algorithm, G is constructed by ﬁrst building a candi-
date graph (which is not necessarily triangulated) by
connecting all pairs of fragments satisfying an appro-
priate distance constraint. Additional edges are added
to create a triangulated graph, and pairwise feature
vectors are generated for all edges on the new graph,
including those which were added during triangula-

We chose features to reﬂect the spatial and temporal
distribution of ink strokes, for example lengths and an-
gles of fragments, whether two fragments were drawn
with a single stroke, and the temporal ordering of
strokes. We also used a number of ‘template’ features
which were designed to capture important higher level
aspects of the ink, such as the presence of T-junctions.
We use Gaussian priors, with correlations speciﬁed be-
tween the priors for weights corresponding to related
features. In total 61 unary features and 37 pairwise
features were used.

4.3 RESULTS

To test the performance of the method, we used a
database of 40 example diagrams, consisting of a total

79of 2157 ink fragments. Three random splits were gen-
erated, each consisting of 20 examples used for training
and 20 used for evaluation. Training was performed by
ﬁnding the MAP weights as described in Section 2.1.
The models were tested by ﬁnding the most probable
partition and labeling as described in Section 2.2, and
counting errors made against ground-truth data.
For comparison, we also consider two related models
which model labeling only, without considering parti-
tioning. The ﬁrst of these models has a similar form
to that described in Section 2, but uses pairwise po-
tentials given by

(
φ(cid:0)vs · f ij (x)(cid:1)
φ(cid:0)vd · f ij (x)(cid:1)

if yi = yj
if yi 6= yj

,

(25)

ψ(2)
ij (y, x, θ) =

where vs and vd are weights corresponding to vertices
i and j having the same and diﬀerent labels respec-
tively. The second related model does not use pairwise
potentials at all — ink fragments are labeled indepen-
dently of the other labelings. In the following, we refer
to the full model performing labeling and partition-
ing as model PLI. LI is the model performing labeling
only with pairwise potentials, and L is the model with
unary potentials only.
Labeling error rates are shown in Table 2. Figure 5
shows the output of the algorithm on an example dia-
gram. Further examples are available online at http:
//research.microsoft.com/∼szummer/aistats05/.

5 DISCUSSION

The results given in Section 4.3 show that our ap-
proach is capable of providing high-quality labeled par-
titions. The data also illustrate an important point;
simultaneous labeling and partitioning produces a sig-
niﬁcant improvement in labeling performance. This
is easily understandable — the constraint that ver-
tices within the same part must be labeled identically
provides strong evidence for the labeling part of the
algorithm, and the boundaries between regions of dif-
ferent labels are strong candidates for part boundaries.
Hence the two aspects of the algorithm reinforce each
other.
There are a number of extensions to the model which
have not been discussed in this paper. The most
straightforward is the incorporation of other local con-
straints, such as known labels of particular vertices, or
information concerning the relationship of two vertices
in the partition. These can easily be included through
additional potentials which assign zero probability to
conﬁgurations violating the constraints, and in the
context of the ink parsing provide a valuable method
for incorporating user feedback.
It seems that more

complex information, such as priors over the number
of parts, can be incorporated by increasing the amount
of information passed in the messages.
In some applications the maximum clique size may be
too large for exact inference to be feasible, motivating
approximate methods. Monte Carlo techniques have
already been applied to problems of this sort [1], but it
is desirable to apply alternative approximations such
as loopy belief propagation, variational inference or
expectation propagation.

6 CONCLUSION

We have presented a probabilistic model over labeled
partitions of an undirected graph, and have shown
that the structure of the graph may be used to eﬃ-
ciently perform exact inference with message passing
algorithms. We have demonstrated the application of
the model to the task of parsing hand-drawn diagrams.
Our experiments illustrate that it is possible to obtain
high-quality results using this technique. The results
obtained prove that in our applications, labeling ac-
curacy is improved by performing partitioning at the
same time.

Acknowledgements

We would like to thank Thomas Minka, Yuan Qi and
Michel Gangnet for helpful advice and discussion, and
for providing excellent software that allowed the work
presented in this paper to be completed. We are
also grateful to Hannah Pepper for collecting our ink
database.

References

[1] A. Barbu and S. Zhu. Graph partition by Swendsen-

Wang cuts. In ICCV, 2003.

[2] J. Laﬀerty, A. McCallum, and F. Pereira. Conditional
random ﬁelds: Probabilistic models for segmenting and
labeling sequence data. In ICML, 2001.

[3] S. Lauritzen. Graphical Models. Oxford University

Press, 1996.

[4] X. Liu and D. Wang. Perceptual organization based on

temporal dynamics. In NIPS, volume 12, 2000.

[5] P. Shenoy and G. Shafer. Axioms for probability and
belief-function propagation. In Readings in uncertain
reasoning, Morgan Kaufmann, pages 575–610, 1990.

[6] N. Sloane. The On-Line Encyclopedia of

Integer
http://www.research.att.com/

Sequences, 2004.
projects/OEIS?Anum=A001861

[7] C. Sutton, K. Rohanimanesh, and A. McCallum. Dy-
namic conditional random ﬁelds: Factorized probabilis-
tic models for labeling and segmenting sequence data.
In ICML, 2004.

80Restructuring Dynamic Causal Systems in Equilibrium

Denver Dash
Intel Research

3600 Juliette Lane, SC12-303,
Santa Clara, CA 95054, USA

denver.h.dash@intel.com

Abstract

In this paper I consider general obstacles to
the recovery of a causal system from its prob-
ability distribution. I argue that most of the
well-known problems with this task belong
in the class of what I call degenerate causal
systems.
I then consider the task of dis-
covering causality of dynamic systems that
have passed through one or more equilibrium
points, and show that these systems present
a challenge to causal discovery that is fun-
damentally diﬀerent from degeneracy. To
make this comparison, I consider two oper-
ators that are used to transform causal mod-
els. The ﬁrst is the well-known Do operator
for modeling manipulation, and the second
is the Equilibration operator for modeling a
dynamic system that has achieved equilib-
rium.
I consider a set of questions regard-
ing the commutability of these operators i.e.,
whether or not an equilibrated-manipulated
model is necessarily equal to the correspond-
ing manipulated-equilibrated model, and I
explore the implications of that commutabil-
ity on the practice of causal discovery.
I
provide empirical results showing that (a)
these two operators sometimes, but not al-
ways, commute, and (b) the manipulated-
equilibrated model is the correct one under
a common interpretation of manipulation on
dynamic systems. I argue that these results
have strong implications for causal discovery
from equilibrium data.

1 Introduction

Causal Discovery refers to a special class of statisti-
cal analysis that seeks to infer, from a set of data,
information about causal relations between variables.

There has been much success on the topic of causal
discovery in the past decade in Artiﬁcial Intelligence
[Spirtes et al., 2000; Verma and Pearl, 1991; Hecker-
man et al., 1999; Tian and Pearl, 2001], building on
structural-equation modelling techniques originating
in early econometrics [cf., Simon, 1953; Wold, 1954].
There are, as one might expect, many diﬃculties with
inferring reliable causal relationships from data. La-
tent common causes confounding relations between the
observed variables, nonlinearity, acyclicity, and viola-
tions of faithfulness due to the cancelling of multiple
causal paths are just a few.
Identifying prospective
pitfalls such as these is the critical ﬁrst step to devel-
oping techniques to handle them in a principled way.
This paper exposes another obstacle to causal discov-
ery that is likely prevalent and important, but is not
currently being addressed by causal discovery research.
I describe this event as a violation of equilibration-
manipulation commutability (or EMC violation,
for
short), for reasons that I hope to make clear shortly.
I show that EMC violation occurs in static systems,
but when those systems have an underlying dynamics
which have passed through some equilibrium points.
I illustrate the existence of EMC violation by exam-
ple. Then as further validation, I provide empirical
results showing that EMC violation occurs in prac-
tice, and its occurrence depends on the time-scale at
which the data is being collected relative to the impor-
tant time-scales of the underlying dynamic systems. I
argue that, since many real-world static systems are
essentially equilibrium points of underlying dynamic
systems, EMC violation is likely to be a common oc-
currence. I also argue that one can reduce the chance
of an EMC violation when building causal models by
taking care when choosing the set of variables to in-
clude in one’s model.
In Section 2, I deﬁne some background concepts and
explore known obstacles to causal discovery; in Sec-
tion 3, I show a motivating example of a dynamic
causal system going through equilibrium, I deﬁne the

81EMC property and show why it is important; in Sec-
tion 4 I show empirically how an EMC violating system
can impact causal discovery in practice; in Section 5
I sketch two theorems that show suﬃcient conditions
for systems to violate and obey EMC, and ﬁnally I
conclude in Section 6.

2 Background Concepts

In this section I deﬁne a causal system, I explore known
obstacles to causal discovery, I introduce the EMC
questions and I demonstrate why these questions are
important.

2.1 Causal Discovery

I deﬁne a causal system [c.f., Pearl, 2000] in terms of
a set of structural equations:

Deﬁnition 1 (causal system) A causal
system
over a set of variables V is a 4-tuple (cid:104)U, V, E, φ(cid:105),
where U is a set of random variables that are deter-
mined outside the system (“exogenous variables”),
V = {V1, V2, . . . Vn} is a set of n variables determined
by the system (“endogenous variables”), E is a set
of n equations, and φ : V → E is an onto mapping
such that for every Vi ∈ V, φ(Vi) can be written as
Vi = fi(Pai, U(cid:48)), where Pai ⊆ V \ {Vi}, U(cid:48) ⊆ U, and
fi is a function.

A causal system deﬁnes a directed graph over variables
in V as follows: For each Vi, let φ(Vi) be written as
Vi = fi(Pai, U(cid:48)), and draw an arc from all variables
i ∈ Pai ∪ U(cid:48) to Vi. A graph constructed in this way
P j
is called a causal graph, and if P j
is a parent of Vi
i
in this graph then P j
is a cause of Vi, and Vi is an
i
eﬀect of P j
i . All Bayesian networks can be mapped
onto a causal system [Druzdzel and Simon, 1993], but
the converse is not true, e.g., causal systems can deﬁne
cyclic graphs.
All randomness in a causal system is induced by the ex-
ogenous variables, which are assumed to be controlled
by external forces and therefore are treated as random
variables. To say that an equation φ(Vi) is determinis-
tic means that U(cid:48) = ∅, in which case, Vi is a determin-
istic function of Pai. Because the variables in U are
random variables, and because in general the variables
in V depend on U, the causal system S = (cid:104)U, V, E, φ(cid:105)
will deﬁne a probability distribution P over the set V.
A common assumption is to assume that each endoge-
nous variable Vi in a causal system S depends on a
single exogenous variable Ui and for all i, j, Ui is in-
dependent of Uj.
Causal systems such that all fi functions are linear
and all Ui ∈ U are normally distributed are called lin-

ear structural equation models, and for decades these
have been widely used in econometrics and the social
sciences to model causality [c.f., Simon, 1953; Wold,
1954].
Causal discovery or causal inference is the task of ana-
lyzing a probability distribution P , and possibly other
background information I, to reconstruct the causal
system S that generated P . In practice, however, even
if P is known exactly, causal inference can do no bet-
ter than identifying the set of causal models that deﬁne
distributions identical to P that are consistent with I.
Probability distributions which do not uniquely deﬁne
a causal system are the most commonly observed ob-
stacles to causal discovery. I call a causal system for
which that is the case degenerate. Speciﬁc instances
of features of causal systems that lead to degenerate
probability distributions have been identiﬁed and are
discussed in the next section.

2.2 Degenerate Causal Systems

Examining the conditional
independence relations
present in the probability distribution is a key method
for causal discovery. Obviously, it is the presence of
these relations that increases the speciﬁcity of the dis-
tribution and makes identiﬁcation of causal relations
possible. One of the most general problems one en-
counters when trying to perform causal inference from
independence relations is a lack of faithfulness:

Deﬁnition 2 (faithfulness) A probability distribu-
tion P (V) over a set of variables V is faithful to a
directed graph G over V if, for every conditional in-
dependence relation (V1 ⊥ V2 | V(cid:48)) in P , there exists
a d-separation condition (V1 ⊥d V2 | V(cid:48)) in G and
vice-versa1, for V1, V2 ∈ V and V(cid:48) ⊂ V.

If P is faithful to G then G is called a perfect map or p-
map of P . P is called causally faithful to G when P is
faithful to G, and G is a causal graph. Speciﬁc cases in
which unfaithful distributions can be generated from
real causal systems have been identiﬁed in Spirtes et
al. [2000]. Two in particular are:

• Determinism: when a variable in a causal sys-
tem depends deterministically on other variables.
For example, in the causal graph with three vari-
ables {A, B, C} such that: A → B → C and
A → C, if C is a deterministic function of A, then
C is independent of B given A although that d-
separation condition does not exist in the causal
graph.

1Some deﬁnitions of faithfulness do not require the con-

verse.

82• Cancelling causal paths: when two or more
causal paths exactly cancel out. This event can
make two or more variables non-correlated al-
though they are causally connected. Although
this is possible in principle, Spirtes et al. [2000]
argue that its occurrence has Lebesque measure
zero.

Other reasons for causal degeneracy are:

• Statistical Indistinguishability: when there
exist other causal structures that have the same
set of adjacencies and v-structures.

• Lack of causal suﬃciency. A common cause
C ← A → B will cause a dependence between C
and B in the probability distribution over these
variables.
If A has been marginalized out of
the distribution P , it becomes diﬃcult to decide
whether there is a direct causal arc between C
and B given only P .

• cyclic causality: when a directed cycle exists
in the causal graph. Although the physical rel-
evance of these systems can be argued, they are
not forbidden by deﬁnition, and the implications
of their existence on independence relations is not
fully explored.

One mitigating fact for all of these obstacles is
that their occurrences are all detectable post-causal-
discovery, at least sometimes: Determinism and can-
celling causal paths will be detectable in the param-
eters of the model; statistical indistinguishability will
be identiﬁable from the structure of the model; hid-
den common causes and cyclic causality can sometimes
be detected: for example, when their presence causes
many v-structures, the PC algorithm for causal discov-
ery [Spirtes et al., 2000] can produce bi-directed arcs
or cycles, respectively.
Degenerate causal systems are on one hand problem-
atic, but on the other hand are easy to understand.
In the next section I introduce a qualitatively diﬀerent
type of obstacle to causal discovery which, in the au-
thor’s opinion, is much less transparent and therefore
more interesting than causal degeneracy. I call it “vio-
lation of Equilibration-Manipulation Commutability.”

3 The EMC Property

When a causal system is based on a set of diﬀeren-
tial (or diﬀerence) equations, the probability distribu-
tion it speciﬁes will not be static, but instead will be
a function of time. The evolution of the probability
distribution should be predictable. For example, con-
sider the following discrete-time ﬁrst-order diﬀerence

system where the change, ∆X, in some variable X, is
determined by a linear balance of factors:

X 0 = x0
1 = α1U 0
F t
2 = α2X t + U 0
F t

1

2

∆X t = α3F t
X t+1 = X t + ∆X t,

1 + α4F t

2 + U 0

x

(1)
(2)
(3)
(4)
(5)

2 , U 0

1 , U 0

where all αi are constants. In this system, I have as-
x} are
sumed that the exogenous variables {U 0
static throughout time (which is why they have a ﬁxed
t = 0 superscript). The causal graph for this system
unrolled out to three time slices is shown in Figure 1-
(a). The dotted boxes around F1, F2 and ∆X are
used to denote the fact that the exogenous variables
are static through time and are thus parents of those
variables in each time slice. For conciseness I will use a
shorthand graph, based on the notation of Iwasaki and
Simon [1994], where arcs that occur through time are
shown with dotted lines, instantaneous arcs are shown
in solid, and static exogenous arcs shown dashed. The
corresponding shorthand graph for our toy example is
shown in Figure 1-(b). It should be emphasized that,
although the shorthand version of this graph contains a
directed cycle, it represents an acyclic dynamic graph.
Sometimes I may also drop the exogenous variables

(a)

(b)

Figure 1: (a) A toy example dynamic causal graph
based on diﬀerence equations and with static exoge-
nous variables, and (b) the same graph in “shorthand”
form.

from this graph to emphasize the endogenous causal
relations.
If one considers what the probability distribution over
the endogenous variables of this system at the nth time
slice will look like, one needs only to expand this sys-
tem out n slices and marginalize out all variables from
previous time-slices to see the causal structure and
to generate the probability distribution of the vari-
ables at the nth slice. The problem, however, is, if
one waits long enough, it may very well be that this
system achieves equilibrium, at which time there will

X0(cid:39)X0F10(cid:39)X1F11(cid:39)X2F12Ux0U10F20F21F22X1X2U20X(cid:39)XF1F2Ux0U10U2083be a qualitative change in the probability distribution.
Speciﬁcally, at equilibrium, ∆X t = 0, so the system
of equations reduces to:

of the equilibration operator is beyond the scope of this
paper (see Iwasaki and Simon [1994] for more details),
a sketch of the operator is as follows:

F1 = α1U 0
1
F2 = −α3F1/α4 − U 0
X = F2/α2 − U 0

x

2

(6)
(7)
(8)

In the distribution deﬁned by this system, although
2 is a parent of F2 in the original causal system, it is
U 0
marginally independent of F2 in the equilibrium equa-
tion system. This fact is obvious by looking at the
independence graph of this system shown in Figure 2,
and it can also be easily derived from the equation
system assuming independent exogenous variables.

Figure 2: The independence graph of the equilibrium
distribution deﬁned by our toy causal system. Al-
though U 0
2 is a parent of F2 in the original dynamic
system, it is marginally independent of F2 in the equi-
librium distribution.

This example illustrates a novel unanswered question
associated with dynamic causal systems. Namely, if a
causal system is a set of equations with some struc-
ture imposed upon it, and if, when a non-structural
equation system goes through equilibrium, the equa-
tions go through a qualitative change, how should the
causality of a system passing through an equilibrium
point be modelled? That is, if some equations and
variables are dropping out, how should the remaining
equations be structured? In the above example, Equa-
tion 4 was originally used to determine ∆X; however in
equilibrium ∆X has dropped out and Equation 4 has
changed into Equation 7 and now “determines” F2. In
fact, if one were to learn a causal graph given the equi-
librium distribution, obviously one would in general
recover a totally diﬀerent causal structure than would
be recovered from the non-equilibrium system at some
arbitrary time slice n. I show this fact empirically in
Section 4.
It has been argued by Iwasaki and Simon [1994] that
the causal relations governing a dynamic system can
change as the time-scale of observation of the system
is increased. In particular, they introduce the Equili-
bration operator that they argue produces the causal
relations of a system in equilibrium given the dynamic
(non-equilibrium) causal system. A detailed treatment

Deﬁnition 3 (Equilibration (sketch)) Let M =
(cid:104)U, V, E, φ(cid:105) be a causal model, and let X ∈ V be a
dynamic variable in M. Equil(M, X) is a causal model
M(cid:48) = (cid:104)U(cid:48), V(cid:48), E(cid:48), φ(cid:48)(cid:105) that is deﬁned by:
1. V(cid:48) is equal to V with all of X’s derivatives re-

moved.

2. E(cid:48) is equal to E with all integration equations re-

moved, and

3. φ(cid:48) : V(cid:48) → E(cid:48) is an onto mapping.

In general, such an operation may not deﬁne a unique
mapping φ(cid:48); however, in the remainder of the paper
I assume that φ(cid:48) is unique and only present examples
for which that is the case.
As we have done with our toy example, the equilibra-
tion operator formally makes the assumption of equi-
librium which causes a modiﬁcation to the equations
of the system, then it recovers a structure consistent
with the remaining set of equations. In many cases,
there is a unique (independence) structure remaining
(as in Figure 2). Iwasaki and Simon argue that under
these circumstances that structure must be the causal
structure of the system under equilibrium.
The Do operator, Do(M, U = u), is another operator
of a causal system that transforms a causal model M
to a new causal model M(cid:48) where a subset of variables
U in M(cid:48) are ﬁxed to speciﬁc values independent of
the causes of U. On the other hand, the Equilibra-
tion operator, Equil(M, X), transforms the model M
with a dynamic (time-varying) variable X to a new
causal model M(cid:48) where X is static. This paper con-
siders the relationship between these two operators. In
particular I am interested in the what I call the Equi-
libration Manipulation Commutability property, or the
EMC property for short:

Deﬁnition 4 (EMC Property) Let M (V) be a
causal model over
M satisﬁes
the Equilibration-Manipulation Commutability (EMC)
property iﬀ

variables V.

Equil(Do(M, U = u), X) = Do(Equil(M, X), U = u),
for all U ⊆ V and all X ∈ V.

In this paper, I consider the following set of questions
(hereafter referred to as the EMC questions):

1. Does the EMC property hold for all dynamic

causal models?

XF1F2Ux0U10U20842. Does the EMC property hold for any dynamic

causal models?

3. Under what conditions is the EMC property guar-

anteed to hold?

4. Under what conditions is the EMC property guar-

anteed to be violated?

5. In general, is it sensible to reason about causal-
ity in a dynamic system that has passed through
some equilibrium points?

These questions are important for at least the follow-
ing reason: Very often in practice a causal model is
ﬁrst built from either data or knowledge of equilibrium
relationships, and then causal reasoning is performed
on that model. This common approach takes path A
in Figure 3. When a manipulation is performed on a

I performed numerical simulations of a dy-
studies.
namic system to demonstrate that as the time scale
was increased enough so that an equilibration could
occur, the causal structure that was learned from data
corresponds to the structure obtained by applying the
Equilibration operator to the dynamic model. This
fact is signiﬁcant because it indicates that whenever a
causal structure that is learned from equilibrium data
is used for causal reasoning, then Path A of Figure 3
is being taken: if the EMC property does not hold for
the model being used then subsequent causal reasoning
will produce incorrect results.
Consider the causal system of ﬁve variables {Qin,
Qout, D, K, P} deﬁned by Equations 9–13 below.

K = K0
Qin = Q0
˙P = α2(α4D − P )

˙Qout = α3(α1KP − Qout)

˙D = α0(Qin − Qout)

(9)
(10)
(11)
(12)
(13)

Figure 3: The EMC Questions consider under what
conditions the Do operator commutes with the Equili-
bration operator operating on a dynamic causal model
S.

system, however, the state of the system in general be-
comes “shocked” taking the system out of equilibrium,
a situation which is modelled by path B in Figure 3.
The validity of the common approach of taking path
A thus hinges on the answers to the EMC Questions.
This paper primarily answers EMC Questions 1, 2,
and 5. The toy example I prove by example and by
empirical tests that the answer to Question 1 is “No”
and that of Question 2 is “Yes”. These results in turn
implies that the answer to Question 5 is “Sometimes”.
The answers to Questions 3 and 4 are addressed in
Dash [2003], but I will sketch those results here as
well.

4 Discovery from Data: Empirical

Results

The previous section presented an example which im-
plied that the answer to EMC Question 1 is “no”. This
section addresses the EMC Questions using empirical

where ˙Qout,
˙D and ˙P are the ﬁrst time-derivatives of
Qout, D and P , respectively, and αi : i ∈ {0, 1, . . . , 4}
are constants.
This system was taken from Iwasaki and Simon [1994].
To give some physical intuition, it roughly approx-
imates a ﬁlling-bathtub where water is entering the
bathtub from the faucet at a rate Qin liters per sec-
ond and is exiting the drain at a rate Qout liters per
second. The pressure of the water at the base of the
drain is P , the depth of the water is D, and the diam-
eter of the drain is K. In this system Qin and K are
exogenous and the remaining variables are dynamic.
The causal graph of this system is shown in Figure 4.

Figure 4: The dynamic causal graph S0 of the bathtub
system.

This system has three dynamic variables, and therefore
three possible equilibrations, corresponding to the oc-
˙Qout = 0, and ˙D = 0. When these
currence of
conditions occur, Equations 11, 12, and 13 reduce to
the equilibrium relations given by Equations 14–16,

˙P = 0,

EquilibrationSS~ManipulationSˆEquilibrationS~ˆManipulationSˆ~=?ABPPDDQQQKinoutout                                                                                                                                            &&&85respectively:

P = ρgD

Qout = α1KP
Qin = Qout

(14)
(15)
(16)

This system has many potential equilibrium causal or-
derings depending on the relative time scales of the
three variables P , Qout and D, and depending on the
time scale at which the system is observed.
If, for
example, P and Qout both reach equilibrium much
sooner than D, and the system is observed before D
has reached equilibrium but after P and Qout, then
Equations 11 and 12 get replaced by Equations 14 and
15, respectively. The causal ordering of this system is
shown in Figure 5.

Figure 5: The causal ordering of the bathtub system
when P and Qout have been equilibrated but not D.

Because the system of Figure 4 involves three dynamic
variables, there exist three important time-scales for
this system, controlled by the inverse of the coeﬃ-
cients: τD ∝ 1/α0, τP ∝ 1/α2, and τQ ∝ 1/α3, for
D, P and Qout respectively. If τP (cid:191) τQ (cid:191) τD, then
there will exist four possible equilibrium causal struc-
tures learned from data depending on the time, τ, at
which the data was observed. These four structures
(over variables V = {Qin, Qout, P , T , K}) are shown
in Figure 6. At τ = 0 each of the ﬁve variables in

τ = 0
τ (cid:39) τP

τ (cid:39) τQ

τ >∼ τD

Figure 6: The bathtub system has four correct equilib-
rium structures depending on the time scale at which
the system is observed.

V are given by their initial conditions and so are ex-
ogenous; in this case S1 will be the structure learned

from data. After enough time has passed for P to equi-
librate (τ (cid:39) τP ), then Equation 11 reduces to Equa-
tion 14, and the structure S2 will result. After τ (cid:39) τQ,
enough time has passed for Qout to equilibrate, and
Equation 12 reduces to Equation 15, resulting in the
structure S3. Finally, after τ > τD, enough time has
passed for D to equilibrate and Equation 13 reduces
to Equation 16, leading to a drastic restructuring of
equations and resulting in model S4.
I simulated learning over several time-scales for the
ﬁlling-bathtub system. The following values for con-
stants were used: α1 = 1, α0 = 0.005, α2 = 0.05, and
α3 = 0.01. All variables were initialized from the uni-
form distribution over the interval (0, 1). Independent
Gaussian error terms with mean 0 were added to each
derivative variable. The error terms for ˙D and ˙Qout
had standard deviation equal to 0.01, and ˙P had stan-
dard deviation equal to 0.5.
I assumed the bathtub
was inﬁnitely high (no bound on D was enforced), so
given these constants, an equilibrium was guaranteed
to exist.
A database of N = 10000 records was generated for
each of the 29 time-scales given in the set T = {0−10,
20, 30, 40, 50, 80, 100, 125, 150, 200, 250, 300, 500,
750, 1000, 1250, 1500, 1750, 2000}, and for each of
these databases the PC algorithm was run to retrieve a
causal graph. A modiﬁed version of PC was used which
forbade cycles or bi-directional arrows and random-
ized the order in which independencies were checked
[Dash and Druzdzel, 1999]. Data for each variable took
on a continuous range of values, and in all cases the
Fisher’s-z statistic was used to test for conditional in-
dependence using a signiﬁcance level of α = 0.05.
I restricted structure learning to the variables {D, P ,
Qout, Qin and K}, namely the variables relevant to
the static analysis of this system. This was performed
50 times for each time scale, and the number of times
the pattern corresponding to the graphs in Figure 6
were exactly recovered was counted.
The normalized results, showing the empirical proba-
bility of retrieving the four structures as a function of
the time scale, are shown in Figure 7. For example,
when the system is observed just one time step away
from the initial conditions, Figure 7 shows that struc-
ture S2 was learned around 45% of the time, structure
S1 was recovered around 6% of the time, structure
S3 was discovered less than 5% of the time, and some
other structure was learned the remainder (about 44%)
of the time. The time-scales 20 ≤ τ ≤ 750 are excluded
from this ﬁgure—they produced empirical probabili-
ties of 0 for all four structures. These results show con-
vincingly that as the time-scale increases, the learned
causal structure changes in the order predicted by the

PDDQQKinout                                                                                                                   &4321       :                                                      :                                                      :                                                      :                                               SKQPDQSKQPDQSKQPDQSKQPDQoutinoutinoutinoutin86a variable V ∈ V is equilibrated in M: M˜v =
Equil(M, V ). I assume that M˜v is unique.

Theorem 1 (EMC violation) If both M and M˜v
are recursive (have acyclic graphs) and there exists any
F ∈ Fb(V )M such that F ∈ V(cid:48) then Do(M˜v, Y ) (cid:54)=
Equil(Do(M, Y ), V ) for any Y ∈ V.

For example, in Figure 6, the graph that results when
D is equilibrated contains variables that are in the
feedback set of D, so the bathtub system violates EMC
when D is equilibrated.

Theorem 2 (EMC obeyance) Let ∆nV
the
highest derivative (diﬀerence) of V in V. If both M
and M˜v are recursive (have acyclic graphs) and V ∈
Pa(∆nV ), then Do(M˜v, Y ) = Equil(Do(M, Y ), V ).

be

in Figure 4, Pa( ˙P ) = {P} and
For example,
Pa( ˙Qout) = {Qout}, so the bathtub system will obey
EMC when either of these variables are equilibrated,
as seen in Figure 6.

6 Conclusions

The results of this paper have important consequences
for causal discovery. In particular, they emphasize the
importance of considering the time-scale of the data
being used for causal discovery.
If data is recorded
of a system for which some variables have achieved
equilibrium, then learning a causal graph and using it
to predict the eﬀects of manipulating variables in the
model amounts to taking path A in Figure 3; however,
path B is the correct one to take: if the EMC property
does not hold for that model, then incorrect inferences
could result.
The fact that taking path A in Figure 3 produces pre-
dictions that diﬀer from path B requires us, if we in-
tend to perform causal reasoning with our model, to
either ensure that we are taking path B or ensure that
we are dealing with models that obey the EMC prop-
erty. Currently, most work regarding the discovery or
building of causal models takes path A and pays no
regard to the EMC property.
I hope that this work
will bring attention to this fact and help to rectify it.
It is a valid question to ask why the EMC property is
useful at all. That is, why treat an equation system
that has passed through equilibrium as causal? The
answer to that question lies in the extreme diﬃculty
of knowing what the important time-scale of an un-
known causal system might be. On top of that, to
break a system down to its ﬁnest time-scale often in-
volves modeling the system in intractable detail. For
example, if it were necessary to model the microstates

Figure 7: As the time step is varied, each of the four
equilibrium structures can be recovered in sequence.

equilibration operator.
It is easy to verify that the EMC property holds
when only P or Qout are equilibrated and any of
these ﬁve variables are manipulated (by verifying
that manipulating any variable in S1 or S2 results
in the same graph as manipulating them in Fig-
ure 4 then equilibrating). On the contrary,
it is
easy to verify that when D is equilibrated, the EMC
property is violated:Do(Equil(S0, D), D) corresponds
to S4 with the arc from P to D removed; whereas
Equil(Do(S0, D), D) (constructed by applying the Do
operator to S0 and then equilibrating all remaining
dynamic variables) corresponds to S3.

5 Theoretical Results: EMC

Questions 3 and 4

The results from Section 4 show that in some cases
the EMC property is preserved, while in others it is
not. While it is beyond the scope of this paper to
address the precise conditions when EMC will or will
not be violated, I will brieﬂy sketch in this section two
results from Dash [2003] with proofs omitted. The ﬁrst
states conditions for which EMC is guaranteed to be
violated, the second states conditions for which EMC
is guaranteed to be satisﬁed.
These results involve the concept of a feedback set. A
feedback set of a variable X in a causal model is the set
of variables that are both ancestors and descendants
of X in the shorthand causal graph. For example, in
Figure 4, the feedback variables of D are ˙P , P ,
˙Qout,
Qout and ˙D. I let Fb(X)M denote the set of feedback
variables of X in model M.
For the following two theorems, we consider a dy-
namic causal model M = (cid:104)U, V, E, φ(cid:105) and let M˜v =
(cid:104)U(cid:48), V(cid:48), E(cid:48), φ(cid:48)(cid:105) denote the graph that results when

Change in Structure over Time Scale for Bathtub Model00.10.20.30.40.50.60.70.80.9012345678910001250150017502000Time StepProbability of Recovering StructureS1S2S3S487Ninth Annual Conference on Uncertainty in Artiﬁ-
cial Intelligence (UAI–93), pages 3–11, San Fran-
cisco, CA, 1993. Morgan Kaufmann Publishers.

David Heckerman, Christopher Meek, and Gregory F.
Cooper. A bayesian approach to causal discovery.
In Clark Glymour and Gregory F. Cooper, editors,
Computation, Causation, and Discovery, chapter
four, pages 141–165. AAAI Press, Menlo Park, CA,
1999.

Yumi Iwasaki and Herbert A. Simon. Causality and
model abstraction. Artiﬁcial Intelligence, 67(1):143–
194, May 1994.

Judea Pearl. Causality: Models, Reasoning, and Infer-
ence. Cambridge University Press, Cambridge, UK,
2000.

Herbert A. Simon. Causal ordering and identiﬁability.
In William C. Hood and Tjalling C. Koopmans, ed-
itors, Studies in Econometric Method. Cowles Com-
mission for Research in Economics. Monograph No.
14, chapter III, pages 49–74. John Wiley & Sons,
Inc., New York, NY, 1953.

Peter Spirtes, Clark Glymour, and Richard Scheines.
Causation, Prediction, and Search. Springer Verlag,
New York, 1993.

Peter Spirtes, Clark Glymour, and Richard Scheines.
Causation, Prediction, and Search. The MIT Press,
Cambridge, MA, second edition, 2000.

Jin Tian and Judea Pearl. Causal discovery from
changes.
In Uncertainty in Artiﬁcial Intelligence:
Proceedings of the Seventeenth Conference (UAI-
2001), pages 512–521, San Francisco, CA, 2001.
Morgan Kaufmann Publishers.

T.S. Verma and Judea Pearl. Equivalence and synthe-
sis of causal models. In P.P. Bonissone, M. Henrion,
L.N. Kanal, and J.F. Lemmer, editors, Uncertainty
in Artiﬁcial Intelligence 6, pages 255 –269. Elsevier
Science Publishing Company, Inc., New York, N. Y.,
1991.

Herman Wold. Causality and econometrics. Econo-

metrica, 22(2):162–177, April 1954.

of a statistical ensemble of particles rather than us-
ing the macroscopic laws directly, then modeling the
causality of any such system would be impossible.
The problem of identifying the relevant time-scales of a
system is especially acute for the task of causal discov-
ery (as opposed to building causal models from expert
knowledge), because obviously, if one is trying to learn
causal relations from data, it is likely that one is not
privy to the details of the underlying dynamics of the
system. The positive conclusion of this work is that,
for systems that obey EMC, one does not need to con-
sider the system on the shortest possible time scale
for the resulting model to accurately reﬂect causality.
The negative conclusion, however, is that at least some
knowledge of temporal behavior of the system is likely
necessary to ensure that the EMC condition is satis-
ﬁed, and what knowledge is necessary and suﬃcient is
not yet known.
Although this work raises important objections to
some uses of causal reasoning with models learned
from data, I believe that the great potential of causal
modeling and causal discovery in artiﬁcial intelligence
make it all the more important for these questions
to be explored further and answered as forcefully as
possible. The fact that equilibrium causal models are
problematic for causal inference should not deter us
from developing further the theory that can allow us
to build and use them in practice.

7 Acknowledgements

This work was extracted from my PhD thesis [Dash,
2003] pursued at the Intelligent System Program at
the University of Pittsburgh in partial collaboration
with my advisor Marek Druzdzel.
I would like to
thank Richard Scheines, Nanny Wermuth and Gregory
Cooper for their encouragement for this work.

References

Denver H. Dash and Marek J. Druzdzel. A hybrid any-
time algorithm for the construction of causal mod-
els from sparse data. In Proceedings of the Fifteenth
Annual Conference on Uncertainty in Artiﬁcial In-
telligence (UAI–99), pages 142–149, San Francisco,
CA, 1999. Morgan Kaufmann Publishers, Inc.

Denver Dash. Caveats for Causal Reasoning. PhD
thesis,
Intelligent Systems Program, Univer-
sity of Pittsburgh, Pittsburgh, PA, April 2003.
http://etd.library.pitt.edu/ETD/available/etd-
05072003-102145/.

Marek J. Druzdzel and Herbert A. Simon. Causality
in Bayesian belief networks. In Proceedings of the

88 	

	

 
!"#%$&'

(*),+.-/+10325476+.8

9;:<>=@?BABCD:E7AFHGIJA=KAMLONPABLRQ=HSITQLO:E>Q:

UVEWLOXH:?MNBLYA[Z\]FHSOS^:_H:a`bFHEdcTFHE

egfhHiTjWklmi

ÇpÈÉJ Ê

ËÈ

|ÌµÇ

npoW:rq>:SRcsF@GVSO:_J=@S]?B:t=HNBFHEWLOEW_LONuG1vWSOS]FHGS^F7_HLRQ=@S
NBvWwTAMS^:ABLO:N=@E>c<W?MFHwd=@wWLOS^LRNPABLRQa<WLYABG.=@SOSONxVyNBvW?BX7:Z
=rEJv>Cuwm:?F@GzAMoW:NB:H{<mFHLOE7AML^E>_rFHvWANBFHCD:uFHGzABoW:
<W?MFHw>S^:CDN|=@E>c}=HCuwWLO_Hv>LYAML^:tN{~=@E>cXK=@?MLOFHv>N=@AP
AM:CD<TAMN*ABFcT:t=@SL^ABoABoW:CxrIFHCD:Q:S^:wW?=KAB:tc
QFHvW?BAVQ=HNB:N=H?B:v>NB:c5G1FH?LOSOS^v>NPAB?=KAML^F7Ebx

7gW

xnpoW:ªB«V: ¬XJLRcT:E>Q:	ITQoWF7SO=H?MNBoWLO<>­	FHGAMoW:

S^ABo>FHvW_7o|AMoW:cTLRNBQL^<>S^LOEW:N	F@GVIJAM=@ABLRN[AMLOQN	=@E>cs`=CDL^_7oJA
NB::CG.=@?=@<>=H?PAt{pABoW:Z3NPo>=H?B:NBFHCD:G1v>E>cW=@CD:E7A=@SL^EJAM:?B
:NPAMNDLOE<d=@?BABLRQvWSR=@?t{AMoW:LOEJAB:?M<W?M:A=KABLOFHEF@Ga:XLRcT:EdQ:H{
AB:tN[AML^E>_rF@GoZ<dFHABoW:tNP:tN{=@EdccT:QLONBL^F7ETCD=HL^EW_rvWE>cT:?;vWET
Q:?PA=@LOEJA[ZHx ;FK]:XH:?{]ABoW:L^?5cTLY¡:?MLOEW_&w>=7QJ_7?BF7vWE>cWND=HE>c
=@<><W?BFJ=HQoW:tN]Q=@EF@G¢AM:ES^:t=HcrABFDCDLONBvWE>cW:?N[A=@E>cTLOEW_JN{TNBv>Qo
=HN,LOEuAMoW:Q:S^:wW?M=@AB:tcD\]F7S^SOL^EdN,Q=HNB:£/¤>=HL^?MS^:Z	=@E>c~¥FJN[AM:SOS^:?
¦§¨H¨H©
¦§J¨@®W¯
_H:EW:?=KAM:c5L^EJAM:?M:NPA;LYAMoWLOENPF7C~:*SO:_J=@SQL^?QSO:NpLOEABo>:	v>NB:
F@G°<W?BF7w>=@w>L^SOLYA[Z±=7N~=HE²=HLOc&ABF?M=@ABLOFHE>=HS]LOEJAB:?M<W?M:A=KABLOFHEF@G
:XLRcT:EdQ:H{*=7N5³:SOS	=HNNBFHCD:sQ?MLYAMLOQLONBCx IFHCD:s<>=@?BABLRQvW
SR=@?MS^Z~L^EJAM:?M:NPABLOEW_cTLR=@SOFH_7vW:Nz]:?B:N[AML^CvWSO=@AB:tcwZAMoW:;<>?BFH
<W?MFHw>=HwWLOS^L^A[Z3<>=@<m:?wZ´¤,LOEWH:SONPAB:L^E=@E>c ¤>=HL^?MS^:Zµ£
¦t§J¨K®J©
£.NB::3n?BLOwm:µ£
¤,LOEWH:SONPAB:L^E¸=@E>c¸¤d=@LO?BSO:Z¹£
¦§J¨T¦t©¶
¦§¨¦
»*=ZH:
n?BLOwd:°£
©·¶º
¦t§J¨@¼7©·¶
¦§¨¦
=HE>c&wZABoW:NMQ:<WABLRQ=@SpwmFFHswZ²\]FHoW:E´£
¦t§J¨@§7©P©¶
¦t§J¨H¨H©
£.NB::IWQoJv>C!£
\]FHoW:E¾£
¦t§J¨@§7©·¶½
¦§H¼7®7©¶
LOS^SOLO=HCN	£
¦t§H¼H®J©·¶

?ML^SOC=ZH:?b=@E>c*»aF7?BEWod=@v>NB:?£

¬z_7_HSO:NPABF7E|£

LOSOS^LR=@CN&£

¦§J¨@§7©¶

¦t§H¼7®7©P©

©·¶

npoW:?B:~o>=XH:uwd::Es=EvWCuwm:?aFHG?B:tQ:E7A*Q=7NP:tNVLOEAMoW:DU;»
oW:?B:A[³F±FH?CDF7?B:Z7FHvWEW_±QoWLOSRcT?B:EgL^E=sG.=HCDL^SOZo>=X7:
cTLO:c	NBv>cWcW:EWSOZ;G1?MFHCEWFVF7wXJLOFHvdNbQ=Hv>NP:7{K=@E>cÅ{t:X7:EaAMoWFHvW_7o
ABo>:?M:LRNrEWFNP<m:QLYqmQ=@SOSOZ²LOE>Q?MLOC~LOE>=@ABLOEW_:XJLRcT:E>Q:7{ABoW:L^?
CDF@AMoW:?po>=7N]wm::EQFHEXLRQ·AB:tcFHGCuvW?cT:?BLOEW_ABoW:Cxy¿E5ABo>:
Q=7NP:FHG*IT=HS^SOZg\]SR=@?M{³=s<d=@:cWLO=@AB?MLOQLO=HEAM:NPABL^q>:c3=@AAB?MLO=HS
ABod=KA*ABo>:<W?BF7w>=@w>L^SOLYA[ZÍ¹ABo>=@A	oW:?aA[³FNPF7E>N]F7vWSRco>=X7:
cTLO:crF@GIy[9aI£.vWEW:ÂT<WSR=@LOEW:tcE>=@ABvW?=@SmQ=@vdNP:tN
¨@Î
CDL^SOSOL^F7Ebxnpo>=@AÅq>_Hv>?B:p=HNLRcT:SOZa=@E>c<W?MFH<m:?MS^Z°Q?MLYAMLOQLONB:cÅ{
wWvTALYAQ=@E*EWFHAbwd:]cT:EWLO:cAMo>=KA,Í²LRNÅ:ÂJAM?B:CD:SOZ°NBCD=HS^SÏxnpo>:
vW:NPABLOFHELRNÃ
o>=@A=H?B:*³:*ABFrCD=HH:	FHGzNPv>Qo3ªMN[A=KAMLONPABLRQ=HS
:XLRcT:EdQ:­JÑ

³=7N

LOE

¨KÎ

Ûuá

ÕuÖ×

×*ÛÜ5Õ

(*ØÙ5Ú

Qo>=HE>Q:~LOE

éëªBL^EWE>FQ:E>Q:­

ÙØÝ¢Ú²Þmß5àà]ß
ÒbÓ.Ô
£.oW:?M:æ
npoW:QF7?B?M:QALOEJAB:?M<W?M:A=KABLOFHEÍãâåäz?t£1æèç
cT:EWF@AM:NrABoW:|:XLOcW:E>Q:êoW:?M:ABo>:G.=7Q·A5FHG*A[]FL^ETG.=HEJA
LON
é%cT:EWF@AM:N&ªB_HvWLOS^AM­&=HE>c
cT:t=KABodN
é¹ç7æ
G¢AB:?°=HS^SÏ{WAMFrNB=Z
:=7NPLOSOZ5cTLRN[AMFH?BAB:tcL^EJABFdÃ]Íâä?£
CDL^SOSOL^F7EAMo>=KAaABo>:DQo>L^SRcT?M:E
ABod=KAaABoW:?B:~LRN
cTLO:cFHGE>=KAMvW?M=HSQ=@v>NB:NV=H<W<m:=@?NAMFwm:VÁ[v>NPA;AMoW:NM=@CD:u=7N
NM=ZJLOEW_*AMo>=KA]ABoWLRN³LONABo>:°<W?MFHwd=@wWLOS^L^A[ZABo>=@AABo>:°CDF@AMoW:?pcTLRc
EWFHAVJLOSOSABoW:C¹ìNB::C~LOEW_7S^ZFKX7:?MoW:SOCDL^E>_:XJLRcT:E>Q:aG1F7?
oW:?°wm:LOEW__HvWLOSYA[Z7x	npoWLRN;CDLRN[A=@H:E´ªPAB?=@E>NB<dFJNPL^ABLOFHEFHGzABo>:
QF7E>cTL^ABLOFHE>=HSO­LRN	NBFQFHCDCDFHEsLOEsQFHvW?BA{oW:?M:L^Auv>NBv>=@SOS^Z
G.=XHF7vW?N³ABoW:	<>?BFJNP:tQvTAML^F7Eb{TABod=KAVL^A;o>=HN;wd::EAM:?MC~:tcª[ABo>:
<W?MF7NB:QvTABF7?
G1FH?³=*QSO:=H?
=HQQF7vWEJA³FHGbABoW:a<W?MF7NB:QvTABF7?
NG.=@SOSO=7QZH{T=HE>c5NBvW_7_H:NPABLOFHEdN]=7N
ABF~oWFKL^ACDL^_7o7Awm:=X7FHLRcT:c
xyA]F7vWSOcro>=XH:°wd::Eo>=@?c
NdÁ[vW?MZ*ABFLO_HEWF7?B:]ABoWLRNNB::CDLOEW_HSOZ	<mFK]:?PG1v>S
G1FH?zIT=HS^SOZ~\]SR=@?M
=@?M_Hv>C~:EJA{W=@EdcAMoW:ZcTLOcLOEG.=HQ·AVQFHEXLOQAx

N,G.=@SOSO=7QZT­£.NB::íL^_7:?M:EWî:?V£/Ä

®H®

y¿E?B:tQ:E7AZ7:=@?N³LYAVod=HNwm:QFHCD:*=@<W<>=H?B:EJA³AMo>=KAV<>?BF7wWS^:CN
=@?MLRNPLOEW_;LOEuSO:_J=@SNP:APAML^EW_JN,?M=HLONB:]NBFHCD:zG.=7NBQL^Ed=KABLOEW_=@E>ccT:SOLY
Q=@AB:³LONMNBvW:NF@GdNPAM=@ABLRN[AMLOQ=@SSOFH_HLRQ@{K=HE>c*AMo>=KAt{@L^EuABvW?MEb{@<>?BF7<d:?
=@<><WS^LRQ=@ABLOFHEF@GmNPAM=@ABLRN[AMLOQ=@S?M:=HNBFHE>L^EW_°o>=HN=°?KÀ
FHSO:AMF<>SO=Z*LOE
ABo>:	<WvW?NPv>LYA;FHGdÁ[vdN[AMLOQ:Hxpy¿EABoWLRNV<d=@<m:?Vyp:ÂT<WSOFH?M:*NPF7CD:*F@G
ABo>:NB:	S^F7_HLRQ=HSbLONMNBvW:N{WL^ABo?M:G1:?B:E>Q:aAMFrNPF7CD:*?B:t=@SQ=HNB:NÃ
NB::*9°=LRcs£/Ä

G1F7?VNPF7CD:°G1v>?PAMoW:?Vwd=HQ_H?MFHvWEdcÅx

®H®

ØðßrØñ

Ü5ïÕ	×

Üòµ×°ïÕ

ÒbÓRÒ
npoW:?B:±LRN=@E}F7wXJLOFHvdNQFHv>E7AM:?B=H?B_7vWCD:EJAL^EAMoWLON|Q=7NP:7{
oWLRQo±y*<W?M:NB:EJAB:tc=@A=@<><d:t=@SÏx
:=@?M:QFHCD<>=H?BLOEW_A[³F
=@S^AB:?BEd=KABLOXH:*oZ<mF@ABo>:NB:NÃ]A[³FrcT:t=KAMo>NVwZIy[9aI{m=HE>cA[³F
cT:t=KABodNwZrCuv>?McT:?x]yGABoW:uQod=@E>Q:*F@G,ABoW:*G1F7?BCD:?VLONV?B:S^:
XK=@EJA{JNPo>FHvWSRc~EWF@AzAMo>=KA]F@GmABoW:VSR=KABAB:?zwd:;:
v>=@SOSOZu?M:SO:XK=@EJAÑ

89

N
w
=
£
½
x
Ä
©
Æ
e
e
©
¦
Ð
½
é
©
©
©
x

¦
¯
Ä
©
¯
©
¯
Û
Ù
½
Ð
¦

Ä~w>L^SOS^LOFHE

CDLOS^SOLOFHEbx

cW=KA=W{FHEW:~QF7vWSOc=@?M_HvW:*G1F7?=5cTFHv>wWS^:CuvW?cT:?
U;NBLOEW_5U°»
q>_7vW?B:°F@G=@?MFHvWE>c
LOEÄuwWLOS^SOL^F7Eb{JABFNB:A=@_7=HL^EdN[A]ABoW:*Iy[9aI
q>_7vW?B:aFHG
LOE
EW:*Q=@ENP::a<W?BFJNP:tQvTAML^F7E5=HE>c
¨@Î
cT:G1:E>Q:wW?M=HE>cTLRNPo>L^EW_AMoW:LO?	?M:NB<d:tQ·AML^X7:qd_HvW?M:NaLOE&=HcTX7:?B
NM=@?MLO=HS³QFHCuwd=KA{w>vTADABoW:QF7?B?M:QA~=@<><W?BFJ=HQo±LRNABF?B:t=@SOLONB:
ABod=KALYALRN]ABoW:L^?p?M:SR=KABLOXH:7{EWF@A=@w>NBFHSOvTAM:H{TXK=@SOvW:N]AMo>=KApC=KAP
AB:?xy¿EG.=7Q·At{>AMoW:LO?;?=KAML^F£
Q=HE±wd:rL^EJAB:?B<>?B:AB:c±=7N*AMoW:FTcWcWNFHE±_7vWL^S^Au_7L^X7:E
®HÎ
ABo>::XLOcT:E>Q:F@GABoW:A[³F~cW:=KAMo>N{JLOCD<WSOZJLOEW_=_HvWLOSYA<W?MFHwW
=@w>L^SOLYA[ZrF@GFHEWSOZ
y¿E5ABoW:*:XH:EJAt{W=@S^ABoWF7vW_HorABoW:	=H<W<d:t=@SÅQF7vW?BA=7QQ:<TAM:crABo>=@A
ABo>:?M:o>=Hcwm::E±NBFHCD:<W?MFHwWSO:CNaL^ABosAMoW:<W?M:NB:EJAM=@ABLOFHE
F@GdABoW:NPAM=@ABLRN[AMLOQ=@ST:XLRcT:EdQ:=KA,AB?MLO=HS/{HLYAzp=HNEWF@ALOEJAB:?M:NPAB:tc
LOE|<W?MFH<m:?MSOZLOcW:EJABL^G1ZL^EW_=HE>cv>E>cT:?NPAM=@EdcTL^E>_5AMoW:DS^F7_HLRQ=HS
LRNBNBvW:NpLOEXHF7S^X7:cÅxzIT=HS^SOZ\]SR=@?M³=7Np:X7:EJABv>=HS^SOZrQS^:t=@?M:cF7E
:EJAML^?M:SOZvWEW?M:SR=KAM:c5_H?MFHvWEdcWNx

CDL^SOSOL^F7E

¦7¨KÎ

Î	


©

73ÈJÊDT

|TÈ73Èµ|È

AM:QoWEWF7S^F7_HZ7{L^ALRNbEWFK±QF7CDC~F7EABFVF7wTAM=HL^E	=V9«

¥=HEJZQ?ML^CDLOE>=@S7Q=HNB:N?M:X7FHSOXH:=@wmFHvWAÅABoW:zLRNMNPvW:FHGTLOcT:EJABL^A[ZmÃ
LRNzAMoW:NBv>NB<d:tQ·AABoW:aNM=@CD:V<m:?NPF7Er=HNzABoW:<d:?B<m:AM?M=@ABF7?
F@G³ABo>:Q?ML^CD:tÑILOC~LOSR=@?*LRNBNBvW:Nu=@?MLONB:LOE±QLOXL^SQ=HNB:N{NBv>Qo
=HNcWLONB<WvTAM:c<>=KAM:?MEWL^A[ZHx
¤WF7?B:E>NBLOQVAB?=HQ::XLRcT:EdQ:LON³F@G¢AM:EwW?MFHvW_7o7A³L^ENBv>Qo5Q=HNB:Nx
¤W?MFHCåABoW:Q?BLOCD:NBQ:EW:³:FHwTA=@LOE|LOETG1F7?BC=KAML^F7EABo>=@A
ABov>N
Q=HE²wm:=HNMNPv>C~:tc&AMF±=@<W<WSOZ±AMF|AMoW:Q?MLOC~LOE>=HS
³:uC=Z5od=XH:u=q>EW_H:?B<>?BLOEJA{=G1FF@AM<W?BLOEJA{dq>wW?M:N{FH?;:ZH:
L^ABEW:tNBN:XLOcT:E>Q:FHGbNP:Â{7=@_H:7{@?=HQ:7{
LYAMo=HcTXK=HE>Q:tN
LOE	9°«
<W?MF@q>SO:uFHGABoW:DQ?MLOC~LOE>=HSG1?MFHC
wWLOFHSOFH_7LOQ=@SC=@AB:?MLR=@S,S^:G¢Aa=@A
ABo>:5NMQ:E>:rF@GpAMoW:5Q?BLOCD:Hxy¿E=7cWcTL^ABLOFHEb{³:o>=X7:rNBL^CDLOSO=H?
LOETG1FH?MC=KABLOFHE²=@wmFHvWA	ABoW:5NPv>NB<m:Q·A p{G1FH?	:ÂT=HCD<WS^:roWLON
9«
oW:E*ABoWLRNbC=@AMQoW:tNÅABo>:Q?ML^CD:NM=@CD<WSO:H{"!#$
â%
{Wâ'&{TNM=ZH{JABod=KApLON³QSO:=H?BSOZD:XLOcW:E>Q:°LOEG.=X7FHvW?]F@G
ABo>:;A[³F~NM=@CD<WSO:N]o>=XLOEW_	AMoW:NM=@CD:NPF7vW?MQ:Hx
vTApoWFK=@?M:
³:<>?BF7<d:?BSOZABFD³:LO_Ho=@E>c=H<W<WSOZABoWLRN:XJLRcT:E>Q:Ñ
EW:?M:SO:XK=HE7AuG1:=KAMvW?M:rF@GC=KAQo&:XLRcT:EdQ:LRN*AMoW:)( *+,.-
vW:E>QZgLYAMo´oWLRQo3ABo>:
/0.132
Qo>=H?M=7Q·AB:?BLRNPABLRQ8&sFQQvW?NL^EABoW:D<mFH<Wv>SO=@ABLOFHE|=@ASR=@?M_H:7x*y¿E
ABo>:~Q=HNB:uF@G³9°«
<>?BFHq>S^LOEW_d{dAMoW:~CD=@AMQo|<W?BF7w>=@w>L^SOLYA[ZQ=HE
wm::tN[AML^C=@AB:crG1?MFHC¹<mFH<Wv>SO=@ABLOFHE5q>_HvW?M:Np=HE>c_7:EW:ABLRQ;AMoW:
FH?MZHx:9:?MZABLOEJZ±C=@AMQo&<W?MFHwd=@wWLOS^L^ABLO:N{:X7:E=7NNBC=@SOS³=7N
FHE>:LOEFHEW:awWLOSOS^LOFHEb{d=@?M:E>FK´?MFHvTAML^EW:7x

!$45!$76ÍDÃsABoWLRNrLRNrABoW:|G1?B:

<>?BFHq>S^:7x

;Ó.Ô

ÕuÖ×

(*ØÙ5Ú

×*ÛÜ5Õ

ÙØÝ¢Ú²Þmß5àà]ß

Ûuá

â¹äz?t£#>â?&´ç@BA

:o>:E>Q:G1FH?BABo L^CD<WSOLRQL^ABSOZ´QF7E>cTL^ABLOFHE´F7EAMoW:±NPv>NB<m:Q·A
Qo>=H?M=7Q·AB:?BLRNPABLRQ@Ã<
â=&xVnpoW:uC=@AMQo<W?MFHw>=HwWLOS^L^A[Z5Q=@Ewm:
xyGp]:cT:tNBQ?BLOwm:
?MLYABAB:E&=7N*Í
ABo>LOND=HN|ª[AMoW:<W?BF7w>=@w>L^SOLYA[ZAMo>=KA~ABoW:Q?MLOC~:NM=@CD<WSO:Q=@CD:
G1?MFHC NBFHCD:uF7EW:FHABoW:?;AMo>=@E­>{m³:D=@?M:uLOC~CD:tcTLO=@AB:S^ZLOE
cW=HEW_H:?³FHG,QFHCDCDLYABABLOEW_DABoW:a<W?MF7NB:QvTABF7?
NG.=@SOSO=7QZFHG<DmÄWx
oWLRQo&LOE7AM:?M<W?M:AMN~Í =7Nuäz?t£EFA
{J!#$ABo>:
âGèçH
<W?MFHw>=HwWLOS^L^A[ZH{pLOE3ABoW:S^LO_HoJA5FHGaABoW:C=@AMQob{pAMo>=KAK¾LONrL^ET

âI&

âC

ÍDxpyGzNB=ZÍâ

EWFTQ:EJA°L^CD<WSOZL^EW_AMo>=KA*AMoW:<W?MFHw>=HwWL^SOL^A[ZF@Gp_HvWLOSYA	é
¦ML
LOE
³:SOSvWE>cT:?MNPAM=HE>c&AMo>=KADAMoW:<W?BF7w>=@w>L^SOLYA[Z±LRNDFHE>S^Z
CDL^SOSOL^F7E5AMo>=KANLRNpEWF@AV_7vWL^S^A[ZH{W=HE>cQF7EJXLRQ·Atx

LON
{JAMoW:Á[vW?MZ5F7?Á[v>cT_7:	CDL^_7oJA
¦t®

®H®H®7®H®7®W¦

®	

;ÓRÒ

ÕuÖ×

×°ïÛ×

ßrØñ

Üòµ×ïÕ

£.NM=Z

ÄcTF:tN	EWFHA
QFHvWEJAB:?P¿=@?M_Hv>C~:EJA*=HS^F7EW_ABo>:S^LOEW:tN	F@GODmÄWx
NBv>QQ::cso>:?M:H{NPLOE>Q:ABoW:<>?BF7w>=@wWLOSOLYA[Z|F@GV=C=KAMQo±v>E>cT:?
ABo>:	=@S^AB:?ME>=@ABLOXH:oJZ<mF@AMoW:NBLONpFHG,_7vWLOSYAVLRNpvWEWL^A[ZHx
y¿E>NPAB:t=Hc´ABoW:±cT:G1:E>Q:±C~LO_HoJA<mFHLOE7AF7vTAABo>=@AAMoW:?M:±=@?M:
PRQ
<d:FH<WSO:oWF²QFHv>SOcgo>=X7:QF7C~CDL^APAM:cgAMoWLON
Q?MLOC~:7x
EW:F@G°ABoW:tNP:LRN~AB?MvWSOZ_Hv>L^S^A[ZH{³=@E>cgNBFC=@AMQoW:tN
oWL^SO:a]:³FHvWSRcr:ÂT<d:tQ·ApABFNB::a=@<W<W?MFÂ
ABo>:aQ?BLOCD:AB?=HQ:
LOCD=@AB:S^Z PÍLOEWEWFTQ:E7A³C=KAMQo>:NzF7vTA]FHGÅABoW:°?B:C=@LOEWL^E>_SP
LOEWEWFTQ:E7A]L^E>cWL^XLRcTv>=@SÏx
QTPÍ
C=KAQoWL^E>_LOE>cTLOXLOcWv>=@SRN{F@G³oWFHCèÁ[v>N[A
LRNa_HvWLOS^A[ZHxDyGp=HS^S
³:EWFKµ=HwdF7vTA8LON°AMo>=KAaoW:~CD=@AMQoW:tN{AMoW:~<W?BF7w>=@w>L^SOLYA[Z
CDLOS^SOL^F7E
oW:LRN_7vWLOSYA[Z&LRN
x²n,=@L^E>_P
=@Edc=@_J=@LOEDÍ}â
LOEWEWFTQ:EJA
C=KAQoW:N{@G1F7?=q>E>=HS>_Hv>L^S^Az<W?MFHw>=HwWL^SOL^A[ZuF@G
oWLRQo
LRNQ:?BAM=HL^E>S^ZaEWFHA:XLOcT:E>Q:DªBwd:ZHFHEdc	=?B:t=HNBFHE>=HwWS^:]cTFHvWwWAM­Wx

:VABov>Nz:ÂT<d:tQ·A]=AMF@AM=HS>FHG

{³:V³FHvWSRc:ÂT<m:QA

Q=PÍ
®H®H®7®H®7®W¦

Î7®
LOE V

¦U
®	

Ú,Ù

¦§7§

ò×

ß5Øñ

Õ	Ö×

Üòµ×ïÕ

LOE>cTLOXJLRcTv>=HSONaLOEABoW:D<mFH<Wv>SO=@ABLOFHELON*:

;ÓW;
npoW:³=@wmFKXH:zcT:G1:E>Q:=@?M_HvWCD:E7A,Q=@E*wm:XK=H?BLO:caLOE	=EvWCuwm:?
F@Gpp=ZN£/9°=LRc
{bC=@EZ|F@GpoWLOQo&=H?B:DLOEJABvWL^ABLOXH:S^Z
=@<><d:t=@SOL^EW_r!=@Edco>=X7:wm::E|?M:QFHCDCD:E>cW:cG1FH?av>NB:u
wWvTA;=H?B:aLOEG.=HQ·ApG.=HS^SR=HQL^F7v>Nx
y¿E=@SOS>Q=HNB:N³:V=HNMNPv>C~:pAMo>=KAt{7<>?BLOFH?AMFu=@EZu:XLOcT:E>Q:7{7=HEJZ
F@G]ABoW:XPYQ
v>=@SOS^Z
SOL^7:SOZ°AMF;wm:_7vWL^S^A[ZH{K=HE>caABod=KA,ABoW:]FHEWSOZa:XLOcW:E>Q:ær=H_7=@LOE>NPA
â[>gâ=&x;¤>FH?°L^SOS^vdN[AM?M=@ABLOFHE
LRNABod=KA°FHGABoW:CD=@AMQobÃZ
³:°A=@7:OP â
V>x
®	
`b:A]\êcT:E>F@AB:5ABo>:v>EWEWFKEEvWCwd:?~FHG;LOE>cTLOXJLRcTv>=HSON_^
o>=XLOEW_`>aâb&x
:NBvW<W<mF7NB:AMo>=KAt{°wm:G1F7?B:=@EZ3NB=HC~
<WSO:N=H?B:CD:=7NPv>?B:tcÅ{M\
o>=7N~ABoW:wWL^E>FHCDLO=HS;cTLRN[AM?BLOwWvTAML^F7E
çæ<d.\
L^E£#PcQ
â=\fehgt{J=@E>cABo>:
:o>=X7:³ä?£.é
q>E>=HS_HvWLOS^Aa<>?BF7w>=@wWLOSOLYA[Z7{bäz?£/éåç>æ
{,Q=@E|wd:F7wTAM=HL^E>:cwZ
AM=HL^EW_aAMoW:V:Â<m:QAM=@ABLOFHEDF@GABo>LON
vd=@EJABL^A[ZuL^ABo?M:NB<d:tQ·AAMF
ABo>:~QFHE>cTL^ABLOFHEd=@ScTLRN[AM?BLOwWvTAML^F7EF@Gi\¾{Å_7L^X7:EAMoW:~:XLOcW:E>Q:
æzx

{TÍâ

¦®7®

®H®

¦H¶

xnpoW:|:XLRcT:E>Q:AM:SOSON5v>NrABo>=@AT\
QFHE>cTL^ABLOFHE>L^EW_DF7ErAMoWLONVZJLO:SRcWN
â¬°£E\

ehg

{;=@EdcNPLOCD<WSO:

ç3\kj

¦t©l

ä?£.é
çæ
LOE£EPpQ

¦7¶

ABoWLRNLRNEWF@A:=7NPLOS^Z:ÂT<W?M:NMNB:c
¤>FH?m\on
LOEQS^FJNP:tcG1F7?BC{wWvTAQ=@Ewd:±Q=HSOQvWSR=KAB:tcÅÃ²G1FH?FHv>?
EvWCwd:?MNpL^AV:XK=@SOv>=@AB:N³AMF]q
E´=@S^AB:?BE>=@ABLOXH:=@?M_Hv>C~:EJALONABo>=@A{V_7L^X7:EABoW:|:XL^
cT:E>Q:7{]³:EWFK¹AMo>=KAAMoW:?M:LONDF7EW:_HvWLOSYA[ZCD=@AMQob{
=HE>cÅ{HF7vTAzF@GmABo>:?B:CD=HL^E>L^EW_8P
LOEWEWFTQ:E7AzLOE>cTLOXLOcWv>=@SRN{

Ósr

ÄTx

90¦
¦

£
©
â
®
x
x

e

½



½

º

*
2
Ð

½
¯
N

©
¯
¦
{

©
¦
2
×
Þ

¦
©

¶
½
¦
¦
£
¦
©
â
Î
¦
Ù
Ø
Ú
V
©
¦
Ð

½
º
Í
©
x
½
©
©
Ð
¦
j
¦
©
º
Í
©
q
Ò
x

:t=HQorod=HN{JLOE>cT:<d:E>cT:E7AMS^Z7{W<W?MFHw>=HwWLOS^L^A[ZÍµFHGNPv><W<WSOZ7
LOEW_	=aC=KAQobxITFaABoW:;QFHE>cWLYAML^F7E>=@S>cWLONPAB?ML^w>vTABLOFHEDF@G@\
LRN
xU;NBL^E>_DABoWLRNpABFDA=@7:°AMoW:	:Â<m:QAM=@
AML^F7EFHG

LOE£EP
e@g

ZJLO:SRcWN

¦L

ä?£/é¸çKæ

¦L
£EPCQ
oWLRQob{TG1F7?FHvW?XK=HS^vW:tN{T_7L^X7:Nq
x¤,LOE>=@SOS^Z7{TABo>:	QFH?M?M:Q·A=@<><W?BFJ=HQobx



¦©

ÓÒ

d

*

â%&

=HE>c

=ZH:tN

LRN
â'&

¦©

:	Q=HE5QF7E>NBLOcT:?pABoW:AMF@AM=HSÅ:XLRcT:E>Q:£#
5â
=HN~AMoW:?B:tNPv>SYAN{pwmF@ABo3NBv>QQ:NMNP:tN{]F@GA[]F±cT?=VN{
!$
QFHvWSRc´wm:sABo>:
±£.NBL^E>Q:
{@G1?MFHCABoW:V<mFH<>vWSO=@ABLOFHEbxnpoW:<W?MFHwW
NM=@CD:LOE>cTLOXJLRcTv>=HS
£EP
=@E>cÅ{
v>NBLOEW_
NVnpoW:FH?M:C{dABoW:~?B:tNPv>SYAML^EW_QF7E>cTL^ABLOFHE>=HS
cTLRNPAB?ML^wWvWABLOFHEF@Gm\
ç+

>( 
	
=HwWL^SOL^A[ZFHGTABoWLRN{K_HLOXH:ES\Ëâ{KLRN
äz?£7\Ëâ
Í

£
oW:?B:ABoW:]EWFH?MC=@SOLONBLOEW_;QF7E>NPAM=@EJA,LONVâ

n,=@LOEW_ABoW::ÂT<m:QAM=KAML^F7EgF@GO\
AMoWLON;cTLONPAB?MLOwWvTABLOFHEAMoW:EZL^:SOc>N
¦+U

L²¦

LYAMo?M:NB<m:Q·ADAMF

dP

¦t©

d.5â'&

QpPÍ

¦L


ä?£.é

PÍ

e@g

ehg

¦U

çæ

LOEu=@_7?B::CD:EJAbL^ABouABoW:]FH?ML^_7L^E>=HS>£.=HE>c*Cv>Qo	NPLOCD<WSO:?
cT:G1:E>Q:~=H?B_7vWCD:EJAx°npoWLON°:XK=HS^v>=@AB:tN;EvWCD:?MLRQ=@SOSOZrAMF

Ó bÔ!

npoW:=HwdFKX7:5LRNaÁ[v>NPAFHEW::ÂW=@CD<WSO:FHG°AMoW:<WL^APG.=HS^SRNwm:NB:AP
ABLOEW_SOFH_HLRQ=HS=@E>c<W?BF7w>=@w>L^SOLONPABLRQ²?B:t=HNBFHEWLOEW_´LOE¸Q=HNB:Ns=@A
SR=*ÃNB::
9=LOc}=HE>c
¥F7?PAM:?= £
9°=LRc
=@Edc¥F7?PAM:?=u£
G1FH?z=°EvWCuwm:?FHGdF@AMoW:?NBvWwTAMS^:LRNBNBvW:tN
F@GLOE7AM:?M<W?M:AM=@ABLOFHE5F@G,G1FH?M:E>NBLOQ°LRcT:EJABL^qdQ=KABLOFHE:XJLRcT:E>Q:7x

¦§H§"H©¶
9°=LRc=@E>c¥F7?PAM:?= £

=HSOcWL^EW_ =@E>cµ9°FHE>EW:SOS^Z
¦§H§"H©¶

¦§H§7©¶

¦§H§7¼7©

á5×

;Ó"

NB:?MLOFHv>N<>?BF7wWS^:C

L^ABowdFHABoAMoW:u<W?MF7NB:QvTABLOFHE=HE>cABo>:
cT:G1:E>Q:;=@?M_HvWCD:E7ANLONABo>=@AzABoW:Z~cWF*EWF@A=HS^SOFK&G1F7?ABoW:;L^ET
QF7?B<mFH?=KAML^F7EDF@G=@EZ~F@AMoW:?]:XLOcW:E>Q:;LOEABoW:Q=7NP:7x,npoW:QFH
oW:?B:E7Ap=@<W<>?BFJ=HQo~ABF~QFHCwWLOEWL^E>_	LOcW:EJABL^qdQ=@ABLOFHEr=HE>cFHABoW:?

:XLRcT:EdQ:LON³AMoW?BF7vW_Ho
{oW:?M:DABo>:
£1F7E&é
F@AMoW:?:XLOcT:E>Q:*LRN=HQQF7vWEJAB:crG1FH?;L^EABo>:*<W?BLOFH?pFTcWcWN{>=HE>c
ABo>:VS^LOH:S^LOoWFFTcD?M=@ABLOF*w>=HNB:c~F7E:XLOcW:E>Q:æ£1oW:?B:o>:?M:Væ
LRN³ABoW:*C=KAQo:XLOcW:E>Q:ª.
LRNcT:qdEW:cwZÃ

N³npoW:FH?M:CÃ$
!"2>4
11)43

1+0('*)+)&%

â,$

râ%&m­

1&%

=Z7:N

*+7!

1+0-'*)+)&%/.10
576â

â'
äz?t£1æçKé
äz?t£1æç

¦U

®H®

!:

!:9

L^E&Ä

¦§7§

{äz?t£1æ3ç

{=@E>cg£.:ÂW=HQABSOZ

AM?BLR=@SdF@Gb9;:EWLRN<;7FHoWE

:Q=@v>NB:uAMoW:?M:~LONA[Z<WLRQ=HS^SOZ=5NBvWwTÁ[:tQ·AML^X7::S^:C~:EJAaLOEs=HNP
NB:NMNPLOEW_<W?BLOFH?a<W?MFHwd=@wWLOS^L^ABLO:N{ÅL^A	LONaFHG¢AB:Es=@?M_Hv>:cAMo>=KA	:Â
<m:?BAMNNBoWFHv>SOcgQF7ETq>EW:AMoW:LO?:XJLRcT:E>Q:AMF&=HNMNP:tNBNBCD:EJAF@G
ABo>:]CDFH?M:	ªBFHwTÁ[:tQ·ABLOXH:t­SOL^7:SOL^oWFFTca?=KABLOF>{SO:=XLOEW_ABo>:³QFHvW?BA
=ZH:tN
ABF=H<W<WSOZ
N*npoW:FH?M:C L^ABo±L^AMNuFKE|<W?MLOFH?*LOEW<WvTANx
£.;FK]:XH:?{@NB::
wm:SOFK²QFHE>Q:?MEWL^E>_a=HCuwWLO_Hv>LYAML^:tN
V*=HE>c
DD
LOE5AMoW:	cT:q>EWL^ABLOFHEF@GABoW:*SOL^7:SOL^o>FJFTc?=KABLOF>x
y¿EABoW:	Q=HNB:aF@GLOcT:EJABL^qdQ=@ABLOFHE:XLRcT:E>Q:*]:*Q=@E±£1v>NBv>=HS^SOZ
AM=HH:uä?£.ægçJé
â}ÍD{mNBFABod=KA;AMoW:uSOLOH:SOL^
ÍDx~yGAMoW:<W?ML^F7?a<W?BF7w>=@w>L^SOLYA[ZFHG]_7vWL^S^A*LON
oWFFTc?=KAML^FLRN
QgÍ
{ABo>:~<mF7NPAB:?BLOFH?°<W?MFHw>=HwWL^SOL^A[ZLRN
xnpoWLON
=@_7?B::Np£.=H<W<W?MFÂTL^C=KAM:SOZ
L^ABo~AMoW:V=@?M_HvWCD:E7AFHGdAMoW:<W?MF7NP
:QvTABF7?	oW:E
LYAMosABo>=@AuF@GpABo>:
®	

cT:G1:E>Q:o>:Eg=@SOSZPRQ
<mF@AB:EJABLR=@SVQv>S^<W?ML^AMND=@?M:
v>=HS^SOZSOLOH:SOZAMFwm:ABoW:r_HvWLOSYA[Z|<>=@?BA[ZHxnpoWLRN	CDL^_7oJA
1+0
wm:NP::E=7NNPv><W<dF7?PAG1F7?AMoW:cT:G1:E>Q:=@?M_HvWCD:E7ALOEgABo>:
=@wdNP:E>Q:aF@G=@EZFHABoW:?:XLOcW:E>Q:Hx
ELOEJAB:?B:tN[AML^EW_5=@<W<WSOLRQ=KAML^F7EF@G
NnpoW:F7?B:Cèp=HNLOE
=ZH:N
ABo>:
cW=@CNG1FH?³NP:Âvd=@Sd=7NBNM=@v>SYAtx
npoW:]FHEWSOZ°<>?BFJNP:tQvTAML^F7E*:XLOcW:E>Q:z³=7N=°9°«
C=KAQob{KLYAMo
C=KAQor<W?MFHw>=HwWLOS^L^A[Z=HNMNP:tNBNB:cDwm:A[³::E
L^EÄ	CDLOS^SOL^F7E5=HE>c
C~LOSOS^LOFHEbxnpo>:DcW:G1:EdQ:?M:SOL^:tcF7EAMoW:DG.=HQA*ABo>=@A
ABo>:XLRQ·AML^C¹cTLRc5EWF@ApLOcW:EJABL^G1Z
c>=@CNp=KA=@ErLRcT:E7AMLYqmQ=KAML^F7E
<>=H?M=7cT:H{@=HE>c=HSONBFaNB=HLOcuABo>=@AzoW:cTLRcE>F@AS^FF7	S^LOH:³AMoW:pCD=HE
oWF&od=Hc3?=@<m:cgoW:?x}y¿E =HcWcTL^ABLOFHE
N5_HLO?MSYG1?ML^:E>c
AB:tN[AMLYqd:cABod=KA;oW:uo>=Hcwm::ELYAMooW:?;=@AVABo>:*ABLOCD:	F@GABo>:
Q?MLOC~:7x
EAMoW:aw>=HNBLRNAMo>=KApAMoW:*Q?ML^CDLOE>=@Sp=HN]S^LOH:S^ZDAMF~wm:*=uSOFTQ=HS
C=@SO:=@_H:tc&wm:A[³::E=HwdF7vTA
{AMoW:<W?ML^F7?<>?BF7w>=@wWLOS^
L^A[ZFHG	_HvWLOS^A{;wm:G1F7?B:=@EZ:XLOcW:E>Q:H{;CDLO_HoJA5wm:s=HNMNP:tNBNB:c
=KA*=@?MFHv>E>cFHE>:LOEÄ
xanpoW:~S^LOH:S^LOoWFFTc?=KABLOFrwd=HNB:c
®H®7®
FHEABoW:9°«
âãÄ&CDL^SOS^LOFHE{;NB=Z7xnpo>=@A
¦+U
w>=7NP:tcFHErABoW:XLOQABLOC
NpEWF7ET?B:tQFH_7EWL^ABLOFHEF@G
cW=HCDNpQFHvWSRc
wm:~=7NBNB:NMNP:tc=KAt{NM=ZH{
{m=HE>cAMo>=KAaw>=HNB:cF7E
¦UK§
®	O¦U@®	
N	=HS^LOwWL]=@A{NM=ZH{
oWLRN	_7L^?MSYG1?MLO:E>c
ÄTx
NMNPv>C
U@®	

LOEW_NPvWL^AM=HwWSO:°LOE>cT:<d:E>cT:EdQ:H{WABoW:a<mF7NPAB:?MLOFH?pFTcWcWN³FHE_HvWLOS^A
wm:QF7CD:s£
¦U
®H®
®7®H®
¦U
{QF7?B?M:NB<dF7E>cTLOEW_ABF=<dFJN[AM:?ML^F7?	<W?MFHw>=HwWLOS^L^A[ZFHG
Î
U@§
£¢AMoWFHv>_HoD?BLRNBL^EW_AMF
CDLOS^SOL^F7E
y¿E|ABoW:=HQABv>=HSQ=HNB:ABoWLRN*=@?M_HvWCD:E7A³=7Na=@SOS^FK³:c=@AaAB?MLO=HS
£.=HSYAMoWFHv>_HoL^A]cTF:NE>F@A]NB::CAMF	o>=XH:pLOCD<W?B:tNBNB:c~AMoW:Á[vW?MZH{
oWFQF7EXJLRQ·AM:c
{WwWvTAV?MvWSO:c5FHvTAVF7E=H<W<m:=@SÏ{TFHEAMoW:*w>=HNBLRN
ABod=KA	:ÂT<WSR=@LOEWLOEW_oWFKµAMF5AMoWLOEW|=HwdF7vTA*<W?BF7w>=@w>L^SOLONPABLRQ~:XL^
cT:E>Q:ªBv>NBvW?B<dNpABoW:	G1vWE>Q·AML^F7EF@GAMoW:Á[vW?MZT­W{>o>LOQogªPCv>NPA
=@<><WS^ZsL^AMN~QF7C~CDF7E&NP:E>NP:t­WxU;ETG1FH?BABv>E>=KAM:SOZ|AMo>=KADSO:=XH:tN
ABo>:&cTFFH?LOcW:F7<d:EABFABoW:s<W?MF7NB:QvTABF7?
N5G.=@SOSO=7QZ=HE>c
F@AMoW:?pAM:CD<TAML^EW_w>vTAVCDLONBS^:t=HcTLOEW_=@?M_Hv>C~:EJAMNx

®	
£/Ä	d
®7®H®7©
LYG]:³A=@H:Í}â

¦U
¦+UK§J©
LOEÄ

®H®
C=KAQoLRN

®7®H®J©
§7¼"

¦t¼&=

cW=@CN

H®

®H®

ÇpÈ

ÇpÈ

gÌ

e?±e

y¿E´NBFHCD:Q=7NP:tNoW:?B:=9°«
<W?MF@qdS^:LRNG1F7vWE>c3=@ArABo>:
Q?MLOC~:*NMQ:EW:aABoW:?B:aC=Zwm:*EWFFHwXLOFHv>NpNBv>NP<m:QAxnpo>:E=
AB?=SC=Zwm:C=HcT:DAMoW?BF7vW_Hos=<dF7S^LRQ:QFHCD<WvTAM:?u9«

¦©

91¦
Q
º
¶
Í
©
\
©
â
£
Í
©
g
Í
x
Î
½

&
©

-
0

/
4


©
U
Q
º
¯

©
â
P

£
Í
©

e


g
â
¦
d

Q
d
£
¦
Q
©
x
©
â
£
¦
©
d
©
q
x
º
£
#
ß
Ú

º
¯
0
!
©
0
!
!
-
1

©
©
é
©

£
º
º
¯

©
©
©
â
¦
é
©
8
8
U
£
8
L
8
Í
©
©
8
â
©
¦
*
/
0
Ð

º
¯


¦
¦


¯

{

Í
¯

§
â
¯
Ä
â

Ä
d
.
d
.
£
.
£
Ä
©
â
¦
©
x
©
¯
>

e

e


0

01

§7§H§

L^E

¦®7®

LRN*

¦t®

®H®7®

¦+U¦t®H®

!:	*

CDLOS^SOL^F7Ebx

N~_7vWL^S^A

LOE
p{TNM=Z	

cW=@AM=@wd=HNB:L^E±AMoW:ro>FH<m:ABod=KAL^ALOSOSzABo>?BFK¸vW<=CD=@AMQobx
IvW<><dFJNP:uABoWLRNo>=@<W<m:EdNÃoWFK*{L^G]=KAa=@SOS/{ÅcTF:tNVAMoW:uG.=7Q·AF@G
ABo>:;cW=KA=@w>=7NP:VNB:=H?MQoD=K¡:QAzABo>:;N[AM?B:EW_@AMoDF@GABoW:;:XLOcW:E>Q:
=@_J=@LOE>NPAp=NBv>NB<d:tQ·AVNPFDLRcT:EJAMLYq>:tc>Ñ
¤WF7?cT:q>E>LYAM:EW:tNBN{7NBvW<W<mF7NB:AMo>=KAAMoW:cW=KA=@w>=7NP: LONFHGmNBL^î:
{ABo>=@A	ABo>:rC=KAQo&<W?MFHw>=HwWL^SOL^A[ZF@GAMoW:rQ?BLOCD:
®7®H®
¦®
<W?MF@q>SO:LRN5Í
CDLOS^SOL^F7Eb{°=HE>cABod=KA5:ÂW=HQ·AMS^ZFHE>:
ABod=KApF@G
LOEABoW:acW=@AM=@wd=HNB:VLONG1FHv>E>cAMF
<W?MF@q>SO:
C=KAQobx
EW:LOE7AMvWL^ABLOFHEgLONABo>=@AABoW:cW=@AM=Hw>=HNB:NB:=H?MQo²o>=HND:S^LOCDLY
E>=@AB:c
L^EdcTL^XLRcTv>=HSONo>F]F7vWSOcFHABoW:?BLRNP:ao>=X7:a?B:
C=@LOEW:c=@S^AB:?BEd=KABLOXH:aNBv>NP<m:QAMNxzíL^X7:E5ABoW:*X7:?MZ~SR=@?M_H:LOEWLY
ABLR=@SÅEvWCwd:?F@G=@S^AB:?ME>=@ABLOXH:aNPv>NB<m:Q·AN{AMoWLRNo>=HN]AMoW:*:¡:QA
F@G°?B:E>cT:?MLOEW_AMoW::XLOcW:E>Q:5LOEG.=X7FHvW?~F@GO
x|npo>:5?M:SO:XK=@EJAuSOLOH:SOLOoWFFc&?M=@ABLOFLON
4$456
( *
NPABLOS^SQS^FJNP:AMF
E¾:EJAML^?M:SOZµcTL^¡m:?B:E7AsLOE7AMvWL^ABLOFHE¾<W?BFTQ::c>N|wZµ=HE>=@SOFH_7Z
vW:EJAMLONPA;N[A=KAMLONPABLRQ=HSb=@<W<W?MF7=7QoW:N]AMFDAB:NPABLOEW_CvWSY
L^ABoG1?M:
ABLO<WSO:DoJZ<mF@AMoW:NB:Nx	npoWLRNa]F7vWSOc|=HcÁ[vdN[AABoW:DC=KAQo<W?MFHwW
=@w>L^SOLYA[ZAMFrA=@H:~=HQQFHv>E7AF@GAMoW:
<dFJNBNBLOwWS^:³=ZTN;F@G
®H®7®
FHwWAM=@LOEWLOEW_=uC=KAMQorL^ErABoW:acW=KA=@w>=7NP:7{7?M:<>SO=7QLOEW_	L^A³wZDABo>:
CDL^SOSOL^F7E
XK=@SOvW:H{QSOF7NB:DABF
LOE
{F@G
ABo>:~<>?BF7w>=@wWLOSOLYA[ZF@Gq>E>cTLOEW_=rC=KAQoLOEAMoW:cW=KA=@w>=7NP:7{mL^G
L^A°cTF:NE>F@AVLOE>QSOv>cT:*AMoW:uQ?BLOCDL^E>=HS/x
E>c=DC=@AMQo<W?MFHw>=@
wWLOS^L^A[ZFHG]FHE>S^Z
:XLRcT:EdQ:~ABo>=HE
E456
CDLOS^SOLOFHEbxay¿E<>=H?PAMLOQvWSR=@?t{mL^A*QFH?M?M:NB<dF7E>cWNpAMF
FHE>:uF@G
=	SOLOH:SOLOoWFFc?M=@ABLOFuLOEG.=XHF7vW?FHG_HvWLOS^A]F@G
{7?=KAMoW:?ABo>=HE
CDL^SOS^LOFHEx
oW:?B:t=HNaAMoW:G1F7?BCD:?L^EJAMvWLYAML^F7EsG1FTQv>NB:N~cTLO?B:tQ·ABSOZFHEsABo>:
oZ<dFHABoW:tNPLRN	
ABo>=@AHLRNb_Hv>L^S^A[ZH{tABo>:SR=KAPAM:?,=HcWcT?M:NMNB:NAMoWLON
LRNBNBvW:LOE>cTLO?B:tQ·ABSOZuwZG1FTQv>NBL^E>_*FHE~ABoW:;oJZ<mF@AMoW:NBLON
&ABo>=@A
NBFHCD:FHEW:L^EaAMoW:cW=@AM=@wd=HNB:LON_HvWLOSYA[Z7x,ILOE>Q:z]:EWFK|ABo>:?M:
p=HN³:ÂW=HQABSOZFHE>:C=@AMQob{AMF]p{W=@E>c5FHE>S^Zr=~C=KAQoWLOEW_DL^ET
cTLOXLOcTvd=@S;Q=@Ewd:_7vWL^S^A[ZH{]ABo>:NB:A[]FsoZ<dFHABoW:tNP:tN=@<W<m:=H?
SOFH_HLRQ=HS^SOZ:
:?B:~AMoWLON*NBF>{AMoW:?M:D]F7vWSRcwm:~E>F
NPAB?MFHEW_*?M:=7NPF7EAMF*G1FTQv>N]FHEF7EW:V?=KAMoW:?ABo>=HEDABoW:°F@ABo>:?
oWLRQo]F7vWSOcwm:*<W?MFHwWSO:C=KAMLOQH{WLOEXJLO:F@G,ABo>:*:EWF7?BCDFHvdN
cTL^¡m:?B:E>Q:wd:A[]::E3AMoW:LO?5=7NBNBFTQLR=KAB:tcS^LOH:S^LOoWFFTcg?M=@ABLOF7Nx
IJAMFQC=@?M?£
{=HE>cABov>N
F@G
{F7EABoW:z_7?BF7vWE>cWNÅABo>=@A
ABo>LONoZ<mF@ABo>:NBLONLRNzcW=@AM=@ÏLOE>cT:<d:E>cT:EJAt{HoW:?B:t=HN,oZJ<mF@AMoW:
Q=@E	E>F@A:XH:E	wm:³NB<d:tQL^q>:cuL^E~=HcTXK=HE>Q:]F@G><m:?BG1FH?MC~
NBLON
LOEW_uAMoW:*NP:t=@?Qor=@EdcrLRcT:EJAMLYG1ZLOEW_
xzVFK³:XH:?{JoWLOS^:aNBv>Qo
cW=@AM=K¿cT:<d:E>cT:EdQ:rQ=@E±=K¡:QAuG1?M:
vW:EJAMLONPAuLOETG1:?M:E>Q:N{L^AMN
?M:SO:XK=@E>Q:ABFDS^LOH:S^LOoWFFTcrLOETG1:?B:E>Q:*LRN=@?M_Hv>=HwWSO:Hx
=@?M:LOE>cT::tc
y¿E±G.=7Q·A{=HSYAMoWFHvW_7o±oZJ<mF@AMoW:NB:N
=@Edc
vWLOXK=@SO:EJAzFHEdQ:³:JE>FKAMo>=KAAMoW:;cW=@AM=@wd=HNB: QFHEJAM=HL^EdN
vWLOX=HS^:EJApwm:
:ÂW=7Q·ABSOZF7EW:°C=@AMQob{AMF {ABoW:Zr³:?M:°EWFHA:
G1FH?M:VC=@LOEW_aABod=KAF7w>NP:?BXK=@ABLOFHEbÃ]:VC=ZuAB:?MC¾ABoW:CY
p=Z&FHGaw>?BLRcT_HLOEW_sAMoW:=@<><>=@?B
!$7!
:EJApQo>=HNBCwm:A[³::EABo>:C¹=@<><d:t=@?NFHE?M:=HS^LRNBL^EW_aAMo>=KA³ABo>:
LRN=@wmFHvWA
ABLOCD:NSR=@?M_H:?
/0
ABod=@EABod=KA;FHG x
E>cÅ{=HN³:*CDFKXH:awd:A[]::EAMoW:NB:	oZJ

vWFHABLOEW_V=pS^LOH:S^LOoWFFTc?M=@ABLOFF@G


x
!+*+4
!$45!$E6²F@G

o>=7N=H?B_7vW:cLOE*G.=XHF7vW?bF@G

vWLOXK=@SO:EJAx

*23

0_/012

¦t®

®H®7®

¦§H§7§7©

*+4$456

¦t®

¦®7®

LOE

¦®H®

<mF@ABo>:NB:N{dAMoWLRNVG.=7Q·ABF7?;wm:A[³::EABo>:LO?°<W?MLOFH?;FTcWc>N°Q=@E>Q:SRN
:ÂW=7Q·ABSOZL^ABoABod=KA	wm:A[³::EAMoW:LO?	=HNMNPFTQLO=@AB:cS^LOH:S^LOoWFFTc
?=KABLOF7NE>F@AB:tcD=@wmFKXH:Hx
F@ABo=H<W<W?MF7=HQo>:NABov>N<W?BFTcTvdQ:pABo>:
LRcT:EJABLRQ=HS<mF7NPAB:?BLOFH?°<W?MFHw>=HwWL^SOL^A[Z£.oW:AMoW:?°G1FH?
F7?;G1F7?
²wm:LOEW_vWEWLOC~<mFH?BAM=HEJA{NPLOE>Q:;ABoW:tNP:°o>=XH:pAM?Bv>S^ZDwm:QF7CD:
SOFH_HLRQ=HS^SOZD:
vW:E7A³ABFABo>:cW=@AM=Hw>=HNB:°NB:=H?MQo
=@Edc±LYAN	qdE>cTLOEW_7N
=ZH:tNPLR=@E
<mF7NBLYAML^F7Eb{H³:?B:_7=H?McuFHvW?zLOETG1:?B:E>Q:V=7N:EJABLO?M:SOZuQ=H?B?ML^:tcuwZ
ABo>:<dFJN[AM:?ML^F7?<>?BF7w>=@wWLOSOLYA[Z7{ÅABoW:?B:DLRNaABov>NaE>FL^E>QFHCD<>=@ABL^
wWLOS^L^A[Zrwm:A[³::ErAMoW:aA[³FD=HE>=@SOZTNP:tNx

x|yG[{AM=@LOEW_|=G1vWE>cW=HC~:EJAM=@S

vWLOXK=@SO:EJA³NBvWw>NB:

:DNB::~AMo>=KAt{LOEAMoW:=@w>NB:E>Q:DF@G³=QSO:=H?BSOZNB<d:tQL^q>:coZJ
<mF@ABo>:NBLON{JABoW:*QF7E>Q:<TApF@G;ªPABoW:S^LOH:S^LOoWFFTc?=KAML^FJ­	Q=HErEWFHA
wm:?M:_J=@?cT:c´=HNFHwTÁ[:tQ·AML^X7:SOZCD:t=@EWLOEW_@G1v>S*L^ELYANP:SYG[{wWvTA
?=KABo>:?~LON°Á[v>NPAFHEW:7{zXHF7SO=@ABLOS^:7{zL^E>_H?M:cTLO:EJAFHGVABo>:s£.L^EXK=@?ML^
=@EJA
v>=HS^SOZ=HE>c
FH<><dFJNPL^AB:S^ZX7FHSR=KAML^SO:D<W?BLOFH?a<W?MFHwd=@wWLOS^L^A[ZAMFQFHCD<WSO:AM:DABo>=@A
LOETG1:?M:E>Q:Hx

<dFJN[AM:?MFH?DL^EWG1:?M:E>Q:

v>L^?ML^E>_|AMoW::

?B:

=Z7:NBLO=HE~=HE>=@SOZTNPLRN?M:NBFHSOXH:tN,ABoW:QFHEdQ:<W
oWLOS^:;ABoWLRNG1v>S^SOZ
?M:C=HL^E>Nx*yG
ABvd=@S<>=@?=HcWFÂ{=NP:?BLOFHv>N°<W?=HQABLRQ=@S,<W?MFHwWSO:C
vWLO?B:tN*AMo>=KA~]:5F@¡:?uSOLOH:SOLOoWFFc&?M=@ABLOF7N{
ªPF7wTÁ[:QABLOXLYA[ZT­?M:
?=KABo>:?³ABo>=HEr<mF7NPAB:?BLOFH?p<W?MFHw>=HwWLOS^L^ABLO:N{L^E5:XLOcW:E>Q:H{ToWLRQo
=@Edc±oWFKèQ=@E&³:5:E>NBvW?B:rABo>=@A~L^AMN
NBoWFHvWSRc&³:r_7L^X7:tÑè
CD:=HEWL^E>_=HE>cv>NB:~LONa<W?MFH<m:?MSOZ=H<W<W?M:QLO=@AB:cdÑ
Na=5C=KAP
AB:?FHGW<>NPZTQoWF7S^F7_HZVL^A,NB::CNÅABF;C~:]<W?M:G1:?=@w>S^:AMF
vWF@AM:ABo>:
SOL^7:SOL^oWFFTcs?=KABLOF?M:SR=KABLOEW_AMF bÃABoW:5QFHv>?PAuLOSOS]NBvW?B:S^Z
q>E>c5L^AV:=HNBLO:?³ABFDvWE>cW:?N[A=@E>c5=@E>c=HNMNP:tNBN]AMoW:a<W?BLOFH?p<W?MFHwW
LONa_7vWLOSYA[Z7{boWLRQoLRNao>=KA*LRNABoW:E|EW::cT:tc
=@w>L^SOLYA[ZABo>=@A
ABFQF7C~<>S^:AB:*AMoW:=HE>=@SOZTNPLRN{d?M=@ABoW:?VAMo>=@E£/=HN;?B:
v>L^?M:cG1F7?
=]/G1FTQv>NP:tc=@Ed=@SOZNBLRN
AMoW:~<W?BLOFH?°<W?MFHw>=HwWL^SOL^A[Z5AMo>=KAABo>:
_Hv>L^S^A[Z²<d=@?BA[Z²LRNLOE3ABo>:|cW=@AM=@wd=HNB:HxµnpoWLRN5Qo>FHLRQ:LRNr=HSONBF
SO:_7=HS^SOZr<>?B:G1:?=@wWSO:H{mNPLOE>Q:	ABoW:uG.=HQ·A;ABo>=@A
³=7NVLRcT:EJAMLYq>:tc
wZ±NP:t=@?QoWL^E>_=cW=KA=@w>=7NP:rCD=Zwm:5LOE>=HcWC~LRNMNPLOwWSO:r=HN:XL^
cT:E>Q:7x
¤WF7?G1v>?PAMoW:?£1FHG¢AB:EuoW:t=KAB:tc
=@SRcTLOEW_~=HE>cr9°FHE>EW:SOS^Z£
¦t§H§7§7©·¶
®H®>¦t©

cTLONMQvdNBNBL^F7E	F@G>ABoW:tNP:]LONMNPv>:N,NP::
9°FHE>EW:SOS^Z=HE>cr¤>?BLO:cWCD=HE
¬XH:ABA]>O*+4
9°=LRc

IJAMFTQJC=H?B?£

¦§7§37©¶

¦t§H§7§7©·¶

®7®H®7©¶

x£ÏÄ

£/Ä

%³ 	È!È"È

 

Çp

7µÇ

&& Ç

®7®

®H®7ÎW¶

NBL^CDLOSO=H?;<W?MFHw>S^:C

£.¥::NPAB:?°=HE>cItÁ[:?M<>N;Ä
¥::NPAB:?
=@EdcItÁ[:?B<dN;Ä
=@?MLRNP:tN]o>:E]:aEWFKAMoW:?M:a]:?B:A[³F
Q?MLOC~LOE>=HSON{mA[]FcTLONPABLOE>QAa9«
NPAM=@LOE>ND£.NM=ZFHEW:FHE=<WLOSY
SOFK*{F7EW:zFHE=VNPo>::A
o>=X7:zwd::EaG1F7vWE>c	=@AbABoW:³NBQ:EW:F@GTABo>:
Q?MLOC~:7{=HE>c|ABoW:?B:DLRN	=NPLOEW_HSO:NBv>NP<m:QA{
p{oWFC=@AMQoW:tN
FHE>:~FHG]AMoW:C NM=ZABoW:<>L^SOS^FK¾N[A=@LOE|!LYAMosLYAN	=HNMNPFH
QLR=KAM:c²C=KAMQo<W?MFHw>=HwWLOS^L^A[Z&ÍDx;FK¹LRN~ABoW:NPAB?M:EW_HABo²F@G
ABo>::XJLRcT:E>Q:D=@_J=@LOE>N[AO=K¡:QAB:tcwZABoW:~Cuv>SYAML^<WSOLRQL^A[ZF@G
NPAM=@LOE>NÑ
E>Q:p=H_7=HL^EABoW:?B:LRNz=aQoWF7LOQ:³FHGmoZ<mF@ABo>:NB:N,ABF	QFHCD<>=H?B:7{
ABo>:NB:wd:L^EW_*SOFH_7LOQ=@SOS^Zu:
vWLOX=HS^:EJAzL^E~ABo>:VS^LO_HoJAF@GmABo>:q>E>c
LOEW_7N{wWvWA	EWF@A	LOE±=HcTXK=@EdQ:Hx
q>?MNPAu=@<><W?BFJ=HQoQFHCD<>=H?B:tN

92
â
d
â
¦
¦

§
{
¯
0
6
%

	


0
¦

Ð
d
{
.
£
¦
¦
©
â

¦
%


0
¦
¦
¦
½

Ð
½

Ð

Ð

:
Ð
Ð
1
	
9
)
1
	

	

!
1
*
2

{

º

Ð
Ð
©
º
½
©
Ð
Ð
½
º
Ð

Ð
Ð
©
©
º
£
x

e
e
e

V
©

©

Ð

£/Ä

L @©U

¦L @©

|cWLOcDEWFHA]SO:=X7:³:LY
ª.|SO:G¢A³FHEW:VFHGABoW:A[³FuNPAM=HL^E>NM­aL^ABo&ª
=aNP:tQF7E>cuQFHCD<>=@?M:N°ª.SO:G¢AABoW:p<WLOSOS^FKN[A=@LOE>­
ABo>:?zNPAM=@LOE
¯O¶
L^ABoª
=HE>c&Z7:A~=ABo>L^?c
µcTLRc&E>F@ADS^:t=XH:r:LYAMoW:?DNPAM=@LOE>­
¾S^:G¢ArAMoW:<WLOSOS^FK
NPAM=@LOE>­±L^ABoèª.¸cTLRc3EWFHA
QF7CD<>=@?M:N±ª
SO:=XH:aAMoW:	<WLOSOS^FKN[A=@LOE>­WxU;E>cT:?NPF7CD:	=HNMNPvWCD<TAML^F7E>N{WABo>:
ÍD{ÍD{
=HNMNBFQLO=@AB:tc±S^LOH:S^LOoWFFTc&?=KAML^FJN=H?B:7{?B:tNP<m:QABLOXH:SOZH{
{doW:?M:
LRNAMoW:*<W?ML^F7?V<W?MFHw>=@
=@Edc
E>c5FHEdQ:a=@_7=HL^E{7AMoW:acTLY¡:?M:EdQ:N
wWLOS^L^A[ZAMo>=KAM&LRN³_HvWLOS^A[ZHx
wm:A[³::ErABoW:tNP:cTLRNB=H<W<d:t=@?p=KG¢AM:?]ABoW:Z=@?M:;QF7CuwWLOEW:crLYAMo
ABo>:LO?	XK=@?MZJLOEW_?M:SO:XK=@EJA*<W?ML^F7?	FTcWcWNxry¿E&9=LOcg£ÏÄ
=@?M_Hv>:;AMo>=KAL^ApLRN³ABo>:aq>?MNPApF@GAMoW:NB:aS^LOH:S^LOoWFFTcr?=KAML^FJN]ABo>=@A
?M:SR=KAB:tNpCDF7NPAcWL^?M:QABSOZABF~AMoW:*?B:S^:XK=@EJALONMNPv>:HÃABod=KAVF@G,ABo>:
_Hv>L^S^A*F@GZx
vTA*FHEW:~CuvdN[A	=@SRNBFAM=HH:~L^EJAMF=7QQFHvWEJAABo>=@A
ABo>:	EWFKS^:tcT_H:AMo>=KAAMoW:?M:*]:?B:aA[³FQvWSO<W?MLYAN:¡:QABLOXH:S^Z
cTF7vWwWSO:NAMoW:;<>?BLOFH?z<>?BF7w>=@wWLOSOLYA[Z~F@G
Nz_7vWL^S^A{=HN]QF7C~<d=@?M:c
L^ABo=DNPLOEW_HSO:¿NBv>NP<m:QAVQ=HNB:Hx

®H®

3È

Çp

7µÇ

TL^EXHF7S^XLOEW_=u?M=H<d:°FH?³NBQv:H{T=uQ?BLOCD:
y¿ErC=HEJZQ=HNB:N{

wm:|=±CDL^ÂABvW?M:F@G	w>L^F7S^F7_HLRQ=@SC=@AB:
AB?=HQ:C=Z²QS^:t=@?MS^Z
?MLO=HSG1?BF7C CDFH?M:uAMo>=@EsFHE>:~LOE>cTLOXLOcWv>=@SÏx
:C=ZF7?*CD=Z
EWFHA;EWFKoWFK C=HEJZQF7EJAB?ML^wWvWABFH?NV=H?B:*LOEXHFHSOXH:tcÅ{WF7?VABo>:
LRcT:EJABL^A[ZF@GpNPF7CD:uF@GABoW:CxyALRNaNPF7CD:ABLOCD:N<mF7NMNPLOwWSO:uAMF
NB:<>=H?M=@AB:VF7vTA]AMoW:°QFHCD<mFHEW:E7ANFHGcTL^¡m:?B:EJApQFHEJAB?ML^w>vTABF7?MN{

]wZ±AM=HL^EW_sLOEJABF±=HQQFHv>E7A~ABo>:cTLY¡:?MLOEW_±=@CDFHvWEJANDF@G
9«
IvW<><dFJNP:³]:³o>=X7:]=NPv>NB<m:Q·A<oWF5ªBC=KAMQo>:NM­ABo>:³Q?BLOCD:
AB?=HQ:H{KLOEuAMo>=KA=HS^SoWLRNw>=HE>cWN=@?M:³QFHEJAM=HL^E>:cL^E~LYAtx
od=KALON
ABo>:~NPAB?M:EW_HABoFHGABoW:D9«
:XLRcT:E>Q:=H_7=@LOE>NPA;oWLOCÑgnpoWLON
Q=HELOEJX7FHSOXH:QFHCD<WSO:Â=@E>c´NPvWwWABSO:Q=@SRQvWSR=KAML^F7E>Nr=HE>c3wm:
NB:E>NBLYAML^X7:ABF=HNMNPv>C~<WABLOFHE>NpC=HcW:Hx

=@AcWLY¡:?M:EJAVw>=HE>cWN{TwWvTAABo>LONLRNvWE>?B:S^LR=@wWSO:Hx

Ú


Ó	Ó

(uÚ,Ù

\°x³y¿E´<W?M:ÏAB?MLO=HS;cT:<dFJNPL^ABLOFHE>N
vW:E>QZ°FHG>IL^CD<>NBFHE

x*;dxVIL^CD<>NBFHE´G1FH?cTF7vWwWSO:

Ó.Ô
y¿E ABoW:sQ:S^:wW?M=@AB:tc3AB?MLR=@SaF@G
Cuv>?McT:?{ÅF7EW:~F@GAMoW:Q?ML^CD:NM=@CD<WSO:NaQF7vWSOcwd:D:Â<>SO=HL^EW:tc
=HND=|CDLYÂABv>?B:F@G°wWS^FFTcG1?BF7C
IL^CD<>NBFHEg=@Edc&FHE>:5FHG;ABo>:
XLOQABLOCN{F7E²íFHSRcTC=@Ebx
A~=Q:?PA=@LOE±S^FTQvdN{zILOCD<>NPF7E
\°{@=@E>c	ABoW:Q?MLOC~:pNM=@CD<WSO:
{HíFHSRcTC=@E
o>=7cu_7:EWFHA[ZJ<m:
o>=7c
{;ABoW:|<W?MF7NB:QvWABLOFHE
=@?M_Hv>:cABo>=@A*ABoW:?M:SO:XK=@EJA*C=KAQo<>?BF7w>=@wWLOSOLYA[ZÍ
NPo>FHvWSRc
wm:AM=HH:E	=7NABo>:G1?B:
N_H:E>F@A[Z<d:
³FHv>SOcwm:~CuvWS^ABLO<WSOL^:tcwZNBL^CDLOSO=H?
=@wmFHvWA
q>_7vW?B:tNQ=HSOQvWSO=@AB:tc&G1F7?F@AMoW:?SOFTQLAMF±FHwTA=@LOEg=HE²FKX7:?=@SOS
C=KAQo<W?MFHwd=@wWLOS^L^A[Z
x,npoW:cT:G1:E>Q:V=H?B_7vW:c	ABo>=@AÍ NPo>FHvWSRc
°
wm:uAMoW:uAMF@A=@S,<W?BF7w>=@w>L^SOLYA[ZF@G=HEZFHGABoW:~_H:EWF@A[Z<m:N{
\°{7\\°{KABod=KA]F7vWSRcuo>=X7:DªPC=KAQoW:cW­;ABo>:
Q?MLOC~:*NM=@CD<WSO:HÃz=HwdF7vTA
VFK³:X7:?t{HF7EDABoW:a=HNMNPv>C~<WABLOFHEDABod=KA³ABoW:°C~L^ÂABvW?M:°QFHE>NBLRN[AN
F@GdíF7SOcWCD=HEu=@EdcABoW:pQvWSO<W?MLYAt{ABoW:³QvWSO<W?MLYA,Cuv>NPAod=XH:A[Z<m:
! #"$&%(')*,+-.&'&/+-.&01+3245 (0.6'&+
;=<?>?>7@ACB7B>DFE9GH9IKJ!L)MN#O.B?PQ<R&S

x£ÏIv>Qo=5Í

')789"%('#:

ÎH§"

\°{

ºpº

"

F7?

ºpº

\°x7npoW:NB:po>=XH:pQF7CuwWLOEW:c<W?MFHw>=HwWLOS^L^A[ZÄ

¦+
=@Edc5L^AVLRNpABoW:u?B:tQLO<W?BFTQ=@SF@GABo>LONpqd_HvW?M:G1FH?;ÍABo>=@AVZL^:SOcWN
ABo>:	QFH?M?M:Q·ASOL^7:SOL^o>FJFTc?=KABLOF>xyG³:	cTLOcEWFHAVEWFKíF7SOc
C=@E
N_7:EWFHA[ZJ<m:H{7FH?AMoWFHvW_7oJAzABo>=@AzABo>:F@ABo>:?QFHEJAB?ML^w>vTABF7?
p=HN	NBFHCD:F7EW::SRNP:7{]:EW::csAMFQF7E>cTv>QA=CDFH?M:rQF7C~
<WSO:ÂQ=@SRQvWSR=KAML^F7EuAMFaFHwTA=@LOEuAMoW:?B:S^:XK=@EJAS^LOH:S^LOoWFFTcu?=KAML^Fdx
y¿EJAB:?B<W?M:AML^E>_ABo>LON=7NÍ
e@g
¦
£¢AMoWFHv>_Ho±AMoWLON~LRNu=HE=HQQLRcT:EJAM=HS]QFHE>QvW?B?M:EdQ:FHGA[]F<mF@
AB:EJABLR=@SOS^ZrcWLY¡:?M:EJAq>_7vW?B:tN

{z³:=H_7=HL^E&F7wTAM=HL^EÍUTåÄ

TÇ°Ç³7XW

ÇÇ

|Ès

oW:E|=rNBv>NB<d:tQ·At{mF7?°FHABoW:?°?M:SO:XK=HE7A°<>=@?BA[ZH{LRN;EWFHA=XK=@LOS^
<>?BFHq>S^LOEW_d{Åv>NP:G1vWSzLOETG1FH?MC=KAML^F7E|Q=HENBFHCD:
=@w>S^:~G1FH?*9«
ABLOCD:Nwm:F7wTAM=HL^EW:tcwJZ²<W?MF@q>SOL^E>_?M:SR=KAML^X7:N=HSYAMoWFHv>_Ho
ABo>:=HE>=@SOZTNPLRNABoW:E²?M:
vWLO?M:cQ=@E²wd:wmF@ABo3QFHE>Q:<TAMv>=@SOS^Z
=@Edc5QFHCD<WvTA=KABLOFHEd=@SOS^ZrQod=@SOS^:EW_HLOEW_>x

Ørß

Õ	Õ*á

bÓ.Ô

¦§

¦§7§H¼

N*9°«

=9«

LOEÄWx
L^E±ÄTx
L^SOS^:?M­&

;J=@CD:Nr;=@E>?M=@APA[Zp=HNr:ÂT:QvTAB:tcG1FH?5?M=H<d:=HE>c

y¿E
Cuv>?McT:?x~y¿E
<>?BFHq>S^:7{=HNMNBvWCD:cAMFwd:~G1?MFHC
ABo>:rQvWSO<W?MLYAt{p=HN	:ÂAB?=HQAB:c|G1?MFHC
NPF7C~:L^AB:CN*ABod=KAuo>=7c
wm::E	NPABF7?B:tcaNPLOE>Q:zABoW:Q?BLOCD:HxyAMN=7NBNBFTQLR=KAM:c°CD=@AMQo*<W?MFHwW
=@w>L^SOLYA[Z5³=7Np=@?MFHvWE>c
CDLOS^SOL^F7Ebx¬XH:?p?M:=7cTZABFDG.=HS^S
N~G.=HS^SR=HQZH{³ABo>:äz?M:NMNcTvWSOZ?B:<dF7?PAM:c
G1FH?ABoW:|<W?BFJNP:tQvTAMFH?
ABo>LON*=7NªBnpoW:?B:~LONa=
C~LOSOS^LOFHEsQo>=@EdQ:ABo>=@A*°=@ET
?=KAPA[Z3p=HN5EWFHAAMoW:
:X7:EAMoWFHv>_Hob{aNPLOE>Q:
³=7NavWE>=XK=@LOSR=@wWSO:H{ÅAMoW:?M:p=HNEWFCDFH?M:
;=HEW?=KAPA[Z
:XLRcT:EdQ:*=@_J=@LOE>N[AoWLOC¹AMo>=@E=H_7=@LOE>NPAp=HEZFHEW:a:SONB:Hx
;=HEW?=KAPA[Z
NpCDF@ABo>:?°=HE>cwW?MF@ABo>:?EWFKF@¡:?M:c5ABo>:LO?;FKE
9«
=@E>csAMoWLRN*G.=@LOSO:csAMF:ÂWQSOv>cT:5oWLOCx
_J=@LOE²?M:<mFH?BAMNDFHG°AMoW:=@wmFKXH:C=KAQo<>?BF7w>=@wWLOSOLYA[ZQL^?QvW
SR=KAB:tc=HN;:XLOcW:E>Q:	F@GoWLRN;_7vWLOSYAtxy¿EG.=HQ·At{>AMoW:=7Q·AMv>=@SS^LOH:
SOL^oWFFTc?M=@ABLOF>{Tw>=7NP:tcrF7EABoW:*LOE>cTLO?B:tQ·AV:XJLRcT:E>Q:aF@GoWLRN?M:S^
=KAML^X7:N
¤,L^Ed=@SOS^ZoWLONzwdFTcTZ~³=7N:ÂTovWCD:cÅ{J=@E>c=acTLO?M:Q·A]CD=@AMQoDFHwW
AM=HL^E>:cÅx
S^ABoWF7vW_Ho|ABo>:cT:G1:E>Q:=KABAB:C~<WAB:c|AMF=@APAM?BLOwWvTAM:
ABo>LONaAMFQFHEJA=@CDL^Ed=KABLOFHE{ÅLYA	LRNa_H:EW:?=@SOS^Z=H_H?M::tcABod=KA*ABo>:
Q=7NP:aLRNpEWFK QS^FJNP:tcÅx

G1F7?u<W?MF@qdS^LOEW_

{Wp=HN=H?BF7vWE>c

9°«

V3V

2Y
Ú(

Õ*á

Ü5Õu×

bÓRÒ

Õ	×
<d=KAB:?BE>LYA[Z¹E>:Q:tNBNM=@?MLOS^Z

2(ß
?M:X7FHSOXH:
äz?MFHw>S^:CDNFHGcTLRNP<>vTAB:tc
FHG	ABoW:<WvT
=@?MFHv>E>c3LOE>cTLO?B:tQ·AgªPC=KAQoWL^E>_7­&FHG	ABo>:9«
AM=@ABLOXH:*G.=@ABoW:?;L^ABoAMo>=KAF@GABo>:	AB?MvW:*G.=@ABoW:?{m=HN;<>=@?BABLR=@SOS^Z
?M:XH:t=@SO:cABo>?BF7vW_HoDAMoW:;QoWLOSOc
oW:Er<W?BFHq>SO:NG1?MFHC
CDF@AMoW:?t{VQoWLOSOc=HE>c3<WvWAM=KAML^X7:G.=KAMoW:?=@?M:=XK=@LOSO=HwWSO:H{pABo>:
SOL^7:SOL^oWFFTcg?=KABLOFsL^EG.=XHFHv>?F@G*<>=KAM:?MEWL^A[Z²Q=HE3wd:|Q=@SRQvW
SR=KAB:tcgwZ²NPAM=@EdcW=@?c²G1FH?MCuvWSR=@:7x
oW:EgABoW:<>vTAM=@ABLOXH:G.=K
Na<W?MF@qdS^:~LONav>E>=XK=@LOSO=HwWS^:7{Å<W?MF@q>SO:NC=Zwd:DF7wTAM=HL^EW:tc
ABo>:?
G1?MFHC¹oWLRN?M:SR=KAML^X7:NÃG1F7?:ÂW=@CD<WSO:H{A[³F~G1vWSOSwW?MF@AMoW:?N{T=HE>c
=@E3v>E>cTLRNP<WvWAB:c´QoWL^SRc3=@EdcgLYAN£.cWLY¡:?M:EJA
SY
ABo>FHvW_7osABoW:5S^F7_HLRQ=@S³N[AM:<>NuL^E²Q=@SRQv>SO=@ABLOEW_ABo>:S^LOH:S^LOoWFFTc

CDF@ABo>:?tx

N³9°«

93¶
g

g

Í
.
£
 

V
©
y
º

¯


e

g
½


½

Ù
ò
ï



º


º

Ð
¯

º

©
{

º
{

{
º
x

º
{
º
{
¯
©
x
V

½

Ð
Ö
ß
ï
Ä

¦

¯
¦



¯

¯


¯

®
x

Ø
ï



¯

x
½
½
¯
©

?=KABLOF|=H?B:5QSO:=@?~LOE<W?ML^EdQLO<WS^:s£¢AMoWFHv>_HoE>F@A~=HS^p=ZTNuNBFAMF
ABo>:]G1F7?B:E>NBLOQ]=@E>cF@AMoW:?:ÂT<m:?BAMNcTLO?B:tQ·AMS^Z*LOEXHFHSOXH:tc*LOENBv>Qo
{mABoW:DQF7C~<>vTAM=@ABLOFHE>=HS,cTL QvWS^ABLO:NFHGL^CD<WSO:CD:E7AML^E>_
³FH?M
ABo>:C
Q=@Ewd:	NB:X7:?M:Hx

gfpg

gfmg

gmpg

gmmg

m2pg

m2mg

pfpg

pfmg

b1pg

b1mg

b2pg

b2mg

m2gt

c2mg

c2pg

tfpg

tfmg

m1pg

m1mg

tf=pf?

b1gt

b2gt

È|Ç³

 È!±µÇ

c2gt

c1pg

c1mg

m1gt

c1gt

¤,L^_7vW?M:
<WSO:Âä=KAB:?BE>LYA[Z5\³=7NP:

=Z7:NBLO=HE~«;:A[³FH?M

:<>?B:tNP:E7A=KAML^F7EFHGÅ=u\]F7C~

&}

Ç³W}Ç

23 March 2004

I::CDL^E>_HSOZ~NPAB?=@LO_HoJAPG1F7?Bp=@?c<W?BF7wWSO:CNzFHGSO:_J=@Sd?B:t=HNBFHEWLOEW_
Q=HE
v>LOQSOZ	S^:t=HcABF	QFHCD<WSO:ÂTL^A[ZH{7QFHEJAB?MFKXH:?MNBZ*=@E>cDQFHETG1vT
NBL^F7EbÃÅABo>:³=HwdFKX7:z:ÂW=@CD<WSO:N,=@?M:bÁ[vdN[Az=G1:=@CDF7EW_7NPAC=@EZ7x
npoW:qd:SRc±<W?MFKXJLRcT:tN*=?BLRQo&=@Edc±Qo>=@SOS^:EW_HLOEW_AM:NPABwm:csG1F7?
=@EZ	_7:EW:?M=HSW=@<W<>?BFJ=HQo~FH?AB:tQoWEWL
vW:pG1FH?z?M:=7NPF7EWLOEW_°v>E>cT:?
vWE>Q:?BAM=HL^EJA[ZHxIv>QQ:NMN~L^EABoWLRNDXH:E7AMvW?M:QFHvWSRc=HSONBFo>=X7:
?M:=@SÅLOCD<>=HQAFHEABoW:aG.=HL^?M:?=7cTCDL^EWLRNPAB?=KABLOFHEF@GmÁ[v>NPABLRQ:7x
ß$#&%')(6-+*8-,.*0/1*0'3254
npoW:]F7?B?M:<mFH?BAB:c´oW:?M:p=HNrG1vWE>cW:c L^E <>=@?BA5wZgABo>:
ía=KANPwZ\]o>=H?BL^AM=HwWS^:¤WF7vWE>cW=@ABLOFHE=HE>cABo>:`:XH:?BovWSOCD:
n?Bv>NPAx

6:

76896
=@SRcTLOEW_>{9ux

E!

{HÄ

-	

7!#

*+4
=

x<;
ÔA

%@?

3J1

63*+4
=*

!#>76>=h

xmy¿ETG1:?M:E>Q:;LOE

<W?MF@q>SO:
:XLRcT:E>Q:uoW:EABoW:~NPvdNP<m:QA;LON;LOcW:EJABL^q>:cABoW?MFHvW_7o=
cW=KA=@w>=7NP:pNB:=@?Qobx3;

xd9°«
¦t§H§7©
!#C=

¦§7§7©
!#

G1FH?M:E>NBLRQLRcT:E7AMLYqmQ=KAML^F7E3£1L^ABo±9;LRNMQv>NMNPLOFHE

@Î

;dx7=@Edc9;F7EWEW:S^SOZH{Täx+;dx£
=@SRcTLOEW_>{H9x+;dx@=@Edc~9°FHE>EW:SOS^Z7{7äx
;dx>£
	*
H®7Î&=W¨
CD:ABo>Fc>N=HE>caS^:_7=HS7cT:tQLRNPLOFHE>NxE	

1+0
?BLOSOCD=Z7:?t{t`xt=HE>c	»aF7?BEWod=@v>NB:?t{t`xJ£
¦§¨K¼7©
!+

0132
ÂG1FH?cÃ]\]SR=@?M:E>cWFHE5ä?B:tNBNx

x0D°v>=HEJABL^AM=KAML^X7:
!$76
1
x

	*
¦
=
Ô

!#
	

¦t§J¨H¨H©


	

T*

GF

@B

-	

-	

HÎ

01

!#

*

0%

xbnpo>:;SOFH_HLRQFHGb<W?BFFHG[xIF
§W¦

!$(

*+4

\]FHo>:Eb{,`zx

\]FHo>:Eb{`zx
!#

!#

¦H¦
x1H

¦t§H¼7®7©
q{

!
;dx£
;dxd£
=¦®7Î
I<WLO:_7:SOo>=@S^AB:?{9ux!;>x£
)LM>/
!:	
;HF7oWE

1TS

!$45!

012

xäxO{°`=@vW?MLYAMî:Eb{°Ixp`zxO{°=HE>c
¦t§H§7§7©
x>I<W?ML^EW_7:?t{W«V:POzF7?Bx

\]FK³:SOS/{	xpí~xO{9=LRcÅ{
,>(
xnpo>:rLRNPSR=@E>c<W?MFHw>S^:CÃ\]FHo>:?M:EJA
6K{>£1:tcÅxäx*x¤W?M::


N=
xäx]£
9=LOcÅ{
¦§7§
v>NB:]FHGdLRcT:EJABL^qdQ=KABLOFHEu:XLOcW:E>Q:HxTy¿E
76RQ
*
C=@E=@Edc

UH
x7¤³xH¥±xICDLYAMo


{@<W<bx

E!#KJS

{Qo>=H<TAB:?
L^SO:Z5=@E>cIF7E>N{d\]o>LOQoW:tN[AM:?tx

¦@§

E

¦H¦

%1

%7/

!:	

!:	

<1
=W¨@®

?±e

!#*

-	*

]£

J

L^_7C~F7?B:

L^_7C~F7?B:

	

<1+0

¦§7§H§J©
v>=HS^L^AM=@ABLOXH:=HE>c
¦§7§J¨H©

y¿EDC=@EZQFHvW?BAzQ=HNB:N,AMoW:?M:LRNz=aCDLYÂT:c~C=HNMNF@G:XLRcT:EdQ:H{
ABo>:|XK=@?MLOFHv>NL^AB:CN5?M:SR=KAML^E>_±ABF²:=HQo3FHABoW:?=HE>cgAMF&ABo>:
vWS^ABLOC=KAB:LRNMNPvW:DLOE±QFHCD<WSO:Â=@E>csNBvWwTABSO:p=ZNx
oW:?M:=7N
CDF7NPA³SR=ZH:?MN³=@?M:°QFHEJAB:EJA]AMF~od=@E>cTSO:°ABoW:tNP:aQF7C~<>S^:ÂL^ABLO:N
LOEr<WvW?M:SOZDL^EJAMvWLYAML^X7:°p=ZTN{NBFHCD:;SO:_J=@SNBQoWF7SO=H?MNzo>=XH:QFHEW
NBLOcT:?B:tcG1FH?MC=@SABFFHSRNVAMFroW:S^<|L^EABoWLRN°<W?BFTQ:NMNx
E:t=@?MS^Z
=@EdcN[AML^SOSLOE
	>vW:EJABLR=@SQFHEJAB?MLOwWvTABLOFHEp=HNpAMoW:ucT:XH:S^F7<WCD:EJA
F@GTAMoW:
¦§7ÎJ¨@©
¦§>¦ÎW¶½
=_7?M=H<WoWLRQ=HSb?B:<W?M:NB:EJAM=@ABLOFHEF@G
v>=HS^L^AM=@ABLOXH:	?M:SR=KAML^F7E>NBoWL^<dN
wm:A[³::EL^AB:CDNpFHG,:XLOcT:E>Q:7x
!$(
*>*>!#;NPLOCDL^SR=@?ML^A[Z°wm:A[³::E
npoW:?B:]LONNBFHCD:
LO_HCDFH?M:
Qo>=H?PANr=@EdcgABoW:|CDFcW:?ME3AB:tQoWEWFHSOFH_7Z²FHGJ*
63
=ZH:tNPLR=@EEW:A[³FH?MTNuo>=X7:
£Ï\]FK³:SOSS>
wm::E|v>NB:cG1F7?°wmF@AMo
v>=HE7AMLYA=KAML^X7:=@Ed=@S^
ZTNPLRNVFHGS^:_7=@S:XLRcT:E>Q:HxVnpoW:	G1FH?MC~:?Vp=HNVv>E>cT:?BAM=HH:EwZ
9=LOc=@E>cs¬XH:ABA£
LOEABoW:QFHEJAB:ÂJA*FHG³=<W?MF7NB:QvT
ABLOFHEG1FH??MFHwWwm:?MZH{Ko>:?M:]L^A³=7N?M:
vWLO?M:c*AMF*QFHCwWLOEW:]:ZH:
L^ABEW:tNBN{HqdwW?B:=@E>cDw>S^FFTc:XLRcT:EdQ:HÃABo>:°NPAB?Mv>Q·AMvW?B:;F@GÅABo>:
EW:A[]F7?BL^CD<WSOLO:NX=H?BLOFHvdNQF7E>cTL^ABLOFHE>=HS7LOE>cT:<d:E>cT:E>Q:]?B:SO=@
ABLOFHEdNPoWLO<>N]wd:A[]::EAMoW:X=H?BLR=@w>S^:tN{HABo>=@A³Q=HEwm:°:ÂJAM?M=7Q·AM:c
=@Edcv>NB:cAMF5NBL^CD<WSOLYG1Z:ÂT<W?B:tNBNBLOFHE>NVG1FH?;SOLOH:SOLOoWFFc?M=@ABLOF7Nx
=ZH:tNPLR=@E|EW:A[³FH?MTND£1oWLRQo
E>F@ABo>:?aG.=HNMQLOE>=@ABLOEW_v>NP:FHG
p=HN*=@SRNBFNPAB?MFHE>_HSOZL^E	>vW:EdQ:cwZ
LO_HCDF7?B:t=@Es=@E>=HS^ZTNBLON
LRNVAMoW:?M:=HE>=@SOZTNPLRNwZ»*=Hc>=@EW:u=HE>cITQovWC
FHGzABo>:
:XLRcT:EdQ:LOEsABoW:5Q:SO:w>?M=@AB:csCvW?cT:?*AM?BLR=@SF@G;IT=HQQF=HE>c
9z=@E>î:ABABLÏx
=ZH:tNPLR=@E±EW:A[]F7?BTNo>=XH:<W?MFKXH:tcs<>=@?BABLRQvWSR=@?MSOZ±X=HS^vd=@wWSO:
LOE´=HcWcW?B:tNBNBL^E>_QF7C~<>S^:Âg<>?BF7wWS^:CNF@G	LOEJAB:?B<W?M:A=KAML^F7E3F@G
9«
=ZH:tNPLR=@E
EW:A[]F7?B?B:<W?M:NB:EJAM=@ABLOFHEF@GAMoW:D=@w>NB:EJA;G.=@ABoW:?a<>=KAM:?MEWLYA[Z
Q=7NP:|cT:NMQ?ML^wm:cL^E
Äx¸npoWLONcTLRNP<>SO=ZTN:XLOcT:EJABLR=@S?B:
SR=KABLOFHEdNPoWLO<>NaLOE±=NB:C=HE7AMLOQ=@SOS^ZvWE>=@CwWLO_HvWF7v>N{QSO:=@?*=HE>c
NPAB?ML^LOEW_aCD=HEWEW:?{H=HE>c~NPvW<><dF7?PANzQF7C~<>S^:ÂQF7C~<>vTAM=@ABLOFHE>=HS
=@Ed=@SOZNBLRNv>NBL^EW_ _H:EW:?=@S	<>vW?B<mF7NB:ä?BF7w>=@wWLOSOLONPABLRQ&¬ÂT<m:?BA
IZTNPAB:C
NPFHG¢A[³=H?B:DNBv>Qo±=HNNP::9°=LRc%>O*+4
£/Ä
G1FH?°G1vW?BABoW:?°cT:AM=HL^SRNxnpoWLRNAB:tQoWEWF7S^F7_HZLON°=@SRNPFwm:
LOEW_&=@<W<>S^LO:cAMF&N[AML^SOS;CDFH?M:QF7C~<>S^:Â²<W?MFHwWSO:CNFHGa9«
=@Ed=@SOZNBLRN{7L^EXHF7S^XLOEW_>{NB:<>=H?M=@AB:SOZ~FH?LOErQFHCuw>L^E>=@ABLOFHEb{NBv>Qo
G1:=@ABvW?M:N=HN°CDLYÂT:tcNPAM=@LOE>ND£.¥FH?BAB:?=)N*+4YxÅÄ
{CvTAM=@
9=LOcÄ
ABLOFHE&£/9°=LRc
{dQFHEJA=@CDL^Ed=KABLOFHE{
=@Edcq>:SOc=HE>cSO=HwdF7?M=@ABFH?MZD:?M?BF7?MNx

<>?BFHq>S^::XLOcT:E>Q:7xnpov>Nb¤,LO_HvW?M:

NBoWFKVNb=

¦§H§7©

®H®>¦H¶

®H®7Î7©

®H®7Î7©

*

xÅÄ

®H®

<?>?>7@ACB7BL

<?H! DFE

L)M7N#O

94©

e
½

!

(
1
0
0
½
{
Ð
/
0
½
%
	
9
2
%
*
4
x
x
º
Ð
Ð
Ð

º
½
©
£
º

¦
º
D
¨
x
x
Ä
©

4

¦
Ã
º
"
Ð
Ð
j
l
6
h
º
©
1

0
4
1
%
1
0
{

x
º

1

0
4
1
%


%
{
{
x
º
1
-
*
0
*

3


{
{

=
x
$
*
2
4
	
)

$
2
4

0
0
*

3



{
Ô
r

x

x
$
*
2
%
0
2
%
*
	

0
6
%
%

V
©
?

	


0
9
?
H
0
!
2

0
)
4

©
x
½
=HSOcWL^EW_±=HE>c²9°FHE>EW:SOS^Z £
63*+4=*
=h

7!#

*+4

E!

9=LOcÅ{
ZTNPLRNF@G,G1FH?M:EdNPLRQLOcT:EJABL^qdQ=@ABLOFHE:XLRcT:E>Q:HxI;
$-
9=LOcÅ{

qdQ=@ABLOFHEL^ABoLOCD<d:?PG1:tQ·A;:XLOcT:E>Q:7xG!

,*+7!

*+4
=

{

40=

®H®>¦t©

xäx£/Ä

9=LOcÅ{

x\]FHCDCD:EJA]F7EIJAMFQC=@?M?

N*ªM`bLOH:
:XLOcW:E>Q:H{boW:E
S^LOoWFFTc?=KAML^FJN°G1FH?*:XK=HS^v>=@ABLOEW_9°«
ABoW:NBv>NP<m:QALRN	G1F7vWE>csAMoW?MFHvW_7o=cW=@AM=@wd=HNB:rNP:t=@?Qo>­
£1L^ABo?B:tNP<mFHEdNP:|wJZ´IABFTQCD=H?B?
M!
§J¨
9=LOcÅ{

( >

!#

®H®

NABoW:FH?M:C
.

=ZH:tN
=@E>c³:LO_HoW
_
-	
!$7!
x,£.ävWwWSOLONBoW:cDLOEwmFFHG1FH?MC¾=7N
¨T¦
({d:cTL^AB:tcwJZ1LOQod=@?cILOEwWvW?MEW:

01

xaäx£/Ä
6K{
ÔmÔ

(

L^E>_5:XJLRcT:E>Q:~wZÁ[v>?BLO:Nx
J*
9=LOcÅ{

63

&=¼7®

=ZH:NBLR=@EuE>:AP

!:	

®7®HÎJ©

xHäxd£/Ä
-	
,4$45!
>CB<4

EF7wTÁ[:QAPFH?ML^:EJAB:c


]F7?BG1F7?~:tN[AML^C=@ABLOEW_CvTAM=@ABLOFHE?=KAM:Nx±y¿E
E!
>!#*
>6
¤W?M:Z
9=LOcÅ{

4
K
x	 ! "$#%'&)(+*,	-./	* Åx
xÅäx£ÏÄ

-
K*
E!#
*!>*£.:cÅx\°x¥±x

J8!:	

E!
,*+7!

!:	

Qv>NMNBL^F7EFHGz¥::tN[AM:?;=HE>cItÁ[:?M<>N	£ÏÄ

=T§H®

0.1

!$45!$76*

9=LOcÅ{

xÅU;NBL^E>_=*_7?M=H<WoWL^
xTäx=@E>cr¬zXH:APAt{7y·x
Q=HS>CD:AMoWFTcDABF	=7NBNBLONPAzAMoW:V:XK=HS^v>=@ABLOFHEDF@GbQFHCD<WSOLOQ=KAB:tc
<>=KABAB:?BE>NF@GW:XLOcT:E>Q:7x

¦§7§J¨H©
*+4

=h>!#

xÅ£

!#



*+4

*+4

1+0

®7®

®7®

7!#

?N0

{+VJÄ

	

%K?

	*+4

	
2K{

x\]FHo>:?M:EJA°=@Ed=@S^

1./'1
1+0
LONBoWFH<±=HE>c

		

;>x

oWLOQo|S^LOH:S^LOoWFFTc?=KAML^FÑy¿E|cTLRN[
0132

!#>76>
xmäx=@E>c¥FH?BAB:?M=>{
63*

xy¿EgcTLRNBQv>NBNBLOFHE
¦§7§H©
xP;
-	
¦§7§7©
!#
ÔA
¦§7§37©
!#E6>=h
¦t§H§H¼J©

	*
"=W¨T¦
&=TÎW¦
xäxz=HE>c¥FH?BAB:?M=>{7;>xV£
;dx,£
&=
xdäxd=@E>c¥F7?PAM:?=W{;dx£
!"2*K{
3A
;dx^{b=HE>cä=7NBQ=@SOL/{9uxÅ`zx£ÏÄ
	*
	*
!#
	
3&=
ÔWÒ
;dx^{ä=HNMQ=HS^LÏ{M9ux`x^{=@E>c´X=HE
	*
7¨H¨=§"
;dx³=HE>c3¤W?MLO:cTC=@E{*xp9ux*£
r
!$(_!:9
J¨@¼&=¼7¼

xÅäz?MFHwd=@wWLOS^LRNPABLRQ:ÂT<m:?BA³NBZNPAB:CN
=*

!#
x¤>FH?M:E>NBLRQ°LRcT:E7AMLY

q{
x^{¤WF7?B:CD=HEb{>`x

!#

xäxO{¥F7?PAM:?=W{

xnpoW:*<W?MFHw>=HwWLOS^L^A[ZrcT:w>=KAM:Hx

xO{d=HE>c
!#
( 
xÅ=HE>c|¥F7NPAB:SOSO:?t{b¤]x]£
¦§¨H¨H©
7!#
xd¤d=@LO?BSO:Z=@E>c¤³xm¥F7NPAB:S^SO:?
:NBS^:ZH{

QF7EXH:?NM=K
45!#
45!#6K{
{d<W<bx
Î3H§
:t=HcTLOEW_d{W¥=HNMNB=7Qov>NP:APANx

¦t§H§7§7©
!#

xÅäx^{b¥F7?PAM:?=W{

®H®7®7©
xdIABFTQJ

V>x
*x£

¦§H¼7®7©
!#

xmIx£ÏÄ

xµ9«

x@M!

,*+7!

.0

:LO?{

7!#

W¦

E!

E!

!:	4$

=W¨@§

{dÄ7Ä

9=LOcÅ{
F@G

Ò
3J1
¼HÎ"=

3N1

9=LOcÅ{

!#*
9°FHEWEW:S^SOZH{°äx

=¼

¬z_7_HSO:NPABF7Eb{

¬zX7:ABA{>y·x

!:	
	*

9=LOcÅ{

®H®>¦t©
«VF7ET/G.=@ABoW:?Bo>FJFTcF7?VCuvTA=KAML^F7EdÑ
<>?BF7w>=@wWLOSOLONPABLRQ	=@<W
<W?MF7=HQoABF<>=@?M:EJAM=HS:ÂWQSOv>NPLOFHEL^E<>=KAM:?MEWL^A[Z5AM:NPABLOEW_>x

cW=KA=@w>=7NP:NP:t=@?QoW:N5=@E>c3ABoW:S^:_7=HSQFHE>NBvWCD<TABLOFHE´F@G
NBQL^:EJABL^qdQ:XLOcW:E>Q:Hx21K!#
§HÎ>¦

¤>=HL^?MSO:ZH{
ABLOFHE=HwdF7vTA*\]F7S^SOLOE>Nxy¿E1=
£1:tcÅx
cWcWLONBFHET

FÂ:S/{9x
G1FH?pG1F7?B:E>NPLRQL^EWG1:?M:E>Q:°G1?MFHCè_H:E>:ABLRQC=@?MH:?NxN=h.*

x£/Ä

®H®

`b:APAB:?ABF~AMoW:	¬cTL^ABF7?	£1L^ABo?M:NB<dF7E>NP:tN³wJZ
C=@?M?V=@E>c

x>9;:XS^LOE

¨=

SOS^:E`=@EW:7Ã5npoW:ä:EW

QF7C~

)-0
!:	
;HF7oWE

!$4

7!#

2RQ

012

	

!

x

¤,L^E>H:SRNPAB:LOEb{r¥&x

¦§¨K®J©
=ZH:NBLR=@E	=@<><W?BFJ=HQoABF°LOcW:EJABL^qdQ=@ABLOFHE	:XLOcT:E>Q:7x3

x5£

x	=@E>c¾¤>=HL^?MSO:ZH{
T¦K¨

{	V

*

¤,L^E>H:SRNPAB:LOEb{>¥&x

¦§¨¦t©
CD:EJAFHE¸ªBn?MLO=HS³wZ¥=KAMoW:C=KAMLOQNB­>x43S*

x£

+*

x³npoW:	SR=VNpF@G<W?MFHw>=HwWLOS^L^A[Z5=HE>cABoW:uSO=
!#

!+

!$76

!#

"10

x,npoW:a:XLRcT:ET
cW=@AM=Hw>=HNB:NP:t=@?Qo~QFHEJAB?MFKXH:?MNBZ
!#

®H®7Î7©


!

;

!#
¼H§
x>=HE>c¤>=@LO?MS^:ZH{
¦¼H®>¦
®7®

=T§

!#

!$

*

!

76Kx

!:	

¦t§H§7©
7E!

-	C=

0%

.2
!:	

¥::NPAB:?t{*x

íLO_H:?M:E>î:?t{Tí~xb£/Ä
!$$-
_HvWLOEäz?M:NMNx

10
»*=Hc>=@EW:7{;dx


»*=ZH:7{W9ux£

¥::NPAB:?t{*x

%J1

x7£
OzFH?Mx

¦t§J¨@§7©
F@GABoW:SR=@E>cbx
3

ABLR=@SdX=HS^v>:L^EDAMoW:;9«
=@E>cABoW:uA[]FN[A=@LOE<W?MFHwWSO:Cx
ÄWx

x=@EdcaIWQoJv>C{K9x
Z

*+456
*3
L^SO:Z=@E>cIF7E>N{W«V:

	
	 5
E	
x;dxW=@E>cItÁ[:?M<>N{W¥±xb£/Ä
x;dxW=@E>cItÁ[:?M<>N{T¥±xb£/Ä
xäVxt9°=LRcÅ{9ux&;>x
><$
;dx^{H9=LRcÅ{
4*$
&=¼7Î

ä=7NBQ=@S=HE>csoWLRN	oW:L^?Nx61K!#
V3V

¦t§H§7§7©
9°«
=cW=KA=@w>=7NP:aNB:=@?Qobx

T¦
=¼3

1+0
¦§¨K§7©

¥F7?PAM:?=W{
äz?MFHw>=HwWLOS^LRN[AMLOQ:ÂT<d:?PANBZTN[AM:CNG1FH?9°«
q>SOL^EW_dx
®"

ITQovWC{W9x£

IJAMFQC=@?M?t{

7!#.*

4W*+7!

-	

1./

®H®

oJZABoW:a:G¢
G1:QAzF@Gd<>?BLOFH?FTcWcWNNBoWFHv>SOc~=HQQFHCD<>=HEZ°AMoW:pS^LOH:S^LOoWFFTc
?M=@ABLOFoW:E?B:<dF7?PAML^EW_9«
:XLRcT:E>Q:£1L^ABo&cWLONMQvT
NPLOFHE*wZ
v>QSO:AMFHE
=@E>c\°xm¥±xÅnp?ML^_7_7N

x7äx^{H=HE>cD`=HvW?BL^ABî:Eb{HIÅxH`zxW£ÏÄ

2@{

®H®7Î7©
CDLYÂAMvW?B:<>?BFH
6K{
¦§>¦

012

!$45!$E6

=@SRcTL^E>_>{&;>xIx
	P!

?M:XL^:3F@GABoW:aQ=7NP:a=@_J=@LOE>N[A
!#

SO=HLONB:

x£

xÅ`L^7:SOL^oWFFTc?=KAML^FJNG1FH?³:XK=@SOv>=@ABLOEW_
:XLRcT:E>Q:aoW:E5ABoW:*NBv>NB<d:tQ·ALON³G1F7vWE>crABoW?MFHv>_Ho

NPLOFHE=HE>c?MLYAMv>=@SL^EABoW:	SO:_J=@S<W?BFTQ:NMNx73S*

¦t§J¨¦

n?BLOwd:7{W`zxWux£

LOQ=@Sb<>?BFF@G[x3
n?BLOwd:7{³`x	x°£

+*

¦§¨¦
¦Î
¦§>¦Î7©

!#
LO_HCDFH?M:H{

!#

;>xTux£
;>xJ	xÅ£

LO_HCDFH?M:H{

£¢AMoWL^?c:cWE
LOS^SOLO=HCN{7í~xW£

LOS^SOLO=HCN{>í~xÅ£

!:	*

!#

¦t§HÎ¨@©
x>`LYABABSO:H{
¦§¨K§7©
!#
¦t§H¼7®7©
q{

¦®HÎ

vW:F@G,CD=@ABoW:C=KAP

xgn?MLR=@SwZ&C=KAMoW:C=KAMLOQNÃä?B:tQL^

!#

!#



*

J¨T¦

!
G1vW?BABoW:?VQ?MLYAML

=W¨
¦t¼W¦t®&=
§&=T§HÎ
xbnpoW:<W?BF7wWSO:C¸F@Gb<W?MFF@G[x8>4$45!:	
¨H¨=§7§
®&=
r
!$(_!:	*
=W¨

xJnpo>:³C=@ABoW:CD=@ABLRQN,F@Gd<W?BFFHG[xF
V>x

!#
	
§¨=Î7®H¼

=HE>c
NBoWF7?PAp?B:PÁ[FHLOE>cT:?xKF

.
F7NPABFHEx

-	
?MFKEb{

!#>!#*

xGH

{>Ä

;

{

011
!$(

95
¯

©
x
1
0
%
{
A

{
x

Ä
©
x
º
¯
$

)

%
1

0
%
-
?

*
)
;
{
%

%
H
-

1
0
©
x

x

º
$



)
9

%
1



	
0
1

2
%
-
	
9
	


	
)
=
%
%
>
;
*
>

%

1
0
!
)
º
º
x
©

V
©
x
½
V
©
x
0
*

>
$
9
*
2
	
)
3
!
%
;
{
x

½
;
1

0
	
1

B

	
%

%
{
x

º
1

0
	
1


%
=
1
0
{

{
V

x

1

0
	
1


%
1
0
%
A

V
Î
x

1
(
0
{
V
§
x

x

B
1
0

	
%
=
	
0
1
4
{
{
x

º
½
Ä
©
	
9
)
*
	
;
1

0
4
1

%
%
{
Ò
r
{
x

-
!

*
	
0
*

3


{
{
F
0
4
0
*

3


{
Ô
r

x
½

½
º
x

º
©
1
0
%
{
A

{
¦
Ä
¨
V
=

x
½
x
º
x

%
%

2
$
1
½
x
º
©
x

½

½
x
º
x

º
*
0
9
0
)
0
*

3



{
=
x

½
x
º
x

0
0
*

3



{


{
x
Ä
©
x
3
1
	


-
3
!
%
0

*
0
	



E

0

º

x
?
$
*
2
!
%
?
	
%
!

1
*
	
)
U
*
L
)

½
1

F
-
*
*

3


{
{
Î
V
=
x
½

1
(
0
%
{
A
r
{
¨
Ä
Î
½
V
©
x
½


º
º
©
x
0
*

*
2
*
	
)
3
!
%
;
{
x

x

H

1
1
4
1


;
{
=
Ä
x
x

º
-
!

*
	
0
*

3

{


{
x


1
(
0
%
{
A
A
{
x
=
©
x

Ð
*
0
0
)
0
*

3



{


{
Ä
®
x
w
©
0
0
)
0
*

3



{


{
Ä
x
½
1
!
%
0
*

3


{

{
x
½
=
1

)
4
$
©
º
º
½
0
9
4
0
*

3


{
Ô
r
Î
V

½
x

0
4
0
*

3



{
Ô
r

x
E(cid:14)cient Non-Parametric Function Induction in Semi-Supervised

Learning

Olivier Delalleau, Yoshua Bengio and Nicolas Le Roux

Dept. IRO, Universit(cid:19)e de Montr(cid:19)eal

P.O. Box 6128, Succ. Centre-Ville, Montreal, H3C 3J7, Qc, Canada

fdelallea,bengioy,lerouxnig@iro.umontreal.ca

Abstract

There has been an increase of interest for
semi-supervised learning recently, because of
the many datasets with large amounts of
unlabeled examples and only a few labeled
ones. This paper follows up on proposed non-
parametric algorithms which provide an esti-
mated continuous label for the given unla-
beled examples. First, it extends them to
function induction algorithms that minimize
a regularization criterion applied to an out-
of-sample example, and happen to have the
form of Parzen windows regressors. This al-
lows to predict test labels without solving
again a linear system of dimension n (the
number of unlabeled and labeled training ex-
amples), which can cost O(n3). Second, this
function induction procedure gives rise to an
e(cid:14)cient approximation of the training pro-
cess, reducing the linear system to be solved
to m (cid:28) n unknowns, using only a subset of
m examples. An improvement of O(n2=m2)
in time can thus be obtained. Comparative
experiments are presented, showing the good
performance of the induction formula and ap-
proximation algorithm.

1

INTRODUCTION

Several non-parametric approaches to semi-supervised
learning (see (Seeger, 2001) for a review of semi-
supervised learning) have been recently introduced,
e.g.
in (Szummer & Jaakkola, 2002; Chapelle et al.,
2003; Belkin & Niyogi, 2003; Zhu et al., 2003a; Zhu
et al., 2003b; Zhou et al., 2004). They rely on weak im-
plicit assumptions on the generating data distribution,
e.g. smoothness of the target function with respect to
a given notion of similarity between examples1. For

1See also (Kemp et al., 2004) for a hierarchically struc-

tured notion of a priori similarity.

classi(cid:12)cation tasks this amounts to assuming that the
target function is constant within the region of input
space (or \cluster" (Chapelle et al., 2003)) associated
with a particular class. These previous non-parametric
approaches exploit the idea of building and smoothing
a graph in which each example is associated with a
node, and arcs between two nodes are associated with
the value of a similarity function applied on the corre-
sponding two examples.

It is not always clear with these graph-based kernel
methods for semi-supervised learning how to gener-
alize to previously unseen test examples.
In general
they have been designed for the transductive setting,
in which the test examples must be provided before
doing the expensive part of training. This typically
requires solving a linear system with n equations and
n parameters, where n is the number of labeled and
unlabeled data. In a truly inductive setting where new
examples are given one after the other and a predic-
tion must be given after each example, it can be very
computationally costly to solve such a system anew
for each of these test examples. In (Zhu et al., 2003b)
it is proposed to assign to the test case the label (or
inferred label) of the nearest neighbor (NN) from the
training set (labeled or unlabeled). In this paper we
derive from the training criterion an inductive formula
that turns out to have the form of a Parzen windows
predictor, for a computational cost that is O(n). Be-
sides being smoother than the NN-algorithm, this in-
duction formula is consistent with the predicted labels
on the unlabeled training data.

In addition to providing a relatively cheap way of do-
ing function induction, the proposed approach opens
the door to e(cid:14)cient approximations even in the trans-
ductive setting. Since we know the analytic functional
form of the prediction at a point x in terms of the
predictions at a set of training points, we can use it to
express all the predictions in terms of a small subset of
m (cid:28) n examples (i.e. a low-rank approximation) and
solve a linear system with m variables and equations.

962 NON-PARAMETRIC

for i 2 L [ U then gives rise to the linear system

SMOOTHNESS CRITERION

In the mathematical formulations, we only consider
here the case of binary classi(cid:12)cation. Each labeled
example xk (1 (cid:20) k (cid:20) l) is associated with a label
yk 2 f(cid:0)1; 1g, and we turn the classi(cid:12)cation task into
a regression one by looking for the values of a func-
tion f on both labeled and unlabeled examples xi
(1 (cid:20) i (cid:20) n), such that f (xi) 2 [(cid:0)1; 1]. The pre-
dicted class of xi is thus sign(f (xi)). Note however
that all algorithms proposed extend naturally to mul-
ticlass problems, using the usual one vs. rest trick.

Among the previously proposed approaches, several
can be cast as the minimization of a criterion (often a
quadratic form) in terms of the function values f (xi)
at the labeled and unlabeled training examples xi:

CW;D;D0;(cid:21)(f ) =

1
2 X

i;j2U [L

W (xi; xj)D(f (xi); f (xj))

+ (cid:21)X

i2L

D0(f (xi); yi)

(1)

where U is the unlabeled set, L the labeled set, xi
the i-th example, yi the target label for i 2 L, W ((cid:1); (cid:1))
is a positive similarity function (e.g. a Gaussian ker-
nel) applied on a pair of inputs, and D((cid:1); (cid:1)) and D0((cid:1); (cid:1))
are lower-bounded dissimilarity functions applied on a
pair of output values. Three methods using a crite-
rion of this form have already been proposed: (Zhu
et al., 2003a), (Zhou et al., 2004) (where an addi-
tional regularization term is added to the cost, equal
to (cid:21)Pi2U f (xi)2), and (Belkin et al., 2004) (where for
the purpose of theoretical analysis, they add the con-
straint Pi f (xi) = 0). To obtain a quadratic form in
f (xi) one typically chooses D and D0 to be quadratic,
e.g. the Euclidean distance. This criterion can then
be minimized exactly for the n function values f (xi).
In general this could cost O(n3) operations, possibly
less if the input similarity function W ((cid:1); (cid:1)) is sparse.

A quadratic dissimilarity function makes a lot of sense
in regression problems but has also been used success-
fully in classi(cid:12)cation problems, by looking for a con-
tinuous labeling function f . The (cid:12)rst term of eq. 1
indeed enforces the smoothness of f . The second term
makes f consistent with the given labels. The hyper-
parameter (cid:21) controls the trade-o(cid:11) between those two
costs. It should depend on the amount of noise in the
observed values yi, i.e. on the particular data distribu-
tion (although for example (Zhu et al., 2003a) consider
forcing f (xi) = yi, which corresponds to (cid:21) = +1).

In the following we study the case where D and D0 are
the Euclidean distance. We also assume samples are
sorted so that L = f1; : : : ; lg and U = fl + 1; : : : ; ng.
The minimization of the criterion w.r.t. all the f (xi)

with

A ~f = (cid:21)~y

~y = (y1; : : : ; yl; 0; : : : ; 0)T

~f = (f (x1); : : : ; f (xn))T

(2)

(3)

and, using the matrix notation Wij = W (xi; xj), the
matrix A written as follows:

A = (cid:21)(cid:1)L + Diag(W 1n) (cid:0) W

(4)

where Diag(v) is the matrix whose diagonal is the vec-
tor v, 1n is the vector of n ones, and (cid:1)L (n (cid:2) n) is

((cid:1)L)ij = (cid:14)ij (cid:14)i2L:

(5)

This solution has the disadvantage of providing no ob-
vious prediction for new examples, but the method is
generally used transductively (the test examples are
included in the unlabeled set). To obtain function in-
duction without having to solve the linear system for
each new test point, one alternative would be to pa-
rameterize f with a (cid:13)exible form such as a neural net-
work or a linear combination of non-linear bases (see
also (Belkin & Niyogi, 2003)). Another is the induc-
tion formula proposed below.

3 FUNCTION INDUCTION

FORMULA

In order to transform the above transductive algo-
rithms into function induction algorithms we will do
two things: (i) consider the same type of smoothness
criterion as in eq. 1, but including a test example x,
and (ii) as in ordinary function induction (by opposi-
tion to transduction), require that the value of f (xi)
on training examples xi remain (cid:12)xed even after x has
been added2.

The second point is motivated by the prohibitive cost
of solving again the linear system, and the reasonable
assumption that the value of the function over the un-
labeled examples will not change much with the addi-
tion of a new point. This is clearly true asymptotically
(when n ! 1). In the non-asymptotic case we should
expect transduction to perform better than induction
(again, assuming test samples are drawn from the same
distribution as the training data), but as shown in our
experiments, the loss is typically very small, and com-
parable to the variability due to the selection of train-
ing examples.

Adding terms for a new unlabeled point x in eq. 1 and
keeping the value of f (cid:12)xed on the training points xj

2Here we assume x to be drawn from the same distri-
bution as the training samples:
if it is not the case, this
provides another justi(cid:12)cation for keeping the f (xi) (cid:12)xed.

97leads to the minimization of the modi(cid:12)ed criterion

W;D(f (x)) = X
C (cid:3)

j2U [L

W (x; xj)D(f (x); f (xj)):

(6)

Taking for D the usual Euclidean distance, C (cid:3)
convex in f (x) and is minimized when
f (x) = Pj2U [L W (x; xj)f (xj)

= ~f (x):

W;D is

(7)

Pj2U [L W (x; xj)

Interestingly, this is exactly the formula for Parzen
windows or Nadaraya-Watson non-parametric regres-
sion (Nadaraya, 1964; Watson, 1964) when W is the
Gaussian kernel and the estimated f (xi) on the train-
ing set are considered as desired values.
One may want to see what happens when we apply ~f
on a point xi of the training set. For i 2 U , we obtain
that ~f (xi) = f (xi). But for i 2 L,

~f (xi) = f (xi) +

(cid:21)(f (xi) (cid:0) yi)

Pj2U [L W (xi; xj)

:

Thus the induction formula (eq. 7) gives the same re-
sult as the transduction formula (implicitely de(cid:12)ned
by eq. 2) over unlabeled points, but on labeled exam-
ples it chooses a value that is \smoother" than f (xi)
(not as close to yi). This may lead to classi(cid:12)cation
errors on the labeled set, but generalization error may
improve by allowing non-zero training error on labeled
samples. This remark is also valid in the special case
where (cid:21) = +1, where we (cid:12)x f (xi) = yi for i 2 L,
because the value of ~f (xi) given by eq. 7 may be dif-
ferent from yi (though experiments showed such label
changes were very unlikely in practice).

The proposed algorithm for semi-supervised learning
is summarized in algorithm 1, where we use eq. 2 for
training and eq. 7 for testing.

Algorithm 1 Semi-supervised induction

(1) Training phase
Compute A = (cid:21)(cid:1)L + Diag(W 1n) (cid:0) W (eq. 4)
Solve the linear system A ~f = (cid:21)~y (eq. 2) to obtain
f (xi) = ~fi
(2) Testing phase
For a new point x, compute its label ~f (x) by eq. 7

4 SPEEDING UP THE TRAINING

PHASE

A simple way to reduce the cubic computational
requirement and quadratic memory requirement for
’training’ the non-parametric semi-supervised algo-
rithms of section 2 is to force the solutions to be ex-
pressed in terms of a subset of the examples. This
idea has already been exploited successfully in a di(cid:11)er-
ent form for other kernel algorithms, e.g. for Gaussian
processes (Williams & Seeger, 2001).

Here we will take advantage of the induction formula
(eq. 7) to simplify the linear system to m (cid:28) n equa-
tions and variables, where m is the size of a subset of
examples that will form a basis for expressing all the
other function values. Let S (cid:26) L [ U with L (cid:26) S be
such a subset, with jSj = m. De(cid:12)ne R = U nS. The
idea is to force f (xi) for i 2 R to be expressed as a
linear combination of the f (xj) with j 2 S:
8i 2 R; f (xi) = Pj2S W (xi; xj)f (xj)

(8)

:

Pj2S W (xi; xj)

Plugging this in eq. 1, we separate the cost in four
terms (CRR; CRS; CSS; CL):

W (xi; xj) (f (xi) (cid:0) f (xj))2

+ 2 (cid:2)

1
2 X

i2R;j2S

CRR

{z

}

W (xi; xj) (f (xi) (cid:0) f (xj))2

CRS

{z

}

W (xi; xj) (f (xi) (cid:0) f (xj))2

+

1
2 X
|

i;j2R

|
1
2 X
|

i;j2S

{z
CSS
(f (xi) (cid:0) yi)2

+ (cid:21)X

i2L

}

|

CL

{z

}

Let ~f denote now the vector with entries f (xi), only for
i 2 S (they are the values to identify). To simplify the
notations, decompose W in the following sub-matrices:

W = (cid:18) WSS W 0
RS
WRS WRR

(cid:19) :

with WSS of size (m (cid:2) m), WRS of size ((n (cid:0) m) (cid:2) m)
and WRR of size ((n (cid:0) m) (cid:2) (n (cid:0) m)). Also de(cid:12)ne W RS
,
the matrix of size ((n(cid:0)m)(cid:2)m) with entries

Wij

Pk2S

Wik

for i 2 R and j 2 S.

Using these notations, the gradient of the above cost
with respect to ~f can be written as follows:

h2(cid:16)W
|

T

RS (Diag(WRR1r) (cid:0) WRR) W RS(cid:17)i ~f
}

RR

~
f

{z
+ h2(cid:16)Diag(WSR1r) (cid:0) W

@C

@

T

RSWRS(cid:17)i ~f
}

|

@C

RS

{z

~
f

@

+ [2 (Diag(WSS 1m) (cid:0) WSS)] ~f
}

{z

|

@C

SS

~
f

@

+ 2(cid:21)(cid:1)L( ~f (cid:0) ~y)
}

{z

|

@C

~
f

L

@

where (cid:1)L is the same as in eq. 5, but is of size (m(cid:2)m),
and ~y is the vector of targets (eq. 3), of size m. The

98linear system A ~f = (cid:21)~y of eq. 2 is thus rede(cid:12)ned with
the following system matrix:

A =

(cid:21)(cid:1)L
T
RS (Diag(WRR1r) (cid:0) WRR) W RS

+ W

+ Diag(WSR1r) (cid:0) W
+ Diag(WSS 1m) (cid:0) WSS:

T
RSWRS

The main computational cost now comes from the
computation of @CRR
. To avoid it, we simply choose
@ ~f
to ignore CRR in the total cost, so that the matrix A
can be computed in O(m2(n (cid:0) m)) time, using only
O(m2) memory, instead of respectively O(m(n (cid:0) m)2)
time and O(m(n (cid:0) m)) memory when keeping CRR.
By doing so we lessen the smoothness constraint on
f , since we do not take into account the part of the
cost enforcing smoothness between the examples in R.
However, this may have a bene(cid:12)cial e(cid:11)ect. Indeed, the
costs CRS and CRR can be seen as regularizers encour-
aging the smoothness of f on R. In particular, using
CRR may induce strong constraints on f that could be
inappropriate when the approximation of eq. 8 is inex-
act (which especially happens when a point in R is far
from all examples in S). This could constrain f too
much, thus penalizing the classi(cid:12)cation performance.
In this case, discarding CRR, besides yielding a signif-
icant speed-up, also gives better results. Algorithm 2
summarizes this algorithm (not using CRR).

of f would not be enforced. This suggests to start with
S = ; and R = U , then add samples xi iteratively by
choosing the point farthest from the current subset, i.e.
the one that minimizes Pj2L[S W (xi; xj). Note that
adding a sample that is far from all other examples
in the dataset will not help, thus we discard an added
point if this is the case (xj being \far" is de(cid:12)ned by a
threshold on Pi2Rnfjg W (xi; xj)). In the worst case,
this could make the algorithm in O(n2), but assuming
only few examples are far from all others, it scales as
O(mn). Once this (cid:12)rst subset is selected, we re(cid:12)ne it
by training the algorithm presented in section 2 on the
subset S, in order to get an approximation of the f (xi)
for i 2 S, and by using the induction formula of sec-
tion 3 (eq. 7) to get an approximation of the ~f (xj) for
j 2 R. We then discard samples in S for which the con-
(cid:12)dence in their labels is high3, and replace them with
samples in R for which the con(cid:12)dence is low (sam-
ples near the decision surface). One should be care-
ful when removing samples, though: we make sure we
do not leave \empty" regions (i.e. Pi2L[S W (xi; xj)
must stay above some threshold for all j 2 R). Finally,
labeled samples are added to S. Overall, the cost of
this selection phase is on the order of O(mn + m3).
Experiments showing its e(cid:11)ectiveness are presented in
section 5.3. The subset selection algorithm4 is sum-
marized in algorithm 3.

5 EXPERIMENTS

Algorithm 2 Fast semi-supervised induction

5.1 FUNCTION INDUCTION

Choose a subset S (cid:19) L (e.g. with algorithm 3)
R   U n S
(1) Training phase

A  

(cid:21)(cid:1)L + Diag(WSR1r)

(cid:0) W

T
RSWRS + Diag(WSS 1m) (cid:0) WSS

Solve the linear system A ~f = (cid:21)~y to obtain f (xi) =
~fi for i 2 S
Use eq. 8 to obtain f (xi) for i 2 R
(2) Testing phase
For a new point x, compute its label ~f (x) by eq. 7

In general, training using only a subset of m (cid:28) n sam-
ples will not perform as well as using the whole dataset.
Thus, it can be important to choose the examples in
the subset carefully to get better results than a ran-
dom selection. Our criterion to choose those examples
is based on eq. 8, that shows f (xi) for i =2 S should be
well approximated by the value of f at the neighbors
of xi in S (the notion of neighborhood being de(cid:12)ned
by W ). Thus, in particular, xi for i =2 S should not
be too far from the examples in S. This is also im-
portant because when discarding the part CRR of the
cost, we must be careful to cover the whole manifold
with S, or we may leave \gaps" where the smoothness

Here, we want to validate our induction formula
(eq. 7): the goal is to show that it gives results close
to what would have been obtained if the test points
had been included in the training set (transduction).
Indeed, we expect that the more unlabeled points the
better, but how much better? Experiments have been
performed on the \Letter Image Recognition" dataset
of the UCI Machine Learning repository (UCI MLR).
There are 26 handwritten characters classes, to be dis-
criminated using 16 geometric features. However, to
keep things simple, we reduce to a binary problem by
considering only the class formed by the characters
’I’ and ’O’ and the class formed by ’J’ and ’Q’ (the
choice of these letters makes the problem harder than
a basic two-character classi(cid:12)cation task). This yields a
dataset of 3038 samples. We use for W (x; y) the Gaus-
sian kernel with bandwidth 1: W (x; y) = e(cid:0)jjx(cid:0)yjj2
First, we analyze how the labels can vary between in-

.

3 In a binary classi(cid:12)cation task, the con(cid:12)dence is given
by jf (xi)j. In the multi-class case, it is the di(cid:11)erence be-
tween the weights of the two classes with highest weights.
4Note that it would be interesting to investigate the use
of such an algorithm in cases where one can obtain labels,
but at a cost, and needs to select which samples to label.

99Algorithm 3 Subset selection

(cid:14) is a small threshold, e.g. (cid:14) = 10(cid:0)10
(1) Greedy selection
S   ; fThe subset we are going to buildg
R   U fThe rest of the unlabeled datag
while jSj + jLj < m do

Find j 2 R s.t. Pi2Rnfjg W (xi; xj) (cid:21) (cid:14) and
Pi2L[S W (xi; xj) is minimum
S   S [ fjg
R   R n fjg

(2) Improving the decision surface
Compute an approximate of f (xi), i 2 S and ~f (xj),
j 2 R, by applying algorithm 1 with the labeled set
L and the unlabeled set S and using eq. 7 on R
SH   the points in S with highest con(cid:12)dence (see
footnote 3)
RL   the points in R with lowest con(cid:12)dence
for all j 2 SH do

if mini2R Pk2L[Snfjg W (xi; xk) (cid:21) (cid:14) then

k(cid:3)   argmink2RL Pi2L[S W (xk; xi)
S   (S n fjg) [ fk(cid:3)g fReplace j by k(cid:3) in Sg
R   (R n fk(cid:3)g) [ fjg fReplace k(cid:3) by j in Rg

S   S [ L fAdd the labeled data to the subsetg

duction and transduction when the test set is large
(section 5.1.1), then we study how this variation com-
pares to the intrinsic variability due to the choice of
training data (section 5.1.2).

5.1.1

Induction vs. Transduction

When we add new points to the training set, two ques-
tions arise. First, do the f (xi) change signi(cid:12)cantly?
Second, how important is the di(cid:11)erence between in-
duction and transduction over a large amount of new
points, in terms of classi(cid:12)cation performance?

The experiments shown in (cid:12)g. 1 have been made con-
sidering three training sets, T 1000, T 2000 and T 3038,
containing respectively 1000, 2000 and 3038 samples
(the results plotted are averaged on 10 runs with ran-
domly selected T 1000 and T 2000). The (cid:12)rst two
curves show the percentage of unlabeled data in T 1000
and T 2000 whose label has changed compared to the
labels obtained when training over T 3038 (the whole
dataset). This validates our hypothesis that the f (xi)
do not change much when adding new training points.

The next three curves show the classi(cid:12)cation error for
the unlabeled data respectively on T 3038 n T 2000,
T 3038 n T 1000 and T 3038 n T 1000, for the algorithm
trained respectively on T 2000, T 1000 and T 3038. This
allows us to see that the induction’s performance is
close to that of transduction (the average relative in-
crease in classi(cid:12)cation error compared to transduction
is about 20% for T 1000 and 10% for T 2000). In addi-

0.2

0.18

0.16

0.14

0.12

0.1

0.08

0.06

0.04

0.02

0
0

Percentage of label changes T2000 vs T3038
Percentage of label changes T1000 vs T3038
Test error T2000(induction)
Test error T1000(induction)
Test error T3038(transduction)

100

200

300

400

500

600

700

800

900

1000

Figure 1: Percentage of unlabeled training data whose
label has changed when test points were added to the
training set, and classi(cid:12)cation error in induction and
transduction. Horizontal axis: number of labeled data.

tion, the di(cid:11)erence is very small for large amounts of
labeled data as well as for very small amounts. This
can be explained in the (cid:12)rst case by the fact that
enough information is available in the labeled data to
get close to optimal classi(cid:12)cation, and in the second
case, that there are too few labeled data to ensure an
e(cid:14)cient prediction, either transductive or inductive.

5.1.2 Varying The Test Set Size

The previous experiments have shown that when the
test set is large in comparison with the training set,
the induction formula will not be as e(cid:14)cient as trans-
duction. It is thus interesting to see how evolves the
di(cid:11)erence between induction and transduction as the
test set size varies in proportion with the training set
size.
In particular, for which size of the test set is
that di(cid:11)erence comparable to the sensitivity of the al-
gorithm with respect to the choice of training set?

To answer this question, we need a large enough
dataset to be able to choose random training sets. The
whole Letters dataset is thus used here, and the binary
classi(cid:12)cation problem is to discriminate the letters ’A’
to ’M’ from the letters ’N’ to ’Z’. We take a (cid:12)xed test
set of size 1000. We repeat 10 times the experiments
that consists in: (i) choosing a random base training
set of 2000 samples (with 10% labeled), and (ii) com-
puting the average error on test points in transduction
by adding a fraction of them to this base training set
and solving the linear system (eq. 2), repeating this so
as to compute the error on all test points.

The results are shown in (cid:12)g. 2, when we vary the num-
ber of test points added to the training set. Adding 0
test points is slightly di(cid:11)erent, since it corresponds to

1000.25

0.24

0.23

0.22

0.21

0.2

0.19

Test error

0

0.05

0.1

0.15

0.2

0.25

0.3

0.35

0.4

0.45

0.5

Figure 2: Horizontal axis: number of test points added
in proportion with the size of the training set. Vertical
axis: test error (in transduction for a proportion > 0,
and in induction for the proportion 0).

the induction setting, that we plot here for comparison
purpose. We see that adding a fraction of test exam-
ples corresponding to less than 5% of the training set
does not yield a signi(cid:12)cant decrease in the test error
compared to induction, given the intrinsic variability
due to the choice of training set. It could be interest-
ing to compare induction with the limit case where we
add only 1 test point at step (ii). We did not do it
because of the computational costs, but one would ex-
pect the di(cid:11)erence with induction to be smaller than
for the 5% fraction.

5.2 COMPARISON WITH EXISTING

ALGORITHM

We compare our proposed algorithm (alg. 1) to the
semi-supervised Laplacian algorithm from (Belkin &
Niyogi, 2003), for which classi(cid:12)cation accuracy on the
MNIST database of handwritten digits is available.
Benchmarking our induction algorithm against the
Laplacian algorithm is interesting because the latter
does not fall into the general framework of section 2.

In order to obtain the best performance, a few re(cid:12)ne-
ments are necessary. First, it is better to use a sparse
weighting function, which allows to get rid of the noise
introduced by far-away examples, and also makes com-
putations faster. The simplest way to do this is to
combine the original weighting function (the Gaussian
kernel) with k-nearest-neighbors. We de(cid:12)ne a new
weighting function Wk by Wk(xi; xj) = W (xi; xj) if
xi is a k-nearest-neighbor of xj or vice-versa, and 0
otherwise. Second, Wk is normalized as in Spectral
Clustering (Ng et al., 2002), i.e.

W k(xi; xj) =

Wk(xi; xj)

q 1

n Pr6=i Wk(xi; xr)Pr6=j Wk(xr; xk)

:

Table 1: Comparative Classi(cid:12)cation Error of the
Laplacian Algorithm (Belkin & Niyogi,
2003),
W holeSet in Transduction and W holeSet in Induc-
tion on the MNIST Database. On the horizontal axis
is the number of labeled examples and we use two dif-
ferent sizes of training sets (1000 and 10000 examples).

Labeled
Total: 1000
Laplacian
W holeSettrans
W holeSetind
Total: 10000
Laplacian
W holeSettrans
W holeSetind

50

100

500

1000

5000

29:3
25:4
26:3

25:5
25:1
25:1

19:6
17:3
18:8

10:7
11:3
11:3

11:5
9:5
11:3

6:2
5:3
5:7

5:7
5:2
5:1

4:2
3:5
4:2

Finally, the dataset is systematically preprocessed by
a Principal Component Analysis on the training part
(labeled and unlabeled), to further reduce noise in the
data (we keep the (cid:12)rst 45 principal components).

Results are presented in table 1. Hyperparameters
(number of nearest neighbors and kernel bandwidth)
were optimized on a validation set of 20000 samples,
while the experiments were done on the rest (40000
samples). The classi(cid:12)cation error is averaged over 100
runs, where the train (1000 or 10000 samples) and
test sets (5000 samples) are randomly selected among
those 40000 samples. Standard errors (not shown) are
all under 2% of the error. The Laplacian algorithm
was used in a transductive setting, while we separate
the results for our algorithm into W holeSettrans (error
on the training data) and W holeSetind (error on the
test data, obtained thanks to the induction formula)5.
On average, both W holeSettrans and W holeSetind
slightly outperform the Laplacian algorithm.

5.3 APPROXIMATION ALGORITHMS

The aim of this section is to compare the classi(cid:12)cation
performance of various algorithms:

(cid:15) W holeSet, the original algorithm presented in
sections 2 and 3, where we make use of all unla-
beled training data (same as W holeSetind in the
previous section),

(cid:15) RSubsubOnly,

the algorithm that consists

in
speeding-up training by using only a random sub-
set of the unlabeled training samples (the rest is
completely discarded),

(cid:15) RSubRR and RSubnoRR, the approximation algo-
rithms described in section 4, when the subset is
selected randomly (the second algorithm discards
the part CRR of the cost for faster training),

5See section 5.3 for the origin of the name W holeSet.

101Table 2: Comparative Computational Requirements
(n = number of training data, m = subset size)

W holeSet
RSubsubOnly

RSubRR
SSubRR
RSubnoRR
SSubnoRR

Time
O(n3)
O(m3)

Memory

O(n2)
O(m2)

O(m(n (cid:0) m)2) O(m(n (cid:0) m))

O(m2(n (cid:0) m))

O(m2)

(cid:15) SSubRR and SSubnoRR, which are similar to
those above, except that the subset is now selected
as in algorithm 3.

Table 2 summarizes time and memory requirements
for these algorithms: in particular, the approximation
method described in section 4, when we discard the
part CRR of the cost (RSubnoRR and SSubnoRR), im-
proves the computation time and memory usage by a
factor approximately (n=m)2.
The classi(cid:12)cation performance of these algorithms was
compared on three multi-class problems: LETTERS
is the \Letter Image Recognition" dataset from the
UCI MLR. (26 classes, dimension 16), MNIST con-
tains the (cid:12)rst 20000 samples of the MNIST database
of handwritten digits (10 classes, dimension 784), and
COVTYPE contains the (cid:12)rst 20000 samples of the
normalized6 \Forest CoverType" dataset from the UCI
MLR. (7 classes, dimension 54).

We repeat 50 times the experiment that consists in
choosing randomly 10000 samples as training data and
the rest as the test set, and computing the test error
(using the induction formula) for the di(cid:11)erent algo-
rithms. The average classi(cid:12)cation error on the test
set (with standard error) is presented in table 3 for
W holeSet, RSubsubOnly, RSubnoRR and SSubnoRR.
For each dataset, results for a labeled fraction of 1%,
5% and 10% of the training data are presented. In al-
gorithms using only a subset of the unlabeled data (i.e.
all but W holeSet), the subset contains only 10% of the
unlabeled set. Hyperparameters have been roughly es-
timated and remain (cid:12)xed on each dataset. In particu-
lar, (cid:21) (in eq. 1) is set to 100 for all datasets, and the
bandwidth of the Gaussian kernel used is set to 1 for
LETTERS, 1:4 for MNIST and 1:5 for COVTYPE.
The approximation algorithms using the part CRR of
the cost (RSubRR and SSubRR) are not shown in the
results, because it turns out that using CRR does not
necessarily improve the classi(cid:12)cation accuracy, as ar-
gued in section 4. Additionally, discarding CRR makes
training signi(cid:12)cantly faster. Compared to W holeSet,
typical training times with these speci(cid:12)c settings show
that RSubsubOnly is about 150 times faster, RSubnoRR

6Scaled so that each feature has standard deviation 1.

Table 3: Comparative Classi(cid:12)cation Error (Induction)
of W holeSet, RSubsubOnly, RSubnoRR and SSubnoRR,
for Various Fractions of Labeled Data.

% labeled
1%

W holeSet
RSubsubOnly
RSubnoRR
SSubnoRR
5%

W holeSet
RSubsubOnly
RSubnoRR
SSubnoRR
10%

W holeSet
RSubsubOnly
RSubnoRR
SSubnoRR

LETTERS

MNIST

COVTYPE

56:0 (cid:6) 0:4
59:8 (cid:6) 0:3
57:4 (cid:6) 0:4
55:8 (cid:6) 0:3

35:8 (cid:6) 1:0
29:6 (cid:6) 0:4
27:7 (cid:6) 0:6
24:4 (cid:6) 0:3

47:3 (cid:6) 1:1
44:8 (cid:6) 0:4
75:7 (cid:6) 2:5
45:0 (cid:6) 0:4

27:1 (cid:6) 0:4
32:1 (cid:6) 0:2
29:1 (cid:6) 0:2
28:5 (cid:6) 0:2

12:8 (cid:6) 0:2
14:9 (cid:6) 0:1
12:6 (cid:6) 0:1
12:3 (cid:6) 0:1

37:1 (cid:6) 0:2
35:4 (cid:6) 0:2
70:6 (cid:6) 3:2
35:8 (cid:6) 0:2

18:8 (cid:6) 0:3
22:5 (cid:6) 0:1
20:3 (cid:6) 0:1
19:8 (cid:6) 0:1

9:5 (cid:6) 0:1
11:4 (cid:6) 0:1
9:7 (cid:6) 0:1
9:5 (cid:6) 0:1

34:7 (cid:6) 0:1
32:4 (cid:6) 0:1
64:7 (cid:6) 3:6
33:4 (cid:6) 0:1

about 15 times, and SSubnoRR about 10 times. Note
however that these factors increase very fast with the
size of the dataset (10000 samples is still \small").

The (cid:12)rst observation that can be made from table 3
is that SSubnoRR consistently outperforms (or does
about the same as) RSubnoRR, which validates our
subset selection step (alg. 3). However, rather sur-
prisingly, RSubsubOnly can yield better performance
than W holeSet (on MNIST for 1% of labeled data,
and systematically on COVTYPE): adding more un-
labeled data actually harms the classi(cid:12)cation accuracy.
There may be various reasons to this, the (cid:12)rst one be-
ing that hyperparameters should be optimized sepa-
ratly for each algorithm to get their best performance.
In addition, for high-dimensional data without obvious
clusters or low-dimensional representation, it is known
that the inter-points distances tend to be all the same
and meaningless (see e.g. (Beyer et al., 1999)). Thus,
using a Gaussian kernel will force us to consider rather
large neighborhoods, which prevents a sensible propa-
gation of labels through the data during training. Nev-
ertheless, a constatation that arises from those results
is that SSubnoRR never \breaks down", being always
either the best or close to the best. It is able to take ad-
vantage of all the unlabeled data, while focussing the
computations on a well chosen subset. The importance
of the subset selection is made clear with COVTYPE,
where choosing a random subset can be catastrophic:
this is probably because the approximation made in
eq. 8 is very poor for some of the points which are not
in the subset, due to the low structure in the data.

Note that the goal here is not to obtain the best perfor-
mance, but to compare the e(cid:11)ectiveness of those algo-

102rithms under the same experimental settings. Indeed,
further re(cid:12)nements of the weighting function (see sec-
tion 5.2) can greatly improve classi(cid:12)cation accuracy.

Additional experiments were performed to asses the
superiority of our subset selection algorithm over ran-
dom selection. In the following, unless speci(cid:12)ed oth-
erwise, datasets come from the UCI MLR, and were
preprocessed with standard normalization. The ker-
nel bandwidth was approximately chosen to optimize
the performance of RSubnoRR, and (cid:21) was arbitrar-
ily set to 100. The experiments consist in taking as
training set 67% of the available data, 10% of which
are labeled, and using the subset approximation meth-
ods RSubnoRR and SSubnoRR with a subset of size
10% of the available unlabeled training data. The
classi(cid:12)cation error is then computed on the rest of
the data (test set), and averaged over 50 runs. On
average, on the 8 datasets tested, SSubnoRR always
gives better performance. The improvement was not
found to be statistically signi(cid:12)cative for the follow-
ing datasets: Mushroom (8124 examples (cid:2) 21 vari-
ables), Statlog Landsat Satellite (6435 (cid:2) 36) and Nurs-
ery (12960 (cid:2) 8). SSubnoRR performs signi(cid:12)cantly bet-
ter than RSubnoRR (with a relative decrease in classi-
(cid:12)cation error from 4:5 to 12%) on: Image (2310 (cid:2) 19),
Isolet (7797 (cid:2) 617), PenDigits (10992 (cid:2) 16), SpamBase
(4601(cid:2)57) and the USPS dataset (9298(cid:2)256, not from
UCI). Overall, our experiments show that random se-
lection can sometimes be e(cid:14)cient enough (especially
with large low-dimensional datasets), but smart sub-
set selection is to be preferred, since it (almost always)
gives better and more stable results.

6 CONCLUSION

The (cid:12)rst contribution of this paper is an extension
of previously proposed non-parametric (graph-based)
semi-supervised learning algorithms, that allows one
to e(cid:14)ciently perform function induction (i.e. cheaply
compute a prediction for a new example, in time O(n)
instead of O(n3)). The extension is justi(cid:12)ed by the
minimization of the same smoothness criterion used
to obtain the original algorithms in the (cid:12)rst place.

The second contribution is the use of this induction
formula to de(cid:12)ne new optimization algorithms speed-
ing up the training phase. Those new algorithms are
based on using of a small subset of the unlabeled data,
while still keeping information from the rest of the
available samples. This subset can be heuristically
chosen to improve classi(cid:12)cation performance over ran-
dom selection. Such algorithms yield important reduc-
tions in computational and memory complexity and,
combined with the induction formula, they give predic-
tions close to the (expensive) transductive predictions.

References

Belkin, M., Matveeva, I., & Niyogi, P. (2004). Regular-
ization and semi-supervised learning on large graphs.
COLT’2004. Springer.

Belkin, M., & Niyogi, P. (2003). Using manifold structure
for partially labeled classi(cid:12)cation. Advances in Neural
Information Processing Systems 15. Cambridge, MA:
MIT Press.

Beyer, K. S., Goldstein, J., Ramakrishnan, R., & Shaft, U.
(1999). When is \nearest neighbor" meaningful? Pro-
ceeding of the 7th International Conference on Database
Theory (pp. 217{235). Springer-Verlag.

Chapelle, O., Weston, J., & Scholkopf, B. (2003). Cluster
kernels for semi-supervised learning. Advances in Neural
Information Processing Systems 15. Cambridge, MA:
MIT Press.

Kemp, C., Gri(cid:14)ths, T., Stromsten, S., & Tenembaum, J.
(2004). Semi-supervised learning with trees. Advances in
Neural Information Processing Systems 16. Cambridge,
MA: MIT Press.

Nadaraya, E. (1964). On estimating regression. Theory of

Probability and its Applications, 9, 141{142.

Ng, A. Y., Jordan, M. I., & Weiss, Y. (2002). On spec-
tral clustering: analysis and an algorithm. Advances in
Neural Information Processing Systems 14. Cambridge,
MA: MIT Press.

Seeger, M. (2001). Learning with labeled and unlabeled data

(Technical Report). Edinburgh University.

Szummer, M., & Jaakkola, T. (2002). Partially labeled
classi(cid:12)cation with markov random walks. Advances in
Neural Information Processing Systems 14. Cambridge,
MA: MIT Press.

Watson, G. (1964). Smooth regression analysis. Sankhya -

The Indian Journal of Statistics, 26, 359{372.

Williams, C. K. I., & Seeger, M. (2001). Using the Nystr(cid:127)om
method to speed up kernel machines. Advances in Neu-
ral Information Processing Systems 13 (pp. 682{688).
Cambridge, MA: MIT Press.

Zhou, D., Bousquet, O., Navin Lal, T., Weston, J., &
Sch(cid:127)olkopf, B. (2004). Learning with local and global
consistency. Advances in Neural Information Processing
Systems 16. Cambridge, MA: MIT Press.

Zhu, X., Ghahramani, Z., & La(cid:11)erty, J. (2003a). Semi-
supervised learning using gaussian (cid:12)elds and harmonic
functions. ICML’2003.

Zhu, X., La(cid:11)erty, J., & Ghahramani, Z. (2003b). Semi-
supervised learning: From gaussian (cid:12)elds to gaussian
processes (Technical Report CMU-CS-03-175). CMU.

103Structured Variational Inference Procedures and their Realizations

Dan Geiger(cid:3)

Computer Science Department

Technion

Haifa, 36000, Israel

dang@cs.technion.ac.il

Christopher Meek
Microsoft Research

Microsoft Cooperation

Redmond, WA 98052, USA

meek@microsoft.com

Abstract

We describe and prove the convergence of
several algorithms for approximate struc-
tured variational inference. We discuss the
computation cost of these algorithms and
describe their relationship to the mean-(cid:12)eld
and generalized-mean-(cid:12)eld variational ap-
proaches and other structured variational
methods.

1 Introduction

Graphical models are an important class of probabilis-
tic models. Their graphical structure, whether di-
rected, undirected, or mixed, provides an appealing
description of the qualitative properties of the model.
Furthermore, the modularity of the de(cid:12)ned probability
distribution allows one to de(cid:12)ne general algorithms,
called inference algorithms, for computing marginal
and conditional probabilities and allows one to easily
incorporate prior knowledge. Inference algorithms are
also useful for parameter learning for graphical mod-
els with missing data because the E-step of the EM
algorithm can be computed using inference.
Although the inference problem is tractable for graph-
ical models with small treewidth, the general inference
problem is NP-hard (Cooper, 1990; Dagum and Luby,
1993) . In fact, for many graphical models of interest
the treewidth is too large to allow e(cid:14)cient inference
and one must use approximate or heuristic inference
methods. In this paper, we examine the family of ap-
proaches that optimize the KL divergence between a
distribution Q and the target distribution P where Q
is constrained to be from some family of distributions
for which inference is tractable.

(cid:3)

This work was partially done while the author visited

Microsoft Research.

One of the nice properties of this family of approaches
is that they provide a bound on marginal probabil-
ities that are useful in model evaluation and learn-
ing.
In particular, let us assume that we are given
an intractable joint distribution P (X) over a set of
discrete variables X and our goal is to compute the
marginal probability P (Y = y) where Y (cid:18) X. We
let H = X n Y . The quantity of interest is bounded
by log P (Y = y) (cid:21) −D(Q(H) jj P (Y = y; H)) where
D((cid:1) jj (cid:1)) denotes the KL divergence between two prob-
ability distributions. The quantity −D(Q jj P ) is often
called the free-energy and denoted by F (Q; P ) where Q
and P are possibly un-normalized distributions. The
bound can be shown by the following argument:
−D(Q(H) jj P (Y = y; H)) = −
X

X
=
= log P (y) − D(Q(H) jj P (HjY = y)) (cid:20) log P (y):

Q(h) log Q(h)
P (y; h)

Q(h) log Q(h)
P (hjy)

Q(h) log P (y) −

X

h

h

h

inequality follows from the fact

The (cid:12)nal
that
D(Q(H) jj P (HjY = y)) (cid:21) 0 with equality holding only
if Q(H) = P (HjY = y).
It is important to note
that if Q is tractable then D(Q(H) jj P (Y = y; H))
can be e(cid:11)ectively computed.
The goal of ap-
proaches in this family is to (cid:12)nd the Q(H) that mini-
mizes D(Q(H) jj P (Y = y; H)) (or maximizes the free-
energy). Approaches in this family include the mean
(cid:12)eld, generalized mean (cid:12)eld, and structured mean (cid:12)eld
approaches to variational inference. These methods
di(cid:11)er with respect to the family of approximating dis-
tributions that can be used with the structural mean
(cid:12)eld approach subsuming the remaining approaches as
special cases.
In this paper, we develop a set of structural varia-
tional methods inspired by the sequence of papers Saul
and Jordan (1996), Ghahramani and Jordan (1997),
Wiegerinck (2000) and Bishop and Winn (2003). We
make several contributions with respect to this earlier

104work. We provide a set of alternative structured vari-
ational methods and prove convergence of the alterna-
tives with a novel simple proof technique. Our alter-
native algorithms di(cid:11)er in their computational pro(cid:12)le
with successive algorithms providing re(cid:12)ned control
over the computational cost of obtaining a variational
approximation. We note that special cases of our (cid:12)-
nal algorithm, called vip], were used in Jojic et al.
(2004) for applying variational inference techniques to
types of phylogenic models. For N (cid:2) N grid-like mod-
els, algorithm vip] is 4N fold faster than algorithm
vip+ and 12N folder faster than algorithm vip, yield-
ing a potential three orders of magnitude improvement
in applications such as phylogeny and genetic linkage
analyses.

2 Single Potential Update Algorithms

Q

Q

We denote distributions by P (x) and Q(x) and re-
lated un-normalized distributions by ~P (x) / P (X)
and ~Q(x) / Q(x). Let X be a set of variables
and x be an instantiation of these variables. Let
P (x) = 1
i Ψi(di) where di is the projection of the
instantiation x to the variables in Di (cid:18) X. The con-
ZP
stant ZP normalizes the product of potentials and the
subsets fDigI
i=1 are allowed to be overlapping. Note
that we often suppress the arguments of a potential
and of a distribution, using (cid:8)j instead of (cid:8)j(cj) and
P instead of P (X).
Our goal is to (cid:12)nd a distribution Q that minimizes the
KL distance between Q and P . We further constrain
Q to be of the form Q(x) = 1
j (cid:8)j(cj) where ZQ
ZQ
is a normalizing constant and where C1; : : : ; CJ are
possibly overlapping subsets of X, which we call clus-
ters. Finding an optimum Q, however, can be di(cid:14)cult.
We set a more modest goal of (cid:12)nding a distribution Q
which is a stationary point for the KL distance between
Q and P , that is, r(cid:8)D(Q jj P ) = 0 where (cid:8) = f(cid:8)jgj.
An algorithm, called vip (for Variational Inference
Procedure), that (cid:12)nds such a distribution Q is given
in Figure 1. The algorithm uses the following indica-
tor functions: gkj = 0 if Ck \ Cj = ; and 1 other-
wise, and fij = 0 if Di \ Cj = ;, and 1 otherwise.
vip relies at each step on an (inference) algorithm to
compute some conditional probabilities from an un-
normalized distribution ~Q represented by a set of po-
tentials (cid:8)j(cj), j = 1; : : : ; J. This is accomplished by
using bucket elimination algorithm or the sum-product
algorithm described in (Dechter, 1999; Kschischang et
al., 2001) as follows. To compute Q(ajb) the algorithm
(cid:12)rst computes ~Q(a; b) and then ~Q(b). The conditional
distribution of interest is the ratio of these two quan-
tities because the normalizing constant cancels. It is
important to note that for ~Q(x) =
j (cid:8)j(cj) the com-

Q

putation of these conditionals is not a(cid:11)ected by mul-
tiplying any (cid:8)j by a constant (cid:11).
Algorithm vip generalizes the mean (cid:12)eld (MF) algo-
rithm and the generalized mean (cid:12)eld (GMF) algorithm
(Xing et al. 2003,2004). The mean (cid:12)eld algorithm is
the special case of vip in which each Cj contains a
single variable. Similarly, the generalized mean (cid:12)eld
algorithm is the special case in which the Cj are dis-
joint subsets of variables. Note that if Cj are disjoint
clusters, then the formula for γj in vip simpli(cid:12)es to
the GMF equations as follows ((cid:12)rst term drops out):

X

X

fi:fij =1g

DinCj

γj(cj)  

Q(dijcj) log  i(di):

(2)

The term Q(dijcj) can be made more explicit when Cj
are disjoint clusters. In particular, we partition the set
Q
Din Cj into Dk
i = (Din Cj)\ Ck for k = 1; : : : ; J where
k 6= j. Note that Dk
i = Di \ Ck. Using this notation
we have Q(dijcj) =
j ) = 1 when-
k Q(dk
i = ;. This factorization further simpli(cid:12)es the
X
X
ever Dk
formula for γj in vip as follows:
γj(cj)  

j ) where Q(dk

X

i ) log  i(di)

Q(dJ

Q(d1

i ) : : :

fi:fij =1g

D1
i

DJ
i

(3)
We note that this simpli(cid:12)cation is achieved automati-
cally by the usage of bucket elimination for computing
γj. The iterated sums in Eq. 3 are in fact the buckets
formed by bucket elimination when Cj are disjoint.
Wiegerinck (2000) presents a less re(cid:12)ned version of the
update equation (Equation 1) and proves convergence
to a stationary point of the KL distance between Q
and P among all distributions Q of the given form
using this update equation. We provide an alternative
novel proof of convergence for our re(cid:12)ned version of
Wiegerinck’s algorithm in Section 4 as a corollary to
Theorem 1.
Equation 1 of vip requires the computation of the
quantities Q(ckjcj) and Q(dijcj), and this is done in
vip using the bucket elimination algorithm. How-
ever, because there could be many indices k such that
Ck \ Cj is not empty, and many indices i such that
Di\Cj is not empty, these function calls are repeatedly
applied independent of each other. However, these
computations share many sub-computations, and it is
therefore reasonable to add a data structure to facili-
tate a more e(cid:14)cient implementation for these function
calls. In particular, it is possible to save computations
if the sets C1; : : : ; CJ form a junction tree.
A set of clusters C1; : : : ; CJ forms a junction tree i(cid:11)
there exists a tree JT having one node, called Cj, for
each subset of variables Cj, and for every two nodes Ci
and Cj of JT, which are connected with a path in JT,

105Q

i Ψi(di) and a

Algorithm vip(Q; P )

Q

A revised set of potentials (cid:8)j(cj) de(cid:12)ning a probability distribution Q via
j (cid:8)j(cj) where ZQ is a normalizing constant, such that Q is a stationary point of

Input: A set of potentials Ψi(di) de(cid:12)ning a probability distribution P via P (x) = 1
ZP
set of clusters Cj, j = 1; : : : ; J, with initial non-negative potentials (cid:8)j(cj).
Output:
Q(x) = 1
the KL distance D(Q jj P ).
ZQ
X

Iterate over all clusters Cj until convergence

For every instantiation cj of cluster Cj do:

X

X

X

Q(dijcj) log Ψi(di)

(1)

γj(cj)   −

Q(ckjcj) log Q(ckjcj) +

CknCj

fk:gkj =1g

Q
using the sum-product algorithm on ~Q(X) =
to compute the quantities Q(ckjcj) and Q(dijcj).

fi:fij =1g

DinCj

i (cid:8)i(Ci)

(cid:8)j(cj)   eγj (cj)

Figure 1. The vip algorithm

CknCj

Q

Q

P

P

j (cid:8)j(cj)=

and for each node Ck on this path, Ci\ Cj (cid:18) Ck holds.
By a tree we mean an undirected graph, not necessarily
connected, with no cycles. Note that this de(cid:12)nition al-
lows a junction tree to be a disconnected graph. When
C1; : : : ; CJ form a junction tree, Q(x) has the decom-
posable form Q(x) =
e (cid:8)e(se), where (cid:8)j
are marginals on the subsets Cj of X, j = 1; : : : ; J,
and where (cid:8)e are the marginals on intersections Se =
Ci \ Cj, one for each two neighboring clusters in the
junction tree (Jensen 1996).
The revised algorithm, which we call vip+, main-
tains a consistent junction tree JT for the distribution
Q(x). By consistency we mean that
(cid:8)j =
CjnCk
In a consis-
(cid:8)k for every two clusters.
tent junction tree, each potential (cid:8)j(Cj) is propor-
tional to Q(Cj). There are two standard opera-
tions for junction trees: DistributeEvidence((cid:8)j),
and CollectEvidence((cid:8)j) (Jensen 1996).
Al-
gorithm vip+ uses the former.
The procedure
DistributeEvidence((cid:8)j) accepts as input a con-
sistent junction tree and a new cluster marginal (cid:8)j
for Cj, and outputs a consistent junction tree, hav-
ing the same clusters, where (cid:8)j is the (possibly un-
normalized) marginal probability of Q on Cj, and
where the conditional probability Q(XjCj) remains
unchanged. Algorithm vip+ is given in Figure 2. This
algorithm is identical to Wiegerink’s algorithm except
that the normalizing constant is not computed in each
iteration. The fact that algorithm vip+ converges to
a distribution Q which is a stationary point of the KL
distance D(Q jj P ) is proved in Section 4 in Theorem 1.
Next we compare the computational bene(cid:12)t of vip+
versus vip. The algorithms di(cid:11)er in two ways. First,

vip+ makes the junction tree consistent with respect
to the updated cluster. Second, vip+ uses junction
tree inference to compute the quantities Q(ckjcj) and
Q(dijcj) whereas vip uses the sum-product algorithm.
Most of the computation in both algorithms is directed
towards computing conditional probabilities Q(ckjcj)
and Q(dijcj). We distinguish among these conditional
probabilities as follows.
De(cid:12)nition: A conditional probability Q(Ajcj) is sub-
sumed by Q if the set of target variables A is a subset
of some cluster Ck in Q (i.e., A n Cj (cid:18) Ck).
In the non-subsumed case, the set of target variables
spans multiple clusters (i.e., An Cj 6(cid:18) Ck). Clearly, all
probabilities of the form Q(Ckjcj) are subsumed by Q.
The cost of running both the junction tree algorithm
and the sum-product algorithm to compute a sub-
sumed conditional probability Q(Ajcj) is exponential
in the treewidth of the model Q. The cost of the junc-
tion tree algorithm is typically twice the cost of the
sum-product algorithm but, as we see below, this extra
factor can be useful in reducing overall costs. For non-
subsumed conditionals, both algorithms can cost upto
a multiplicative factor of the size of the non-subsumed
set.
In the case of using junction trees, one can use
the variable propagation algorithm in Jensen (1996)
for each non-subsumed conditional.
The next example highlights the computational di(cid:11)er-
ence between vip and vip+.

Example 1 The target distribution P is a square grid
of pairwise potentials (see Figure 3a) and the approx-
imating family is de(cid:12)ned by the set of columns in the

106Algorithm vip+(Q; P )

Input: A set of potentials Ψi(di) de(cid:12)ning a probability distribution P via P (x) = 1
i Ψi(di) and a
ZP
set of clusters Cj, j = 1; : : : ; J, with initial potentials (cid:8)j(cj) that form a consistent junction tree JT.
Output: A revised set of potentials (cid:8)j(cj) de(cid:12)ning a probability distribution Q via Q(x) =

Q
e (cid:8)e(se), such that Q is a stationary point of the KL distance D(Q jj P ).

Q
j (cid:8)j(cj)=
Note: The potentials (cid:8)j are consistent un-normalized marginals encoding ~Q / Q. This fact is an
invariant of the loop due to initialization and Step 2.
Iterate over all clusters Cj until convergence

Q

Step 1.

X

X

For every instantiation cj of cluster Cj do:
γj(cj)   −

Q(ckjcj) log Q(ckjcj) +

X

X

DinCj

CknCj

fk:gkj =1g
where the quantities Q(ckjcj) and Q(dijcj) are computed via the junction tree
algorithm operating on JT .

fi:fij=1g

Q(dijcj) log Ψi(di)

(4)

(cid:8)j(cj)   eγj (cj)

Step 2. Make JT consistent with respect to (cid:8)j:

DistributeEvidence((cid:8)j)

Figure 2. The vip+ algorithm

grid and denoted by QF (see Figure 3b) in which the
clusters Ci (i = 1; : : : ; 30) correspond to edges.

Note that all conditionals required by the algorithms
when optimizing QF are subsumed. In this example,
for each cj not on the boundary, there are six condi-
tional probabilities that need to be computed. By us-
ing the junction tree algorithm all of these conditional
probabilities can be computed with one call to Dis-
tributeEvidence whereas, when using the sum-product
algorithm, each of these is computed separately. This
yields a 3-fold speed up for vip+ with respect to vip.
For those cj on a boundary, the speedup is a factor
less than 3. As the size of the grid grows, a smaller
fraction of the edges are on the boundary, and, thus,
the speedup approaches a 3-fold speedup. For small
grids, vip+ can be slower than vip.

3 Multiple Potential Update

Algorithm

In this section, we develop an algorithm to update mul-
tiple potentials at once to reduce the computational
cost of optimizing the Q distribution. Algorithms vip
and vip+ do not assume any structure for (cid:8)j, namely,
these algorithms hold tables (cid:8)j with an explicit entry
for every instantiation of Cj. Since the computations
Q(ckjcj) and Q(dijcj) grow exponentially in the size
of Di and Ck, these algorithms become infeasible for
large cliques or clusters. However, when structure is
added to (cid:8)j, these algorithms can be modi(cid:12)ed to be

more e(cid:14)cient by simultaneously updating this struc-
ture. In particular, one can use structure of the form,

njY

(cid:8)j(cj) =

(cid:8)jl(cjl);

l=1

where the sets Cjl are possibly overlapping subsets of
Cj, and cjl is the projection of the instantiation cj on
the variables in Cjl. The potentials (cid:8)jl are assumed
to be full tables and to form a junction tree JTj.
Central to our development is a compatibility condi-
tion which allows us to simultaneously update the po-
tentials.
De(cid:12)nition: A distribution Q with clusters Cj and
subsets Cjl is compatible with a distribution P with
sets Di if for every Di and Cj the set of indices Bij =
fl : Di \ Cj (cid:18) Cjlg is non-empty.
Our re(cid:12)ned algorithm, vip], given in Figure 4, uses an
indicator function fij(l) which equals 0 when Di\Cj =
;, and when Di \ Cj 6= ;, it equals 1 for a single (cid:12)xed
index l 2 Bij and 0 for all other indices in Bij. Our
algorithm is closely related to the algorithm in Bishop
and Winn (2003). As in Bishop and Winn (2003), we
assume that the clusters of the approximating distribu-
tion are independent, that is, Q(Ckjcj) = Q(Ck). Our
algorithm also generalizes the algorithm employed in
(Jojic et al. 2004), which concentrates on speci(cid:12)c mod-
els for phylogenetic analysis. We prove convergence of
vip] in Section 4.

107Figure 3. (a) Grid-like P distribution (b) factored structured distribution QF (c) connected distribution QC.

Example 2 The target distribution P is a square grid
of pairwise potentials (see Figure 3a) and the approx-
imating family is a de(cid:12)ned by the set of columns in
the grid and denoted by QF (see Figure 3b) where Ci
(i = 1; : : : ; 6) are columns of the grid.

The approximating family with clusters de(cid:12)ned by
columns in this example satisfy the compatibility con-
dition and the independence condition required by our
algorithm.

Example 3 The target distribution P is a square grid
of pairwise potentials (see Figure 3a) and the approxi-
mating family is a de(cid:12)ned by the set of columns in the
grid and denoted by QC (see Figure 3c) where C1 is
the connected row of the grid and Ci (i = 2; : : : ; 7) are
columns of the grid.

The approximating family de(cid:12)ned in Example 3 satis-
(cid:12)es the compatibility condition but not the indepen-
dence condition required by our algorithm. Note that,
while the approximating family in Example 3 cannot
be optimized using our re(cid:12)ned algorithm below, it can
be optimized using either vip or vip+ in which, for
instance, the Ci each contain a single edge.
We use Examples 1 and 2 to compare the bene(cid:12)ts of
vip] as compared to vip+. To analyze the di(cid:11)erence
between vip] and vip+ we need to analyze the num-
ber of times that one needs to call DistributeEvidence
while computing conditional and marginal probabili-
ties.
We begin by noting that the update Equation 5 in vip]
takes advantage of the strong independence assump-
tion to factor Q(Dijcj), yielding a set of marginal prob-
abilities that do not depend on cj. Furthermore, the
assumption of compatibility between P and Q implies
that all the conditionals are subsumed. The factoriza-
tion and compatibility conditions imply that each of
these marginal probabilities can be obtained by lookup
from the appropriate junction tree without calling Dis-
tributeEvidence. Therefore, we need no calls to Dis-
tributeEvidence in Step 1 and only one call to an infer-
ence algorithm to calibrate the junction tree associated

with the potential being updated (Step 2).
In vip+, for each cluster Cj (edge) not in the boundary
of the grid, there are twenty four conditionals that we
need to compute, six for each of the four possible values
for the cluster Cj. Every group of six conditionals can
be updated with a single call to DistributeEvidence
for a given cj which gives four calls to the Distribu-
teEvidence per cluster (edge). Again, as the size of the
N (cid:2) N grid grows, a smaller fraction of the edges are
on the boundary, and, thus, the speedup approaches
a 4N-fold speedup for vip] as compared to vip+, and
12N-fold as compared to vip.

4 Proof of Convergence

In order to prove convergence of our algorithms,
namely, that they converge to a stationary point of
the KL distance between Q and P among all distribu-
tions Q of the given form, we examine properties of the
KL distance between two distributions Q and P . Our
proof technique is novel in that it uses properties of the
KL distance rather than being based on Lagrangians
(e.g., Wiegerinck 2000). The following lemmas furnish
the needed properties of KL via basic algebra.

Q

i Ψi(ci) and Q(x) =

Lemma 1 Let P (x) = 1
ZP
1
ZQ

Q
j (cid:8)j(dj). Then,
D(Q jj P ) =

X

where Γj(cj) = eγj (cj) and where

+ log(ZP )

(6)

Cj

Q(cj) log Q(cj)
Γj(cj)
X
X

X

k

DinCj

i

γj(cj) = −
X

+

Q(ckjcj) log Q(ckjcj)

CknCj
Q(dijcj) log Ψi(di):

Proof: Recall that
D(Q jj P ) =

Q(x) log

X

x

= − [H(Q) + EQ[log P (x)]]

Q(x)
P (x)

(7)

108Algorithm vip] (Q,P)

Q
Input: A set of disjoint clusters Cj, j = 1; : : : ; J and a nested structure Cjl (l = 1 : : : ; nj) where Q(c) /
j;l (cid:8)jl(cjl). A set of potentials Ψi(di) de(cid:12)ning a probability distribution P via P (x) = 1
i Ψi(di)
ZP
such that the potentials are compatible with Q. A set of junction trees (JTj) for each cluster Cj and a
where Q(cj) /Qnj
set of initial potentials (cid:8)j(cj) =
Output: A revised set of potentials (cid:8)jl(cj) de(cid:12)ning a probability distribution Q via Q(x) =

l=1 (cid:8)jl(cjl) such that Q is a stationary point of D(Q jj P ).

Q
Q

l=1 (cid:8)jl(cjl).

Qnj

j Qj(cj)

Iterate over all clusters Cj until convergence

Step 1. Compute messages for l = 1; : : : ; nj:
For every instantiation cjl of Cjl do:

X

X

X

DJ
i

Q(d1

i ) : : :

Q(dJ

i ) log Ψi(di)

(5)

fi:fij (l)=lg

D1
i

γjl(cjl)  

i ) can be obtained by lookup in JTk for (cid:8)k.

where the quantities Q(dk
(cid:8)jl(cjl)   eγjl (cjl )
Q

Note: (cid:8)jl(cjl), l = 1; : : : ; nj, implicitly encode the potential (cid:8)j(cj), which is not being held explic-
itly anymore as in vip, via (cid:8)j(cj) =

nj
l=1 (cid:8)jl(cjl). Recall that Dk

i = Di \ Ck.
DistributeEvidence((cid:8)j)

Step 2. Make JTj consistent with respect to (cid:8)j:

Figure 4. The vip] algorithm

where H(Q) denotes the entropy of Q(x) and EQ de-
notes expectation with respect to Q. The entropy term
can be written as
X
H(Q) = −

Q(cj) log Q(cj)

X

X

Q(xjcj) log Q(xjcj)

−

Cj
Q(cj)

Cj

XnCj

where the (cid:12)rst term is the entropy of Q(Cj) and the
second term is the conditional entropy of Q(XjCj).
This well known form of H(Q) is derived by splitting
summation over X into summation over Cj and over
X n Cj, and using the fact that
Q(xjcj) = 1.
By splitting the sum over X n Cj, this entropy term is
further rewritten as

P

XnCj

X

X
H(Q) = −

−

Cj
Q(cj)

Q(cj) log Q(cj)

X

X

CknCj

k

Q(ckjcj) log Q(ckjcj):

The second term of Eq. 7 is similarly written as
EQ[log P (x)] =

Cj

X

X
X

i

Q(cj)

X

Cj
Q(cj)

Cj

i

X
X

XnCj

DinCj

=

=

Q(xjcj) log Ψi(di) − log(ZP )
Q(dijcj) log Ψi(di) − log(ZP )

Hence Eq. 7 is rewritten as
D(Q jj P ) =
X

P
24−
Q(cj) log Q(cj)−
X
X
X

X

Q(cj)

Cj

k

Cj

+

CknCj
Q(dijcj) log Ψi(di)

Q(ckjcj) log Q(ckjcj)

35 + log(ZP )

DinCj

i

Denoting the bracketed term by γj(cj), and letting
Γj(cj) = eγj (cj), we get

D(Q jj P ) =

Q(cj) log Q(cj)
Γj(cj)

+ log(ZP ):

(cid:5)

X

Cj

Note that Γj(cj) in Eq. 6 does not depend on Q(cj)
and is a function of Q(x) only through the conditional
distribution of X n Cj given Cj (via Q(ckjcj)). Eq. 6
states that the KL distance between Q(x) and P (x) is
equal, up to an additive constant, to the KL distance
between Q(cj) and an un-normalized potential Γj(cj).
This interesting result generalizes a similar equation
for a special case derived in (Jojic et al, 2004).
The next lemma provides a variant of a well known
property of KL. Recall that for every two proba-
bility distributions Q(x) and P (x), the KL distance

109D(Q(x) jj P (x)) (cid:21) 0 and equality holds if and only
if Q(x) = P (x) (Cover and Thomas 1991; Theorem
2.6.3). A similar result holds also for un-normalized
probability distributions.

Lemma 2 Let ~Q(x) and ~P (x) be non-negative func-
tions such that

P

x

P

~P (x) = ZP > 0, and let
~Q(x)=ZQg D( ~Q(x) jj ~P (x))

min

x

^Q(x) =

f ~Qj

where ZQ is a positive constant. Then ^Q(x) =

ZQ
ZP

P (x).

Proof. We observe that

D( ~Q(x) jj ~P (x)) = ZQ (cid:1) D( ~Q(x)

ZQ

jj ~P (x)

ZP

) + log ZQ
ZP

which implies, using the cited result about normal-
ized distributions, that the minimum is obtained when
~Q(x)
ZQ

, yielding the desired claim. (cid:5)

= ~P (x)
ZP

Theorem 1 (Convergence of vip+) Algorithm
vip+ converges to a stationary point of
the KL
distance between Q and P among all distributions Q
of the form Q(x) = 1
ZQ

j (cid:8)j(cj).

Q

Proof. We need to show that at the start of each
iteration of vip+ the function Q de(cid:12)ned by the revised
potentials (cid:8)j(cj) is closer to P in KL distance than
Q at the start of the previous iteration. We rewrite
the KL distance D(Q jj P ) using Eq. 6, as justi(cid:12)ed by
Lemma 1. Using the given form of Q, we have

24X

Y

XnCj

k6=j

35 (cid:8)j(cj):

(cid:8)k(ck)

(8)

Q(cj) =

1
ZQ

24X

Cj

35 + log BZP

:

ZQ

We denote the bracketed coe(cid:14)cient of (cid:8)j(cj) by B and
note that it is constant in the sense that it does not
depend on the quantity (cid:8)j being optimized. We now
use Eq. 8 to rewrite Eq. 6 as

D(Q jj P ) = B
ZQ

(cid:8)j(cj) log

(cid:8)j(cj)
Γj(cj)

(9)
Recall that Γj(cj) = eγj (cj ) does not depend on (cid:8)j(cj)
since it only depends on the conditional probability
Q(Xjcj). Hence, Lemma 2 states that the (global)
minimum wrt (cid:8)j is achieved when (cid:8)j(cj) is set to be
proportional to Γj(cj). It is possible to set (cid:8)j(cj) to
be proportional to Γj(cj), as done in Step 1 of vip+,
because (cid:8)j(cj) is a full potential. The proportionality
constant does not matter because if (cid:8)j is multiplied by

(cid:11), and the arbitrary constraining constant ZQ is also
multiplied by (cid:11), these inﬂuences cancel in Eq. 9. For
simplicity, in the algorithm, we use (cid:11) = 1 and therefore
(cid:8)j(cj)   eγj (cj). Algorithm vip+ computes (cid:8)j(cj)
according to this formula and hence decreases the KL
distance in each iteration by improving (cid:8)j(cj) while
holding all other cluster potentials (cid:12)xed. Since the
KL distance is lower bounded by zero, vip+ converges
to a stationary point.
It remains to show that at the start of each iteration,
the quantities Q(ckjcj) and Q(dijcj) can be computed
correctly from the junction tree for the un-normalized
distribution ~Q of the current normalized distribution
Q. At each iteration, Q is computed up to some im-
plicit normalizing factor, say (cid:11), so that ~Q(x) = (cid:11)Q(x).
The procedure DistributeEvidence((cid:8)j) is based on
the following update scheme. Starting with (cid:8)j, every
neighboring cluster node Ck in the junction tree, rep-
resenting the cluster potential (cid:8)k(ck), is updated via

(ck)   (cid:8)k(ck)

(cid:8)new

k

(cid:8)new
(sjk)
k
(cid:8)k(sjk)

where sjk is the instantiation for the separator Sjk =
Cj \ Ck consistent with the instantiation ck, and then
the cluster neighbors of the neighboring clusters are
updated similarly, until all clusters have been updated
(Jensen, 1996). In each step, any normalizing constant
implicitly appears 4 times in this update equation, and
it cancels out regardless of its value. Hence, the quan-
tities Q(ckjcj) and Q(dijcj) are updated correctly from
the un-normalized distribution ~Q. (cid:5)

Corollary 1 (Convergence of vip) Algorithm vip
converges to a stationary point for the KL distance be-
tween Q and P among all distributions Q of the form
Q(x) = 1
ZQ

j (cid:8)j(cj).

Q

Proof. vip convergence follows from Theorem 1 be-
cause the update equations for the two algorithms,
Equations 1 and 4, are identical; the two algorithms
only di(cid:11)er in the method by which conditional proba-
bilities are computed. (cid:5)
Q

Theorem 2 (Convergence of vip]) Algorithm
vip] converges to a stationary point of the KL dis-
tance between Q and P among all distributions Q of
the form Q(x) = 1
jl (cid:8)jl(cjl) where Q and P are
ZQ
compatible.

Proof: We analyze Equation 4 in light of the assump-
tions made in vip]. The (cid:12)rst term in Equation 4 is
constant with respect to cj and, thus, does not ef-
fect the update and can be dropped. Next, the fact
that the clusters Cj of Q are independent means that

110Saul, L. & Jordan, M. I. (1996). Exploiting tractable
In Ad-
substructures in intractable networks.
vances in Neural Information Processing Systems
(NIPS). MIT Press.

Wiegerinck, W. (2000). Variational approximations
between mean (cid:12)eld theory and the junction tree
In Uncertainty in Arti(cid:12)cial Intelli-
algorithm.
gence. Morgan Kaufmann.

Xing, E. P., Jordan, M. I., & Russell, S. (2003). A
generalized mean (cid:12)eld algorithm for variational
inference in exponential families. In Uncertainty
in Arti(cid:12)cial Intelligence. Morgan Kaufmann.

Xing, E. P., Jordan, M. I., & Russell, S. (2004). Graph
partition strategies for generalized mean (cid:12)eld in-
ference. In Uncertainty in Arti(cid:12)cial Intelligence.
Morgan Kaufmann.

Q
P

Q(dJ

DJ
i

Q(d1

i ) : : :

D1
i

P

k Q(Dk

Q
P
i = Di \ Ck. This factor-
Q(Di) =
i ) where Dk
ization implies that Q(Dijcj) =
k6=j Q(Dk
i ) which in
Q(dijcj) log Ψi(di)
turn implies that Fi(c) =
DinCj
i ) log Ψi(di). By the
equals
assumption of compatibility, each Fi(c) is a function
of cjl (i.e., after summing out all variables in Di n Cj)
and, thus, can be put into the potential (cid:8)jl(cjl). Ev-
ery element in the second sum of Equation 4 is put
into some potential and Γj(cj) from Theorem 1 is
equal to
l eγjl (cjl ). Therefore, by updating, for all
l, (cid:8)jl(cjl) / Γjl(cjl) is equivalent to updating (cid:8)j in
Theorem 1 and, thus, the algorithm converges.(cid:5)

Q

Acknowledgments

We thank Nir Friedman, David Heckerman, and Nebo-
jsa Jojic for various discussions on the subject of vari-
ational techniques.

References

Bishop, C. & Winn, J. (2003). Structured variational
distributions in VIBES. In Arti(cid:12)cial Intelligence
and Statistics. Society for Arti(cid:12)cial Intelligence
and Statistics.

Cooper, G. (1990). Probabilistic inference using belief
networks is NP-hard. Arti(cid:12)cial Intelligence, 42,
393{405.

Cover, T. M. & Thomas, J. A. (1991). Elements of

Information Theory. Wiley.

Dagum, P. & Luby, M. (1993). Approximating prob-
abilistic inference in Bayesian belief networks is
NP-hard. Arti(cid:12)cial Intelligence, 60 (1), 141{153.

Dechter, R. (1999). Bucket elimination: A unifying
framework for reasoning. Arti(cid:12)cial Intelligence,
113 (1-2), 41{85.

Ghahramani, Z. & Jordan, M. I. (1997). Factorial hid-
den Markov models. Machine Learning, 29, 245{
273.

Jensen, F. V. (1996). An Introduction to Bayesian

Networks. UCL Press.

Jojic, V., Jojic, N., Meek, C., Geiger, D.,Siepel, A.,
Haussler, D., & Heckerman, D. (2004). E(cid:14)cient
approximations for learning phylogenetic HMM
models from data. Bioinformatics, 20, 161{168.

Kschischang, F. R., Frey, B. J., & Loeliger, H.-A.
(2001). Factor graphs and the sum-product algo-
rithm. IEEE Transactions on Information The-
ory, 47 (2).

111(cid:1)(cid:1)  (cid:5)(cid:9)(cid:10)(cid:1)(cid:11) (cid:5)(cid:12)(cid:9)(cid:10)(cid:9)(cid:13)(cid:1) (cid:14) (cid:15)(cid:1)(cid:1)(cid:11)(cid:1)(cid:13)(cid:1) (cid:1)(cid:9)	(cid:1)(cid:1)

(cid:0)(cid:3)	 (cid:5)(cid:6) (cid:0) (cid:6)(cid:11)(cid:12)(cid:13)(cid:6) (cid:14) (cid:12)(cid:1)  (cid:17)(cid:18)(cid:17)(cid:6) (cid:19)		(cid:6) (cid:22)(cid:12) (cid:23)  (cid:6)(cid:25)(cid:17)(cid:26)(cid:3)(cid:2) (cid:0)(cid:13)(cid:6)(cid:17) (cid:19)(cid:6) (cid:17)(cid:27)(cid:17)
(cid:12)(cid:27) (cid:0)	(cid:29)(cid:12)(cid:3) (cid:30)		(cid:27)(cid:6) 	(cid:12)(cid:31)(cid:12)(cid:12)  (cid:12)	  (cid:19)(cid:6)(cid:3)(cid:12)(cid:13) (cid:14)(cid:26)(cid:3)" (cid:27)(cid:23)  (cid:17)(cid:27) (cid:29)(cid:3)(cid:6)(cid:17)

(cid:0)(cid:4) (cid:6)(cid:7)	(cid:9)(cid:10)(cid:11)(cid:13)(cid:9)(cid:4)(cid:13)(cid:4)(cid:16)(cid:9) (cid:17) (cid:9)(cid:18)(cid:4)(cid:19) (cid:6)(cid:7)(cid:6)	(cid:4)(cid:9)(cid:16)	(cid:4)(cid:6)	 (cid:21)(cid:9)(cid:10)(cid:7)(cid:11)(cid:22)(cid:23)(cid:4)(cid:22)

  (cid:4) (cid:7)(cid:8) (cid:10)(cid:8)(cid:11)(cid:12)  (cid:13)(cid:14)(cid:15)(cid:16)(cid:16)(cid:8)(cid:11) (cid:20)(cid:21)	(cid:15)(cid:8)(cid:10)(cid:16) (cid:23)(cid:16)(cid:12)(cid:14)

(cid:1) (cid:13)(cid:20)(cid:26) (cid:13)(cid:12)(cid:15)(cid:16)(cid:12) (cid:26)	(cid:12) (cid:8)(cid:12)(cid:27) (cid:2) (cid:8)(cid:11)(cid:4) (cid:28)(cid:16)(cid:16)(cid:12)(cid:11)(cid:29) (cid:13)(cid:12)(cid:15)(cid:8)(cid:30)(cid:10)(cid:16) (cid:31)

(cid:0)(cid:1)(cid:5)(cid:6)

!(cid:16) (cid:30)(cid:8)(cid:11)	 (cid:16)(cid:30)	(cid:11)(cid:8)(cid:10) #(cid:16)(cid:16)   (cid:8) (cid:15)(cid:16) (cid:12)(cid:11)(cid:16)
(cid:28) &	(cid:15)(cid:12)(cid:16)(cid:30) (cid:16)(cid:12)	(cid:16) (cid:4) (cid:12)(cid:8)(cid:8)(cid:11)(cid:12)  (cid:30)(cid:16)(cid:16)	
(cid:30)(cid:16)(cid:11)(cid:16) )(cid:8)(cid:29) (cid:16)(cid:29)(cid:12)(cid:8)  (cid:11)(cid:12)(cid:8)(cid:16)(cid:30) (cid:11)*(cid:12)(cid:8)	
(cid:12)(cid:11)(cid:16) (cid:13)(cid:13) (cid:12) *(cid:16)  (cid:11)(cid:8)(cid:16)(cid:8)  (cid:16) (cid:30)(cid:16)	
(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:4) (cid:12)(cid:30) *(cid:12)(cid:8)(cid:12)(cid:15) (cid:16), !(cid:16) (cid:29))
(cid:29)(cid:12) (cid:13)(cid:13) (cid:8) (cid:12) (cid:16) (cid:4) (cid:8)(cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:8)(cid:4) (cid:12)(cid:30)
 (cid:14) (cid:8)(cid:4) (cid:29)(cid:16) (cid:12)(cid:11)(cid:8)(cid:12)(cid:16)(cid:30) (cid:28) & (cid:12)(cid:16) 	(cid:8)*(cid:16)(cid:12) ,
(cid:20)(cid:29)(cid:12) (cid:12)(cid:8)(cid:30)  (cid:8)(cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:16) (cid:16)-(cid:8) (cid:29)(cid:12)
(cid:11)(cid:12) (cid:30)(cid:8)(cid:8)(cid:10)	(cid:8)(cid:29) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16) (cid:12)(cid:30) (cid:8)(cid:30)(cid:16)(cid:16)(cid:30)(cid:16)
(cid:12)(cid:30) *(cid:12)(cid:8)(cid:12)(cid:15) (cid:16) (cid:8) (cid:12)   (cid:11)(cid:8)(cid:11)	(cid:12)(cid:11)(cid:16), .(cid:16)	
(cid:16)(cid:30)(cid:16) (cid:12)(cid:30) *(cid:12)(cid:8)(cid:12)(cid:15) (cid:16) (cid:11)(cid:12) (cid:16)	  (cid:8) (cid:12)
(cid:13)(cid:13) )(cid:29)(cid:8)(cid:11)(cid:29) (cid:8) (cid:12)(cid:15)(cid:8)(cid:12)(cid:8) (cid:14) (cid:11) (cid:16)  /(cid:16) )(cid:29)(cid:16)
(cid:29)(cid:16) 	(cid:11)(cid:16) (cid:30)(cid:16)(cid:8)(cid:8)(cid:16) (cid:12)(cid:16) (cid:29)(cid:8)(cid:10)(cid:29) (cid:14) 	(cid:29),
(cid:26)   (cid:11)	(cid:16) #(cid:16)(cid:16) 	(cid:15)(cid:12)(cid:16)(cid:30) (cid:8)(cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:16)
(cid:29)(cid:12)(cid:16) (cid:29)(cid:8) (cid:15)(cid:16)(cid:29)(cid:12)*(cid:8)	, !(cid:16) (cid:30)(cid:16)(cid:12)(cid:16) (cid:16)-	
(cid:16)(cid:8)(cid:12)  (cid:11)*(cid:16)(cid:10)(cid:16)(cid:11)(cid:16) (cid:15)(cid:16))(cid:16)(cid:16) (cid:29)(cid:16) 	 (cid:12)	
(cid:8) (cid:12)(cid:30) (cid:16)(cid:8)(cid:8)(cid:11)(cid:12)  (cid:13)(cid:13), 0(cid:8)(cid:12)  (cid:14) )(cid:16) 	(cid:16)
(cid:13)(cid:13) (cid:12) (cid:12) (cid:16)(cid:12)	(cid:16) (cid:4) 1(cid:8) (cid:16)	(cid:12)  (cid:12)(cid:11)(cid:8)*	
(cid:8)(cid:14) (cid:15)(cid:16))(cid:16)(cid:16) *-(cid:16)  (cid:8) (cid:28) (cid:16)(cid:11)(cid:30)(cid:8)(cid:10) (cid:4) (cid:29)(cid:16)
(cid:12)(cid:11)(cid:12)	(cid:16) #(cid:16)(cid:14) (cid:12)(cid:30) (cid:11)(cid:12)(cid:16) (cid:29)(cid:16) (cid:16)	  
(cid:29)(cid:16) 		(cid:12)  (cid:8)(cid:4)(cid:12)(cid:8) (cid:12)(cid:30) (cid:29)(cid:16) (cid:11)(cid:16) (cid:12)(cid:8),
!(cid:16) (cid:12)  (cid:29)) (cid:29)(cid:16) (cid:16)3(cid:16)(cid:11) (cid:4) (cid:16)*(cid:8)(cid:10) (cid:15)(cid:16)(cid:12)(cid:29)	
(cid:8)(cid:10) (cid:12)(cid:16)(cid:4)(cid:12)(cid:11) (cid:4) (cid:29)(cid:16) (cid:28) (cid:16)(cid:11)(cid:30)(cid:8)(cid:10),

(cid:11)	(cid:6)(cid:13)

(cid:7)
(cid:20)(cid:16)  (cid:30)(cid:16)(cid:16)(cid:8)(cid:16) (cid:29)(cid:16) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16)  (cid:8)(cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16)
(cid:4) (cid:12)(cid:30) *(cid:12)(cid:8)(cid:12)(cid:15) (cid:16) (cid:12)(cid:16) )(cid:16)   (cid:16)(cid:12)(cid:15) (cid:8)(cid:29)(cid:16)(cid:30) (cid:8) (cid:12)(cid:8)(cid:8)(cid:11)(cid:12) 
(cid:12)(cid:12) (cid:14)(cid:8), &(cid:16) (cid:12)(cid:12)(cid:11)(cid:29)(cid:16) (cid:16)	(cid:8)(cid:16) (cid:30)(cid:16)(cid:8)(cid:14) (cid:16)(cid:8)(cid:12)(cid:8)
(cid:12) (cid:12) (cid:8)(cid:16)(cid:16)(cid:30)(cid:8)(cid:12)(cid:16) (cid:16) 4567 (cid:8) (cid:12) (cid:11) (cid:12)(cid:8)(cid:11) 	(cid:30)(cid:14)(cid:27) )(cid:29)(cid:8) (cid:16)
(cid:29)(cid:16) (cid:12)	(cid:16) (cid:12) (cid:12)(cid:12)(cid:16)(cid:8)(cid:11) (cid:30)(cid:16)  (cid:4) (cid:29)) (cid:29)(cid:16) *(cid:12)(cid:8)(cid:12)(cid:15) (cid:16)
)(cid:16)(cid:16) (cid:15)(cid:12)(cid:8)(cid:16)(cid:30) (cid:4) (cid:8)(cid:30)(cid:16)(cid:16)(cid:30)(cid:16) (cid:12)(cid:30) *(cid:12)(cid:8)(cid:12)(cid:15) (cid:16) (cid:12)
(cid:8) (cid:15) (cid:8)(cid:30) 	(cid:11)(cid:16) (cid:16)(cid:12)(cid:12)(cid:8) 4587,

 (cid:29)(cid:8) (cid:12)(cid:16) )(cid:16) (cid:16) (cid:12) 	(cid:12)(cid:12)(cid:16)(cid:8)(cid:11) (cid:8)(cid:30)(cid:16)(cid:16)	
(cid:30)(cid:16)(cid:11)(cid:16) (cid:11)(cid:8)(cid:16)(cid:8) )(cid:29)(cid:8)(cid:11)(cid:29) (cid:16) (cid:8)(cid:16)  (cid:29)(cid:16) (cid:4)(cid:12)(cid:11) (cid:29)(cid:12) (cid:29)(cid:16) (cid:12)	
(cid:30) *(cid:12)(cid:8)(cid:12)(cid:15) (cid:16)(cid:0) (cid:0)(cid:0) (cid:1) (cid:12)(cid:16) (cid:8)(cid:30)(cid:16)(cid:16)(cid:30)(cid:16) (cid:8)(cid:4) (cid:12)(cid:30)  (cid:14) (cid:8)(cid:4)

(cid:0)(cid:0)4(cid:1) (cid:0)7(cid:0)(cid:1)4(cid:2)(cid:1)7 9 (cid:0)(cid:0)(cid:0)(cid:1)4(cid:1) (cid:0)(cid:2)(cid:1)7(cid:3)

5,5

(cid:4) (cid:15)	(cid:30)(cid:16)(cid:30) (cid:11)(cid:8)		 (cid:4)	(cid:11)(cid:8) (cid:1)(cid:0) (cid:2) (cid:16)(cid:16) (cid:4) (cid:8)(cid:12)(cid:11)(cid:16)
45: 5;7, (cid:20)(cid:29)(cid:16) (cid:16)(cid:30) (cid:11)(cid:8)(cid:16)(cid:8) )# (cid:15)(cid:14) (cid:12)-(cid:8)(cid:8)	
(cid:8)(cid:10) (cid:29)(cid:16) (cid:30)(cid:8)(cid:11)(cid:16)(cid:12)(cid:11)(cid:14) (cid:15)(cid:16))(cid:16)(cid:16) (cid:29)(cid:16) (cid:16)(cid:8)(cid:8)(cid:11)(cid:12)  (cid:16)(cid:8)(cid:12)(cid:16) (cid:4)

(cid:29)(cid:16)  & (cid:12)(cid:30) (cid:28) & (cid:4) 5,5 *(cid:16) (cid:16)	(cid:16)(cid:11)(cid:8)=(cid:16)(cid:30) (cid:4)	(cid:11)(cid:8)
(cid:11) (cid:12)(cid:16) (cid:1) (cid:0) (cid:1) (cid:12)(cid:30) (cid:2) (cid:0) (cid:2) (cid:12)(cid:30) (cid:11)(cid:12)(cid:8)(cid:10) (cid:29)(cid:16) (cid:30)(cid:8)(cid:11)(cid:16)	
(cid:12)(cid:11)(cid:14)  (cid:29)(cid:16) (cid:12)	 (cid:4) (cid:30)(cid:16)*(cid:8)(cid:12)(cid:8) (cid:29)(cid:12) (cid:11)(cid:12) (cid:15)(cid:16) (cid:16)-(cid:16)(cid:11)(cid:16)(cid:30)
(cid:4) (cid:29)(cid:16) (cid:4)(cid:12)(cid:11) (cid:29)(cid:12) )(cid:16) (cid:12)(cid:16) (cid:30)(cid:16)(cid:12) (cid:8)(cid:10) )(cid:8)(cid:29) (cid:16)(cid:8)(cid:8)(cid:11)(cid:12)  (cid:16)(cid:8)	
(cid:12)(cid:16) (cid:12)(cid:29)(cid:16) (cid:29)(cid:12) (cid:16)-(cid:16)(cid:11)(cid:12)(cid:8), !(cid:16) (cid:11)(cid:12)   	 (cid:11)(cid:8)(cid:16)(cid:8)
(cid:29)(cid:16) (cid:11)(cid:12)(cid:8)(cid:16)(cid:30) (cid:11)*(cid:12)(cid:8)(cid:12)(cid:11)(cid:16) (cid:13)(cid:13),(cid:1)

(cid:20)(cid:29)(cid:16) (cid:16)	  (cid:16)(cid:16)(cid:16)(cid:30) (cid:29)(cid:16)(cid:16) (cid:15)	(cid:8) (cid:30)  (cid:16)(cid:11)(cid:16) )# 	(cid:15)	
 (cid:8)(cid:29)(cid:16)(cid:30)  (cid:29)(cid:16) 	(cid:15)1(cid:16)(cid:11) (cid:4) #(cid:16)(cid:16)  (cid:15)(cid:12)(cid:16)(cid:30) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:16)(cid:12)	
	(cid:16),  (cid:12)(cid:8)(cid:11)	 (cid:12) (cid:29)(cid:16) (cid:11)(cid:12)(cid:8)(cid:11)(cid:12)  (cid:11)(cid:16) (cid:12)(cid:8) (cid:15)(cid:16))(cid:16)(cid:16)
(cid:4)	(cid:11)(cid:8) (cid:8) (cid:12) (cid:16)(cid:30)	(cid:11)(cid:8)(cid:10) #(cid:16)(cid:16)   (cid:8) (cid:15)(cid:16) (cid:12)(cid:11)(cid:16) (cid:13)(cid:13)
(cid:30)(cid:16)=(cid:16)(cid:30) (cid:8) 457 (cid:4) (cid:12) *(cid:12)(cid:8)(cid:16)(cid:14) (cid:4) #(cid:16)(cid:16)  (cid:12)(cid:30) (cid:8) 45>7 (cid:4)
 (cid:8)(cid:16) (cid:11)(cid:12) (cid:15)(cid:16) 	(cid:16)(cid:30) (cid:12) (cid:12) (cid:16) (cid:4) (cid:8)(cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16), (cid:30)(cid:16)(cid:16)(cid:30)
(cid:8) (cid:29)(cid:16) (cid:11)(cid:12)(cid:16) (cid:4) (cid:23)(cid:12)	(cid:8)(cid:12) #(cid:16)(cid:16)  (cid:7)(cid:12)(cid:11)(cid:29) (cid:12)(cid:30) (cid:30)(cid:12) (cid:29))
(cid:29)(cid:16) (cid:13)(cid:13)  (cid:15)(cid:16) /(cid:16) (cid:8)(cid:4) (cid:12)(cid:30)  (cid:14) (cid:8)(cid:4) (cid:8) ) (cid:12)(cid:10)	(cid:16)
(cid:12)(cid:16) (cid:12)(cid:8)(cid:8)(cid:11)(cid:12)  (cid:14) (cid:8)(cid:30)(cid:16)(cid:16)(cid:30)(cid:16),  &(cid:16)(cid:11)(cid:8) 6 )(cid:16) (cid:11)(cid:29)(cid:12)(cid:12)(cid:11)	
(cid:16)(cid:8)(cid:16) (cid:6)   (cid:16)(cid:30)	(cid:11)(cid:8)(cid:10) #(cid:16)(cid:16)   (cid:8) (cid:15)(cid:16) (cid:12)(cid:11)(cid:16) (cid:28) &
(cid:4) )(cid:29)(cid:8)(cid:11)(cid:29) (cid:29)(cid:8) (cid:16)(cid:14) (cid:29) (cid:30) (cid:15)(cid:29) (cid:4) (cid:13)(cid:13) (cid:12)(cid:30)
(cid:13)(cid:13)@ (cid:29)(cid:16)(cid:16) (cid:12)(cid:16) (cid:16)	(cid:8)(cid:16)(cid:30)  (cid:15)(cid:16) 	(cid:11)(cid:24)(cid:9)(cid:6)  (cid:29)(cid:16) (cid:28) &
	 (cid:15)(cid:16) (cid:30)(cid:16)(cid:16) (cid:8) (cid:29)(cid:16) (cid:12)(cid:11)(cid:16) (cid:4) (cid:11)(cid:8)		 (cid:4)	(cid:11)(cid:8)
4887, &(cid:16)(cid:11)(cid:8)=(cid:11)(cid:12)  (cid:14) (cid:29)(cid:16) (cid:23)(cid:12)	(cid:8)(cid:12) (cid:12)(cid:30) (cid:12) (cid:12)(cid:11)(cid:16) #(cid:16)(cid:16) 
(cid:12)(cid:16) 	(cid:8)*(cid:16)(cid:12)  (cid:12) (cid:12)(cid:16) (cid:12)(cid:14) (cid:16)-(cid:16)(cid:8)(cid:12) 	(cid:15)(cid:12)(cid:16)(cid:30) #(cid:16)(cid:16) (cid:27)
 (cid:14)(cid:8)(cid:12)  #(cid:16)(cid:16)  (cid:29))(cid:16)*(cid:16) (cid:12)(cid:16)  	(cid:8)*(cid:16)(cid:12) ,

!(cid:16) (cid:16)- (cid:30)(cid:16)(cid:12)(cid:16) (cid:8) &(cid:16)(cid:11)(cid:8) : (cid:29)(cid:12) (cid:4) (cid:12) =-(cid:16)(cid:30)	(cid:8)/(cid:16)
=(cid:8)(cid:16) (cid:12) (cid:16) (cid:4) (cid:16)(cid:9)(cid:9)(cid:16)(cid:9) (cid:12)(cid:30) *(cid:12)(cid:8)(cid:12)(cid:15) (cid:16) (cid:29)(cid:16)(cid:16) (cid:16)-	
(cid:8)  (cid:16) (cid:29)(cid:12) (cid:11)(cid:12) (cid:16) (cid:8)(cid:12)(cid:15) (cid:14) (cid:30)(cid:16)(cid:16)(cid:11) (cid:29)(cid:12) (cid:29)(cid:16) (cid:12)(cid:30)
*(cid:12)(cid:8)(cid:12)(cid:15) (cid:16) (cid:12)(cid:16) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16), (cid:20) (cid:11) (cid:12)(cid:8)(cid:4)(cid:14) (cid:29)) (cid:29)(cid:8) (cid:8)(cid:10)(cid:29) (cid:12)(cid:4)	
(cid:4)(cid:16)(cid:11) 	 (cid:11)(cid:8)(cid:16)(cid:8) )(cid:16) *(cid:16) (cid:29)(cid:12) (cid:29)(cid:16) 	 (cid:12)(cid:8) (cid:13)(cid:13)
(cid:11)(cid:12) (cid:15)(cid:16) (cid:12)(cid:30)(cid:16) (cid:12)(cid:15)(cid:8)(cid:12)(cid:8) (cid:14) (cid:12)   )(cid:29)(cid:16) (cid:11)(cid:16)(cid:12)(cid:8) (cid:29)(cid:16)
(cid:12)	(cid:8)  (cid:29)(cid:16) (cid:30)(cid:16)(cid:8)(cid:14) (cid:12)(cid:16) *(cid:8) (cid:12)(cid:16)(cid:30) )(cid:29)(cid:8)(cid:11)(cid:29) (cid:12)#(cid:16)
(cid:8) (cid:30)(cid:8)Æ(cid:11)	   (cid:30)(cid:16)(cid:16)(cid:11) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16)  (cid:29)(cid:16) (cid:15)(cid:12)(cid:8) (cid:4) (cid:12) =	
(cid:8)(cid:16) (cid:12) (cid:16), (cid:20)(cid:29)(cid:8) (cid:8) (cid:12)  	(cid:16) (cid:4) (cid:29)(cid:16) (cid:16) (cid:12)(cid:16)(cid:30) #(cid:16)(cid:16) 
(cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:16)(cid:12)	(cid:16) (cid:8)(cid:11) 	(cid:30)(cid:8)(cid:10) (cid:29)(cid:16) #(cid:16)(cid:16)  		(cid:12)  (cid:8)	
(cid:4)(cid:12)(cid:8)  (cid:8) 4;7 (cid:12)(cid:30) #(cid:16)(cid:16)  (cid:10)(cid:16)(cid:16)(cid:12) (cid:8)(cid:16)(cid:30) *(cid:12)(cid:8)(cid:12)(cid:11)(cid:16)
(cid:23)A (cid:8) 457 (cid:15)(cid:29) (cid:4) )(cid:29)(cid:8)(cid:11)(cid:29) )(cid:16)(cid:16) (cid:29)) (cid:8) 4;7  (cid:15)(cid:16)
	(cid:16) (cid:15)	(cid:30) (cid:16)(cid:12) (cid:8)(cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16)  (cid:29)(cid:16) (cid:12)/(cid:16) )(cid:8)	
(cid:30)) (cid:16)(cid:8)(cid:12)(cid:16) (cid:4) (cid:29)(cid:16) 		(cid:12)  (cid:8)(cid:4)(cid:12)(cid:8), (cid:20)(cid:29)	 (cid:12) (cid:8)
(cid:12)   (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:16) (cid:12)(cid:14) (cid:8)(cid:4)(cid:16)(cid:16)(cid:11)(cid:16) (cid:12)(cid:30)(cid:16) (cid:8) 	(cid:15)1(cid:16)(cid:11) 
(cid:11)(cid:16)(cid:12)(cid:8) (cid:12)	(cid:8) (cid:12)(cid:15)	 (cid:29)(cid:16) 	(cid:30)(cid:16) (cid:14)(cid:8)(cid:10) (cid:10)(cid:16)(cid:16)(cid:12)(cid:8)*(cid:16)
(cid:11)(cid:16) 	 (cid:29)(cid:16) (cid:16)(cid:16) )# (cid:30)(cid:16)(cid:11)(cid:8)(cid:15)(cid:16) (cid:29)(cid:16)(cid:16) (cid:12)	(cid:8)
(cid:16)- (cid:8)(cid:11)(cid:8) (cid:14) (cid:4) (cid:29)(cid:16) = (cid:8)(cid:16) (cid:8) (cid:29)(cid:16) (cid:11)(cid:12)(cid:16) (cid:4) #(cid:16)(cid:16) 	(cid:15)(cid:12)(cid:16)(cid:30)
(cid:16),

(cid:0)(cid:0)(cid:1) (cid:2)(cid:4)(cid:1) (cid:6)(cid:8) (cid:11)(cid:6)(cid:4)(cid:6)(cid:12) (cid:1) (cid:1) (cid:3)(cid:5)(cid:6)(cid:15)

(cid:1) (cid:17)(cid:18)(cid:19) (cid:21)(cid:4) (cid:2)(cid:6) (cid:22)(cid:6)  (cid:1)(cid:8) (cid:21)(cid:1) (cid:23)(cid:1)(cid:1)  (cid:22)(cid:11)(cid:6)(cid:4)(cid:6)(cid:22)(cid:1) (cid:26)(cid:15)

112(cid:16)- )(cid:16) (cid:10)(cid:8)*(cid:16) ) (cid:15)	(cid:30) (cid:15)(cid:12)(cid:16)(cid:30)  (cid:28)(cid:12)(cid:30)(cid:16)(cid:12)(cid:11)(cid:29)(cid:16) (cid:12)*(cid:16)	
(cid:12)(cid:10)(cid:16) )(cid:29)(cid:8)(cid:11)(cid:29) (cid:30)(cid:16)(cid:11)(cid:8)(cid:15)(cid:16) (cid:9)(cid:18)(cid:9)(cid:11)(cid:6)  (cid:11)*(cid:16)(cid:10)(cid:16)(cid:11)(cid:16) (cid:15)(cid:16))(cid:16)(cid:16)
(cid:29)(cid:16) 	 (cid:12)(cid:8) (cid:12)(cid:30) (cid:16)(cid:8)(cid:8)(cid:11)(cid:12)  (cid:13)(cid:13), (cid:20)(cid:29)(cid:16) = (cid:12)	(cid:16)
	 (cid:29)(cid:12) (cid:29)(cid:16) 	 (cid:12)(cid:8) (cid:13)(cid:13) (cid:8) (cid:12)   )(cid:29)(cid:16) (cid:29)(cid:16) (cid:16)(cid:8)	
(cid:8)(cid:11)(cid:12)  (cid:13)(cid:13) (cid:8) (cid:12)  (cid:27) (cid:29)(cid:16) (cid:16)(cid:11)(cid:30) (cid:29)) (cid:29)(cid:12) (cid:29)(cid:16) 	 (cid:12)	
(cid:8) (cid:13)(cid:13) (cid:8)  (cid:12)(cid:10)(cid:16) )(cid:29)(cid:16) (cid:29)(cid:16) (cid:16)(cid:8)(cid:8)(cid:11)(cid:12)  (cid:13)(cid:13) (cid:8)  (cid:12)(cid:10)(cid:16)
(cid:15)(cid:29) (cid:12)(cid:16)(cid:16) (cid:12) (cid:14) )(cid:8)(cid:29) (cid:29)(cid:8)(cid:10)(cid:29) (cid:15)(cid:12)(cid:15)(cid:8) (cid:8)(cid:14), (cid:20)(cid:29)(cid:16)(cid:16)
(cid:16)	  (cid:12)(cid:16) *(cid:16)(cid:14) (cid:8)(cid:16)(cid:16)(cid:8)(cid:10) (cid:8) (cid:29)(cid:12) (cid:29)(cid:16)(cid:14) (cid:8)  	(cid:12)(cid:16) (cid:12)
(cid:15)(cid:12)(cid:30)(cid:16) (cid:29)(cid:16)(cid:16)@  )  (cid:16)(cid:12)(cid:8)(cid:10) (cid:12)(cid:16) (cid:30)  (cid:11)(cid:11)	
(cid:8) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:16)(cid:8)(cid:10) (cid:16)*(cid:16) (cid:29)	(cid:10)(cid:29) (cid:29)(cid:16)(cid:14) (cid:12)(cid:16) 	(cid:12)*(cid:8)(cid:30)	
(cid:12)(cid:15) (cid:16) (cid:8) (cid:16)(cid:10)(cid:16)(cid:8) (cid:12)(cid:30) (cid:11) (cid:12)(cid:8)=(cid:11)(cid:12)(cid:8) 4B (cid:13)(cid:29), C7, (cid:20)(cid:29)(cid:8)
(cid:8)(cid:10)(cid:29) (cid:12)(cid:16)(cid:12) 	(cid:8)(cid:8)(cid:10) (cid:8) (cid:29)(cid:16) (cid:16)(cid:11)(cid:8)=(cid:11) (cid:11)(cid:12)(cid:16) (cid:4) (cid:13)(cid:13)
(cid:8)(cid:11)(cid:16) (cid:29)(cid:8) (cid:11)(cid:8)(cid:16)(cid:8) (cid:8) (cid:8)(cid:8)(cid:16)(cid:30) (cid:8) (cid:29)(cid:16) (cid:11)	(cid:16) (cid:4) #(cid:16)	
(cid:16) (cid:8)(cid:16)(cid:30) & (cid:16)(cid:10)(cid:16)(cid:8) (cid:12)	(cid:8)(cid:10) (cid:12) #(cid:16)(cid:16) (cid:8)(cid:16)(cid:30) 		
(cid:12)(cid:11)(cid:16)@ (cid:16)(cid:16) (cid:29)(cid:16) (cid:30)(cid:8)(cid:11)	(cid:8) (cid:8) 487, (cid:26)(cid:29)(cid:16) (cid:8)(cid:12)
(cid:11)(cid:16)	(cid:16)(cid:11)(cid:16) (cid:4) (cid:29)(cid:16) (cid:15)	(cid:30) (cid:8) (cid:29)(cid:12) (cid:6)(cid:25) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:15)(cid:16)	
)(cid:16)(cid:16) (cid:29)(cid:16) (cid:12)(cid:30) *(cid:12)(cid:8)(cid:12)(cid:15) (cid:16) )(cid:8)   (cid:15)(cid:16) (cid:30)(cid:16)(cid:16)(cid:11)(cid:16)(cid:30) (cid:12)(cid:8)(cid:30) (cid:14) (cid:6)
(cid:21)(cid:9) (cid:6) (cid:9) (cid:11)(cid:26)(cid:9) (cid:11)(cid:22)(cid:9)(cid:6)(cid:9) (cid:16)*(cid:16) (cid:29)	(cid:10)(cid:29) (cid:16)(cid:4)(cid:16)(cid:11) (cid:30)(cid:16)(cid:16)	
(cid:30)(cid:16)(cid:11)(cid:16) (cid:30)(cid:16)(cid:16)(cid:11)(cid:8) (cid:8) (cid:8)(cid:8)(cid:15) (cid:16) (cid:4) =-(cid:16)(cid:30) (cid:12) (cid:16) (cid:8)/(cid:16),

0(cid:8)(cid:12)  (cid:14) )(cid:16) (cid:30)(cid:16)(cid:11)(cid:8)(cid:15)(cid:16) (cid:12) (cid:16)	(cid:11)(cid:8)(cid:16)(cid:11)(cid:16) (cid:12) (cid:8)(cid:11)(cid:12)(cid:8) )(cid:29)(cid:16)(cid:16)
	 (cid:16)(cid:29)(cid:30) (cid:11)(cid:12) (cid:15)(cid:16) 	(cid:16)(cid:30), (cid:26) 	(cid:15)(cid:16) (cid:4) (cid:10)	 (cid:16),(cid:10),
467 (cid:29)(cid:12)*(cid:16) (cid:15)(cid:16)(cid:10)	 (cid:16)-(cid:12)(cid:8)(cid:8)(cid:10) (cid:29)(cid:16) (cid:8)(cid:16)(cid:12)(cid:11)(cid:8) (cid:15)(cid:16))(cid:16)(cid:16)
(cid:16)	(cid:12)  (cid:14)(cid:16) 	(cid:8)(cid:10) (cid:4)(cid:28) (cid:8) (cid:29)	(cid:12), (cid:20)(cid:29)(cid:16) (cid:16)(cid:11)(cid:16)
	(cid:30)(cid:14) (cid:4) (cid:7). (cid:4)(cid:28) (cid:8) (cid:29)(cid:16) (cid:12)(cid:11)(cid:12)	(cid:16) #(cid:16)(cid:14) 	(cid:8)(cid:10)
(cid:29)(cid:8)(cid:10)(cid:29) =(cid:16) (cid:30) :,C(cid:20)  C(cid:20) (cid:11)(cid:12)(cid:16) 45C 5B7 (cid:29)(cid:12) (cid:16)	 (cid:16)(cid:30)
(cid:8) 	(cid:15)(cid:12)(cid:8)(cid:12)  (cid:8)(cid:11)(cid:16)(cid:12)(cid:16) (cid:8) (cid:12)(cid:8)(cid:12)  (cid:12)(cid:30) (cid:16)(cid:12)  (cid:16) 		
(cid:8) )(cid:29)(cid:16) (cid:16)(cid:12)	(cid:8)(cid:10) (cid:15)(cid:12)(cid:8) (cid:12)(cid:11)(cid:8)*(cid:8)(cid:14) (cid:12)(cid:16) (cid:16)	 (cid:8)(cid:10)
(cid:4) *(cid:12)(cid:8)	 (cid:8)	 (cid:8),
 &(cid:16)(cid:11)(cid:8) B )(cid:16) (cid:12) (cid:14) (cid:13)(cid:13)
 (cid:29)(cid:16)(cid:16) (cid:29)(cid:8)(cid:10)(cid:29) (cid:16) 	(cid:8) (cid:30)(cid:12)(cid:12)  (cid:12)  (cid:30)(cid:16)(cid:16)(cid:11) (cid:30)(cid:16)(cid:16)	
(cid:30)(cid:16)(cid:11)(cid:16) (cid:15)(cid:16))(cid:16)(cid:16) (cid:7). (cid:16)(cid:16) )(cid:8)(cid:29)(cid:8) (cid:29)(cid:16) *(cid:8)	(cid:12)  (cid:11)	
(cid:16)-,  	(cid:8)(cid:10) (cid:13)(cid:13)  (cid:30)(cid:16)(cid:16)(cid:11) (cid:16)(cid:10)(cid:8) (cid:4) (cid:29)(cid:8)(cid:10)(cid:29) (cid:30)(cid:16)(cid:16)	
(cid:30)(cid:16)(cid:11)(cid:16) )(cid:16) (cid:4)  ) 4E7 )(cid:29) (cid:12)-(cid:8)(cid:8)(cid:16) (cid:12) #(cid:16)(cid:16) 	(cid:15)(cid:12)(cid:16)(cid:30) (cid:30)(cid:16)	
(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:16)(cid:12)	(cid:16) (cid:8) (cid:29)(cid:16)(cid:8) (cid:11)(cid:12)(cid:16) (cid:29)(cid:16) (cid:23)A (cid:12) (cid:12) (cid:16)(cid:12)
(cid:4) *(cid:12)(cid:8)(cid:12)(cid:15) (cid:16) (cid:16) (cid:16)(cid:11)(cid:8), !(cid:16) (cid:12)  (cid:8)*(cid:16)(cid:8)(cid:10)(cid:12)(cid:16) (cid:29)) (cid:29)(cid:16) (cid:16)(cid:12)	
	(cid:16)(cid:30) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:11)(cid:29)(cid:12)(cid:10)(cid:16) )(cid:8)(cid:29) (cid:29)(cid:16) (cid:16)*(cid:12)  (cid:4) (cid:15)(cid:16)(cid:12)(cid:29)	
(cid:8)(cid:10) (cid:12)(cid:16)(cid:4)(cid:12)(cid:11) )(cid:29)(cid:8)(cid:11)(cid:29) (cid:8) (cid:4)(cid:16)(cid:12)(cid:8)(cid:15) (cid:16) (cid:30)	(cid:16)  (cid:29)(cid:16) (cid:29)(cid:8)(cid:10)(cid:29) (cid:16)(cid:12) 
(cid:16) 	(cid:8) (cid:4) 	 (cid:16)(cid:12)	(cid:16)(cid:16),

(cid:14) (cid:15)(cid:16)(cid:17)(cid:13)(cid:13) (cid:5)(cid:11) (cid:18)(cid:5)(cid:6)(cid:19)(cid:20)	(cid:11)
(cid:7)(cid:16)(cid:4)(cid:16) (cid:16)(cid:16)(cid:8)(cid:10) 	 (cid:12)(cid:8) (cid:16)	  )(cid:16) (cid:15)(cid:16)(cid:10)(cid:8) 	 (cid:30)(cid:8)	
(cid:11)	(cid:8) )(cid:8)(cid:29) (cid:16) (cid:16) (cid:16)*(cid:12) (cid:30)(cid:16)=(cid:8)(cid:8) (cid:12)(cid:30) (cid:15)(cid:12)(cid:11)#(cid:10)	(cid:30)
(cid:29)(cid:16)(cid:14) (cid:11)*(cid:16)(cid:8)(cid:10) (cid:15)(cid:29) (cid:11) (cid:12)(cid:8)(cid:11)(cid:12)  (cid:8)(cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:11)(cid:8)(cid:16)(cid:8)(cid:12)
(cid:12)(cid:30) (cid:28) &,(cid:2) (cid:16) F(cid:0)(cid:3)(cid:0) (cid:0)(cid:0)(cid:1) (cid:15)(cid:16) (cid:12) (cid:15)(cid:12)(cid:15)(cid:8) (cid:8)(cid:14) (cid:12)(cid:11)(cid:16),
(cid:13)(cid:8)(cid:30)(cid:16) (cid:12)(cid:30) *(cid:12)(cid:8)(cid:12)(cid:15) (cid:16) (cid:0) @ F(cid:0)(cid:3) (cid:4) (cid:4)(cid:0)(cid:5) (cid:12)(cid:30)
(cid:1) @ F(cid:0)(cid:3) (cid:4) (cid:5)(cid:0)(cid:6) )(cid:29)(cid:16)(cid:16) (cid:4) (cid:12)(cid:30) (cid:5) (cid:12)(cid:16) (cid:11) (cid:16)(cid:16)
(cid:16)(cid:8)(cid:11) (cid:12)(cid:11)(cid:16) (cid:12)(cid:30) (cid:5) (cid:12)(cid:30) (cid:6) (cid:29)(cid:16)(cid:8) (cid:16)(cid:16)(cid:11)(cid:8)*(cid:16) (cid:7)(cid:16)  (cid:6)	
(cid:12) (cid:10)(cid:16)(cid:15)(cid:12), (cid:20)(cid:29)(cid:16) (cid:11)*(cid:12)(cid:8)(cid:12)(cid:11)(cid:16) (cid:15)(cid:16))(cid:16)(cid:16) (cid:0) (cid:12)(cid:30) (cid:1) (cid:8) (cid:30)(cid:16)=(cid:16)(cid:30)
(cid:12) (cid:4)  ),

’(cid:6)((cid:17)(cid:17) ) +(cid:18)(cid:12)(cid:17)(cid:12)(cid:26)(cid:6)- (cid:27)(cid:21)(cid:9) (cid:22)(cid:24)(cid:6)(cid:11)(cid:6)(cid:22)(cid:9) (cid:23) (cid:28)
(cid:6)(cid:16) (cid:24)(cid:6)(cid:11)(cid:6)(cid:10) (cid:9) (cid:0)(cid:0) (cid:1) (cid:11) (cid:13)(cid:11)(cid:24)(cid:9) (cid:6)

(cid:11)*(cid:0)(cid:0) (cid:1) @9 (cid:0)(cid:0)(cid:0)(cid:1)4(cid:0)(cid:1)7   (cid:0)(cid:0)4(cid:0)7(cid:0)(cid:1)4(cid:1)7(cid:3)

8,5

0 	 	(cid:16) (cid:29)(cid:16) (cid:8) (cid:4) (cid:8)(cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:4) (cid:12)	
(cid:30) *(cid:12)(cid:8)(cid:12)(cid:15) (cid:16) (cid:8) (cid:15)(cid:16) (cid:16)-(cid:16)(cid:16)(cid:30) 	(cid:8)(cid:10) (cid:29)(cid:16) (cid:4)  )(cid:8)(cid:10)
(cid:11)(cid:29)(cid:12)(cid:12)(cid:11)(cid:16)(cid:8)(cid:12)(cid:8)@

(cid:2)(cid:28)(cid:21)(cid:4) (cid:1)(cid:29)(cid:4)(cid:4) (cid:4) (cid:1)(cid:22)(cid:1)(cid:6)(cid:4) (cid:31) (cid:8)(cid:1)(cid:1)  (cid:1)(cid:1) (cid:17)!"(cid:19) (cid:6)(cid:8) (cid:17)#!(cid:19)

$ (cid:1) (cid:8)(cid:1)(cid:6)(cid:4) (cid:15)

.(cid:3)(cid:6)(cid:6) ) (cid:13)(cid:6)(cid:6)(cid:13)(cid:6)(cid:26)(cid:6) 0)12- (cid:27)(cid:21)(cid:9) (cid:6)(cid:16)
(cid:24)(cid:6)(cid:11)(cid:6)(cid:10) (cid:9) (cid:0) (cid:6)(cid:16) (cid:1) (cid:6)(cid:9) (cid:11)(cid:16)(cid:9)(cid:9)(cid:16)(cid:9) (cid:11)(cid:23) (cid:6)(cid:16)  (cid:25) (cid:11)(cid:23)
(cid:11)*(cid:1) (cid:0)(cid:0) (cid:2)(cid:1) 9 G (cid:23) (cid:9)(cid:6)(cid:22)(cid:21) (cid:6)(cid:11) (cid:1)(cid:0) (cid:2) (cid:23) (cid:10)	(cid:16)(cid:9)(cid:16)
(cid:22)(cid:11)		 (cid:23)	(cid:22)(cid:11)(cid:4)

(cid:20)(cid:29)(cid:8) (cid:29)(cid:16)(cid:16) 	(cid:10)(cid:10)(cid:16) (cid:29)(cid:16) (cid:4)  )(cid:8)(cid:10) (cid:30)(cid:16)=(cid:8)(cid:8) (cid:12) (cid:12)
(cid:8)(cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:16),
’(cid:6)((cid:17)(cid:17) 3 +(cid:12)(cid:17)(cid:6)(cid:13) (cid:26)(cid:18)(cid:12)(cid:17)(cid:12)(cid:26)(cid:6)- (cid:23)(cid:8)*(cid:16)
(cid:4)	(cid:11)(cid:8) (cid:11) (cid:12)(cid:16) (cid:1)(cid:0)(cid:2) (cid:11)(cid:12)(cid:8)(cid:8)(cid:10) 	(cid:15)(cid:12)(cid:11)(cid:16) (cid:7) (cid:0) (cid:1) (cid:12)(cid:30)
(cid:8) (cid:0) (cid:2) )(cid:16) (cid:30)(cid:16)=(cid:16) (cid:29)(cid:16) (cid:22)(cid:6)(cid:11)(cid:9)(cid:16) (cid:22)(cid:24)(cid:6)(cid:11)(cid:6)(cid:22)(cid:9) (cid:12)
(cid:13)(cid:13)(cid:0)(cid:0)(cid:1)(cid:27) (cid:7)(cid:0) (cid:8) @9 	

4(cid:11)*(cid:1) (cid:0)(cid:0) (cid:2)(cid:1)7 (cid:3) 8,8

(cid:1)(cid:3)(cid:2)(cid:0)(cid:3)(cid:3)(cid:4)

(cid:8)(cid:4) (cid:7) (cid:12)(cid:30) (cid:8) (cid:12)(cid:16) 	(cid:8) (cid:15)(cid:12)   (cid:8) (cid:29)(cid:16)(cid:8) (cid:16)(cid:16)(cid:11)(cid:8)*(cid:16) (cid:12)(cid:11)(cid:16)
(cid:29)(cid:16) (cid:29)(cid:8) (cid:8) 1	 (cid:29)(cid:16)  (cid:4) (cid:29)(cid:16) (cid:11)*(cid:12)(cid:8)(cid:12)(cid:11)(cid:16) 	
(cid:16)(cid:12) (cid:12)(cid:8)(cid:10) (cid:2)  (cid:1)@
(cid:16)(cid:16) 4E7 (cid:12)(cid:30) (cid:16)(cid:4)(cid:16)(cid:16)(cid:11)(cid:16)
(cid:29)(cid:16)(cid:16)(cid:8), (cid:23)(cid:8)*(cid:16)  (cid:8)(cid:30)(cid:16)(cid:16)(cid:30)(cid:16) (cid:15)(cid:16)*(cid:12)(cid:8) (cid:0) @9
(cid:10)(cid:0)(cid:0) (cid:11)(cid:0)(cid:0) (cid:3) (cid:3) (cid:3) (cid:0) (cid:10)(cid:0) (cid:11) (cid:8) (cid:9)  (cid:11) (cid:8) (cid:16)(cid:8)(cid:8)(cid:11)(cid:12)  (cid:16)	
(cid:8)(cid:12)(cid:16) (cid:8) (cid:30)(cid:16)=(cid:16)(cid:30) (cid:12)

(cid:13)(cid:13)(cid:3)(cid:0)(cid:27) (cid:7)(cid:0) (cid:8) @9

	

(cid:1)(cid:3)(cid:2)(cid:0)(cid:3)(cid:3)(cid:4)(cid:0)(cid:1) 5

(cid:2)(cid:6)(cid:6)(cid:0)

(cid:1) (cid:10)(cid:6)(cid:2)(cid:11)(cid:6)  



5
(cid:1)

(cid:2)(cid:6)(cid:6)(cid:0)

(cid:1) (cid:10)(cid:6)

(cid:2)(cid:7)(cid:6)(cid:0)

(cid:2)(cid:11)(cid:7)(cid:3)(cid:4) (cid:3)

 (cid:4)  ) (cid:4) (cid:20)(cid:29)(cid:16)(cid:16) 5 (cid:29)(cid:12) (cid:8)(cid:4) (cid:1)(cid:0)(cid:2) (cid:12)(cid:16) (cid:29)(cid:16)
(cid:16) (cid:4) (cid:11)(cid:8)		 (cid:4)	(cid:11)(cid:8) (cid:15)	(cid:30)(cid:16)(cid:30) (cid:15)(cid:14) 5 )(cid:16) (cid:29)(cid:12)*(cid:16)
(cid:13)(cid:13)(cid:0)(cid:0)(cid:1)(cid:27)(cid:1)(cid:0)(cid:2) 9 G (cid:8)(cid:4) (cid:12)(cid:30)  (cid:14) (cid:8)(cid:4) (cid:0) (cid:12)(cid:30) (cid:1) (cid:12)(cid:16) (cid:8)(cid:30)(cid:16)	
(cid:16)(cid:30)(cid:16),(cid:7)  (cid:29)(cid:16) )(cid:30) (cid:13)(cid:13) (cid:12)(cid:30) (cid:13)(cid:13)(cid:3) (cid:12)(cid:16)
(cid:11)(cid:8)(cid:16)(cid:8)(cid:12) )(cid:29)(cid:8)(cid:11)(cid:29) (cid:11)(cid:12) (cid:15)(cid:16) (cid:16)(cid:16)(cid:30) (cid:16)(cid:11)(cid:9)(cid:22) (cid:25) )(cid:8)(cid:29)	 (cid:29)(cid:16) (cid:16)(cid:16)(cid:30)
(cid:4) (cid:12) (cid:8)(cid:16)(cid:16)(cid:30)(cid:8)(cid:12)(cid:16) (cid:30)(cid:16)(cid:8)(cid:14) (cid:16)(cid:8)(cid:12) (cid:8) (cid:10)(cid:16)(cid:16)(cid:12)  (cid:29)(cid:16)
(cid:30)(cid:8)(cid:8)(cid:15)	(cid:8) (cid:12)(cid:14)  (cid:16)*(cid:16) (cid:29)(cid:12)*(cid:16) (cid:30)(cid:16)(cid:8)(cid:8)(cid:16),  (cid:8) (cid:12) 
(cid:11) (cid:16)(cid:12) (cid:29))(cid:16)*(cid:16) (cid:29)(cid:12) 	 (cid:16) (cid:7)(cid:0) (cid:8) (cid:12)(cid:16) (cid:16)(cid:8)(cid:11)(cid:16)(cid:30) (cid:8) (cid:4)		
(cid:29)(cid:16) )(cid:12)(cid:14) (cid:13)(cid:13)(cid:3) )(cid:8)   (cid:12) )(cid:12)(cid:14) (cid:15)(cid:16)  (cid:12)(cid:10)(cid:16) (cid:30)	(cid:16)  (cid:29)(cid:16)
(cid:8)(cid:11)(cid:29) (cid:11)(cid:29)(cid:8)(cid:11)(cid:16) (cid:4) (cid:4)	(cid:11)(cid:8) (cid:12)*(cid:12)(cid:8) (cid:12)(cid:15) (cid:16), (cid:26) 	(cid:11)(cid:24)(cid:11)(cid:6)  (cid:16)(cid:9)(cid:9)	
(cid:16)(cid:9)(cid:22)(cid:9) (cid:9)(cid:6)	(cid:9) (cid:8) (cid:29)	 (cid:15)(cid:12)(cid:8)(cid:16)(cid:30) 	(cid:8)(cid:10) (cid:4)	(cid:11)(cid:8) (cid:11) (cid:12)(cid:16)
(cid:29)(cid:12) (cid:30)  (cid:10)(cid:8)*(cid:16) (cid:12) (cid:16)*(cid:16)(cid:14))(cid:29)(cid:16)(cid:16)	/(cid:16) (cid:16)(cid:8)(cid:8)(cid:11)(cid:12)  (cid:12)*(cid:16)(cid:12)(cid:10)(cid:16)
(cid:14)(cid:16) )(cid:29)(cid:8)(cid:11)(cid:29) (cid:8)   (cid:10)	(cid:12)(cid:12)(cid:16)(cid:16) (cid:29)(cid:12) (cid:13)(cid:13) (cid:8) /(cid:16) (cid:8)(cid:4) (cid:12)(cid:30)
 (cid:14) (cid:8)(cid:4) (cid:8) (cid:12)(cid:10)	(cid:16) (cid:12)(cid:16) (cid:8)(cid:30)(cid:16)(cid:16)(cid:30)(cid:16), (cid:26) (cid:12)(cid:30)(cid:16)3 (cid:15)(cid:16)	
)(cid:16)(cid:16) (cid:29)(cid:16) (cid:16)(cid:8)(cid:11)(cid:8)*(cid:16)(cid:16) (cid:4) (cid:29)(cid:16)(cid:16) (cid:4)	(cid:11)(cid:8) (cid:11) (cid:12)(cid:16) (cid:12)(cid:30)
(cid:29)(cid:16) (cid:11)*(cid:16)(cid:10)(cid:16)(cid:11)(cid:16) (cid:4) (cid:13)(cid:13)(cid:3)  (cid:13)(cid:13) (cid:11)(cid:12) (cid:15)(cid:16) (cid:12)(cid:11)(cid:11)	
 (cid:8)(cid:29)(cid:16)(cid:30) 	(cid:8)(cid:10) (cid:12)(cid:30)(cid:12)(cid:30)   (cid:4) 	(cid:8)(cid:4) (cid:11)*(cid:16)(cid:10)(cid:16)(cid:11)(cid:16)
(cid:29)(cid:16)(cid:14) (cid:16)(cid:16) &(cid:16)(cid:11)(cid:8) >,

 	 	 &(cid:16)(cid:11)(cid:8) 6 (cid:29)(cid:12) 	(cid:8)	(cid:12)(cid:30)(cid:8)	 (cid:15)(cid:12)   (cid:8) 	(cid:8)	
*(cid:16)(cid:12)  (cid:16)(cid:30)	(cid:11)(cid:8)(cid:10) #(cid:16)(cid:16)   (cid:8) (cid:15)(cid:16) (cid:12)(cid:11)(cid:16) (cid:11)(cid:8)	(cid:16)
(cid:4)	(cid:11)(cid:8) (cid:11) (cid:12)(cid:16) (cid:29)(cid:12) (cid:14)(cid:8)(cid:16) (cid:30) 	(cid:8)*(cid:8)(cid:12)  (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:16)	
(cid:8)(cid:12)(cid:16), (cid:20) (cid:30)(cid:16)(cid:12)(cid:16) (cid:29)(cid:8) )(cid:16) )(cid:8)   	(cid:16) (cid:11)(cid:16)(cid:12)(cid:8)
(cid:16)(cid:8)(cid:16) (cid:4) (cid:29)(cid:16)(cid:16) (cid:12)(cid:11)(cid:16) 48G7, (cid:26) (cid:16)(cid:30)	(cid:11)(cid:8)(cid:10) #(cid:16)(cid:16) 
 (cid:8) (cid:15)(cid:16) (cid:12)(cid:11)(cid:16) (cid:8) (cid:12)  (cid:8) (cid:15)(cid:16) (cid:12)(cid:11)(cid:16) (cid:1) (cid:4) )(cid:29)(cid:8)(cid:11)(cid:29) (cid:12) (cid:16)(cid:12)(cid:11)(cid:29)
(cid:10) (cid:0) (cid:9)  (cid:29)(cid:16) (cid:8) (cid:16)*(cid:12) 	(cid:12)(cid:8) (cid:4)	(cid:11)(cid:8)(cid:12)  Æ(cid:8) @ (cid:1) (cid:4) (cid:0)(cid:0)
)(cid:29)(cid:8)(cid:11)(cid:29) (cid:12) (cid:1) (cid:0) (cid:1)  (cid:1) (cid:10) (cid:0) (cid:0) (cid:8) (cid:11)(cid:8)		, (cid:20) (cid:16)(cid:12)(cid:11)(cid:29)
(cid:16)(cid:30)	(cid:11)(cid:8)(cid:10) #(cid:16)(cid:16)   (cid:8) (cid:15)(cid:16) (cid:12)(cid:11)(cid:16) (cid:29)(cid:16)(cid:16) (cid:11)(cid:16)(cid:30) (cid:12)
	(cid:8)	(cid:16) (cid:8)(cid:8)*(cid:16) (cid:30)(cid:16)=(cid:8)(cid:16) #(cid:16)(cid:16)  (cid:12) @ (cid:9)  (cid:9) (cid:4) (cid:0) (cid:29)(cid:16)
(cid:16)(cid:30)	(cid:11)(cid:8)(cid:10) #(cid:16)(cid:16)  )(cid:29)(cid:8)(cid:11)(cid:29) (cid:11)(cid:8)	(cid:16) (cid:29)(cid:16) (cid:8)(cid:16) (cid:30)	
	(cid:11)  (cid:29)(cid:8) (cid:12)(cid:11)(cid:16)@ (cid:29)(cid:8) (cid:8) (cid:10)	(cid:12)(cid:12)(cid:16)(cid:16)(cid:30) (cid:15)(cid:14) (cid:29)(cid:16) (cid:16)	
(cid:26)/(cid:12)1 (cid:29)(cid:16)(cid:16),

(cid:3) (cid:1)(cid:1) (cid:2)(cid:1) (cid:1) (cid:0) & (cid:0) (cid:6)(cid:8) (cid:1) & (cid:1)(cid:15)

113 (cid:28) & (cid:29)(cid:16) (cid:16)(cid:16)(cid:16)(cid:16) (cid:29)(cid:16)(cid:16) 4857 (cid:29) (cid:30) (cid:12)(cid:8)(cid:10)
(cid:29)(cid:12) (cid:29)(cid:16)  	(cid:8) (cid:4) (cid:12) (cid:8)(cid:8)(cid:12)(cid:8) (cid:15) (cid:16) (cid:30)(cid:16)(cid:16)	
(cid:30)(cid:16)  (cid:14)  (cid:29)(cid:16) (cid:4)	(cid:11)(cid:8) (cid:16)*(cid:12) 	(cid:12)(cid:8)  (cid:12) (cid:16) (cid:4) (cid:15)	
(cid:16)*(cid:12)(cid:8) (cid:12)(cid:30)  (cid:28) &   (cid:8)(cid:16) (cid:8) (cid:29)(cid:16) (cid:12) (cid:4) (cid:29)(cid:16)
#(cid:16)(cid:16)  (cid:4)	(cid:11)(cid:8) (cid:16)*(cid:12) 	(cid:12)(cid:16)(cid:30)  (cid:29)(cid:16) (cid:15)(cid:16)*(cid:12)(cid:8), (cid:20)(cid:29)(cid:8)
(cid:16)(cid:14) (cid:8) (cid:16)- 	(cid:16)(cid:30)  (cid:16)(cid:11)(cid:8)(cid:4)(cid:14) (cid:12) (cid:16)(cid:12)(cid:8) (cid:14) (cid:11)	(cid:16)(cid:30) (cid:16)-	
(cid:16)(cid:8) (cid:4) (cid:13)(cid:13)(cid:3)(cid:0)(cid:27) (cid:7)(cid:0) (cid:8) )(cid:29)(cid:16)(cid:16) (cid:7) (cid:12)(cid:30) (cid:8) (cid:12)(cid:16) (cid:16)	
(cid:16)(cid:11)(cid:8)*(cid:16) (cid:14) 	(cid:8) (cid:15)(cid:12)   (cid:8) (cid:29)(cid:16) (cid:16)(cid:30)	(cid:11)(cid:8)(cid:10) #(cid:16)(cid:16)   (cid:8) (cid:15)(cid:16)
(cid:12)(cid:11)(cid:16) (cid:1) (cid:12)(cid:30) (cid:2), (cid:20)(cid:29)(cid:16) (cid:4) (cid:12)(cid:14) (cid:15)(cid:16) (cid:4)	(cid:30) (cid:8) 4;7,
(cid:6)(cid:12) ) 4(cid:12) 	(cid:6) (cid:23) (cid:13)(cid:13)(cid:3)(cid:0)(cid:27) (cid:7)(cid:0) (cid:8)- (cid:31)(cid:9)(cid:9) (cid:10)(cid:25)
(cid:1)(cid:0)(cid:2)   (cid:19)  (cid:21)(cid:9) (cid:16)(cid:6)(cid:11) (cid:9) (cid:6)(cid:16) (cid:11) (cid:9)(cid:9)(cid:22)(cid:11)(cid:24)(cid:9) (cid:25) (cid:6)(cid:16)
 (cid:9) (cid:7)(cid:0) (cid:8) (cid:10)(cid:9) (cid:21)(cid:9) 	(cid:11) (cid:10)(cid:6)   (cid:11) (cid:21)(cid:9) (cid:22)(cid:9)(cid:16)(cid:11)(cid:13)   (cid:19)(cid:4)
(cid:27)(cid:21)(cid:9)

(cid:13)(cid:13)(cid:3)(cid:0)(cid:27) (cid:7)(cid:0) (cid:8) 9

8,6

5

(cid:12) H (cid:1) H (cid:3)(cid:12)(cid:1)



(cid:28)(cid:21)(cid:9)(cid:9) H (cid:1) (cid:11) (cid:21)(cid:9) (cid:6)(cid:11)(cid:18) (cid:10)(cid:6)(cid:11)(cid:9)(cid:16) (cid:10)(cid:25) (cid:21)(cid:9) #(cid:9)(cid:22)(cid:11)
H (cid:1) 9   (cid:1)  (cid:28)(cid:11)(cid:21) #(cid:9)(cid:22)(cid:11) (cid:9)(cid:6) (cid:6)(cid:7) 9 Æ(cid:6)(cid:7)   (cid:0)
(cid:6)(cid:16) $(cid:6) (cid:6)(cid:11)(cid:18)  (cid:1)
(cid:6)(cid:7) 9 (cid:12)(cid:1) (cid:10)(cid:6)(cid:0) (cid:10)(cid:7) (cid:4) H (cid:3) (cid:11) (cid:16)(cid:9)(cid:0)(cid:9)(cid:16) (cid:10)(cid:25)
(cid:6)(cid:6) (cid:13)(cid:25) 	(cid:11)(cid:13) (cid:21)(cid:9) %(cid:9)(cid:9)  (cid:23) (cid:2) (cid:28)(cid:21)(cid:11)(cid:22)(cid:21) (cid:11)(cid:13)(cid:21) (cid:10)(cid:9) (cid:16)(cid:11)’(cid:9)(cid:9)
(cid:23) (cid:21)(cid:6) (cid:23) (cid:1)(cid:4)
(cid:26) (cid:16)(cid:11)(cid:30) (cid:29)(cid:16)(cid:16) )(cid:29)(cid:8)(cid:11)(cid:29) )(cid:8)   (cid:15)(cid:16) (cid:11)	(cid:11)(cid:8)(cid:12)  (cid:8) 	 (cid:4)
(cid:8) (cid:16)(cid:11)(cid:16) (cid:29)(cid:16)(cid:16) )(cid:29)(cid:8)(cid:11)(cid:29) *(cid:8)(cid:30)(cid:16) (cid:12) (cid:30)(cid:16)(cid:11)(cid:8)(cid:8)
(cid:4) (cid:29)(cid:16) #(cid:16)(cid:16)  (cid:8) (cid:16)(cid:8)(cid:10)(cid:16)(cid:4)	(cid:11)(cid:8) (cid:12)(cid:30) (cid:16)(cid:8)(cid:10)(cid:16)*(cid:12) 	(cid:16),
.(cid:3)(cid:6)(cid:6) 5 (cid:6)(cid:26)(cid:6) (cid:3)(cid:6)(cid:6)- (cid:9) (cid:12)(cid:0) (cid:0)
(cid:4)(cid:9) (cid:1) (cid:10)(cid:9) (cid:6) (cid:25)(cid:9)(cid:11)(cid:22) (cid:9)(cid:6)  (cid:24)(cid:6) 	(cid:9)(cid:16) (cid:23)	(cid:22)(cid:11) (cid:28)(cid:11)(cid:21) (cid:6)
(cid:6)(cid:22)(cid:11)(cid:6)(cid:9)(cid:16) (cid:11)(cid:11)(cid:24)(cid:9) (cid:16)(cid:9)(cid:0)(cid:11)(cid:9) (cid:11)(cid:9)(cid:13)(cid:6)  (cid:9)(cid:6) (cid:28)(cid:11)(cid:21) 	
(cid:6) (cid:11)(cid:9)(cid:16) (cid:21)(cid:13)(cid:6)  (cid:9)(cid:11)(cid:13)(cid:9)(cid:23)	(cid:22)(cid:11)  (cid:0) (cid:1)(cid:9)  (cid:9)(cid:16)
	(cid:22)(cid:21) (cid:21)(cid:6) (cid:21)(cid:9) (cid:6)(cid:22)(cid:11)(cid:6)(cid:9)(cid:16) (cid:9)(cid:11)(cid:13)(cid:9)(cid:24)(cid:6) 	(cid:9) J(cid:12) (cid:16)  (cid:11)(cid:22)(cid:9)(cid:6)(cid:9)(cid:4)
(cid:27)(cid:21)(cid:9) (cid:23) (cid:6)  (cid:6)   (cid:10)(cid:6) (cid:0) (cid:9) (cid:6)(cid:16) (cid:10)(cid:7) (cid:0) (cid:9)  (cid:21)(cid:9) (cid:9)(cid:11)(cid:9)

(cid:12)(cid:10)(cid:6)(cid:0) (cid:10)(cid:7)  @9

(cid:4)(cid:2)(cid:6)(cid:0)

J(cid:12)(cid:10)(cid:6)(cid:10)(cid:7) 

	

(cid:22)(cid:24)(cid:9)(cid:13)(cid:9) (cid:6)(cid:10) 	(cid:9) (cid:25) (cid:6)(cid:16) 	(cid:11)(cid:23) (cid:25)(cid:4)  (cid:6)(cid:16)(cid:16)(cid:11)(cid:11) (cid:21)(cid:9)

(cid:6)(cid:6)(cid:0) (cid:14)J(cid:12)(cid:6)(cid:14) (cid:22)(cid:24)(cid:9)(cid:13)(cid:9) (cid:6)  (cid:4) (cid:15)(cid:4)

0(cid:8)(cid:12)  (cid:14) )(cid:16) (cid:10)(cid:8)*(cid:16) #(cid:16)(cid:16) 	(cid:30)(cid:16)(cid:16)(cid:30)(cid:16) (cid:30)(cid:16)(cid:11)(cid:12)(cid:14) (cid:12)(cid:16) (cid:4) (cid:29)(cid:16)
(cid:11)(cid:16)Æ(cid:11)(cid:8)(cid:16) 	(cid:16)(cid:30)  (cid:16)-(cid:12)(cid:30) (cid:4)	(cid:11)(cid:8) (cid:8) (cid:1) (cid:8) (cid:16) (cid:4)
(cid:29)(cid:16) (cid:16) (cid:4) (cid:15)(cid:12)(cid:8) (cid:4)	(cid:11)(cid:8) (cid:16)(cid:6)(cid:17) (cid:4) (cid:16)(cid:11)(cid:16) (cid:29)(cid:16)	
(cid:16),

(cid:6)(cid:12) 1 (cid:22)(cid:12)(cid:6) (cid:23) (cid:13)(cid:6)(cid:26)(cid:12)(cid:31) (cid:23) (cid:6)(cid:11)(cid:12)(cid:17) (cid:26)(cid:6)Æ	
(cid:26)(cid:17)(cid:6)- (cid:9) (cid:1) (cid:0) (cid:1) (cid:28)(cid:21)(cid:9)(cid:9) (cid:1) (cid:10) @9 (cid:4)(cid:6)(cid:6)(cid:0)
J(cid:1)(cid:6)(cid:6)(cid:10)(cid:4)
(cid:27)(cid:21)(cid:9) (cid:6)  (cid:13) (cid:6) J(cid:12)(cid:6) (cid:0) (cid:11)(cid:22)(cid:9)(cid:6)(cid:9) 	(cid:9)	 (cid:11)(cid:9)(cid:6) (cid:25) (cid:28)(cid:11)(cid:21)
(cid:18) (cid:14) J(cid:1)(cid:6)(cid:14) (cid:0) (cid:19)(cid:0) (cid:6)(cid:16) (cid:21)(cid:9)(cid:9) (cid:9)(cid:18)(cid:11) (cid:6)  (cid:8) (cid:0)  	(cid:22)(cid:21) (cid:21)(cid:6) (cid:23)
(cid:6)   (cid:21) (cid:22) G (cid:6)(cid:16) (cid:6)     (cid:22)  (cid:8) (cid:14) J(cid:1) (cid:14) (cid:23) (cid:21)(cid:4)
(cid:23)(cid:4) (cid:20)(cid:29)(cid:8) (cid:29) (cid:30) (cid:8)(cid:11)(cid:16) (cid:4) (cid:12)(cid:14) (cid:1) (cid:0) (cid:1) (cid:12)(cid:1)(cid:12)(cid:1)
(cid:6)
(cid:4)(cid:6)(cid:6)(cid:0)

(cid:6) (cid:7)J(cid:12)(cid:6)(cid:8) (cid:0)

(cid:20)(cid:29)(cid:16) 	(cid:16)	 (cid:8)(cid:16)(cid:12)(cid:8)(cid:14) (cid:16)	(cid:8)(cid:16)(cid:16) (cid:8) (cid:16)(cid:12) : (cid:8) (cid:12)	
(cid:8)=(cid:16)(cid:30) (cid:15)(cid:14) (cid:12)(cid:14) #(cid:16)(cid:16)  (cid:8)(cid:11) 	(cid:30)(cid:8)(cid:10) (cid:29)(cid:16) (cid:23)(cid:12)	(cid:8)(cid:12) (cid:4)
)(cid:29)(cid:8)(cid:11)(cid:29) (cid:29)(cid:16) J(cid:12) (cid:0) (cid:8)(cid:11)(cid:16)(cid:12)(cid:16) (cid:12) (cid:16)-(cid:1)(cid:27) (cid:16)(cid:16) 4857, !(cid:16)
(cid:12)	(cid:16) (cid:29)(cid:16)(cid:16)(cid:12)(cid:4)(cid:16) (cid:29)(cid:12) 	 #(cid:16)(cid:16)  (cid:12)(cid:8)=(cid:16) (cid:29)(cid:16) (cid:16)	(cid:8)(cid:16)	
(cid:16) (cid:4) (cid:16)(cid:12) :,

(cid:23) (cid:15),

J(cid:1) (cid:1)

@9

(cid:21) (cid:0) (cid:22)(cid:16) (cid:23) (cid:11)(cid:16)(cid:16)(cid:11)(cid:16)(cid:6)(cid:16)
!(cid:16) ) (cid:11)(cid:29)(cid:12)(cid:12)(cid:11)(cid:16)(cid:8)(cid:16) (cid:29)(cid:16) (cid:11) (cid:12) (cid:4) #(cid:16)(cid:16)  (cid:4) )(cid:29)(cid:8)(cid:11)(cid:29)
(cid:13)(cid:13) (cid:8) (cid:12) 	(cid:8)*(cid:8)(cid:12)  (cid:16) (cid:4) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16), (cid:20)(cid:29)(cid:16) (cid:12)(cid:8)
(cid:16)	  (cid:8) (cid:10)(cid:8)*(cid:16) (cid:8) (cid:20)(cid:29)(cid:16)(cid:16) B (cid:8) )(cid:29)(cid:8)(cid:11)(cid:29) )(cid:16) (cid:30)(cid:16)(cid:12)(cid:16)
(cid:29)(cid:12) (cid:13)(cid:13) (cid:11)(cid:8)	(cid:16) 	(cid:11)(cid:29) (cid:12) (cid:16) )(cid:29)(cid:16) (cid:1) (cid:12)(cid:30) (cid:2) (cid:12)(cid:16)
(cid:28) & )(cid:8)(cid:29) (cid:12) 	(cid:8)*(cid:16)(cid:12)  #(cid:16)(cid:16)  4887,
’(cid:6)((cid:17)(cid:17) 8 9(cid:17)(cid:18)(cid:6)(cid:12)  (cid:27)(cid:6)(cid:6) - (cid:26) (cid:22)(cid:11)		 %(cid:9)	
(cid:9)  (cid:12)(cid:0)  (cid:12) (cid:11)(cid:12)(cid:11) (cid:16)(cid:8)(cid:11) (cid:12)(cid:11)(cid:16) (cid:9) (cid:0) (cid:25) (cid:8) (cid:11)(cid:12)  (cid:16)(cid:30)
	(cid:8)*(cid:16)(cid:12)  (cid:8)(cid:4) (cid:12)(cid:30)  (cid:14) (cid:8)(cid:4) (cid:29)(cid:16) (cid:28) & (cid:1) (cid:8)(cid:30)	(cid:11)(cid:16)(cid:30) (cid:15)(cid:14) (cid:29)(cid:16)
#(cid:16)(cid:16)  (cid:8) (cid:30)(cid:16)(cid:16) (cid:8) (cid:26)(cid:9)  )(cid:8)(cid:29) (cid:16)(cid:16)(cid:11)  (cid:29)(cid:16)  (cid:10)(cid:14)
(cid:8)(cid:30)	(cid:11)(cid:16)(cid:30) (cid:15)(cid:14) (cid:29)(cid:16) (cid:8)=(cid:8)(cid:14)  (cid:12)(cid:1)   (cid:2)(cid:12)(cid:4)
0 (cid:8)(cid:12)(cid:11)(cid:16) 4887 (cid:29)) (cid:29)(cid:16) (cid:4)  )(cid:8)(cid:10) ) #(cid:16)(cid:16)  (cid:12)(cid:16)
	(cid:8)*(cid:16)(cid:12)   (cid:11)(cid:12)(cid:11) 	(cid:15)(cid:16) (cid:4) (cid:0)(cid:12) @

(cid:3)

(cid:12)(cid:10)(cid:0) (cid:10)(cid:7) 9 (cid:16)-  (cid:27)(cid:12)(cid:10)   (cid:10)(cid:7)(cid:12)(cid:1) (cid:12)(cid:30)
(cid:12)(cid:10)(cid:0) (cid:10)(cid:7) 9 (cid:16)-  (cid:27)(cid:12)(cid:10)   (cid:10)(cid:7)(cid:12) (cid:4) (cid:27) (cid:22) G(cid:3)
!(cid:16) ) (cid:12)(cid:16) 	 (cid:12)(cid:8) (cid:16)	  (cid:4) (cid:29)(cid:8) (cid:16)(cid:11)(cid:8),
.(cid:3)(cid:6)(cid:6) : ++ (cid:17)  (cid:31) ;(cid:6) (cid:12) (cid:17)(cid:13)(cid:6)(cid:6)	
(cid:13)(cid:6)(cid:26)(cid:6) (cid:23) 	(cid:17)(cid:18)(cid:6)(cid:12)  (cid:27)(cid:6)(cid:6) - (cid:31)(cid:9)(cid:9) (cid:10)(cid:25) (cid:1)(cid:0)(cid:2)
  (cid:19) (cid:28)(cid:11)(cid:21) 	(cid:11)(cid:24)(cid:9)(cid:6)  %(cid:9)(cid:9)  (cid:12)(cid:1) (cid:0) (cid:12)(cid:3)  (cid:21)(cid:9) (cid:22)(cid:6)(cid:22)
(cid:16)(cid:6)(cid:11) (cid:9) (cid:6)(cid:16) (cid:11) (cid:9)(cid:9)(cid:22)(cid:11)(cid:24)(cid:9) (cid:25) (cid:6)(cid:16)  (cid:9) (cid:7)(cid:0) (cid:8) (cid:10)(cid:9) (cid:21)(cid:9) 	(cid:11)
(cid:10)(cid:6)   (cid:11) (cid:21)(cid:9) (cid:22)(cid:9)(cid:16)(cid:11)(cid:13)   (cid:19)(cid:4) ,(cid:9) (cid:6)	(cid:9) (cid:28)(cid:11)(cid:21)	
  (cid:23) (cid:13)(cid:9)(cid:9)(cid:6) (cid:11)(cid:25) (cid:21)(cid:6) (cid:12)(cid:1)(cid:12)(cid:4) (cid:18) 5 (cid:6)(cid:16) (cid:12)(cid:2)(cid:12)(cid:4) (cid:18) 5 (cid:23) (cid:6)  
(cid:1) (cid:0) (cid:1) (cid:6)(cid:16) (cid:2) (cid:0) (cid:2)(cid:4) (cid:27)(cid:21)(cid:9) (cid:13)(cid:13)(cid:0)(cid:0)(cid:1)(cid:27) (cid:7)(cid:0) (cid:8) 9 G (cid:11)(cid:23) (cid:6)(cid:16)
 (cid:25) (cid:11)(cid:23) (cid:0)(cid:0) (cid:1) (cid:6)(cid:9) (cid:11)(cid:16)(cid:9)(cid:9)(cid:16)(cid:9)(cid:4)

(cid:23)(cid:4)  (cid:8) (cid:11) (cid:16)(cid:12) (cid:29)(cid:12) (cid:13)(cid:13)(cid:0)(cid:0)(cid:1)(cid:27) (cid:7)(cid:0) (cid:8) (cid:8) /(cid:16) (cid:8)(cid:4)
(cid:0) (cid:12)(cid:30) (cid:1) (cid:12)(cid:16) (cid:8)(cid:30)(cid:16)(cid:16)(cid:30)(cid:16), !(cid:16) *(cid:16) (cid:29)(cid:16) (cid:11)	
*(cid:16)(cid:16) (cid:15)(cid:14) (cid:11)(cid:12)(cid:30)(cid:8)(cid:11)(cid:8) 	(cid:8)(cid:10) (cid:29)(cid:16) (cid:12)(cid:8)(cid:10) (cid:12)	(cid:8)
(cid:13)(cid:13)(cid:0)(cid:0)(cid:1)(cid:27) (cid:28)(cid:9) (cid:0) (cid:28)(cid:11) 9 (cid:29) (cid:4) (cid:16) (cid:29) (cid:22) G (cid:29)(cid:16)(cid:16)
(cid:28)(cid:9)  (cid:30)(cid:16)(cid:16) (cid:29)(cid:16) 	(cid:15)(cid:16) (cid:4) (cid:26)(cid:9)  (cid:4) (cid:11)(cid:8)		 (cid:4)	(cid:11)	
(cid:8) (cid:15)	(cid:30)(cid:16)(cid:30) (cid:15)(cid:14) 5 (cid:8) (cid:29)(cid:16) (cid:4)(cid:9)  (cid:12)(cid:30) (cid:28)(cid:11) (cid:8) (cid:30)(cid:16)=(cid:16)(cid:30)
(cid:8) (cid:12) (cid:12)(cid:12) (cid:10)	 (cid:12)(cid:16) (cid:12)(cid:30) (cid:13)(cid:13)(cid:0)(cid:0)(cid:1)(cid:27) (cid:7)(cid:0) (cid:8) 9 G,
(cid:20)(cid:29)(cid:16)(cid:16) (cid:16)-(cid:8) ) (cid:16)	(cid:16)(cid:11)(cid:16) (cid:4) (cid:4)	(cid:11)(cid:8) (cid:1) (cid:0) (cid:26)(cid:9)  (cid:12)(cid:30)
(cid:2) (cid:0) (cid:26)(cid:11) (cid:12)(cid:8)(cid:4)(cid:14)(cid:8)(cid:10) (cid:12)(cid:1)(cid:12)(cid:4) (cid:18) 5(cid:0)(cid:12)(cid:2)(cid:12)(cid:4) (cid:18) 5 (cid:4)
)(cid:29)(cid:8)(cid:11)(cid:29)

(cid:11)*(cid:1)(cid:0)(cid:0) (cid:2)(cid:1) 9 (cid:29)(cid:3)

 (cid:8)
(cid:8)(cid:4)

(cid:16)  (cid:29)(cid:16) (cid:8) (cid:29)(cid:16)(cid:16) (cid:16)-(cid:8) (cid:12)  (cid:4) )(cid:29)(cid:8)(cid:11)(cid:29)
(cid:11)*(cid:1)(cid:0) (cid:0)(cid:2)(cid:1) (cid:19) (cid:29)(cid:30)8, !(cid:16) #) (cid:29)(cid:12) (cid:1) (cid:12)(cid:30) (cid:2) (cid:12)(cid:16)
(cid:16)(cid:16)(cid:11)(cid:8)*(cid:16) (cid:14) (cid:30)(cid:16)(cid:16) (cid:8) (cid:26)(cid:9)  (cid:12)(cid:30) (cid:26)(cid:11)@ (cid:29)(cid:8) (cid:16)(cid:12) (cid:29)(cid:12)
(cid:4) (cid:12)   5(cid:30)6 (cid:22) (cid:21) (cid:22) G )(cid:16) (cid:11)(cid:12) =(cid:30) (cid:16) (cid:1) (cid:0) (cid:1) (cid:12)(cid:30) (cid:12)
(cid:23) (cid:21) 9 (cid:13)
(cid:12)(cid:12) (cid:10)	 (cid:2) (cid:0) (cid:2) (cid:12)(cid:8)(cid:4)(cid:14)(cid:8)(cid:10) (cid:12)(cid:1)   (cid:1)(cid:12)(cid:4)
(cid:1)(cid:7) ,
!(cid:8)(cid:8)(cid:10) (cid:12) J(cid:1)(cid:0) @9 (cid:1)(cid:0)   (cid:1)(cid:0)  (cid:1)(cid:0) )(cid:8)(cid:29) (cid:12)
(cid:12)(cid:12) (cid:10)	 J(cid:2)(cid:1) (cid:30)(cid:16)=(cid:8)(cid:8) )(cid:16) (cid:15)(cid:12)(cid:8)

(cid:11)*(cid:1)(cid:0)(cid:0) (cid:2)(cid:1)

9 (cid:0)(cid:0)(cid:0)(cid:1)(cid:11) J(cid:1) (cid:0)J(cid:2)(cid:1)(cid:12)   (cid:0)(cid:0) J(cid:1) (cid:0)(cid:0)(cid:1)J(cid:2)(cid:1)

(cid:19) (cid:11)*(cid:1)(cid:0)(cid:0) (cid:2) (cid:1)   8(cid:21)(cid:14)(cid:0)(cid:0) (cid:1)(cid:0)(cid:14)

  8(cid:21)(cid:14)(cid:0)(cid:1) (cid:2)(cid:1)(cid:14)   8(cid:21)(cid:1)
(cid:29)
8   B
(cid:19)
(cid:11)(cid:12)(cid:30)(cid:8)(cid:11)

(cid:29)
8:

(cid:22) G(cid:3)

(cid:29)
:

9

(cid:20)(cid:29)(cid:8)
(cid:11)*(cid:1)(cid:0)(cid:0) (cid:2)(cid:1) 9 G (cid:12)(cid:30) (cid:11) (cid:16)(cid:16) (cid:29)(cid:16) (cid:4),

(cid:12)	(cid:8)

(cid:29)(cid:16)

(cid:29)(cid:12)

114(cid:20)(cid:29)(cid:16) #(cid:16)(cid:16)  (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:16) (cid:13)(cid:13)  (cid:23)A (cid:12)(cid:30)
(cid:13)(cid:13) (cid:12)(cid:16) (cid:10)(cid:16)(cid:16)(cid:12) (cid:8)(cid:16)(cid:30) (cid:8) 4; 57  (cid:12) (cid:10)(cid:16)(cid:12)(cid:16) 	(cid:15)(cid:16) (cid:4)
(cid:12)(cid:30) *(cid:12)(cid:8)(cid:12)(cid:15) (cid:16) *(cid:8)(cid:30)(cid:8)(cid:10) (cid:16) (cid:4) (cid:12)(cid:8))(cid:8)(cid:16) (cid:8)(cid:30)(cid:16)(cid:16)	
(cid:30)(cid:16)(cid:11)(cid:16),

(cid:25) (cid:13)(cid:13)(cid:5)(cid:13) (cid:23) (cid:11)(cid:16)(cid:16)(cid:11)(cid:16)(cid:6)(cid:16) (cid:22)(cid:16)
1-) (cid:5)(cid:6)(cid:6)(cid:12)  (cid:17)(cid:13)(cid:6)(cid:6)(cid:13)(cid:6)(cid:26)(cid:6) (cid:6)
 (cid:29)(cid:8) (cid:16)(cid:11)(cid:8) )(cid:16) (cid:8)  	(cid:12)(cid:16) )(cid:8)(cid:29) (cid:12) (cid:8) (cid:16) (cid:16)-(cid:12) (cid:16)
(cid:29)(cid:12) (cid:4) (cid:12) =(cid:8)(cid:16) (cid:12) (cid:16) (cid:29)(cid:16)(cid:16) (cid:16)-(cid:8)  (cid:16) (cid:4) (cid:8)(cid:30)(cid:16)	
(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) )(cid:29)(cid:8)(cid:11)(cid:29) (cid:11)(cid:12) (cid:16) (cid:8)(cid:12)(cid:15) (cid:14) (cid:8),(cid:16), )(cid:8)(cid:29) (cid:29)(cid:8)(cid:10)(cid:29) (cid:15)(cid:12)(cid:15)(cid:8) 	
(cid:8)(cid:14) (cid:30)(cid:8)(cid:8)(cid:10)	(cid:8)(cid:29) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:4) (cid:8)(cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16), (cid:20)(cid:29)(cid:8)
(cid:30)(cid:8)(cid:11)	(cid:8) (cid:8) (cid:8)(cid:16)(cid:30)(cid:16)(cid:30) (cid:12) (cid:12) (cid:11) (cid:16)(cid:16)  (cid:29)(cid:16) (cid:16)- (cid:16)(cid:11)	
(cid:8) )(cid:29)(cid:16)(cid:16) )(cid:16) (cid:16)- (cid:8)(cid:11)(cid:8) (cid:14) (cid:11)	(cid:11) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16) (cid:12)(cid:30)
*(cid:12)(cid:8)(cid:12)(cid:15) (cid:16) )(cid:29)(cid:8)(cid:11)(cid:29) (cid:12)(cid:16) (cid:30)(cid:8)Æ(cid:11)	  (cid:4) (cid:29)(cid:16) (cid:16)(cid:8)(cid:8)(cid:11)(cid:12)  (cid:13)(cid:13)
 (cid:30)(cid:8)(cid:8)(cid:10)	(cid:8)(cid:29) (cid:4) (cid:8)(cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16), !(cid:16) (cid:8)  	(cid:12)(cid:16) (cid:29)(cid:16)
(cid:11)(cid:12)(cid:16) )(cid:29)(cid:16)(cid:16) (cid:9) (cid:8) (cid:11)	(cid:12)(cid:15) (cid:16) (cid:15)	 	 (cid:16)(cid:12)(cid:8)(cid:10) (cid:12) (cid:8)(cid:16)
(cid:16)	(cid:12)  (cid:14)  (cid:11)(cid:8)		 (cid:12)(cid:11)(cid:16),
!(cid:16) (cid:15)(cid:16)(cid:10)(cid:8) )(cid:8)(cid:29) (cid:16) (cid:12)(cid:8), (cid:13)(cid:8)(cid:30)(cid:16) (cid:12) (cid:16)  (cid:4)
(cid:15)(cid:12)(cid:15)(cid:8) (cid:8)(cid:14) (cid:30)(cid:8)(cid:8)(cid:15)	(cid:8) (cid:0) )(cid:29)(cid:16)(cid:16) (cid:2) (cid:11)(cid:12)(cid:8)  (cid:16)	
(cid:8)(cid:16), (cid:20)(cid:29)(cid:16) (cid:16)  (cid:8)  (cid:8) (cid:8) ) 	(cid:15)(cid:16)@ (cid:6) (cid:11)	
(cid:12)(cid:8) (cid:30)(cid:8)(cid:8)(cid:15)	(cid:8) (cid:6)
(cid:4) 		(cid:12)  (cid:14) (cid:8)(cid:30)(cid:16)(cid:16)(cid:30)(cid:16) (cid:12)	
(cid:30) *(cid:12)(cid:8)(cid:12)(cid:15) (cid:16) (cid:6)
(cid:0)(cid:0)  (cid:12)(cid:30) (cid:12) (cid:11)(cid:12)(cid:8) (cid:30)(cid:8)	
(cid:8)(cid:15)	(cid:8) (cid:12)
(cid:4) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16) (cid:12)(cid:30) *(cid:12)(cid:8)(cid:12)(cid:15) (cid:16), !(cid:16)
(cid:16)- (cid:8)(cid:30)	(cid:11)(cid:16) (cid:12) (cid:16) (cid:1) )(cid:29)(cid:8)(cid:11)(cid:29) (cid:12)#(cid:16) (cid:12) (cid:30)(cid:12)(cid:12) (cid:16)(cid:11)
(cid:1) (cid:21) (cid:0) (cid:12)(cid:30) (cid:16)	

(cid:0) 9 	

(cid:7)(cid:6)(cid:0)

(cid:0)

(cid:0)

(cid:1) 9 5 @ (cid:1) (cid:21) (cid:12)

(cid:0) (cid:0)

(cid:1) 9 G @ (cid:1) (cid:21) (cid:6)

(cid:0)

(cid:23)(cid:8)*(cid:16) (cid:29)(cid:12) (cid:29)(cid:16) (cid:16) (cid:16)(cid:16)  (cid:14) (cid:12) =(cid:8)(cid:16) (cid:12) (cid:16) (cid:8) (cid:11)(cid:12)
(cid:30)(cid:16)(cid:16)(cid:8)(cid:16) )(cid:8)(cid:29) (cid:11) (cid:16)(cid:16) (cid:11)(cid:16)(cid:12)(cid:8)(cid:14) )(cid:29)(cid:16)(cid:29)(cid:16) (cid:29)(cid:16) (cid:30)(cid:12)(cid:12)
(cid:12)(cid:16) (cid:30)(cid:12)) (cid:4) (cid:12)
(cid:0) , !(cid:16) (cid:11)(cid:12)    (cid:12) (cid:31)	(cid:16) )(cid:29)(cid:16)
(cid:1) 9 5 (cid:18) (cid:31)(cid:27)

(cid:0)  (cid:6)

(cid:2)
(cid:0)

(cid:0)

(cid:0)(cid:10)



	
(cid:0) (cid:3)(cid:2)

(cid:2)

(cid:8) (cid:29)(cid:16) )(cid:30) (cid:31) 	(cid:16) (cid:15)	(cid:30) (cid:29)(cid:16) (cid:15)(cid:12)(cid:15)(cid:8) (cid:8)(cid:14) (cid:4) (cid:12)
(cid:20)(cid:14)(cid:16)  (cid:16), 	 (cid:29)(cid:16)(cid:16) (cid:8) (cid:12) (cid:4)  )@
.(cid:3)(cid:6)(cid:6) < 9(cid:17)(cid:18)(cid:6)(cid:12) 
 (cid:17)(cid:17)  (cid:13)(cid:6)(cid:6)(cid:13)(cid:6)(cid:26)(cid:6)
(cid:6) - - (cid:6)(cid:25) (cid:31)	(cid:9) (cid:9) (cid:0)(cid:18)(cid:9)(cid:16)  (cid:0)  (cid:6)(cid:16) (cid:6)(cid:25)
5   (cid:31) (cid:22) (cid:21) (cid:22) G (cid:21)(cid:9)(cid:9) (cid:9)(cid:18)(cid:11) (cid:0) (cid:22)(cid:0) (cid:6) 	(cid:22)(cid:21) (cid:21)(cid:6)

(cid:0)(cid:10)

(cid:0) (cid:1) 9 G (cid:19) 5   (cid:31)   (cid:21)(cid:27)

(cid:11) (cid:21)(cid:9) (cid:28)(cid:16) (cid:6) (cid:16)(cid:9)(cid:9)(cid:16)(cid:9)(cid:22)(cid:9) (cid:9) (cid:28)(cid:11)(cid:21) (cid:6)  (cid:28) (cid:27)(cid:25)(cid:9) 
(cid:9) (cid:22)(cid:6) (cid:21)(cid:6)(cid:24)(cid:9) (cid:6) (cid:9)(cid:24)(cid:9)(cid:9) (cid:27)(cid:25)(cid:9)  (cid:9)(cid:4)

(cid:23)(cid:4) !(cid:16) (cid:8)(cid:30)	(cid:11)(cid:16) (cid:12) (cid:30)(cid:8)(cid:8)(cid:15)	(cid:8) (cid:14)
 (cid:12)
(cid:30)(cid:12)) (cid:4) (cid:14)
(cid:20)(cid:14)(cid:16)  (cid:16) (cid:4) (cid:29)(cid:8) (cid:8)-	(cid:16) (cid:8) (cid:29)(cid:16)

(cid:0) 5 
 )(cid:29)(cid:16)(cid:16) G (cid:18)   (cid:23) 5, (cid:13) (cid:16)(cid:12) (cid:14) (cid:12)(cid:30) *(cid:12)(cid:8)(cid:12)(cid:15) (cid:16)
(cid:12)(cid:16) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16), (cid:20)(cid:29)(cid:16) (cid:15)(cid:12)(cid:15)(cid:8) (cid:8)(cid:14) (cid:4) (cid:12)

@9  (cid:6)

(cid:0)

(cid:0)

(cid:0)



(cid:3)
(cid:0)

(cid:0)(cid:10)

9(cid:2)(cid:0)

9 

(cid:14)(cid:16)(cid:6)(cid:0)

(cid:14)

(cid:0)

(cid:1) 9 G

(cid:2)
(cid:0)

(cid:0)(cid:10)

(cid:1) 9 G

(cid:15)

9(cid:2)(cid:0)
(cid:11)(cid:16)(cid:0)(cid:6)(cid:8) 9(cid:2)(cid:0)

(cid:14)(cid:16)(cid:6)(cid:0)
9 5   (cid:31)

(cid:14)

(cid:0) (cid:1)(cid:0)(cid:6)(cid:8)

 (cid:6)

(cid:0) (cid:11)(cid:16)(cid:0)(cid:6)(cid:8)

(cid:4)(cid:0)(cid:1) (cid:8)(cid:1)(cid:1) (cid:12)(cid:31) (cid:0) (cid:2) (cid:0) (cid:21)(cid:1) (cid:8)(cid:6)(cid:2)(cid:4)’ $  (cid:4)(cid:15)(cid:4)(cid:15)(cid:8)(cid:15) (cid:6) (cid:1)

(cid:0)  & (cid:0)(cid:0)(cid:3) (cid:4) (cid:4) (cid:4) (cid:3) (cid:0) $ (cid:0)(cid:15)

)(cid:29)(cid:16)(cid:16) (cid:29)(cid:16) 	 (cid:4)  )(cid:8)(cid:10) (cid:12) (cid:8) *(cid:16) (cid:12)   (cid:8)(cid:15) (cid:16) (cid:30)(cid:12))
(cid:4) (cid:1) (cid:4) (cid:14)
(cid:0)  (cid:12)(cid:30) (cid:17) (cid:8) (cid:29)(cid:16) (cid:8)(cid:30)(cid:8)(cid:11)(cid:12) (cid:4)	(cid:11)(cid:8) (cid:4)
(cid:16)*(cid:16) !, (cid:20)(cid:12)#(cid:8)(cid:10)   *(cid:16)(cid:14) (cid:11) (cid:16)  5 (cid:8),(cid:16), (cid:12)#(cid:8)(cid:10) (cid:29)(cid:16)
(cid:30)(cid:16)(cid:16)(cid:30)(cid:16) (cid:30)(cid:8)(cid:8)(cid:15)	(cid:8) *(cid:16)(cid:14) 	 (cid:8)#(cid:16) (cid:14) (cid:8) (cid:29)(cid:16) (cid:8)-	(cid:16)
*(cid:16) (cid:29)(cid:16) (cid:29)(cid:16)(cid:16),

1-3 (cid:6)(cid:6)  (cid:17)(cid:13)(cid:6)(cid:6)(cid:13)(cid:6)(cid:26)(cid:6) (cid:6)
!(cid:16) *(cid:16) (cid:29)(cid:16) (cid:16)-(cid:8)(cid:16)(cid:11)(cid:16) (cid:4) (cid:12) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16) (cid:15)(cid:12)(cid:15)(cid:8) (cid:8)(cid:14) (cid:30)(cid:8)	
(cid:8)(cid:15)	(cid:8) (cid:4) )(cid:29)(cid:8)(cid:11)(cid:29) (cid:13)(cid:13) (cid:8) (cid:12)   (cid:15)	 )(cid:8)(cid:29) (cid:12)  (cid:12)(cid:10)(cid:16)
(cid:11)*(cid:12)(cid:8)(cid:12)(cid:11)(cid:16) (cid:15)(cid:16))(cid:16)(cid:16) (cid:11)(cid:16)(cid:12)(cid:8) (cid:4)	(cid:11)(cid:8) (cid:8) (cid:1) (cid:12)(cid:30) (cid:2)(cid:27) )(cid:16)
(cid:29)(cid:16) (cid:30)(cid:16)(cid:12)(cid:16) (cid:29)(cid:12) (cid:29)(cid:8) (cid:12)  (cid:29) (cid:30) (cid:4) (cid:29)(cid:16) (cid:13)(cid:13)
 (cid:12)(cid:30) (cid:23)A, (cid:26) (cid:29)	(cid:10)(cid:29) (cid:29)(cid:16) 	 (cid:12)(cid:8) (cid:13)(cid:13) (cid:8)
 /(cid:16) (cid:4) (cid:29)(cid:8) (cid:30)(cid:16)(cid:8)(cid:14) (cid:8) (cid:12)   (cid:8)/(cid:16) )(cid:8)   (cid:12)#(cid:16) (cid:29)(cid:8)
(cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:29)(cid:12)(cid:30)  (cid:30)(cid:16)(cid:16)(cid:11) 	 (cid:16) (cid:12)  (cid:12)(cid:10)(cid:16) (cid:30)(cid:12)(cid:12) (cid:12)	
 (cid:16) (cid:8) (cid:12)*(cid:12)(cid:8) (cid:12)(cid:15) (cid:16), !(cid:16) (cid:8)  	(cid:12)(cid:16) (cid:29)(cid:8) (cid:29)(cid:16)(cid:16) (cid:15)(cid:14)
(cid:16)(cid:11)(cid:8)(cid:4)(cid:14)(cid:8)(cid:10) (cid:12) (cid:12)(cid:8)(cid:11)	 (cid:12) 1(cid:8) (cid:30)(cid:16)(cid:8)(cid:14) (cid:3) (cid:0)(cid:0)(cid:1) )(cid:8)(cid:29) (cid:30)(cid:8)(cid:8)	
(cid:15)	(cid:8) (cid:0)(cid:0)(cid:1) (cid:11)(cid:29)(cid:16) 	(cid:11)(cid:29) (cid:29)(cid:12) (cid:11)* (cid:0)(cid:0)  (cid:1) (cid:8)  (cid:12)(cid:10)(cid:16)
(cid:4) (cid:16)  (cid:12)(cid:10)(cid:16)   (cid:16)(cid:12)(cid:8)(cid:10) (cid:0)(cid:0) (cid:1) (cid:29)(cid:12)*(cid:16) (cid:12) 	(cid:8)*(cid:8)(cid:12)  (cid:30)(cid:16)	
(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:15)	 (cid:13)(cid:13)(cid:0)(cid:0)(cid:1)(cid:27) (cid:7)(cid:0) (cid:8) (cid:8) (cid:12)  , (cid:20)(cid:29)(cid:16) (cid:8)		
(cid:8)(cid:8) (cid:15)(cid:16)(cid:29)(cid:8)(cid:30) 	 (cid:12)(cid:10)	(cid:16) (cid:8) (cid:12)(cid:30)(cid:16) (cid:11) (cid:16)(cid:12) (cid:15)(cid:14) (cid:16)	)(cid:8)(cid:8)(cid:10)
(cid:13)(cid:13) (cid:4) (cid:28) & (cid:12)

(cid:13)(cid:13) (cid:0)(cid:0)(cid:1)(cid:27) (cid:7)(cid:0) (cid:8) 9 	

(cid:1)(cid:3)(cid:6) (cid:0) (cid:3)(cid:3)(cid:11)

(cid:11)* (cid:1) (cid:0)(cid:0) (cid:2)(cid:1)

(cid:12)(cid:1)(cid:12)(cid:6) (cid:12)(cid:2)(cid:12)(cid:11)

(cid:3) :,5

(cid:20)(cid:29)(cid:8) )(cid:8)   (cid:15)*(cid:8)	 (cid:14) (cid:15)(cid:16) (cid:12)   )(cid:29)(cid:16) (cid:29)(cid:16) (cid:28) &  (cid:8)
(cid:29)(cid:16) (cid:30)(cid:16)(cid:8)(cid:12) (cid:12)(cid:16) 	(cid:11)(cid:29)  (cid:12)(cid:10)(cid:16) (cid:29)(cid:12) (cid:29)(cid:16) (cid:11)*(cid:12)(cid:8)(cid:12)(cid:11)(cid:16)
(cid:8) (cid:29)(cid:16) 	(cid:16)(cid:12)@ )(cid:16) )(cid:8)   (cid:16)(cid:16) (cid:29)(cid:12) (cid:29)(cid:8) (cid:8)*(cid:12)(cid:16) 	
(cid:11)(cid:29)(cid:8)(cid:11)(cid:16) (cid:4) (cid:30)(cid:16)(cid:8)(cid:14), (cid:16) (cid:16)(cid:11)(cid:8)=(cid:11)(cid:12)  (cid:14) (cid:29)(cid:8)(cid:10)(cid:29) (cid:30)(cid:16) (cid:16)(cid:8)(cid:10)(cid:16)	
(cid:4)	(cid:11)(cid:8) (cid:4) (cid:29)(cid:16) #(cid:16)(cid:16) (cid:13)  (cid:10) (cid:12)(cid:30)  (cid:11) (cid:4)  (cid:12)(cid:10)(cid:16)  
(cid:29)(cid:12)*(cid:16)  (cid:12)(cid:10)(cid:16) (cid:28) &  (cid:12) (cid:4)(cid:12)(cid:11) )(cid:8)(cid:30)(cid:16) (cid:14) (cid:16)- (cid:8)(cid:16)(cid:30) (cid:8)
(cid:16)(cid:10)(cid:16)(cid:8) (cid:12) (cid:12) 	(cid:10)(cid:29)(cid:16) (cid:16)(cid:12) (cid:14) 4857, (cid:20)(cid:29)	 (cid:8)(cid:4) (cid:29)(cid:16)
(cid:29)(cid:8)(cid:10)(cid:29) (cid:30)(cid:16) (cid:16)(cid:8)(cid:10)(cid:16)(cid:4)	(cid:11)(cid:8) (cid:12)(cid:16) (cid:8)(cid:16) (cid:8) (cid:3) (cid:0)(cid:0)(cid:1) (cid:8),(cid:16),
(cid:4) (cid:29)(cid:8)(cid:10)(cid:29) (cid:14) 	(cid:29) (cid:30)(cid:16)(cid:8)(cid:8)(cid:16) )(cid:16) (cid:16)-(cid:16)(cid:11) (cid:13)(cid:13)
 (cid:15)(cid:16) (cid:12)   (cid:16)*(cid:16) )(cid:29)(cid:16) (cid:29)(cid:16)(cid:16) (cid:16)-(cid:8) (cid:12)   (cid:4) )(cid:29)(cid:8)(cid:11)(cid:29)
(cid:11)* (cid:0)(cid:0)  (cid:1) (cid:8)  (cid:12)(cid:10)(cid:16),(cid:14)
.(cid:3)(cid:6)(cid:6) > ’(cid:6)(cid:6)(cid:13)(cid:6) (cid:12)(cid:13) (cid:18)(cid:12)(cid:17)(cid:12)(cid:25) (cid:6) (cid:26)(cid:12)
(cid:3)(cid:12)(cid:18)(cid:6) (cid:12)   ++- (cid:27)(cid:21)(cid:9)(cid:9) (cid:9)(cid:18)(cid:11) (cid:6) (cid:16)(cid:9)(cid:11)(cid:25) (cid:3) (cid:0)(cid:0)(cid:1)
(cid:23) (cid:28)(cid:21)(cid:11)(cid:22)(cid:21) (cid:11)*  (cid:0)(cid:0)  (cid:1) (cid:19) "   (cid:21) (cid:23) 	(cid:11)(cid:24)(cid:11)(cid:6) 
" (cid:6)(cid:16) (cid:6)(cid:10)(cid:11)(cid:6)(cid:11) (cid:25) (cid:6)   (cid:21) (cid:22) G (cid:25)(cid:9)
(cid:23) (cid:28)(cid:21)(cid:11)(cid:22)(cid:21)
(cid:13)(cid:13)(cid:0)(cid:0)(cid:1)(cid:27) (cid:7)(cid:0) (cid:8) (cid:23)   (cid:23) (cid:6) (cid:6)(cid:10)(cid:11)(cid:6)(cid:11) (cid:25) (cid:6)     (cid:22) G(cid:4)

(cid:23)(cid:4) (cid:20)(cid:29)(cid:16) (cid:4) (cid:8) (cid:12) #(cid:16)(cid:11)(cid:29)  (cid:14)@
(cid:4)	(cid:29)(cid:16) (cid:30)(cid:16)(cid:12)(cid:8)  (cid:8)
(cid:10)(cid:8)*(cid:16) (cid:8) 45G7, !(cid:16) (cid:15)(cid:16)(cid:10)(cid:8) (cid:15)(cid:14) (cid:11)	(cid:11)(cid:8)(cid:10) (cid:12) (cid:30)(cid:16)(cid:8)(cid:14) (cid:4)
)(cid:29)(cid:8)(cid:11)(cid:29) (cid:11)*  (cid:0)(cid:0)  (cid:1) (cid:19) "   (cid:21), (cid:20)(cid:29)(cid:8) (cid:8) )(cid:8)(cid:16)

(cid:3) (cid:0)(cid:0)(cid:1)(cid:10)(cid:0) (cid:11) 9 (cid:31)   " (cid:10) (cid:11)

:,8

)(cid:29)(cid:16)(cid:16) (cid:3) (cid:0)(cid:0)(cid:1)(cid:10)(cid:0) (cid:11) (cid:19) G (cid:12)(cid:30) (cid:15) (cid:3) (cid:0)(cid:0)(cid:1)(cid:10)(cid:0) (cid:11)(cid:25)(cid:10)(cid:25)(cid:11) 9 5, (cid:20)(cid:29)(cid:16)

= (cid:11)(cid:12)(cid:8) (cid:16)	(cid:8)(cid:16) (cid:31)    " (cid:8)(cid:8)(cid:0)(cid:18) (cid:10) (cid:11) (cid:19) G
(cid:5)((cid:1)(cid:1) (cid:28)(cid:21)(cid:1)(cid:1) ) $ (cid:6) (cid:8)(cid:1)*(cid:4)(cid:4) $ (cid:21)(cid:1) (cid:1)(cid:4)’(cid:1)$	(cid:22)(cid:4)(cid:15)
(cid:1) (cid:21)(cid:6) (cid:21)(cid:1) (cid:23)(cid:1)(cid:1)  (cid:4) (cid:0) (cid:6)(cid:8) (cid:1) (cid:6)(cid:31)  (cid:12)(cid:1) (cid:4)(cid:8)(cid:1)(cid:4)(cid:22)(cid:6) 
(cid:6)(cid:8) (cid:21)(cid:1) (cid:1)(cid:4)’(cid:1)$	(cid:22)(cid:4) (cid:1)(cid:6) (cid:6)(cid:8) (cid:2) (cid:7) (cid:4)’(cid:21) (cid:21)(cid:1)(cid:1)$(cid:1) (cid:12)(cid:1)
(cid:8)(cid:4)-(cid:1)(cid:1)(cid:15) (cid:0)(cid:1) 	(cid:1) (cid:21)(cid:1) (cid:1)(cid:7)	(cid:3) $ (cid:21)(cid:1) (cid:1)(cid:4)’(cid:1)$	(cid:22)(cid:4) 
(cid:8)(cid:4)(cid:4)’	(cid:4)(cid:21) (cid:12)(cid:1)(cid:2)(cid:1)(cid:1) (cid:21)(cid:1) (cid:4)(cid:22)(cid:1) (cid:21)(cid:4) (cid:4) 	(cid:6)(cid:12)(cid:4)’		 (cid:6)(cid:8)
(cid:6)(cid:11)(cid:4)(cid:8) (cid:1)(cid:31) (cid:6)(cid:4)(cid:15)

(cid:6)(cid:28)(cid:21)(cid:4) (cid:1)(cid:6)(cid:4)’ (cid:22)(cid:6) (cid:12)(cid:1) (cid:1)(cid:29)(cid:1)(cid:8)(cid:1)(cid:8)  (cid:4)(cid:11)(cid:6)(cid:1) (cid:23)(cid:1)(cid:1) 
(cid:22)(cid:21)(cid:4)(cid:22)(cid:1) $ (cid:21)(cid:1) (cid:8)(cid:1)(cid:1)(cid:22)(cid:4) $ (cid:6)(cid:4)(cid:22)	 (cid:6) (cid:8)(cid:1)(cid:1)(cid:8)(cid:1)(cid:22)(cid:4)(cid:1) (cid:6) 	
(cid:21)	’(cid:21) (cid:21)(cid:4) (cid:4) (cid:12)(cid:1)(cid:31)(cid:8) (cid:21)(cid:1) (cid:22)(cid:1) $ (cid:21)(cid:1) (cid:1)(cid:1) 	(cid:8)(cid:31)(cid:15) (cid:1)
(cid:6)  (cid:21)(cid:6) (cid:6) (cid:6) (cid:1)(cid:6)(cid:4)(cid:11)(cid:1) (cid:6)0(cid:1)	(cid:2)(cid:4)(cid:8)(cid:2) (cid:12)(cid:6)(cid:1)(cid:8) (cid:4)(cid:1)(cid:1)(cid:6)	
(cid:4) $ (cid:23)(cid:1)(cid:1)  (cid:22)(cid:21)(cid:4)(cid:22)(cid:1) (cid:4) ’(cid:4)(cid:11)(cid:1) (cid:4) (cid:17)(cid:18)(cid:19)(cid:15)

115)(cid:29)(cid:8)(cid:11)(cid:29) (cid:11)(cid:12) (cid:15)(cid:16) (cid:12)(cid:8)=(cid:16)(cid:30) (cid:12)  (cid:10) (cid:12) (cid:29)(cid:16)  (cid:10) (cid:12)(cid:30)  (cid:11)
(cid:12)(cid:16) (cid:12)(cid:15) 	(cid:16) (cid:14) (cid:15)	(cid:30)(cid:16)(cid:30),(cid:15) (cid:20)(cid:29)(cid:16) (cid:16)(cid:11)(cid:30) (cid:11)(cid:12)(cid:8) (cid:12)(cid:4)	
(cid:4)(cid:16)(cid:11) (cid:29)(cid:16) (cid:11)*(cid:12)(cid:8)(cid:12)(cid:11)(cid:16) (cid:15)(cid:16))(cid:16)(cid:16) #(cid:16)(cid:16)  (cid:16)(cid:8)(cid:10)(cid:16)(cid:4)	(cid:11)(cid:8)

@9 (cid:0)(cid:0)(cid:0)(cid:1)(cid:6)(cid:0)(cid:7) (cid:1)   (cid:0)(cid:0)(cid:6)(cid:0)(cid:0)(cid:1)(cid:7)(cid:1)(cid:3)

(cid:16)(cid:26)(cid:6)(cid:0)(cid:7) 9 (cid:11)*(cid:6)(cid:10)(cid:0) (cid:7) (cid:11)
(cid:30)(cid:16)(cid:16)(cid:30) (cid:29)(cid:8) (cid:11)(cid:12)(cid:8) (cid:11)(cid:12)	(cid:16) (cid:16)+  (cid:29)(cid:12)*(cid:16) (cid:18)(cid:0) #(cid:29) (cid:16)(cid:8)(cid:16)

:,:

:,6

(cid:16)(cid:26)(cid:6)(cid:12)(cid:6) (cid:0)(cid:7)(cid:12)(cid:6)  @9 (cid:21)(cid:6)(cid:7) (cid:0)

(cid:16)(cid:26) (cid:0)  @9 "  (cid:21)  (cid:0)

)(cid:29)(cid:16)(cid:16) (cid:21)(cid:6)(cid:7) (cid:30)(cid:16)(cid:16) (cid:12) 	(cid:12)(cid:8)(cid:14) )(cid:8)(cid:29) (cid:12)(cid:15) 	(cid:16) *(cid:12) 	(cid:16) (cid:12)	
(cid:15)(cid:8)(cid:12)(cid:8) (cid:14) (cid:12)   (cid:4)  (cid:12)(cid:10)(cid:16) (cid:16)	(cid:10)(cid:29)   (cid:29)(cid:16) (cid:4) (cid:16)	(cid:8)(cid:16)
(cid:16) (cid:16)(cid:30)(cid:8)	 (cid:12) (cid:10)(cid:16)(cid:15)(cid:12) (cid:15)	 (cid:8)  (cid:30)(cid:8)Æ(cid:11)	 @ (cid:12)(cid:15) (cid:14) (cid:8)
(cid:12)#(cid:16) 	(cid:16) (cid:4) (cid:29)(cid:16) (cid:30)(cid:16)(cid:11)(cid:12)(cid:14) (cid:16)	  (cid:8) (cid:16)(cid:12) :,

!(cid:16) (cid:16)- (cid:16)-(cid:12)(cid:30) (cid:29)(cid:16) (cid:4)	(cid:11)(cid:8) (cid:1) (cid:12)(cid:30) (cid:2) )(cid:29)(cid:8)(cid:11)(cid:29) (cid:30)(cid:16)	
=(cid:16) (cid:13)(cid:13) (cid:8),(cid:16),
(cid:16) (cid:16)(cid:16) (cid:4) (cid:29)(cid:16) (cid:16)(cid:16)(cid:11)(cid:8)*(cid:16) (cid:28) &
(cid:12) )(cid:29)(cid:8)(cid:11)(cid:29) (cid:29)(cid:16) 	(cid:16)	 (cid:8) (cid:12)(cid:12)(cid:8)(cid:16)(cid:30) (cid:12) (cid:1) (cid:10) 9

J(cid:1)(cid:6)(cid:6)(cid:10) (cid:12)(cid:30) (cid:2)(cid:11) 9 (cid:4)(cid:7)(cid:6)(cid:0) J(cid:2)(cid:7)(cid:7)(cid:11) (cid:29)(cid:16) (cid:16)-(cid:12)	

(cid:8) (cid:11)(cid:16)Æ(cid:11)(cid:8)(cid:16) (cid:12)(cid:16) )(cid:8)(cid:16) (cid:12) *(cid:16)(cid:11) J(cid:23) (cid:0) J(cid:29), (cid:31)	
(cid:8)(cid:10) (cid:29)(cid:16)(cid:16) (cid:16)-(cid:12)(cid:8) (cid:29)(cid:16) 	(cid:16)(cid:12) (cid:4) :,5 (cid:15)(cid:16)(cid:11)(cid:16)

(cid:4)(cid:6)(cid:6)(cid:0)
(cid:11)*(cid:1) (cid:10)(cid:0) (cid:2)(cid:11) 9 J(cid:23)(cid:13)(cid:16)+J(cid:29) (cid:12)(cid:30)
(cid:4)(cid:2)(cid:7)(cid:6)(cid:0)

J(cid:23)(cid:13)(cid:16)+J(cid:29) (cid:18)

(cid:14) J(cid:1)(cid:6)(cid:14)(cid:14)J(cid:2)(cid:7)(cid:14) (cid:21)  (cid:14) J(cid:1) (cid:14)(cid:14)J(cid:2) (cid:14) "

(cid:4)(cid:2)(cid:6)(cid:6)(cid:0)
9 (cid:12)J(cid:23)(cid:12)(cid:0) (cid:12)J(cid:29)(cid:12)(cid:0) (cid:21)  (cid:14) J(cid:1) (cid:14)(cid:14)J(cid:2) (cid:14) "(cid:0)

)(cid:29)(cid:16)(cid:16) )(cid:16) (cid:16) (cid:12)(cid:11)(cid:16) (cid:12)   (cid:16)(cid:8)(cid:16) (cid:8) (cid:16)+ )(cid:8)(cid:29) (cid:29)(cid:16)(cid:8) (cid:16)-(cid:16)(cid:8)
(cid:8) :,: (cid:12)(cid:30) (cid:21) (cid:8) (cid:29)(cid:16) (cid:21)(cid:6)(cid:7) )(cid:8)(cid:29)  (cid:12)(cid:10)(cid:16) (cid:12)(cid:15) 	(cid:16) *(cid:12) 	(cid:16),
(cid:16)(cid:12) : (cid:16)	(cid:16) (cid:29)(cid:12) (cid:12)J(cid:23)(cid:12)(cid:0) (cid:12)(cid:30) (cid:12)J(cid:29)(cid:12)(cid:0) (cid:15)(cid:29) (cid:11)*(cid:16)(cid:10)(cid:16),
 (cid:29)(cid:16) (cid:11)(cid:12)(cid:16) (cid:4) (cid:29)(cid:16) (cid:16)(cid:12)(cid:8)(cid:8)(cid:10) (cid:16) (cid:14) J(cid:1) (cid:14)(cid:14)J(cid:2) (cid:14) " )(cid:16) (cid:30)(cid:8)*(cid:8)(cid:30)(cid:16)
(cid:29)	(cid:10)(cid:29) (cid:15)(cid:14) (cid:29)(cid:16)  (cid:8) (cid:29)(cid:16) (cid:30)(cid:16)(cid:8)(cid:12) (cid:4) (cid:13)(cid:13) 
(cid:10)(cid:16)

(cid:14) J(cid:1) (cid:14)(cid:14)J(cid:2) (cid:14) "(cid:17)(cid:2)(cid:4)
(cid:18) "J(cid:12)(cid:1)

J(cid:12)(cid:3)
  (cid:0)

 

(cid:6)(cid:6)(cid:0)

J(cid:1) (cid:1)

(cid:6)(cid:8) (cid:0)(cid:18)  (cid:2)
(cid:6) (cid:7)J(cid:12)(cid:1)

(cid:3)(cid:17)(cid:2)(cid:4)

(cid:7)(cid:6)(cid:0)

J(cid:1) (cid:1)

(cid:3)

(cid:7)(cid:8) (cid:0)(cid:18)  (cid:2)
(cid:7) (cid:7)J(cid:12)(cid:3)

(cid:12)(cid:30) (cid:29)(cid:16) (cid:8)(cid:10)(cid:29) (cid:29)(cid:12)(cid:30) (cid:8)(cid:30)(cid:16) (cid:12)(cid:12)(cid:11)(cid:29)(cid:16) /(cid:16) (cid:12)   (cid:4) (cid:15)
(cid:29)(cid:12)#  (cid:20)(cid:29)(cid:16)(cid:16) 6,(cid:16)

(cid:13)(cid:13), (cid:20)(cid:29)(cid:16) (cid:13)(cid:13) (cid:8) (cid:30)(cid:16)=(cid:16)(cid:30) (cid:12)

(cid:19) (cid:0)(cid:0)(cid:1)(cid:27)(cid:1)(cid:0)(cid:2)
@9 	

(cid:1)(cid:3)(cid:6) (cid:0) (cid:3)(cid:3)(cid:11)

(cid:11)* (cid:1) (cid:0)(cid:0) (cid:2)(cid:1)

*(cid:12) (cid:1) (cid:0)  $(cid:12)(cid:1)(cid:12)(cid:1)
(cid:6) (cid:12)(cid:2)(cid:12) (cid:0)
(cid:11)

(cid:6)*(cid:12) (cid:2) (cid:1)  $(cid:12)(cid:2)(cid:12)(cid:1)

(cid:11)

(cid:11)* (cid:1)(cid:0)(cid:0) (cid:2)(cid:1)

(cid:18) $ (cid:0)(cid:12)(cid:1)(cid:12) (cid:0)
(cid:18) $ (cid:0)(cid:13)(cid:13) (cid:0)(cid:0)(cid:1)(cid:27) (cid:7)(cid:0) (cid:8) (cid:0)
)(cid:29)(cid:16)(cid:16) (cid:1)(cid:0) (cid:2) (cid:12)(cid:12)(cid:8) (cid:29)(cid:16) 	(cid:16)	 (cid:8) (cid:29)(cid:16) =  (cid:8)(cid:16) (cid:12)(cid:30)
)(cid:16) (cid:12)	(cid:16) (cid:1) (cid:12)(cid:30) (cid:2)  (cid:15)(cid:16) (cid:15)	(cid:30)(cid:16)(cid:30),

0(cid:8)(cid:12)  (cid:14) )(cid:16) (cid:30)(cid:16)(cid:12)(cid:16) (cid:29)(cid:12) (cid:29)(cid:16)  4;7 (cid:12)(cid:30) (cid:23)A
457 )(cid:29)(cid:8)(cid:11)(cid:29) (cid:12)(cid:16) (cid:16)(cid:16)(cid:11)(cid:8)*(cid:16) (cid:14) (cid:16)-(cid:16)(cid:8)  (cid:13)(cid:13) (cid:12)(cid:30)
(cid:29)(cid:16) (cid:13)(cid:13) (cid:29)(cid:12)*(cid:16) (cid:29)(cid:16) (cid:12)(cid:16) (cid:16)(cid:14), (cid:20)(cid:29)(cid:8) (cid:4)  ) (cid:8)(cid:11)(cid:16)
(cid:29)(cid:16)  (cid:11)(cid:12) (cid:15)(cid:16) )(cid:8)(cid:16) (cid:12)   (cid:0)
(cid:6) 
)(cid:29)(cid:16)(cid:16) (cid:14)%(cid:6)(cid:14) (cid:12)(cid:16) 	(cid:16) (cid:15)	(cid:30)(cid:16)(cid:30) (cid:15)(cid:14) (cid:13)(cid:13) (cid:12)(cid:30) (cid:29)(cid:16)
(cid:23)A (cid:12)   (cid:0)
(cid:6)  )(cid:29)(cid:16)(cid:16) (cid:29)(cid:16) (cid:14) (cid:6)(cid:14) (cid:12)(cid:16) 		
(cid:16) (cid:15)	(cid:30)(cid:16)(cid:30) (cid:15)(cid:14) (cid:29)(cid:16) (cid:13)(cid:13), &(cid:12)   (cid:13)(cid:13) )(cid:8)   (cid:29)(cid:16)(cid:16)	
(cid:4)(cid:16) (cid:11)(cid:12)	(cid:16) (cid:12)    (cid:12)(cid:30) (cid:12)   (cid:13)(cid:13) )(cid:8)   (cid:11)(cid:12)	(cid:16) (cid:12)  
(cid:23)A,

(cid:1)  (cid:10)	

(cid:1)  (cid:10)	

(cid:6)(cid:6)(cid:0)5   %(cid:1)

(cid:6)(cid:6)(cid:0)5    (cid:1)

(cid:28) (cid:18)	(cid:11)
!(cid:16) (cid:10)(cid:8)*(cid:16) ) (cid:11)*(cid:16)(cid:10)(cid:16)(cid:11)(cid:16) (cid:15)	(cid:30) (cid:8) (cid:29)(cid:8) (cid:16)(cid:11)(cid:8),
(cid:20)(cid:29)(cid:16) = (cid:12)(cid:30) (cid:8) (cid:16) (cid:10)	(cid:12)(cid:12)(cid:16)(cid:16) (cid:12)   	 (cid:12)(cid:8)
(cid:13)(cid:13) )(cid:29)(cid:16) (cid:29)(cid:16) (cid:16)(cid:8)(cid:8)(cid:11)(cid:12)  (cid:13)(cid:13) (cid:8) (cid:12)  (cid:27) (cid:29)(cid:16) (cid:16)(cid:11)(cid:30)
)(cid:29)(cid:8)(cid:11)(cid:29) (cid:29)(cid:12) (cid:12) (cid:16) (cid:8)* *(cid:16)(cid:30) (cid:30)(cid:16)(cid:8)*(cid:12)(cid:8) (cid:10)	(cid:12)(cid:12)(cid:16)(cid:16) (cid:29)(cid:12)
(cid:8)(cid:4) (cid:29)(cid:16) (cid:16)(cid:8)(cid:8)(cid:11)(cid:12)  (cid:13)(cid:13) (cid:8)  (cid:12)(cid:10)(cid:16) (cid:29)(cid:16) (cid:29)(cid:16) 	 (cid:12)(cid:8)
(cid:13)(cid:13) (cid:8) (cid:12)   (cid:12)(cid:10)(cid:16), (cid:20)(cid:29)(cid:16) (cid:4) (cid:12)(cid:16) (cid:10)(cid:8)*(cid:16) (cid:8) #(cid:16)(cid:11)(cid:29)
(cid:4)  (cid:14)(cid:27) (cid:8)(cid:10)	 (cid:30)(cid:16)(cid:8)*(cid:12)(cid:8) (cid:12)(cid:16) *(cid:8)(cid:30)(cid:16)(cid:30) (cid:8) 45G7,
(cid:26) (cid:11)(cid:16)	(cid:16)(cid:11)(cid:16) (cid:4) (cid:29)(cid:16)(cid:16) (cid:15)	(cid:30) (cid:8) (cid:29)(cid:12) (cid:29)(cid:16) (cid:16)(cid:8)(cid:8)(cid:11)(cid:12) 
(cid:13)(cid:13) (cid:11)*(cid:16)(cid:10)(cid:16)  (cid:29)(cid:16) 	 (cid:12)(cid:8) (cid:13)(cid:13) (cid:12) (cid:16)(cid:16)(cid:30)
5(cid:30), (cid:20)(cid:29)(cid:8) (cid:16)(cid:12) (cid:29)(cid:12) (cid:8)(cid:4) )(cid:16) (cid:30)(cid:16)=(cid:16) (cid:29)(cid:16) (cid:8)(cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16)
(cid:16) (cid:0) &(cid:16)(cid:11)(cid:8) :,5 (cid:12) (cid:29)(cid:16) (cid:8)(cid:30)(cid:8)(cid:11)(cid:12) (cid:29)(cid:12) (cid:13)(cid:13) (cid:8)

 (cid:12)(cid:10)(cid:16) (cid:29)(cid:12) (cid:12) (cid:16) (cid:4) (cid:29)(cid:16) (cid:4) (cid:26) (cid:10)5(cid:30)(cid:31)(cid:30) )(cid:8)(cid:29) (cid:26)

(cid:12) (cid:11)(cid:12) (cid:29)(cid:16) (cid:0) (cid:8) (cid:12) (cid:31)	(cid:16) )(cid:8)(cid:29) (cid:14)(cid:16)  (cid:16)
	(cid:16) (cid:15)	(cid:30)(cid:16)(cid:30) (cid:15)(cid:14) (cid:12) (cid:16) (cid:12)(cid:12)(cid:11)(cid:29)(cid:8)(cid:10) /(cid:16) (cid:12) 5(cid:30),
	 = (cid:15)	(cid:30) (cid:12)#(cid:16) 	(cid:16) (cid:4) (cid:29)(cid:16) (cid:4)  )(cid:8)(cid:10) (cid:29)(cid:16)(cid:16)
)(cid:29)(cid:8)(cid:11)(cid:29) (cid:12) (cid:8)(cid:16)  (cid:31)	(cid:12)(cid:8)(cid:8)(cid:11) (cid:4) (cid:29)(cid:16) #(cid:8)(cid:30) )(cid:16) (cid:16)(cid:11)	(cid:16)
(cid:8) (cid:11)(cid:12) (cid:11)	 (cid:12)(cid:8)(cid:10) (cid:11)*(cid:12)(cid:8)(cid:12)(cid:11)(cid:16),
.(cid:3)(cid:6)(cid:6) ? (cid:17)(cid:17)(cid:18)(cid:6) (cid:13)(cid:6)(cid:18)(cid:17)(cid:12)(cid:17) (cid:25)	(cid:13) (cid:23) (cid:6)
(cid:12) (cid:6) 9	(cid:12)(cid:17)(cid:17)(cid:26) 0)) - 382- .(cid:11)(cid:16)(cid:9) (cid:6) (cid:22) 	
 (cid:9)(cid:22)(cid:11) (cid:23)  (cid:11)(cid:4)(cid:11)(cid:4)(cid:16)(cid:4) (cid:6)(cid:16) (cid:24)(cid:6)(cid:11)(cid:6)(cid:10) (cid:9) (cid:2)(cid:0)(cid:0) (cid:3) (cid:3) (cid:3) (cid:0) (cid:2)(cid:4) ,(cid:9)
(cid:16)(cid:9)(cid:0)(cid:9) (cid:21)(cid:9) /	(cid:6)(cid:11)(cid:11)(cid:22)

5

   5 (cid:3) (cid:3) (cid:3)      5(cid:2)(cid:0)



’(cid:6)(cid:2)(cid:0)(cid:20)(cid:20)(cid:20)(cid:0)(cid:6) (cid:2)(cid:6)(cid:2) (cid:0) (cid:3) (cid:3) (cid:3) (cid:0) (cid:2)(cid:6) (cid:0)

(cid:28)(cid:21)(cid:9)(cid:9) (cid:21)(cid:9) (cid:11)(cid:16)(cid:9)(cid:18) (cid:9) (cid:17)
 (cid:11) (cid:21)(cid:9) (cid:9) (cid:23) (cid:6)   		 (cid:9) (cid:16)(cid:6)(cid:28)
(cid:28)(cid:11)(cid:21)	 (cid:9) (cid:6)(cid:22)(cid:9)(cid:9) (cid:23) (cid:16)5(cid:0) (cid:3) (cid:3) (cid:3) (cid:0) (cid:17) (cid:6)(cid:16) (cid:21)(cid:9) (cid:23)	(cid:22)(cid:11)
’ (cid:11) (cid:22)(cid:6)  (cid:9)(cid:16) (cid:21)(cid:9) #(cid:16)(cid:16)  (cid:23) (cid:21)(cid:9) /	(cid:6)(cid:11)(cid:11)(cid:22)(cid:4) (cid:23) ( (cid:18) ’ (cid:18) )

)   ((cid:1) (cid:18) (cid:3)
		   (cid:0)		 (cid:19)  (cid:18) (cid:16)-(cid:17) 8(cid:1)(cid:25)(cid:30)(cid:26)

!(cid:16) ) (cid:12)(cid:16) (cid:29)(cid:16) (cid:15)	(cid:30),
.(cid:3)(cid:6)(cid:6) )@ 9(cid:6) (cid:25)	(cid:13)  	 (cid:12)(cid:17)
++- (cid:17)	(cid:9) (cid:21)(cid:6) (cid:23)	(cid:22)(cid:11) (cid:11) (cid:7) (cid:6)(cid:16) (cid:8) (cid:6)(cid:9)

!(cid:16) ) (cid:12)(cid:30)(cid:30)(cid:16) (cid:29)) (cid:29)(cid:16) (cid:13)(cid:13) 457 (cid:29)(cid:12) (cid:29)(cid:16) (cid:12)(cid:16)  (cid:8)(cid:8)	
(cid:12)(cid:8) (cid:15)(cid:16)(cid:8)(cid:10) 	(cid:16) (cid:15)	(cid:30)(cid:16)(cid:30) (cid:15)(cid:14) (cid:12) (cid:11)(cid:12) 	 (cid:8) (cid:16) (cid:4)

	 @9

(cid:7)(cid:28)(cid:21)(cid:4) (cid:22)(cid:8)(cid:4)(cid:4) (cid:4)  (cid:6)(cid:4)*(cid:1)(cid:8) $ (cid:6)   (cid:1)(cid:22)(cid:1) (cid:23)(cid:1)(cid:1)  
(cid:1)(cid:1) (cid:17)#! 2(cid:29)(cid:1)(cid:22)(cid:4)(cid:1) #(cid:15)#"(cid:19)(cid:15) (cid:28)(cid:21)(cid:1) (cid:6)	(cid:4) (cid:21) (cid:8) (cid:4)  (cid:1)(cid:11)	
(cid:1)(cid:31)(cid:8)(cid:6)(cid:31) (cid:22)(cid:6)(cid:1) (cid:2)(cid:1) (cid:1)(cid:22)	(cid:1) (cid:1)(cid:15)’(cid:15) (cid:21)(cid:1) 3	(cid:4)(cid:1) (cid:12)(cid:6)(cid:4) (cid:21)(cid:2)	
(cid:1)(cid:11)(cid:1)  (cid:4) (cid:4) (cid:1)(cid:6)(cid:6)(cid:12) (cid:1) (cid:4) (cid:21)(cid:4) (cid:22)(cid:1)(cid:29)(cid:15)

(cid:1) (cid:6)(cid:8) 7(cid:8)(cid:3)

(cid:8) (cid:21)(cid:1) (cid:12)(cid:6)(cid:4) $ (cid:21)(cid:4) $ (cid:2)(cid:1) (cid:4)’(cid:21) 	(cid:1) (cid:21)(cid:6) 	(cid:4)’
(cid:6) 563 (cid:23)(cid:1)(cid:1)  (cid:2)(cid:4)(cid:21) (cid:6)   (cid:2)(cid:4)(cid:8)(cid:21) (cid:6)(cid:8) (cid:21)	 (cid:2)(cid:4)(cid:21) (cid:6)  (cid:2)
(cid:8)(cid:1)(cid:22)(cid:6)(cid:31) $ (cid:21)(cid:1) (cid:22)(cid:1)Æ(cid:22)(cid:4)(cid:1) 7(cid:8)(cid:3)
(cid:2)  (cid:2)	 (cid:8) (cid:6)(cid:23)(cid:1) (cid:26)(cid:26)
 (cid:6)’(cid:1) (cid:2)(cid:21)(cid:1) (cid:8)(cid:1)(cid:1)(cid:8)(cid:1)(cid:22)(cid:1) (cid:6)(cid:23)(cid:1) (cid:21)(cid:1) $ "(cid:15)# (cid:6)(cid:12)(cid:11)(cid:1) (cid:2)(cid:4)(cid:21)
(cid:21)(cid:4)’(cid:21) (cid:8)(cid:1) (cid:1)(cid:4)’(cid:1)$	(cid:22)(cid:4)  (cid:6)(cid:3)  (cid:7)(cid:15) (cid:0)(cid:21)(cid:4) (cid:1) (cid:21)(cid:4) (cid:4) 	(cid:1)
(cid:21)(cid:1) (cid:1)(cid:4)(cid:4)(cid:22)(cid:6)  (cid:1)(cid:4)(cid:6)(cid:1) $ (cid:26)(cid:26) (cid:2)(cid:4)   (cid:12)(cid:1)(cid:22)(cid:1) (cid:4)(cid:6)(cid:22)(cid:22)	(cid:6)(cid:1)
(cid:4)$ (cid:21)(cid:1) (cid:6)(cid:22)(cid:4)’ (cid:12)(cid:1)(cid:2)(cid:1)(cid:1) (cid:6) (cid:1) (cid:4)’(cid:4)*(cid:22)(cid:6) (cid:31) (cid:1)(cid:29)(cid:22)(cid:1)(cid:1)(cid:8) (cid:21)(cid:1)
(cid:23)(cid:1)(cid:1)  (cid:2)(cid:4)(cid:8)(cid:21)  (cid:21)	 (cid:21)(cid:1)(cid:1) (cid:4) (cid:6) (cid:6)(cid:22)(cid:4)(cid:22)(cid:6)   (cid:4)(cid:4)  (cid:21)(cid:2) (cid:6)  
(cid:2)(cid:1) (cid:22)(cid:6) (cid:6)(cid:23)(cid:1) (cid:21)(cid:1) (cid:23)(cid:1)(cid:1) (cid:15)

116(cid:20)(cid:29)(cid:16) = (cid:16) (cid:8) (cid:15)	(cid:30)(cid:16)(cid:30) 	(cid:8)(cid:10) (cid:11).(cid:8)(cid:12)(cid:8)(cid:30) 45E7 (cid:12)(cid:30)
(cid:14)(cid:16)(cid:8)(cid:12)(cid:8) (cid:8) (cid:29)(cid:16) 		(cid:12)  )(cid:12)(cid:14),  (cid:29)(cid:16) (cid:11)(cid:12)(cid:16) (cid:4) (cid:29)(cid:16)
(cid:16)(cid:11)(cid:30) (cid:16) )(cid:16) (cid:15)(cid:16)(cid:10)(cid:8) )(cid:8)(cid:29) (cid:11).(cid:8)(cid:12)(cid:8)(cid:30)  (cid:10)(cid:16)

(cid:0)(cid:0)(cid:1)(cid:23)(cid:24) 	
(cid:1)(cid:3)(cid:2)(cid:0)(cid:3)(cid:3)(cid:4)(cid:23)(cid:24) 5
   5(cid:2)(cid:6)(cid:12)(cid:6)(cid:7)
(cid:1)(cid:3)(cid:2)(cid:0)(cid:3)(cid:3)(cid:4)(cid:0)(cid:1)
   5(cid:2)(cid:6)(cid:12)(cid:6)(cid:7)

(cid:0)(cid:0)(cid:0)(cid:1)

	

5

(cid:1)(cid:6)(cid:2)(cid:7)   (cid:0)(cid:0)(cid:1) (cid:0)(cid:1)(cid:2)(cid:25)(cid:26) (cid:19)
(cid:25)     (cid:26)
(cid:1)(cid:6)(cid:2)(cid:7)   (cid:0)(cid:0)(cid:1) (cid:0)(cid:1)(cid:2)(cid:3)(cid:4)
(cid:31)

 

(cid:15)

(cid:29)(cid:30)

(cid:28)

 (cid:3)

(cid:4)

(cid:3)

(cid:18) +

!(cid:16) (cid:11)(cid:12) (cid:14)(cid:16)(cid:8)(cid:16) (cid:29)(cid:8) (cid:16)-(cid:16)(cid:8) (cid:30)(cid:8)(cid:16)(cid:11) (cid:14)@
(cid:8)	
(cid:16)(cid:12)(cid:30) )(cid:16) = (cid:12) (cid:14) (cid:29)(cid:16)  (cid:16)3(cid:30)(cid:8)(cid:10) (cid:30)(cid:16)(cid:11)(cid:8)(cid:8) (cid:12)(cid:30)
(cid:29)(cid:16) (cid:30)(cid:16)(cid:11)	 (cid:16) (cid:4)  )(cid:8)(cid:10) 4>7, (cid:20)(cid:29)(cid:8) (cid:14)(cid:8)(cid:16) (cid:30) (cid:12) 	(cid:16)
(cid:15)	(cid:30)  (cid:29)(cid:16) (cid:16)-(cid:16)(cid:11)(cid:12)(cid:8) (cid:12) (cid:29)(cid:12) )(cid:16) (cid:11)(cid:12) (cid:14)(cid:16)(cid:8)(cid:16),
!(cid:16) (cid:30)  (cid:10) (cid:8) (cid:30)(cid:16)(cid:12)(cid:8)  (cid:15)	 (cid:29)(cid:16) (cid:8)(cid:30)(cid:16)(cid:12) (cid:8)  (cid:16) (cid:12)(cid:11)(cid:16)
(cid:11)(cid:16)(cid:12)(cid:8) (cid:4) (cid:29)(cid:16) (cid:12)(cid:30) *(cid:12)(cid:8)(cid:12)(cid:15) (cid:16) (cid:15)(cid:14) (cid:8)(cid:30)(cid:16)(cid:16)(cid:30)(cid:16) (cid:11)(cid:8)(cid:16),
(cid:26)(cid:4)(cid:16) (cid:30)(cid:16)(cid:11)	 (cid:8)(cid:10) (cid:12)(cid:30) (cid:14)(cid:16)(cid:8)(cid:12)(cid:8) )(cid:16) (cid:15)(cid:12)(cid:8)

(cid:12) (cid:18) 68 (cid:0) 	

5

(cid:1)(cid:0)(cid:3) (cid:21)

(cid:6)(cid:6)(cid:6)(cid:7)(cid:7)(cid:17)(cid:1) (cid:0)(cid:6)(cid:2)(cid:1)(cid:7)(cid:7)
 (cid:1) (cid:0)(cid:6)(cid:2)(cid:1)(cid:7)(cid:7)(cid:7)    (cid:1) (cid:0)(cid:7)(cid:7)(cid:6) (cid:2)(cid:1)(cid:7)(cid:7)  (cid:1) (cid:0)(cid:7)(cid:6)(cid:2)(cid:1)(cid:7)(cid:7)(cid:7) (cid:18)(cid:22)

   5

(cid:2)(cid:6)(cid:6)(cid:0)

(cid:2)(cid:6)(cid:12)(cid:6)(cid:7)



:


(cid:0) 	
(cid:1)(cid:0)(cid:3)

(cid:2)(cid:6)(cid:6)(cid:0)

(cid:6)(cid:6)(cid:1) (cid:0)(cid:6)(cid:2)(cid:1)(cid:7)(cid:6) 9 )(cid:0)

)(cid:29)(cid:16)(cid:16) (cid:29)(cid:16) (cid:6)(cid:6) (cid:12)(cid:16) (cid:28)(cid:12)(cid:30)(cid:16)(cid:12)(cid:11)(cid:29)(cid:16) (cid:12)(cid:30) *(cid:12)(cid:8)(cid:12)(cid:15) (cid:16) (cid:29)(cid:12)
(cid:12)#(cid:16) *(cid:12) 	(cid:16) (cid:8) (cid:16) 5(cid:0) 5(cid:17) )(cid:8)(cid:29) (cid:16)	(cid:12)  (cid:15)(cid:12)(cid:15)(cid:8) (cid:8)(cid:14) (cid:6)(cid:7)(cid:6) (cid:12)(cid:16)
(cid:8)(cid:30)(cid:16)(cid:16)(cid:30)(cid:16) (cid:11)(cid:8)(cid:16) (cid:4) (cid:6)(cid:6) (cid:0)(cid:7)(cid:6) (cid:0)(cid:7)(cid:7)(cid:6) (cid:12)(cid:16) (cid:8)(cid:30)(cid:16)(cid:16)(cid:30)(cid:16) (cid:11)(cid:8)(cid:16)
(cid:4) (cid:0)(cid:6) (cid:12)(cid:30) (cid:1)(cid:7)(cid:6) (cid:1)(cid:7)(cid:7)(cid:6) (cid:12)(cid:16) (cid:8)(cid:30)(cid:16)(cid:16)(cid:30)(cid:16) (cid:11)(cid:8)(cid:16) (cid:4) (cid:1)(cid:6), (cid:20) (cid:11)	
(cid:11) 	(cid:30)(cid:16) (cid:29)(cid:16) (cid:4) (cid:8) 	 	 (cid:29)(cid:12) )(cid:16) (cid:30)  (cid:16)(cid:16)(cid:30) 
(cid:16)- (cid:8)(cid:11)(cid:8) (cid:14) (cid:30)(cid:16)(cid:12)  )(cid:8)(cid:29) (cid:29)(cid:16)(cid:16) (cid:12)(cid:30)(cid:30)(cid:8)(cid:8)(cid:12)  (cid:11)(cid:8)(cid:16)@
(cid:8)(cid:16)(cid:12)(cid:30)
)(cid:16) (cid:12) (cid:14) (cid:12) (cid:8) (cid:16) (cid:12)(cid:30)(cid:30)(cid:8)(cid:8)(cid:12)  (cid:15)	(cid:30) (cid:16)(cid:16) 45G7  (cid:10)(cid:16)

	

(cid:10)	(cid:16)(cid:9)(cid:16) (cid:6)(cid:4)(cid:4) (cid:10)(cid:25) 5(cid:4) (cid:27)(cid:21)(cid:9) (cid:23)  (cid:22) 5 (cid:6)(cid:16) (cid:6)   Æ (cid:22) G
(cid:28)(cid:11)(cid:21) (cid:10)(cid:6)(cid:10)(cid:11) (cid:11)(cid:25) (cid:6)  (cid:9)(cid:6) 5   Æ
(cid:11)*(cid:1) (cid:0)(cid:0) (cid:2)(cid:1) (cid:18) 	

(cid:1)(cid:3)(cid:2)(cid:0)(cid:3)(cid:3)(cid:4)(cid:20)(cid:11)*(cid:1) (cid:10)(cid:0) (cid:2)(cid:11)  (cid:3)
(cid:1) (cid:0)(cid:3)  (cid:6)(cid:16) (cid:28)(cid:9) (cid:16)(cid:9)(cid:9) (cid:21)(cid:9) (cid:9)(cid:11)(cid:11)(cid:22)(cid:6) 

(cid:1)(cid:3)(cid:2)(cid:0)(cid:3)(cid:3)(cid:4)

(cid:22)(cid:24)(cid:6)(cid:11)(cid:6)(cid:22)(cid:9) (cid:10)(cid:6)(cid:9)(cid:16)  (cid:21)(cid:9) (cid:6) (cid:9) (cid:0) (cid:6)

(cid:28)(cid:21)(cid:9)(cid:9)  9  (cid:1)  (cid:19)(cid:1)(cid:22)Æ
(cid:20)(cid:11)*(cid:1) (cid:10)(cid:0) (cid:2)(cid:11) @9

(cid:28)(cid:21)(cid:9)(cid:9) (cid:1)(cid:6) @9 (cid:1) (cid:10)(cid:6) (cid:6)(cid:16) (cid:2)(cid:7) @9 (cid:2)(cid:11)(cid:7)(cid:4)

5

   5(cid:2)(cid:6)(cid:12)(cid:6)(cid:7)

(cid:1)(cid:6)(cid:2)(cid:7)  

5


(cid:2)(cid:6)(cid:6)(cid:0)

(cid:1)(cid:6)(cid:2)(cid:6)(cid:0)

(cid:23)(cid:4) 0(cid:8) )(cid:16) (cid:16)(cid:12)(cid:12)(cid:10)(cid:16)

	

(cid:1)(cid:3)(cid:2)(cid:0)(cid:3)(cid:3)(cid:4)

(cid:11)*(cid:1) (cid:0)(cid:0) (cid:2)(cid:1)   	
	

(cid:1)(cid:3)(cid:2)(cid:0)(cid:3)(cid:3)(cid:4)(cid:20)(cid:11)*(cid:1) (cid:10)(cid:0) (cid:2)(cid:11) (cid:18)
(cid:11)*(cid:1) (cid:0)(cid:0) (cid:2)(cid:1)  (cid:20)(cid:11)*(cid:1) (cid:10)(cid:0) (cid:2)(cid:11) (cid:3)

(cid:1)(cid:3)(cid:2)(cid:0)(cid:3)(cid:3)(cid:4)

!(cid:16) (cid:11)(cid:12) (cid:29)(cid:16)(cid:16)(cid:4)(cid:16) (cid:8)(cid:10)(cid:16) (cid:29)(cid:16) 	(cid:16)(cid:12) (cid:12)(cid:30) (cid:16)(cid:12)  (cid:14)
(cid:29)(cid:16) (cid:12)(cid:30) *(cid:12)(cid:8)(cid:12)(cid:15) (cid:16) (cid:4) @9 (cid:1) (cid:0) (cid:12)(cid:30) (cid:5) @9 (cid:2)(cid:1), (cid:20)
(cid:11) (cid:16)(cid:16) (cid:29)(cid:16) (cid:15)	(cid:30) )(cid:16) (cid:12)#(cid:16) (cid:29)(cid:16)  (cid:8)

5


(cid:3) (cid:0)(cid:4) (cid:11)*(cid:4)(cid:0) (cid:5)  (cid:20)(cid:11)*(cid:1)(cid:0) (cid:2) (cid:19)  (cid:18)
(cid:3) (cid:0)(cid:4)(cid:21) 
(cid:4)(cid:6)(cid:5)(cid:6)  (cid:0)(cid:3)(cid:0)(cid:4)(cid:4)(cid:5) (cid:19) 5   (cid:31)(cid:22) 
(cid:2)(cid:6)(cid:6)(cid:0)
(cid:3) (cid:0)(cid:4)(cid:23)(cid:24) 5
(cid:4)(cid:6)(cid:5)(cid:7)   (cid:0)(cid:3)(cid:4)(cid:0)(cid:4)(cid:5) (cid:19) (cid:31)(cid:25)(cid:26)
   5(cid:2)(cid:6)(cid:12)(cid:6)(cid:7)

(cid:20)(cid:29)(cid:16) = (cid:16) (cid:8) (cid:15)	(cid:30)(cid:16)(cid:30) (cid:12)(cid:8)(cid:10)(cid:29)(cid:4))(cid:12)(cid:30) (cid:14) 	(cid:8)(cid:10)  	
(cid:16)3(cid:30)(cid:8)(cid:10) (cid:8)(cid:16)	(cid:12) (cid:8)(cid:14) 4557, (cid:20) (cid:15)	(cid:30) (cid:29)(cid:16) (cid:16)(cid:11)(cid:30) (cid:16)
(cid:8) (cid:29)(cid:16) 	 )(cid:16) (cid:30)(cid:16)=(cid:16) (cid:29)(cid:16) (cid:12)(cid:30) *(cid:16)(cid:11) (cid:2)(cid:6) @9 (cid:4)(cid:6)(cid:0) (cid:5)(cid:6)
(cid:12)(cid:30) (cid:29)(cid:16) #(cid:16)(cid:16)  ’(cid:6)(cid:0)(cid:7)(cid:2)(cid:6)(cid:0) (cid:2)(cid:7) @9 (cid:4)(cid:6)(cid:5)(cid:7),  (cid:8) (cid:11) (cid:16)(cid:12) (cid:29)(cid:12) (cid:20)(cid:29)(cid:16)	
(cid:16) ; (cid:29)(cid:16) (cid:12) (cid:8)(cid:16), !(cid:16) (cid:11) (cid:16)(cid:16) (cid:29)(cid:16) (cid:4) (cid:15)(cid:14) (cid:16)(cid:8)(cid:10)

(cid:31) 9 8   8,

(cid:26)  )(cid:16) (cid:15)	(cid:30)  (cid:29)(cid:16) 	 (cid:12)(cid:8) (cid:13)(cid:13) (cid:8) (cid:29)(cid:12)(cid:30)(cid:16) 
(cid:11)	(cid:16) (cid:8)(cid:11)(cid:16) )(cid:16) (cid:29)(cid:12)*(cid:16)  (cid:30)(cid:16)(cid:12)  )(cid:8)(cid:29) (cid:29)(cid:16) 	(cid:16)(cid:12),
.(cid:3)(cid:6)(cid:6) )) A(cid:6) (cid:25)	(cid:13)  	 (cid:12)(cid:17)
++- (cid:17)	(cid:9) (cid:23)	(cid:22)(cid:11) (cid:11) (cid:7) (cid:6)(cid:16) (cid:8) (cid:6)(cid:9) (cid:10)	(cid:16)(cid:9)(cid:16)
(cid:6)(cid:4)(cid:4) (cid:10)(cid:25) 5 (cid:6)(cid:16) (cid:21)(cid:6) (cid:21)(cid:9) (cid:23)	(cid:22)(cid:11) (cid:12)(cid:1) (cid:10)(cid:0) (cid:10) (cid:18) 5 (cid:6)(cid:16)
(cid:12)(cid:3)(cid:11)(cid:0) (cid:11) (cid:18) 5 (cid:23) (cid:6)   (cid:10) (cid:0) (cid:9) (cid:6)(cid:16) (cid:11) (cid:0) (cid:11)(cid:4) (cid:27)(cid:21)(cid:9) (cid:23)  (cid:22) 5
(cid:6)(cid:16) (cid:6)   Æ (cid:22) G (cid:28)(cid:11)(cid:21) (cid:10)(cid:6)(cid:10)(cid:11) (cid:11)(cid:25) (cid:6)  (cid:9)(cid:6) 5   Æ
56:


(cid:11)*(cid:1)(cid:0) (cid:2) 

	

(cid:1)(cid:3)(cid:2)(cid:0)(cid:3)(cid:3)(cid:4)(cid:20)(cid:11)*(cid:1)(cid:0) (cid:2) (cid:18) 	

(cid:1)(cid:3)(cid:2)(cid:0)(cid:3)(cid:3)(cid:4)

(cid:23)(cid:4) !(cid:16) (cid:15)(cid:16)(cid:10)(cid:8) )(cid:8)(cid:29) (cid:12) (cid:16)(cid:12)(cid:12)(cid:10)(cid:16)(cid:16) (cid:4) (cid:29)(cid:16) 	(cid:16)(cid:12)(cid:27)

 5E  (cid:10) 8(cid:30)Æ



(cid:18)

	

	

(cid:11)*(cid:0)(cid:0)(cid:1)(cid:1) (cid:0)(cid:0) (cid:2)(cid:1)

(cid:1)(cid:3)(cid:2)(cid:0)(cid:3)(cid:3)(cid:4)
5


(cid:1)(cid:3)(cid:2)(cid:0)(cid:3)(cid:3)(cid:4)(cid:20)(cid:11)*(cid:1) (cid:10)(cid:0) (cid:2)(cid:11)   	
(cid:1)(cid:3)(cid:2)(cid:0)(cid:3)(cid:3)(cid:4)(cid:21)(cid:0)(cid:0)(cid:0)(cid:1)(cid:1) (cid:0)(cid:2)(cid:1)  
(cid:2)(cid:6)(cid:6)(cid:0)
(cid:1) (cid:10)(cid:6)(cid:2)(cid:11)(cid:7)   (cid:0)(cid:0)(cid:1) (cid:0)(cid:0)(cid:1)(cid:2)(cid:1)(cid:25)(cid:26) (cid:3)
(cid:1)(cid:3)(cid:2)(cid:0)(cid:3)(cid:3)(cid:4)(cid:23)(cid:24) 5
   5(cid:2)(cid:6)(cid:12)(cid:6)(cid:7)

(cid:1) (cid:10)(cid:6)(cid:2)(cid:11)(cid:6)(cid:22) 

	

) (cid:18)



:


(cid:3)

   5

58E

(cid:0)(cid:0)(cid:0)(cid:1)(cid:2)(cid:6)(cid:12)(cid:6)(cid:7)
(cid:0)(cid:0)(cid:0)(cid:1)(cid:2) "		
(cid:2)(cid:6)(cid:6)(cid:0)

(cid:12)(cid:1) (cid:0)(cid:6)(cid:0) (cid:0)(cid:6)(cid:12)(cid:3)(cid:1)(cid:6)(cid:0) (cid:1)(cid:6)

(cid:12)(cid:1) (cid:0)(cid:6)(cid:0) (cid:0)(cid:6)(cid:12)(cid:3)(cid:1)(cid:7)(cid:6)(cid:0) (cid:1)(cid:7)(cid:6)(cid:0)

(cid:12)(cid:30) (cid:29)(cid:16) 	(cid:15)(cid:8)	(cid:16) (cid:12)(cid:1) (cid:10)(cid:0) (cid:10) (cid:18) 5 (cid:12)(cid:30) (cid:12)(cid:3)(cid:11)(cid:0) (cid:11) (cid:18) 5,
(cid:29) (cid:30)(cid:31)(cid:16)(cid:13)(cid:16) (cid:5)(cid:11) (cid:11)(cid:13)(cid:6)	(cid:13)
!(cid:16) (cid:16)*(cid:8)	 (cid:14) (cid:12) (cid:8)(cid:16)(cid:30) (cid:13)(cid:13) (cid:8) (cid:29)(cid:16) (cid:11)(cid:16)- (cid:4) (cid:8)(cid:30)(cid:16)	
(cid:16)(cid:30)(cid:16) (cid:11)(cid:16) (cid:12)(cid:12) (cid:14)(cid:8) (cid:13)(cid:26) 4;7 )(cid:29)(cid:16)(cid:16) (cid:8) (cid:16)	
(cid:4)(cid:16)(cid:30) (cid:8)(cid:8) (cid:12) (cid:14)  (cid:29)(cid:16) #(cid:16)(cid:16)  (cid:11)(cid:12)(cid:8)(cid:11)(cid:12)  (cid:11)(cid:16) (cid:12)(cid:8) 457,
(cid:20)(cid:29)	 (cid:13)(cid:13) (cid:29)(cid:12) (cid:15)(cid:16)(cid:16) (cid:16)(cid:12)(cid:15) (cid:8)(cid:29)(cid:16)(cid:30) (cid:8) (cid:12)(cid:11)(cid:8)(cid:11)(cid:16) (cid:12) (cid:12)
	(cid:16)(cid:4)	  (cid:16) (cid:4) (cid:11)(cid:16)(cid:9)(cid:9)(cid:16)(cid:9)(cid:22)(cid:9),  (cid:29)(cid:16) (cid:16)(cid:16) 	(cid:30)(cid:14) )(cid:16)
(cid:10)(cid:8)*(cid:16) (cid:16) (cid:8)(cid:8)(cid:12)(cid:14) (cid:16)	  (cid:15)(cid:12)(cid:8)(cid:16)(cid:30) )(cid:29)(cid:16) 	(cid:8)(cid:10) (cid:13)(cid:13)
 (cid:30)(cid:16)(cid:16)(cid:8)(cid:16) (cid:16)(cid:10)(cid:8) (cid:29)(cid:12) (cid:29)) (cid:21)(cid:11)(cid:13)(cid:21) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:8)

117(cid:29)(cid:16) (cid:12)(cid:11)(cid:12)	(cid:16) (cid:8)(cid:12)(cid:14) *(cid:8)	(cid:12)  (cid:11)(cid:16)-, !(cid:16) (cid:12)(cid:16) (cid:12)(cid:15) (cid:16) 
(cid:8) (cid:16)	(cid:12)  (cid:12)(cid:11)(cid:8)*(cid:8)(cid:14) (cid:8) (cid:29)(cid:16)(cid:16) (cid:30)(cid:8)3(cid:16)(cid:16) )(cid:12)(cid:14)@ (cid:12)
(cid:16) (cid:16)(cid:11)(cid:29)(cid:14)(cid:8) (cid:10)(cid:14)  (cid:14) )(cid:8)(cid:29)  (cid:12)(cid:10)(cid:16) (cid:16) (cid:16)(cid:11)(cid:30)(cid:16) (cid:12)(cid:12)(cid:14) (cid:15)
(cid:4)(cid:28)  (cid:14) (cid:12)(cid:30) (cid:11) (cid:11)(cid:15)(cid:8)(cid:16)(cid:30) (cid:16) (cid:16)(cid:11)(cid:30)(cid:16) (cid:12)(cid:30) (cid:4)(cid:28) (cid:16)(cid:12)	
	(cid:16)(cid:16), (cid:20)(cid:29)(cid:16) (cid:16)(cid:16) (cid:16)(cid:11)(cid:8) (cid:30)(cid:16)(cid:12)   (cid:14) )(cid:8)(cid:29) (cid:30)(cid:16)	
(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:16)(cid:12)	(cid:16)  (cid:29)(cid:16) (cid:4)(cid:28) (cid:8)(cid:10)(cid:12)  (cid:15)	 )(cid:16) (cid:12)(cid:16)
(cid:11)	(cid:16) (cid:14) (cid:16)-(cid:12)(cid:30)(cid:8)(cid:10) (cid:29)(cid:8) (cid:12)(cid:12) (cid:14)(cid:8)  (cid:11)*(cid:16) (cid:12) (cid:15)(cid:12)(cid:30)(cid:16)
(cid:12)(cid:10)(cid:16) (cid:4) (cid:12)(cid:11)	(cid:8)(cid:8)(cid:8) (cid:16)(cid:11)(cid:29)(cid:8)	(cid:16) 45C7  (cid:12)  (cid:11)	
(cid:12)(cid:16) (cid:29)(cid:16) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:4)	(cid:30) (cid:4) (cid:29)(cid:16)(cid:16) (cid:30)(cid:8)3(cid:16)(cid:16) (cid:14)(cid:16)
(cid:4) (cid:16)(cid:12)	(cid:16)(cid:16), 	 (cid:4)(cid:28) (cid:16)(cid:12)(cid:30)(cid:8)(cid:10) )(cid:16)(cid:16) (cid:12)#(cid:16) 		
(cid:8)(cid:10) (cid:12) :,C(cid:20) (cid:11)(cid:12)(cid:16) )(cid:8)(cid:29) (cid:12) (cid:12) (cid:8)(cid:10) (cid:4)(cid:16)	(cid:16)(cid:11)(cid:14) (cid:4) : /
(cid:12)(cid:30) (cid:12) ;B-;B =(cid:16) (cid:30) (cid:4) *(cid:8)(cid:16)) 0A )(cid:8)(cid:29) (cid:16) 		
(cid:8) 8>B-8>B (cid:12)(cid:30) G,>  (cid:8)(cid:11)(cid:16) (cid:29)(cid:8)(cid:11)#(cid:16) (cid:8) (cid:12)(cid:11)(cid:11)(cid:30)(cid:12)(cid:11)(cid:16)
)(cid:8)(cid:29) (cid:29)(cid:16) (cid:11)(cid:16)(cid:30)	(cid:16) (cid:8) 45B7, (cid:20)(cid:29)(cid:16) (cid:8)	 	 	(cid:16)(cid:30) )(cid:12) (cid:12)
(cid:11) (cid:8) (cid:4) N&(cid:12) !(cid:12)O )(cid:29)(cid:8)(cid:11)(cid:29) )(cid:12) (cid:11)(cid:29)(cid:16)  (cid:12)  (cid:16)-	
(cid:11)(cid:8)(cid:16) (cid:12) (cid:15)(cid:12)(cid:30) (cid:12)(cid:10)(cid:16) (cid:4) (cid:12)(cid:11)(cid:8)*(cid:8)(cid:14) )(cid:8)(cid:29)(cid:8) (cid:29)(cid:16) *(cid:8)	(cid:12)  (cid:11)(cid:16)-,
.(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) )(cid:12) (cid:8)*(cid:16)(cid:8)(cid:10)(cid:12)(cid:16)(cid:30) (cid:4) *-(cid:16)  (cid:8) (cid:29)(cid:16) (cid:8)(cid:12)(cid:14)
*(cid:8)	(cid:12)  (cid:12)(cid:16)(cid:12) A5 (cid:4) (cid:12) (cid:12)  (cid:4) 8>G *-(cid:16)  (cid:12)(cid:30) (cid:29)(cid:16) (cid:8)(cid:10)	
(cid:12)  (cid:30)	(cid:12)(cid:8) (cid:30)	(cid:8)(cid:10) (cid:8)	 	 )(cid:12) 8>G (cid:16)(cid:11)(cid:30) 5GGG
(cid:12) (cid:16), (cid:20)(cid:29)(cid:16) (cid:16)	  (cid:15)(cid:12)(cid:8)(cid:16)(cid:30) (cid:12)(cid:16) (cid:12) (cid:12)(cid:10)(cid:10)(cid:16)(cid:10)(cid:12)(cid:16) *(cid:16)
6> 	(cid:11)(cid:29) (cid:16)-(cid:16)(cid:8)(cid:16),

(cid:20)(cid:29)(cid:16) (cid:15)(cid:16)*(cid:16)(cid:30) (cid:4)(cid:28) (cid:8)(cid:10)(cid:12)  )(cid:16)(cid:16) (cid:11)(cid:12)(cid:8)(cid:12)(cid:16)(cid:30) )(cid:8)(cid:29)
(cid:12) (cid:15)(cid:16)(cid:12)(cid:29)(cid:8)(cid:10) (cid:11)(cid:16), &(cid:8)(cid:11)(cid:16) (cid:29)(cid:16) (cid:12)(cid:11)(cid:12)	(cid:16) #(cid:16)(cid:14)
)(cid:12) 	(cid:30)(cid:16) (cid:10)(cid:16)(cid:16)(cid:12)  (cid:12)(cid:12)(cid:16)(cid:29)(cid:16)(cid:8)(cid:11) (cid:30)	(cid:8)(cid:10) (cid:30)(cid:12)(cid:12) (cid:12)(cid:11)	(cid:8)(cid:8)(cid:8)
(cid:15)(cid:16)(cid:12)(cid:29)(cid:8)(cid:10) )(cid:12) (cid:16)(cid:11)(cid:29)(cid:12)(cid:8)(cid:11)(cid:12)  (cid:14) (cid:12)(cid:8)(cid:16)(cid:30) (cid:12)(cid:30) (cid:29)(cid:12)(cid:30) (cid:12) (cid:11)	
(cid:12) (cid:4)(cid:16)	(cid:16)(cid:11)(cid:14) (cid:4) (cid:12)-(cid:8)(cid:12)(cid:16) (cid:14) G,: /, !(cid:16) (cid:30)(cid:16)  (cid:16)(cid:30)
(cid:29)(cid:8) (cid:15)(cid:16)(cid:12)(cid:29)(cid:8)(cid:10) (cid:12) (cid:15)(cid:16)(cid:8)(cid:10) (cid:4) (cid:11)(cid:12) (cid:12) (cid:8)	(cid:30)(cid:16) (cid:12)(cid:30)  (cid:8)	
(cid:16)(cid:12) (cid:14) 	(cid:16)(cid:16)(cid:30)  (cid:29)(cid:16) (cid:29)(cid:12)(cid:16)(cid:30)(cid:14)(cid:12)(cid:8)(cid:11) (cid:16)(cid:16), (cid:20)(cid:29)(cid:8)
(cid:30)(cid:16)  (cid:8) (cid:8)*(cid:12)(cid:16)(cid:30) (cid:15)(cid:14) (cid:29)(cid:16) (cid:12))(cid:16) (cid:4) (cid:29)(cid:16) (cid:16)(cid:11)	
(cid:12)  (cid:16)(cid:12)# (cid:12) (cid:29)(cid:16) (cid:15)(cid:16)(cid:12)(cid:29)(cid:8)(cid:10) (cid:4)(cid:16)	(cid:16)(cid:11)(cid:14) (cid:12)(cid:30) (cid:29)(cid:12)(cid:8)(cid:11)
)(cid:29)(cid:8)(cid:11)(cid:29) 	(cid:10)(cid:10)(cid:16) (cid:29)(cid:12) (cid:12)(cid:14) (cid:12) (cid:8)	(cid:30)(cid:16) (cid:30)	 (cid:12)(cid:8) (cid:4) (cid:29)(cid:16)
(cid:15)(cid:16)(cid:12)(cid:29)(cid:8)(cid:10) (cid:8)(cid:10)(cid:12)  (cid:8) (cid:4) *(cid:16)(cid:14)  ) (cid:4)(cid:16)	(cid:16)(cid:11)(cid:14) (cid:12)(cid:30) (cid:11)(cid:12) (cid:15)(cid:16)
(cid:12)	(cid:16)(cid:30) (cid:16)3(cid:16)(cid:11)(cid:8)*(cid:16) (cid:14) (cid:11)(cid:12), (cid:20)(cid:29)	 )(cid:29)(cid:8) (cid:16) )(cid:16) (cid:11)	 (cid:30)
 (cid:30)(cid:8)(cid:16)(cid:11) (cid:14) (cid:16)(cid:11)*(cid:16) (cid:29)(cid:16) 	(cid:16) (cid:15)(cid:16)(cid:12)(cid:29)(cid:8)(cid:10) (cid:11)(cid:12)(cid:8)(cid:12)(cid:8)
(cid:12) (cid:16)(cid:12)(cid:11)(cid:29) *-(cid:16)  )(cid:16) )(cid:16)(cid:16) (cid:12)(cid:15) (cid:16)  	(cid:16) (cid:29)(cid:16) (cid:30)(cid:16)(cid:11)(cid:16)(cid:12)(cid:16) (cid:8)
(cid:29)(cid:16) (cid:16)(cid:11)(cid:12)  (cid:16)(cid:12)# (cid:12) (cid:29)(cid:16) (cid:15)(cid:16)(cid:12)(cid:29)(cid:8)(cid:10) (cid:4)(cid:16)	(cid:16)(cid:11)(cid:14) (cid:12)*(cid:16)(cid:12)(cid:10)(cid:16)(cid:30)
(cid:12)(cid:11) (cid:12)   *-(cid:16)  (cid:12) (cid:12) (cid:16)(cid:12)	(cid:16) (cid:4) 	(cid:11)(cid:11)(cid:16) (cid:8) (cid:16)*(cid:8)(cid:10)
(cid:29)(cid:16) (cid:15)(cid:16)(cid:12)(cid:29)(cid:8)(cid:10) (cid:12)(cid:16)(cid:4)(cid:12)(cid:11),  (cid:12)(cid:8)(cid:11) (cid:12) (cid:8)(cid:16)(cid:10)(cid:16) 	 (cid:8)	
 (cid:16) (cid:4) (cid:29)(cid:16) (cid:4)	(cid:30)(cid:12)(cid:16)(cid:12)  (cid:4)(cid:16)	(cid:16)(cid:11)(cid:14) )(cid:16)(cid:16) (cid:30)(cid:16)  (cid:16)(cid:30) (cid:8) (cid:29)(cid:16)
(cid:12)(cid:16) )(cid:12)(cid:14), (cid:20)(cid:29)(cid:16) (cid:16)-(cid:12)(cid:11) (cid:4)(cid:16)	(cid:16)(cid:11)(cid:14) (cid:4) (cid:29)(cid:16) (cid:15)(cid:16)(cid:12)(cid:29)(cid:8)(cid:10) (cid:8)(cid:10)(cid:12) 
)(cid:12) (cid:4)	(cid:30) (cid:15)(cid:14) (cid:12)*(cid:16)(cid:12)(cid:10)(cid:8)(cid:10) (cid:29)(cid:16) (cid:16)(cid:11)	 *(cid:16) (cid:12)   *-(cid:16) 
(cid:12)(cid:30) (cid:29)(cid:16) (cid:29)(cid:12)(cid:16) (cid:12) (cid:16)(cid:12)(cid:11)(cid:29) *-(cid:16)  )(cid:12) (cid:11)(cid:29)(cid:16)  (cid:12)-(cid:8)(cid:8)(cid:16)
(cid:29)(cid:16) 1(cid:16)(cid:11)(cid:8) (cid:8) (cid:29)(cid:16) (cid:8)(cid:16) (cid:30)(cid:12)(cid:8) (cid:4) (cid:29)(cid:16) (cid:15)(cid:16)(cid:12)(cid:29)(cid:8)(cid:10) (cid:8)	
	(cid:8)(cid:30),  (cid:14) *-(cid:16)  (cid:16)(cid:12)  (cid:12)(cid:10)(cid:16) (cid:15) (cid:30) *(cid:16)(cid:16)  )(cid:16)(cid:16) (cid:11)	
(cid:12)(cid:8)(cid:12)(cid:16)(cid:30) (cid:15)(cid:14) (cid:29)(cid:16) (cid:15)(cid:16)(cid:12)(cid:29)(cid:8)(cid:10) (cid:8)(cid:10)(cid:12)  (cid:12)(cid:30) (cid:29)	 (cid:12) (cid:29)(cid:16)(cid:29)	
 (cid:30) (cid:16) )(cid:12) (cid:12) (cid:8)(cid:16)(cid:30)  (cid:29)(cid:16) (cid:16)(cid:11)	 (cid:12) (cid:16)(cid:12)(cid:11)(cid:29) *-(cid:16)  
(cid:16) )(cid:29)(cid:16)(cid:29)(cid:16) (cid:12) 	(cid:15)(cid:12)(cid:8)(cid:12)  (cid:15)(cid:16)(cid:12)(cid:29)(cid:8)(cid:10) (cid:11)(cid:16) )(cid:12)
*(cid:8)(cid:8)(cid:15) (cid:16), !(cid:29)(cid:16)(cid:16) (cid:15)(cid:16)(cid:12)(cid:29)(cid:8)(cid:10) )(cid:12) (cid:16)(cid:16) (cid:12) (cid:8)	(cid:8)(cid:30) (cid:4)
(cid:11)(cid:16)(cid:30)(cid:8)(cid:10) (cid:4)(cid:16)	(cid:16)(cid:11)(cid:14) (cid:12)(cid:30) (cid:29)(cid:12)(cid:16) )(cid:12) 1(cid:16)(cid:11)(cid:16)(cid:30) 	
(cid:8) (cid:29)(cid:16) (cid:8)(cid:16) (cid:30)(cid:12)(cid:8) (cid:29)	 (cid:12)  (cid:16)*(cid:8)(cid:10) (cid:29)(cid:16) (cid:12)(cid:11)(cid:8)(cid:12)(cid:16)(cid:30)
(cid:4)(cid:16)	(cid:16)(cid:11)(cid:14) (cid:30)(cid:12)(cid:8) (cid:8)(cid:30)(cid:16) (cid:15)(cid:16) (cid:11)(cid:12)	(cid:16)(cid:30) (cid:15)(cid:14) =(cid:8)(cid:16) (cid:8)(cid:10)(cid:12)  (cid:30)		
(cid:12)(cid:8), (cid:20)(cid:29)(cid:16) (cid:12)(cid:16) (cid:11)(cid:16)(cid:30)	(cid:16) )(cid:12) 	(cid:16)(cid:30)  (cid:16)*(cid:16) (cid:29)(cid:16)
= ) (cid:29)(cid:12)(cid:8)(cid:11), !(cid:16) (cid:30)(cid:8)(cid:30)  (cid:15)(cid:12)(cid:30)	(cid:12) = (cid:16) (cid:29)(cid:16)
(cid:8)(cid:10)(cid:12)   (cid:16)*(cid:16) (cid:29)(cid:16) (cid:15)(cid:16)(cid:12)(cid:29)(cid:8)(cid:10) (cid:12) (cid:29)(cid:8) )	 (cid:30) (cid:29)(cid:12)*(cid:16)
(cid:16) (cid:8)(cid:8)(cid:12)(cid:16)(cid:30) (cid:12) (cid:10)(cid:16)(cid:12)(cid:16) (cid:8) (cid:4) (cid:29)(cid:16) (cid:16)(cid:11)(cid:12)  (cid:11)	
(cid:16) (cid:30)	(cid:16)  (cid:29)(cid:16) (cid:29)(cid:12)(cid:16)(cid:30)(cid:14)(cid:12)(cid:8)(cid:11) (cid:12)(cid:11)(cid:8)*(cid:8)(cid:14),

(cid:26) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:16)(cid:12)	(cid:16) (cid:15)(cid:16))(cid:16)(cid:16) (cid:12)(cid:8) (cid:4) *-(cid:16)  )(cid:16)
(cid:12) (cid:8)(cid:16)(cid:30) (cid:11) (cid:11)(cid:16) (cid:12)(cid:8) (cid:15)(cid:16))(cid:16)(cid:16) *-(cid:16)  (cid:29)(cid:16) 		(cid:12) 

(cid:8)(cid:4)(cid:12)(cid:8)  (cid:11)	(cid:16)(cid:30) 	(cid:8)(cid:10) (cid:29)(cid:16) (cid:16)(cid:29)(cid:30) (cid:8) 4:7
(cid:12)(cid:30) (cid:13)(cid:13) 	(cid:8)(cid:10) (cid:28) & )(cid:8)(cid:29) (cid:23)(cid:12)	(cid:8)(cid:12) #(cid:16)(cid:16) ,
(cid:20)(cid:29)(cid:16) *(cid:12)(cid:8)(cid:12)(cid:8) (cid:8) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:15)(cid:16))(cid:16)(cid:16) *-(cid:16)  )(cid:12) 	(cid:30)	
(cid:8)(cid:16)(cid:30) )(cid:8)(cid:29) (cid:12)   (cid:29)(cid:16)(cid:16) (cid:16)(cid:29)(cid:30) (cid:12) (cid:12) (cid:4)	(cid:11)(cid:8) (cid:4) (cid:12)*(cid:16)(cid:12)(cid:10)(cid:16)
(cid:30)(cid:8)(cid:12)(cid:11)(cid:16) (cid:15)(cid:16))(cid:16)(cid:16) *-(cid:16)  (cid:8) (cid:29)(cid:16) )(cid:30) )(cid:16) (cid:10)	(cid:16)(cid:30)
(cid:10)(cid:16)(cid:29)(cid:16) (cid:12)   (cid:12)(cid:8) (cid:4) *-(cid:16)  (cid:12) (cid:16)	(cid:12)  (cid:30)(cid:8)(cid:12)(cid:11)(cid:16) (cid:4) (cid:16)(cid:12)(cid:11)(cid:29)
(cid:29)(cid:16)(cid:27) )(cid:16) (cid:29)(cid:16) (cid:11) 	(cid:16)(cid:16)(cid:30) (cid:29)(cid:16)(cid:16) (cid:12)(cid:8)  (cid:12)  (cid:30)(cid:12)) 	
(cid:10)(cid:16)(cid:29)(cid:16) *-(cid:16)  (cid:12)(cid:8) )(cid:8)(cid:29) (cid:8)(cid:8) (cid:12) (cid:30)(cid:8)(cid:12)(cid:11)(cid:16), (cid:20)(cid:29)(cid:16) (cid:16)(cid:10)(cid:8)
(cid:4) (cid:8)(cid:16)(cid:16) (cid:28) )(cid:16)(cid:16) (cid:11)(cid:12)(cid:8)(cid:16)(cid:30)  (cid:15)(cid:16) (cid:11)*(cid:16)- (cid:16)
 (cid:12)  (cid:12)*(cid:8)(cid:30) (cid:8)(cid:11)(cid:16)(cid:11) (cid:30)(cid:8)(cid:12)(cid:11)(cid:16) (cid:16)(cid:8)(cid:12)(cid:16), &(cid:16)(cid:11)(cid:8)=	
(cid:11)(cid:12)  (cid:14) P	(cid:11) (cid:8)(cid:30)(cid:16)(cid:12) (cid:30)(cid:8)(cid:12)(cid:11)(cid:16) (cid:12) (cid:29)(cid:16) (cid:8)(cid:12)(cid:10)(cid:16)  (cid:16)*(cid:16)  (cid:12)(cid:14) (cid:8)(cid:10)	
(cid:8)=(cid:11)(cid:12) (cid:14) (cid:30)(cid:8)3(cid:16) (cid:4) (cid:29)(cid:16) (cid:12)(cid:11)	(cid:12)  (cid:12)-(cid:8)(cid:11) (cid:30)(cid:8)(cid:12)(cid:11)(cid:16) (cid:11)	
(cid:16)(cid:11)(cid:8)(cid:10) (cid:16)	(cid:12)  (cid:8)(cid:16), !(cid:16) 	(cid:15)(cid:12)(cid:11)(cid:16)(cid:30) (cid:12) (cid:15)(cid:12)(cid:16) (cid:8)(cid:16) (cid:30)(cid:16)(cid:16)	
(cid:30)(cid:16)(cid:11)(cid:16) (cid:4) (cid:16)(cid:12)(cid:11)(cid:29) (cid:4) (cid:29)(cid:16) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:16)(cid:12)	(cid:16) )(cid:29)(cid:8)(cid:11)(cid:29)
)(cid:12) (cid:15)(cid:12)(cid:8)(cid:16)(cid:30) (cid:15)(cid:14) (cid:12)*(cid:16)(cid:12)(cid:10)(cid:8)(cid:10) (cid:29)(cid:16) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:15)(cid:16))(cid:16)(cid:16)
(cid:29)(cid:16) A5 (cid:16)(cid:10)(cid:8) (cid:12)(cid:30) (cid:12) (cid:16) (cid:16)(cid:10)(cid:8) (cid:4) (cid:29)(cid:16) (cid:15)(cid:12)(cid:8) (cid:29)(cid:16)  (cid:12)(cid:16)
(cid:15)(cid:16)(cid:8)(cid:10) 	(cid:16) (cid:12)(cid:16)(cid:30)  *(cid:8)	(cid:12)  (cid:11)(cid:16)(cid:8)(cid:10), (cid:20)(cid:29)(cid:16) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16)
(cid:12) (cid:8)	(cid:30)(cid:16) )(cid:16)(cid:16) (cid:29)(cid:16) (cid:30)(cid:8)*(cid:8)(cid:30)(cid:16)(cid:30) (cid:15)(cid:14) (cid:29)(cid:16) (cid:12)(cid:30)(cid:12)(cid:30) (cid:30)(cid:16)*(cid:8)(cid:12)	
(cid:8) (cid:8) (cid:29)(cid:16) (cid:12)*(cid:16)(cid:12)(cid:10)(cid:16) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:15)(cid:16))(cid:16)(cid:16) A5 (cid:12)(cid:30) (cid:29)(cid:8)
(cid:16) (cid:16)(cid:10)(cid:8), (cid:28)(cid:16)	  (cid:12)(cid:16)  (cid:16)(cid:30) (cid:8) 0(cid:8)(cid:10)	(cid:16) B,5,

(cid:13)(cid:12)(cid:8)(cid:10) (cid:29)(cid:16) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:16)(cid:12)	(cid:16) (cid:15)(cid:16)(cid:4)(cid:16) (cid:12)(cid:30) (cid:12)(cid:4)	
(cid:16) (cid:15)(cid:16)(cid:12)(cid:29)(cid:8)(cid:10) (cid:16)*(cid:12)  (cid:29)) (cid:8)(cid:10)(cid:8)=(cid:11)(cid:12) (cid:16)3(cid:16)(cid:11) (cid:4) (cid:16)	
(cid:8)(cid:12)(cid:14) (cid:12)(cid:16)(cid:4)(cid:12)(cid:11)  (cid:29)(cid:16) (cid:29)(cid:8)(cid:10)(cid:29) (cid:30)(cid:16)(cid:0)(cid:8) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) *,
(cid:30)(cid:8)(cid:12)(cid:11)(cid:16) (cid:11)	*(cid:16) (cid:13)(cid:13) (cid:12)(cid:30) @ (cid:29)(cid:8) =(cid:30)(cid:8)(cid:10) 	(cid:10)	
(cid:10)(cid:16) (cid:16)-(cid:16)(cid:16) (cid:11)(cid:12)	(cid:8) (cid:4) 	(cid:30)(cid:8)(cid:16) (cid:8) (cid:29)	(cid:12) (cid:8) )(cid:29)(cid:8)(cid:11)(cid:29)
(cid:16)(cid:8)(cid:12)(cid:8)	(cid:8)(cid:30)	(cid:11)(cid:16)(cid:30) (cid:8)(cid:10)(cid:12)  (cid:11)(cid:12) (cid:16)(cid:12)(cid:8) (cid:14) (cid:15)(cid:16) (cid:30)(cid:16)  (cid:16)(cid:30)
(cid:30)	(cid:16)   ) (cid:16)(cid:12)  (cid:12) (cid:8)(cid:10) (cid:12)(cid:16) (cid:12) )(cid:16)   (cid:12) *(cid:12)(cid:8)(cid:12)(cid:15) (cid:16)
(cid:16)(cid:8)(cid:12)(cid:8) (cid:4)(cid:16)	(cid:16)(cid:11)(cid:14) (cid:12)(cid:30) (cid:12) (cid:8)	(cid:30)(cid:16), (cid:8)  (cid:15)(cid:16)(cid:12)(cid:29)	
(cid:8)(cid:10) (cid:16)*(cid:12)  (cid:13)(cid:13) (cid:12)(cid:30) (cid:29)(cid:16)  *(cid:16)(cid:16)(cid:8)(cid:12)(cid:16) (cid:29)(cid:16) (cid:30)(cid:16)	
(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:15)(cid:16))(cid:16)(cid:16) *-(cid:16)  (cid:29)(cid:16) (cid:15)(cid:16)(cid:12)(cid:29)(cid:8)(cid:10) (cid:12)(cid:16)(cid:4)(cid:12)(cid:11) (cid:15)(cid:16)	
(cid:8)(cid:10) (cid:12) 	(cid:11)(cid:16) (cid:4) (cid:11)(cid:8)(cid:30)(cid:16)(cid:12)(cid:15) (cid:16) (cid:8)(cid:8) (cid:12)(cid:8)(cid:14) (cid:12) (cid:30)(cid:16) (cid:29)(cid:16)
(cid:11)(cid:16) (cid:12)(cid:8) (cid:29)	(cid:10)(cid:29)  (cid:12)  (cid:16)(cid:16) (cid:16)-(cid:16), (cid:20)(cid:29)(cid:8) (cid:11)(cid:12) (cid:15)(cid:16)
(cid:16)- (cid:12)(cid:8)(cid:16)(cid:30) (cid:15)(cid:14) (cid:29)(cid:12)(cid:16) (cid:29)(cid:8)(cid:4) (cid:15)(cid:16))(cid:16)(cid:16) (cid:29)(cid:16) (cid:15)(cid:16)(cid:12)(cid:29)(cid:8)(cid:10) (cid:11)	
(cid:12)(cid:8)(cid:12)(cid:8) (cid:15)(cid:16)*(cid:16)(cid:30) (cid:12) (cid:30)(cid:8)3(cid:16)(cid:16) *-(cid:16)  )(cid:29)(cid:8)(cid:11)(cid:29) (cid:16)(cid:30)	(cid:11)(cid:16)
(cid:29)(cid:16) (cid:11)(cid:16) (cid:12)(cid:8) (cid:15)	 (cid:29)(cid:12)*(cid:16)  (cid:16) (cid:16)3(cid:16)(cid:11)  (cid:16) (cid:10)(cid:16)(cid:16)(cid:12) 
(cid:16)(cid:12)	(cid:16) (cid:4) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16), (cid:20)(cid:29)(cid:16) (cid:29)(cid:8)(cid:10)(cid:29) (cid:30)(cid:16) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16)
(cid:11)	*(cid:16) (cid:12)  Q(cid:12)(cid:16) 	 (cid:12) (cid:12)(cid:15)	 > (cid:11)(cid:16) (cid:15)(cid:16)(cid:12)(cid:29)(cid:8)(cid:10)
(cid:8) (cid:16)*(cid:16)(cid:30) (cid:15)	 (cid:11)(cid:8)	(cid:16)  (cid:30)(cid:16)(cid:11)(cid:12)(cid:14) )(cid:8)(cid:29) (cid:30)(cid:8)(cid:12)(cid:11)(cid:16) )(cid:29)(cid:16)
(cid:15)(cid:16)(cid:12)(cid:29)(cid:8)(cid:10) (cid:8) (cid:16)(cid:16), (cid:7)(cid:14) (cid:11)(cid:12) (cid:29)(cid:16) (cid:11)(cid:16) (cid:12)(cid:8) (cid:8)
 (cid:15)(cid:16)(cid:12)(cid:29)(cid:8)(cid:10) (cid:16)*(cid:12)  (cid:8) (cid:11)(cid:12)  )(cid:8)(cid:29)(cid:8) (cid:15)(cid:16)*(cid:12)	
(cid:8)(cid:12)  	(cid:11)(cid:16)(cid:12)(cid:8)(cid:14) (cid:12)(cid:4)(cid:16) (cid:12)(cid:15)	 8(cid:27) (cid:4)  )(cid:8)(cid:10) (cid:15)(cid:16)(cid:12)(cid:29)	
(cid:8)(cid:10) (cid:16)*(cid:12)  (cid:29))(cid:16)*(cid:16) (cid:29)(cid:16) (cid:8) (cid:12) )(cid:29)(cid:8)(cid:11)(cid:29) (cid:8) Q(cid:12)(cid:16) 	
(cid:8) (cid:16) (cid:30)(cid:8)Æ(cid:11)	   (cid:30)(cid:16)(cid:16)(cid:8)(cid:16), 0(cid:8)(cid:12)  (cid:14) (cid:11)(cid:12)(cid:16)(cid:30) )(cid:8)(cid:29)
(cid:29)(cid:16)  (cid:13)(cid:13) (cid:12) (cid:29) (cid:30)(cid:8)(cid:12)(cid:11)(cid:16) (cid:8) (cid:12)  (cid:12)(cid:10)(cid:16) 	 (cid:8) (cid:16)
(cid:4) (cid:29)(cid:16) (cid:12)(cid:30)(cid:12)(cid:30) (cid:30)(cid:16)*(cid:8)(cid:12)(cid:8) (cid:8) (cid:16) (cid:16)(cid:10)(cid:8) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16)
)(cid:29)(cid:8)(cid:11)(cid:29) (cid:8)(cid:10)(cid:29) (cid:12)#(cid:16) (cid:13)(cid:13) (cid:12) (cid:16) (cid:16) (cid:8)(cid:12)(cid:15) (cid:16) (cid:16)(cid:12)	(cid:16) (cid:4)
	(cid:11)(cid:29) (cid:29) (cid:12)(cid:10)(cid:16) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:8)(cid:16),  (cid:29)(cid:16) (cid:29)(cid:16) (cid:29)(cid:12)(cid:30)
(cid:15)(cid:29) (cid:29)(cid:16)  (cid:12)(cid:30) (cid:29)(cid:16) (cid:11)(cid:16) (cid:12)(cid:8) (cid:4)(cid:12)    (cid:12) (cid:15)(cid:12)(cid:16) (cid:8)(cid:16)  (cid:16)*(cid:16) 
(cid:4) (cid:12)(cid:11)(cid:8)*(cid:8)(cid:14) (cid:10)(cid:16)(cid:12)(cid:16) (cid:29)(cid:12) (cid:29)(cid:12) (cid:8) (cid:29)(cid:16) (cid:16) (cid:16)(cid:10)(cid:8) )(cid:29)(cid:8)(cid:11)(cid:29)
(cid:13)(cid:13) (cid:30)(cid:16)  (cid:30)(cid:16)(cid:16)(cid:11), (cid:26)(cid:30)(cid:30)(cid:8)(cid:8)(cid:12)  (cid:16)-(cid:16)(cid:8)(cid:16)  (cid:12)
(cid:10)(cid:16)(cid:12)(cid:16) 	(cid:15)(cid:16) (cid:4) 	(cid:15)1(cid:16)(cid:11) (cid:12)(cid:30) (cid:8)	 (cid:8) )(cid:8)   (cid:15)(cid:16) 	(cid:16)(cid:30) 
*(cid:16)(cid:8)(cid:4)(cid:14) (cid:29)(cid:16)(cid:16) (cid:15)(cid:16)*(cid:12)(cid:8),

(cid:4)(cid:11)	  (cid:29)(cid:16) (cid:11)	(cid:11)(cid:8) (cid:4)
0	(cid:29)(cid:16) )# )(cid:8)  
(cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16)	(cid:30)(cid:8)(cid:12)(cid:11)(cid:16) (cid:4)	(cid:11)(cid:8) 	(cid:8)(cid:10) (cid:4) (cid:8)(cid:12)(cid:11)(cid:16) (cid:29)(cid:16)
)(cid:16)   (cid:30)(cid:16)*(cid:16) (cid:16)(cid:30) (cid:12)(cid:29)(cid:16)(cid:12)(cid:8)(cid:11)(cid:12)  (cid:4)(cid:12)(cid:16))# (cid:4) Q(cid:12) (cid:15)(cid:12)(cid:8)	

(cid:0)(cid:9)(cid:28)(cid:21)(cid:1) (cid:22)(cid:1) (cid:6)(cid:4) (cid:6)(cid:23)(cid:1) (cid:4) (cid:6)(cid:22)(cid:22)	  (cid:31) (cid:1)(cid:22)(cid:8) (cid:8)(cid:1)
(cid:8)(cid:1)(cid:1)(cid:8)(cid:1)(cid:22)(cid:1) (cid:2)(cid:21)(cid:1)(cid:1)(cid:6) (cid:26)(cid:26) (cid:6)(cid:8) (cid:21)(cid:1)  (cid:22)(cid:6) (cid:8)(cid:1)(cid:1)(cid:22) (cid:8)(cid:1)(cid:1)	
(cid:8)(cid:1)(cid:22)(cid:1) $ (cid:6)(cid:31) (cid:8)(cid:1)(cid:15)

118Constrained covariance (COCO)

e
c
n
e
d
n
e
p
e
D

10

8

6

4

2

0

−2

0

0.04

0.035

0.03

0.025

0.02

0.015

0.01

0.005

e
c
n
e
d
n
e
p
e
D

10

0

0

2

4

6

8

Between−voxel distance(mm)

Mutual information

Correlation

0.14

0.12

0.1

0.08

0.06

0.04

0.02

0

e
c
n
e
d
n
e
p
e
D

10

−0.02

0

2

4

6

8

Between−voxel distance(mm)

2

4

6

8

10

Between−voxel distance(mm)

0(cid:8)(cid:10)	(cid:16) B,5@ (cid:28)(cid:16)	  (cid:15)(cid:16)(cid:4)(cid:16) (cid:15) (cid:12)(cid:11)# (cid:12)(cid:30) (cid:12)(cid:4)(cid:16) (cid:16)(cid:30) (cid:15)(cid:16)(cid:12)(cid:29)(cid:8)(cid:10) (cid:16)*(cid:12)  (cid:4) (cid:13)(cid:13) (cid:29)(cid:16) 		(cid:12)  (cid:8)(cid:4)(cid:12)(cid:8) 
(cid:12)(cid:30) (cid:29)(cid:16) (cid:11)(cid:16) (cid:12)(cid:8), (cid:20)(cid:29)(cid:16) 3(cid:16) (cid:12)(cid:30) (cid:11)(cid:12) (cid:8)(cid:10) (cid:4) (cid:29)(cid:16) (cid:30)(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:8) (cid:30)(cid:16)(cid:11)(cid:8)(cid:15)(cid:16)(cid:30) (cid:8) (cid:29)(cid:16) (cid:12)(cid:8) (cid:15)(cid:30)(cid:14) (cid:4) (cid:29)(cid:16) (cid:16)-, (cid:20)(cid:29)(cid:16)
(cid:29)(cid:8)/(cid:12)  (cid:12)-(cid:8) (cid:30)(cid:8) (cid:12)(cid:14) (cid:29)(cid:16) (cid:12)*(cid:16)(cid:12)(cid:10)(cid:16) (cid:30)(cid:8)(cid:12)(cid:11)(cid:16) (cid:15)(cid:16))(cid:16)(cid:16) *-(cid:16)  (cid:12)(cid:8),

(cid:12) (cid:10)(cid:16)(cid:16)(cid:12)(cid:8) 4C7, .(cid:16)(cid:16)(cid:30)(cid:16)(cid:11)(cid:16) (cid:16) (cid:29)(cid:12) (cid:12)#(cid:16) (cid:8)
(cid:12)(cid:11)(cid:11)	 (cid:29)(cid:16) (cid:4)(cid:12)(cid:11) (cid:29)(cid:12) (cid:29)(cid:16) (cid:8)(cid:10)(cid:12)  (cid:12)(cid:16)  (cid:8),(cid:8),(cid:30), )(cid:8)   (cid:12) 
(cid:15)(cid:16) (cid:11)(cid:12)(cid:16)(cid:30) )(cid:8)(cid:29) (cid:29)(cid:16) (cid:16)(cid:16) (cid:12)(cid:12)(cid:11)(cid:29)(cid:16),
 (cid:12)(cid:30)(cid:30)(cid:8)	
(cid:8) (cid:8) (cid:8) (cid:4) (cid:8)(cid:16)(cid:16)  (cid:30)(cid:16)*(cid:16)  #(cid:16)(cid:16) 	(cid:15)(cid:12)(cid:16)(cid:30) (cid:30)(cid:16)(cid:16)	
(cid:30)(cid:16)(cid:11)(cid:16) (cid:16)(cid:12)	(cid:16) (cid:4) 	(cid:8),(cid:8),(cid:30), (cid:8)(cid:16) (cid:16)(cid:8)(cid:16),

 (cid:16)(cid:23)(cid:16)(cid:16)(cid:6)(cid:16)

(cid:17)!(cid:19) 3(cid:15) 6(cid:6)(cid:22)(cid:21) (cid:6)(cid:8) (cid:15) (cid:8)(cid:6)(cid:15) (cid:1)(cid:1)  (cid:4)(cid:8)(cid:1)(cid:1)(cid:8)(cid:1) (cid:22)	

(cid:1) (cid:6)(cid:6) (cid:31)(cid:4)(cid:15) (cid:14) ) !9": #;;#(cid:15)

(cid:17)#(cid:19) <(cid:15) (cid:15) 6(cid:6)(cid:23)= >(cid:15) <(cid:1) (cid:15) 3(cid:6)0 (cid:6)(cid:8) 6(cid:15) ((cid:22)(cid:21)? (cid:23)$(cid:15)
	 (cid:4)(cid:11)(cid:6)(cid:4)(cid:6)(cid:1) (cid:1)’(cid:1)(cid:4) (cid:2)(cid:4)(cid:21) (cid:4)(cid:1)$(cid:1)  (cid:22)(cid:6)(cid:4)(cid:15) (cid:28)(cid:1)(cid:22)(cid:21)	
(cid:4)(cid:22)(cid:6)  5(cid:1) !;! (cid:6)(cid:29)  (cid:6)(cid:22)(cid:23) (cid:4)	(cid:1) $ 6(cid:4) ’(cid:4)(cid:22)(cid:6) 
(cid:26)(cid:31)(cid:12)(cid:1)(cid:1)(cid:4)(cid:22) #;;"(cid:15)

(cid:17))(cid:19) (cid:26)(cid:15) 6	(cid:22)(cid:21)(cid:1)  (cid:6)(cid:8) (cid:15) 3(cid:4)(cid:15) (cid:8)	 (cid:6)(cid:4) $ (cid:22)(cid:1)(cid:22)(cid:4)(cid:11)	
(cid:4)(cid:31) (cid:4) (cid:11)(cid:4)	(cid:6)  (cid:6)(cid:21)(cid:2)(cid:6)(cid:31) (cid:12)(cid:31) (cid:6)(cid:1)(cid:4)  (cid:22)(cid:4)(cid:22)(cid:6)  (cid:4)(cid:1)	
(cid:6)(cid:22)(cid:4) (cid:1)(cid:11)(cid:6) 	(cid:6)(cid:1)(cid:8) (cid:2)(cid:4)(cid:21) 	(cid:22)	(cid:6)  (cid:1)	(cid:6)(cid:4) (cid:8)(cid:1)  (cid:4)’
(cid:6)(cid:8) $5(cid:15) (cid:15)(cid:3)(cid:3)(cid:16)(cid:1)  (cid:15)(cid:3)(cid:19) A AB:9AA: !(cid:18)(cid:18)A(cid:15)

(cid:17)"(cid:19) <(cid:15) >(cid:15) C(cid:6)(cid:12)(cid:1)  (cid:6)(cid:31) (cid:6)(cid:8) (cid:15) D(cid:6)E(cid:8)(cid:6)(cid:15) 2(cid:4)(cid:6)(cid:4) $ (cid:21)(cid:1) (cid:4)	
$(cid:6)(cid:4) (cid:12)(cid:31) (cid:6) (cid:6)(cid:8)(cid:6)(cid:4)(cid:11)(cid:1) (cid:6)(cid:4)(cid:4)(cid:4)’ $ (cid:21)(cid:1) (cid:12)(cid:1)(cid:11)(cid:6)	
(cid:4) (cid:6)(cid:22)(cid:1)(cid:15) (cid:21)(cid:21)(cid:21) (cid:22)(cid:1)(cid:1)(cid:23)(cid:5)  (cid:6)(cid:1)(cid:5) (cid:22)(cid:24)(cid:3)	
(cid:26) "F" !)!F9!)#! !(cid:18)(cid:18)(cid:18)(cid:15)

(cid:17)F(cid:19) D(cid:15) (cid:8)(cid:1)  (cid:6) (cid:1)7(cid:6) (cid:6)(cid:8) 2(cid:15) <(cid:4)G(cid:1)(cid:15) (cid:27)(cid:3)(cid:23)	 (cid:5)(cid:7)(cid:29) (cid:6) (cid:27)(cid:3)(cid:3)	

(cid:30)(cid:3)(cid:23)(cid:3)  (cid:30)(cid:3)(cid:3)(cid:30)(cid:3)(cid:23)(cid:3)(cid:15) ((cid:4)’(cid:1) (cid:1)(cid:2) H(cid:23) !(cid:18)(cid:18)(cid:18)(cid:15)

(cid:17)B(cid:19) (cid:15) C(cid:1)(cid:11)(cid:31)(cid:1) (cid:15) <(cid:31)?* (cid:6)(cid:8) <(cid:15) 	’(cid:4)(cid:15) (cid:31) (cid:16)(cid:1)(cid:16)(cid:5) (cid:5)(cid:5)(cid:23)
(cid:22)(cid:24)(cid:3)(cid:26) (cid:6) (cid:1)(cid:3) (cid:14)(cid:3)(cid:23)(cid:7)(cid:5)(cid:5) (cid:11) 	(cid:1) )! $ (cid:31) (cid:5)(cid:23)(cid:1)	
(cid:5) (cid:6) (cid:1)(cid:24)(cid:3)(cid:1)(cid:5)(cid:23)(cid:15) ((cid:4)’(cid:1) (cid:1)(cid:2) H(cid:23) !(cid:18)(cid:18)B(cid:15)

(cid:17)A(cid:19) C(cid:15) D(cid:6) 2(cid:1)  (cid:15) C	(cid:31) ((cid:15) (cid:21)(cid:4) (cid:6)(cid:8) (cid:15) (cid:4)  (cid:1)(cid:15) 3	(cid:22)	
(cid:4)(cid:6)  (cid:6)(cid:8) 	(cid:22)	(cid:6)  (cid:6)(cid:4)’ $ (cid:21)	(cid:6) (cid:22)(cid:1)(cid:1)(cid:12)(cid:6)  (cid:22)	
(cid:1)(cid:29)   	(cid:4) (cid:6)(cid:1) (cid:4) (cid:21)(cid:1) 	$(cid:6)(cid:22)(cid:1)(cid:15) (cid:23)(cid:3)(cid:3)(cid:30)(cid:5)(cid:7) (cid:6) (cid:1)"
(cid:31)(cid:23)(cid:1)(cid:30)" (cid:6) #(cid:23)(cid:5)(cid:3)(cid:23)(cid:3) (cid:6) (cid:24)(cid:3) $#(cid:31) (cid:18)F A::9A(cid:18)F !(cid:18)(cid:18):(cid:15)

(cid:17):(cid:19) (cid:15) 3	(cid:23)	(cid:4)0	 3(cid:15) 5(cid:15) 6(cid:6)(cid:22)(cid:21) (cid:6)(cid:8) (cid:15) (cid:15) (cid:8)(cid:6)(cid:15) C(cid:4)(cid:1)	
(cid:4)(cid:6) (cid:4)(cid:31) (cid:1)(cid:8)	(cid:22)(cid:4) $ 	(cid:1)(cid:11)(cid:4)(cid:1)(cid:8)  (cid:1)(cid:6)(cid:4)’ (cid:2)(cid:4)(cid:21) (cid:1)	
(cid:8)	(cid:22)(cid:4)’ (cid:23)(cid:1)(cid:1)  (cid:21)(cid:4) (cid:12)(cid:1) (cid:6)(cid:22)(cid:1)(cid:15) (cid:14) F A)9(cid:18)(cid:18) #;;"(cid:15)

(cid:17)(cid:18)(cid:19) >(cid:15) <(cid:1) 5(cid:15)  (cid:1)(cid:12)(cid:4)(cid:22)(cid:21) (cid:6)(cid:8) >(cid:15) ( (cid:6)(cid:15) (cid:28)(cid:21)(cid:1) (cid:23)(cid:1)(cid:1) 
		(cid:6)  (cid:4)$(cid:6)(cid:4)(cid:15) (cid:28)(cid:1)(cid:22)(cid:21)(cid:4)(cid:22)(cid:6)  (cid:1)  $ 6(cid:4)	
 ’(cid:4)(cid:22)(cid:6)  (cid:26)(cid:31)(cid:12)(cid:1)(cid:1)(cid:4)(cid:22) #;;)(cid:15)

(cid:17)!;(cid:19) >(cid:15) <(cid:1) >(cid:15) ( (cid:6) (cid:15) 6		(cid:1) (cid:6)(cid:8) 5(cid:15)  (cid:1)(cid:12)(cid:4)(cid:22)(cid:21)(cid:15)
6(cid:1)(cid:21)(cid:6)(cid:11)(cid:4)	 (cid:6)(cid:8) (cid:22)(cid:11)(cid:1)’(cid:1)(cid:22)(cid:1) $ (cid:21)(cid:1) (cid:22)(cid:6)(cid:4)(cid:1)(cid:8) (cid:22)(cid:11)(cid:6)(cid:4)	
(cid:6)(cid:22)(cid:1)(cid:15) (cid:28)(cid:1)(cid:22)(cid:21)(cid:4)(cid:22)(cid:6)  (cid:1)  $ 6(cid:4) ’(cid:4)(cid:22)(cid:6)  (cid:26)(cid:31)(cid:12)(cid:1)(cid:1)	
(cid:4)(cid:22) #;;"(cid:15)

(cid:17)!!(cid:19) (cid:0)(cid:15)  (cid:1)-(cid:8)(cid:4)’(cid:15) (cid:12)(cid:6)(cid:12)(cid:4) (cid:4)(cid:31) (cid:4)(cid:1)	(cid:6) (cid:4)(cid:4)(cid:1) $ 	 $
(cid:12)	(cid:8)(cid:1)(cid:8) (cid:6)(cid:8) (cid:11)(cid:6)(cid:4)(cid:6)(cid:12) (cid:1)(cid:15) 	(cid:1)  (cid:6) (cid:24)(cid:3) (cid:31)(cid:3)(cid:5)(cid:23)(cid:1)
#(cid:1)(cid:5)(cid:5)(cid:23)(cid:1)  (cid:31)(cid:23)(cid:5)(cid:1)(cid:5) F: !)9); !(cid:18)B)(cid:15)

(cid:17)!#(cid:19) >(cid:15)  (cid:31)(cid:11)?(cid:6)(cid:4)(cid:1) (cid:15) (cid:6)(cid:21)	(cid:1) (cid:6)(cid:8) 2(cid:15) E(cid:6)(cid:15)

(cid:30)(cid:3)(cid:3)	
(cid:30)(cid:3) (cid:15)(cid:3) (cid:31)(cid:1) (cid:26)(cid:5)(cid:15) (cid:21) (cid:0)(cid:4) (cid:1)(cid:31) (cid:6)(cid:8) ( (cid:1)(cid:2)
H(cid:23) #;;!(cid:15)

(cid:17)!)(cid:19) H	(cid:15) (cid:15) ’(cid:1)(cid:15) > (cid:6)(cid:31)(cid:4)(cid:22)(cid:6)  (cid:31) (cid:4)(cid:4)(cid:6)(cid:29) (cid:1) $ (cid:21)(cid:1)
(cid:21)(cid:31)(cid:21)(cid:1)(cid:4) $ (cid:4)(cid:8)(cid:1)(cid:1)(cid:8)(cid:1)(cid:22)(cid:1)(cid:15) " #%(cid:5)(cid:3) (cid:1)(cid:24)" "" "BB9
"AB !(cid:18):(cid:18)(cid:15)

(cid:17)!"(cid:19) (cid:15) (cid:6)(cid:22)(cid:8) (cid:6)(cid:8) (cid:15) (cid:1)(cid:15)
((cid:4)’(cid:1) (cid:1)(cid:2) H(cid:23) #;;;(cid:15)

(cid:16)(cid:1)(cid:16)(cid:5) (cid:5)(cid:26) (cid:21)(cid:3)(cid:5)(cid:1) (cid:15)

(cid:17)!F(cid:19) ((cid:15) 2(cid:15) (cid:1)	’(cid:6) 5(cid:15) >(cid:15) (cid:31)(cid:1)(cid:1)(cid:8) (cid:6)(cid:8) 6(cid:15) (cid:0)(cid:15) ((cid:4) (cid:11)(cid:1)	
(cid:6)(cid:15) (cid:26)(cid:6)(cid:4)(cid:22)(cid:6)  (cid:22)(cid:1) (cid:6)(cid:4) (cid:6)(cid:6) (cid:31)(cid:4) (cid:2)(cid:21)(cid:1) (cid:21)(cid:1) (cid:8)(cid:6)(cid:6)
(cid:6)(cid:1) (cid:22)	(cid:11)(cid:1)(cid:15) " (cid:14)" #(cid:1)" #(cid:23)" & FF) A#F9A"; !(cid:18)(cid:18))(cid:15)

(cid:17)!B(cid:19) (cid:15) ’(cid:21)(cid:1)(cid:4)  (cid:15) <	’’(cid:1)(cid:12)(cid:1)’(cid:1) (cid:6)(cid:8) (cid:15) (cid:6)	 
((cid:15) (cid:1) (cid:1)(cid:8)(cid:15) 3	(cid:22)(cid:4)(cid:6)  (cid:4)(cid:6)’(cid:4)’ $ (cid:21)(cid:1) (cid:23)(cid:1)(cid:31) (cid:12)(cid:6)(cid:4)(cid:15)
(cid:1)	(cid:3) (cid:3)	(cid:23)(cid:5)(cid:3)(cid:23)(cid:3) # FFF9FB# !(cid:18)(cid:18)(cid:18)(cid:15)

(cid:17)!A(cid:19) (cid:15) ’(cid:21)(cid:1)(cid:4) (cid:15) (cid:6)	  (cid:15) >	’(cid:6)(cid:21) (cid:28)(cid:15) (cid:28)(cid:4)(cid:6)(cid:21) (cid:6)(cid:8)
>(cid:15) (cid:1) (cid:1)(cid:6)(cid:15) (cid:1)	(cid:21)(cid:31)(cid:4) ’(cid:4)(cid:22)(cid:6)  (cid:4)(cid:11)(cid:1)(cid:4)’(cid:6)(cid:4) $
(cid:21)(cid:1) (cid:12)(cid:6)(cid:4) $ (cid:21)(cid:1) $5 (cid:4)’(cid:6) (cid:15) (cid:1)	(cid:3) "!# !F;9!FA
#;;!(cid:15)

(cid:17)!:(cid:19) (cid:26)(cid:15) (cid:22)C(cid:4)(cid:6)(cid:4)(cid:8)(cid:15)  (cid:21)(cid:1) (cid:1)(cid:21)(cid:8) $ (cid:12)	(cid:8)(cid:1)(cid:8) (cid:8)(cid:4)-(cid:1)(cid:1)(cid:22)(cid:1)(cid:15)
#	%(cid:3)(cid:26) (cid:5) (cid:15)(cid:16)(cid:5)(cid:1)(cid:5)(cid:23) (cid:6)’(cid:1) !":9!:: !(cid:18):(cid:18)(cid:15) (cid:26)(cid:6)	
(cid:12)(cid:4)(cid:8)’(cid:1) J(cid:4)(cid:11)(cid:1)(cid:4)(cid:31) (cid:1)(cid:15)

(cid:17)!(cid:18)(cid:19) >(cid:15) 5G(cid:1)(cid:31)(cid:4)(cid:15)  (cid:1)(cid:6)	(cid:1) $ (cid:8)(cid:1)(cid:1)(cid:8)(cid:1)(cid:22)(cid:1)(cid:15) (cid:31)(cid:23)(cid:1) (cid:1)(cid:24)"

(cid:31)(cid:23)(cid:1)(cid:30)" #(cid:23)(cid:5)"  	(cid:7)(cid:1)" !; ""!9"F! !(cid:18)F(cid:18)(cid:15)

(cid:17)#;(cid:19) ((cid:15) ((cid:6)(cid:4)(cid:21)(cid:15) (cid:22)(cid:24)(cid:3)(cid:26) (cid:6) (cid:14)(cid:3)(cid:30)	(cid:23)(cid:5)(cid:7) (cid:3)(cid:3)  (cid:1)(cid:30) (cid:5) (cid:31)	
 (cid:5)(cid:23)(cid:1)(cid:5)(cid:15) ’(cid:6) ((cid:22)(cid:4)(cid:1)(cid:4)*(cid:22) (cid:6)(cid:8) (cid:28)(cid:1)(cid:22)(cid:21)(cid:4)(cid:22)(cid:6)   (cid:6) (cid:2)
J !(cid:18)::(cid:15)

(cid:17)#!(cid:19) 6(cid:15) ((cid:22)(cid:21)? (cid:23)$ (cid:6)(cid:8) >(cid:15) ( (cid:6)(cid:15) (cid:3)(cid:1)(cid:5)(cid:7) )(cid:5)(cid:24) (cid:3)(cid:3) (cid:15)

(cid:28) (cid:1) (cid:26)(cid:6)(cid:12)(cid:4)(cid:8)’(cid:1) > #;;#(cid:15)

(cid:17)##(cid:19) (cid:15) ((cid:1)(cid:4)(cid:2)(cid:6)(cid:15)  (cid:21)(cid:1) (cid:4)K	(cid:1)(cid:22)(cid:1) $ (cid:21)(cid:1) (cid:23)(cid:1)(cid:1)   (cid:21)(cid:1)
(cid:22)(cid:4)(cid:1)(cid:22)(cid:31) $ 	 (cid:11)(cid:1)(cid:22) (cid:6)(cid:22)(cid:21)(cid:4)(cid:1)(cid:15) (cid:14) #
#;;!(cid:15)

119Semisupervised alignment of manifolds

Jihun Ham

Department of Electrical and

Systems Engineering,

University of Pennsylvania,

Philadelphia, PA 19104

Daniel D. Lee

Department of Electrical and

Systems Engineering,

University of Pennsylvania,

Philadelphia, PA 19104

Lawrence K. Saul

Department of Computer and

Information Science,

University of Pennsylvania,

Philadelphia, PA 19104

Abstract

In this paper, we study a family of semisu-
pervised learning algorithms for “aligning”
diﬀerent data sets that are characterized by
the same underlying manifold. The optimiza-
tions of these algorithms are based on graphs
that provide a discretized approximation to
the manifold. Partial alignments of the data
sets—obtained from prior knowledge of their
manifold structure or from pairwise corre-
spondences of subsets of labeled examples—
are completed by integrating supervised sig-
nals with unsupervised frameworks for man-
ifold learning. As an illustration of this
semisupervised setting, we show how to learn
mappings between diﬀerent data sets of im-
ages that are parameterized by the same un-
derlying modes of variability (e.g., pose and
viewing angle). The curse of dimensionality
in these problems is overcome by exploiting
the low dimensional structure of image man-
ifolds.

1 Introduction

Examples of very high-dimensional data such as high-
resolution pixel images or large vector-space represen-
tations of text documents abound in multimodal data
sets. Learning problems involving these data sets are
diﬃcult due to the curse of dimensionality and associ-
ated large computational demands. However, in many
cases, the statistical analysis of these data sets may be
tractable due to an underlying low-dimensional mani-
fold structure in the data. Recently, a series of learn-
ing algorithms that approximate data manifolds have
been developed, such as Isomap [15], locally linear em-
bedding [13], Laplacian eigenmaps [3], Hessian eigen-
maps [7], and charting [5]. While these algorithms ap-
proach the problem of learning manifolds from an un-

supervised perspective; in this paper, we address the
problem of establishing a regression between two or
more data sets by aligning their underlying manifolds.
We show how to align the low-dimensional representa-
tions of the data sets given some additional informa-
tion about the mapping between the data sets. Our al-
gorithm relies upon optimization over a graphical rep-
resentation of the data, where edges in the graphs are
computed to preserve local structure in the data. This
optimization yields a common low-dimensional embed-
ding which can then be used to map samples between
the disparate data sets.
Two main approaches for alignment of manifolds are
presented. In the ﬁrst approach, additional knowledge
about the intrinsic embedding coordinates of some of
the samples are used to constrain the alignment. This
information about coordinates may be available given
knowledge about the data generating process, or when
some coordinates are manually assigned to correspond
to certain labeled samples. Our algorithm yields a
graph embedding where these known coordinates are
preserved. Given multiple data sets with such coordi-
nate labels, we show how the underlying data mani-
folds can be aligned to each other through a common
set of coordinates.
In the second approach, we assume that there is no
prior knowledge of explicit coordinates, but that we
know the pairwise correspondences of some of the sam-
ples [11, 16]. These correspondences may be apparent
from temporal conjunction, such as simultaneously ob-
tained images and sounds from cameras and micro-
phones. Correspondences may also be obtained from
hand-labeled matches among samples in diﬀerent data
sets. We demonstrate how these correspondences al-
low implicit alignment of the diﬀerent data manifolds.
This is achieved by joining the graph representations
of the diﬀerent data sets and estimating a common
low-dimensional embedding over the joined graph.
In Section 2 we ﬁrst review a graph-based framework
for manifold learning algorithms. Section 3 describes

120our algorithms for manifold alignment using either
prior coordinate knowledge or paired correspondences.
Section 4 demonstrates the application of our approach
to aligning the pose manifolds of images of diﬀerent ob-
jects. Finally, the utility and future direction of this
approach is discussed in Section 5.

2 Unsupervised manifold learning

with graphs

Let X and Y be two data sets in high dimensional
vector spaces
X = {x1,··· , xm} ⊂ RDX , Y = {y1,··· , yn} ⊂ RDY ,
with DX , DY (cid:29) 1. When the data lie close to a low-
dimensional manifold embedded in a high dimensional
Euclidean space, manifold learning algorithms such as
[3] can successfully learn low-dimensional embeddings
by constructing a weighted graph that captures local
structure in the data. Let G(V,E) be the graph where
the vertices V correspond to samples in the data and
the undirected edges E denote neighborhood relation-
ships between the vertices. These neighborhood rela-
tions can be deﬁned in terms of k-nearest neighbors or
an -ball distance criterion in the Euclidean space of
original data. The similarities between points are sum-
marized by a weight matrix W where Wij 6= 0 when
the ith and jth data points are neighbors (i ∼ j), oth-
erwise Wij = 0. The matrix W is typically symmetric,
and has nonnegative weights Wij = Wji ≥ 0. The
generalized graph Laplacian L is then deﬁned as:

 di,

−Wij,
0,

if i = j,
if i ∼ j,
otherwise

Lij :=

where di = P

j∼i Wij is the degree of the ith ver-
tex.
If the graph is connected, L will have a sin-
gle zero eigenvalue associated with the uniform vector
e = [11··· 1]T .
A low-dimensional embedding of the data can be com-
puted from the graph Laplacian in the following man-
ner. A real valued function f : V 7→ R on the vertices
of the graph is associated with the cost:

f T Lf =

1
2

(fi − fj)2Wij.

(1)

X

i,j

An optimal embedding is given by functions f that
minimize (1), subject to scale and translation con-
straints f T f = 1 and f T e = 0. These solutions are
then the eigenvectors of L with the smallest non-zero
eigenvalues [8]. These solutions may also be inter-
preted as the kernel principal components of a Gram

Figure 1: Two-dimensional embeddings of surfaces in
R3. The embeddings are computed from diagonalizing
the graph Laplacians. Diﬀerent edge weightings yield
qualitative diﬀerences in the embeddings. Only 600
and 800 points were sampled from the two manifolds,
making it diﬃcult for the algorithms to ﬁnd a faithful
embedding of the data.

matrix given by the pseudoinverse of L [10]. This in-
terpretation deﬁnes a metric over the graph which is
related to the commute times of random walks on the
graph [1], and resistance distance in electrical networks
[6].

Choice of weights

Within this graph framework, diﬀerent algorithms
may employ diﬀerent choices for the weights W . For
example, W can be deﬁned according to the Gaussian
process Wij = e−|xi−xj|2/2σ2, and is related to a diﬀu-
sion process on the graph [3, 12]. The symmetric, non-
negative assumptions on the weights Wij = Wji ≥ 0
can be relaxed. For a directed graph structure, such as
when the neighborhoods are determined by k-nearest
neighbors, the matrix W is not symmetric. Nonneg-
ativity constraints may also be lifted. Consider the

Original dataEmbeddings (affine)Embeddings (convex)Embeddings (Gaussian)121least-squares approach to optimize weights Wij :

Wij = arg min
W

Wijxj|2,

(2)

|xi −X

j∼i

from minimizing (2) subject to P

that is, Wij are the coeﬃcients of the neighbors of xi
that best approximates xi, and are in general asym-
metric. Locally linear embedding determines weights
j Wij = 1, yielding
possibly negative coeﬃcients that best approximates
xi from an aﬃne combination of its neighbors [14].
This is in contrast to minimizing (2) over a set of con-
vex coeﬃcients that are nonnegative: Wij ≥ 0. As
noted in [14], a possible disadvantage of convex ap-
proximation is that a point on the boundary may not
be reconstructed from the convex hull of its neighbors.
Consequently, the corners of the resultant embedding
with convex weights tend to be rounded.
Graph Laplacians with negative weights have been re-
cently studied [9, 10]. Although it is diﬃcult to prop-
erly generalize spectral graph theory, we can deﬁne
a new cost function analogous to (1) for graphs with
asymmetric, negative weights as:

f T LT Lf =X

|fi −X

i

j∼i

Wijfj|2,

(3)

where L = D − W . Since LT L is positive semideﬁnite
and satisﬁes LT Le = 0, the eigenvectors of LT L can
be used to construct a low-dimensional embedding of
the graph that minimizes the cost (3).
Figure 1 shows the unsupervised graph embedding of
two artiﬁcial data sets using three diﬀerent weighting
schemes: a symmetric Gaussian, asymmetric convex
reconstruction, and asymmetric aﬃne reconstruction
weights. 600 points were sampled from an S-shaped
two-dimensional manifold, and 800 points were sam-
pled from a wavy two-dimensional manifold. The data
was intentionally undersampled, and the unsupervised
learning algorithms have diﬃculty in faithfully recon-
structing the proper embedding.
In the next sec-
tions, we will show how semisupervised approaches can
greatly improve on these embeddings with the same
data.

3 Semisupervised alignment of

manifolds

We now consider aligning disparate data manifolds,
given some additional information about the data sam-
ples.
In the following approaches, we consider this
additional information to be given for only a partial
subset of the data. We denote the samples with this
additional “labeled” information by the ordinal index
l, and the samples without extra information by the

index u. We also use the same notation for the sets X
and Y ; for example, Xl and Yl refer to the “labeled”
parts of X and Y .
This additional information about the data samples
may be of two diﬀerent types. In the ﬁrst algorithm,
the labels refer to prior information about the intrinsic
real-valued coordinates within the manifold for par-
ticular data samples.
In the second algorithm, the
labels indicate pairwise correspondences between sam-
ples xi ∈ X and yj ∈ Y . These two types of additional
information are quite diﬀerent, but we show how each
can be used to align the diﬀerent data manifolds.

3.1 Alignment with given coordinates

In this approach, we are given desired coordinates for
certain labeled samples. Similar to regression models,
we would like to ﬁnd a map deﬁned on the vertices of
the graph f : V 7→ R that matches known target values
for the labeled vertices. This can be solved by ﬁnding
arg minf |fi − si|2 (i ∈ l) where s is the vector of tar-
get values. With a small number of labeled examples,
it is crucial to exploit manifold structure in the data
when constructing the class of admissible functions f.
The symmetric graph Laplacian L = LT provides this
information. A regularized regression cost on a graph
is deﬁned as:

µ|fi − si|2 + f T Lf .

(4)

C(f) =X

i

f T Lf ≈P

The ﬁrst term in (4) is the ﬁtting error, and the sec-
ond term enforces smoothness along the manifold by
i |∇if|2 [2, 17]. The relative weighting of
these terms is given by the coeﬃcient µ. The optimum
f is then obtained by the linear solution:

(cid:19)

(cid:18) µI + Lll Llu
(cid:20) Lll Llu

(cid:19)−1(cid:18) µI
(cid:21)

Luu

Lul

0

L =

Lul Luu

.

f =

s,

(5)

where L consists of labeled and unlabeled partitions:

In the limit µ → ∞, i.e. there is no uncertainty in the
labels s, the solution becomes

f u = −(Luu)−1Luls = (Luu)−1Wul s.

(6)

This result is directly related to harmonic functions
[18], which are smooth functions on the graph such
that fi is determined by the average of its neighbors:

P
P

fi =

j Wijfj
j Wij

.

(7)

122Figure 2: Graph embeddings for the s-curve and wave surface are aligned with given coordinates, and compared to
the unaligned embeddings. The lines indicate samples whose known coordinates are used to estimate a common
embedding space.

The solution in (6) is a linear superposition of har-
monic functions which directly interpolate the labeled
data.
Given r-dimensional coordinate vectors S = [s1 ··· sr]
as desired embedding coordinates, solutions f i of (5)
or (6) can be used as estimated coordinates of un-
labeled data. This ”stretches” the embedding of the
graph so that the labeled vertices are at the desired co-
ordinates. Figure 3 shows the results of this algorithm
applied to an image manifold with two-dimensional
pose parameters as coordinates. Simultaneous align-
ment of two diﬀerent data sets is performed by simply
mapping each of the data sets into a common space
with known coordinates. Given two data sets X and
Y , where subsets Xl and Yl are given coordinates s
and t respectively, we let f and g denote real-valued
functions, and Lx and Ly the graph Laplacians of X
and Y respectively. Since there is no explicit coupling
between X and Y , we use (6) to get the two solutions:

uu)−1Ly

ul t.

f u = −(Lx

uu)−1Lx

ul s, and gu = −(Ly

Figure 2 shows the semisupervised algorithm applied
to the synthetic data used in the previous section.
Among the 600 and 800 points, 50 labeled points are
randomly chosen from each, and the two-dimensional
coordinates are provided for s and t. The graph
weights are chosen by the best convex reconstruction
from 6 and 10 neighbors. As can be seen from the ﬁg-
ure, the two curves are automatically aligned to each
other by sharing a common embedding space. From
this common embedding, a point on the s-curve can be
mapped to the corresponding point on the wave sur-
face using nearest neighbors, without inferring a direct
transformation between the two data spaces.
In [18, 17] the authors assumed symmetric and nonneg-
ative weights. With an asymmetric L, the quadratic

term in (4) is no longer valid, and the smoothness term
may be replaced with the squared error cost (3). How-
ever, there is a diﬀerence in the resulting aligned em-
beddings using a diﬀerent choice of edge weights on
the graph. This is illustrated in the right side of Fig-
ure 3 where convex and aﬃne weights are used. With
convex weights, the aligned embedding of unlabeled
points lies within the convex hull of labeled points. In
contrast, the aﬃne weights can extrapolate to points
outside the convex hull of the labeled examples. If we
consider the matrix of coeﬃcients M = −(Luu)−1Lul
j Mij = 1 for all i
j Lij = 0 for all
i. Consequently, each row of M are aﬃne coeﬃcients.
With an additional constraint Wij ≥ 0, the M satisﬁes
Mij ≥ 0 as well, (refer to [4] for proofs) rendering each
row of M convex coeﬃcients.

in (6), it is not diﬃcult to see P
because P
j∈l Lij = P

j∈u Lij +P

3.2 Alignment by pairwise correspondence

Given multiple data sets containing no additional in-
formation about intrinsic coordinates, it is still possi-
ble to discover common relationships between the data
sets using pairwise correspondences. In particular, two
data sets X and Y may have subsets Xl and Yl which
are in pairwise alignment. For example, given sets of
images of diﬀerent persons, we may select pairs with
the same pose, facial expression, etc. With this ad-
ditional information, it is possible to then determine
how to match the unlabeled examples using an aligned
manifold embedding.
The pairwise correspondences are indicated by the in-
dices xi ↔ yi, (i ∈ l), and f and g denote real-valued
functions deﬁned on the respective graphs of X and Y .
f and g represent embedding coordinates that are ex-
tracted separately for each data set, but they should

s-curve   Intrinsic coordinateswaveRaw embeddingAligned embedding123equivalent to

min
h

˜C(h) := hT Lzh
hT h

where Lz is deﬁned as

, s.t. hT e = 0,

(10)

(cid:21)

Lz =

−U xy
Ly + U y

≥ 0,

(11)

and U x,U y,U xy, and U yx are matrices having non-zero
elements only on the diagonal

−U yx

(cid:20) Lx + U x
(cid:26) µ,

Uij =

0,

i = j ∈ l
otherwise

The r-dimensional embedding is obtained by the r-
nonzero eigenvectors of Lz. A slightly diﬀerent em-
bedding results from using the normalized cost func-
tion (9):

˜C(f , g) :=

f T Dxf + gT Dyg

,

C(f , g)

ii = P

P

j W x

j W y

ij and Dy

where Dx and Dy are diagonal matrices correspond-
ing to the vertex degrees Dx
ii =
ij. This optimization is solved by ﬁnding the
generalized eigenvectors of Lz and Dz = diag(Dx, Dy).
In (8) the coeﬃcient µ weights the importance of the
correspondence term relative to the smoothness term.
In the limit µ → ∞, the result is equivalent to impos-
ing hard constraints fi = gi for i ∈ l. In this limit, the
optimization is given by the eigenvalue problem:

where h and Lz are deﬁned as

˜C(h) := hT Lzh
hT h

 , Lz =

 Lx

 f l = gl

f u
gu

h =

, s.t. hT e = 0,

ll + Ly
Lx
ul
Ly
ul

ll Lx
Lx
uu
0

lu Ly
lu
0
Ly
uu

(12)

 .

(13)
This formulation results in a smaller eigenvalue prob-
lem than (10), and the parameter µ need not be ex-
plictly determined.
The two methods in (11) and (13) of constructing a
new graph Laplacian Lz can be interpreted as joining
two disparate graphs. The former deﬁnition of Lz links
two graphs by adding edges between paired vertices
of the graphs with weights µ, whereas the latter Lz
“short-circuits” the paired vertices. In either case, the
embedding of the joint graph automatically aligns the
two constituent graphs.
Figure 4 shows the alignment of the embeddings of s-
curve and wave surfaces via the hard coupling of the
graphs. Joining the two graphs not only aligns each
other, but also highlights the underlying structure in
common, yielding slightly more uniform embeddings
than the unsupervised ones.

Figure 3: Embedding a data manifold with given coor-
dinates. A set of 698 images of a statue was taken by a
camera with varying tilt and pan angles as pose param-
eters. These pose parameters are provided as labeled
coordinates for chosen imges (large dots). This in-
formation is used to infer the two-dimensional coordi-
nates corresponding to poses of the unlabeled images.
Diﬀerent conditions for weights in the graph Laplacian
result in quite diﬀerent embeddings.

take similar values for corresponding pairs. General-
izing the single graph embedding algorithm, the dual
embedding can be deﬁned by optimizing:

C(f , g) = µ

|fi − gi|2 + f T Lxf + gT Lyg,

(8)

X

i∈l

where Lx and Ly are the graph Laplacian matrices.
The ﬁrst term penalizes discrepancies between f and g
on the corresponding vertices, and the second term im-
poses smoothness of f and g on the respective graphs.
However, unlike the regression in (4), the optimiza-
tion in (8) is ill-deﬁned because it is not invariant to
simultaneous scaling of f and g. We instead should
minimize the Rayleigh quotient:

˜C(f , g) := C(f , g)
f T f + gT g

(9)

This quotient can be written in terms of the aug-
mented vector: h = [f T gT ]T . Minimizing (9) is then

00.5100.5100.5100.5100.5100.5100.5100.5100.5100.51Intrinsic coordinatesAligned embedding (convex)Aligned embedding (affine)Raw embedding (convex)Raw embedding (affine)124Figure 4: The graph embeddings of the s-curve and wave surface are aligned by pairwise correspondence. 100
pairs of points in one-to-one correspondence are indicated by lines (only 50 shown).

4 Applications

The goal of aligning manifolds was to ﬁnd an bi-
continuous map between the manifolds. A common
embedding space is ﬁrst learned by incorporating ad-
ditional information about the data samples. We can
use this common low-dimensional embedding space to
address the following matching problems. What is the
most relevant sample yi ∈ Y that corresponds to a
xj ∈ X? or the most relevant sample xi ∈ X that
corresponds to a yj ∈ Y ?
The Euclidean distance of samples in the common
embedding space can provide a relevant measure for
matching. Let F = [f 1f 2 ··· f r] and G = [g1g2 ··· gr]
be the r-dimensional representations of aligned mani-
folds of X and Y . If the coordinates in F and G are
aligned from known coordinates, the distance between
xi ∈ X and yj ∈ Y is deﬁned by the usual distance:

d(xi, yj)2 :=X

|Fik − Gjk|2.

consists of 120 × 100 images obtained by varying the
pose of a person’s head with a ﬁxed camera. Data
set Y are 64 × 64 computer generated images of a 3-
D model with varying light sources and pan and tilt
angles for the observer. Data set Z are 100 × 100 ren-
dered images of the globe by rotating its azimuthal and
elevation angles. For Y and Z we know the intrinsic
parameters of the variations: Y varies through -75 to
75 degrees of pan and -10 to 10 degrees of tilt, and
-75 to 75 degrees of light source angles. Z contains of
-45 to 45 degrees of azimuth and -45 to 45 degrees for
elevation changes. We use the pan and tilt angles of
Y and Z as the known 2-D coordinates of the embed-
dings. Aﬃne weights are determined with 12,12, and
6 nearest neighbors to construct the graphs of data X,
Y , and Z.
We describe how both known pose coordinates as well
as pairwise correspondences are used to align the im-
age manifolds from the three diﬀerent data sets.

k

If F and G are computed from normalized eigenvec-
tors of a graph Laplacian, the coordinates should be
properly scaled. We use the eigenvalues λ1, λ2,··· , to
scale the distance between xi and yi [10]:
|Fik − Gjk|2/λk.

d(xi, yj)2 :=X

k

Then the best match yi ∈ Y to x ∈ X is given by
ﬁnding arg mini d(x, yi).
We demonstrate matching image examples with three
sets of high-dimensional images. The three data sets
X, Y , and Z consist of 841 images of a person, 698
images of a statue, and 900 images of the earth,
available at http://www.seas.upenn.edu/∼jhham and
http://isomap.stanford.edu/datasets.html. Data set X

Matching two sets with correspondence and
known coordinates

The task is to align X and Y using both the correspon-
dences of X ↔ Y , and the known pose coordinates of
Y . First, 25 matching pairs of images in X and Y
are manually chosen. The joint graph of X and Y is
formed by fusing the corresponding vertices as in (13).
Then the joint graph is aligned to the 25 sample co-
ordinates of Y by (6). The best matching images in
X and Y that correspond to various pose parameters
are found by nearest image samples in the embedding
space. Figure 5 shows the result when 16 grid points
in the pose parameter embedding are given and the
best matching images in X and Y are displayed.

s-curvewaveRaw embeddingAligned embedding125Figure 5: Matching two data sets with correspondence and external coordinates. 25 images of a statue are
parameterized by its tilt/pan angles (gray dots on the left). Additionally, 25 corresponding pairs of images of
the statue and person are manually matched. Given 16 queries (dark dots on the left) in the embedding space,
the best matching images of statue (middle) and person (right) are found by aligning the two data sets and pose
parameters simultaneously.

Matching three sets with correspondence

We also demonstrate the simultaneous matching of
three data sets. Among the three data sets, we have
pairwise correspondence between example images in
X ↔ Y and examples images in Y ↔ Z separately.
25 pairs of corresponding images between X and Y
are used, and an additional 25 pairs of images in Y
and Z are chosen manually. The joint graph of X, Y ,
and Z is formed by the straightforward extension of
(12) to handle three sets. A joint graph Laplacian is
formed and the ﬁnal aligned embeddings of the three
sets are computed by diagonalizing the graph Lapla-
cian. Given unlabeled sample images from Z as input,
the best matching data for Y and X are determined
and shown in Figure 6.

5 Discussion

The main computational cost of the graph algorithm
lies in ﬁnding the spectral decomposition of a large ma-
trix. We employ methods for calculating eigenvectors
of large sparse matrices to eﬃciently speed computa-
tion of the embeddings. The graph algorithm is able
to quite robustly align the underlying manifold struc-
ture in these data sets. Even with the small number
of training samples provided, the algorithm is able to
estimate a common low-dimensional embedding space
which can be used to map samples from one data set
to another. Even in situations where the unsupervised
manifold learning algorithm suﬀers from a lack of sam-
ples, additional knowledge from the known coordinates
and/or pairwise correspondences can be used to dis-
cover a faithful embedding. We are currently work-
ing on extending these results on additional real-world

data sets such as video streams and audio signals.
Finally, we would like to acknowledge support from
the U.S. National Science Foundation, Army Reser-
ach Oﬃce, and Defense Advanced Research Projects
Agency.

References

[1] D. Aldous and J. Fill. Reversible Markov chains
and random walks on graphs, 2002. In prepara-
tion.

[2] M. Belkin, I. Matveeva, and P. Niyogi. Regular-
ization and regression on large graphs.
In Pro-
ceedings of 17th Annual Conference on Learning
Theory, pages 624–638, 2004.

[3] M. Belkin and P. Niyogi. Laplacian eigenmaps for
dimensionality reduction and data representation.
Neural Computation 15, pages 1373–1396, 2003.

[4] A. Berman and R. J. Plemmons. Nonnegative
Matrices in the Mathematical Science. Academic
Press, New York, 1996.

[5] M. Brand. Charting a manifold. In Advances in
Neural Information Processing Systems 15, pages
961–968, Cambridge, MA, 2003. MIT Press.

[6] A. K. Chandra, P. Raghavan, W. L. Ruzzo, and
R. Smolensky. The electrical resistance of a graph
captures its commute and cover times. In Proceed-
ings of the twenty-ﬁrst annual ACM symposium
on Theory of computing, pages 574–586. ACM
Press, 1989.

Queries (coordinates)Match 1Match 200.5100.20.40.60.81126Figure 6: Matching three data sets using correspondence between 25 image pairs of statue and person, and 25
additional image pairs of statue and earth. After the aligned embedding of the joint graph is computed, it is
possible to match images across the three data sets. Given the left images of the earth as queries, the right
ﬁgures show the best matching images of the statue (middle) and person (right).

[14] L. K. Saul and S. T. Roweis. Think globally,
ﬁt locally: unsupervised learning of low dimen-
sional manifolds. Journal of Machine Learning
Research, 4, pages 119–155, 2003.

[15] J. Tenenbaum, V. de Silva, and J. C. Langford.
A global geometric framework for nonlinear di-
mensionality reduction. Science, 290, pages 2319–
2323, 2000.

[16] J. J. Verbeek, S. T. Roweis, and N. Vlassis. Non-
linear CCA and PCA by alignment of local mod-
els. In Advances in Neural Information Processing
Systems 16, 2004.

[17] D. Zhou and B. Sch¨olkopf. A regularization
framework for learning from graph data. In Work-
shop on Statistical Relational Learning at Twenty-
ﬁrst International Conference on Machine Learn-
ing, 2004.

[18] X. Zhu, Z. Ghahramani, and J. Laﬀerty. Semi-
supervised learning using gaussian ﬁelds and har-
monic functions. In Proceedings of International
Conference on Machine Learning, pages 912–919,
2003.

[7] D. L. Donoho and C. Grimes. Hessian eigen-
maps:
locally linear embedding techniques for
high-dimensional data. In Proceedings of National
Academy of Science, 100 (10), pages 5591–5596,
2003.

[8] M. Fiedler. A property of eigenvectors of non-
negative symmetric matrices and its applications
to graph theory. Czechoslovak Math Journal, 25
(100), pages 619–633, 1975.

[9] S. Guattery. Graph embeddings, symmetric real
matrices, and generalized inverses. Technical Re-
port NASA/CR-1998-208462 ICASE Report No.
98-34, Institute for Computer Applications in Sci-
ence and Engineering, August 1998.

[10] J. Ham, D. D. Lee, S. Mika, and B. Sch¨olkopf.
Kernel view of the dimensionality reduction of
manifolds. In Proceedings of International Con-
ference on Machine Learning, 2004.

[11] J. Ham, D. D. Lee, and L. K. Saul. Learn-
ing high-dimensional correspondences from low-
dimensional manifolds. In Workshop on The Con-
tinuum from Labeled to Unlabled Data in Machine
Learning and Data Mining at Twentieth Inter-
national Conference on Machine Learning, pages
34–39, 2003.

[12] I. Kondor and J. Laﬀerty. Diﬀusion kernels on
graphs and other discrete structures.
In Pro-
ceedings of International Conference on Machine
Learning, 2002.

[13] S. T. Roweis and L. K. Saul. Nonlinear dimen-
sionality reduction by locally linear embedding.
Science, 290, pages 2323–2326, 2000.

Match 1Match 2Queries (samples)127Learning Causally Linked Markov Random Fields

G. E. Hinton, S. Osindero and K. Bao

Department of Computer Science

University of Toronto

Toronto, Canada M5S 3G4

Abstract

2 Learning Causal Models

We describe a learning procedure for a gen-
erative model that contains a hidden Markov
Random Field (MRF) which has directed
connections to the observable variables. The
learning procedure uses a variational approx-
imation for the posterior distribution over the
hidden variables. Despite the intractable par-
tition function of the MRF, the weights on
the directed connections and the variational
approximation itself can be learned by max-
imizing a lower bound on the log probability
of the observed data. The parameters of the
MRF are learned by using the mean (cid:12)eld ver-
sion of contrastive divergence [1]. We show
that this hybrid model simultaneously learns
parts of objects and their inter-relationships
from intensity images. We discuss the exten-
sion to multiple MRF’s linked into in a chain
graph by directed connections.

One way to make generative models with stochastic
hidden variables is to use a directed acyclic graph as
shown in Figure 1 (a). The di(cid:14)culty in learning such
\causal" models is that the posterior distribution over
the hidden variables is intractable (except in certain
special cases such as factor analysis, mixture mod-
els, square ICA or graphs that are very sparsely con-
nected). Despite the intractability of the posterior,
it is possible to optimize a bound on the log proba-
bility of the data by using a simple factorial distri-
bution, Q(hjx), as an approximation to the true pos-
terior, P (hjx) over hidden con(cid:12)gurations, h, given a
data-vector, x. If the hidden variables are binary, a
factorial distribution can be represented by assigning
a probability, qj to each hidden variable, j:

Q(hjx) = Y

j

q

hj

j (1 (cid:0) qj)1(cid:0)hj

(1)

where hj is the binary state of hidden unit j in hidden
con(cid:12)guration h. Neal and Hinton [2] show that:

(cid:0) logP (x) = F(x) (cid:0) KL(Q(hjx)jjP (hjx))

(2)

1

Introduction

where the F denotes the ‘variational free-energy’ of
the data and is given by
F(x) = X

Q(hjx) log Q(hjx)(cid:0)X

Q(hjx) log P (h; x)

h

h

Generative models are widely used within machine
learning. However, in many applications the graph-
ical models involve exclusively causal, or exclusively
undirected edges.
In this paper we consider models
that contain both types of edge, and suggest approx-
imate learning methods for such models. The main
contribution of this paper is the proposal of combining
variational inference with the contrastive divergence
algorithm to facilitate learning in systems involving
causally linked Markov Random Fields (MRF’s). We
support our proposal with examples of learning in sev-
eral domains.

(3)
where x is a data-vector and P (h; x) is the joint prob-
ability of (cid:12)rst generating h from the model, and then
generating x from h.

Since the intractable KL divergence term in equation
2 is non-negative, the variational free-energy, F, gives
a tractable upper bound on the negative log probabil-
ity of the data. Minimizing this bound also has the
useful property that it tends to adjust the parameters
to make the true posterior distribution as factorial as
possible which makes factorial approximate inference
work well in the learned model.

128j

j

G

ij

i

G

ij

i

a(

)

W

jk

c(

)

 

 

k

j

G

ij

i

l

j

W jk

b(

)

d(

)

k

 

Figure 1: (a) A \causal" generative model. (b) A Markov
random (cid:12)eld (MRF) with pairwise interactions between the
variables. (c) A hybrid model in which the hidden variables
of a causal generative model form a Markov random (cid:12)eld.
(d) A causal hierarchy of MRF’s.

For each data-vector in the training set, a locally opti-
mal factorial approximation to the true posterior can
be found by following the gradient of the bound w.r.t.
Q. Alternatively, the same gradient can be used to
train a feedforward \recognition" network to map each
training case to a good Q. Once it has been learned,
the feedforward network can be viewed as a way of
caching the results of iterative settling whilst also
acting as a regularizer that encourages similar data-
vectors to use similar Q distributions.

3 Learning Markov Random Fields

Hidden latent causes are a good way to model some
types of correlation, but they are not good at modeling
constraints between variables1. Consider, for example,
a spherical, zero-mean, 20-dimensional Gaussian that
has been projected onto the plane in which the sum
of the coordinates is 1. To capture this constrained
distribution, factor analysis requires 19 hidden factors
because it must use a very tight noise model on all
20 variables and then use hidden factors to increase
the variance in the 19 allowable directions of variation.
Hidden ancestral variables cannot be used to decrease
variance2.

A better way to model constraints is to use an \energy-
based" model that associates high energies with data-

1In a directed graph, this requires observed descendants.
2Assuming the factor loadings do not use imaginary

components to create negative variance.

vectors that violate constraints. The probability of a
data-vector is then de(cid:12)ned in terms of its energy using
the Boltzmann distribution:

P (x) =

e(cid:0)E(x)

Z

;

Z = X

u

e(cid:0)E(u)

(4)

where x is a data-vector, E(x) is its energy, and u is
an index over all possible data-vectors.

The main di(cid:14)culty in learning energy-based models
comes from the normalizing term, Z, (called the par-
tition function) in Eq 4. This is an intractable sum
or integral over all possible data-vectors. If a Markov
chain is used to sample vectors, u from the distribution
de(cid:12)ned by the model, it is possible to get an unbiased
estimate of the gradient of the log probability of the
data:

@ log P (x)

@(cid:18)

= (cid:0)

@E(x)

@(cid:18)

+ X

u

P (u)

@E(u)

@(cid:18)

(5)

However, the estimate of the gradient will be very
noisy and it is typically hard to know how long to
run the Markov chain before it is sampling from the
model’s distribution. In practice, it is common to as-
sume that if the learning works, the Markov chain
must have been close to its equilibrium distribution
| a dubious inference.

In some energy-based models, such as a Boltzmann
machine with interconnected hidden variables,
it is
necessary to sum over all possible con(cid:12)gurations of the
hidden variables to compute the numerator in Eq 4.
In other energy-based models, such as \fully visible"
Boltzmann machines that just have lateral connections
between the visible units it is easy to compute the en-
ergy of a data-vector3 but it is still hard to get the
exact derivatives of the partition function. For models
of this type, Hinton [3] has shown that learning can
still work very well if a Markov chain is started at the
data and then run for just a few steps instead of being
run all the way to equilibrium.

The use of a brief Markov chain can be combined with
the mean (cid:12)eld approximation in which the distribution
over binary con(cid:12)gurations is represented by a factorial
distribution Q [1]. For fully visible Boltzmann ma-
chines, this leads to a learning algorithm in which the
network starts at a data-vector and then updates the
q values of all the units in parallel using the rule:

qt+1
j = (cid:21)qt

j +

1 (cid:0) (cid:21)

(6)

1 + exp((cid:0)bj (cid:0) Pk qt

kwjk)

3Other models that fall within this class include \re-
stricted Boltzmann machines" in which there are no inter-
connections between hidden units and also models in which
the global energy is a function of the activities of multiple
layers of deterministic, non-linear hidden units.

129where bj is the bias of unit j, wjk is a symmetric con-
nection between unit j and unit k, and (cid:21) is a damping
coe(cid:14)cient between 0 and 1 that is used to prevent os-
cillations. Using the parallel updates in Eq. 6, the
learning rule in Eq. 5 becomes:

(cid:1)wjk / X

cases

j q+
q+

k (cid:0) q(cid:0)

j q(cid:0)

k

(7)

where the q+ values are the the components of a train-
ing vector and the q(cid:0) values are produced by allowing
the mean (cid:12)eld net to run for a few iterations of equa-
tion 6. The q+ values would normally be binary, but
the learning procedure can still be applied if each train-
ing case is a factorial distribution over binary vectors.

4 Causally Linked Markov Random

Fields

Both purely causal models and MRF’s are used exten-
sively within machine learning, but there are notice-
ably fewer models in the literature that employ both
causal and undirected connections 4. Causal hierar-
chies of MRF’s (chain-graphs) have some very attrac-
tive properties as generative models (see below) but
the problem of learning them e(cid:14)ciently when there is
dense connectivity has not been adequately addressed.

To generate data from such a model[6], we (cid:12)rst run the
top-level MRF to equilibrium and pick a con(cid:12)guration
from the distribution de(cid:12)ned by its energy function.
This con(cid:12)guration then provides top-down input to
the MRF at the next level down via the causal connec-
tions. The top-down input modi(cid:12)es the energy func-
tion of the second level MRF by changing the e(cid:11)ective
biases of its units5. We then run the second level MRF
using its modi(cid:12)ed energy function and pick a con(cid:12)gu-
ration from its distribution. This can be repeated for
as many levels as desired, with the bottom level being
the \visible" units which may or may not be connected
together in an MRF.

This generative model has a major advantage over a
purely causal hierarchy: At each level of the hierarchy,
learned constraints can be used to \clean-up" the rep-
resentations generated from the level above. Consider,
for example, a generative model in which the top level
represents the pose parameters of a face and the next
level down represents the pose parameters of each of
the two eyes. The height of an eye within the face is
somewhat variable, but the two eyes are constrained
to have the same height. This creates a problem for
a purely causal hierarchy in which the poses of the

4Such models are formally referred to as chain-graphs;

see for example [4, 5].

5It could also modify pairwise interactions between

units in the lower-level MRF.

left and right eye are conditionally independent given
the representation at the level above. The height of
both eyes must be chosen at the top level and then
the height of each eye must be communicated very ac-
curately to the level below. But if an MRF can be used
for clean-up at the level below, the height of each eye
can be loosely determined by the top-down input, and
the MRF can then enforce the constraint on the two
heights. So the top-down input to each level can be
used to select between (and distort) highly structured
and (cid:12)nely balanced alternatives rather than having to
specify a pattern in full detail. The causal connections
are adept at suggesting which ‘parts’ to instantiate
and roughly where to put them, whilst the undirected
connections within the MRF are ideal for enforcing
consistency relationships between these parts.

As we shall see, combining multiple MRF’s into causal
hierarchies also has a major advantage over combining
them into one big MRF by using undirected connec-
tions: The causal connections between layers act as
insulators that prevent the partition functions of the
individual MRF’s from combining together into one
large partition function.

5 A simple version of the model

We begin by presenting the simplest architecture from
the framework we have just described: a single, hid-
den MRF layer with causal connections to a layer of
observed variables as illustrated by the network shown
in Figure 1 (c).

For concreteness, we will work with a particular simple
form for the model’s interactions, although more elab-
orate cases can be treated in essentially the same way.
The hidden MRF layer will consist of a Boltzmann ma-
chine which has binary nodes with pairwise interaction
energies of the form E(hi; hj) = hihj wij, and single
node energies of the form E(hi) = bihi where hk is the
binary state of node k and fwij ; big are free param-
eters to be learned. Conditioned upon these hidden
variables, the directed connections in our model spec-
ify a Gaussian distribution on the observables with
P (xjh) = N (Gh + m; (cid:27)I) where (cid:27) is a pre-speci(cid:12)ed
noise variance6.

We use a single-layer sigmoid recognition network to
specify the q’s of the posterior approximation in equa-
tion 1 and the probabilities are given by

qi = (cid:18)1 + e

(cid:0)Pj

Rij xj +ci(cid:19)(cid:0)1

(8)

where fRij ; cig are parameters to be learned 7.

6We (cid:12)x (cid:27) for simplicity, but it could also be learned.
7The derivatives that are used to train this recognition

130Our formalism leads to the following expression for the
variational free energy,

F = FMRF + FGauss

(9)

FMRF = X

i

[qi log qi + (1 (cid:0) qi) log(1 (cid:0) qi)]

(cid:0)

1
2

qT Wq (cid:0) bT q + log Z

(10)

FGauss =

1
2(cid:27)2 (cid:0)qT GT Gq (cid:0) 2xT Gq(cid:1)
+qT K(1 (cid:0) q) + c

(a)

(11)

(b)

(c)

(d)

(e)

where Kij = (cid:14)ij(GT G)ij, and c denotes constants that
do not a(cid:11)ect the derivatives of F w.r.t. the parame-
ters. Minimising F is equivalent to maximising a lower
bound on the data log-likelihood.

A crucial property of this model is that the intractable
log Z term only depends on the biases and lateral con-
nections of the hidden units.
It does not enter into
the derivatives of either the q+ values or the weights
on the causal connections. So the recognition weights
(R; c) that determine the q values, and also the causal
generative parameters (G; m), can be learned by us-
ing the exact gradient of the cost function To learn the
hidden biases and the lateral weights (b; W) between
hidden units, we allow the hidden units to run for a
few mean (cid:12)eld iterations from their initial q values and
then use the contrastive divergence learning rule [3], as
given in equation 7.

6 A toy example

To illustrate the model we used 50,000 24x24 images of
the digit seven that were generated by small rotations,
translations and scalings of 1000 normalized 16x16 im-
ages from the Cedar CD-Rom. The distortions re-
duced the long-range correlations introduced by the
normalization. We trained a network with 64 fully
inter-connected hidden units for 500 sweeps through
the training set updating the weights after every 250
examples. There was very little change in the weights
after 80 sweeps. We used a momentum of 0:9 with
learning rates of 10(cid:0)4 for the causal generative connec-
tions and visible biases and for the recognition connec-
tions and biases, and 10(cid:0)5 for the lateral connections
and hidden generative biases. We also implemented
L1 weight-decay corresponding to a Laplacian prior on
the lateral connections. This aids interpretability by
making most lateral connections small or zero, whilst
also allowing large values for a few weights.

Figure 2 (a) and (b) show the generative weights of all
64 hidden units, along with examples of lateral inter-

A

B

C

D

E

F

G

H

X

1

2

3

4

5

6

7

8

X

X

1A

2A

2B

X

7H

Figure 2: (a) The generative weights of all 64 hidden units
in a model of handwritten 7’s. (b) The lateral connection
patterns for units 1A, 1C, 3F and 7H. The X marks the
location of the unit itself. Note the positive interactions
between units with collinear generative (cid:12)elds (e.g. 7H and
2G) and also the sizeable negative weights between mutu-
ally exclusive alternatives (e.g. 2A and 4A). Unit 2B ap-
pears to be a corner detector, and its interactions with 4A
and 6B match this intuition. (c) Examples of the training
data used. (d) Samples from the distribution learned by
the model (obtained using prolonged Gibbs sampling.) (e)
Samples from a model with the same generative parame-
ters as in (a,d) but with the lateral connections set to zero,
and the biases re-learned to compensate. Notice that there
is much less consistency between the strokes in the samples
generated from the model without lateral connections.

action patterns for 4 representative units. The (cid:12)gure
caption highlights some salient aspects of the learned
lateral connections.

7 Learning to model natural objects

as inter-related parts

network could be used to train a far more powerful recog-
nition network that contained hidden layers.

It is hard to model real-valued images using binary
hidden units so we use binomial units that are equiv-

1311

2

3

4

5

6

7

8

1

2

3

4

5

6

7

8

9

10 11 12 13 14 15 16

A

B

C

D

E

F

G

H

A

B

C

D

E

F

G

H

I

J

K

L

M

N

O

P

X

X

X

3D

6A

X
5H

7B

X

6H

X

6K

X

8E

X

9K

Figure 3: The results of applying the learning algorithm to
images of faces. The generative weights of the hidden units
are shown at the top and the lateral connections of some
of the hidden units are shown beneath. The 8; 400 31x31
training images were created by rotating ((cid:6)30(cid:14)), scaling
(1.0 to 1.5), cropping and subsampling the 400 face images
of 40 di(cid:11)erent people in the Olivetti face dataset. Each
cropped image was then centred (zero pixel mean) and
PCA was used to whiten the data and reduce the dimen-
sionality from 961 to 144 by maintaining the normalised
projections on the leading 144 eigenvectors.

Figure 4: The generative weights of 256 hidden units
trained on 150; 000 12x12 patches of natural images ex-
tracted from Hyvarinen’s natural image data. The images
were whitened and reduced to 100 dimensions using cen-
tering and PCA. The lateral interactions were restricted
to a 9x9 neighborhood with wraparound. There are strong
negative interactions between anti-phase pairs f6H, 3Gg
& f8E, 6Fg and also between highly non-collinear pairs
f6H, 5Hg, f6K, 5Hg, f6K, 5Ig, f6K, 9Lg. The interac-
tions between approximately collinear pairs with consistent
phase are usually positive: f6H, 2Dg, f6H, 5Gg, f6K, 2Lg.

alent to replicating each hidden unit (together with
all its weights) N = 100 times [7]. We also make
an additional modi(cid:12)cation that is motivated by a de-
sire to produce more neurally plausible representation
schemes. The variance contributed by a binomial pool
of N binary units each of which has a probability of
q of turning on is N q(1 (cid:0) q). (This appears through
the term qT K(1 (cid:0) q) in equation 11.) If we omit the
(1 (cid:0) q) term, binomial units cannot use values of q
near 1 to achieve low variance and so they learn to use
small values of q and behave like Poisson units whose
variance is linear in their \(cid:12)ring rate".

Figure 3 shows the weights learned by a network with
64 hidden Poisson units when it was trained on images
of faces.

After learning, the hidden activities are sparse with
a small subset of the units having activities signi(cid:12)-
cantly above their baseline for each image. The ability

to learn parts and their relationships simultaneously
should make it easier to achieve the goal of (cid:12)nding
natural parts of objects in sets of unlabelled images
[8], but we have not yet had time to explore this issue
in detail. Unlike non-negative matrix factorization [9]
our model learns parts without requiring any restric-
tions on the weights, but it is possible that it would
be even better at extracting parts if we restricted the
weights on the causal connections to be positive.

Clearly, it would be better to perform some extrac-
tion of low level features before attempting to extract
inter-related parts of complex objects. Figure 4 shows
the results of applying exactly the same algorithm to
patches of natural images.

1328 Learning with multiple hidden

layers

Ideally, a whole hierarchy of features at di(cid:11)erent levels
should be learned cooperatively in order to encourage
low-level features to be useful for extracting high-level
parts that have consistent inter-relations. Our model
is proposed with multiple hidden layers in mind, how-
ever we have only just started to investigate this em-
pirically.

We now present the free energy, F2, for a model with
two hidden MRF layers, with the ‘top’ layer having a
directed in(cid:13)uence on the layer below (as shown in Fig-
ure 1 (d)). If we are able to adequately tackle the ex-
tra complexity involved in learning such a model then
the generalisation to hierarchies of arbitrary depth in-
volves relatively little extra e(cid:11)ort. We will now use
hm and ht to denote the binary states of hidden units
in the middle and top MRF layers respectively. As
before, Q(hmjx) will denote the a factorial approx-
imation to the posterior probabilities for the MRF
units connected to the observables, and we will use
R(htjx) to denote the factorial approximation for the
MRF units in the top layer.

F2 = X

ht

R(htjx) log R(htjx)

Q(hmjx) log Q(hmjx)

R(htjx) log P (ht)

+X

hm

(cid:0)X

ht

(cid:0) X

ht;hm

R(htjx)Q(hmjx) log P (hmjht)

Q(hmjx) log P (xjhm)

(12)

(cid:0)X

hm

The main di(cid:11)erence between this free energy and the
one which we have already dealt with is due to the
term Pht;hm R(htjx)Q(hmjx) log P (hmjht). The par-
tition function of the middle layer MRF now depends
on the states in the top layer MRF. Consequently we
are required to deal with an expectation over partition
functions as one of the terms within our free energy.
Again for concreteness we (cid:12)rst present the mathemat-
ical form of the free energy for a simple case before
discussing an initial approximation for overcoming this
di(cid:14)culty. Our model now involves two Boltzmann ma-
chine layers, as illustrated by Figure 1 (d), and condi-
tioning on the states of the top layer provides an ad-
ditional bias term to the energy function of the layer
below. The factorial approximation to the posterior
on the middle layer units remains unchanged, and a
similar approximation is used for the top level units,
speci(cid:12)cally R(htjx) = Qj r

j (1 (cid:0) rj)1(cid:0)ht

j . As before,

ht

j

the observables are given by a Gaussian distribution
conditioned on the states of the middle layer units.
The free energy is given by,

F2 = X

j

[rj log rj + (1 (cid:0) rj) log(1 (cid:0) rj)]

[qi log qi + (1 (cid:0) qi) log(1 (cid:0) qi)]

i

(cid:0)

rT Hr (cid:0) cT r + log ZTOP

+X
1
2
1
(cid:0)
2
+ (cid:10)log ZMID(ht)(cid:11)ht(cid:24)R(htjx)
+FGauss

qT Wq (cid:0) (b + r)T q

(13)

One strategy is to replace the expectation over parti-
tion functions with the partition function evaluated at
the expected value of ht, i.e. at ht = r. This can be
viewed as a (cid:12)rst order Taylor series approximation to
log ZMID(ht) about the mean of R(htjx) (higher order
expansions might also be feasible, however the terms
are much more complicated.) Such an approximation
means that the free energy is no longer a bound on the
true log likelihood, however we are at present unaware
of any other tractable approximation that would allow
us to maintain such a bound.

In this new approximation we use contrastive diver-
gence both to estimate derivatives of the lateral con-
nections and MRF biases, and also to compute a com-
ponent of the derivative with respect to the top level
activities, r. (From the point of view of forming deriva-
tives, the top level units simply act as case dependent
biases.)

Preliminary experiments using models with two MRF
layers causally linked into a hierarchy indicate that
this approximation might be adequate for our gradient
based learning. The ‘middle’ MRF layer typically de-
velops features that are qualitatively similar to those in
the single layer case. The ‘top’ level units tend to sensi-
bly co-activate sets of units in the ‘middle’ layer, how-
ever it is hard to properly characterise the behaviour
of units deeper within a densely connected network
and their e(cid:11)ects are not always apparent simply by
studying the generative weights.

To illustrate the increased representational power
achieved by adding an additional MRF layer, we
present somewhat qualitative results from a simple ex-
periment again using the Cedar digits. Our data con-
sisted of 1100 16 (cid:2) 16 images of each class type from 0
to 9 (that is 11000 training examples in total). Figure
5 (a) shows an example of the training data. Using this
dataset, we trained two di(cid:11)erent model architectures:
the (cid:12)rst had a single hidden Boltzmann machine layer

133consisting of 256 fully interconnected units; the second
had two hidden Boltzmann machine layers, again with
256 fully interconnected units within each layer, and
with directed connections from the top layer providing
additional biases to the middle layer. We trained both
networks until the changes in parameters were very
small (approximately 500 sweeps through the whole
data set). Figures 5 (b) and (c) illustrate generative
samples from models with one and two hidden MRF
layers respectively. From this qualitative comparison
it is immediately apparent that the model with a hi-
erarchy of MRF layers has managed to capture more
of the statistical structure within the dataset. The
generated samples in Figure 5 (b) somewhat resemble
single digits, but they are also rather contaminated by
additional strokes | as if several digits classes were
combined. This contamination is present to a much
smaller degree in Figure 5 (c) in which we can see
clearer examples of single digits being generated. We
speculate that the additional hidden layer is bene(cid:12)cial
by providing top down biases to shift the middle layer
activities in favour of the strokes for particular digit
classes, which might then make the task of ensuring
‘stroke consistency’ easier for the lateral connections
within that layer.

9

Improving the accuracy of
approximate inference

There are several reasons why one might wish to use
models containing both directed and undirected con-
nections. As discussed in Section 4 they are elegantly
able to capture some kinds of statistical structure
which would be di(cid:14)cult to capture using connections
of just one type. In particular, hierarchies of MRF’s
have many appealing properties that make them suit-
able for learning parts-based representations.

Another quite di(cid:11)erent reason for choosing to combine
elements of both kinds of model is to allow approxi-
mate inference techniques to work more e(cid:11)ectively, and
this bene(cid:12)t can be seen in the case of even just a sin-
gle hidden MRF layer. Many approximate inference
techniques assume some simplifying independence re-
lationships, but such relationships generally do not,
and cannot, hold in the true posterior.
In particu-
lar, if the latent variables are assumed to be indepen-
dent in the prior, an e(cid:11)ect known as ‘explaining-away’
causes those variables to coupled in the posterior [10].
However, somewhat counter-intuitively, it is possible
to reduce or eliminate this posterior dependence by
using a model in which the variables are coupled in
the opposite way in the prior. The required coupling
depends on the parameters, but not on the data.

Our proposed learning method is able to take advan-

(a)

(b)

(c)

Figure 5: Illustrative results from learning with multi-
ple hidden layers. (a) Examples of training data, cor-
rupted with the same amount of Gaussian noise as as-
sumed during learning. (b) Random selection of exam-
ples generated by Gibbs sampling from a model with a
single hidden layer. (c) Random selection of examples
generated by Gibbs sampling from a model with a hi-
erarchy of two MRF layers. Each MRF layer had 256
fully interconnected hidden units, and there was full
directed connectivity from the top MRF layer to the
middle MRF layer, as well as full directed connectivity
from the middle MRF layer to the observables.

tage of this fact, and to work within a space of mod-
els for which factorial inference is more accurate than
it would be able to be if directed connections alone

134were used. This point is illustrated rather nicely by
some of the lateral connections in Figure 4. The lat-
eral interactions tend to cancel out the correlations in
the posterior that would be introduced by explaining-
away. Consider, for example, two hidden units such
as 6H and 3G in Figure 4 that have highly anti-
correlated weights on their causal connections. If both
these units turn on together the image will be un-
changed, so explaining-away would make their activi-
ties be strongly positively correlated in the posterior.
By learning a strongly negative lateral interaction, the
network manages to make them approximately inde-
pendent in the posterior thus making the variational
inference work well.

The idea of using a complicated prior distribution in
order to achieve approximate independence in the pos-
terior is a very di(cid:11)erent approach from Independent
Components Analysis (ICA) [11, 12] which assumes
independence in the prior and therefore gives rise to
awkward posteriors when there are more hidden vari-
ables than observables.

10 Summary & Discussion

We have presented a learning procedure for training
models that contain both directed and undirected con-
nections; in particular we have focused on large densely
connected MRF’s that are linked to either observ-
ables or other MRF’s via directed (causal) connections.
Learning in such models is generally intractable, and
so the learning task necessitates approximations. Our
proposed method combines variational techniques with
the contrastive divergence algorithm.

Whilst initial results are promising, there is clearly
much more work to be done in developing more sophis-
ticated approximation schemes and in exploring di(cid:11)er-
ent model architectures for di(cid:11)erent types of problem.
In addition to the approximation methods we have de-
veloped in this paper, there are other schemes that
may be useful and indeed could be combined with our
approach. One could, for instance, consider running
our method until convergence and then using this so-
lution as the starting point for a much slower, but
potentially more accurate approach that uses Monte
Carlo methods. Alternatively, the learned recognition
model parameters could be used to initialise further
learning using a version of the wake-sleep algorithm
[13].

There are many domains in which hybrid models such
as the ones we have presented here might be useful,
and we hope that our suggested approximation tech-
niques open up avenues for exploration.

Acknowledgements This research was funded by

NSERC and CFI. We thank Peter Dayan, Zoubin
Ghahramani, Javier Movellan, Sam Roweis, Terry Se-
jnowski, Yee Whye Teh, Max Welling and Rich Zemel
for helpful discussions. GEH holds a Canada Research
Chair and is a fellow of CIAR.

References

[1] M. Welling and G. E. Hinton. A new learning al-
gorithm for mean (cid:12)eld boltzmann machines. In
Proc. International Conference on Arti(cid:12)cial Neu-
ral Networks, pages 351{357. 2002.

[2] R. M. Neal and G. Hinton. A view of the EM
algorithm that justi(cid:12)es incremental, sparse, and
other variants.
In M. I. Jordan, editor, Learn-
ing in Graphical Models, pages 355{368. Kluwer
Academic Publishers, 1998.

[3] G. E. Hinton. Training products of experts by
minimizing contrastive divergence. Neural Com-
putation, 14:1771{1800, 2002.

[4] S. Lauritzen and N Wermuth. Graphical models
for associations between variables, some of which
are qualitative and some quantitative. Annals of
Statistics, 17:31{57, 1989.

[5] W. L. Buntine. Chain graphs for learning.

In
Uncertainty in Arti(cid:12)cial Intelligence, pages 46{
54, 1995.

[6] S. L. Lauritzen and T. S. Richardson. Chain
graphs and their causal interpretations. Journal
of the Royal Statistical Society. Series B. Statis-
tical Methodology, 64(3):321{361, 2002.

[7] Y. W. Teh and G. E. Hinton. Rate-coded re-
stricted boltzmann machines for face recognition.
In Advances in Neural Information Processing
Systems 13. 2001.

[8] M. Weber, M. Welling, and P. Perona. Unsu-
pervised learning of models for recognition.
In
Proc. 6th European Conference on Computer Vi-
sion, 2000.

[9] D.D. Lee and H. S. Seung. Algorithms for non-
negative matrix factorization.
In Advances in
Neural Information Processing Systems 13. 2001.
[10] J. Pearl. Probabilistic Reasoning in Intelligent
Systems: Networks of Plausible Inference. Mor-
gan Kaufmann Publishers Inc., 1988.

[11] A. J. Bell and T. J. Sejnowski. An information
maximisation approach to blind separation and
blind devonvolution. Neural Cmputation, 7:1129{
1159, 1995.

[12] J.F. Cardoso. Infomax and maximum likelihood
for blind source separation. IEEE Signal Process-
ing Letters, 4:112{114, 1997.

[13] G.E. Hinton, P. Dayan, B.J. Frey, and R.M. Neal.
The "wake-sleep" algorithm for unsupervised neu-
ral networks. Science, 268:1158{1160, 1995.

135Hilbertian Metrics and Positive Deﬁnite Kernels on Probability

Measures

Max Planck Institute for Biological Cybernetics, 72076 T¨ubingen, Germany

Matthias Hein and Olivier Bousquet

{ﬁrst.last}@tuebingen.mpg.de

Abstract

We investigate the problem of deﬁning
Hilbertian metrics resp. positive deﬁnite ker-
nels on probability measures, continuing the
work in [5]. This type of kernels has shown
very good results in text classiﬁcation and
has a wide range of possible applications. In
this paper we extend the two-parameter fam-
ily of Hilbertian metrics of Topsøe such that
it now includes all commonly used Hilbertian
metrics on probability measures. This allows
us to do model selection among these met-
rics in an elegant and uniﬁed way. Second we
investigate further our approach to incorpo-
rate similarity information of the probability
space into the kernel. The analysis provides
a better understanding of these kernels and
gives in some cases a more eﬃcient way to
compute them. Finally we compare all pro-
posed kernels in two text and two image clas-
siﬁcation problems.

1 Introduction

Kernel methods have shown in the last years that they
are one of the best and generally applicable tools in
machine learning. Their great advantage is that posi-
tive deﬁnite (pd) kernels can be deﬁned on every set.
Therefore they can be applied to data of any type.
Nevertheless in order to get good results the kernel
should be adapted as well as possible to the underly-
ing structure of the input space. This has led in the
last years to the deﬁnition of kernels on graphs, trees
and manifolds. Kernels on probability measures also
belong to this category but they are already one level
higher since they are not deﬁned on the structures di-
rectly but on probability measures on these structures.
In recent time they have become quite popular due to
the following possible applications:

• Direct application on probability measures e.g.

histogram data of text [8] and colors [1].

• Given a statistical model for the data one can ﬁrst
ﬁt the model to the data and then use the kernel
to compare two ﬁts, see [8, 7]. Thereby linking
parametric and non-parametric models.

• Given a bounded probability space X one can use
the kernel to compare arbitrary sets in that space,
e.g by putting the uniform measure on each set.

In this paper we consider Hilbertian metrics and pd
+(X )1. In a ﬁrst section we will summa-
kernels on M1
rize the close connection between Hilbertian metrics
and pd kernels so that in general statements for one
category can be easily transferred to the other one.
We will consider two types of kernels on probability
measures. The ﬁrst one is general covariant. That
means that arbitrary smooth coordinate transforma-
tions of the underlying probability space will have no
inﬂuence on the kernel. Such kernels can be applied if
only the probability measures themselves are of inter-
est, but not the space they are deﬁned on. We intro-
duce and extend a two parameter family of covariant
pd kernels which encompasses all previously used ker-
nels of this type. Despite the great success of these
general covariant kernels in text and image classiﬁca-
tion, they have some shortcomings. For example for
some applications we might have a similarity measure
resp. a pd kernel on the probability space which we
would like to use for the kernel on probability mea-
sures. In the second part we further investigate types
of kernels on probability measures which incorporate
such a similarity measure, see [5]. This will yield on
the one hand a better understanding of these kernels
and on the other hand gives in some cases an eﬃcient
way of computing these kernels. Finally we apply these
kernels on two text (Reuters and WebKB) and two im-
age classiﬁcation tasks (Corel14 and USPS).

1M1

+(X ) denotes the set of positive measures µ on X

with µ(X ) = 1

1362 Hilbertian Metrics versus Positive

Deﬁnite Kernels

3 γ-homogeneous Hilbertian Metrics
and Positive Deﬁnite Kernels on R+

3

It is a well-known fact that a pd kernel k(x, y) corre-
sponds to an inner product hφx, φyiH in some feature
space H. The class of conditionally positive deﬁnite
(cpd) kernels is less well known. Nevertheless this class
is of great interest since Sch¨olkopf showed in [11] that
all translation invariant kernel methods can also use
the bigger class of cpd kernels. Therefore we give a
short summary of this type of kernels and their con-
nection to Hilbertian metrics2.

Deﬁnition 2.1 A real valued function k on X × X
Pn
is pd (resp. cpd) if and only if k is symmetric and
i,j cicjk(xi, xj) ≥ 0, for all n ∈ N, xi ∈ X , i =
ci ∈ R, i = 1, ..., n, withPn
1, ..., n, and for all ci ∈ R, i = 1, ..., n, (resp.
for all

i ci = 0).

Note that every pd kernel is also cpd. The close con-
nection between the two classes is shown by the fol-
lowing lemma:

Lemma 2.1 [2] Let k be a kernel deﬁned as k(x, y) =
ˆk(x, y)− ˆk(x, x0)− ˆk(x0, y) + ˆk(x0, x0), where x0 ∈ X .
Then k is pd if and only if ˆk is cpd.

Similar to pd kernels one can also characterize cpd
kernels. Namely one can write all cpd kernels in the
form: k(x, y) = − 1
2 kφx − φyk2H +f(x)+f(y). The cpd
kernels corresponding to Hilbertian (semi)-metrics are
characterized by f(x) = 0 for all x ∈ X , whereas if k is
2 k(x, x) ≥ 0. We refer to [2,
pd it follows that f(x) = 1
3.2] and [11] for further details. We also would like to
point out that for SVM’s the class of Hilbertian (semi)-
metrics is in a sense more important than the class of
pd kernels. Namely one can show, see [4], that the
solution and optimization problem of the SVM only
depends on the Hilbertian (semi)-metric, which is im-
plicitly deﬁned by each pd kernel. Moreover a whole
family of pd kernels induces the same semi-metric. In
order to avoid confusion we will in general speak of
Hilbertian metrics since, using Lemma 2.1, one can al-
ways deﬁne a corresponding pd kernel. Nevertheless
for the convenience of the reader we will often explic-
itly state the corresponding pd kernels.

2A (semi)-metric d(x, y) (A semi-metric d(x, y) fulﬁlls
the conditions of a metric except that d(x, y) = 0 does
not imply x = y.)
is called Hilbertian if one can em-
bed the (semi)-metric space (X , d) isometrically into a
Hilbert space. A (semi)-metric d is Hilbertian if and only
if −d2(x, y) is cpd. That is a classical result of Schoenberg.

The class of Hilbertian metrics on probability mea-
sures we consider in this paper are based on a point-
wise comparison of the densities p(x) with a Hilbertian
metric on R+. Therefore Hilbertian metrics on R+ are
the basic ingredient of our approach. In principle we
could use any Hilbertian metric on R+, but as we will
explain later we require the metric on probability mea-
sures to have a certain property. This in turn requires
that the Hilbertian metric on R+ is γ-homogeneous4.
The class of γ-homogeneous Hilbertian metrics on R+
was recently characterized by Fuglede:

Theorem 3.1 (Fuglede [3]) A symmetric function
d : R+ × R+ → R+ with d(x, y) = 0 ⇐⇒ x = y is
a γ-homogeneous, continuous Hilbertian metric d on
R+ if and only if there exists a (necessarily unique)
non-zero bounded measure ρ ≥ 0 on R+ such that d2
can be written as

Z

R+

(cid:12)(cid:12)(cid:12)x(γ+iλ) − y(γ+iλ)(cid:12)(cid:12)(cid:12)2

d2(x, y) =

dρ(λ)

(1)

Using Lemma 2.1 we deﬁne the corresponding class of
pd kernels on R+ by choosing x0 = 0. We will see later
that this corresponds to choosing the zero-measure as
origin of the RKHS.
Corollary 3.1 A symmetric function k : R+ × R+ →
R+ with k(x, x) = 0 ⇐⇒ x = 0 is a 2γ-homogeneous
continuous pd kernel k on R+ if and only if there ex-
ists a (necessarily unique) non-zero bounded symmet-
ric measure κ ≥ 0 on R such that k is given as

k(x, y) =

x(γ+iλ)y(γ−iλ) dκ(λ)

(2)

Z

R

If k has the form given in (2), then it is ob-
Proof:
viously 2γ-homogeneous and since k(x, x) = x2γκ(R)
we have k(x, x) = 0 ⇐⇒ x = 0. The other direc-
tion follows by ﬁrst noting that k(0, 0) = hφ0, φ0i =
0 and then by applying theorem 3.1, where κ is
the symmetrized version of ρ around the origin, to-
gether with lemma 2.1 and k(x, y) = hφx, φyi =
(cid:3)

(cid:0)−d2(x, y) + d2(x, 0) + d2(y, 0)(cid:1) .

1
2
At ﬁrst glance Theorem 3.1, though mathematically
beautiful, seems not to be very helpful from the view-
point of applications. But as we will show in the sec-
+(X ) this result
tion on structural pd kernels on M1
allows us to compute this class of kernels very eﬃ-
ciently.

3R+ is the positive part of the real line with 0 included
4A symmetric
if

γ-homogeneous

is
k(c x, c y) = cγk(x, y) for all c ∈ R+

function k

137Recently Topsøe and Fuglede proposed an interest-
ing two-parameter family of Hilbertian metrics on R+
[13, 3]. We extend now the parameter range of this
family. This allows us in the next section to recover
+(X ) from
all previously used Hilbertian metrics on M1
this family.
Theorem 3.2 The function d : R+×R+ → R deﬁned
as:

α − 2 1
β (xα + yα) 1
2 1
α − 2 1
2 1

β

α|β(x, y) =
(3)
d2
is a 1/2-homogeneous Hilbertian metric on R+, if α ∈
2 , α] or β ∈ [−∞,−1]. Moreover the
[1,∞], β ∈ [ 1
pointwise limit for α → β is given as:
!(1/β)
xβ + yβ(cid:17) 1
(cid:16)

d2
α|β (x, y) =

β221/β
log(2)

xβ + yβ

lim
α→β

 

∂
∂β

 

 

!

=

"

β

2

!#

log(2)

xβ + yβ

xβ + yβ

xβ + yβ

xβ + yβ

xβ

log

2xβ

yβ

+

log

2yβ

α(cid:0)xβ + yβ(cid:1) 1

β

α|β = d2

β|α. We need the following lemmas

Note that d2
in the proof:
Lemma 3.1 [2, 2.10] If k : X×X is cpd and k(x, x) ≤
0, ∀x ∈ X then −(−k)γ is also cpd for 0 < γ ≤ 1.
Lemma 3.2 If k : X × X → R is cpd and k(x, y) <
0, ∀ x, y ∈ X , then −1/k is pd.

It follows from Theorem 2.3 in [2] that if
Proof:
k : X × X → R− is cpd, then 1/(t − k) is pd for all
t > 0. The pointwise limit of a sequence of cpd resp.
pd kernels is cpd resp. pd if the limit exists, see e.g.
[10]. Therefore limt→0 1/(t − k) = −1/k is positive
(cid:3)
deﬁnite if k is strictly negative.
We can now prove Theorem 3.2:
Proof: The proof for the symmetry, the limit α → β
and the parameter range 1 ≤ α ≤ ∞, 1/2 ≤ β ≤ α
can be found in [3]. We prove that −d2
α|β is cpd for
1 ≤ α ≤ ∞, −∞ ≤ β ≤ −1. First note that k(x, y) =
−(f(x)+f(y)) is cpd on R+, for any function f : R+ →
R+ and satisﬁes k(x, y) ≤ 0, ∀ x, y ∈ X . Therefore by
Lemma 3.1, −(xα + yα)1/α is cpd for 1 ≤ α < ∞. The
pointwise limit limα→∞ −(xα + yα)1/α = − max{x, y}
exists, therefore we can include the limit α = ∞. Next
we consider k(x, y) = −(x + y)1/β for 1 ≤ β ≤ ∞
which is cpd as we have shown and strictly negative
if we restrict k to {x ∈ R| x > 0} × {x ∈ R| x > 0}.
Then all conditions for lemma 3.2 are fulﬁlled, so that
k(x, y) = (x + y)−1/β is pd. But then also k(x, y) =
(x−β+y−β)−1/β is pd. Moreover k can be continuously
extended to 0 by k(x, y) = 0 for x = 0 or y = 0.
Multiplying the ﬁrst part with (2(1/α−1/β) − 1)−1 and
the second one with (1 − 2(1/β−1/α))−1 and adding
(cid:3)
them gives the result.

4 Covariant Hilbertian Metrics on

M1

+(X )

+(X )
In this section we deﬁne Hilbertian metrics on M1
by comparing the densities pointwise with a Hilbertian
metric on R+ and integrating these distances over X .
Since densities can only be deﬁned with respect to a
dominating measure5 our deﬁnition will at ﬁrst de-
pend on the choice of the dominating measure. This
dependence would restrict the applicability of our ap-
proach. For example if we had X = Rn and chose µ
to be the Lebesgue measure, then we could not deal
with Dirac measures δx since they are not dominated
by the Lebesgue measure.
Therefore we construct the Hilbertian metric such that
it is independent of the dominating measure. This jus-
tiﬁes the term ’covariant’ since independence from the
dominating measure also yields invariance from arbi-
trary one-to-one coordinate transformations. In turn
this also implies that all structural properties of the
probability space will be ignored so that the metric on
+(X ) only depends on the probability measures. As
M1
an example take the color histograms of images. Co-
variance here means that the choice of the underlying
color space say RGB, HSV or CIE Lab does not inﬂu-
ence our metric, since these color spaces are all related
by one-to-one transformations. Note however that in
practice the results will usually slightly diﬀer due to
diﬀerent discretizations of the color space.
In order to simplify the notation we deﬁne p(x) to be
the Radon-Nikodym derivative (dP/dµ)(x) 6 of P with
respect to the dominating measure µ.

Z

X

Proposition 4.1 Let P and Q be two probability mea-
sures on X , µ an arbitrary dominating measure7 of P
and Q and dR+ a 1/2-homogeneous Hilbertian metric
on R+. Then DM1

+(X ) deﬁned as

D2M1

+(X )(P, Q) :=

d2R+(p(x), q(x))dµ(x) ,

(4)

is a Hilbertian metric on M1
pendent of the dominating measure µ.

+(X ). DM1

+(X ) is inde-

For a proof, see [5]. Note that if we use an arbitrary
metric on R+ in the above proposition, we also get
a Hilbertian metric. But this metric would only be
deﬁned on the set of measures dominated by a certain
+(X ). Moreover it would also
measure µ and not on M1
depend on the choice of the dominating measure µ.

5A measure µ dominates a measure ν if µ(E) > 0 when-
ever ν(E) > 0 for all measurable sets E ⊂ X . In Rn the
dominating measure µ is usually the Lebesgue measure.
6In case of X = Rn and when µ is the Lebesgue measure

we can think of p(x) as the normal density function.

7Such a dominating measure always exists take e.g.

M = (P + Q)/2

138We can now apply this principle of building covariant
+(X ) and use the family of
Hilbertian metrics on M1
α|β on R+ from
1/2-homogeneous Hilbertian metrics d2
the previous section. This yields as special cases the
+(X ).
following well-known measures on M1

D2

1|−1(P, Q) =

D2
1

2|1(P, Q) =

D2

1|1(P, Q) =

D2∞|1(P, Q) =

X

X
1

(p(x) − q(x))2
(pp(x) −pq(x))2dµ(x),
p(x) + q(x) dµ(x),
Z
(cid:21)

p(x) log

2p(x)

(cid:20)

(cid:20)

2q(x)

log(2)

X

+ q(x) log

p(x) + q(x)
|p(x) − q(x)|dµ(x).

p(x) + q(x)

dµ(x),

(cid:21)

(5)

Z
Z

Z

X

1|−1 is the symmetric χ2-measure, D 1

2|1 the Hellinger
D2
distance, D2
1|1 the Jensen-Shannon divergence and
D2∞|1 the total variation. The symmetric χ2-metric
was for some time wrongly assumed to be pd and is
new in this family due to our extension of d2
α|β to nega-
tive values of β. The Hellinger metric is well known in
the statistics community and was for example used in
[7]. The total variation was implicitly used in SVM’s
through a pd counterpart which we will give below.
Finally the Jensen-Shannon divergence is very inter-
esting since it is a symmetric and smoothed variant of
the Kullback-Leibler divergence. Instead of the work
in [9] where they have a heuristic approach to get from
the Kullback-Leibler divergence to a pd matrix, the
Jensen-Shannon divergence is a theoretically sound al-
ternative. Note that the family d2
α|β is designed in such
α|β is 2,∀ α, β.
a way that the maximal distance of D2
For completeness we also give the corresponding pd
+(X ), where we take in Lemma 2.1 the
kernels on M1
+(X ). This choice seems
zero measure as x0 in M1
strange at ﬁrst since we are dealing with probability
measures. But in fact the whole framework presented
in this paper can easily be extended to all ﬁnite, pos-
itive measures on X . For this set the zero measure is
a natural choice of the origin.

K1|−1(P, Q) =

K 1

2|1(P, Q) =

K1|1(P, Q) =

K∞|1(P, Q) =

p(x)q(x)
pp(x)q(x)dµ(x),
p(x) + q(x) dµ(x),
(cid:18)
Z

p(x) log

(cid:18)

X

X
−1
log(2)

+ q(x) log

p(x) + q(x)
min{p(x), q(x)}dµ(x).

p(x) + q(x)

p(x)

(cid:19)

dµ(x),

q(x)

(cid:19)

Z
Z

Z

X

X

The astonishing fact is that we ﬁnd the four (partially)
previously used Hilbertian metrics resp. pd kernels on
+(X ) as special cases of a two-parameter family of
M1
+(X ). Due
Hilbertian metrics resp. pd kernels on M1
to the symmetry of d2
α|β (which implies symmetry of
α|β) we can even see all of them as special cases of
D2
the family restricted to α = 1. This on the one hand
shows the close relation of these metrics among each
other and on the other hand gives us the opportunity
to do model selection in this one-parameter family of
Hilbertian metrics. Yielding an elegant way to handle
both the known similarity measures and intermediate
ones in the same framework.

5 Structural Positive Deﬁnite Kernels
The covariant Hilbertian metrics proposed in the last
section have the advantage that they only compare the
probability measures, thereby ignoring all structural
properties of the probability space. On the other hand
there exist cases where we have a reasonable similarity
measure on the space X , which we would like to be
incorporated into the metric. We will consider in this
section two ways of doing this.

5.1 Structural Kernel I
To incorporate structural information about the prob-
ability space X is helpful when we compare probability
measures with disjoint support. For the covariant met-
rics disjoint measures have always maximal distance,
irrespectively how ”close” or ”far” their support is.
Obviously if our training set consists only of disjoint
measures learning is not possible with covariant met-
rics. We have proposed in [5] a positive deﬁnite kernel
which incorporates a given similarity measure, namely
a pd kernel, on the probability space. The only disad-
vantage is that this kernel is not invariant with respect
to the dominating measure. That means we can only
+(X ) of mea-
deﬁne it for the subset M1
sures dominated by µ. On the other hand in some
cases one has anyway a preferred measure like e.g. for
Riemannian manifolds where there exists a natural vol-
ume measure. Such a preferred measure is then a nat-
ural choice for the dominating measure, so that theo-
retically it does not seem to be a major restriction. For
our experiments it does not make any diﬀerence since
we anyway use only probabilities over ﬁnite, discrete
spaces, so that the uniform measure dominates all
+(X ).
other measures and therefore M1
Theorem 5.1 (Structural Kernel I) Let k be a
bounded PD kernel on X and ˆk a bounded PD kernel
on R+. Then

+(X , µ) ⊂ M1

+(X , µ) ≡ M1

Z

Z

KI(P, Q) =

(6)

X

X

k(x, y) ˆk(p(x), q(y)) dµ(x) dµ(y)

(7)

139is a pd kernel on M1

+(X , µ) × M1

+(X , µ).

We refer to [5] for the proof. Note that this kernel can
easily be extended to all bounded, signed measures as
it is in general true for all metrics resp. kernels in
this paper. This structural kernel generalizes previous
work done by Suquet, see [12], where the special case
with ˆk(p(x), q(y)) = p(x)q(y) has been considered.
The advantage of this choice for ˆk is that KI(P, Q)
becomes independent of the dominating measure. In
fact it is easy to see that among the family of struc-
tural kernels KI(P, Q) of the form (7) this choice of
ˆk yields the only structural kernel K(P, Q) which is
independent of the dominating measure.
Indeed for
independence bilinearity of ˆk is required, which yields
ˆk(x, y) = xy ˆk(1, 1).
The structural kernel has the disadvantage that the
computational cost increases dramatically compared
to the covariant one, since one has to integrate twice
over X . An implementation seems therefore only to be
possible for either very localized probability measures
or a sharply concentrated similarity kernel ˆk e.g. a
compactly supported radial basis function on Rn.
The following equivalent representation of this kernel
will provide a better understanding and at the same
time will show a way to reduce the computational cost
considerably.

Proposition 5.1 The kernel KI(P, Q) can be equiva-
lently written as the inner product in L2(T × S, ω⊗ κ):

KI(P, Q) =

φP (t, λ)φQ(t, λ) dκ(λ) dω(t)

for some sets T, S with the feature map:
+(X , µ) → L2(T × S, ω ⊗ κ),

φ :M1

Γ(x, t)Ψ(p(x), s)dµ(x).

Z

Z

T

S

Z

X

P → φP (t, λ) =

where

k(x, y) =

ˆk(p(x), q(x)) =

Z
Z

T

S

Γ(x, t)Γ(y, t)dω(t),

Ψ(p(x), s)Ψ(p(y), s)dκ(s).

R
Proof: First note that one can write every pd ker-
nel in the form : k(x, y) = hΓ(x,·), Γ(y,·)iL2(T,ω) =
T Γ(x, t)Γ(y, t)dω(t), where Γ(x,·) ∈ L2(T, µ) for
each x ∈ X . In general the space T is very big, since
one can show that such a representation always ex-
ists in L2(RX , µ), see e.g. [6]. For the product of two
positive deﬁnite kernels we have such a representation
on the set T × S. Since for any ﬁnite measure space
(Y, µ) one has L2(Y, µ) ⊂ L1(Y, µ) we can apply Fu-
bini’s theorem and interchange the integration order.

The deﬁnition of the feature map ΦP (t, λ) then follows
(cid:3)
easily.
This representation has several advantages. First the
functions Γ(x, t) give us a better idea what proper-
ties of the measure P are used in the structural ker-
nel. Second in the case where S × T is of the same
or smaller size than X we can decrease the computa-
tion cost, since we now have to do only an integration
over T × S instead of an integration over X × X . Fi-
nally this representation is a good starting point if one
wants to approximate the structural kernel. Since any
discretization of T, S, or X or integration over smaller
subsets, will nevertheless give a pd kernel in the end.
We illustrate this result with a simple example. We
take X = Rn and k(x, y) = k(x−y) to be a translation
invariant kernel, furthermore we take ˆk(p(x), q(y)) =
p(x)q(y). The characterization of translation invariant
kernels on Rn is a classical result due to Bochner:
Theorem 5.2 A continuous function k(x, y) = k(x−
k(x − y) =
y) is pd on Rn if and only if
Rn eiht,x−yidω(t), where ω is a ﬁnite non-negative
measure on Rn.
Obviously we have in this case T = Rn. Then
the above proposition tells us that we are eﬀectively
computing the following feature vector for each P ,
Rn eihx,tip(x)dµ(x) = EP eihx,ti. Finally the
structural kernel can in this case be equivalently writ-
Rn EP eihx,tiEQeihx,tidω(t). That
means the kernel is in this case nothing else than the
inner product between the characteristic functions of
the measures in L2(Rn, ω)8. Moreover the computa-
tional cost has decreased dramatically, since we only
have to integrate over T = Rn instead of Rn × Rn.
Therefore in this case the kernel computation has the
same computational complexity as in the case of the
covariant kernels. The calculation of the features, here
the characteristic functions, can be done as a prepro-
cessing step for each measure.

φP (t) = R
ten as KI(P, Q) = R

R

5.2 Structural Kernel II

The second structural kernel we propose has almost
the opposite properties compared to the ﬁrst one. It is
invariant with respect to the dominating measure and
therefore deﬁned on the set of all probability measures
+(X ). On the other hand it can also incorporate a
M1
similarity function on X , but the distance of disjoint
measures will not correspond to their ’closeness’ in X .
Theorem 5.3 (Structural Kernel II) Let s : X ×
X → R be a non-negative function, ˆk a one-
homogeneous pd kernel on R+ and µ a dominating

8Note that ω is not the Lebesgue measure.

140measure of P and Q. Then

Z

KII (P, Q) =

s(x, y)ˆk(p(x), q(x))ˆk(p(y), q(y))dµ(x) dµ(y),

X 2

s(x, y)

(8)
is a pd kernel on M1
is independent
of the dominating measure. Moreover KII(P, Q) ≥
+(X ) if s(x, y) is a bounded positive
0, ∀ P, Q ∈ M1
deﬁnite kernel.

+(X ). KII

+(X ). Note that Pn
Proof: We ﬁrst prove that KII is positive deﬁ-
R
nP
nite on M1
i,j=1 cicjKII (Pi, Pj) =
cicj ˆk(pi(x), pj(x))ˆk(pi(y), pj(y))dµ(x)dµ(y)
X 2
The second term is a non-negative function in x and y,
since ˆk2 positive deﬁnite on (R+ × R+) × (R+ × R+).
Since s(x, y) is also a non-negative function, the
integration over X × X is positive. The independence
of KII(P, Q) of the dominating measure follows
from the one-homogeneity of ˆk(x, y). Deﬁne now
f(x) = ˆk(p(x), q(x)). Then f ∈ L1(X , µ) since

qˆk(p(x), p(x))ˆk(q(x), q(x))dµ(x)
pp(x)q(x)dµ(x) ≤ κ(R)2, where we

i,j=1

X

inition of f(x) as above, KII

have used the representation of one-homogeneous
kernels. A bounded pd kernel s(x, y) deﬁnes a positive
deﬁnite integral operator I : L1(X , µ) → L∞(X , µ),
X s(x, y)g(y)dµ(y). With the def-
is positive since
X s(x, y)f(x)f(y)dµ(x)µ(y) ≥ 0. (cid:3)
Even if the kernel looks quite similar to the ﬁrst one
it cannot be decomposed as the ﬁrst one, since s(x, y)
need not be a positive deﬁnite kernel. We just give the
equivalent representation without proof:

X

X

R
X |f(x)|dµ(x) ≤R
= κ(R)2R
(Ig)(x) = R
KII(P, Q) =R

R

Proposition 5.2 If s(x, y) is a positive deﬁnite kernel
on X , then KII(P, Q) can be equivalently written as:

Z
where s(x, y) =R

KII(P, Q) =

T

(cid:12)(cid:12)(cid:12)(cid:12)Z

X

Γ(x, t)ˆk(p(x), q(x)dµ(x)

dω(t)

(cid:12)(cid:12)(cid:12)(cid:12)2

T Γ(x, t)Γ(x, t)dω(t).

We illustrate this representation with a simple exam-
ple. Let s(x, y) be a translation-invariant kernel on
Rn. Then we can again use Bochner’s theorem for the
representation of s(x, y). The proposition then states
that the kernel KII(P, Q) is nothing else than the in-
tegrated power spectrum of the function ˆk(p(x), q(x))
with respect to ω.

6 Experiments

We compared the performance of the proposed met-
rics/kernels in four classiﬁcation tasks. All used data
sets consist of inherently positive data resp. counts of

terms, counts of pixels of a given color, intensity at a
given pixel. Also we will never encounter an inﬁnite
number of counts in practice, so that the assumption
that the data consists of bounded, positive measures
seems reasonable. Moreover we normalize always so
that we get probability measures. For text data this is
one of the standard representations, also for the Corel
data this is quite natural, since all images have the
same size and therefore the same number of pixels.
This in turn implies that all images have the same
mass in color space. For the USPS dataset it might
seem at ﬁrst a little bit odd to see digits as probabil-
ity measures. Still the results we get are comparable
to that of standard kernels without normalization, see
[10]. Nevertheless we don’t get state-of-the-art results
for USPS since we don’t implement invariance of the
digits with respect to translations and small rotations.
Details of the datasets and used similarity measures:
• Reuters text data set. The documents are rep-
resented as term histograms. Following [8] we
used the ﬁve most frequent classes earn, acq, mon-
eyFx, grain and crude. Documents which belong
to more than one of theses classes are excluded.
This results in a data set with 8085 examples of
dimension 18635.

• WebKB web pages data set. The documents are
also represented as term histograms. The four
most frequent classes student, faculty, course and
project are used. 4198 documents remain each of
dimension 24212, see [8]. For both structural ker-
nels we took for both text data sets the correlation
matrix in the bag of documents representation as
a pd kernel on the space of terms.

• Corel image data base. We chose the categories
Corel14 from the Corel image database as in [1].
The Corel14 has 14 classes each with 100 ex-
amples. As reported in [1] the classes are very
noisy, especially the bear and polar bear classes.
We performed a uniform quantization of each im-
age in the RGB color space, using 16 bins per
color, yielding 4096 dimensional histograms. For
both structural kernels we used as a similarity
measure on the RGB color space, the compactly
supported positive deﬁnite RBF kernel k(x, y) =
(1 − kx − yk /dmax)2
+, with dmax = 0.15, see [14].
7291 training and 2007 test
samples. For the ﬁrst structural kernel we used
again the compactly supported RBF kernel with
dmax = 2.2, where we take the euclidean distance
on the pixel space such that the smallest distance
between two pixels is 1. For the second struc-
tural kernel we used as the similarity function
s(x, y) = 1kx−yk≤2.2.

• USPS data set.

141All data sets were split into a training (80%) and a
test (20%) set. The multi-class problem was solved by
one-vs-all with SVM’s. For all experiments we used
the one-parameter family d2
α|1 of Hilbertian metrics
resp. their positive deﬁnite kernel counterparts kα|1
as basic metrics resp. kernels on R+, in order to build
the covariant Hilbertian metrics and both structural
kernels. In the table they are denoted as dir. Then a
second run was done by plugging the metric Dα|1(P, Q)
+(X ) induced by the covariant resp. structural
on M1
kernels into a Gaussian9:

Kα|1,λ(P, Q) = e−D2

α,1(P,Q)/λ

(9)

They are denoted in the table as exp. As a com-
parison we show the results if one takes the linear
kernel on R+, k(x, y) = xy as a basis kernel. Note
that this kernel is 2-homogeneous compared to the 1-
homogeneous kernels kα|1. Therefore the linear kernel
will not yield a covariant kernel. As mentioned ear-
lier the ﬁrst structural kernel becomes independent of
the dominating measure with this choice of ˆk. Also in
+(X )
this case we plugged the resulting metric on M1
into a Gaussian for a second series of experiments.
In the simplest case this gives the Gaussian kernel
k(x, y) = exp(−kx − yk2 /λ).
For
the penalty constant we chose from C =
{10k, k = −1, 0, 1, 2, 3, 4} and for α from α =
{1/2,±1,±2,±4,±16,∞} (α = −∞ coincides with
α = ∞). For the Gaussian (9) we chose additionally
from λ = 0.2∗σ∗{3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13}, where
σ = 1
m=1 K(Pm, Pm). In order to ﬁnd the best pa-
n
rameters for C, α resp. C, α, λ we performed 10-folds
cross validation. For the best parameters among α, C
resp. α, C, λ we evaluated the test error. Since the
Hilbertian metrics of (5) were not yet compared or
even used in kernel methods we also give the test er-
rors for the kernels corresponding to α = −1, 1/2, 1,∞.
The results are shown in table 1.

Pn

6.1

Interpretation

• The test error for the best α among the family
kα|1 selected by cross-validation gives for all three
types of kernels and their Gaussian transform al-
ways optimal or close to optimal results.

• For the text classiﬁcation the covariant kernels
were always better than the structured ones. We
think that by using a better similarity measure on
terms the structural kernels should improve. For
the two image classiﬁcation tasks the test errors
of the best structural kernel is roughly 10% better
than the best covariant one.

9It is well-known that this transform yields a positive

deﬁnite kernel iﬀ D is a Hilbertian metric, see e.g. [2].

• The linear resp. Gaussian kernel were for the ﬁrst
three data-sets always worse than the correspond-
ing covariant ones. This remains valid even if one
only compares the direct covariant ones with the
Gaussian kernel (so that one has in both cases
only a one-parameter family of kernels). For the
USPS dataset the results are comparable. Future
experiments have to show whether this remains
true if one considers unnormalized data.

7 Conclusion

We went on with the work started in [5] on Hilbertian
+(X ). We extended
metrics resp. pd kernels on M1
a family of Hilbertian metrics proposed by Topsøe,
so that now all previously used measures on proba-
bilities are now included in this family. Moreover we
studied further structural kernels on probability mea-
sures. We gave an equivalent representation for our
+(X ), which on the one
ﬁrst structural kernel on M1
hand provides a better understanding how it captures
structure of the probability measures and on the other
hand gives in some cases a more eﬃcient way to com-
pute it. Further we proposed a second structural ker-
nel which is independent of the dominating measure,
therefore yielding a structural kernel on all probability
measures. Finally we could show that doing model se-
lection in d2
α|1 resp. kα|1 gives almost optimal results
for covariant and structural kernels. Also the covariant
kernels and their Gaussian transform are almost al-
ways superior to the linear resp. the Gaussian kernel,
which suggests that the considered family of kernels
is a serious alternative whenever one has data which
is generically positive. It remains an open problem if
one can improve the structural kernels for text clas-
siﬁcation by using a better similarity function/kernel.

Acknowledgements

We would like to thank Guy Lebanon for kindly pro-
viding us with the WebKB and Reuters data set in
preprocessed from. Furthermore we are thankful to
Flemming Topsøe and Bent Fuglede for providing us
with preprints of their papers [13, 3].

References

[1] O. Chapelle, P. Haﬀner, and V. Vapnik. SVMs
for histogram-based image classiﬁcation.
IEEE
Trans. on Neural Networks, 10:1055–1064, 1999.
[2] J. P. R. Christensen C. Berg and P. Ressel. Har-
monic Analysis on Semigroups. Springer, New
York, 1984.

[3] B. Fuglede. Spirals in Hilbert space. With an ap-
plication in information theory. To appear in Ex-
positiones Mathematicae, 2004.

142Table 1: The table shows the test errors for the covariant and the two structural kernels resp. of their Gaussian
transform for each data set. The ﬁrst column shows the test error and the α-value of the kernel with the best
cross-validation error over the family D2
α|1 denoted as dir resp. of the Gaussian transform denoted as exp. The
next four columns provide the results for the special cases α = −1, 1/2, 1,∞ in D2
α|1 resp. Kα|1,λ. The last
column h·,·i gives the test error if one takes the linear kernel as basis kernel resp. of the Gaussian transform.

Best α

-1
1.36
1/2
1.54
1
1.85
1
1.54
1
1.54
1/2
1.67
4.88
16
1
4.76
4.88 ∞
5.11 ∞
1/2
4.88
1/2
5.59
12.86
-1
1
12.50
-1
15.71
1
10.36
20.00
16
1/2
17.14
-2
7.82
-16
4.53
7.52
-1
1/2
4.04
2
5.48
4.29
1/2

α = −1
1.36
1.73
1.60
1.60
1.85
2.04
4.76
4.76
5.47
5.35
5.59
6.18
12.86
11.43
15.71
10.71
18.57
18.57
8.07
4.58
7.52
3.99
5.18
4.09

cov
cov
str
str
str2
str2
cov
cov
str
str
str2
str2
cov
cov
str
str
str2
str2
cov
cov
str
str
str2
str2

dir
exp
dir
exp
dir
exp
dir
exp
dir
exp
dir
exp
dir
exp
dir
exp
dir
exp
dir
exp
dir
exp
dir
exp

α = 1
2
1.42
1.54
1.91
1.54
1.67
1.67
4.88
4.40
5.95
5.23
4.88
5.59
20.71
14.29
23.21
12.50
21.43
17.14
7.92
4.58
8.87
4.04
5.28
4.29

α = 1

1.36
1.79
1.85
1.54
1.54
1.91
4.52
4.76
5.23
5.11
5.59
5.95
15.71
12.50
16.43
10.36
19.29
19.29
8.17
4.53
7.77
3.94
5.33
4.24

α = ∞
1.79
1.91
1.67
1.60
2.35
2.53
4.64
4.99
4.88
5.11
6.30
7.13
12.50
11.79
12.14
11.07
20.00
18.93
7.87
5.28
7.87
4.78
6.03
5.03

h·,·i
1.98
1.73
2.16
2.10
2.41
2.65
7.49
7.25
6.30
6.42
9.39
9.04
30.00
34.64
29.64
20.36
36.79
35.71
9.02
4.53
9.07
4.09
5.03
4.88

Reuters

WebKB

Corel14

USPS

[4] M. Hein, O. Bousquet, and B. Sch¨olkopf. Maximal
margin classiﬁcation for metric spaces. Journal of
Computer and System Sciences, to appear.

[5] M. Hein, T. N. Lal, and O. Bousquet. Hilbertian
metrics on probability measures and their applica-
tion in SVM’s. In 26th Pattern Recognition Sym-
posium (DAGM). Springer, 2004.

[6] S. Janson. Gaussian Hilbert Spaces. Cambridge

University Press, Cambridge, 1997.

[7] T. Jebara and R. Kondor. Bhattacharyya and
expected likelihood kernels. In 16th Annual Con-
ference on Learning Theory (COLT), 2003.

[8] J. Laﬀerty and G. Lebanon. Diﬀusion kernels
on statistical manifolds. Technical Report CMU-
CS-04-101, School of Computer Science, Carnegie
Mellon University, Pittsburgh, 2004.

[9] P. J. Moreno, P. P. Hu, and N. Vasconcelos. A
Kullback-Leibler divergence based kernel for SVM

classiﬁcation in multimedia applications. NIPS,
16, 2003.

[10] B. Sch¨olkopf and A. Smola. Learning with Ker-

nels. MIT Press, Cambridge, MA, 2002.

[11] B. Sch¨olkopf. The kernel trick for distances.

NIPS, 13, 2000.

[12] C. Suquet. Distances euclidiennes sur les mesures
sign´ees et application `a des th´eor`emes de Berry-
Ess´een. Bull. Belg. Math. Soc. Simon Stevin,
2:161–181, 1995.

[13] F. Topsøe. Jenson-Shannon divergence and norm-
based measures of discrimination and variation.
Preprint, 2003.

[14] H. Wendland. Piecewise polynomial, positive def-
inite and compactly supported radial basis func-
tions of minimal degree. Adv. Comp. Math.,
4:389–396, 1995.

143Fast Non-Parametric Bayesian Inference on Inﬁnite Trees

Marcus Hutter

IDSIA, Galleria 2, CH-6928 Manno-Lugano, Switzerland
http://www.idsia.ch/∼marcus
marcus@idsia.ch

Abstract

Given i.i.d. data from an unknown distribu-
tion, we consider the problem of predicting
future items. An adaptive way to estimate
the probability density is to recursively sub-
divide the domain to an appropriate data-
dependent granularity. A Bayesian would as-
sign a data-independent prior probability to
“subdivide”, which leads to a prior over in-
ﬁnite(ly many) trees. We derive an exact,
fast, and simple inference algorithm for such
a prior, for the data evidence, the predictive
distribution, the eﬀective model dimension,
and other quantities.

1 INTRODUCTION

Inference. We consider the problem of inference from
i.i.d. data D, in particular of the unknown distribution
q the data is sampled from. In case of a continuous
domain this means inferring a probability density from
data. Without structural assumption on q, this is hard
to impossible, since a ﬁnite amount of data is never
suﬃcient to uniquely select a density (model) from an
inﬁnite-dimensional space of densities (model class).
In parametric estimation one assumes
Methods.
that q belongs to a ﬁnite-dimensional family. The
two-dimensional family of Gaussians characterized by
mean and variance is prototypical. The maximum
likelihood (ML) estimate of q is the distribution that
maximizes the data likelihood. Maximum likelihood
overﬁts if the family is too large and especially if it is
inﬁnite-dimensional. A remedy is to penalize complex
distributions by assigning a prior (2nd order) probabil-
ity to the densities q. Maximizing the model posterior
(MAP), which is proportional to likelihood times the
prior, prevents overﬁtting. Bayesians keep the com-
plete posterior for inference. Typically, summaries like
the mean and variance of the posterior are reported.

In ﬁnite or small
How to choose the prior?
compact low-dimensional spaces a uniform prior of-
ten works (MAP reduces to ML).
In the non-
parametric case one typically devises a hierarchy of
ﬁnite-dimensional model classes of increasing dimen-
sion. Selecting the dimension with maximal posterior
often works well due to the Bayes factor phenomenon
[Goo83, Jay03, Mac03]:
In case the true model is
low-dimensional, higher-dimensional (complex) model
classes are automatically penalized, since they contain
fewer “good” models. Full Bayesians would assign a
d2 ) to dimension d and mix over
prior probability (e.g. 1
dimension.
Interval Bins. The probably simplest and oldest
model for an interval domain is to divide the interval
(uniformly) into bins, assume a constant distribution
within each bin, and take a frequency estimate for the
probability in each bin, or a Dirichlet posterior if you
are a Bayesian. There are heuristics for choosing the
number of bins as a function of the data size. The
simplicity and easy computability of the bin model is
very appealing to practitioners. Drawbacks are that
distributions are discontinuous, its restriction to one
dimension (or at most low dimension: curse of dimen-
sionality), the uniform (or more generally ﬁxed) dis-
cretization, and the heuristic choice of the number of
bins. We present a full Bayesian solution to these prob-
lems, except for the non-continuity problem. Polya
trees [Lav94] inspired our model.
More advanced model classes. There are plenty
of alternative Bayesian models that overcome some
or all of the limitations. Examples are continuous
Dirichlet process (mixtures) [Fer73], Bernstein polyno-
mials [PW02], Bayesian ﬁeld theory [Lem03], Bayesian
kernel density estimation or other mixture models
[EW95], or universal priors [Hut04b], but analyti-
cal solutions are infeasible. Markov Chain Monte
Carlo sampling or Expectation Maximization algo-
rithms [DLR77] or variational methods can often be
used to obtain approximate numerical solutions, but
computation time and global convergence remain crit-

144ical issues. Practitioners usually use (with success)
eﬃcient MAP or M(D)L or heuristic methods, e.g. ker-
nel density estimation [GM03], but note that MAP or
MDL can fail, while Bayes works [PH04].
Our tree mixture model. The idea of the model
class discussed in this paper is very simple: With
equal probability, we chose q either uniform or split
the domain in two parts (of equal volume), and as-
sign a prior to each part, recursively, i.e. in each part
again either uniform or split. For ﬁnitely many splits,
q is a piecewise constant function, for inﬁnitely many
splits it is virtually any distribution. While the prior
over q is neutral about uniform versus split, we will
see that the posterior favors a split if and only if the
data clearly indicates non-uniformity. The method is a
full Bayesian non-heuristic tree approach to adaptive
binning for which we present a very simple and fast
algorithm for computing all(?) quantities of interest.
Contents. In Section 2 we introduce our model and
compare it to Polya trees. We also discuss some ex-
ample domains, like intervals, strings, volumes, and
classiﬁcation tasks. In Section 3 we present recursions
for various quantities of interest, including the data ev-
idence, the predictive distribution, the eﬀective model
dimension, the tree size and height, and cell volume.
We discuss the qualitative behavior and state conver-
gence of the posterior for ﬁnite trees. The proper case
of inﬁnite trees is discussed in Section 4, where we an-
alytically solve the inﬁnite recursion at the data sepa-
ration level. Section 5 collects everything together and
presents the algorithm. We also numerically illustrate
the behavior of our model on one example distribu-
tion. Section 6 contains a brief summary, conclusions,
and outlook, including natural generalizations of our
model. See [Hut04a] for derivations, proofs, program
code, extensions, and more details.

2 THE TREE MIXTURE MODEL

Setup and basic quantities of interest. We are
given i.i.d. data D = (x1,...,xn) ∈ Γn of size n from
domain Γ, e.g. Γ ⊆ IRd sampled from some unknown
probability density q : Γ → IR. Standard inference
problems are to estimate q from D or to predict the
next data item xn+1 ∈ Γ. By deﬁnition, the (objec-
tive or aleatoric) data likelihood density under model
q is p(D|q) ≡ q(x1)·...·q(xn). Note that we consider
sorted data, which avoids annoying multinomial co-
eﬃcients. Otherwise this has no consequences. Re-
sults are independent of the order and depend on the
counts only, as they should. A Bayesian assumes a
(cid:82)
(belief or 2nd-order or epistemic or subjective) prior
p(q) over models q in some model class Q. The data
Qp(D|q)p(q)dq. Having the evi-
evidence is p(D) =
dence, Bayes’ famous rule allows to compute the (be-

(cid:82)

k =

lief or 2nd-order or epistemic or subjective) posterior
p(q|D)= p(D|q)p(q)/p(D) of q. The predictive or pos-
terior distribution of x is p(x|D) = p(D,x)/p(D), i.e.
the conditional probability that the next data item is
x=xn+1, given D, follows from the evidences of D and
(D,x). Since the posterior of q is a complex object,
we need summaries like the expected q-probability of
x and (co)variances. Fortunately they can also be
reduced to computation of evidences: E[q(x)|D] :=
q(x)p(q|D)dq = p(x|D). In the last equality we used
the formulas for the posterior, the likelihood, the ev-
idence, and the predictive distribution, in this order.
Similarly for the covariance. We derive and discuss
further summaries of q for our particular tree model,
like the model complexity or eﬀective dimension, and
the tree height or cell size, later.
Hierarchical tree partitioning. Up to now every-
thing has been fairly general. We now introduce the
tree representation of domain Γ. We partition Γ into
(cid:83)m
Γ0 and Γ1, i.e. Γ=Γ0∪Γ1 and Γ0∩Γ1 = φ. Recursively
we (sub)partition Γz = Γz0 ˙∪Γz1 for z ∈ IBm
0 , where
i=k{0,1}i is the set of all binary strings of
IBm
length between k and m, and Γ =Γ, where ={0,1}0
is the empty string. We are interested in an inﬁnite
recursion, but for convenience we assume a ﬁnite tree
height m < ∞ and consider m → ∞ later. Also let
l := (cid:96)(z) be the length of string z = z1...zl =: z1:l, and
|Γz| the volume or length or cardinality of Γz.
Example spaces. Intervals: Assume Γ = [0,1) is the
unit interval, recursively bisected into intervals Γz =
[0.z,0.z+2−l) of length |Γz|=2−l, where 0.z is the real
number in [0,1) with binary expansion z1...zl.
Strings: Assume Γz ={zy : y ∈{0,1}m−l} is the set of
strings of length m starting with z. Then Γ ={0,1}m
and |Γz|=2m−l. For m=∞ this set is continuous, for
m <∞ ﬁnite.
Trees: Let Γ be a complete binary tree of height m
and Γz0 (Γz1) be the left (right) subtree of Γz. If |Γz|
is deﬁned as one more than the number of nodes in Γz,
then |Γz|=2m+1−l.
Volumes: Consider Γ ⊂ IRd, e.g. the hypercube Γ =
[0,1)d. We recursively halve Γz with a hyperplane
orthogonal to dimension (l mod d)+1, i.e. we sweep
through all orthogonal directions. |Γz|=2−l|Γ|.
Compactiﬁcation: We can compactify Γ⊆ (1,∞] (this
x : x∈
includes Γ = IN\{1}) to the unit interval Γ(cid:48) :={ 1
Γ}⊆ [0,1), and similarly Γ⊆ IR (this includes Γ = ZZ)
x(1−x) ∈ Γ}. All reasonable spaces
to Γ(cid:48) :={x∈ [0,1) : 2x−1
can be reduced to one of the spaces described above.
Classiﬁcation: Consider an observation o ∈ Γ(cid:48) (e.g.
email) that is classiﬁed as c∈{0,1} (e.g. good versus
spam), where Γ(cid:48) could be one of the spaces above (e.g.
o is a sequence of binary features in decreasing order

1450

z×{0} and Γ1z = Γ(cid:48)

of importance). Then x := (o,c) ∈ Γ := Γ(cid:48)×{0,1} and
z×{1}. Given D (e.g. pre-
Γ0z = Γ(cid:48)
classiﬁed emails), a new observation o is classiﬁed as
c with probability p(c|D,o)∝ p(D,x). Similar for more
than two classes.
In all these examples (we have chosen) |Γz0| =|Γz1| =
2|Γz| ∀z∈IBm−1
, and this is the only property we need
1
and henceforth assume. W.l.g. we assume/deﬁne/
rescale |Γ|=1. Generalizations to non-binary and non-
symmetric partitions are straightforward and brieﬂy
discussed at the end.
0 } are
Identiﬁcation. We assume that {Γz : z ∈ IBm
(basis) events that generate our σ-algebra. For ev-
ery x∈ Γ let x(cid:48) be the string of length (cid:96)(x(cid:48)) = m such
that x ∈ Γx(cid:48). We assume that distributions q are σ-
measurable, i.e. to be constant on Γx(cid:48) ∀x(cid:48) ∈ IBm. For
m = ∞ this assumption is vacuous; we get all Borel
measures. Hence, we can identify the continuous sam-
ple space Γ with the (for m<∞ discrete) space IBm of
binary sequences of length m, i.e. in a sense all exam-
ple spaces are isomorphic. While we have the volume
model in mind for real-world applications, the string
model will be convenient for mathematical notation,
the tree metaphor will be convenient in discussion, and
the interval model will be easiest to implement and to
present graphically.
Notation. As described above, Γ may also be a tree.
This interpretation suggests the following scheme for
deﬁning the probability of q on the leaves x(cid:48). The
probability of the left child node z0, given we are in
the parent node z, is P [Γz0|Γz,q], so we have

p(x|Γz, q) = p(x|Γz0, q)·P [Γz0|Γz, q]

if x ∈ Γz0

and similarly for the right child. In the following we
often have to consider distributions conditioned to and
in the subtree Γz, so the following notation will turn
out convenient

qz0 := P [Γz0|Γz, q],

pz(x|...) := 2−lp(x|Γz...)

(1)

m(cid:89)

⇒ pz(x|q) = 2qzxl+1pzxl+1(x|q) = ... =

2qx1:i if x∈ Γz

i=l+1

1

where we have used that p(x|Γx(cid:48),q) = |Γx(cid:48)|−1 = 2m is
uniform. Note that qz0 +qz1 = 1. Finally, let (cid:126)qz∗ :=
(qzy :y∈IBm−l
) be the (2m−l+1−2)-dimensional vector
or ordered set or tree of all reals qzy ∈ [0,1] in subtree
Γz. Note that qz (cid:54)∈ (cid:126)qz∗. The (non)density qz(x) :=
pz(x|q) depends on all and only these qzy. For z (cid:54)= ,
qz() and pz() are only proportional to a density due
to the factor 2−l, which has been introduced to make
px(cid:48)(x|...)≡ 1. (They are densities w.r.t. 2lλ|Γz, where
λ is the Lebesgue measure.) We have to keep this in
mind in our derivations, but can ignore this widely in
our discussion.

In the Polya tree model one assumes
Polya trees.
that the qz0≡1−qz1 are independent and Beta(·,·) dis-
tributed, which deﬁnes the prior over q. Polya trees
form a conjugate prior class, since the posterior is also
a Polya tree, with empirical counts added to the Beta
parameters. If the same Beta is chosen in each node,
the posterior of x is pathological for m→∞: The dis-
tribution is everywhere discontinuous with probability
1. A cure is to increase the Beta parameters with l,
e.g. quadratically, but this results in “underﬁtting” for
large sample sizes, since Beta(large,large) is too infor-
2. It also violates
mative and strongly favors qz0 near 1
scale invariance, which should hold in the absence of
2)
prior knowledge. That is, the p(oste)rior in Γ0 =[0, 1
should be the same as for Γ = [0,1) (after rescaling all
x ; x/2 in D).
The new tree mixture model. The prior P [q]
follows from specifying a prior over (cid:126)q∗, since q(x) ∝
qx1 ·...·qx1:m by (1). The distribution in each subset
Γz ⊆Γ shall be either uniform or non-uniform. A nec-
essary (but not suﬃcient) condition for uniformity is
2.
qz0 = qz1 = 1

pu(qz0, qz1) := δ(qz0 − 1

2)δ(qz1 − 1
2),

(2)

where δ() is the Dirac delta. To get uniformity on Γz
we have to recurse the tree down in this way.

pu((cid:126)qz∗) := pu(qz0, qz1)pu((cid:126)qz0∗)pu((cid:126)qz1∗)

(3)

with the natural recursion termination pu((cid:126)qz∗) = 1
when (cid:96)(z) = m, since then (cid:126)qz∗ = φ. For a non-uniform
distribution on Γz we allow any probability split
q(Γz) = q(Γz0)+q(Γz0), or equivalently 1 = qz0 +qz1.
We assume a uniform prior on the split, i.e.
ps(qz0, qz1) := δ(qz0 + qz1 − 1)

(4)

We now recurse down the tree

ps((cid:126)qz∗) := ps(qz0, qz1)p((cid:126)qz0∗)p((cid:126)qz1∗)

(5)

again with the natural recursion termination p((cid:126)qz∗) =
p(φ) = 1 when (cid:96)(z) = m. Finally we have to mix the
uniform with the non-uniform case.

(6)
2. This com-

p((cid:126)qz∗) := p(u)pu((cid:126)qz∗) + p(s)ps((cid:126)qz∗)

We choose a 50/50 mixture p(u)= p(s)= 1
pletes the speciﬁcation of the prior P [q]= p((cid:126)q∗).
For example, if the ﬁrst bit in x is a class label and
the remaining are binary features in decreasing order
of importance, then given class and features z = x1:l,
further features xl+1:m could be relevant for classiﬁ-
cation (qz(x) is non-uniform) or irrelevant (qz(x) is
uniform).
Comparison to the Polya tree. Note the important
diﬀerence in the recursions (3) and (5). Once we de-
cided on a uniform distribution (2) we have to equally

1461

2) + 1

(cid:89)

2[Beta(∞,∞)+Beta(1,1)].

split probabilities down the recursion to the end, i.e.
we recurse in (3) with pu, rather than the mixture p
(this actually allows to solve the recursion). On the
other hand if we decided on a non-uniform split (4),
the left and right partition each itself may be uniform
or not, i.e. we recurse in (5) with the mixture p, rather
than ps. Inserting (4) in (5) in (6) and recursively (2)
in (3) in (6) we get
δ(qzy− 1
p((cid:126)qz∗) = 1
2
y∈IBm−l

2 δ(qz0+qz1−1)p((cid:126)qz0∗)p((cid:126)qz1∗)
(7)
Choosing p(u)=0 would lead to the Polya tree model
(and its problems) with qz0∼ Beta(1,1). For our choice
2), but with p instead of pu on the r.h.s. of (3)
(p(u)= 1
we would get a quasi-Polya model (same problems)
with qz0∼ 1
For m→∞, our model is scale invariant and leads to
continuous distributions for n → ∞, unlike the Polya
tree model. We also don’t have to tune Beta pa-
rameters; the model tunes itself by suitably assign-
ing high/low posterior probability to subdividing cells.
While Polya trees form a natural conjugate prior class,
our prior does not directly, but can be generalized to
do so [Hut04a]. The computational complexity for
the quantities of interest will be the same (essentially
O(n)), i.e. as good as it could be.
Formal and eﬀective dimension. Formally our
model is 2·(2m−1)-dimensional, but the eﬀective di-
mension can by much smaller, since (cid:126)q∗ is forced with
a non-zero probability to a much smaller polytope, for
2 to the zero-dimensional
instance with probability 1
globally uniform distribution. We will compute the
eﬀective p(oste)rior dimension.

3 QUANTITIES OF INTEREST

The evidence recursion. At the end of Section 2 we
deﬁned our tree mixture model. The next step is to
compute the standard quantities of interest deﬁned at
the beginning of Section 2. The evidence p(D) is key,
the other quantities (posterior, predictive distribution,
expected q(x) and its variance) follow then immedi-
ately. Let Dz :={x∈ D : x∈Γz} be the nz :=|Dz| data
points that lie in subtree Γz. We compute pz(Dz) re-
cursively for all z∈ IBm−1
, which gives p(D)= p(D).
Inserting (1) and (7) into

0

pz(Dz|(cid:126)qz∗)p((cid:126)qz∗)d(cid:126)qz∗

(cid:90)
(cid:163)
1 + pz0(Dz0)pz1(Dz1)

w(nz0, nz1)

(cid:164)

(8)

(9)

pz(Dz) =

one can derive the following recursion [Hut04a]:

pz(Dz) = 1
2

w(nz0, nz1)

:= 2−nz

(nz +1)!
nz0!nz1!

nz = nz0 + nz1, ∆z := nz0
nz

=: wnz(∆z)
− 1

2

The recursion terminates with pz(Dz)=1 when (cid:96)(z)=
m. Recall (1) if you insist on a formal proof: For
(cid:96)(z)= m and x∈Γz we have Γx(cid:48) =Γz ⇒ pz(x|q)=1 ⇒
pz(Dz|q)=1 ⇒ pz(Dz)=1.
2, the evidence
Interpretation of (9): With probability 1
is uniform in Γz. Otherwise data Dz is split into two
partitions of size nz0 and nz1 = nz−nz0. First, choose
nz0 uniformly in {0,...,nz}. Second, given nz, choose
uniformly among the ( nz
) possibilities of selecting
nz0
nz0 out of nz data points for Γz0 (the remaining nz1
are then in Γz1). Third, distribute Dz0 according to
pz0(Dz0) and Dz1 according to pz1(Dz1). Then, the
evidence in case of a split is the second term in (9).
The factor 2nz is due to our normalization convention
(1). This also veriﬁes that the r.h.s. yields the l.h.s. if
integrated over all Dz, as it should be.
Discussing the weight. The relative probability of
splitting (second term on r.h.s. of (9)) to the uniform
case (ﬁrst term in r.h.s. of (9)) is controlled by the
weight w. Large (small) weight indicates a (non) uni-
form distribution, provided pz0 and pz1 are O(1). Bal-
ance ∆z ≈ 0 ((cid:54)≈ 0) indicates a (non) symmetric parti-
tioning of the data among the left and right branch
of Γz. Asymptotically for large nz (keeping ∆z ﬁxed),
we have

(cid:113)

wnz(∆z) ∼

2nz

π e−2nz∆2

z

z

z

w.p.1

∞ if

nz) nz→∞−→

= ˙qz0±O(n−1/2

Assume that data D is sampled from the true distri-
bution ˙q. The probability of the left branch Γz0 of Γz
is ˙qz0 ≡ P [Γz0|Γz, ˙q] = 2l ˙qz(Γz0). The relative frequen-
asymptotically converge to ˙qz0. More precisely
cies nz0
nz
) with probability 1 (w.p.1). Sim-
nz0
nz
ilarly for the right branch. Assume the probabilities
2), possibly but not necessarily
are equal ( ˙qz0 = ˙qz1 = 1
due to a uniform ˙qz() on Γz. Then ∆z = O(n−1/2
),
which implies
√
wnz(∆z) ∼ Θ(
˙qz0 = ˙qz1 = 1
2 ,
consistent with our anticipation. Conversely, for ˙qz0(cid:54)=
(cid:113)
˙qz1 (which implies non-uniformity of
˙qz()) we have
2 (cid:54)=0, which implies
∆z → c:= ˙qz0− 1
π e−2nzc2 nz→∞−→
wnz(∆z) ∼
again, consistent with our anticipation.
Asymptotic convergence/consistency (n→∞).
For ﬁxed m <∞, one can show that almost surely the
posterior pz((cid:126)qz∗|D) concentrates around the true dis-
tribution ˙(cid:126)qz∗ for n→∞. This implies that the poste-
rior pz(x|Dz)→ ˙qz(x) for all x∈Γz. One can also show
that the evidence pz(Dz) → 1
2 or 1 for uniform ˙qz(),
and increases exponentially with nz for non-uniform
˙qz() (see [Hut04a] for proofs).
Model dimension and cell number. As discussed
in Section 2, the eﬀective dimension of (cid:126)q∗ is the number

˙qz0 (cid:54)= ˙qz1,

0 if

w.p.1

2nz

1472 by (2). Note
of components that are not forced to 1
2 in (4), but
that a component may be “accidentally” 1
since this is an event of probability 0, we don’t have
to care about this subtlety. So the eﬀective dimension
2} of (cid:126)qz∗ can be given recursively
N(cid:126)qz∗ =#{q∈(cid:126)qz∗ :q(cid:54)= 1
as

N(cid:126)qz∗ =

if

0
1 + N(cid:126)qz0∗ + N(cid:126)qz1∗

(cid:96)(z) = m or

qz0 = 1
2

else

(10)

(cid:189)

(cid:90)

2, since this im-
The eﬀective dimension is zero if qz = 1
2 due to (7). If
plies that the whole tree Γz has qzy = 1
qz(cid:54)= 1
2, we add the eﬀective dimensions of subtrees Γz0
and Γz1 to the root degree of freedom qz0 = qz−qz1.
Bayes’ rule allows to represent the posterior probabil-
ity that N(cid:126)qz∗ = k as
δN(cid:126)qz∗ kpz(Dz|(cid:126)qz∗)p((cid:126)qz∗)d(cid:126)qz∗
Pz[N(cid:126)qz∗ = k|Dz]·pz(Dz) =
where Pz[...|...]:=P [...|Γz...], and δab =1 for a=b and 0
else. The r.h.s. coincides with (8) except for the extra
factor δN(cid:126)qz∗ k. Analogous to the evidence (8), using
(10) we can prove the following recursion:
Pz[N(cid:126)qz∗ = 0|Dz] = 1 − gz(Dz),
Pz[N(cid:126)qz∗ = k + 1|Dz] =

(11)
Pz0[N(cid:126)qz0∗ = i|Dz0] · Pz1[N(cid:126)qz1∗ = k−i|Dz1],

gz(Dz)· k(cid:88)

l < m,

for

i=0

Pz[N(cid:126)qz∗ = k|Dz] = δk0 :=
gz(Dz) := 1
2

pz0(Dz0)pz1(Dz1)
pz(Dz)w(nz0, nz1)

(9)= 1 −

for

l = m.
1

2pz(Dz)

(12)

(cid:169) 1 if k=0

(cid:170)

0 if k>0

Read: The probability that tree Γz has dimension k+1
equals the posterior probability gz(Dz) of splitting Γz,
times the probability that left subtree has dimension i,
times the probability that right subtree has dimension
k−i, summed over all possible i.
Let us deﬁne a cell or bin as a maximal volume on
which q() is constant. Then the model dimension is 1
less than the number of bins (due to the probability
constraint). Hence we also have a recursion for the
distribution of the number of cells.
Tree height and cell size. The eﬀective height of
tree (cid:126)qz∗ at x ∈ Γz is also an interesting property.
If
2 or (cid:96)(z)= m, then the height h(cid:126)qz∗(x) of tree (cid:126)qz∗
qz0 = 1
at x is obviously zero. If qz0(cid:54)= 1
2, we take the height of
the subtree (cid:126)qzxl+1∗ that contains x and add 1:

(cid:40)

h(cid:126)qz∗(x) =

0

if
1 + h(cid:126)qzxl+1∗(x)

(cid:96)(z) = m or

else

qz0 = 1
2

One can show that the tree height at x averaged over
all trees (cid:126)qz∗ is
Ez[h(cid:126)qz∗(x)|Dz] = gz(Dz)

(cid:104)
1 + Ezxl+1[h(cid:126)qzxl+1∗(x)|Dzxl+1]

(cid:105)

where Ez[f(cid:126)qz∗|...] =
Pz[f(cid:126)qz∗|...]p((cid:126)qz∗)d(cid:126)qz∗. We may
also want to compute the tree height averaged over
all x∈Γz. For (cid:96)(z) < m and qz0(cid:54)= 1

2 we get

(cid:90)

¯h(cid:126)qz∗ :=

(cid:82)

Ez[¯h(cid:126)qz∗|Dz] = gz(Dz)

h(cid:126)qz∗(x)q(x|Γz)dx = 1+ qz0·¯h(cid:126)qz0∗ + qz1·¯h(cid:126)qz1∗
(cid:105)

(cid:104)
1 + nz0+ 1
+ nz1+ 1

nz + 2 Ez0[¯h(cid:126)qz0∗|Dz0]
nz + 2 Ez1[¯h(cid:126)qz1∗|Dz1]

with obvious interpretation: The expected height of a
subtree is weighted by its relative importance, that is
(an estimate of) its probability. The recursion termi-
nates with Ez[h(cid:126)qz∗|Dz]=0 when (cid:96)(z)=m. We can also
compute intra and inter tree height variances.
Finally consider the average cell size or volume v.
Maybe more useful
is to consider the logarithm
−log2|Γz| = (cid:96)(z), since otherwise small volumes can
get swamped in the expectation by a single large one.
2, and else re-
Log-volume v(cid:126)qz∗ =(cid:96)(z) if (cid:96)(z)=m or qz = 1
cursively v(cid:126)qz∗ = qz0v(cid:126)qz0∗ +qz1v(cid:126)qz1∗. We can reduce this
to the tree height, since v(cid:126)qz∗ =¯h(cid:126)qz∗ +(cid:96)(z), in particular
v(cid:126)q∗ =¯h(cid:126)q∗
4 INFINITE TREES (m→∞)

Motivation. We have chosen an (arbitrary) ﬁnite tree
height m in our setup, needed to have a well-deﬁned
recursion start at the leaves of the trees. What we are
really interested in are inﬁnite trees (m=∞). Why not
feel lucky with ﬁnite m? First, for continuous domain
Γ (e.g. interval [0,1)), our tree model contains only
piecewise constant models. The true distribution ˙q() is
typically non-constant and continuous (Beta, normal,
...). Such distributions are outside a ﬁnite tree model
class (but inside the inﬁnite model), and the posterior
p(x|D) cannot converge to the true distribution, since
it is also piecewise constant. Hence all other estimators
based on the posterior are also not consistent. Second,
a ﬁnite m violates scale invariance (a non-informative
prior on Γz should be the same for all z, apart from
scaling). Finally, having to choose the “right” m may
be worrisome.
For increasing m, the cells Γx become smaller and will
(normally) eventually contain either only a single data
item, or be empty. It should not matter whether we
further subdivide empty or singleton cells. So we ex-
pect inferences to be independent of m for suﬃciently
large m, or at least the limit m→∞ to exist. In this
section we show that this is essentially true.
Prior inferences (D = φ). We ﬁrst consider the
prior (zero data) case D = φ. Recall that z ∈ IBm
is
some node and x ∈ IBm a leaf node. Normalization

0

148implies pz(φ)=1 for all z, which is independent of m,
hence the prior evidence exists for m → ∞. This is
nice, but hardly surprising.
The prior eﬀective model dimension N(cid:126)q∗ is more in-
teresting. D = φ implies Dz = φ implies nz = 0 implies
w(nz0,nz1) = 1 implies a 50/50 prior chance gz(φ) = 1
2
for a split (see (12)). Recursion (11) reads

Pz[N(cid:126)qz∗ = k + 1] = 1
2

Pz0[N(cid:126)qz0∗ =i]· Pz1[N(cid:126)qz1∗ =k−i]

with Pz[N(cid:126)qz∗ = k] = δk0 for l = m and Pz[N(cid:126)qz∗ = 0] = 1
2
for l < m. So the recursion terminates in recursion
depth min{k+1,m−l}. Hence Pz[N(cid:126)qz∗ = k+1] is the
same for all m > l + k, which implies that the limit
m→∞ exists. Furthermore, recursion and termination
are independent of z, hence also ak := Pz[N(cid:126)qz∗ = k]. So
we have to solve the recursion

k(cid:88)

i=0

k(cid:88)

i=0

ak+1 = 1
2

ai·ak−i with a0 = 1

2

(13)

(cid:80)∞

1

=

2k
k

(cid:181)

(cid:181)

8, 1

16, 5

128, 7

k−3/2

256, 21

2(k+1)4k

1/2
k + 1

The ﬁrst few coeﬃcients can be bootstrapped by hand:
2048,...). A closed form can also
1024, 33
2, 1
( 1
be obtained: Inserting (13) into f(x) :=
k=0akxk+1
2[x+ f 2(x)] with solution f(x) = 1−
(cid:182)
(cid:182)
√
we get f(x) = 1
1−x, which has Taylor expansion coeﬃcients
∼ 1
√
ak = (−)k
(cid:80)
2

(ak)k∈IN0 is a well-behaved distribution. It decreases
(cid:80)
kak = f(1) =
fast enough to be a proper measure (
1 < ∞), but too slow for the expectation E[N(cid:126)q∗] =
kk·ak =∞ to exist. This is exactly how a proper non-
(cid:80)
informative prior on IN should look like: as uniform
as possible, i.e. slowly decreasing. Further, P [N(cid:126)q∗ <
∞]=
kak =1 implies P [N(cid:126)q∗ <∞|D]=1, which shows
that the eﬀective dimension is almost surely ﬁnite, i.e.
inﬁnite (Polya) trees have probability zero.
For the tree height we have Ez[h(cid:126)qz∗(x)]=0 if l=m and
otherwise

π

Ez[h(cid:126)qz∗(x)] = 1

2[1 + Ezxl+1[h(cid:126)qzxl+1∗(x)]]

2)m−l → 1

= ... = 1 − ( 1

for m → ∞
This also implies that the expected average height
2)m−l → 1. This is the ﬁrst case where
Ez[¯h(cid:126)qz∗] = 1−( 1
the result is not independent of m for large ﬁnite m,
but it converges for m → ∞, what is enough for our
purpose.
Single data item D = (x). Since p(x)≡ 1 (by sym-
metry and normalization) and w1 = 1 are the same as
for the n = 0 case, all prior n = 0, m → ∞ results re-
2, P [N(cid:126)q∗ = k|x] = ak, and
main valid for n = 1: g(x) = 1
E[h(cid:126)q∗(x)|x]→1.

General D. We now consider general D. For con-
tinuous spaces Γ and non-singular distribution ˙q, the
probability of observing the same point more than once
(multi-points) is zero and hence can, to a certain ex-
tend, be ignored. See [Hut04a] for a thorough workout
of this case. In order to compute p(D) and other quan-
tities, we recurse (9) down the tree until Dz is either
empty or a singleton Dz =(x)∈Γz. We call the depth
mx :=(cid:96)(z) at which this happens, the separation level.
In this way, the recursion always terminates. For in-
stance, for Γ = [0,1), if ε := min{|xi−xj| : xi (cid:54)= xj with
xi,xj ∈ D} is the shortest distance, then mx <log2
ε =:
m0 < ∞, since ε > 0. At the separation level we can
insert the derived formulas for evidence, posterior, di-
mension, and height. Note, there is no approximation
here. The procedure is exact, since we analytically
computed the inﬁnite recursion for empty and single-
ton D.
So we have devised a ﬁnite procedure, linear in the
data size n, for exactly computing all quantities of in-
terest in the inﬁnite Bayes tree.
In the worst case,
we have to recurse down to level m0 for each data
point, hence our procedure has computational com-
plexity O(n·m0). For non-singular prior, the time is
actually O(n) with probability 1. So, inference in our
mixture tree model is very fast. Posterior (weak) con-
vergence/consistency for m=∞ can be shown similarly
to the m <∞ case [Hut04a].

2

5 THE ALGORITHM

In the last two sections we
What it computes.
derived all necessary formulas for making inferences
with our tree model. Collecting pieces together we
get the exact algorithm for inﬁnite tree mixtures be-
low. It computes the evidence p(D), the expected tree
height E[h(cid:126)q∗(x)|D] at x, the average expected tree
height E[¯h(cid:126)q∗|D], and the model dimension distribu-
tion P [N(cid:126)q∗|D]. It also returns the number of recursive
function calls, i.e. the size of the explicitly generated
tree. The size is proportional to n for regular distri-
butions ˙q.
The BayesTree algorithm (in pseudo C code)
takes arguments (D[],n,x,N); data array D[0..n−1]∈
[0,1)n, a point x ∈ IR, and an integer N.
It returns

(p,h,¯h,˜p[],r); the logarithmic data evidence p(cid:98)=lnp(D),
the expected tree height h(cid:98)=E[h(cid:126)q∗(x)|D] at x, the av-
erage expected tree height ¯h(cid:98)=E[¯h(cid:126)q∗|D], the model di-
mension distribution ˜p[0..N −1](cid:98)=P [N(cid:126)q∗ = ..|D], and

the number of recursive function calls r i.e. the size
of the generated tree. Computation time is about
N 2nlogn nano-seconds on a 1GHz P4 laptop.

149/* see (13) */

BayesTree(D[],n,x,N)
(cid:100) if (n≤1 and (n==0 or D[0]== x or x(cid:54)∈[0,1)))
(cid:100) if (x∈[0,1)) then h=1; else h=0;
¯h=1; p=ln(1); r =1;
(cid:98) for(k =0,..,N−1) ˜p[k]= ak;
else
(cid:100) n0 = n1 =0;
for(i=0,..,n−1)
(cid:100) if (D[i] < 1
(cid:98)
(p0,h0,¯h0,˜p0[],r0)=BayesTree(D0[],n0,2x,N−1);
(p1,h1,¯h1,˜p1[],r1)=BayesTree(D1[],n1,2x−1,N−1);
t= p0+p1−lnw(n0,n1);
if (t <100) then p=ln( 1

n0 = n0+1;]
else [D1[n1]=2D[i]−1; n1 = n1+1;]

2) then[ D0[n0]=2D[i];

2(1+exp(t));

else p= t−ln(2);

2exp(−p);

g =1− 1
if (x∈[0,1)) then h= g·(1+h0+h1); else h=0;
¯h= g·(1+ n0+1
˜p[0]=1−g;

for(k =0,..,N−1) ˜p[k+1]= g·(cid:80)k

¯h0+ n1+1

i=0 ˜p0[i]· ˜p1[k−i];

¯h1);

n+2

n+2

(cid:98) r =1+r0+r1;
(cid:98) return (p,h,¯h,˜p[],r);

How algorithm BayesTree() works. Since evi-
dence p(D) and weight 1/wn can grow exponentially
with n, we have to store and use their logarithms.
In the n ≤ 1

So the algorithm returns p(cid:98)=lnp(D).
branch, the closed form solutions p(cid:98)=lnp(φ) = ln(1),
h(cid:98)=E[h(cid:126)q∗(x)|φ or x]=1, ¯h(cid:98)=E[¯h(cid:126)q∗|D]=1, and ˜p[k]= ak

have been used to truncate the recursion. If D=(x1)(cid:54)=
x, we have to recurse further until x falls in an empty
interval. In this case or if n > 1 we partition D into
2. Then we rescale the points
points left and right of 1
to [0,1) and store them in D0 and D1, respectively.
Array D could have been reused (like in quick sort)
without allocating two new arrays. Then, algorithm
BayesTree() is recursively called for each partition.
The results are combined according to the recursions
derived in Section 2. lnw can be computed from (9) via
lnn! =
k=1lnk. (Practically, pre-tabulating ak or n!
does not improve overall performance). For comput-
2(1+et)) ˙=t−ln2 to machine
ing p we need to use ln( 1
precision for large t in order to avoid numerical over-
ﬂow.
Remarks. Strictly speaking, the algorithm has run-
time O(nlogn), since the sorting eﬀectively runs once
through all data at each level. If we assume that the
data are presorted or the counts nz are given, then
the algorithm is O(n) [Hut04a]. The complete C code,
available from [Hut04a], also handles multi-points.
Note that x passed to BayesTree() is not and cannot
be used to compute p(x|D). For this, one has to call

(cid:80)n

BayesTree() twice, with D and (D,x), respectively.
The quadratic order in N is due to the convolution,
which could be reduced to O(NlogN) by transforming
it to a scalar product in Fourier space with FFT.
Multiply calling BayesTree(), e.g. for computing the
predictive density function p(x|D) on a ﬁne x-grid,
is ineﬃcient. But it is easy to see that if we once
pre-compute the evidence pz(Dz) for all z up to the
separation level in time O(n), we can compute “lo-
cal” quantities like p(x|D) at x in time O(logn). This
is because only the branch containing x needs to be
recursed, the other branch is immediately available,
since it involves the already pre-computed evidence
only. The predictive density p(x|D) = E[q(x)|D] and
higher moments, the distribution function P [x≤ a|D],
updating D by adding or removing one data item, and
most other local quantities can be computed in time
O(logn) by such a linear recursion.
A good way of checking correctness of the implemen-
tation and of the derived formulas, is to force some
minimal recursion depth m(cid:48). The results must be in-
dependent of m(cid:48), since the closed-form speedups are
exact and applicable anywhere beyond the separation
level.
Numerical example. To get further insight into the
behavior of our model, we numerically investigated
some example distributions ˙q(). We have chosen el-
ementary functions, which can be regarded as proto-
types for more realistic functions. They include the
Beta, linear, a singular, piecewise constant distribu-
tions with ﬁnite and inﬁnite Bayes trees, and oth-
ers. These examples on [0,1) also shed light on the
other spaces discussed in Section 2, since they are iso-
√
morphic. The posteriors, model dimensions, and tree
1−x
heights, of the singular distribution ˙q(x) = 2/
are plotted in Figure 1 for random samples D of sizes
n=100,...,105. The posterior p(x|D) clearly converges
for n → ∞ to the true distribution ˙q(), accompanied
by a (necessary) moderate growth of the eﬀective di-
mension. For n = 10 we show the data points. It is
visible how each data point pulls the posterior up, as
it should be (“one sample seldom comes alone”). The
expected tree height E[h(x)|D] correctly reﬂects the
local needs for (non)splits, i.e. is larger near the singu-
larity at x = 1. The other examples display a similar
behavior (see [Hut04a]).

6 DISCUSSION

We presented a Bayesian model on inﬁnite trees, where
we split a node into two subtrees with prior probabil-
2, and uniform choice of the probability assigned
ity 1
to each subtree. We devised closed form expressions
for various inferential quantities of interest at the data

150√
Figure 1: BayesTree() results for a prototypical proper singular distribution ˙q(x)=2/

1−x.

separation level, which led to an exact algorithm with
runtime essentially linear in the data size. The theo-
retical and numerical model behavior was very reason-
able, e.g. consistency (no underﬁtting) and low ﬁnite
eﬀective dimension (no overﬁtting).
There are various natural generalizations of our model.
The splitting probability p(s) could be chosen diﬀer-
2, k-ary trees could be allowed, and the
ent from 1
uniform prior over subtrees could be generalized to
Beta/Dirichlet distributions. We were primarily in-
terested in the case of zero prior knowledge, hence
zero model (hyper)parameters, but the generalizations
above make the model ﬂexible enough, in case prior
knowledge needs to be incorporated. The dependency
on p(s) is particularly interesting [Hut04a]. The ex-
pected entropy can also be computed by allowing frac-
dx xα|α=1
tional counts nz and noting that xlnx = d
[Hut02]. A sort of maximum a posteriori (MAP) tree
skeleton can also easily be read oﬀ from (9). A node
Γz in the MAP-like tree is a leaf iﬀ pz0(Dz0)pz1(Dz1)
w(nz0,nz1) <1.
A challenge is to generalize the model from piecewise
constant to piecewise linear continuous functions, at
least for Γ=[0,1). Independence of subtrees no longer
holds, which was key in our analysis.

References

[DLR77] A. P. Dempster, N. Laird, and D. Rubin. Max-
imum likelihood estimation for incomplete data
via the EM algorithm. Journal of the Royal Sta-
tistical Society, Series B 39:1–38, 1977.

[EW95] M. Escobar and M. West. Bayesian density es-
timation and inference using mixtures. Journal
of the American Statistical Association, 90:577–
588, 1995.

[Fer73] T. S. Ferguson. On the mathematical founda-
tions of theoretical statistics. Annals of Statis-
tics, 1(2):209–230, 1973.

[GM03] A. G. Gray and A. W. Moore. Nonparamet-
ric density estimation: Toward computational
tractability.
In SIAM International Conf. on
Data Mining, volume 3, 2003.

[Goo83]

I. J. Good. Explicativity, corroboration, and the
relative odds of hypotheses.
In Good thinking:
The Foundations of Probability and its applica-
tions. University of Minnesota Press, Minneapo-
lis, MN, 1983.

[Hut02] M. Hutter. Distribution of mutual information.
In Advances in Neural Information Processing
Systems 14, pages 399–406, Cambridge, MA,
2002. MIT Press.

[Hut04a] M. Hutter. Additional material to article.

http://www.idsia.ch/˜marcus
/ai/bayestreex.htm, 2004.

[Hut04b] M. Hutter. Universal Artiﬁcial Intelligence: Se-
quential Decisions based on Algorithmic Prob-
ability.
300 pages,
http://www.idsia.ch/∼ marcus/ai/uaibook.htm.

Springer, Berlin, 2004.

[Jay03] E. T. Jaynes. Probability Theory: The Logic
of Science. Cambridge University Press, Cam-
bridge, MA, 2003.

[Lav94] M. Lavine. More aspects of Polya tree distribu-
tions for statistical modelling. Annals of Statis-
tics, 22:1161–1176, 1994.

[Lem03] J. C. Lemm. Bayesian Field Theory and Ap-
proximate Symmetries. Johns Hopkins Univer-
sity Press, 2003.

[Mac03] D. J. C. MacKay. Information theory, inference
and learning algorithms. Cambridge University
Press, Cambridge, MA, 2003.

[PH04]

J. Poland and M. Hutter. Convergence of dis-
crete MDL for sequential prediction.
In Proc.
17th Annual Conf. on Learning Theory (COLT-
2004), volume 3120 of LNAI, pages 300–314,
Banﬀ, 2004. Springer, Berlin.

[PW02] S. Petrone and L. Wasserman. Consistency of
Bernstein polynomial posteriors. Journal of the
Royal Statistical Society, B 64:79–100, 2002.

Posterior p(x|D)00.511.522.533.5400.20.40.60.81ExactD for n=10n=10n=1000n=100000Dimension P[N|D]00.020.040.060.080.10.120.14020406080100n=0&1n=10n=100n=1000n=10000n=100000n=0&1n=10n=100n=10000n=1000n=100000Height E[h(x)|D]01234567891000.20.40.60.81n=100000n=1000n=10151Restricted concentration models – graphical Gaussian models with

concentration parameters restricted to being equal

Søren Højsgaard

Biometry Research Unit

Danish Institute of Agricultural Sciences
Research Center Foulum, DK–8830 Tjele

Denmark

Abstract

In this paper we introduce restricted concen-
tration models (RCMs) as a class of graphical
models for the multivariate Gaussian distri-
bution in which some elements of the concen-
tration matrix are restricted to being identi-
cal is introduced. An estimation algorithm
for RCMs, which is guaranteed to converge
to the maximum likelihood estimate, is pre-
sented. Model selection is brieﬂy discussed
and a practical example is given.

1 Introduction

This paper introduces a class of graphical Gaus-
sian models, Lauritzen (1996), (hereafter abbreviated
GGMs) also known as covariance selection models,
Dempster (1972), in which elements of the concen-
tration matrix are restricted to being identical. Such
models are denoted restricted concentration models
and abbreviated RCMs. These models are linear in
the inverse covariance matrix and can therefore be seen
as instances of models discussed by Anderson (1970).
Besag (1974) also studies instances of such models.

RCMs can be of relevance in a variety of diﬀerent prob-
lems. An example could be gene expression data where
the expression of many genes are measured. From a
biological point of view it may be of interest to embody
in the model that the conditional covariance between
genes i and j should be the same as the conditional
covariance between genes k and l. It may also be of
interest (and in some cases a necessity) to impose such
restrictions simply in order to reduce the dimensional-
ity of the problem.

Models with equal conditional correlations can be con-
structed within RCMs but this requires restrictions on
both the conditional covariances and the conditional
variances. An interesting extension of RCMs would

Steﬀen Lauritzen

Department of Statistics

University of Oxford

1 South Parks Road, Oxford OX1 3TG

United Kingdom

therefore be models with equal conditional correlations
and no other restraints.

Finally we mention that the restrictions in RCMs can
lead to some regression functions being constrained to
equality as illustrated in Section 3.

2 Background and notation

The setting in GGMs is i.i.d. samples of a random vec-
tor y = (y1, . . . , yd)⊤ following a Nd(µ, Σ) distribution.
Let K = Σ−1 denote the inverse covariance matrix,
also known as the concentration matrix with elements
(kαβ). It is then well known, Lauritzen (1996), p. 130,
that the partial correlation between y1 and y2 given
all other variables is

ρ12|3...d = −k12/√k11k22

(1)

Thus k12 = 0 if and only if y1 and y2 are independent
given all other variables, and this is the traditional
focus of graphical Gaussian modeling.

A GGM is often represented by an undirected graph
G = (Γ, E) where Γ is the set of nodes representing the
d variables and E is the set of undirected edges rep-
resenting the concentration parameters kαβ which are
not restricted to being zero. For additional properties
of GGMs we refer to Lauritzen (1996), Chapter 5. In
the following we use Greek letters to refer to variables
and Latin letters to refer to sets of variables.

3 The problem to be solved

The issue addressed in this paper is to estimate K
when some entries kαβ are restricted to being equal.
Such restrictions can be imposed both on the diagonal
and the oﬀ–diagonal elements of K.

Example To illustrate possible implications of such
restrictions, consider the model in Figure 1. The as-
terisks indicate the restrictions that k13 = k14 = c1,

152k23 = k24 = c2 and k33 = k44 = c3, i.e.

5 The NIPS (Newton+IPS) algorithm

K =




k11
k12
c1
c1

k12
k22
c2
c2

c1
c2
c3
0

c1
c2
0
c3




If we let a = {1, 2} and b = {3, 4}, then the regres-
sion parameters when regressing b on a are given as
−(K bb)−1K ba. Thus the slope parameters for y3 and
y4 become identical,

E(yi|y1, y2) = ai + (c1/c3)y1 + (c2/c3)y2 for i = 3, 4,
meaning that the regression lines are parallel.

Another property of this model is that some partial
correlations are restricted to being equal. For example
it follows directly from (1) that

ρ31|24 = ρ41|23 = −c3/pk11c1 and
ρ32|14 = ρ42|13 = −c3/pk11c2.

1

2

*

*

**

**

3

***

4

***

Figure 1: Graphical Gaussian model with the ad-
ditional restrictions that (*) k13 = k14 = c1, (**)
k23 = k24 = c2 and (***) k33 = k44 = c3.

4 Restricted concentration models

To formalize the restrictions on the elements of K, let
the edge set E be partitioned into non–empty disjoint
subsets E1, . . . , ES each containing one or more edges.
Let E1, . . . , Es denote those subsets containing more
than one edge (those edges are said to be marked), and
Es+1, . . . , ES be those containing only one edge (those
edges are unmarked). Let Γ1, . . . , ΓT be a similar par-
titioning of Γ into sets of nodes, some of which are
marked and some unmarked. A natural way to rep-
resent this situation graphically is to colour the edges
(vertices) in the graph such that all edges (vertices) in
the same edge (vertex) set have the same colour.
Let R = {E1, . . . ES, Γ1, . . . , ΓT} be the collection
of such restrictions on K. The elements of R are
in 1–1 correspondence with the parameters θ =
(θ1, . . . , θS+T ) in K = K(θ). The edge sets E1, . . . ES
and vertex sets Γ1, . . . , ΓT deﬁne a RCM.

The algorithm is a combination of the classical IPS
algorithm for graphical Gaussian models, Lauritzen
(1996), p. 134 and the modiﬁed Newton procedure
of Jensen, Johansen and Lauritzen (1991) (hereafter
JJL91), see also Lauritzen (1996), p. 269.
Let ˆΣ = ˆK −1 denote the current estimate of Σ at any
time during the iteration, and let f = n− 1 where n is
the number of observations, SSD = Pn
s=1(ys− ¯y)(ys−
¯y)⊤ and S = SSD/f .

5.1 Newton algorithm

The simplest version of the algorithm (which is just a
speciﬁc version of the modiﬁed Newton algorithm of
JJL91) is as follows:
Repeatedly loop through R until convergence doing
the following: For each s ∈ R deﬁne the d × d matrix
K s as follows: 1) If s is an edge set, then K s has entries
αβ = 1 if {α, β} ∈ s and 0 otherwise. Thus K s is the
K s
incidence matrix for the graph (Γ, s). 2) If s is a vertex
set then K s is a diagonal matrix with entries K s
αα = 1
if α ∈ s and 0 otherwise. For convenience we shall
identify a vertex α with a set {α, α} such that vertex
sets and edge sets can be treated simultaneously in the
following.
Deﬁne the discrepancy ∆ = tr(K s ˆΣ) − tr(K sS). For
each element s do a sequence of Newton steps

θn+1
s

← θn

s +

kαβ ← θn+1

s

∆

tr(K s ˆΣK s ˆΣ) + f ∆2/2
for all {α, β} ∈ s.

,

(2)

The substitution (2) is repeated until convergence for
the set s before moving on to the next set in R. Thus
the algorithm consists of two nested loops: 1) An outer
loop running over the elements of R and 2) an inner
loop maximizing L with respect to θs while keeping
all other parameters ﬁxed. Below it is shown that this
algorithm in some cases can be speeded up by replacing
the inner loop by a direct line search.

The likelihood equations are obtained as follows: With
the deﬁnition of the matrices K s for all s ∈ R given
above, the concentration matrix can be written K =
Ps θsK s. Let SS denote the sums–of–squares ma-
trix. Then tr(KSS) = Ps θstr(K sSS). Let ts =
Ps tr(K sSS). Hence (−t1/2, . . . ,−tS+T /2, ¯y) is a set
of canonical statistics, and these are to be equated with
their expectation.

To do so, we exploit the following: The multivariate
normal distribution is a regular k–dimensional expo-
nential family. Therefore the maximum likelihood es-
timate (MLE) exists and is unique, provided that the

153suﬃcient statistic is contained in its convex support.
By Theorem 2 in Jensen et al. (1991), the MLE can
be found by iteratively maximizing over each canonical
parameter, keeping the others ﬁxed. Note that when
keeping all parameters but one at ﬁxed values we get a
regular one–dimensional exponential family. By The-
orem 1 in JJL91, their modiﬁed Newton algorithm ap-
plied to a one–dimensional regular exponential family
converges to the MLE for any starting value.

Following Lauritzen (1996), p. 133, ˆµ = ¯y so what
remains is to maximize L(θ, ˆµ) over Θ which is an S+T
dimensional space restricted only by the requirement
that K(θ) must be positive deﬁnite for all θ ∈ Θ. For
any θ∗ ∈ Θ and any s ∈ R, deﬁne
Θs(θ∗) = {θ ∈ Θ|θr = θ∗

r for r 6= s}.

Then L is maximized by cyclically maximizing L over
Θs(θ∗), Lauritzen (1996), p. 270. For practical reasons
we have chosen to ﬁt the model on S rather than on
SS. Following Lauritzen (1996) p. 259, τ s = E(ts) =
2 tr(K sΣ) and vs = V ar(ts) = 1
− 1
2 tr(K sΣK sΣ). The
modiﬁed Newton algorithm of JJL91 consists in up-
dating θ as

θn+1 = θn +

ts − τ s

vs + (ts − τ s)2
which specializes to (2) in this context.

Convergence The parameter space Θ is restricted
by K(θ) having to be positive deﬁnite. We have not
shown that the Newton steps are guaranteed to keep
K positive deﬁnite and this should therefore strictly
speaking be checked at each Newton step, decreasing
the step length appropriately if the condition is no
longer satisﬁed, see JJL91. Empirical evidence sug-
gests however, that K indeed remains positive deﬁnite.

5.2 IPS algorithm

For a GGM (without restrictions of the kind discussed
in this paper) let a = {α, β} be an edge in the graph
and let b denote the complement to a. Then in the
IPS algorithm, see e.g. Lauritzen (1996) p. 134 ﬀ, can
be used for updating the parameters kαα, kββ and kαβ
by updating the 2 × 2 submatrix K aa of K as
K aa ← (Saa)−1 + K ab(K bb)−1K ba.

(3)

Note that in this step both the conditional variances
and conditional covariances are updated. This IPS
step maximizes the likelihood over the particular sec-
tion of the parameter space given by kαα, kββ and kαβ
and thus no iteration is needed. This operation can
also be performed on a single vertex α, which gives an
update of the 1 × 1 submatrix K αα.

5.3 NIPS algorithm

Considerable computational savings can be achieved
by combining the Newton sequence (2) with the
IPS step (3) and this combination constitutes the
NIPS (=Newton+IPS) algorithm.
The combina-
tion is straight forward and most easily explained
by an example: The graph in Figure 2 has cliques
[12][23][34][45]. The asterisks indicate that the edges
[12] and [23] and the vertices 2 and 3 are marked, i.e.
the restrictions k12 = k23 and k22 = k33.

1

*

2
**

*

3
**

4

5

Figure 2: RCM with the additional restrictions that
(*) k12 = k23 and (**) k22 = k33.

The marked entries can be updated using the Newton
sequence while k11 is unrestricted and can be updated
using an IPS step on a 1 × 1 matrix. The edge [45]
(comprising the parameters k44, k45 and k55 can also
be updated in a single IPS step on a 2 × 2 matrix.
Left to consider is therefore only k34. Even though no
restriction is put onto this parameter it can not im-
mediately be updated using an IPS step (3) because
that would also update k33 (and k44) which is con-
strained. Therefore this parameter is updated using
a Newton sequence. This constitutes one full cycle of
the inner loop of the NIPS algorithm. Note that it is
easy to keep track of such restrictions: Whenever an
edge {α, β} contains a marked vertex, the edge must
itself be marked.

Computational Savings The following considera-
tions can lead to substantial computational savings:

1. Computational savings can be achieved when cal-
culating ∆ = tr(K s ˆΣ) − tr(K sS). The incidence
matrix K s serves to pick out (and sum the correct
way) the relevant entries of S and ˆΣ. For a ﬁxed
edge set s ∈ R, let a denote the set of vertices
in s and let b be the complement of a. Let ˜As
be the incidence matrix for the graph (a, s) and
let ﬁnally ˆΣaa and Saa denote the corresponding
submatrices of ˆΣ and S. It it then straight for-
ward to see that tr(K sS) = tr( ˜AsSaa) and hence
∆ = tr( ˜As ˆΣaa) − tr( ˜AsSaa). The modiﬁcation
when s is a vertex set is straight forward.

2. After updating entries of K in a NR step, one need
not ﬁnd Σ = K −1. The relevant part Σaa can be
found as (K aa−K ab(K bb)−1K ba)−1, and here it is
noted that 1) K ab(K bb)−1K ba is ﬁxed throughout
the whole Newton sequence and 2) the dimension
of Σaa is often much smaller than the dimension

154of Σ. A similar construct can be used when cal-
culating the value of the likelihood function.

3. Convergence is sometimes speeded up when re-
placing the Newton steps in (2) by an alternative
line search algorithm of the form

One motivation for considering RCMs is applications
where data is sparse, i.e. where n < d. In this case S
is singular and hence K = S−1 does not exist. One
option in this case is to start from the independence
model and do a forward selection possibly supplied
with joining operations as discussed above.

← θn

θn+1
s
kαβ ← θn+1

s

s + α · p,

for all {α, β} ∈ s

(4)

8 Example: measurements on pig

carcasses

where p =
maximize L in the direction deﬁned by θn

tr(As ˆΣAs ˆΣ)+f ∆2/2

and α is chosen to

s + tp.

∆

4. If a clique consists exclusively of unmarked
edges/vertices, then it is more computationally
eﬃcient to update the entire clique using IPS at
one time rather than working the way through the
edges one at the time.

6 Implementation

The algorithm has been implemented in the gen-
eral statistical package R, R Development Core Team
(2004).

7 Model selection issues

The number of diﬀerent models which can be formed
by colouring edges/vertices in a given graph is enor-
mous. To illustrate the complexity, consider graphs
with vertices, 1,2 and 3 (for which there are 8 dif-
ferent graphs). There are 5 possible vertex sets:
{123},{12, 3},{1, 23},{13, 2} and {1, 2, 3}. A tedious
calculation shows that there are in total (over all 8
graphs) 15 possible vertex sets giving 5 × 15 = 75 dif-
ferent models! Therefore, good model selection strate-
gies become important. Here we shall just outline some
ideas:

Often in model selection in graphical models one con-
sider the operations dropEdge and addEdge. For
RCMs there are four additional operations which are
natural to consider: joinEdgeSet and splitEdgeSet
(and similarly for vertices). In connection with a back-
ward model search where edges are successively deleted
it is tempting to supplement with the possibility of
joining two edge sets.
If there are p edge sets then
there are p(p − 1)/2 pairwise comparisons of the cor-
responding parameters and this can be done by e.g.
calculating Wald statistics (which requires V ar(ˆθ) to
be computed).

A more brute force approach is to search for a graph-
ical model and then apply a clustering algorithm to
the diagonal of K and to the non–zero oﬀ–diagonal
elements of K.

To illustrate the developments in this paper we con-
sider a prediction problem: In slaughter pig produc-
tion, prediction of the lean meat content is important
1) to ensure fair payment to the producers and 2) to en-
sure an appropriate processing of the meat afterwards.
The task is to predict the lean meat percentage y on
the basis of a set of predictor variables denoted by x.
In modern carcass grading, the predictor variables are
often obtained e.g. by ultra sound measurements on
the carcass and hence the number of predictor vari-
ables can be very large – and much larger than the
sample size.

For simplicity, we here consider the carcass data set
contained in the mimR package in R, see Højsgaard
(2004). This data set contains measurements of the
thickness of the meat and fat layer at three locations on
the back of 340 carcasses. The data also contains the
lean meat percentage determined by dissection. The
response variable is the meat percentage, y = M P
while x denotes the measurements of thickness of meat
and fat layers. The regression coeﬃcients for the pre-
diction are ΣyxΣ−1
xx = −(K yy)−1K yx. The problem in
such prediction problems is that either Σxx is singu-
lar or it is very ill–conditioned because the predictor
variables often are very correlated.

To accommodate for this, one often make a principal
component regression or a partial least squares regres-
sion to obtain the regression coeﬃcients. Other al-
ternatives are ridge regression and the lasso, see e.g.
Hastie, Tibshirani and Friedman (2001), pp. 59 for a
description of these methods.

8.1 Selection of diﬀerent models

The saturated model (which has Table 1 as concen-
tration matrix) is in the following denoted M1. Ta-
ble 1 shows that the fat–concentration parameters all
tend to be of the same size (conditional variances as
well as covariances) and so do the meat concentration
parameters. Similarly, the concentration parameters
between the fat measurements and the lean meat per-
centage appear identical and so do (to a lesser extent)
the concentration parameters between the meat mea-
surements and the lean meat percentage. The model

155with these constraints is denoted M1r and the esti-
mated concentration matrix is shown in Table 2.

Table 4: Estimated concentration matrix for the car-
cass data (multiplied by 10) for M2r.

Table 1: Empirical concentration matrix for the car-
cass data (multiplied by 10).

F1
4.36
-1.99
-1.58
0.28
-0.73
0.41
0.99

F2
-1.99
5.35
-2.09
-0.26
0.64
-0.53
0.88

F3
-1.58
-2.09
5.57
-0.56
-0.06
0.26
0.71

M1
0.28
-0.26
-0.56
1.58
-0.60
-0.56
-0.33

M2
-0.73
0.64
-0.06
-0.60
1.35
-0.88
-0.04

M3
0.41
-0.53
0.26
-0.56
-0.88
1.57
-0.14

MP
0.99
0.88
0.71
-0.33
-0.04
-0.14
2.63

F1
F2
F3
M1
M2
M3
MP

F1
F2
F3
M1
M2
M3
MP

F1
4.60
-2.00
-2.00
0.00
-0.20
0.00
0.77

F2
-2.00
4.60
-1.11
0.00
0.00
0.00
0.77

F3
-2.00
-1.11
4.60
-0.20
0.00
0.00
0.77

M1
0.00
0.00
-0.20
1.06
-0.47
-0.47
-0.20

M2
-0.20
0.00
0.00
-0.47
1.06
-0.47
0.00

M3
0.00
0.00
0.00
-0.47
-0.47
1.06
-0.20

MP
0.77
0.77
0.77
-0.20
0.00
-0.20
2.39

Table 2: Estimated concentration matrix for the car-
cass data (multiplied by 10) under the model M1r
with parameters restricted to being equal.

F1
4.83
-1.77
-1.77
0.30
-0.86
0.42
0.88

F2
-1.77
4.83
-1.77
-0.27
0.58
-0.37
0.88

F3
-1.77
-1.77
4.83
-0.30
-0.04
0.04
0.88

M1
0.30
-0.27
-0.30
1.40
-0.64
-0.64
-0.16

M2
-0.86
0.58
-0.04
-0.64
1.40
-0.64
-0.16

M3
0.42
-0.37
0.04
-0.64
-0.64
1.40
-0.16

MP
0.88
0.88
0.88
-0.16
-0.16
-0.16
2.64

F1
F2
F3
M1
M2
M3
MP

Starting with the independence model and doing a for-
ward selection we get the model M2 with concentra-
tion matrix in Table 3. Then we applied a clustering
algorithm to the diagonal and to the oﬀ–diagonals to
identify possible edge sets and vertex sets. Inspired by
Table 1, we asked for 3 clusters on the diagonal and
5 clusters on the oﬀ–diagonal. The model with these
restrictions is M2r and the estimated concentrations
are presented in Table 4.

This scheme was repeated with a backward selec-
tion starting from the saturated model giving model
M3. Clustering the entries as described above gave
(The estimated concentration matrices have
M3r.
been omitted).

Table 3: Estimated concentration matrix for the car-
cass data (multiplied by 10) for M2.

F1
4.06
-1.68
-1.53
0.00
-0.18
0.00
1.08

F2
-1.68
5.04
-2.12
0.00
0.00
0.00
0.78

F3
-1.53
-2.12
5.54
-0.39
0.00
0.00
0.75

M1
0.00
0.00
-0.39
1.52
-0.56
-0.56
-0.27

M2
-0.18
0.00
0.00
-0.56
1.22
-0.79
0.00

M3
0.00
0.00
0.00
-0.56
-0.79
1.51
-0.26

MP
1.08
0.78
0.75
-0.27
0.00
-0.26
2.68

F1
F2
F3
M1
M2
M3
MP

1

N = 8, 10, 15, 20, 30 and ﬁtted the models to these
training data. Then we predicted M P for the valida-
tion data consisting of 340–N carcasses and calculated
the mean squared prediction error (MSPE) deﬁned as
340−N Pi(yi− ˆyi)2 . This scheme was repeated M = 5
times and at the end average MSPE was calculated. To
provide a benchmark for comparison we also made a
principal component regression (PCR) and a partial
least squares regression (PLS). Højsgaard, Jørgensen,
Olsen and Busk (2004) have found that 3 components
were optimal in PLS and PCR for predictions of these
data, and therefore 3 components have been used here.
To ease the comparison the MSPEs were all calculated
relative to the MSPE for the PCR model.

8.3 Results

The relative MSPEs are presented in Table 5. Within
each sample size, we ﬁnd the following: It is always
beneﬁcial to reduce the saturated model M1 to the
restricted model M1r, and for small samples (N =
8, 10) the improvement is quite dramatic. (Note that
when N = 8 the saturated model is just identiﬁable as
there are 7 variables in the model).
A comparison of models Mi and Mir for i = 2, 3
yields no clear picture, but it suggests that there is a
place for reﬁnement of the brute force clustering ap-
proach used in getting from Mi and Mir. For each
sample size, one of the RCMs always performs at least
as well or better than the traditional regression meth-
ods PLS and PCR. Finally it is noted that when sam-
ple size increases the models perform more and more
similarly, which was to be expected.

8.4 Computing time

8.2 Model comparisons – predictive

performance

To evaluate the feasibility of the various models, we
took a cross validation approach as follows: Out of
the 340 carcasses we took a random sample of size

Compared with the IPS algorithm used for GGMs
the NIPS algorithm presented here is somewhat more
time consuming. For example, ﬁtting M3 (which is a
GGM) took 1.27 seconds while ﬁtting the RCM M3r
took 4.87 seconds.

156Hastie, T., Tibshirani, R. and Friedman, J. (2001).

The Elements of Statistical Learning. Springer.

Højsgaard, S. (2004). The mimR package for graphical

modelling in R. Journal of Statistical Software .

Højsgaard, S., Jørgensen, E., Olsen, E. V. and Busk,
H. (2004). A comparison of latent variable models
and partial least squares regression – with an appli-
cation to pig carcass grading. Livestock Production
Science Manuscript submitted.

Jensen, S. T., Johansen, S. and Lauritzen, S. L. (1991).
Globally convergent algorithm for maximizing like-
lihood function. Biometrika 78, 867–877.

Lauritzen, S. L. (1996). Graphical Models. Oxford Uni-

versity Press.

R Development Core Team (2004). R: A language and
environment for statistical computing. R Foundation
for Statistical Computing, Vienna, Austria, ISBN 3-
900051-00-3.

Table 5: Relative mean squared prediction error
(MSPE) (calculated relative to MSPE for principal
component regression) for diﬀerent models and diﬀer-
ent sizes of the training data sets.

M1
M1r
M2
M2r
M3
M3r
PLS
PCR

8
4.53
0.99
1.11
1.18
1.20
1.20
1.16
1.00

Sample size

10
1.08
0.92
1.03
0.99
1.04
0.95
1.01
1.00

15
1.10
0.99
1.04
1.03
1.04
1.01
1.03
1.00

20
1.06
0.99
1.03
0.99
1.07
1.00
1.04
1.00

30
1.01
0.99
1.01
1.00
1.00
1.01
1.01
1.00

9 Discussion and directions for future

work

This paper has presented an estimation algorithm for
restricted concentration models (RCMs), and it has
been proven empirically that important gains in terms
of prediction precisions can be achieved from such
models.

It is emphasized, that to use the result in JJL91 we
should strictly speaking check that the concentration
matrix stays positive deﬁnite in each step (2) and, if
not, only move half of the distance to the associated
boundary point of the parameter space. We have not
seen an example where the positive deﬁniteness has
been violated, but we have not been able to prove
theoretically that this cannot happen. For practical
purposes we therefore suggest that this check is only
performed occasionally.

To make RCMs of practical importance, it is important
to investigate possible model selection strategies for
RCMs, and this is a subject of future work. In this
connection it will become important to make a fast
implementation of the NIPS algorithm.

References

Anderson, T. W. (1970). Estimation of covariance ma-
trices which are linear combinations or whose in-
verses are linear combinations of given matrices. In:
Essays in Probability and Statistics (eds. R. C. Bose,
I. M. Chakravarti, P. C. Mahalanobis, C. R. Rao and
K. J. C. Smith), University of North Carolina Press,
Chapel Hill, N.C., 1–24.

Besag, J. E. (1974). Spatial interaction and the sta-
tistical analysis of lattice systems (with discussion).
Journal of the Royal Statistical Society, Series B 36,
192–236.

Dempster, A. P. (1972). Covariance selection. Biomet-

rics 28, 157–175.

157Fast maximum a posteriori inference in Monte Carlo state spaces

Mike Klaas

Dustin Lang

Nando de Freitas

Computer Science Department
University of British Columbia
{klaas,dalang,nando}@cs.ubc.ca

Abstract

Many important algorithms for statistical in-
ference can be expressed as a weighted max-
kernel search problem. This is the case
with the Viterbi algorithm for HMMs, mes-
sage construction in maximum a posteriori
BP (max-BP), as well as certain particle-
smoothing algorithms. Previous work has
focused on reducing the cost of this proce-
dure in discrete regular grids [4]. Monte-
Carlo state spaces, which are vital for high-
dimensional inference, cannot be handled by
these techniques. We present a novel dual-
tree based algorithm that is appliable to a
wide range of kernels and shows substantial
performance gains over na¨ıve computation.

Introduction

Max-kernel problems arise at the heart of many pow-
erful and widely-used statistical inference algorithms.
Examples include the message computation in max
belief propagation, sequence recursion in the Viterbi
algorithm, and classes of maximum a posteriori se-
quence estimation algorithms based on particle meth-
ods. This operation is expensive—requiring O(N 2) op-
erations, where N is the size of the state space of a ran-
dom variable. As a result, applications with large state
spaces either must artiﬁcially coarsen the state space
or simply choose to use less powerful inference tech-
niques. Recent work by Felzenszwalb et al. addresses
the computational burden when the state space can be
embedded in a regular discrete grid [4, 5]. This tech-
nique, based on the distance transform, is extremely
powerful in its domain, but has two major limitations:

• It is limited to kernels of the form K(x, y) =

exp(cid:8) 1

σ2kx − yk(cid:9) or exp(cid:8) 1

σ2kx − yk2(cid:9)

• It is only applicable to state spaces embedded in

a regular grid of parameters.

Monte Carlo methods, such as MCMC and particle
ﬁlters, have been shown to eﬀectively adapt to ex-
amine interesting regions of the state space, and can
achieve better results than regular discretizations us-
ing fewer support points [1, 13]. Problems requir-
ing high-dimensional inference are ubiquitous in ma-
chine learning, and are best attacked with Monte Carlo
techniques as regular discretizations grow exponen-
tially and quickly become intractable.
In this pa-
per, we address the need of fast algorithms for com-
puting weighted max-kernel on Monte Carlo grids by
demonstrating how the quadratic cost can be reduced
to N log N by adopting and extending powerful algo-
rithms proposed for N-body simulation [7, 8].1
In particular, we develop a new eﬃcient dual-tree re-
cursion to exactly solve the max-kernel problem. We
derive the method in the context of kernels parameter-
ized by a distance function,2 which represent a broad
class of frequently used kernel functions,
including
Gaussians, Epanechnikov, spherical, and linear ker-
nels, as well as thresholded versions of the same. Our
method can also be used to accelerate other spatial-
based kernels (such as K(x, y) = x · y), and problems
that have multiple kernels over diﬀerent regions of the
state space, but we restrict our attention to the simpler
and more common case in this paper.
Our empirical results show that our algorithm provides
a speedup of several orders of magnitude over the na¨ıve
method, becoming more eﬃcient after as little as 10ms
of compute time. The dual-tree algorithm still com-
pares favorably to na¨ıve computation on discrete grids
where the distance transform can be applied, but we

1We note that there are techniques for dealing with
KDE on Monte Carlo grids (fast Gauss Transform), but
these are inapplicable in the max-kernel setting.

2By distance functions we mean functions that are sim-
ilar to a metric but need not obey the triangle inequality.

158ﬁnd that the latter algorithm is superior in this case.
The performance of algorithms based on dual-tree re-
cursion as N grows is relatively well-understood; see
Gray and Moore [8] and Ihler [9]. However, we have
found that the performance of this family of techniques
also depends heavily on other variables, such as the
data distribution, the dimensionality of the problem,
and the choice of spatial index and kernel. We present
several experiments to investigate these eﬀects, and
we believe that the conclusions can be generalized to
other pruning-based dual-tree algorithms.

1 Problem setting

The algorithms we discuss in this paper are designed
to solve the following problem: We are given points
(which we will call particles) X , {xj} and Y , {yi},
and weights {wj} corresponding to the X particles.
The source (X) particles exert an inﬂuence on the tar-
get (Y ) particles given by inﬂ(xj, yi) = wjK(xj, yi),
where K(·) is an aﬃnity kernel. We wish to compute,
for each y, the maximum inﬂuence attained and the x
particle corresponding to it,3 ie.

fi = Nmax

j=1

wjK(yi, xj)

i = 1, 2, . . . , M

(1)

This procedure’s O(M N) cost dominates the runtime
of many important algorithms such as max-BP and
MAP sequence estimation, which limits their use to
settings of small order (correponding to a coarse dis-
cretization of a continuous state space or choosing a
small number of particles).
In the following section, we detail how the max-kernel
algorithm arises in common inference methods.

1.1 Maximum a posteriori belief propagation

Given a graphical model with latent variables u1:n
4,
observations z1:n, and potentials ψkl, φk, a joint prob-
ability distribution is admitted:

p(u1:n, z1:n) =

1
Z

Y

ψkl(uk, ul)Y

k,l

k

φk(uk, zk)

We are interested in computing the maximum a poste-
1:n = arg maxu1:n p(u1:n|z1:n). We
riori estimate, uM AP
can use the standard max-product belief propagation
equations for message passing and marginal (belief)

3We will subsequently refer to this procedure as

weighted maximum-kernel, or simply max-kernel.

4In describing these algorithms, we use u and z rather
than the traditional x and y to highlight the distinction
between the variables in the inference algorithms and the
variables in the max-kernel computation.

computation [12]. The message from node l to node k
is given by:

φ(ulj, zl)ψ(uki, ulj) Y

mrl(ulj)

r∈N (l)−k

mlk(uki) =

|ul|
max
j=1

(2)
where N (l)−k denotes the neighbours of node l exclud-
ing k. We can re-write equation (2) as a max-kernel
problem by setting

{xj} = {ulj},
{yi} = {uki},

wj = φ(ulj, zl) Y

r∈N (l)−k

mrl(ulj),

K(yi, xj) = ψ(uki, ulj)

1.2 MAP sequence estimation using particle

methods

Consider the Markovian time-series model with latent
state ut and observations zt given by

ut ∼ p(ut|ut−1)
zt ∼ p(zt|ut)

oN

n
PN

i=1

u(i)
1:n

using sequential

bp(un|z1:n) = 1

In standard particle ﬁltering [3], we draw a
set of samples
impor-
tance sampling in order to approximate the ﬁl-
tering distribution with a Monte Carlo estimator
(dun) de-
notes the delta Dirac function. This is typically done
in a chain (or tree) with n nodes, at a cost of O(nN).
However, our goal is to obtain an estimate of the max-
imum a posteriori sequence

(dun), where δu

i=1 δu

(i)
n

(i)
n

N

1:n (n) , arg max
uM AP

u1:n

p(u1:n|z1:n).

(3)

As introduced by Godsill et al. in [6], equation (3) can
be estimated by performing a Viterbi-like algorithm
on the Monte Carlo state space induced by the ﬁltered
particles at time t. At the heart of this algorithm lies
the following recursion:

δk(j) = log p

+ max

i

h

k

zk|u(j)
δk−1(i) + log p

(cid:16)

k |u(i)
u(j)

k

(cid:17)i

(4)

(cid:16)

(cid:17)

This must be computed for each particle, thus incur-
ring a O(N 2) cost. It is straightforward to show that
the maximization in (4) is equivalent to the max-kernel
problem in equation (1) transformed to log space.

159Figure 1: Example of pruning the max-kernel algo-
rithm (for a single y particle). The candidate (dark)
and non-candidate (light) nodes are shown.
In the
bottom-right plot, a close-up of the six ﬁnal candidate
nodes is shown (dashed). The single box whose par-
ticles are examined is shown in black. The subset of
the particles that are examined individually is shown
in black. There were 2000 particles in X, of which six
nodes (containing 94 particles total) were candidate
leaf nodes. Of these, only six particles from the ﬁrst
node were examined individually.

2 Fast methods for computing

max-kernel

2.1 The distance transform

In [4], Felzenszwalb and Huttenlocher derive a fast
algorithm for a class of max-kernel problems by ob-
serving that the maximization in equation (1) is solv-
able by applying the distance transform. This achieves
O(N) cost and is very eﬃcient in practice. Addition-
ally, the problem is separable in dimensionality, so a
d-dimensional transform of N d points costs O(dN d).

2.1.1 Extension to Monte Carlo grids in 1-D

While the distance transform was designed to work ex-
clusively on regular grids, it is easily extended to irreg-
ular grids in the one-dimensional case, for a small in-
crease in cost. This observation is novel, to our knowl-
edge, although it represents a rather direct extension
to the original algorithm.
Assume we are given source particles {x1, . . . , xN} and
target particles {y1, . . . , yM}. The ﬁrst step of the
algorithm is to compute the lower envelope of the

Figure 2: Dual-tree max-kernel example. Top: the in-
ﬂuence bounds for the nodes shown in ﬁgure 1. The
pruning threshold at each level is shown (dashed line),
along with the bounds for each candidate node. Bot-
tom: pruning at the leaf level:
in the example, six
leaf nodes are candidates. We begin examining parti-
cles in the ﬁrst box. As it happens, the ﬁrst particle
we examine is the best particle (the correct answer).
Pruning by particle weight (the upper marker) allows
us to ignore all but the ﬁrst six particles. The pruning
threshold is then suﬃciently high that we can prune
the remaining candidate nodes without having to ex-
amine any of their particles.

parabolas anchored at {xi}. This step is unchanged,
save that the x particles need to be pre-sorted at a cost
of O(N log N). The second step is to calculate the
value of the lower envelope at each y particle. This
can be done by either pre-sorting the y particles, or
employing binary search on the lower-envelope, which
costs O(M log M) or O(M log N) respectively.
Unfortunately, this extension only applies to the one-
dimensional case. Other means must be used to
compute higher-dimensional max-kernel problems on
Monte Carlo grids.

PSfragreplacementsLogInﬂuence0−1−2−3−4−50−100ObjectsCandidateBoxesExaminedBoxesExaminedParticlesSkippedParticlesSkippedBoxesPSfragreplacementsLogInﬂuence0−1−2−3−4−50−100ObjectsCandidateBoxesExaminedBoxesExaminedParticlesSkippedParticlesSkippedBoxes160inputs: root nodes of X and Y trees: Xr, Yr.
algorithm:
leaves = {}, candidates = {Xr}
max recursive(Yr, leaves, candidates,−∞)
function max recursive(Y, leaves, candidates, τ )
if (leaf (Y ) and candidates = {})
// Base Case: reached leaves (see ﬁgure 4).
max base case(Y, leaves)
else // Recursive case: recurse on each Y child.
foreach y ∈ children∗(Y )
τy = τ, valid = {}
foreach p ∈ candidates
// Check if we can prune parent node p.

if`w (p) K`dl (p, y)´ < τy
“
“

continue
foreach x ∈ children (p)
// Compute child bounds.
f{u,l} (x) = w (x) K
// Set pruning threshold.
τy = max
valid = valid ∪ {x ∈ children (p) : f u (x) ≥ τy}
valid = {x ∈ valid : f u (x) ≥ τy}
leavesy = {x ∈ valid : leaf (x)}
candidatesy = {x ∈ valid : not (leaf (x))}
sort(leavesy by f l)
max recursive (y, leavesy, candidatesy, τy)

d{l,u} (x, y)

””

τy , max

f l(x)

”

“

´

x

Figure 3: Dual-tree max-kernel algorithm, part 1.

2.2 Dual-tree max-kernel

In this section we present a novel dual-tree algorithm
for solving the weighted max-kernel problem. Our al-
gorithm is based on bounding the distance and weight,
hence the inﬂuence, of subtrees of X particles upon
subtrees of Y particles. We begin by constructing
space-partitioning trees for the X particles and Y
points (see Section 2.3). The leaf nodes of these trees
can contain multiple points. We also cache at each
node in the X tree the maximum particle weight in
the node (w(X)). At leaf nodes, we sort the particles
in order of decreasing weight.
The algorithm proceeds by doing a depth-ﬁrst recur-
sion down the Y tree. For each node, we maintain
a list of X nodes that could contain the best parti-
cle (candidates). We know the particle of maximum
weight in a given node X. Thus, we can bound the
inﬂuence of X by considering the cases when that par-
ticle is as close (or far) from Y as possible.
For each X node we compute the lower and upper
bounds of the inﬂuence of the maximum particle in
the node on all points in the Y node (f{l,u}) by evalu-
ating the kernel at the upper and lower bound on the
distances to particles in the node (d{i, l}). The largest
lower bound on inﬂuence is the pruning threshold (τ):
any candidate node whose upper bound is less than
this threshold cannot possibly contain the best parti-

“

“

function max base case(Y, leaves)
foreach x ∈ leaves
f{u,l} (x) = w (x) K
τ = max
leaves = {x ∈ leaves : f u (x) ≥ τ}

”
sort`leaves by f l´

d{l,u} (x, Y )

f l (x)

x

”

// Examine individual y points.
foreach y ∈ Y
τy = τ
foreach x ∈ leaves
// Prune nodes by Y (cached), then by y.

if`f u(x) < τy or w (x) K`dl (x, y)´ < τy
„

continue
// Examine individual x particles.
foreach i ∈ x
// Prune by weight.

«

´

if

f u (x)

w (i)
w (x)

< τy

break

f (i) = w (i) K (d (i, y))
if (f (i) > τy)
// i is the new best particle.
τy = f (i) , x∗ (y) = i

Figure 4: Dual-tree max-kernel algorithm, part 2.

cle, and hence need not be considered. See Figures 1
and 2 for an example.
In each recursive step, we choose one Y child on which
to recurse. Initially, the set of X candidates is the set
of candidates of the parent. We sort the candidates
by lower bound, which allows us to explore the most
promising nodes ﬁrst. For each of the candidates’ chil-
dren, we compute the lower bound on distance and
hence the upper bound on inﬂuence. Any candidates
that have upper bound less than the pruning threshold
are pruned. For those that are kept, the lower inﬂuence
bound is computed; these nodes have the potential to
become the new best candidate.
The inﬂuence bounds tighten as we descend the tree,
allowing an increasingly number of nodes to be pruned.
Once we reach the leaf nodes, we begin looking at in-
dividual particles. The candidate nodes are sorted by
lower inﬂuence bound, and the particles are sorted by
weight, so we examine the most promising particles
ﬁrst and minimize the number of individual particles
examined.
In many cases, we only have to examine
the ﬁrst few particles in the ﬁrst node, since the prun-
ing threshold often increases suﬃciently to prune the
remaining candidate nodes. Figures 3 and 4 contain
pseudo-code for the algorithm.
For a given node in the Y tree, the list of candidate
nodes in the X tree is valid for all the points within
the Y node, which is the secret behind the eﬃciency
of dual-tree recursion. In this way, pruning decisions
are shared among Y points when possible.

161important as in some applications the kernel evalua-
tion is extremely expensive and thus dominates the
runtime of the algorithm.

3.1 Multi-modal non-linear time series

Consider the following standard reference model [3, 6]:

+ 8 cos 1.2t + vt+1

where vt ∼ N (0, σv) and wt ∼ N (0, σw). The ﬁl-
tered distribution is bimodal and highly non-linear
(ﬁgure 5), meaning the standard particle ﬁlter pro-
duces signiﬁcant error even with a high particle count.
After running a standard SIR particle ﬁlter, we im-

ut+1 =

zt+1 =

1
2 ut + 25 ut
1 + u2
t
+ wt+1

u2
t+1
20

2.3 Spatial indices

Spatial indices (sometimes called spatial access meth-
ods) intelligently subdivide a set into regions of high
locality given some concept of distance. We brieﬂy
review two commonly-used spatial indices.

2.3.1 Kd-trees

A kd-tree operates on a vector ﬁeld, and recursively
chooses a dimension and split point to localize parti-
cles The dimension of largest spread is typically chosen
as splitting dimension. Kd-trees are eﬀective in low di-
mensional settings; a 2-D example is given in ﬁgure 1
(not all levels are shown).

2.3.2 Anchors hierarchy and metric trees

Metric trees are more relaxed in their requirements
than kd-trees; they need only a deﬁned distance met-
ric. Nodes in a metric tree consist of a pivot (a point
lying at the centre of the node), and radius. All points
belonging to the node must have a distance to the
pivot smaller than the radius of the node.5 The An-
chors hierarchy was introduced by Moore in [11] and is
an eﬃcient means of constructing a metric tree. Unlike
kd-trees, metric tree construction and access costs do
not have factors that explicitly depend on dimension.

Figure 6: Particle ﬁlter and MAP estimates of the
latent state in the 1-D time series experiment. Mean
error for the particle ﬁlter was 4.05, while the MAP
solution achieved a mean error of 1.74.

plemented the MAP sequence estimation described
in Section 1.2. Figure 6 demonstrates the accuracy
gained by calculating the MAP solution. We chose
a one-dimensional setting so that the dual-tree al-
gorithm could be directly compared against the dis-
tance transform (using the modiﬁed algorithm from
Section 2.1.1). Figures 7 and 8 summarize the results.
It is clear that the distance transform is superior in
this setting, although the dual-tree algorithm is still
quite usable, being several orders of magnitude faster
than the na¨ıve method.

3.2 Beat-tracking

Beat-tracking is the process of determining the time
slices in a raw song ﬁle that correspond to musical
beats. This is a challenging problem: both the tempo
and phase of the beats must be estimated throughout

Figure 5: Filtered distribution p(ut|z1:t)

3 Performance in N

We turn to empirical evaluation of the dual-tree algo-
rithm. In this section, we focus on performance in syn-
thetic and real-world settings as N grows; comparisons
are made both in settings where the distance transform
is applicable and where it is not. We present results
in terms of both CPU time and number of distance
computations (kernel evaluations) performed. This is

5Note: it is not the case that all points within the radius

of the pivot belong to the node.

−25−20−15−10−5051015202502040608010000.10.20.30.4Time (t)utp(ut|z1:t)05101520253035404550−20−15−10−50510152025time stepNoisy obs.True xPF estimateMAP estimate162Figure 7: 1-D time series results. The dual-tree al-
gorithm became more eﬃcient than na¨ıve computa-
tion after approximately 70ms of compute time. Both
dual-tree and distance transform methods show similar
asymptotic growth, although the constants in the dis-
tance transform are approximately three times smaller.

Figure 9: Beat-tracking results:
particle
count. The dual-tree method becomes more eﬃcient at
t = 10ms, and thereafter dominates the na¨ıve method.

time v.

Figure 8: 1-D time series results: distance computa-
tions v. particle count.

the song. MAP sequence estimation after particle ﬁl-
tering has achieved impressive results in the literature.
We omit the details of the probability model for the
sake of brevity, but a full explanation is found in [10].
The algorithm used was the forward pass particle ﬁl-
ter, backward pass Viterbi algorithm described in Sec-
tion 1.2. Since the state space of this model is a three-
dimensional Monte Carlo grid, the distance transform
cannot be used. Figures 9 and 10 summarize the re-
sults: songs can be processed in seconds rather than
hours with this method. Using the fast method also
enables more particles to be used, which results in a
better solution: the probability of the MAP sequence
with 50000 particles was p = 0.87, while using 1000
particles resulted in a MAP sequence of probability
p = 0.53.

Figure 10: Beat-tracking results: distance computa-
tions v. particle count.

4 The eﬀect of other parameters

4.1 Distribution and dimensionality

To examine the eﬀects of other parameters on the
behaviour of the dual-tree algorithm, we ran several
experiments varying dimensionality, distribution, and
spatial index while keeping N constant. We used two
spatial indices: kd-trees and metric trees (built us-
ing the Anchors hierarchy) as described in Section 2.3.
We generated synthetic data by drawing points from a
mixture of Gaussians distributed evenly in the space.
Figure 11 shows a typical clustered data distribution.
In all runs the number of particles was held constant
at N = 20, 000, and the dimension was varied to a
maximum of d = 40. Figures 12 and 13 show the
results for CPU time and distance computations, re-
spectively. In these ﬁgures, the solid line represents a
uniform distribution of particles, the dashed line rep-
resents a 4-cluster distribution, the dash-dot line has

10210310410−1100101102103ParticlesTime (s)naivedual−treedist. transform10210310410510610710810910101011ParticlesDistance computationsnaivedual−treedist. transform10210310410−310−210−1100101102ParticlesTime (s)naivedual−tree102103104105106107108109ParticlesDistance computationsnaivedual−tree16320 clusters, and the dotted line has 100. We ex-

pect methods based on spatial indexing to fare poorly
given uniform data since the average distance between
points quickly becomes a very peaked distribution in
high dimension, reducing the value of distance as a
measure of contrast. The results are consistent with
this expectation:
for uniform data, both the kd-tree
and anchors methods exceeded O(N 2) distance com-
putations when d ≥ 12. More surprising is that the
kd-tree method consistently outperformed the anchors
method on uniform data even up to d = 40. The depth
of a balanced binary kd-tree of 20000 particles and leaf
size 25 is ten, so for d > 10 there are many dimensions
that are not split even a single time!

Figure 11: Synthetic data set with c = 20 clusters.

Figure 12: Time v. dimensionality. For clarity, only
the uniform distribution and one level of clustered data
are shown. This experiment demonstrates that some
structure is required to accelerate max-kernel in high
dimensions.

dimensionality;

Figure 14: Time v.
ratio to
kd-tree = 1. Metric trees are better able to properly
index clusters: the more clustered the data, the smaller
dimensionality required for the anchors method to out-
perform kd-trees (d = 30 for somewhat-clustered data,
d = 15 for moderately-clustered data, and d = 6 for
signiﬁcantly-clustered data).

Of more practical interest are the results for clustered
data. It is clear that the distribution vastly aﬀects the
runtime of dual-tree algorithms; at d = 20, perform-
ing max-kernel with the anchors method was six times
faster on clustered data compared to uniform. We ex-
pect this eﬀect to be even greater on real data sets, as
the clustering should exist on many scales rather than

Figure 13: Distance computations v. dimensionality.
The level of clustering shown is less than in ﬁgure 12.
For kd-trees, clustering hurts performance when d ≤ 8.

1104010−1100101102DimensionTime (s)naiveanchorskd−tree11040106107108DimensionDistance computationsnaiveanchorskd−tree1anchorskd−tree1anchorskd−tree1anchorskd−tree110401DimensionRelative time (s)anchorskd−tree164simply on the top level as is the case with our synthetic
data. It is also interesting to note the diﬀerent eﬀect
that clustering had on kd-trees compared to metric
trees. For the anchors method, clustering always im-
proved the runtime, albeit by a marginal amount in
low dimensions. For kd-trees, clustering hurt perfor-
mance in low dimensions, only providing gains after
about d = 8. The diﬀerence in the two methods is
shown in ﬁgure 14.

4.2 Eﬀect of kernel width

To measure the eﬀect of diﬀerent kernels, we test both
methods on a 1-D uniform distribution of 200, 000
points, and use a Gaussian kernel with bandwidth (σ)
varying over several orders of magnitude. The number
of distance computations required was reduced by an
order of magnitude over this range (ﬁgure 15). Wider
kernels allow the weights to have more contrast, hence
aﬀording more opportunities for pruning.

and dynamic quantization [2] to achieve even faster re-
sults, albeit at the expense of the loss of accuracy that
those methods entail. The techniques we present could
also be integrated seamlessly into hierarchical BP [4].
We also look at the other variables that aﬀect the per-
formance of dual-tree recursion, such as dimensional-
ity, data distribution, spatial index, and kernel. These
parameters have dramatic eﬀects on the runtime of
the algorithm, and our results suggest that more ex-
ploration is warranted into these eﬀects—behaviour as
N varies is only a small part of the story.

References

[1] N Bergman, Recursive Bayesian estimation: Naviga-
tion and tracking applications, Ph.D. thesis, Depart-
ment of Electrical Engineering, Link¨oping University,
Sweeden, 1999.

[2] J M Coughlan and H Shen, Shape matching with belief
propagation: Using dynamic quantization to accomo-
date occlusion and clutter, GMBV, 2004.

[3] A Doucet, N de Freitas, and N J Gordon (eds.), Se-
quential Monte Carlo methods in practice, Springer-
Verlag, 2001.

[4] P Felzenszwalb and D Huttenlocher, Eﬃcient belief

propagation for early vision, CVPR, 2004.

[5] P Felzenszwalb, D Huttenlocher, and J Kleinberg,
Fast algorithms for large-state-space HMMs with ap-
plications to web usage analysis, NIPS (2003).

[6] S J Godsill, A Doucet, and M West, Maximum a pos-
teriori sequence estimation using Monte Carlo particle
ﬁlters, Ann. Inst. Stat. Math. 53 (2001), no. 1, 82–96.

[7] A Gray and A Moore, ‘N-Body’ problems in statistical

learning, NIPS, 2000, pp. 521–527.

Figure 15: Eﬀect of kernel choice: distance computa-
tions v. bandwidth of a Gaussian kernel.

[8] A Gray and A Moore, Rapid evaluation of multiple

density models, AISTATS, 2003.

5 Conclusion

Weighted maximum-kernel problems are common in
statistical inference, being used, for instance, in be-
lief propagation and MAP particle ﬁlter sequence es-
timation. We develop an exact algorithm based on
dual-tree recursion that substantially reduces the com-
putational burden of this procedure for a wide vari-
ety of kernels. It is particularly important when the
state space lies on a multi-dimensional Monte Carlo
grid, where, to our knowledge, no existing accelera-
tion methods can be applied.
The method we present speeds up the inner loop of be-
lief propagation, which means that it can be combined
with other acceleration methods such as node pruning

[9] A T Ihler, E B Sudderth, W T Freeman, and A S
Willsky, Eﬃcient multiscale sampling from products
of Gaussian mixtures, NIPS 16, 2003.

[10] D Lang and N de Freitas, Beat tracking the graphical

model way, NIPS 17, 2004.

[11] A Moore, The Anchors Hierarchy: Using the triangle
inequality to survive high dimensional data, UAI 12,
2000, pp. 397–405.

[12] J Pearl, Probabilistic reasoning in intelligent systems:
networks of plausible inference, Morgan-Kaufmann,
1988.

[13] C P Robert and G Casella, Monte Carlo statistical

methods, Springer-Verlag, New York, 1999.

10−610−410−2100102024681012x 106sDistance computationsdual−treedist. Transform165Generative Model for Layers of Appearance and Deformation

Anitha Kannan1, Nebojsa Jojic2, Brendan J. Frey1

1 Probabilistic and Statistical Inference Group, University of Toronto

2 Microsoft Research, Redmond, WA, USA

Abstract

We are interested in learning generative mod-
els of objects that can be used in wide
range of tasks such as video summariza-
image segmentation and frame inter-
tion,
polation.
Learning object-based appear-
ance/shape models and estimating motion
ﬂelds (deformation ﬂeld) are highly interde-
pendent problems. At the extreme, all mo-
tions can be represented as an excessively
large set of appearance exemplars. However,
a more e–cient representation of a video se-
quence would save on frame description if it
described the motion from the previous frame
instead. The extreme in this direction is also
problematic as there are usually causes of ap-
pearance variability other than motion. The
(cid:176)exible sprite model (Jojic and Frey 2001)
illustrates the beneﬂts of joint modelling of
motion, shape and appearance using very
simple models. The advantage of such a
model is that each part of the model tries
to capture some of the variability in the data
until all the variability is decomposed and ex-
plained through either appearance, shape or
transformation changes. Yet, the set of mo-
tions modelled is very limited, and the resid-
ual motion is simply captured in the variance
maps of the sprites.
In this paper, we de-
velop a better balance between the transfor-
mation and appearance model by explicitly
modelling arbitrary large, non-uniform mo-
tion.

1

Introduction

Our objective is to learn generative models of objects
in a visual scene so that scene analysis (such as video
summarization) can be e–ciently performed. An im-
portant component of scene analysis involves learn-

ing object based appearance/shape models and esti-
mate motion reliably. These two interesting problems
of learning object based appearances and estimating
motion are extensively studied separately even though
both appearance and motion provide independent cues
for estimating each other. In this work, we introduce a
probabilistic generative model that uniﬂes appearance
modelling and motion estimation.

A step in this direction is reported in (Jojic and Frey
2001), as a layered extension of (Frey and Jojic 1999)
for multiple objects. Here, the goal
is to learn a
layered density model for image formation. Given
an input video sequence, the approach iteratively up-
dates the appearances and masks of objects associated
with each layer and the estimates of global transforma-
tion(motion) of the objects while capturing the resid-
ual motion in the variance maps of the sprites. Despite
this appearance (cid:176)exibility, the model requires an ex-
cessive number of appearance classes to capture many
types of nonuniform large motions for which the trans-
lational variable is not a su–cient descriptor. We de-
scribe a new generative model for layered image forma-
tion that simultaneously learns deformation-invariant
appearances and infer complex deformation ﬂelds. We
use variational inference and generalized EM for learn-
ing and present results on (cid:176)ow computation, image
segmentation and frame interpolation.

2 Related work

In a scene with multiple objects, approaches to mo-
tion estimation that operate on matching patches from
one image to another (Lucas and Kanade 1981) under
perform at the boundary regions due to occlusions and
disocclusions. A good appearance model enables eﬁec-
tive handling of boundary regions. On the other hand,
objects can undergo complex deformations, and mo-
tion provides useful cues to learn appearances (Black
and Jepson 1996). Thus, the estimation of appear-
ances and motion should be done in tandem. A popu-
lar approach to this is to use a layered representation

166in which we decompose a 3 dimensional scene into a
set of 2 dimensional layers.

One such layered formalism is based on mixture mod-
els (Ayer and Sawhney 1995), (Jepson and Black
1993), (Weiss and Adelson 1996) in which each pixel
is assigned probabilistically to one of several layers.
When multiple objects are moving in a scene, there
is a fair amount of occlusions and disocclusions, and
without proper appearance models for the objects in
the scene, it is extremely di–cult to ﬂnd the bound-
aries of the object.

In (Black and Fleet 2000), a framework for modelling
motion discontinuities is presented. In this work, the
foreground and background are separated by a straight
edge within a single, ﬂxed window in the image se-
quences. The image sequence within the window is
modelled by a generative model that predicts the im-
age at time t from the image at time t ¡ 1 using un-
known state variables that describe the location of the
edge and the motions of the foreground and back-
ground. An algorithm based on particle ﬂltering is
used to infer the location of the edge, motion vec-
tors for the foreground and the background at each
time step. Again, this approach does not have explicit
model for appearances of the objects, but instead re-
lies on straight edge to diﬁerentiate foreground and
background pixels within a small window. Moreover,
for complex object shapes, a single edge may not be
su–cient to diﬁerentiate the two layers.

In (Jojic and Frey 2001), a generative model frame-
work is used to automatically learn layers of \(cid:176)exible
sprites", which are probabilistic 2-dimensional appear-
ance maps and masks of moving, occluding objects.
An important assumption of this model is that pixels
belonging to a sprite move with the same velocity (for
instance, uniform translation). For many interesting
video sequences, this assumption is too rigid.

In (Frey, Jojic and Kannan 2003), we suggest lineariz-
ing the transformation manifold locally. This approach
has two drawbacks - it requires an additional global
transformation for ﬂnding the position and often a lin-
ear manifold is not su–cient to capture large complex
deformation. The use of low-frequency wavelets for
smooth deformation ﬂelds (Jojic et al. 2001) suﬁers
from the same problem.

3 Flexible sprites with deformation

ﬂelds

Fig. 1 shows the hierarchical generative model that de-
scribes the process involved in two-layer image forma-
tion. The statistical generative process is as follows:
For each layer, an appearance and a mask are gen-
erated from appropriate prior distributions associated

with object classes. We sample deformation vectors
for each pixel. The deformation ﬂeld is then applied
to both the appearance and the mask. The position
variables are randomly selected and the appropriate
latent images shifted in accordance. The ﬂnal image
is composed from the layers according to the masks,
which can be either continuous or discrete.

At this juncture, we would like to point out that the
deformation ﬂeld is fully expressive and nonlinear, and
the model without the position variable can still cap-
ture well the correct global motion. We have added
the shift variable only to serve the purposes of regu-
larization and speedup of computation. There are too
many relatively good solutions to arbitrary matching
patches in the mean image and the observation. The
existence of the shift variable limits the search space
for the deformation ﬂeld estimation, and regularizes
the search.

This is also the main diﬁerence from our earlier work
(Frey, Jojic and Kannan 2003), where we used a lin-
earizing manifold locally. To make this linearization
work, an added nonlinearity is needed, and for that
purpose, we used discrete shifts.

4 A generative model for occluded

patches in motion

Although the following discussion applies to an arbi-
trary number of layers, we consider for simplicity a
two-layer model, consisting of a foreground and a back-
ground. We treat foreground appearance (denoted by
f ) and background appearance (b) as parameters that
apply to an entire sequence. (In the full model, there
are several layers and several appearance classes that
can occupy them).

We associate with the foreground layer a binary mask
m of the same size as f such that mi=1 indicates that
the corresponding pixel is a foreground pixel. Let the
probability that mi = 1 be ﬁi so that

P (m) = Y

i

ﬁmi

i

(1 ¡ ﬁi)(1¡mi):

Although the multiplicative alpha map we used in
some of our previous papers is attractive for model-
ing mixed pixels, the binary mask tends to allow for a
more robust inference (Frey and Jojic 2004)(Williams
and Titsias 2003).

Each pixel in the latent images undergoes a deforma-
tion. In this paper, we use a discrete coordinate system
for clarity, although techniques for sub-pixel inference
and multi-scale search can be used. A priori the fore-
ground and background motion vectors, U and V are
independent and follow uniform distribution denoted
by P (U) and P (V). We can favor smaller motions by
using, for instance, a Gaussian prior on displacement.

167Ap(cid:13)pe(cid:13)aran(cid:13)ce(cid:13)

Ma(cid:13)sk(cid:13)

Ap(cid:13)pe(cid:13)aran(cid:13)ce(cid:13)

Ma(cid:13)sk(cid:13)

Deformatio(cid:13)n f (cid:13)ie(cid:13)ld(cid:13)

Deformatio(cid:13)n f (cid:13)ie(cid:13)ld(cid:13)

Position(cid:13)

Position(cid:13)

Figure 1: Illustration of the generative model using two layers. The images used in this ﬂgure are obtained by
learning the model using a video sequence of a person walking towards the camera diagonally. The deformation
model is nonlinear and is fully expressive; the additional level of global transformation provides regularization
and oﬁers signiﬂcant computational advantage as discussed in sec. 3, but could be instead absorbed into the
deformation ﬂeld.

168Every M £ N observed frame is decomposed into a
(M ¡ K + 1) £ (N ¡ K + 1) grid of K £ K overlapping
patches in the spirit similar to our epitomic represen-
tations (Jojic, Frey and Kannan 2003). We let P(z)
denote the set of coordinates that are in the patch cen-
tered at z so that P(z) = fw : jw ¡ zj • Kg and the
corresponding pixel intensities to be I(P(z))

For pixel I t(z) in the observed image at time t, the
foreground motion vector is represented by the random
variable Ut(z), and the background motion vector by
the random variable Vt(z).

To generate a pixel I t(z) in the observed image at time
t, a foreground motion vector , Ut(z) = u from P (U)
and a background motion vector Vt(z) = v from P (V)
are drawn. The intensity of the pixel in the patch P(z)
at time t is generated using :

I t(w 2 P(z)) =

f (w+u)m(w+u) ⁄b(w+v)(1¡m(w+u)) + noise

Thus, when m(w+ u) = 1, foreground pixel intensity
is observed, and when m(w+u) = 0, background pixel
intensity is observed at pixel location w 2 P(z). We
assume that the (sensor) noise is Gaussian with vari-
ance (cid:190)2 so that the observation likelihood of the patch
is a Gaussian given by,

P (I t(P(z))jUt(z) = u; Vt(z) = v) / exph

¡ X

w2P(z)

(f (w+u)m(w+u)b(w+v)1¡m(w+u) ¡I t(w))2

2(cid:190)2

i

As in the epitome representation, we assume that the
patch appearances are independent.

Let the motion ﬂelds in all nearby frames be U and V
and the observed patches in all nearby frames be I so
that joint distribution is proportional to

P (U ; V; I; m) /

P (m)P (I t(P(z))jUt(z) = u; Vt(z) = v; m) (1)

Y

t

Y

z

5

Inference & Learning

For learning, the natural choice is the Expectation
Maximization algorithm (Dempster, Laird and Rubin
1977) that maximizes the likelihood of observation.
However, as exact inference is intractable, we resort
to variational approximation (Jordan et al. 1999) for
the posterior and use generalized EM (Neal and Hin-
ton 1998) for learning.

For each observed image, we approximate posterior as:

P (U; V; mjI t) = Y

z

qt(U(z); V(z))qt(m)

Letting ﬂt
pixel in the tth frame, and ﬂt

i be the probability that mi=1 given the ith

i = 1-ﬂt
i ,

qt(m) = Y

i

(ﬂt

i )mi ﬂt
i

(1¡mi)

Generalized EM maximizes the bound on the (log)
probability of the data:
logP (I) ‚ X
X

qt(U(z); V(z))qt(m)

X

X

u;v

t

z

m

log

P (U (z); V (z); I t(P(z)); m)

qt(U(z); V(z))qt(m)

Before, we derive the update equations, we deﬂne two
quantities: We allow every patch to shift by at most
D pixels. This reduces the search space and therefore
the computational cost. When there is large motion,
we can further reduce this search space D by incorpo-
rating global transformation, as described in sec. 3.

The set of all coordinates in the observed image whose
K £ K patches can \reach" coordinate x in f or b
when moved by at most D is R(x) = fz : jx ¡ zj •
(K ¡ 1)=2 + Dg The set of all motion vectors for the
patch at z in observed image that cause a pixel in the
patch to be mapped to x in f or b is

M(x; z) = fu : j(x ¡ z) ¡ uj • (K ¡ 1)=2; juj • Dg:

The posterior distribution over the motion vectors is

qt(U(z) = u; V(z) = v) = ‰ exph¡

1
2(cid:190)2 X

w2P(z)

nﬂt

w(I t(w) ¡ f (w+u))2 + ﬂt

w(I t(w) ¡ b(w+v))2oi
(2)
where ‰ ensures that Pu Pv P (Ut(z) = u; Vt(z) =
vjI t) = 1. Due to the use of binary mask, the com-
putation inside the exponential splits into sum of two
distance measures. When the posterior over the mask
is peaked, pixels in the observed patch that are at-
tributed to foreground are compared with patch from
the shifted foreground, and observed pixels that be-
long to background are matched with the correspond-
ing shifted patch in the background. This distance
computation need not be done on a patch by patch
basis, but instead by observing that each pixel partic-
ipates in a large number of patches, we can employ
simple trick using cumulative sums and calculate the
distances for all patches in tandem.

The posterior distribution over the mask is

w = 1=h1 + exp‡X
ﬂt

u;v

q(Ut(z) = u; Vt(z) = v)

((I t(w) ¡ b(w + v))2 ¡ (I t(w) ¡ f (w + u))2)·i (3)

169Figure 2: Top row: entire sequence of 6 frames used to train the model. Notice that one person is moving
towards the camera, inducing a zooming in eﬁect, and another person moving in the background. Bottom
row: interpolated frame between adjacent frames in the top row. Interpolation is performed using the learned
parameters and the inferred deformation ﬂelds.

We use < : >= Pt Pz2R(y) Pu2M(y;z) Pv2M(y;z)
to represent the su–cient statistic collected from all
pixels, z in all frames, t, that map pixel y and the
motion vectors for z that cause the pixel to be mapped.

The update for background appearance is:

b(y) ˆ

¿ﬂt

y¡vq(Ut(z) = u; Vt(z) = v)I t(y¡v)(cid:192)
¿ﬂt

y¡vq(Ut(z) = u; Vt(z) = v)(cid:192)

inferring the layered optical (cid:176)ow in images. However,
in the full (cid:176)exible sprites model, the chosen variational
factorization, when combined with the variational fac-
torization of the shifts in the original (cid:176)exible sprites
paper leads to e–cient inference and learning whose
results are shown in Fig. 1. We omit the mathemati-
cal details for brevity.

(4)

6 Experimental results

The above update involves aligning the observed pixel
with respect to the background using the posterior dis-
tribution over the motion vectors and then multiplying
this with the posterior probability of the pixel belong-
ing to the background. Since multiple patches from all
the frames contribute to updating the same pixel in the
background, the denominator normalizes for multiple
counts.

The foreground appearance is updated similarly:

f (y) ˆ

¿ﬂt

y¡uq(Ut(z) = u; Vt(z) = v)I t(y¡u)(cid:192)
¿ﬂt

y¡uq(Ut(z) = u; Vt(z) = v)(cid:192)

(5)

The prior probability of a pixel to be from the fore-
ground is given by:

ﬁy ˆ

¿ﬂt

y¡uq(Ut(z) = u; Vt(z) = v)(cid:192)
¿q(Ut(z) = u; Vt(z) = v)(cid:192)

(6)

We initialize the appearance variables to a reference
frame (usually the middle frame in the sequence) and
let the prior distribution over the mask to be uniform.
We iterate between ﬂnding the posterior over motion
vectors and the posterior over the mask in the Estep,
and updating the appearances and the prior distribu-
tion for the mask in the Mstep. This procedure enables

6.1 Modelling complex deformation and

appearances in two layers

For this experiment, we used 6 frames of 88 £ 133 RGB
sequence shown in ﬂg. 2. The sequence has a person
moving towards the camera in front of a moving back-
ground inducing a complex deformation ﬂeld. There
is also another person walking behind in the opposite
direction. The translational motion of the background
is due to camera shake.

We trained our foreground-background model on this
sequence using 5£5 overlapping patches. For compu-
tational reasons, we restricted the search space for the
foreground motion to be 4 pixels in both directions
(81 possible directions). The background motion was
restricted to 2 pixels in the horizontal direction. The
state space of the posterior distribution over the mo-
tion ﬂeld has a cardinality of 405 (9 £ 9 £ 5 £ 1). Upon
investigation, we found that the posterior distribution
is peaked at a few values. This fact can be used to
address the storage issue during inference. In fact, in
our experiments we store the distribution of only the
top 20 motion directions.

In Fig. 3b, we show the learned appearances of the
foreground and background, and the probability dis-
tribution of the binary mask. It is interesting to notice
that the learned mask distribution has captured the
person walking behind as part of the foreground. Also,
some of the occluded background pixels are ﬂlled in. In
ﬂg. 3a, results of learning (cid:176)exible sprites model with-
out deformation is shown. Since, the (cid:176)exible sprites

170a)

b)

Figure 3: Top row: Flexible sprites model Background, foreground (masked) and transparency mask learned
using the two layer sprites model on the data in Fig. 2. The complex deformation of the foreground object can’t
be modelled using this model.
Bottom row:Proposed model Learned background, foreground and probability values of binary mask learned. The
foreground appearance is invariant to deformation, and the background has lesser number of occluded pixels,
and the mask captures the person moving away from the camera as part of the foreground.

model assumes that the pixels belonging to a layer
move with the same velocity it can not handle non-
uniform motion. In fact, some of the foreground pixels
are misclassiﬂed to be background pixels as the corre-
sponding background pixels are always occluded.

Inference in this model also gives us the distribution
over the motion vectors for each pixel and for each
layer. Using this we can compute the expected motion
for each pixel by averaging the foreground and back-
ground motion weighted by their posterior probabili-
ties. The middle frame is considered as the reference
frame for which the motion is set to be 0. Fig. 4 shows
the inferred deformation ﬂeld for each frame with re-
spect to the reference frame. Note, however, that our
motion ﬂeld is deﬂned with respect to the derived fore-
ground and background appearances in b and f which
have more disoccluded pixels than any frame.

The learned appearances and the inferred (cid:176)ow vec-
tors can be used to perform video interpolation.
In
Fig. 2 we present 1 frame interpolation between adja-
cent frames. See the accompanying website for more
interpolation results.

6.2 Modelling mixtures of complex

deformation and appearances in two

layers

Our model can easily be extended to incorporate mul-
tiple layers of moving objects with appearance of each
layer modelled as a mixture model.

In this experiment, we present results for learning a
two layer model where the foreground appearance is
modelled using a Gaussian mixture with 2 classes. We
also allow the latent variables (appearances and prob-
ability masks) to be bigger than the observed image
so as to learn a panoramic background.

We learn the model using 10 RGB frames (138 £ 148 £

3) sampled from a longer video sequence (Fig. 6a).
Each frame consists of one of the two persons (mod-
elled using diﬁerent classes) moving towards the cam-
era in front of a non-stationary background. Notice
that the images include scale changes in appearance
due to zoom, complex motion of hands and legs, wrin-
kles in the clothing, and large shifts in the position.

We used larger appearances and masks (138 £ 178)
than the observed frames. Referring to our model in
ﬂg. 1, we ﬂrst train the model without incorporation of
the deformation to obtain the global position variables
in each layer for each frame. Once the global shifts are
inferred, we ﬂx them to learn the deformation ﬂeld and
the parameters of the model in tandem as outlined in
Sec. 5

In ﬂg. 5, the parameters of the learned model are
shown. Frames corresponding to the ﬂrst appearance
class have pixels belonging to the background that
are always occluded. However, these pixels are visi-
ble in some frames where the other appearance class
is present. By jointly modelling all the frames, we are
able to ﬂll in for almost all the occluded pixels belong-
ing to the background for any given frame. This is
further shown in ﬂg. 5a. If we had chosen to learn two
separate models for the two classes, the background
will not have all its corresponding pixels observed.

For the pixels belonging to the texture less pathway,
the prior probability distribution over the mask is close
to uniform (ﬂg. 5c & e). This suggests that for those
regions that do not have enough textural variations to
group them as belonging to one of the two layers, it is
at best to assign equal probability for either layer to
explain them.

In ﬂg. 6, we present inference results for some repre-
sentative frames, shown in ﬂg. 6a. Fig. 6b is the corre-
sponding inferred deformation ﬂeld shifted according
to inferred global transformation. The (cid:176)ow vectors

171Figure 4: Inferred deformation ﬂeld corresponding to the image sequence shown in Fig. 2(the (cid:176)ow ﬂeld is drawn
with reference to the fourth frame which is not shown here)

a

b

c

d

e

Figure 5: Parameters of two layered two class model learned using 10 frames from a video sequence (representative
frames in ﬂg. 6 a)Learned background is larger than the size of input image b) Appearance of foreground object of
class 1 and c) the corresponding probability distribution of the binary mask (with white referring to probability
of 1 for the pixel belonging to foreground ) d) & e) appearance and probability mask of the second class of
foreground layer.

a

b

c

d

e

f

Figure 6: Illustration of inference for some frames of the sequence explained in sec. 6.2 a) frames from a sequence.
b) Deformation ﬂeld for the background. c) Deformed, globally transformed background. d) Deformation ﬂeld
for the foreground (masked). e) Distribution for the mask after global transformation is applied. f) Mask applied
on the frame in a)

172algorithm. Proceedings of the Royal Statistical Soci-
ety, B-39:1{38.

Frey, B. and Jojic, N. 2004. Advances in algorithms for
inference and learning in complex probability models.
IEEE Transactions on Pattern Analysis and Machine
Intelligence (to appear).

Frey, B. J. and Jojic, N. 1999. Estimating mixture models
of images and inferring spatial transformations using
the em algorithm. In Proceedings of the IEEE Con-
ference on Computer Vision and Pattern Recognition.
IEEE.

Frey, B. J., Jojic, N., and Kannan, A. 2003. Learning ap-
pearance and transparency manifolds of occluded ob-
jects in layers. In Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition.

Jepson, A. and Black, M. J. 1993. Mixture models for op-
tical (cid:176)ow computation.
In Proceedings of the IEEE
Conference on Computer Vision and Pattern Recog-
nition, pages 760{761.

Jojic, N., Frey, B., and Kannan, A. 2003. Epitomic analysis
of appearance and shape. In Proceedings of Interna-
tional Conference in Computer Vision. IEEE.

Jojic, N. and Frey, B. J. 2001. Learning (cid:176)exible sprites in
video layers. In Proceedings of the IEEE Conference
on Computer Vision and Pattern Recognition.

Jojic, N., Simard, P., Frey, B. J., and Heckerman, D. 2001.
Separating appearance from deformation. In Proceed-
ings of the IEEE Conference on Computer Vision and
Pattern Recognition.

Jordan, M. I., Ghahramani, Z., Jaakkola, T., and Saul,
L. 1999. An introduction to variational methods for
graphical models. Machine Learning, 37(2):183{233.

Lucas, B. D. and Kanade, T. 1981. An iterative image
registration technique with an application to stereo
vision. In Proceedings of the 7th International Joint
Conference on Artiﬂcial Intelligence.

Neal, R. M. and Hinton, G. E. 1998. A view of the em algo-
rithm that justiﬂes incremental,sparse, and other vari-
ants. In Jordan, M. I., editor, Learning in Graphical
Models. Kluwer Academic Publishers, Norwell MA.

Weiss, Y. and Adelson, E. 1996. A uniﬂed mixture frame-
work for motion segmentation: Incorporating spatial
coherence and estimating the number of models. In
Proceedings of IEEE Computer Vision and Pattern
Recognition.

Williams, C. W. and Titsias, M. K. 2003. Learning about
multiple objects in images: Factorial learning without
factorial search. In Becker, S., Thrun, S., and Ober-
mayer, K., editors, Advances in Neural Information
Processing Systems 15. MIT Press, Cambridge MA.

are drawn relative to the learned parameters. Each
vector in this ﬂeld represents the most probable (that
vector that has the largest posterior probability) defor-
mation vector for that pixel. The inferred deformation
ﬂeld for the foreground appearance is in ﬂg. 6c. It is
interesting to note that the deformation vectors for
appearance are smoother and more consistent along
the boundaries than on the central regions of the fore-
ground object. As our approach learns a good ap-
pearance model, the boundaries of the objects are well
deﬂned but the motion within the object is not very
coherent due to lack of enough texture variation be-
tween adjacent patches to reliably favor a particular
motion direction. We contrast this with inferred (cid:176)ow
vectors in the previous experiment (ﬂg. 4) where we
had enough textural variation in the central region of
object of interest that we learned a much smoother
(cid:176)ow ﬂeld.

7 Conclusions

We have enriched the (cid:176)exible sprites model with
the deformable motion variables deﬂned on over-
lapping patches. We assume that in each patch
there exist two motion vectors and that some pix-
els are following one and others the other motion.
The selection is deﬂned by a patch of binary vari-
ables. These patches are also overlapping in the
model of the mask, aligned with one of the layers.
We were able to use this model of motion within
the (cid:176)exible sprites model and obtain better appear-
ance, mask and motion estimates. See the web page
http://www.psi.utoronto.ca/»anitha/(cid:176)ex.html for ad-
ditional results and videos.

Acknowledgments

The authors thank P.Anandan for discussion on the im-
portance of combining top-down object appearance models
with low-level visual cues, in particular, motion. We also
thank Allan Jepson for his comments on an earlier version
of the work.

References

Ayer, S. and Sawhney, H. S. 1995. Layered representation
of motion video using robust maximum likelihood es-
timation of mixture models and mdl encoding.
In
Proceedings of the International Conference on Com-
puter Vision, pages 777{784.

Black, M. J. and Fleet, D. J. 2000. Probabilistic detection
and tracking of motion discontinuities. International
Journal on Computer Vision.

Black, M. J. and Jepson, A. 1996. Estimating optical (cid:176)ow
in segmented images using variable-order parametric
models with local deformations. IEEE Transactions
on Pattern Analysis and Machine Intelligence.

Dempster, A. P., Laird, N. M., and Rubin, D. B. 1977.
Maximum likelihood from incomplete data via the EM

173Toward Question-Asking Machines:

The Logic of Questions and the Inquiry Calculus

Kevin H. Knuth∗

Computational Sciences Division

NASA Ames Research Center
Moﬀett Field, CA 94035-1000

Abstract

For over a century, the study of logic has fo-
cused on the algebra of logical statements.
This work, ﬁrst performed by George Boole,
has led to the development of modern com-
puters, and was shown by Richard T. Cox
to be the foundation of Bayesian inference.
Meanwhile the logic of questions has been
much neglected. For our computing machines
to be truly intelligent, they need to be able
to ask relevant questions. In this paper I will
show how the Boolean lattice of logical state-
ments gives rise to the free distributive lat-
tice of questions thus deﬁning their algebra.
Furthermore, there exists a quantity analo-
gous to probability, called relevance, which
quantiﬁes the degree to which one question
answers another. I will show that relevance
is not only a natural generalization of infor-
mation theory, but also forms its foundation.

1 INTRODUCTION

Intelligent machines need to actively acquire informa-
tion, and the act of asking questions is central to
this capability. Question-asking comes in many forms
ranging from the simplest where an instrument con-
tinuously monitors data from a sensor, to the more
complex where a rover must decide which instrument
to deploy or measurement to take, and even the more
human-like where a robot must verbally request infor-
mation from an astronaut during in an in-orbit con-
struction task.
Intelligence is not just about providing the correct so-
lution to a problem. When vital information is lacking,
intelligence is required to formulate relevant questions.
For over 150 years mathematicians have studied the

∗
http://www.huginn.com/knuth/

logic of statements (Boole, 1854); whereas the mathe-
matics of questions has been almost entirely neglected.
In this paper, I will describe my recent work performed
in understanding the algebra of questions, and its as-
sociated calculus, the inquiry calculus.
Much of the material presented in this paper relies on
the mathematics of partially-ordered sets and lattices.
For this reason, I have included a short appendix to
which the reader can refer for some of the mathemati-
cal background. Section §2 brieﬂy discusses questions
and the motivation for this work. Section §3 introduces
the formal deﬁnition of a question. I develop the lattice
of questions and its associated algebra in Section §4.
I extend the question algebra to the inquiry calculus
in Section §5 by introducing a bi-valuation called rele-
vance, which quantiﬁes the degree to which one ques-
tion answers another. In section §6, I show that the
inquiry calculus is not only a natural generalization
of information theory, but also forms its foundation.
Section §7 summarizes the results, discusses how infor-
mation theory has been used for some time to address
question-asking, and describes how this more general
methodology and deeper understanding will facilitate
this process.

2 QUESTIONS

Each and every one of us asks questions, and has
done so since being able to construct simple sentences.
Questions are an essential mechanism by which we ob-
tain information, however as we all know, some ques-
tions are better than others. Questions are not always
verbal requests, but are often asked in the form of
physical manipulations or experiments: ‘What happens
when I let go of my cup of milk?’ or ‘Will my mother
make that face again if I drop it a second time? ’ Ques-
tions may also be more fundamental, such as the sac-
cade you make when you detect motion in your pe-
ripheral visual ﬁeld. Or perhaps the issue is more ef-
fectively resolved by turning your head so as to deploy

174both your visual and auditory sensory modalities. Re-
gardless of their form, “questions are requests for in-
formation” (Caticha, 2004).
Many questions simply cannot be asked: there may
be no one who will know the answer, no immediate
way to ask it, you may not be allowed for a variety
of reasons, or the question may be too expensive with
respect to some cost criteria. In most situations, these
questions cannot now be asked directly: ‘Is there life
in Europa’s ocean? ’, ‘How fast does the SR71 Black-
bird ﬂy?’, ‘How would radiation exposure on a Mars
mission aﬀect an astronaut’s health? ’, or ‘What is the
neutrino ﬂux emitted from Alpha Centauri?’ In these
cases, one must resort to asking other questions that
do not directly request the information sought, yet still
have relevance to the unresolved issue. This sets up the
iterative process of inquiry and inference, which is es-
sential to the process of learning—be it active learning
by a machine, learning performed by a child, or the act
of doing science by the scientiﬁc community.
Choosing relevant questions is a diﬃcult task that re-
quires intelligence. Anyone who has tried to perform a
construction task with the assistance of a small child
will appreciate this fact. Constantly being asked ‘Do
you need a hammer? ’ by even the most enthusiastic
helper can be a great annoyance when you are strug-
gling to drill a hole. This is precisely the situation we
will need to avoid when robots are used to assist us in
diﬃcult and dangerous construction tasks. Relevant
questions asked by an intelligent assistant will be in-
valuable to minimizing risks and maximizing produc-
tivity in human-robot interactions. However, despite
being an important activity on which we intelligent
beings constantly rely, the mathematics of quantifying
the relevance of a question to an outstanding issue has
been surprisingly neglected.

3 DEFINING QUESTIONS

One of the most interesting facts about questions is
that even though we don’t know the answer, the ques-
tion is essentially useless if we have absolutely no idea
of what the answer could be. That is, when questions
are asked intelligently, we already have a notion of the
set of possible answers that the resolution may take.
Richard T. Cox in his last paper captured this idea
when he deﬁned a question as the set of all logical
statements that answer it (Cox, 1979).
The utility of such a deﬁnition becomes apparent when
one considers the set of all possible answers to be a
hypothesis space. The act of answering a question
is equivalent to retrieving information, which will be
used to further reﬁne the probability density func-
tion over the hypothesis space, thereby reducing un-

certainty. This can be formalized to a greater de-
gree, and to our advantage, by realizing that a set
of logical statements can be partially-ordered by the
binary ordering relation ‘implies’. This set of logical
statements along with its binary ordering relation →,
generically written in order-theoretic notation as ≤,
forms a partially-ordered set, which can be shown to
be a Boolean lattice (Birkhoﬀ, 1967; Davey & Priest-
ley, 2002). As a concrete example, consider a human-
robotic cooperative construction task involving a robot
named Bender and a human named Fry.1 Bender has
become aware that Fry will be in need of a tool, but
must decide which tool Fry will prefer:

d = ‘Fry needs a drill!’
w = ‘Fry needs a wrench!’
h = ‘Fry needs a hammer!’

These three atomic statements comprise the three mu-
tually exclusive possibilities in Bender’s hypothesis
space. The Boolean lattice A (Figure 1), which I will
interchangeably call the statement lattice or the asser-
tion lattice, is the powerset of these three statements,
formed by considering all possible logical disjunctions,
ordered by the binary ordering relation ‘implies’, →.
In an ideal situation, Bender’s situational awareness
would provide suﬃcient information to allow him to
infer the tool Fry most probably needs. However, in re-
ality, this will not always be the case, and Bender may
need more information to adequately resolve the infer-
ence. The human way to accomplish this is to simply
ask Fry for more information. Clearly, the most rele-
vant question Bender can ask will depend both on the
probabilities of the various hypotheses in this space,
and on the speciﬁc issue Bender desires to resolve.
I now introduce a more formal deﬁnition of a question,
which will allow us to generate a lattice of questions
from a lattice of logical statements representing the
hypothesis space. I ﬁrst deﬁne a down-set (Davey &
Priestley, 2002).

Deﬁnition 1 (Down-set) A down-set is a subset J
of an ordered set L where if a ∈ J, x ∈ L, x ≤ a then
x ∈ J. Given an arbitrary subset K of L, we write the
down-set formed from K as J = ↓K = {y ∈ L|∃x ∈
K where y ≤ x}.
Keep in mind that ≤ represents the ordering relation
for the ordered set—in this case ≤ is equivalent to
→ for the lattice A. A formalized version of Cox’s
deﬁnition of a question follows (Knuth, 2003a, 2004b,
2005).

1Bender and Fry are characters on the animated televi-

sion series Futurama created by Matt Groening.

175Figure 1: A3 is the Boolean lattice formed from three
mutually exclusive assertions ordered by the relation
‘implies’. The bottom element ⊥ is the absurdity,
which is always false, and the top element (cid:7) is the
truism, which is always true.

Deﬁnition 2 (Question) A question Q is deﬁned as
a down-set of logical statements Q = ↓{a1, a2, . . . , an}.
The question lattice Q is the set of down-sets of the
assertion lattice A ordered by the usual set-inclusion
⊆, so that Q = O(A).

This deﬁnes a question in terms of the set of statements
that answer it, which includes all the statements that
imply those statements. Note that I am using lower-
case letters for assertions (logical statements), upper-
case letters for questions (or sets), and script letters
for ordered sets (lattices). The question lattice Q gen-
erated from the Bender’s Boolean assertion lattice A
is shown in Figure 2 with the following notation:

H = ↓h = {h,⊥}

W H = ↓w ∨ h = {w ∨ h, w, h,⊥}
DW H = ↓d ∨ w ∨ h = {d ∨ w ∨ h, . . .}

This lattice shows all the possible questions that one
can ask concerning the hypothesis space A. For ex-
ample, the question H ∪ DW is the set union of the
questions H and DW . H∪DW represents the question
‘Do or do you not need a hammer? ’, since this question
can be answered by the statements {d ∨ w, d, w, h,⊥},
where d∨ w is equivalent to ‘Fry does not need a ham-
mer! ’, since ∼ h = d ∨ w. 2 Note that not all of the
questions in Q have English language equivalents.

4 THE QUESTION ALGEBRA

The ordered set Q is comprised of sets ordered by the
usual set inclusion ⊆. This ordering relation naturally
implements the notion of answering. If a question A
2Note also that ⊥ is the absurd answer, which answers

all questions since it implies everything (see Figure 1).

Figure 2: Q3 is the free distributive lattice formed from
the assertion lattice A3. Questions are ordered by set-
inclusion which implements the relation ‘answers’.

is deﬁned by a set that is a subset of the answers to
a second question B, so that A ⊆ B, then answering
the question A will also answer the question B. Thus
question A answers question B if and only if A ⊆ B.
This allows us to read A ⊆ B as ‘A answers B’, and
recognize that questions lower in the lattice (Figure 2)
answer questions higher in the lattice.
The fact that the ordered set Q is comprised of sets
ordered by ⊆ and closed under set union ∪ and set
intersection ∩ implies that it is a distributive lattice
(Knuth, 2003a,b, 2004a,b, 2005). This means that Q
possesses two binary algebraic operations, the join ∨
and meet ∧, which are identiﬁed with ∪ and ∩, respec-
tively (Knuth, 2003a). Just as the join and meet on
the assertion lattice A can be identiﬁed with the logi-
cal disjunction ∨ (OR) and the logical conjunction ∧
(AND), the join and meet on the question lattice can
also be viewed as a disjunction and a conjunction of
questions, respectively. The question formed from the
meet of two questions asks what the two questions ask
jointly and is called the joint question; whereas the
question formed from the join of two questions asks
what the two questions ask in common and is called
the common question (Cox, 1979). These operations

176Table 1: The Question Algebra

Answers
Reﬂexivity
Antisymmetry
Transitivity

ORDERING
≤ ≡ ⊆
For all A, A ≤ A
If A ≤ B and B ≤ A then A = B
If A ≤ B and B ≤ C then A ≤ C

OPERATIONS
∨ ≡ ∪
Disjunction
∧ ≡ ∩
Conjunction
A ∨ A = A
Idempotency
A ∧ A = A
Commutativity A ∨ B = B ∨ A
A ∧ B = B ∧ A
A ∨ (B ∨ C) = (A ∨ B) ∨ C
A ∧ (B ∧ C) = (A ∧ B) ∧ C
A ∨ (A ∧ B) = A ∧ (A ∨ B) = A
A ∧ (B ∨ C) = (A ∧ B) ∨ (A ∧ C)
A ∨ (B ∧ C) = (A ∨ B) ∧ (A ∨ C)

Absorption
Distributivity

Associativity

A ≤ B ⇔ A ∧ B = A ⇔ A ∨ B = B

CONSISTENCY

allow us to algebraically manipulate questions as easily
as we currently manipulate logical statements.
However, the similarities to the more speciﬁc Boolean
algebra end there. Distributive algebras, in general, do
not possess the Boolean operation of negation. Thus,
in general, questions do not possess complements.
The join-irreducible elements of the question lattice
J(Q) are the questions that cannot be written as
the join (set union) of two other questions.
I call
these questions ideal questions (Knuth 2003a), de-
noted I = J(Q), reﬂecting the fact that they are the
ideals (Birkhoﬀ, 1967; Davey & Priestley, 2002) of the
lattice Q. While ideal questions neither have a ver-
bal analogue nor are interesting to ask, they are use-
ful mathematical constructs.
Ideal questions form a
lattice isomorphic to the original assertion lattice A.
Thus we have the correspondence where Q = O(A)
and A ∼ J(Q). The lattices A and Q are said to be
dual in the sense of Birkhoﬀ’s Representation Theo-
rem (Knuth 2005). Furthermore, O takes lattice sums
to lattice products; whereas J takes lattice products
to lattice sums. These maps are the order-theoretic
analogues of the exponential and the logarithm. This
will have important consequences when we generalize
the question algebra to the inquiry calculus.
There are other important types of questions. The
ﬁrst deﬁnition originated with Cox (1979).

Deﬁnition 3 (Real Question) A real question is a
question Q ∈ Q, which can always be answered by a
true statement. The real sublattice is denoted by R.

It is straightforward to show that a real question enter-
tains each of the mutually exclusive atomic statements
of A as acceptable answers (Knuth 2003a). This leads
to the following proposition, which I will leave for the
reader to prove.

Proposition 1 (The Least Real Question) For

all Q ∈ Q, Q ∈ R iﬀ Q ≥ (cid:1) ↓ J(A). The question

(cid:1) ↓J(A) = min R is the least real question.

C =

Thus the least element in the real sublattice R is the
question formed from the join of the downsets of the
mutually exclusive atomic statements of A.
In our
example, this is D ∪ W ∪ H. This question is unique
in that it answers all real questions in Q.

Deﬁnition 4 (Central Issue) The central issue is
the least element in the real sublattice R of the ques-
tion lattice Q, denoted min R. Answering the central
issue resolves all the real questions in the lattice.

Last, a partition question is a real question that neatly
partitions its set of answers. Speciﬁcally,

Deﬁnition 5 (Partition Question) A
partition
question is a real question P ∈ R formed from the
(cid:1)n
Xi where
join of a set of ideal questions P =
∀ Xj, Xk ∈ J(Q), Xj ∧ Xk = ⊥ when j (cid:18)= k.

i=1

There are ﬁve partition questions in our example:
DW H, H ∪ DW , W ∪ DH, D∪ W H, and D∪ W ∪ H.
Together these questions form a lattice P isomorphic
to the partition lattice Π3. Note that the central issue
is the partition question with the maximal number of
partitions. For this reason, it is the least ambiguous
question.
The question lattice Q generated from the Boolean lat-
tice A is known as the free distributive lattice (Knuth,
2003a). As such, it is isomorphic to the lattice of sim-
plicial complexes in geometry (Klain & Rota, 1997), as
well as the lattice of hypergraphs (Knuth, 2005). Thus

Figure 3: The hypergraph associated with the question
H ∪ DW = ‘Do you or do you not need a hammer?’

177hypergraphs are a convenient graphical means of dia-
gramming questions. Figure 3 shows the hypergraph
associated with the partition question H ∪ DW = ‘Do
you or do you not need a hammer?’ Such hypergraphs
may play a more signiﬁcant role when inquiry is united
with inference in the form of Bayes Nets.

and its multi-question generalization
d(X1 ∨ X2 ∨ ··· ∨ Xn|Q) =
(cid:5)

(cid:5)

d(Xi|Q) −

d(Xi ∧ Xj|Q)+

i

(cid:5)

i<j

d(Xi ∧ Xj ∧ Xk|Q) − ··· ,

(2)

5 THE INQUIRY CALCULUS

i<j<k

With the question algebra well-deﬁned, I now extend
the ordering relation to a quantity that describes the
degree to which one question answers another. This
is done by deﬁning a bi-valuation on the lattice that
takes two questions and returns a real number d ∈
I call this
[0, c], where c is the maximal relevance.3
bi-valuation the relevance (Knuth, 2005)

Deﬁnition 6 (Relevance) The degree to which a
question Q resolves an outstanding issue I, for all
Q, I ∈ Q, is called the relevance, and is written d(I|Q)
where
d(I|Q) =

if Q ≤ I
if Q ∧ I = ⊥ (Q and I are exclusive)

c
0
d otherwise, where 0 < d < c.

(Q answers I)




with c being the maximal relevance.

This bi-valuation is deﬁned so as to extend the dual
of the zeta function for the lattice, which acts to
quantify order-theoretic inclusion, which in this case,
indicates whether the question Q answers the ques-
tion I (Knuth, 2004a,b, 2005). The utility of this
bi-valuation becomes apparent when one considers
I = min R to be the central issue, and Q ∈ R to be an
arbitrary real question. The bi-valuation d(I|Q) quan-
tiﬁes the degree to which Q resolves the central issue I
by taking a value d where 0 < d < c. This is analogous
to the notation in probability theory where p(x|y) de-
scribes the degree to which the statement y implies the
statement x (Cox, 1946, 1961; Jaynes, 2003).
Since the arguments of the relevance function can be
expressed as algebraic combinations of questions, we
must require that the values returned by the func-
tion are consistent with the algebraic properties of the
lattice. This consistency requirement results in three
rules, which describe how relevances relate to one an-
other (Knuth 2004a, 2005). Consistency with asso-
ciativity gives rise to the Sum Rule (Caticha, 1998;
Knuth 2004a, 2005):
d(X ∨ Y |Q) = d(X|Q) + d(Y |Q) − d(X ∧ Y |Q), (1)

3Real numbers preserve transitivity, which is a useful
property in this context. Are real numbers always ap-
propriate in such generalizations? The answer is ‘no’ and
quantum mechanics is an excellent example (Caticha, 1998;
Knuth, 2004a).

which, due to the M¨obius function of the distributive
lattice, displays the familiar sum and diﬀerence pat-
tern known as the inclusion-exclusion principle (Klain
& Rota, 1997; Knuth 2004a, 2005).
Consistency with distributivity of ∧ over ∨ results
in the Product Rule (Caticha, 1998; Knuth 2004a,
2005):

d(X ∧ Y |Q) = c d(X|Q)d(Y |X ∧ Q),

(3)

where the real number c is again the maximal rele-
vance. Note that the calculus cannot simultaneously
support distributivity of ∧ over ∨ and distributivity
of ∨ over ∧, which are both allowed in a distributive
lattice (Knuth 2004a, 2005). It may surprise some to
learn that is also the case in probability theory.
Last, consistency with commutativity of ∧ results in a
Bayes’ Theorem Analogue (Knuth 2004a, 2005):

d(Y |X ∧ Q) =

d(Y |Q)d(X|Y ∧ Q)

d(X|Q)

.

(4)

The fact that these three rules are shared between the
inquiry calculus and probability theory is a result of
the fact that both the assertion lattice A and the ques-
tion lattice Q are distributive lattices, with a Boolean
lattice being a special case of a distributive lattice.
Since the assertion lattice A and the question lattice Q
are dual to one another in the sense of Birkhoﬀ’s Rep-
resentation Theorem, it is not unreasonable to expect
that the values of the relevances of questions must be
consistent with the probabilities of their possible an-
swers. Given an ideal question X = ↓x we require

d(X|(cid:7)) = H(p(x|(cid:7))),

(5)
where d(X|(cid:7)) is the degree to which the question that
asks everything (cid:7) answers X, p(x|(cid:7)) is the degree to
which the truism (the top element of A) implies the
statement x, and H is a function to be determined.
The result, which I discuss in detail elsewhere (Knuth,
2005), is based on four constraints imposed by the lat-
tice structure additivity, subadditivity, symmetry, and
expansibility. Additivity and subadditivity are a re-
sult of the sum rule for questions (2). The constraint
of symmetry reﬂects the commutativity of the join;
whereas the constraint of expansibility reﬂects the fact

178that adding a statement that is known to be false to
the underlying assertion lattice A does not aﬀect the
results. An important result from Janos Acz´el and col-
leagues (Acz´el, Forte & Ng, 1974) enables one to show
that given these properties, there is a unique form of
the relevance d(P|(cid:7)) in terms of probabilities.
Theorem 1 (Relevance) If and only if d(P|(cid:7)) sat-
isﬁes additivity, subadditivity, symmetry and expansi-
bility, then there exist a ≥ 0 and b ≥ 0 such that
d(P|(cid:7)) = a Hm(p1, p2,··· , pn)+

b oHm(p1, p2,··· , pn),

(6)
where pi ≡ p(xi|(cid:7)), the Shannon entropy (Shannon &
Weaver, 1949) is deﬁned as

Hm(p1, p2,··· , pn) = − n(cid:5)

i=1

pi log2

pi,

(7)

and the Hartley entropy (Hartley, 1928) is deﬁned as

oHm(p1, p2,··· , pn) = log2

N(P ),

(8)

where N(P ) is the number of non-zero arguments pi.

This result is important since it rules out the use of
other entropies for the purpose of inference and in-
quiry. Any other entropy function will lead to an in-
consistency between the bi-valuations deﬁned on the
assertion lattice A and the bi-valuations deﬁned on the
question lattice Q.

6 A NATURAL GENERALIZATION

OF INFORMATION THEORY

I will now show that these results not only lead natu-
rally to information theory, but signiﬁcantly generalize
its scope including several generalizations already pro-
posed in the literature. For simplicity, I will assign the
arbitrary constants so that a = 1 and b = 0, and limit
ourselves to the Shannon entropy. The main result
of the previous section is that the degree to which the
top question (cid:7) answers any partition question P ∈ P is
quantiﬁed by the entropy of its answers. Thus proba-
bility quantiﬁes what we know, whereas entropy quan-
tiﬁes what we do not know.
However, more basic quantities also appear, and take
on new fundamental importance. Since partition ques-
tions are joins of ideal questions, it is straightforward
to show, using the sum rule, that the degree to which
(cid:7) answers an ideal question Xi ∈ I is given by the
probability-weighted surprise

d(Xi|(cid:7)) = −pi log2

pi.

(9)

If we look at our earlier example, we can compute the
degree to which (cid:7) answers the question DW ∨ W H.
This is easily done using the sum rule, which gives

d(DW ∨ W H|(cid:7)) = d(DW|(cid:7)) + d(W H|(cid:7))

− d(DW ∧ W H|(cid:7)).

(10)

Clearly this quantity is related to the mutual informa-
tion between DW and W H, which when written in
standard notation would look like

I(DW ; W H) =

H(DW ) + H(W H) − H(DW, W H),

(11)
where d(DW ∧ W H|(cid:7)) is related to the joint entropy.
Thus mutual information is related to the disjunction
of two issues, whereas the joint entropy is related to the
conjunction of two issues. However, in this illustration
is important to note that (10) is not exactly a mutual
information since neither DW nor W H are partition
questions, however with a larger hypothesis space it is
trivial to construct the mutual information this way.
By considering the disjunction and conjunction of
multiple issues, one can construct relevances that
are higher-order mutual informations and higher-order
joint entropies that exhibit the sum and diﬀerence pat-
terns in the multi-question generalization of the sum
rule. Higher-order generalizations such as these were
independently suggested by several authors (McGill,
1955; Cox, 1961, 1979; Bell, 2003), however here one
can see that they occur naturally as a result of the
inquiry calculus.
To consider the conjunction and disjunction of ques-
tions to the right of the solidus, one must use the
sum and product rules in conjunction with the Bayes’
theorem analogue to move questions from one side
of the solidus to the other. The following exam-
ple demonstrates a typical calculation, which also in-
cludes some algebraic manipulation. Consider again
Bender’s central issue T = ‘Which tool do you need? ’.
However, Bender has asked this question 10 times
in the last hour, and Fry is getting quite irri-
tated and will
lose his temper if he hears that
question again. To ﬁnd another question, Bender
computes the relevance that the question QH =
‘Do you or do you not need a hammer?’ has on the is-
sue. This calculation results in

(12)

d(QH|(cid:7))
d(T|(cid:7))

d(T|QH) = d(T|QH ∧ (cid:7))
= d(QH|T ∧ (cid:7))
= d(QH|T )
d(QH|(cid:7))
d(T|(cid:7))

= c

d(QH|(cid:7))
d(T|(cid:7))
,

179where the result is simply a ratio of two entropies.
Note that this formalism relies on relevances that are
conditional—like probabilities. This notion is absent
in traditional information theory, and is another way in
which the inquiry calculus is a natural generalization.

7 DISCUSSION

I have demonstrated that the question algebra and
the inquiry calculus follow naturally from a straight-
forward deﬁnition of a question as the set of state-
ments that answer it. The question algebra enables
one to manipulate questions algebraically as easily as
we currently manipulate logical statements, whereas
the inquiry calculus allows us to quantify the degree
to which one question answers another. This method-
ology promises to enable us to design machines that
can identify maximally relevant questions in order to
actively obtain information. This work has clear im-
plications for areas of research that rely on question-
asking, such as experimental design (Lindley, 1956;
Loredo, 2004), search theory (Pierce, 1979), and ac-
tive learning (MacKay, 1992), each of which has taken
advantage of information theory during their histories.
In addition, this approach has already shown promise
in several applications by Robert Fry (1995, 2002).
However, the inquiry calculus is more fundamental
than information theory in the sense that it derives
directly from the question algebra. The sole postulate
is that the bi-valuations on the dual lattices are de-
ﬁned consistently. The result is that the Shannon and
Hartley entropies are the only entropies that can be
used for the purposes of inquiry—all other entropies
will lead to inconsistencies. Entropy is related to the
relevances involving the partition questions, mutual in-
formation is related to disjunctions of questions, and
joint entropy is related to conjunctions of questions.
Higher-order informations occur naturally when multi-
ple disjunctions and conjunctions are considered. Last,
the calculus allows for, and relies on, conditional quan-
tities not considered in traditional information theory.
The result is an algebra and a calculus that takes the
guesswork out of deﬁning information-theoretic cost
functions in applications involving question-asking.
Our explorations into the realm of questions are only
beginning, and it would be na¨ıve to think that the
work presented here is the entire story. Recently, Ariel
Caticha presented an alternative approach to viewing
a question as a probability distribution, which is in
some ways simultaneously more general yet more re-
strictive than the approach presented here (Caticha,
2004). The result is a measure of relevance described
by relative entropy. It will be interesting to see where
these new investigations lead.

APPENDIX: POSETS AND
LATTICES

In this section I introduce some basic concepts of order
theory that are necessary to understand the spaces of
logical statements and questions. Order theory cap-
tures the notion of ordering elements of a set. For a
given set, one associates a binary ordering relation to
form what is called a partially-ordered set, or a poset
for short. This ordering relation, generically written
≤, satisﬁes reﬂexivity, antisymmetry, and transitivity.
The ordering a ≤ b is generally read ‘b includes a’.
When a ≤ b and a (cid:18)= b, we write a < b. Furthermore,
if a < b, but there does not exist an element x in the
set such that a < x < b, then we write a ≺ b, read ‘b
covers a’, indicating that b is a direct successor to a in
the hierarchy induced by the ordering relation. This
concept of covering can be used to construct diagrams
of a poset. If an element b includes an element a then
it is drawn higher in the diagram. If b covers a then
they are connected by a line.
A poset P possesses a greatest element if there exists
an element (cid:7) ∈ P , called the top, where x ≤ (cid:7) for all
x ∈ P . Dually, a poset may possess a least element
⊥ ∈ P , called the bottom. The elements that cover the
bottom are called atoms.
Given two elements x and y, their upper bound is de-
ﬁned as the set of all z ∈ P such that x ≤ z and y ≤ z.
If a unique least upper bound exists, it is called the
join, written x ∨ y. Dually, we can deﬁne the lower
bound and the greatest lower bound, which if it exists,
is called the meet, x∧y. Graphically the join of two ele-
ments can be found by following the lines upward until
they ﬁrst converge on a single element. The meet can
be found dually. Elements that cannot be expressed
as a join of two elements belong to a special set of
elements called join-irreducible elements.
The dual of a poset P , written P ∂ can be formed by re-
versing the ordering relation, which can be visualized
by ﬂipping the poset diagram upside-down. This ac-
tion exchanges joins and meets and is the reason that
their relations come in pairs (see Table 1).
A lattice L is a poset where the join and meet exist for
every pair of elements. We can view the lattice from
a structural viewpoint as a set of objects arranged by
an ordering relation ≤. However, we can also view the
lattice from an operational viewpoint as an algebra
on the space of elements with the operations ∨ and ∧
along with any other relations induced by the ordering
relation. The join and meet obey idempotency, com-
mutativity, associativity, and the absorption property.

180Acknowledgements

This work was supported by the NASA IDU/IS/CICT
Program and the NASA Aerospace Technology Enter-
prise. I am deeply indebted to Ariel Caticha, Bob Fry,
Janos Acz´el and Kevin Wheeler for insightful and in-
spiring discussions, and the anonymous reviewers for
their detailed and helpful comments.

References

(1967).

Lattice Theory, Provi-

Acz´el J., Forte B. & Ng C.T. (1974). Why the Shannon
and Hartley entropies are ‘natural’. Adv. Appl. Prob.,
Vol. 6, pp. 131–146.
Bell A.J. (2003). The co-information lattice. Proceed-
ings of the Fifth International Workshop on Indepen-
dent Component Analysis and Blind Signal Separation:
ICA 2003 (eds. S. Amari, A. Cichocki, S. Makino and
N. Murata).
Birkhoﬀ G.D.
dence:American Mathematical Society.
Boole G. (1854). An Investigation of the Laws of
Thought. London:Macmillan.
Caticha A. (1998). Consistency, amplitudes and prob-
abilities in quantum theory. Phys. Rev. A, Vol. 57,
pp. 1572–1582.
Caticha A. (2004). Questions, relevance and rela-
tive entropy. In press: Bayesian Inference and Max-
imum Entropy Methods in Science and Engineering,
Garching, Germany, August 2004 (eds. R. Fischer, R.
Preuss, U. Von Toussaint, V. Dose). AIP Conf. Proc.,
Melville NY:AIP.
Cox R.T. (1946). Probability, frequency, and reason-
able expectation. Am. J. Physics, Vol. 14, pp. 1–13.
Cox R.T. (1961). The algebra of probable inference.
Baltimore:Johns Hopkins Press.
In The
Cox R.T. (1979). Of inference and inquiry.
Maximum Entropy Formalism (eds. R. D. Levine &
M. Tribus). Cambridge:MIT Press, pp. 119–167.
Introduction
Davey B.A. & Priestley H.A. (2002).
to Lattices and Order. Cambridge:Cambridge Univ.
Press.
Fry R.L. (1995). Observer-participant models of neu-
ral processing. IEEE Trans. Neural Networks, Vol. 6,
pp. 918–928.
Fry R.L. (2002). The engineering of cybernetic sys-
In Bayesian Inference and Maximum Entropy
tems.
Methods in Science and Engineering, Baltimore MD,
USA, August 2001 (ed. R. L. Fry). New York:AIP,
pp. 497–528.

the logic of

Hartley R.V. (1928). Transmission of information.
Bell System Tech. J., Vol. 7, pp. 535–563.
Jaynes E.T. (2003). Probability theory:
science. Cambridge:Cambridge Univ. Press.
Introduction to
Klain D.A. & Rota G.-C. (1997).
geometric probability. Cambridge:Cambridge Univ.
Press.
Knuth K.H. (2003a). What is a question? In Bayesian
Inference and Maximum Entropy Methods in Science
and Engineering, Moscow ID, USA, August 2002 (ed.
C. Williams). AIP Conf. Proc. Vol. 659, Melville
NY:AIP, pp. 227–242.
Knuth K.H. (2003b). Intelligent machines in the 21st
foundations of inference and inquiry, Phil.
century:
Trans. Roy. Soc. Lond. A, Vol. 361, No. 1813, pp.
2859–2873.
Knuth K.H. (2004a). Deriving laws from ordering re-
lations. In Bayesian Inference and Maximum Entropy
Methods in Science and Engineering, Jackson Hole
WY, USA, August 2003 (ed. G. J. Erickson). AIP
Conf. Proc. Vol. 707, Melville NY:AIP, pp. 204–235.
Knuth K.H. (2004b). Measuring questions: Relevance
and its relation to entropy. In press: Bayesian Infer-
ence and Maximum Entropy Methods in Science and
Engineering, Garching, Germany, August 2004 (eds.
R. Fischer, R. Preuss, U. Von Toussaint, V. Dose).
AIP Conf. Proc., Melville NY:AIP.
Knuth K.H. (2005). Lattice duality: The origin of
probability and entropy. In press: Neurocomputing.
Lindley D.V. (1956). On the measure of information
provided by an experiment. Ann. Math. Statist. Vol.
27, pp. 986–1005.
Loredo T.J. (2004). Bayesian adaptive exploration.
In: Bayesian Inference and Maximum Entropy Meth-
ods in Science and Engineering, Jackson Hole WY,
USA, August 2003 (ed. G. J. Erickson). AIP Conf.
Proc. Vol. 707, Melville NY:AIP, pp. 330–346.
MacKay D.J.C. (1992).
Information-based objective
functions for active data selection. Neural Computa-
tion Vol. 4 No. 4, pp. 589–603.
McGill W.J. (1955). Multivariate information trans-
mission. IEEE Trans Info Theory, Vol. 4, pp. 93–111.
Pierce J.G. (1979). A new look at the relation be-
tween information theory and search theory. In The
Maximum Entropy Formalism (eds. R. D. Levine &
M. Tribus), Cambridge:MIT Press, pp. 339–402.
Shannon C.E. & Weaver W. (1949). A mathematical
theory of communication. Chicago:Univ. of Ill. Press.

181(cid:0)(cid:3)(cid:4)(cid:6)(cid:4) (cid:4)(cid:4)	(cid:4)(cid:9)(cid:4)(cid:10)(cid:6)(cid:11)(cid:4)(cid:12) (cid:4)(cid:15)(cid:6)(cid:4) (cid:15)(cid:10)(cid:6) (cid:17) (cid:4)(cid:4)(cid:6)(cid:18) (cid:10)(cid:10)(cid:10)(cid:19)(cid:15)(cid:10)

(cid:0) (cid:2)(cid:3)(cid:4)(cid:4)  (cid:9)(cid:10)

(cid:1)(cid:2)(cid:6) (cid:8)(cid:9)(cid:9)(cid:10)(cid:2)(cid:11)

(cid:12)(cid:10)(cid:14)(cid:1)(cid:15)(cid:16)(cid:9) (cid:18)

(cid:20)(cid:22)(cid:23)(cid:1)(cid:2)(cid:6)(cid:24)(cid:2)

(cid:0)(cid:1)(cid:5)(cid:6)

(cid:25)(cid:9)(cid:9)	(cid:9)(cid:27)(cid:9)(cid:1)(cid:16)(cid:11)(cid:9)(cid:15) (cid:10)(cid:28)	(cid:15)	(cid:2) (cid:9)(cid:10)(cid:16)(cid:9) (cid:10)	
(cid:1)(cid:16) (cid:25)(cid:8)  (cid:1) (cid:10) (cid:10) (cid:16)(cid:1)(cid:11) (cid:6) (cid:9)(cid:9)(cid:16)# (cid:1)(cid:1)	
(cid:1)$(cid:10)(cid:1) (cid:1)(cid:15)	(cid:2)(cid:9)(cid:15) (cid:9)(cid:2)(cid:9) # (cid:14)#  (cid:10)(cid:1)(cid:27)(cid:1)(cid:16)(cid:11)
(cid:9) (cid:10) (cid:24) %&’(cid:24)
 (cid:11)(cid:10)(cid:9) (cid:9) (cid:1)(cid:1) (cid:10)(cid:1)(cid:1)(cid:9) (cid:27)(cid:1)(cid:11)
(cid:9)(cid:10)   # (cid:14)(cid:9) (cid:1)(cid:9)(cid:6) (cid:10)(cid:16)(cid:10)(cid:1)(cid:24) (cid:25)(cid:8)  (cid:27)(cid:10)
(cid:1)(cid:1)(cid:9)(cid:15) (cid:14)# (cid:10) (cid:14) (cid:9) (cid:6) (cid:10)(cid:28)(cid:1)(cid:1)$(cid:1)(cid:16) (cid:10)  (cid:27)(cid:9)
(cid:14)	(cid:15)  (cid:11)(cid:9) (cid:9)(cid:9)(cid:16)#(cid:24)  (cid:27)(cid:9)(cid:20)(cid:9) (cid:11)(cid:9) (cid:10) (cid:16)(cid:1)(cid:11)
(cid:1)  (cid:16)	(cid:10)(cid:10)(cid:9)(cid:9)(cid:15)  (cid:1)(cid:2)(cid:9)(cid:10)(cid:9) (cid:11)(cid:1) (cid:14)	(cid:15) 	 (cid:1)
(cid:10)# (cid:10)(cid:2)	(cid:10)  # (cid:16) (cid:15)(cid:27)(cid:24)
 (cid:10)(cid:15)(cid:15)(cid:1)(cid:1) (cid:25)(cid:8) 
(cid:15)(cid:9)  (cid:10) (cid:27)(cid:10)# (cid:2)(cid:20)(cid:9)(cid:16)(cid:9)(cid:24)  (cid:9) (cid:15)(cid:9)(cid:20)(cid:9)  (cid:10) (cid:15)	
(cid:1),(cid:2)(cid:10)(cid:1) (cid:6) (cid:11)(cid:1) (cid:10) (cid:16)(cid:1)(cid:11) (cid:27)(cid:11)(cid:1)(cid:2)(cid:11) (cid:27)(cid:9) (cid:2)(cid:10)   (cid:1)	
	(cid:1)(cid:7)(cid:8)  (cid:1)(cid:1)	(cid:1)(cid:11)(cid:1)(cid:7)(cid:12)(cid:13)(cid:1)(cid:14) (cid:1)(cid:8)(cid:12)(cid:1) (cid:8)(cid:7)(cid:12)(cid:24) 
(cid:10)(cid:1) (cid:9)# (cid:1) (cid:11)(cid:10) (cid:11)(cid:9) (cid:14)	(cid:15) (cid:1) (cid:16)	(cid:10)(cid:10)	
(cid:9)(cid:9)(cid:15)   (cid:15)(cid:9)(cid:2)(cid:9)(cid:10)(cid:9)(cid:24)  (cid:9) (cid:10)  (cid:16)(cid:1)(cid:20)(cid:9) (cid:10) (cid:11)(cid:1)(cid:8)(cid:17) (cid:1)(cid:1)
(cid:8)(cid:12)(cid:1)(cid:1)(cid:1) (cid:2)(cid:15)(cid:1)(cid:1) (cid:27)(cid:11)(cid:1)(cid:2)(cid:11) (cid:2)(cid:11)(cid:10)(cid:10)(cid:2)(cid:9)(cid:1)$(cid:9)  (cid:2)(cid:10) 
(cid:10)(cid:28)(cid:1)(cid:10) (cid:6) (cid:11)(cid:9) (cid:14)	(cid:15) (cid:27)(cid:1)(cid:11) (cid:9)(cid:9)(cid:2)  (cid:25)(cid:8) 
(cid:10) (cid:16)(cid:1)(cid:11)(cid:24)  (cid:9) (cid:20)(cid:9) (cid:11)(cid:10) 	 (cid:10) (cid:16)(cid:1)(cid:11) (cid:11)(cid:10)
(cid:10)  (cid:1)(cid:1) (cid:1) (cid:11)(cid:10) (cid:10)(cid:2)(cid:11)(cid:1)(cid:9)(cid:20)(cid:9) (cid:27)(cid:9)(cid:10)(cid:22) (cid:9)(cid:9) (cid:10)(cid:16)(cid:9)(cid:9)	
(cid:9)(cid:24)
-(cid:28)(cid:9)(cid:1)(cid:9)(cid:10)  (cid:9)	  (cid:15)(cid:9)(cid:10)(cid:9)
(cid:11)(cid:10)  (cid:2)(cid:9)(cid:10)(cid:1) #(cid:11)(cid:9)(cid:1)(cid:2) (cid:10)(cid:15) (cid:9)(cid:10)  (cid:14) (cid:9)
	 (cid:10) (cid:16)(cid:1)(cid:11) 	(cid:9)(cid:6) (cid:14)(cid:11) (cid:11)(cid:9) (cid:15)(cid:1)(cid:10)#
(cid:14)(cid:9) (cid:1)(cid:9)(cid:6) (cid:10)(cid:16)(cid:10)(cid:1) (cid:10)(cid:15) (cid:9)(cid:9)	(cid:9)(cid:27)(cid:9)(cid:1)(cid:16)(cid:11)(cid:9)(cid:15) (cid:10) (cid:16)	
(cid:1)(cid:11) %&’(cid:24)

(cid:7)

(cid:11)	(cid:6)(cid:13)

(cid:11)		(cid:3)	(cid:15) (cid:2) (cid:9)(cid:4)(cid:17) (cid:9)(cid:10) 
 # (cid:14)(cid:9) (cid:1)(cid:9)(cid:6)
(cid:10)(cid:16)(cid:10)(cid:1) .		(cid:15)	(cid:2) /0 (cid:1) (cid:10) 	 (cid:10) (cid:10) (cid:16)	
(cid:1)(cid:11) (cid:6) (cid:1)(cid:6)(cid:9)(cid:9)(cid:2)(cid:9) (cid:1) /(cid:10)#(cid:9)(cid:1)(cid:10) (cid:9)(cid:27)(cid:22)(cid:24) (cid:6) (cid:11)(cid:9) (cid:9)	
(cid:27)(cid:22) (cid:1) (cid:10) (cid:9)(cid:9) (cid:11)(cid:9) (cid:1) (cid:2)(cid:20)(cid:9)(cid:16)(cid:9) (cid:1) (cid:10) ,(cid:1)(cid:9) 	(cid:14)(cid:9)
(cid:6) (cid:1)(cid:9)(cid:10)(cid:1) (cid:10)(cid:15) (cid:11)(cid:9)  	(cid:1) (cid:16)(cid:1)(cid:20)(cid:9) (cid:9)(cid:28)(cid:10)(cid:2) (cid:10)(cid:16)(cid:1)(cid:10) (cid:24)
 (cid:27)(cid:9)(cid:20)(cid:9) (cid:1)(cid:6) (cid:11)(cid:9) (cid:9)(cid:27)(cid:22) (cid:2)(cid:10)(cid:1)   (cid:11)(cid:9) (cid:2)(cid:20)(cid:9)	
(cid:16)(cid:9)(cid:2)(cid:9) (cid:1)  (cid:16)	(cid:10)(cid:10)(cid:9)(cid:9)(cid:15)(cid:24)

1(cid:1)(cid:28)(cid:9)(cid:15) (cid:1) (cid:6) / (cid:11)(cid:10)(cid:20)(cid:9) (cid:14)(cid:9)(cid:9) (cid:11)(cid:27)  (cid:2)(cid:9)(cid:15) 
(cid:9)(cid:28)(cid:9)(cid:10) (cid:6) (cid:11)(cid:9) 	(cid:2)(cid:10)  (cid:9)(cid:15) /(cid:9)(cid:11)(cid:9) (cid:6)(cid:9)(cid:9) (cid:9)(cid:9)(cid:16)# %23’(cid:24) (cid:25)(cid:11)(cid:1)
(cid:1)(cid:20)(cid:10)(cid:9)(cid:15) (cid:10) (cid:16)(cid:1)(cid:11) (cid:6) (cid:15)(cid:1)(cid:9)(cid:2) (cid:1)(cid:1)(cid:1)$(cid:10)(cid:1) (cid:6) (cid:11)(cid:9)
/(cid:9)(cid:11)(cid:9) (cid:6)(cid:9)(cid:9) (cid:9)(cid:9)(cid:16)# 	(cid:2)(cid:11) (cid:10) (cid:12)(cid:12)(cid:12) %24’ (cid:10)(cid:15) (cid:18)5 %6’(cid:24)

(cid:25)(cid:11)(cid:9)# (cid:10)(cid:9) (cid:16)	(cid:10)(cid:10)(cid:9)(cid:9)(cid:15)  (cid:2)(cid:20)(cid:9)(cid:16)(cid:9)7 (cid:11)(cid:27)(cid:9)(cid:20)(cid:9) (cid:11)(cid:9) (cid:2)	
	(cid:10)(cid:1) (cid:2) (cid:1) (cid:6)(cid:9) (cid:11)(cid:1)(cid:16)(cid:11)(cid:9) (cid:11)(cid:10) (cid:11)(cid:9) (cid:2) (cid:6) /(cid:24)

5(cid:9)(cid:20)(cid:9)(cid:10)  (cid:9)(cid:9)(cid:10)(cid:2)(cid:11)(cid:9) (cid:9)(cid:15) (cid:10) (cid:9)(cid:10)(cid:1)(cid:20)(cid:9)  (cid:11)(cid:9) /(cid:9)(cid:11)(cid:9)
(cid:6)(cid:9)(cid:9) (cid:9)(cid:9)(cid:16)# %8 9 22 4’(cid:24) 1	(cid:2)(cid:1)(cid:10)  	(cid:9)(cid:15) (cid:1) %8 9’ (cid:10)(cid:9)
(cid:2)(cid:20)(cid:9)(cid:28) 	(cid:9) (cid:14)	(cid:15)  (cid:11)(cid:9)  (cid:16) (cid:10)(cid:1)(cid:1) (cid:6)	(cid:2)(cid:1)
(cid:10)(cid:15) (cid:6)	(cid:2)(cid:1)(cid:10)  (cid:1) %4’ (cid:10)(cid:9) (cid:2)(cid:20)(cid:9)(cid:28) 	(cid:9) (cid:14)	(cid:15)  (cid:11)(cid:9)
/(cid:9)(cid:11)(cid:9) (cid:6)(cid:9)(cid:9) (cid:9)(cid:9)(cid:16)#(cid:24)
 (cid:15)(cid:9)  (cid:1)(cid:1)(cid:1)$(cid:9) (cid:11)(cid:9)(cid:9) (cid:6)	(cid:2)	
(cid:1)(cid:10)  (cid:14)(cid:9) (cid:1)(cid:9)(cid:6) (cid:10)(cid:16)(cid:10)(cid:1) (cid:10) (cid:16)(cid:1)(cid:11) (cid:27)(cid:10) (cid:15)(cid:1),(cid:9)(cid:15) (cid:1)
	(cid:2)(cid:11) (cid:10) (cid:27)(cid:10)# (cid:11)(cid:10) (cid:1) ,(cid:28)(cid:9)(cid:15) (cid:1) (cid:2)(cid:9)(cid:15)  (cid:9)(cid:28)(cid:9)(cid:10)
(cid:6) (cid:11)(cid:9) (cid:6)	(cid:2)(cid:1)(cid:10) (cid:24)

(cid:25)(cid:11)(cid:9) (cid:10) (cid:16)(cid:1)(cid:11) (cid:9)(cid:15) (cid:1) %9’ (cid:1) (cid:2)(cid:10)  (cid:9)(cid:15) (cid:1)(cid:1)	(cid:1)(cid:11)(cid:1)(cid:7)(cid:12)(cid:13)(cid:1)(cid:14)
(cid:1)(cid:8)(cid:12)(cid:1) (cid:8)(cid:7)(cid:12) (cid:25)(cid:8) (cid:24) (cid:9)(cid:9)(cid:1)(cid:16) # (cid:1) ,(cid:28)(cid:9)(cid:15) (cid:1)
(cid:10)(cid:2)(cid:11)(cid:1)(cid:9)(cid:20)(cid:9) (cid:11)(cid:9) (cid:12) (cid:19)(cid:8)  (cid:1)(cid:1)	 (cid:6) (cid:11)(cid:9) 	(cid:9) (cid:14)	(cid:15)(cid:24) (cid:18)	
(cid:6)	(cid:10)(cid:9) # (cid:10) (cid:1) (cid:11)(cid:9) (cid:2)(cid:10)(cid:9) (cid:6) (cid:15)(cid:1)(cid:10)# / (cid:2)(cid:20)(cid:9)(cid:16)(cid:9)(cid:2)(cid:9)
(cid:1)  (cid:16)	(cid:10)(cid:10)(cid:9)(cid:9)(cid:15)(cid:24)

(cid:2)(cid:20)	(cid:3)	(cid:15) (cid:2) (cid:9)(cid:4)(cid:17) (cid:12) (cid:9) # (cid:9) (cid:10)(cid:9)(cid:15)  		
(cid:15)	(cid:2) (cid:10)(cid:9) .(cid:10)(cid:28)	(cid:15)	(cid:2)0  .(cid:1)		0 / (cid:10) (cid:16)	
(cid:1)(cid:11)(cid:24) (cid:25)(cid:11)(cid:9)(cid:1) (cid:16)(cid:10)  (cid:1)  ,(cid:15) (cid:10) (cid:2),(cid:16)	(cid:10)(cid:1) (cid:27)(cid:1)(cid:11) (cid:11)(cid:9)
(cid:10)(cid:28)(cid:1)	 (cid:10) (cid:9)(cid:1)(cid:1) : (cid:14)(cid:10)(cid:14)(cid:1) (cid:1)#  (cid:10) (cid:2)	
,(cid:16)	(cid:10)(cid:1) (cid:27)(cid:1)(cid:11) (cid:11)(cid:9) (cid:10)  (cid:9) (cid:9)(cid:9)(cid:16)#(cid:24) ;(cid:9)(cid:9)(cid:10)  # (cid:10)(cid:28)	
(cid:15)	(cid:2) (cid:10) (cid:16)(cid:1)(cid:11) (cid:2)(cid:10) (cid:14)(cid:9) (cid:14)(cid:10)(cid:1)(cid:9)(cid:15) (cid:6) 		(cid:15)	(cid:2)
(cid:20)(cid:9)(cid:1) (cid:1) (cid:11)(cid:9) $(cid:9) (cid:9)(cid:9)(cid:10)	(cid:9)  (cid:1)(cid:1)(cid:24) (cid:25)(cid:11)(cid:9)(cid:9) (cid:10)(cid:9)
(cid:2)(cid:10)(cid:20)(cid:9)(cid:10) (cid:11)(cid:27)(cid:9)(cid:20)(cid:9)7 (cid:6) (cid:9)(cid:28)(cid:10) (cid:9) (cid:1) (cid:1)  (cid:22)(cid:27) (cid:27)(cid:11)(cid:9)(cid:11)(cid:9)
,(cid:28)(cid:9)(cid:15) (cid:1) (cid:6) (cid:10)(cid:28)	(cid:15)	(cid:2) / (cid:2)(cid:9)(cid:15)  (cid:9)(cid:28)(cid:9)(cid:10)
(cid:6) (cid:9) (cid:6)	(cid:2)(cid:1)(cid:10) (cid:24)

 (cid:11)(cid:1) (cid:10)(cid:9) (cid:27)(cid:9) (cid:6)(cid:2)	  (cid:11)(cid:9) (cid:10)(cid:28)	(cid:15)	(cid:2) (cid:20)(cid:9)(cid:1) (cid:6)
(cid:9)(cid:9)	(cid:9)(cid:27)(cid:9)(cid:1)(cid:16)(cid:11)(cid:9)(cid:15) (cid:10) (cid:16)(cid:1)(cid:11) %&’(cid:24)
 (cid:6)(cid:10)(cid:2) (cid:27) (cid:15)(cid:1)<(cid:9)(cid:9)
(cid:25)(cid:8)  (cid:10) (cid:16)(cid:1)(cid:11) (cid:10)(cid:9) (cid:15)(cid:9)(cid:20)(cid:9) (cid:9)(cid:15) (cid:1) %&’(cid:24) (cid:25)(cid:11)(cid:9)# (cid:10)(cid:9) (cid:1)	
(cid:1)(cid:9)(cid:15) (cid:14)# (cid:11)(cid:9) (cid:14) (cid:9) (cid:6) (cid:10)(cid:28)(cid:1)(cid:1)$(cid:1)(cid:16) (cid:10) (cid:2)(cid:2)(cid:10)(cid:20)(cid:9)  (cid:27)(cid:9)
(cid:14)	(cid:15)  (cid:11)(cid:9) (cid:9)(cid:9)(cid:16)#(cid:24) (cid:25)(cid:11)(cid:9)(cid:9) (cid:10) (cid:16)(cid:1)(cid:11) (cid:11)(cid:10)(cid:20)(cid:9) (cid:11)(cid:9) (cid:6) 	
 (cid:27)(cid:1)(cid:16) (cid:9)#= (cid:1)(cid:6) (cid:11)(cid:9)(cid:1) ,(cid:28)(cid:9)(cid:15) (cid:1) (cid:10)(cid:1),(cid:9) (cid:10) (cid:2)(cid:9)(cid:10)(cid:1)
(cid:2)(cid:15)(cid:1)(cid:1) .(cid:9)(cid:9) (cid:10)(cid:16)(cid:9)(cid:9)(cid:9)0 (cid:11)(cid:9) (cid:1) (cid:1) (cid:16)	(cid:10)(cid:10)(cid:9)(cid:9)(cid:15) 
(cid:16)(cid:1)(cid:20)(cid:9) (cid:10) :  	(cid:1) (cid:1)(cid:24)(cid:9)(cid:24) (cid:10) (cid:16) (cid:14)(cid:10)  (cid:1)(cid:1)	 (cid:6) (cid:11)(cid:9)
(cid:9)(cid:9)(cid:16)#(cid:24)

 (cid:27)(cid:9)(cid:20)(cid:9) (cid:25)(cid:8)  (cid:10) (cid:16)(cid:1)(cid:11) (cid:1) %&’ (cid:2)(cid:10) (cid:14)(cid:9) (cid:20)(cid:1)(cid:9)(cid:27)(cid:9)(cid:15) (cid:10)
(cid:10) (cid:16)(cid:1)(cid:11) (cid:6) (cid:15)(cid:1)(cid:9)(cid:2) (cid:10)(cid:28)(cid:1)(cid:1)$(cid:10)(cid:1) (cid:6) (cid:11)(cid:9) (cid:14)	(cid:15)(cid:24) 	
(cid:15)(cid:9)(cid:9)(cid:15) (cid:1) 	 (cid:9)(cid:28)(cid:9)(cid:1)(cid:9) (cid:27)(cid:9) (cid:14)(cid:9)(cid:20)(cid:9)(cid:15) (cid:11)(cid:10) (cid:9)(cid:1)(cid:9)
(cid:11)(cid:9)# (cid:15)(cid:9)(cid:2)(cid:9)(cid:10)(cid:9) (cid:1)(cid:24) :  (cid:11)(cid:9) (cid:10) (cid:16)(cid:1)(cid:11) (cid:15)  (cid:10) (cid:27)(cid:10)#
(cid:2)(cid:20)(cid:9)(cid:16)(cid:9)7 (cid:27)(cid:11)(cid:9) (cid:1) (cid:11)(cid:10)(cid:9) (cid:11)(cid:9) (cid:20)(cid:10) 	(cid:9) (cid:6) (cid:11)(cid:9) (cid:14)	(cid:15) (cid:6)	

182(cid:9) (cid:16)(cid:9) (cid:1) (cid:10)  (cid:24)

	 (cid:10)(cid:1) (cid:2)(cid:1)(cid:14)	(cid:1) (cid:1) (cid:10) (cid:6)  (cid:27)= (cid:27)(cid:9) (cid:11)(cid:27) (cid:11)(cid:27) 
(cid:15)(cid:1)(cid:6)# (cid:25)(cid:8)  (cid:10) (cid:16)(cid:1)(cid:11)  (cid:11)(cid:10) (cid:11)(cid:9) (cid:20)(cid:10) 	(cid:9) (cid:6) (cid:11)(cid:9) (cid:14)	(cid:15)
(cid:1) (cid:16)	(cid:10)(cid:10)(cid:9)(cid:9)(cid:15)   (cid:15)(cid:9)(cid:2)(cid:9)(cid:10)(cid:9)(cid:24) (cid:25)(cid:11)	 (cid:27)(cid:9) (cid:10)(cid:9) (cid:16)	(cid:10)(cid:10)	
(cid:9)(cid:9)(cid:15)  ,(cid:15) (cid:10)  (cid:9)(cid:10) (cid:10) . (cid:2)(cid:10) 0 (cid:10)(cid:28)(cid:1)	 (cid:6) (cid:11)(cid:9) (cid:14)	(cid:15)(cid:24)
(cid:25)(cid:11)(cid:9) (cid:27)(cid:15) . (cid:2)(cid:10) 0 (cid:1) (cid:1) 	(cid:9) (cid:1)(cid:2)(cid:9) (cid:6) (cid:2)(cid:2)(cid:10)(cid:20)(cid:9) (cid:6)	(cid:2)	
(cid:1) (cid:10)    (cid:2)(cid:10)  (cid:10)(cid:28)(cid:1)(cid:10) (cid:10)(cid:9) (cid:16) (cid:14)(cid:10)  (cid:1)(cid:6) (cid:11)(cid:9) (cid:10)(cid:15)(cid:10)(cid:15) (cid:9)	
(cid:1)(cid:2) (cid:10)(cid:2)(cid:9)  (cid:16)# (cid:1) 	(cid:9)(cid:15)(cid:24)  (cid:9)(cid:9) (cid:27)(cid:9) 	(cid:9) (cid:10) (cid:27)(cid:9)(cid:10)(cid:22)(cid:9)  	
(cid:16)#= 	 (cid:10)(cid:28)(cid:1)(cid:10) (cid:10)(cid:9)  (cid:2)(cid:10)  (cid:27)(cid:1)(cid:11) (cid:9)(cid:9)(cid:2)  (cid:11)(cid:9) (cid:25)(cid:8) 
(cid:10) (cid:16)(cid:1)(cid:11)(cid:24)  (cid:9) (cid:6)	 (cid:10)(cid:9) (cid:11)(cid:9) (cid:11)(cid:1)(cid:8)(cid:17) (cid:1)(cid:1) (cid:8)(cid:12)(cid:1)(cid:1)(cid:1) (cid:2)	
(cid:15)(cid:1)(cid:1)  (cid:25): (cid:27)(cid:11)(cid:1)(cid:2)(cid:11) (cid:16)(cid:1)(cid:20)(cid:9) (cid:10) (cid:9)(cid:2)(cid:1)(cid:9) (cid:2)(cid:11)(cid:10)(cid:10)(cid:2)(cid:9)(cid:1)$(cid:10)(cid:1) (cid:6)
	(cid:2)(cid:11) (cid:10)(cid:28)(cid:1)(cid:10)(cid:24)  (cid:9) (cid:20)(cid:9) (cid:11)(cid:10) 	 (cid:10) (cid:16)(cid:1)(cid:11) (cid:11)(cid:10) (cid:10) 	(cid:14)	
(cid:9)	(cid:9)(cid:2)(cid:9) (cid:2)(cid:20)(cid:9)(cid:16)(cid:1)(cid:16)  (cid:10) (cid:20)(cid:9)(cid:2) (cid:10)(cid:1)(cid:6)#(cid:1)(cid:16)  (cid:25):(cid:24)

: (cid:1)(cid:9)(cid:9)(cid:1)(cid:16) 	(cid:9)(cid:1) (cid:1) (cid:27)(cid:11)(cid:9)(cid:11)(cid:9)  (cid:25): (cid:10) (cid:27)(cid:10)# (cid:16)(cid:1)(cid:20)(cid:9)
(cid:10) (cid:16) (cid:14)(cid:10)  (cid:10)(cid:28)(cid:1)	 (cid:6) (cid:11)(cid:9) (cid:14)	(cid:15)(cid:24)  (cid:9) (cid:11)(cid:27) (cid:11)(cid:10) (cid:11)(cid:1)
(cid:1)  (cid:11)(cid:9) (cid:2)(cid:10)(cid:9) (cid:14)# (cid:20)(cid:1)(cid:15)(cid:1)(cid:16) (cid:10) (cid:2)	(cid:9)(cid:9)(cid:28)(cid:10) (cid:9)(cid:24) (cid:25)(cid:11)(cid:1)
(cid:1) (cid:10) (cid:15)(cid:1)<(cid:9)(cid:9)(cid:2)(cid:9) (cid:14)(cid:9)(cid:27)(cid:9)(cid:9) 		(cid:15)	(cid:2) (cid:10)(cid:15) (cid:10)(cid:28)	(cid:15)	(cid:2)
(cid:2)(cid:10)(cid:9)(cid:24)

(cid:25)(cid:8)  (cid:10) (cid:16)(cid:1)(cid:11) (cid:9)	(cid:1)(cid:9) (cid:9) (cid:2)(cid:11)(cid:1)(cid:2)(cid:9) (cid:6) (cid:9)(cid:9) (cid:2)(cid:20)(cid:9)	
(cid:1)(cid:16) (cid:11)(cid:9) (cid:16)(cid:10)(cid:11)(cid:24)
(cid:6) (cid:11)(cid:9) (cid:9)(cid:9) (cid:11)(cid:10)(cid:20)(cid:9) (cid:10) (cid:9)(cid:2)(cid:1)(cid:10)  	(cid:2)	(cid:9)
(cid:10)(cid:9) # (cid:2)(cid:11)(cid:10)(cid:1) (cid:27)(cid:11)(cid:1)(cid:2)(cid:11) (cid:10)(cid:9) (cid:7)(cid:20) (cid:27)(cid:1)(cid:11) (cid:9)(cid:9)(cid:2) 
(cid:9) (cid:15)(cid:9)(cid:1)(cid:16)  (cid:11)(cid:9) (cid:16)(cid:10)(cid:11) (cid:11)(cid:9) 	 (cid:10) (cid:16)(cid:1)(cid:11) (cid:9)	
(cid:15)	(cid:2)(cid:9)  (cid:11)(cid:9) (cid:25)(cid:8)  (cid:9)(cid:10)(cid:16)(cid:9)	(cid:10)(cid:1)(cid:16) (cid:10) (cid:16)(cid:1)(cid:11) (cid:6)  (cid:10)(cid:1)	
(cid:27)(cid:1)(cid:16)(cid:11) (cid:9) (cid:10) (cid:24) %&’ (cid:14)	 (cid:27)(cid:1)(cid:11) (cid:10) (cid:1)(cid:16)(cid:1),(cid:2)(cid:10) (cid:15)(cid:1)(cid:1)(cid:2)(cid:1)= (cid:27)(cid:9)
	(cid:15)(cid:10)(cid:9) (cid:9)(cid:10)(cid:16)(cid:9) (cid:1) (cid:10) (cid:9)(cid:2)(cid:1),(cid:2) (cid:1)	(cid:1)(cid:7)(cid:8)  (cid:15)(cid:9) (cid:10)(cid:11)(cid:9)
(cid:11)(cid:10) (cid:1) (cid:10)(cid:10)  (cid:9) (cid:24)
 (cid:11)(cid:9) (cid:2)(cid:9)(cid:28) (cid:6) (cid:15)(cid:1)(cid:10)# / (cid:1)
(cid:1) (cid:10) (cid:27)(cid:9)  	(cid:22)(cid:27) (cid:9)(cid:28)(cid:9)(cid:1)(cid:9)(cid:10)  (cid:6)(cid:10)(cid:2) (cid:11)(cid:10) (cid:9)	(cid:9)(cid:1)(cid:10)  		
(cid:15)(cid:10)(cid:9) (cid:10)(cid:9) 	(cid:9)(cid:1)  (cid:10)(cid:10)  (cid:9)  	(cid:15)(cid:10)(cid:9) (cid:10) (cid:11)	(cid:16)(cid:11) (cid:2)	
(cid:20)(cid:9)(cid:16)(cid:9)(cid:2)(cid:9) (cid:1) (cid:1)    (cid:16)	(cid:10)(cid:10)(cid:9)(cid:9)(cid:15)(cid:24)  (cid:9) (cid:16)(cid:1)(cid:20)(cid:9) (cid:10) (cid:11)(cid:9)(cid:9)(cid:1)(cid:2)(cid:10) 
@	(cid:1),(cid:2)(cid:10)(cid:1) (cid:6) (cid:9)	(cid:9)(cid:1)(cid:10)  	(cid:15)(cid:10)(cid:9) (cid:1) (cid:11)(cid:9) (cid:2)(cid:10)(cid:9) (cid:6) (cid:9)(cid:9)	
(cid:9)(cid:27)(cid:9)(cid:1)(cid:16)(cid:11)(cid:9)(cid:15) (cid:10) (cid:16)(cid:1)(cid:11)(cid:24)

	 (cid:9)(cid:28)(cid:9)(cid:1)(cid:9)(cid:10)  (cid:9)	  (cid:1)(cid:2) 	(cid:15)(cid:9) (cid:14)(cid:11) #(cid:11)(cid:9)(cid:1)(cid:2) (cid:10)(cid:15)
(cid:9)(cid:10)  (cid:14) (cid:9)(cid:24)
 (cid:10)(cid:1)(cid:2)	 (cid:10) (cid:27)(cid:9) (cid:2)(cid:1)(cid:15)(cid:9) (cid:10) (cid:9)(cid:9)(cid:16)#
(cid:6)	(cid:2)(cid:1) (cid:10)(cid:1)(cid:1)(cid:16) (cid:1) (cid:11)(cid:9) (cid:9)(cid:9) (cid:10)(cid:2)(cid:11)(cid:1)(cid:16) (cid:14) (cid:9) %2’(cid:24)
 (cid:9) (cid:15)(cid:9)(cid:10)(cid:9) (cid:11)(cid:10) 	 (cid:10) (cid:16)(cid:1)(cid:11) 	(cid:9)(cid:6) (cid:14)(cid:11)
(cid:11)(cid:9) (cid:15)(cid:1)(cid:10)# / (cid:10)(cid:15) (cid:11)(cid:9) (cid:25)(cid:8)  (cid:10) (cid:16)(cid:1)(cid:11) (cid:6)  (cid:10)(cid:1)	
(cid:27)(cid:1)(cid:16)(cid:11) (cid:9) (cid:10) (cid:24) %&’(cid:24) (cid:9)(cid:20)(cid:9) (cid:27)(cid:9) (cid:14)(cid:10)(cid:1) (cid:10)  (cid:1)(cid:16)(cid:11) #  (cid:27)(cid:9)
(cid:9)(cid:9)(cid:16)# (cid:11)(cid:10) (cid:11)(cid:9) (cid:9)(cid:28)(cid:10)(cid:1) (cid:20)(cid:9) (cid:9)(cid:11)(cid:15) %2’ (cid:27)(cid:11)(cid:1)(cid:2)(cid:11) (cid:1)
(cid:16)(cid:9)(cid:9)(cid:10)  # (cid:2)(cid:1)(cid:15)(cid:9)(cid:9)(cid:15)  (cid:14)(cid:9) (cid:11)(cid:9)  (cid:10)(cid:2)(cid:2)	(cid:10)(cid:9) (cid:1)(cid:1)(cid:1)$(cid:10)	
(cid:1) (cid:9)(cid:2)(cid:11)(cid:1)	(cid:9) (cid:6) 	(cid:2)(cid:11) (cid:9)(cid:9)(cid:16)# (cid:6)	(cid:2)(cid:1)(cid:24)

	 (cid:4)(cid:23) (cid:25)(cid:11)(cid:9) (cid:10)(cid:9) (cid:1) (cid:16)(cid:10)(cid:1)$(cid:9)(cid:15) (cid:10) (cid:6)  (cid:27)(cid:24)  (cid:9)(cid:2)	
(cid:1) 3 (cid:27)(cid:9) (cid:1)(cid:15)	(cid:2)(cid:9) 	 (cid:10)(cid:1) (cid:10)(cid:15) (cid:9)(cid:20)(cid:1)(cid:9)(cid:27) (cid:9) (cid:9)	
	  (cid:6) %&’ (cid:1) (cid:10)(cid:1)(cid:2)	 (cid:10) (cid:11)(cid:9)  (cid:27)(cid:9) (cid:14)	(cid:15)  (cid:11)(cid:9)
(cid:9)(cid:9)(cid:16)# (cid:6)	(cid:2)(cid:1) (cid:20)(cid:1)(cid:10) (cid:2)(cid:20)(cid:9)(cid:28) (cid:2)(cid:14)(cid:1)(cid:10)(cid:1) (cid:6) (cid:9)(cid:9) (cid:10)(cid:15)
(cid:15)	(cid:10) (cid:1)# (cid:9)	 (cid:24) 	 (cid:9)(cid:27) (cid:9)(cid:9)	(cid:9)(cid:27)(cid:9)(cid:1)(cid:16)(cid:11)(cid:9)(cid:15) (cid:10) (cid:16)(cid:1)(cid:11) (cid:10)(cid:15)
(cid:1) (cid:10)(cid:10) #(cid:1) (cid:10)(cid:9) (cid:16)(cid:1)(cid:20)(cid:9) (cid:1) (cid:9)(cid:2)(cid:1) 4(cid:24) -(cid:28)(cid:9)(cid:1)(cid:9)(cid:10)  (cid:9)	 
(cid:10)(cid:9) (cid:15)(cid:9)(cid:2)(cid:1)(cid:14)(cid:9)(cid:15) (cid:1) (cid:9)(cid:2)(cid:1) A(cid:24) 1(cid:1)(cid:10)  # (cid:27)(cid:9) (cid:16)(cid:1)(cid:20)(cid:9) (cid:2)(cid:2) 	(cid:1)
(cid:1) (cid:9)(cid:2)(cid:1) 6(cid:24)

(cid:14) (cid:5)(cid:13) (cid:5)(cid:11) (cid:1)(cid:5)(cid:6)(cid:16)(cid:17)	(cid:11)

 (cid:11)(cid:1) (cid:10)(cid:9) (cid:27)(cid:9) (cid:2) (cid:9) # (cid:6)  (cid:27) (cid:11)(cid:9) (cid:10)(cid:1) 	(cid:9)(cid:15) (cid:1) %&’(cid:24)
 (cid:27)(cid:9)(cid:20)(cid:9) (cid:1)(cid:9)(cid:10)(cid:15) (cid:6) (cid:10)(cid:28)(cid:1)(cid:1)$(cid:1)(cid:16) (cid:9)(cid:1) (cid:14)(cid:10)(cid:14)(cid:1) (cid:1)#

(cid:27)(cid:9) (cid:1)(cid:1)(cid:1)$(cid:9) (cid:10) (cid:9)(cid:9)(cid:16)# (cid:6)	(cid:2)(cid:1)(cid:24) (cid:25)(cid:11)(cid:9)(cid:9)(cid:6)(cid:9) (cid:27)(cid:9) (cid:9) (cid:10)(cid:2)(cid:9)
.(cid:1)0 (cid:27)(cid:1)(cid:11) .(cid:10)(cid:28)0 .(cid:1)(cid:6)0 (cid:27)(cid:1)(cid:11) .	0 (cid:10)(cid:15) (cid:20)(cid:1)(cid:2)(cid:9) (cid:20)(cid:9)(cid:10)(cid:24)

(cid:9) (cid:0) C (cid:1)(cid:0) (cid:2) (cid:14)(cid:9) (cid:10) 	(cid:15)(cid:1)(cid:9)(cid:2)(cid:9)(cid:15) (cid:16)(cid:10)(cid:11) (cid:27)(cid:1)(cid:11) (cid:11)(cid:9) (cid:9) (cid:6)
(cid:20)(cid:9)(cid:1)(cid:2)(cid:9) (cid:1) (cid:10)(cid:15) (cid:11)(cid:9) (cid:9) (cid:6) (cid:9)(cid:15)(cid:16)(cid:9) (cid:2)(cid:24) 1 (cid:9)(cid:10)(cid:2)(cid:11)  (cid:3) (cid:1)  (cid:9)
(cid:2) (cid:14)(cid:9) (cid:10) (cid:20)(cid:10)(cid:1)(cid:10)(cid:14) (cid:9) (cid:10)(cid:22)(cid:1)(cid:16) (cid:20)(cid:10) 	(cid:9) (cid:1) (cid:9) (cid:15)(cid:1)(cid:2)(cid:9)(cid:9) (cid:10)(cid:2)(cid:9)
(cid:4)(cid:24) /# (cid:2)(cid:2)(cid:10)(cid:9)(cid:10)(cid:1)(cid:16) (cid:11)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:14) (cid:9) (cid:10) (cid:9)(cid:10)(cid:2)(cid:11) (cid:15)(cid:9) (cid:27)(cid:9)
(cid:14)(cid:10)(cid:1) (cid:10) (cid:20)(cid:9)(cid:2) (cid:20) (cid:27)(cid:1)(cid:11)  C (cid:5)(cid:1)(cid:5) (cid:9) (cid:9)(cid:9)(cid:24) (cid:25)(cid:11)(cid:1) (cid:20)(cid:9)(cid:2)
(cid:10)(cid:22)(cid:9) (cid:20)(cid:10) 	(cid:9) (cid:1) (cid:11)(cid:9) (cid:10)(cid:2)(cid:9) (cid:4) C (cid:4)(cid:0)  (cid:4)(cid:1)  (cid:4) (cid:4) (cid:4)  (cid:4)(cid:24)
(cid:18) (cid:9) (cid:9)(cid:15) (cid:11)(cid:9)(cid:27)(cid:1)(cid:9) #(cid:14)   (cid:10)(cid:15)  (cid:27)(cid:1)   (cid:15)(cid:9)(cid:9)
(cid:15)(cid:9) (cid:1) (cid:1) (cid:0)  	 (cid:9)(cid:15)(cid:16)(cid:9) (cid:1) (cid:2) (cid:6) (cid:10)(cid:15) (cid:7) 	 (cid:20)(cid:10)(cid:1)(cid:10)(cid:14) (cid:9) (cid:1) (cid:4)
(cid:10)(cid:15) (cid:4) (cid:9)(cid:9)(cid:2)(cid:1)(cid:20)(cid:9) #(cid:24)

(cid:21)	(cid:20)(cid:7) (cid:1) (cid:10) (cid:10)(cid:1)(cid:16) (cid:8) = (cid:4) (cid:7) (cid:0)(cid:24)
: (cid:1)(cid:7)(cid:8) 
 (cid:9) (cid:2)(cid:10) (cid:10)  (cid:2)(cid:1)(cid:15)(cid:9) (cid:10) (cid:6)(cid:10)(cid:1) # (cid:6) (cid:9)(cid:1)(cid:10)  (cid:6)	(cid:2)(cid:1)
(cid:8)(cid:8)(cid:3) (cid:5) (cid:9) (cid:3) (cid:10) (cid:27)(cid:11)(cid:9)(cid:9)  (cid:1) (cid:9) (cid:1)(cid:15)(cid:9)(cid:28) (cid:9)(cid:24) (cid:25)(cid:11)(cid:1) (cid:6)(cid:10)(cid:1) #
(cid:15)(cid:9),(cid:9) (cid:10) (cid:20)(cid:9)(cid:2)	(cid:20)(cid:10) 	(cid:9)(cid:15) (cid:10)(cid:1)(cid:16) (cid:0) = (cid:4) (cid:7) (cid:0)(cid:4) (cid:24) :(cid:2)(cid:1)	
(cid:10)(cid:9)(cid:15) (cid:27)(cid:1)(cid:11) (cid:0) (cid:1) (cid:10) (cid:9)(cid:10) 	(cid:20)(cid:10) 	(cid:9)(cid:15) (cid:20)(cid:9)(cid:2) (cid:10) C (cid:8)(cid:10)(cid:3) (cid:5) (cid:9) (cid:3) (cid:10)
(cid:27)(cid:11)(cid:1)(cid:2)(cid:11) (cid:27)(cid:9) (cid:2)(cid:10)   (cid:10) (cid:1)(cid:1)(cid:12)(cid:22) (cid:8)(cid:8)(cid:1)(cid:1) (cid:23)(cid:1)(cid:20)(cid:0)(cid:24) (cid:25)(cid:11)(cid:1) (cid:20)(cid:9)(cid:2)
(cid:15)(cid:9),(cid:9) (cid:10) (cid:9)(cid:9)(cid:16)# (cid:6)	(cid:2)(cid:1) (cid:11) (cid:5) (cid:10) = (cid:4) (cid:7) (cid:0) (cid:10) (cid:6)  (cid:27)=

(cid:11)(cid:20) (cid:5) (cid:10) C (cid:12)(cid:10)(cid:0) (cid:0)(cid:20)(cid:13) C (cid:0)

(cid:10)(cid:3)(cid:8)(cid:3)(cid:20)

2

(cid:3)(cid:0)

(cid:27)(cid:11)(cid:9)(cid:9) (cid:12)(cid:0) (cid:13) (cid:1) (cid:11)(cid:9) (cid:15)(cid:1)(cid:10)# -	(cid:2) (cid:1)(cid:15)(cid:9)(cid:10) (cid:15)	(cid:2) (cid:1) (cid:0)(cid:4) (cid:24)

 (cid:9) (cid:27)(cid:1)   	(cid:9) (cid:11)(cid:9) (cid:2)  (cid:9)(cid:2)(cid:1) (cid:6) (cid:9)(cid:1)(cid:10)  (cid:6)	(cid:2)(cid:1) (cid:2)(cid:10)  (cid:9)(cid:15)
(cid:11)(cid:9) (cid:20)(cid:8)(cid:7)(cid:20)(cid:8)  (cid:23)(cid:1)(cid:20) (cid:1)(cid:1) (cid:1)(cid:1)(cid:1)(cid:8)(cid:7) %D 2E’(cid:24)  (cid:1)
(cid:15)(cid:9),(cid:9)(cid:15) (cid:10) (cid:6)  (cid:27)=

(cid:8)Æ(cid:5)(cid:2)(cid:10) (cid:14) (cid:8)Æ(cid:5)(cid:2)Æ(cid:6)(cid:2)(cid:10) (cid:14) (cid:8)(cid:8)(cid:7)(cid:20)(cid:10)

(cid:27)(cid:11)(cid:9)(cid:9) Æ(cid:5)(cid:2) (cid:1) (cid:10) (cid:7)(cid:14)(cid:7)(cid:20)(cid:8) (cid:21)	(cid:20)(cid:7) 	 (cid:1) (cid:1) (cid:9)	(cid:10)  
(cid:9) (cid:1)(cid:6) (cid:2) C (cid:6) (cid:10)(cid:15) $(cid:9) (cid:11)(cid:9)(cid:27)(cid:1)(cid:9)(cid:24) 1	(cid:2)(cid:1) (cid:8)(cid:7)(cid:20)
(cid:9)	(cid:10)   2 (cid:6) (cid:10)   (cid:10)(cid:16)	(cid:9)(cid:24) (cid:25)(cid:11)(cid:9) (cid:1)(cid:15)(cid:9)(cid:28) (cid:9) (cid:6) (cid:11)(cid:1)
(cid:9)(cid:9)(cid:9)(cid:10)(cid:1) (cid:1)

 C (cid:8)7 (cid:6)(cid:10) (cid:14) (cid:8)7 (cid:6)(cid:7)(cid:10) (cid:14) (cid:8)(cid:12)(cid:10)

(cid:9) (cid:11)(cid:10) 7 (cid:6)(cid:7) (cid:15) 7 (cid:7)(cid:6)  (cid:10)(cid:2)(cid:5)(cid:6) (cid:10)(cid:15) (cid:10)(cid:2)(cid:6)(cid:5) (cid:10)(cid:9) (cid:11)(cid:9)
(cid:10)(cid:9) (cid:9) (cid:9)(cid:9)(cid:24)

5(cid:9)(cid:1)(cid:9) (cid:1) (cid:27)(cid:1)   (cid:14)(cid:9) (cid:2)(cid:20)(cid:9)(cid:1)(cid:9)  (cid:15)(cid:9)(cid:9) (cid:9) (cid:9)(cid:9) (cid:10)(cid:2)(cid:5)
(cid:10)(cid:15) (cid:10)(cid:2)(cid:5)(cid:6) (cid:10) (cid:10)(cid:6) (cid:10)(cid:15) (cid:10)(cid:6)(cid:0) (cid:7) (cid:9)(cid:9)(cid:2)(cid:1)(cid:20)(cid:9) #(cid:24)  (cid:9) (cid:27)(cid:1)  
(cid:10)  	(cid:9) (cid:10)(cid:1) (cid:10)  (cid:15)(cid:9)(cid:9) (cid:10) (cid:20)(cid:9)(cid:2) (cid:6) (cid:1)$(cid:9) (cid:5)(cid:4)(cid:5) (cid:10)(cid:15)
(cid:10)  (cid:15)(cid:9)(cid:9) (cid:10) (cid:20)(cid:9)(cid:2) (cid:6) (cid:1)$(cid:9) (cid:5)(cid:4)  (cid:4)(cid:5)(cid:24)

(cid:9) (cid:11)(cid:10) (cid:9)(cid:9)(cid:16)# (cid:6)	(cid:2)(cid:1) 2 (cid:2)(cid:9)(cid:15)(cid:1)(cid:16)  (cid:11)(cid:1) (cid:9)	
(cid:9)(cid:9)(cid:10)(cid:1) (cid:2)(cid:10) (cid:14)(cid:9) (cid:27)(cid:1)(cid:9) (cid:10) (cid:10) 	 (cid:6) 	(cid:10)# (cid:9)
(cid:2)(cid:9)(cid:15)(cid:1)(cid:16)  (cid:15)(cid:9) (cid:1) (cid:1) (cid:10)(cid:15) (cid:10)(cid:1)(cid:27)(cid:1)(cid:9) (cid:9) (cid:2)	
(cid:9)(cid:15)(cid:1)(cid:16)  (cid:9)(cid:15)(cid:16)(cid:9) (cid:1) (cid:2)=

(cid:11)(cid:20) (cid:5) (cid:10) C (cid:10)(cid:7)  (cid:0)

(cid:10)(cid:2)  (cid:0)

(cid:10)(cid:2)(cid:0) (cid:2)

(cid:0)(cid:2)

(cid:9)(cid:0)(cid:3)

(cid:9) 	 (cid:1)(cid:15)	(cid:2)(cid:9) (cid:10)(cid:11)(cid:9) (cid:10)(cid:1) (cid:27)(cid:11)(cid:1)(cid:2)(cid:11) (cid:27)(cid:9) (cid:27)(cid:1)  
	(cid:9) (cid:9)(cid:28)(cid:9)(cid:1)(cid:20)(cid:9) # (cid:11)	(cid:16)(cid:11)	 (cid:11)(cid:9) (cid:10)(cid:9)(cid:24)
1	(cid:2)(cid:1)
(cid:0) (cid:2)(cid:5) (cid:0) (cid:2)(cid:5)(cid:6) = (cid:0)(cid:4) (cid:7) (cid:0) (cid:16)(cid:1)(cid:20)(cid:9) (cid:1)(cid:6)(cid:10)(cid:1) (cid:10)(cid:14)	 (cid:11)(cid:9)

(cid:0) (cid:2)(cid:3) (cid:5)(cid:6)(cid:7) (cid:9)(cid:9)(cid:12)(cid:12) (cid:0) (cid:14) (cid:16)(cid:9)  (cid:12)(cid:18) (cid:9) (cid:0)(cid:1)(cid:0)(cid:6)(cid:7)  (cid:7)(cid:7)(cid:0)	
(cid:0) (cid:12)(cid:0)(cid:13)(cid:19) (cid:20)(cid:12) 	(cid:12) (cid:9) (cid:18)(cid:14)(cid:22)(cid:12)(cid:12) (cid:9)(cid:12)  (cid:12)(cid:24)(cid:9)(cid:14)(cid:25)(cid:12) (cid:24)(cid:12) (cid:26)(cid:9)(cid:16)
(cid:24)(cid:9) 	 (cid:0) (cid:14) (cid:24)(cid:12) (cid:12)(cid:27)(cid:9)(cid:14)(cid:28)(cid:12) (cid:26) (cid:0) 	(cid:12)(cid:18) (cid:14) (cid:2)(cid:3) (cid:5)(cid:6)(cid:7)(cid:19)

183(cid:1)(cid:1)	 (cid:20)(cid:10) 	(cid:9) (cid:6) (cid:11)(cid:9) (cid:9)(cid:9)(cid:16)# 	(cid:15)(cid:9) (cid:15)(cid:1)<(cid:9)(cid:9) (cid:2)	
(cid:10)(cid:1)=

C (cid:1)(cid:0)(cid:0)(cid:4)

(cid:11)(cid:20) (cid:5) (cid:10)
(cid:10)
(cid:11)(cid:20) (cid:5) (cid:10)
(cid:2)(cid:5)(cid:10) C (cid:1)(cid:0)(cid:0)(cid:4) (cid:9)(cid:10)(cid:5)(cid:5)
(cid:2)(cid:5)(cid:6)(cid:10) C (cid:1)(cid:0)(cid:0)(cid:4) (cid:9)(cid:10)(cid:5)(cid:5)(cid:9)(cid:10)(cid:5)(cid:6) (cid:11)(cid:20) (cid:5) (cid:10)

I(cid:10) 	(cid:9) (cid:2)(cid:5)(cid:10) (cid:10)(cid:15) (cid:2)(cid:5)(cid:6)(cid:10) (cid:10)(cid:9) (cid:2)(cid:10)  (cid:9)(cid:15) (cid:7)	(cid:8)(cid:12)(cid:7)(cid:8) 
(cid:6) (cid:15)(cid:9)  (cid:10)(cid:15) (cid:9)(cid:15)(cid:16)(cid:9) (cid:0)  (cid:9)(cid:9)(cid:2)(cid:1)(cid:20)(cid:9) #(cid:24)

(cid:24)(cid:25)(cid:26) (cid:27)(cid:23)(cid:2)(cid:2)(cid:23)(cid:23)(cid:4)(cid:28)(cid:2)(cid:4) (cid:2)(cid:3) (cid:2)(cid:20)	(cid:3)	(cid:15)

(cid:29)(cid:23) (cid:4)(cid:23)(cid:30) (cid:2)(cid:9)(cid:2)(cid:4)

(cid:6) (cid:27) (cid:10)(cid:10)(cid:9)(cid:9) (cid:20)(cid:9)(cid:2) (cid:10) (cid:10)(cid:15) (cid:10)(cid:5) (cid:15)(cid:9),(cid:9) (cid:11)(cid:9) (cid:10)(cid:9) (cid:9)	
(cid:9)(cid:16)# (cid:6)	(cid:2)(cid:1) (cid:1)(cid:24)(cid:9)(cid:24) (cid:11)(cid:20) (cid:5) (cid:10)(cid:5) C (cid:11)(cid:20) (cid:5) (cid:10) (cid:6) (cid:10)   (cid:20) (cid:3) (cid:4) 
(cid:11)(cid:9) (cid:10)(cid:5) (cid:1) (cid:2)(cid:10)  (cid:9)(cid:15) (cid:10) (cid:1)(cid:8)(cid:8)(cid:1)(cid:1)(cid:7)(cid:24)(cid:8)(cid:7) (cid:6) (cid:10) %D 2E’(cid:24)  (cid:9)
(cid:27)(cid:1)   (cid:27)(cid:1)(cid:9) (cid:11)(cid:1) (cid:10) (cid:10)(cid:5) (cid:15) (cid:10)(cid:24) (cid:9) (cid:11)(cid:10) (cid:11)(cid:1) (cid:2)(cid:15)(cid:1)(cid:1)
(cid:15)(cid:9)  (cid:9)(cid:2)(cid:9)(cid:10)(cid:1) # (cid:1) # (cid:11)(cid:10) (cid:10)(cid:5) C (cid:10) (cid:1)(cid:2)(cid:9) (cid:11)(cid:9)(cid:9) (cid:10)(cid:9)
(cid:20)(cid:10)(cid:1)	  (cid:1)(cid:9)(cid:10) (cid:9) (cid:10)(cid:1) (cid:10)(cid:16) (cid:9)(cid:1)(cid:10)  (cid:6)	(cid:2)(cid:1) (cid:8)(cid:3)(cid:24)

(cid:8)(cid:9)(cid:10)(cid:10)(cid:9)(cid:9)(cid:1)$(cid:10)(cid:1) (cid:20)(cid:1)(cid:15)(cid:9) (cid:10) (cid:10) (cid:9)(cid:10)(cid:1)(cid:20)(cid:9)   (cid:6)
(cid:11)(cid:9) (cid:10)(cid:10) #(cid:1) (cid:6) (cid:14)(cid:9) (cid:1)(cid:9)(cid:6) (cid:10)(cid:16)(cid:10)(cid:1) (cid:10) (cid:16)(cid:1)(cid:11)(cid:24) (cid:8)(cid:9)(cid:2)(cid:10)  
(cid:11)(cid:10) (cid:10) (cid:14)(cid:10)(cid:1)(cid:2) (cid:9)(cid:10)(cid:1) (cid:6) / (cid:1) (cid:8)(cid:7)(cid:12) (cid:8) (cid:1)(cid:8)(cid:12)(cid:1) (cid:6)
(cid:15)(cid:9)   (cid:15)(cid:9) (cid:24) : (cid:11)(cid:27) (cid:1) %D 2E’ (cid:11)(cid:1) (cid:9)(cid:10)(cid:1)
(cid:2)(cid:10) (cid:14)(cid:9) (cid:1) (cid:9)(cid:9)(cid:9)(cid:15) (cid:27)(cid:1)(cid:11)	 (cid:10)# (cid:9)(cid:10)(cid:16)(cid:9)= (cid:1) (cid:1) (cid:9)	(cid:1)(cid:20)	
(cid:10) (cid:9)  (cid:10) (cid:2)(cid:9)(cid:10)(cid:1) (cid:9)(cid:10)(cid:10)(cid:9)(cid:9)(cid:1)$(cid:10)(cid:1) (cid:6) (cid:20)(cid:9)(cid:2) (cid:10) (cid:10)(cid:15)
(cid:10) (cid:6) (cid:9)(cid:15)(cid:16)(cid:9) (cid:0)  (cid:10)(cid:15) (cid:15)(cid:9)  (cid:9)(cid:9)(cid:2)(cid:1)(cid:20)(cid:9) #(cid:24)  (cid:9) (cid:27)(cid:1)   (cid:10)#
(cid:11)(cid:10) (cid:10) (cid:1) (cid:1) (cid:10) (cid:8)  (cid:21) (cid:1)(cid:6) (cid:1) (cid:1) (cid:10) ,(cid:28)(cid:9)(cid:15) (cid:1) (cid:6) /(cid:24)

(cid:6) (cid:16)(cid:10)(cid:11) (cid:0) (cid:1) (cid:10) (cid:9)(cid:9) (cid:11)(cid:9) (cid:20)(cid:10) 	(cid:9) (cid:10)(cid:2)(cid:5) (cid:10)(cid:15) (cid:10)(cid:2)(cid:5)(cid:6) (cid:6)
(cid:20)(cid:9)(cid:2) (cid:10) (cid:1) (cid:10) (cid:10)  (cid:6) (cid:11)(cid:10)(cid:20)(cid:9) (cid:10) (cid:10)(cid:1)(cid:2)	 (cid:10) # (cid:1) (cid:9)
(cid:1)(cid:9)(cid:9)(cid:10)(cid:1) %2E’ 	 (cid:11)(cid:9)# (cid:2)(cid:9)(cid:15)  (cid:1)	(cid:10)(cid:16)(cid:1)(cid:10) 
	  (cid:10) (cid:2)(cid:10)=

(cid:2)(cid:5)(cid:10)
 (cid:12)
(cid:2)(cid:5)(cid:6)(cid:10) C (cid:10)(cid:2)(cid:5)  (cid:10)(cid:2)(cid:5)(cid:6)  (cid:10)(cid:2)(cid:6)  (cid:12)

(cid:10)(cid:2)(cid:5)

C

3

(cid:27)(cid:11)(cid:9)(cid:9) (cid:12) (cid:10)(cid:15) (cid:12) (cid:10)(cid:9) (cid:2)(cid:10) (cid:1)(cid:15)(cid:9)(cid:9)(cid:15)(cid:9) (cid:6)
(cid:6) (cid:10)(cid:15) (cid:7)(cid:24)

(cid:24)(cid:25)(cid:24)  (cid:23) (cid:29)	(cid:3)  (cid:17)(cid:23) (cid:23)(cid:23)(cid:9)! (cid:30)	(cid:15)(cid:4)

 (cid:11)(cid:1) (cid:9)(cid:2)(cid:1) (cid:27)(cid:9) (cid:9)(cid:20)(cid:1)(cid:9)(cid:27) (cid:11)(cid:9) (cid:14)	(cid:15) (cid:9)(cid:15) (cid:1) %&’(cid:24)
 (cid:15)(cid:9)  (cid:15)(cid:9)(cid:2)(cid:1)(cid:14)(cid:9) (cid:1) (cid:27)(cid:9) (cid:9)(cid:9)(cid:15)  (cid:1)(cid:15)	(cid:2)(cid:9) (cid:9) 	
(cid:10)(cid:1)(cid:24)

(cid:9) (cid:16) (cid:14)(cid:9) (cid:10) (cid:2)  (cid:9)(cid:2)(cid:1) (cid:6) (cid:9)(cid:9) (cid:1) (cid:16)(cid:10)(cid:11) (cid:0) (cid:10)(cid:15) (cid:14)(cid:11) (cid:0) (cid:15) (cid:3) (cid:16)
(cid:14)(cid:9) (cid:9) (cid:15)(cid:1)(cid:1)(cid:14)	(cid:1)  (cid:16) (cid:24) (cid:25)(cid:11)	(cid:16)(cid:11)	 (cid:11)(cid:9) (cid:10)(cid:9) (cid:27)(cid:9)
(cid:10)	(cid:9) (cid:11)(cid:10) (cid:9)(cid:10)(cid:2)(cid:11) (cid:9)(cid:9) (cid:11)(cid:10) (cid:10) 	$(cid:9) (cid:14)(cid:10)(cid:14)(cid:1) (cid:1)# (cid:10)(cid:15)
(cid:9)(cid:10)(cid:2)(cid:11) (cid:9)(cid:15)(cid:16)(cid:9) (cid:1) (cid:2) (cid:1) (cid:2)(cid:20)(cid:9)(cid:9)(cid:15) (cid:14)# (cid:10)  (cid:9)(cid:10) (cid:9) (cid:9)(cid:9)(cid:24)

1 (cid:10) (cid:16)(cid:1)(cid:20)(cid:9) (cid:9)(cid:9) (cid:15) C (cid:1) (cid:11) (cid:0) (cid:2) (cid:11)  (cid:27)(cid:9) (cid:15)(cid:9),(cid:9) (cid:10) (cid:9)

 (cid:11) C (cid:8)7 (cid:6) (cid:5)  (cid:3) (cid:1) (cid:11) (cid:10)(cid:14)(cid:8)7 (cid:6)(cid:7) (cid:5) (cid:0)  (cid:3) (cid:2) (cid:11) (cid:10)(cid:14)(cid:8)(cid:12)(cid:10)

(cid:2)(cid:9)(cid:15)(cid:1)(cid:16)  (cid:11)(cid:9) (cid:1)(cid:15)(cid:9)(cid:28)(cid:9) (cid:10)(cid:2)(cid:1)(cid:10)(cid:9)(cid:15) (cid:27)(cid:1)(cid:11) (cid:20)(cid:9)(cid:1)(cid:2)(cid:9)
(cid:10)(cid:15) (cid:9)(cid:15)(cid:16)(cid:9) (cid:1) (cid:11)(cid:9) (cid:9)(cid:9)(cid:24)

(cid:25) (cid:9)(cid:10)(cid:2)(cid:11) (cid:9)(cid:9) (cid:15) (cid:3) (cid:16)  (cid:27)(cid:9) (cid:10)(cid:2)(cid:1)(cid:10)(cid:9) (cid:10) (cid:9)(cid:9)(cid:16)# (cid:10)(cid:10)(cid:9)(cid:9)
(cid:10)(cid:11) (cid:11)(cid:10) 	 (cid:9)(cid:9)(cid:2) (cid:11)(cid:9) 	(cid:2)	(cid:9) (cid:6) (cid:15) (cid:24) (cid:9) (cid:9)	
(cid:2)(cid:1)(cid:9) # (cid:11)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) (cid:10)(cid:11) 	 (cid:14)(cid:9) (cid:16)  (cid:11)(cid:9) (cid:6)  (cid:27)(cid:1)(cid:16)

 (cid:1)(cid:9)(cid:10) (cid:2)(cid:10)(cid:1) (cid:9)=

(cid:17)(cid:11) C (cid:8)(cid:10)(cid:11) (cid:3) (cid:0)(cid:4) (cid:5) (cid:10)(cid:11)

(cid:3) C E (cid:18) (cid:9) (cid:3)  (cid:11) (cid:10)

/# (cid:2)(cid:2)(cid:10)(cid:9)(cid:10)(cid:1)(cid:16) (cid:10)   (cid:6) (cid:11)(cid:9) (cid:9)(cid:9) (cid:20)(cid:9)(cid:2) (cid:27)(cid:9) (cid:6) (cid:10)
 (cid:10)(cid:16)(cid:9) (cid:20)(cid:9)(cid:2) (cid:1) C (cid:8)(cid:10)(cid:11) (cid:5) (cid:15) (cid:3) (cid:16) (cid:10) (cid:27)(cid:11)(cid:1)(cid:2)(cid:11) (cid:1) (cid:10) (cid:9) (cid:9)(cid:9) (cid:6)
(cid:0)(cid:4)(cid:7)(cid:8) (cid:7)(cid:24) I(cid:9)(cid:2) (cid:1) 	 (cid:14)(cid:9) (cid:16)  (cid:11)(cid:9) (cid:2)(cid:10)(cid:1) (cid:9)

(cid:17) C (cid:8)(cid:1) (cid:3) (cid:0)(cid:4)(cid:7)(cid:8) (cid:7) (cid:5) (cid:10)(cid:11) (cid:3) (cid:17)(cid:11) (cid:6) (cid:10)   (cid:15) (cid:3) (cid:16) (cid:10)

(cid:12)(cid:1)(cid:15)(cid:9) (cid:6)	(cid:2)(cid:1) (cid:12) = (cid:17) (cid:7) (cid:0) (cid:15)(cid:9),(cid:9)(cid:15) (cid:10) (cid:6)  (cid:27)=

(cid:12)(cid:1) C (cid:0)

(cid:14)(cid:11) (cid:10)(cid:11)  C (cid:0)

(cid:11)

(cid:11)

(cid:14)(cid:11) (cid:1)

(cid:0)(cid:0)(cid:4) (cid:1)(cid:10)(cid:11) (cid:0) (cid:0)(cid:20)(cid:2)

%&’ (cid:11)(cid:27) (cid:11)(cid:10) (cid:1)(cid:6) (cid:11) (cid:14)(cid:11) (cid:10)(cid:11) C J(cid:10) (cid:11)(cid:9) (cid:12)(cid:1) (cid:1) (cid:10)  (cid:27)(cid:9)
(cid:14)	(cid:15)  (cid:11)(cid:9) (cid:1)(cid:10)  (cid:20)(cid:10) 	(cid:9) (cid:6) (cid:11)(cid:9) (cid:9)(cid:9)(cid:16)# (cid:6) (cid:20)(cid:9)(cid:2)
J(cid:10) (cid:11)(cid:1) (cid:6)  (cid:27) (cid:6) (cid:9)(cid:9) (cid:1)(cid:9)	(cid:10) (cid:1)#(cid:24) (cid:25) (cid:16)(cid:9) (cid:11)(cid:9)
(cid:1)(cid:16)(cid:11)(cid:9) (cid:14)	(cid:15) (cid:27)(cid:9) (cid:2)(cid:10) (cid:2)(cid:1)(cid:15)(cid:9) (cid:11)(cid:9) (cid:6)  (cid:27)(cid:1)(cid:16) (cid:10)(cid:28)(cid:1)	
(cid:1)$(cid:10)(cid:1) (cid:14) (cid:9)=

(cid:10)(cid:28)

(cid:0)(cid:0)(cid:9)(cid:9)(cid:2) (cid:12)(cid:2) (cid:13)(cid:2) (cid:5) (cid:6)(cid:13)

(cid:12)(cid:1)

4

(cid:9)(cid:9)(cid:1)(cid:16) # (cid:11)(cid:9) (cid:1)(cid:10)  (cid:20)(cid:10) 	(cid:9) (cid:6) (cid:11)(cid:1) (cid:14) (cid:9) (cid:15)(cid:9)
 (cid:15)(cid:9)(cid:9)(cid:15)  (cid:11)(cid:9) (cid:2)(cid:11)(cid:1)(cid:2)(cid:9) (cid:6) (cid:9)(cid:9) %&’(cid:24) : (cid:6) (cid:6) (cid:11)(cid:1)
(cid:6)(cid:10)(cid:2) (cid:2)(cid:10) (cid:14)(cid:9) 	(cid:10)(cid:1)$(cid:9)(cid:15) (cid:10) (cid:6)  (cid:27)(cid:24) (cid:12) (cid:1) (cid:10) (cid:2)(cid:2)(cid:10)(cid:20)(cid:9)
(cid:6)	(cid:2)(cid:1) (cid:6) (cid:1)7 (cid:9)(cid:20)(cid:9) (cid:11)(cid:9) (cid:2)(cid:10)(cid:1) (cid:6) (cid:14) (cid:9) 4
(cid:10)(cid:9)  (cid:1)(cid:9)(cid:10) (cid:1) (cid:1)(cid:24) (cid:25)(cid:11)	 (cid:27)(cid:9) (cid:2)(cid:10) (cid:2)(cid:1)(cid:15)(cid:9) (cid:1) (cid:10)(cid:16)(cid:10)(cid:16)(cid:1)(cid:10)
(cid:15)	(cid:10) (cid:24) (cid:25)(cid:11)(cid:1) (cid:15)	(cid:10)  (cid:14) (cid:9) 	 	  (cid:14)(cid:9) (cid:10) (cid:2)(cid:9)(cid:10)(cid:1)  (cid:1)	
(cid:9)(cid:10) (cid:16)(cid:10)(cid:1)(cid:16) (cid:9) (cid:10)(cid:28)(cid:10)(cid:1) (cid:6) (cid:11)(cid:9) (cid:1)(cid:16)(cid:1)(cid:10)  (cid:1)(cid:1)(cid:1)$(cid:10)	
(cid:1) (cid:14) (cid:9) (cid:10)(cid:15) (cid:15)(cid:9)  (cid:1)(cid:20) (cid:20)(cid:9) (cid:10)# (cid:9)(cid:9)(cid:1)(cid:24)

(cid:18) (cid:19)(cid:20) (cid:19)(cid:19)	(cid:19)(cid:20)(cid:19)(cid:13)(cid:17)(cid:22)(cid:19)(cid:11) (cid:19)(cid:5)(cid:17)(cid:19)

(cid:5)(cid:13)(cid:17) (cid:5) (cid:17)(cid:13)(cid:22)

(cid:10)(cid:28)(cid:1)(cid:1)$(cid:10)(cid:1) (cid:14) (cid:9) 4 (cid:1)(cid:1)(cid:9)(cid:15) (cid:27) (cid:10) (cid:16)(cid:1)(cid:11) (cid:1) %&’
	 (cid:9)(cid:9)	(cid:9)(cid:27)(cid:9)(cid:1)(cid:16)(cid:11)(cid:9)(cid:15) (cid:9)(cid:10)(cid:16)(cid:9) (cid:10)(cid:1)(cid:16) (cid:27)(cid:1)(cid:11) (cid:9)(cid:15)(cid:16)(cid:9) (cid:14)(cid:10)(cid:9)(cid:15) 		
(cid:15)(cid:10)(cid:9) (cid:25)(cid:8) 	- (cid:10)(cid:15) (cid:27)(cid:1)(cid:11) (cid:9)(cid:9) (cid:14)(cid:10)(cid:9)(cid:15) 	(cid:15)(cid:10)(cid:9) (cid:25)(cid:8) 	
(cid:25)(cid:24)  (cid:27)(cid:9)(cid:20)(cid:9) (cid:9)(cid:1)(cid:11)(cid:9) (cid:10) (cid:16)(cid:1)(cid:11) (cid:10)(cid:1)(cid:10)(cid:1) (cid:2)(cid:10)(cid:1)
(cid:11) (cid:14)(cid:11) (cid:10)(cid:11) C J(cid:10) (cid:6) (cid:14) (cid:9) 4(cid:24)
(cid:15)(cid:9)(cid:9)(cid:15) (cid:11)(cid:9)# (cid:9)(cid:6)
(cid:9)(cid:10)(cid:10)(cid:9)(cid:9)(cid:1)$(cid:10)(cid:1) (cid:6) (cid:11)(cid:9) (cid:1)(cid:16)(cid:1)(cid:10)  (cid:10)(cid:10)(cid:9)(cid:9) (cid:20)(cid:9)(cid:2)
 (cid:11)(cid:1) (cid:9)	(cid:10) (cid:1)# (cid:10)# (cid:14)(cid:9)(cid:2)(cid:9) (cid:20)(cid:1) (cid:10)(cid:9)(cid:15)(cid:7)(cid:24) (cid:9) 	 (cid:9) (cid:10)(cid:2)(cid:9)
(cid:1) (cid:27)(cid:1)(cid:11) (cid:11)(cid:9) (cid:2)(cid:10)(cid:1) (cid:11) (cid:14)(cid:11) (cid:10)(cid:11) (cid:15) J(cid:10)(cid:24) (cid:25)(cid:11)	 (cid:27)(cid:9) (cid:10)(cid:9) (cid:27)
(cid:1)(cid:9)(cid:9)(cid:9)(cid:15) (cid:1) (cid:11)(cid:9) (cid:6)  (cid:27)(cid:1)(cid:16) (cid:10)(cid:28)(cid:1)(cid:1)$(cid:10)(cid:1) (cid:14) (cid:9)=

(cid:10)(cid:28)

(cid:0)(cid:0)(cid:9)(cid:9)(cid:2) (cid:12)(cid:2) (cid:13)(cid:2) (cid:10) (cid:6)(cid:13)

(cid:12)(cid:1)

A

(cid:25)(cid:11)(cid:9) (cid:6)  (cid:27)(cid:1)(cid:16)  (cid:9)(cid:10) @	(cid:1),(cid:9) (cid:11)(cid:1) (cid:6)	 (cid:10)(cid:1)(cid:24)

(cid:23)(cid:2) "(cid:25)(cid:26)(cid:25) (cid:25)(cid:13)(cid:1) (cid:7)(cid:8)  (cid:23)(cid:8) 	(cid:1) (cid:21) (cid:19) (cid:1) (cid:26) (cid:1)	(cid:8) 
 (cid:13)(cid:1) (cid:7)(cid:8)  (cid:23)(cid:8) 	(cid:1) (cid:21) (cid:19) (cid:1) (cid:27)(cid:28)

(cid:1)(cid:2)(cid:29)(cid:7) (cid:26)	 (cid:9)(cid:12)(cid:18) (cid:24)(cid:12) (cid:18)	(cid:9) (cid:14)(cid:30) (cid:24)(cid:12)(cid:12) (cid:26) (cid:24)(cid:12) (cid:16)(cid:9)(cid:12) (cid:31)(cid:24)(cid:12)
(cid:12)(cid:12) (cid:14) (cid:0) (cid:9)(cid:12) (cid:7)(cid:6)(cid:15)(cid:19)  (cid:31)(cid:12)(cid:28)(cid:12) (cid:24)(cid:12)(cid:14) (cid:26) (cid:12)(cid:28)(cid:12) 	(cid:12)
(cid:24)(cid:14) (cid:9)	(cid:14)(cid:19)  (cid:24)(cid:14) (cid:9)(cid:12) (cid:31)(cid:12) (cid:18)  (cid:9)	(cid:12) (cid:24)(cid:9) (cid:12)(cid:12)
(cid:9)(cid:12) (cid:9)(cid:14)(cid:27)(cid:19)

(cid:2)(cid:12) (cid:24)(cid:9)  (cid:12)(cid:9) " (cid:9)(cid:18) (cid:5)(cid:5) (cid:14) (cid:2)(cid:29)(cid:7) (cid:12)(cid:12)  (cid:16)(cid:9)(cid:14) (cid:9)
(cid:14)(cid:9)#(cid:12)(cid:19) (cid:12)(cid:9) (cid:5)(cid:5) (cid:26) (cid:12)%(cid:9) (cid:12) (cid:9)(cid:30) (cid:24)(cid:9) &’(cid:20)	& (cid:9) (cid:27)	
(cid:14)(cid:24) (cid:9)(cid:14)(cid:9)(cid:14) (cid:24)(cid:12) (cid:12)(cid:30) (cid:0) (cid:1)(cid:0) (cid:0)(cid:0) ) *(cid:0)(cid:19)  (cid:31)(cid:12)(cid:28)(cid:12) (cid:24)(cid:12)
(cid:26) (cid:18)(cid:12)  (cid:9)#(cid:12) (cid:14) (cid:9)(cid:16)(cid:16)	 (cid:12)(cid:9)(cid:9)(cid:12)(cid:12)(cid:14)(cid:25)(cid:9)(cid:14) (cid:12)(cid:19)

184(cid:21)(cid:28) 5(cid:9)(cid:9) %A’(cid:24) (cid:25)(cid:11)(cid:9) (cid:6) (cid:1)(cid:20) (cid:20)(cid:9) (cid:11)(cid:27)(cid:1)(cid:16) (cid:11)(cid:10) (cid:10)#
(cid:9)(cid:10)(cid:10)(cid:9)(cid:9)(cid:1)$(cid:10)(cid:1) (cid:2)(cid:10) (cid:14)(cid:9) (cid:9)(cid:28)(cid:9)(cid:9)(cid:15) (cid:20)(cid:1)(cid:10) (cid:9)(cid:10)(cid:16)(cid:9)(cid:24) 
(cid:1) (cid:1)(cid:9)(cid:15) (cid:15)	(cid:9)  (cid:10)(cid:2)(cid:9)  (cid:1)(cid:1)(cid:10)(cid:1)(cid:24)

: (cid:11)(cid:27) (cid:1) %&’ (cid:25)(cid:8) 	- (cid:10)(cid:15) (cid:25)(cid:8) 	(cid:25) (cid:10) (cid:16)(cid:1)(cid:11) (cid:10)(cid:1)	
(cid:10)(cid:1) (cid:11)(cid:9) (cid:2)(cid:10)(cid:1) (cid:6) (cid:14) (cid:9) A(cid:24) (cid:18)(cid:6)	(cid:10)(cid:9) # (cid:11)(cid:9)#
(cid:15)  (cid:16)	(cid:10)(cid:10)(cid:9)(cid:9) (cid:11)(cid:10) (cid:11)(cid:9) (cid:14)@(cid:9)(cid:2)(cid:1)(cid:20)(cid:9) (cid:6)	(cid:2)(cid:1) (cid:12) 	
(cid:1)(cid:2)(cid:10)  # (cid:1)(cid:2)(cid:9)(cid:10)(cid:9) 	 (cid:1) 	 (cid:9)(cid:28)(cid:9)(cid:1)(cid:9) (cid:27)(cid:9) (cid:11)(cid:10)(cid:20)(cid:9) (cid:14)	
(cid:9)(cid:20)(cid:9)(cid:15) (cid:11)(cid:10) (cid:9)(cid:1)(cid:9) (cid:1) (cid:16)(cid:9) (cid:15)(cid:27)(cid:24)  (cid:6)(cid:10)(cid:2) (cid:27)(cid:11)(cid:9) (cid:11)(cid:9)
(cid:10) (cid:16)(cid:1)(cid:11) (cid:6)(cid:10)(cid:1) (cid:9)(cid:15)  (cid:2)(cid:20)(cid:9)(cid:16)(cid:9) (cid:11)(cid:9) (cid:20)(cid:10) 	(cid:9) (cid:6) (cid:12)(cid:1) (cid:6)(cid:9)
(cid:11)(cid:10)(cid:15) (cid:16)(cid:9) (cid:1) (cid:10)  (cid:24) (cid:9)(cid:28) (cid:27)(cid:9) (cid:15)(cid:9)(cid:1)(cid:16) (cid:10) (cid:9)(cid:27) (cid:10) (cid:16)(cid:1)(cid:11)
(cid:27)(cid:1)(cid:11) (cid:11)(cid:9) (cid:9)# (cid:11)(cid:10) (cid:12) (cid:9)(cid:20)(cid:9) (cid:15)(cid:9)(cid:2)(cid:9)(cid:10)(cid:9)(cid:24)

	 (cid:10) (cid:16)(cid:1)(cid:11) (cid:1) (cid:11)(cid:27) (cid:1) 1(cid:1)(cid:16)(cid:24) 2(cid:24) (cid:18) (cid:1)(cid:22)(cid:9) (cid:25)(cid:8) 	- (cid:10)(cid:15)
(cid:25)(cid:8) 	(cid:25) (cid:10) (cid:16)(cid:1)(cid:11) (cid:27)(cid:11)(cid:1)(cid:2)(cid:11) 	(cid:9) (cid:10)(cid:10)  (cid:9)  	(cid:15)(cid:10)(cid:9) (cid:27)(cid:9) 		
(cid:15)(cid:10)(cid:9) (cid:20)(cid:9)(cid:2) (cid:8)(cid:10)(cid:11) (cid:10) (cid:9)	(cid:9)(cid:1)(cid:10)  #(cid:24) (cid:25)(cid:11)(cid:9)(cid:9)(cid:6)(cid:9) (cid:27)(cid:9) (cid:2)(cid:10)   	
(cid:10) (cid:16)(cid:1)(cid:11) .(cid:9)	(cid:9)(cid:1)(cid:10)  (cid:9)(cid:9)	(cid:9)(cid:27)(cid:9)(cid:1)(cid:16)(cid:11)(cid:9)(cid:15) (cid:9)(cid:10)(cid:16)(cid:9) (cid:10)	
(cid:1)(cid:16)0 (cid:25)(cid:8) 	5(cid:24)

(cid:8)(cid:9)(cid:10)(cid:10)(cid:9)(cid:9)(cid:1)$(cid:10)(cid:1) (cid:9) 2(cid:10) (cid:2)(cid:10) (cid:14)(cid:9) (cid:1) (cid:9)(cid:9)(cid:9)(cid:15) (cid:1)
(cid:10)# (cid:15)(cid:1)<(cid:9)(cid:9) (cid:27)(cid:10)#(cid:24) (cid:9) (cid:1)(cid:14)(cid:1) (cid:1)# (cid:1)  (cid:2)(cid:20)(cid:9) (cid:20)(cid:9)(cid:2)	
 (cid:10)(cid:11)  (cid:10)  (cid:6) # 	(cid:1)(cid:16) (cid:11)(cid:9) (cid:15)(cid:1)(cid:10)# (cid:10)(cid:28)	
(cid:15)	(cid:2) /(cid:8)(cid:24)  (cid:27)(cid:9)(cid:20)(cid:9) (cid:11)(cid:1) (cid:27)	 (cid:15) (cid:14)(cid:9) (cid:20)(cid:9)# (cid:9)(cid:28)(cid:9)(cid:1)(cid:20)(cid:9) (cid:1)(cid:6)
(cid:9)(cid:9) (cid:10)(cid:9)  (cid:10)(cid:16)(cid:9)(cid:24) : (cid:9) (cid:9)Æ(cid:2)(cid:1)(cid:9) (cid:9)(cid:2)(cid:11)(cid:1)	(cid:9) (cid:1) (cid:15)(cid:1)(cid:2)	(cid:9)(cid:15)
(cid:1) (cid:9)(cid:2)(cid:1) 4(cid:24)4(cid:24)

"(cid:25)(cid:26) #(cid:23)(cid:2)$ (cid:23)(cid:23) (cid:2)(cid:9)(cid:23)(cid:23)(cid:23)

(cid:25)(cid:11)(cid:9) (cid:10) (cid:16)(cid:1)(cid:11) (cid:1) 1(cid:1)(cid:16)(cid:24) 2 (cid:15)(cid:9)  (cid:9)(cid:2)(cid:1)(cid:6)# (cid:27)(cid:11)(cid:10) (cid:11)(cid:9) 	
(cid:1)(cid:16) (cid:2)(cid:1)(cid:9)(cid:1) (cid:1)(cid:24)
 (cid:11)(cid:1) (cid:9)(cid:2)(cid:1) (cid:27)(cid:9) (cid:10)(cid:15)(cid:15)(cid:9) (cid:11)(cid:1) (cid:1)	
	(cid:9) (cid:14)# (cid:16)(cid:1)(cid:20)(cid:1)(cid:16) (cid:11)(cid:1)(cid:8)(cid:17) (cid:1)(cid:1) (cid:8)(cid:12)(cid:1)(cid:1)(cid:1) (cid:2)(cid:15)(cid:1)(cid:1)  (cid:25):(cid:24)
(cid:10)(cid:9) (cid:27)(cid:9) (cid:27)(cid:1)   (cid:11)(cid:27) (cid:11)(cid:10) (cid:1) (cid:2)(cid:11)(cid:10)(cid:10)(cid:2)(cid:9)(cid:1)$(cid:9)  (cid:2)(cid:10)  (cid:10)(cid:28)(cid:1)(cid:10)
(cid:6) (cid:11)(cid:9) (cid:10) (cid:16)(cid:1)(cid:11) (cid:27)(cid:1)(cid:11) (cid:9)(cid:9)(cid:2)  (cid:6)	(cid:2)(cid:1) (cid:12)(cid:24) (cid:9)
(cid:9)(cid:2)(cid:1)(cid:9) # (cid:27)(cid:9) (cid:27)(cid:1)   (cid:20)(cid:9) (cid:11)(cid:10) (cid:11)(cid:9) (cid:10) (cid:16)(cid:1)(cid:11) (cid:11)(cid:10) (cid:10) 	(cid:14)	
(cid:9)	(cid:9)(cid:2)(cid:9) (cid:2)(cid:20)(cid:9)(cid:16)(cid:1)(cid:16)  (cid:10) (cid:20)(cid:9)(cid:2) (cid:10)(cid:1)(cid:6)#(cid:1)(cid:16)  (cid:25): (cid:2)	
(cid:15)(cid:1)(cid:1)(cid:24) (cid:9)(cid:20)(cid:9) (cid:1)(cid:6) (cid:10) (cid:20)(cid:9)(cid:2) (cid:10)(cid:1),(cid:9) (cid:11)(cid:9)(cid:9) (cid:2)(cid:15)(cid:1)(cid:1)
(cid:11)(cid:9) (cid:11)(cid:9) (cid:10) (cid:16)(cid:1)(cid:11) (cid:27)(cid:1)    (cid:10)(cid:22)(cid:9) (cid:10)# (cid:16)(cid:9) (cid:1)(cid:24)(cid:9)(cid:24) (cid:1)
(cid:27)(cid:1)    (cid:1)(cid:2)(cid:9)(cid:10)(cid:9) (cid:6)	(cid:2)(cid:1) (cid:12)(cid:24)

 (cid:15)(cid:9)  (cid:15)(cid:9),(cid:9) (cid:11)(cid:1) (cid:2)(cid:15)(cid:1)(cid:1) (cid:1) (cid:1) (cid:2)(cid:20)(cid:9)(cid:1)(cid:9) 
(cid:1)(cid:15)	(cid:2)(cid:9) (cid:9) (cid:10)(cid:1)(cid:24) (cid:9) (cid:25)(cid:11) (cid:10)(cid:11)  (cid:14)(cid:9) (cid:11)(cid:9) (cid:9) (cid:6)
(cid:1)(cid:10)  (cid:2),(cid:16)	(cid:10)(cid:1) (cid:6) (cid:10)(cid:10)(cid:9)(cid:9) (cid:10)(cid:11) (cid:24) (cid:9) (cid:25)(cid:1)
(cid:14)(cid:9) (cid:11)(cid:9) (cid:2)  (cid:9)(cid:2)(cid:1) (cid:8)(cid:25)(cid:11) (cid:10)(cid:11)  (cid:5) (cid:15) (cid:3) (cid:16) (cid:10) (cid:6) (cid:11)(cid:9) (cid:9) (cid:6)
(cid:1)(cid:10)  (cid:2),(cid:16)	(cid:10)(cid:1) (cid:6) (cid:20)(cid:9)(cid:2) (cid:10)(cid:11) (cid:24)
 (cid:14)(cid:9) (cid:16) 
(cid:11)(cid:9) (cid:9) 3(cid:4) (cid:7)(cid:8) (cid:7) C 3(cid:4)  (cid:4) (cid:4) (cid:4)  3(cid:4) (cid:5)(cid:16) (cid:5) (cid:1)(cid:9)(cid:24) 1 (cid:27)
(cid:2)  (cid:9)(cid:2)(cid:1) (cid:1)(cid:0) L(cid:1) (cid:3) 3(cid:4) (cid:7)(cid:8) (cid:7) (cid:27)(cid:9) (cid:27)(cid:1)   (cid:27)(cid:1)(cid:9) (cid:1) (cid:20) L(cid:1) (cid:1)(cid:6) (cid:1)(cid:11) (cid:20)
L(cid:1)(cid:11) (cid:6) (cid:10)# (cid:9)(cid:9) (cid:15) (cid:24)

E(cid:24) (cid:1)(cid:1)(cid:10) (cid:1)$(cid:9) (cid:1)  (cid:11)(cid:10) (cid:1) (cid:3) (cid:17) (cid:10)(cid:15) (cid:11) (cid:14)(cid:11) (cid:10)(cid:11) (cid:15) J(cid:10)(cid:24)
2(cid:24) 5(cid:9) (cid:9)(cid:2) (cid:9) (cid:15)(cid:9) (cid:6) (cid:15)(cid:9) (cid:10)(cid:15) (cid:9)(cid:15)(cid:16)(cid:9) (cid:1) (cid:1) (cid:14) (cid:2)(cid:24)
1 (cid:9)(cid:10)(cid:2)(cid:11) (cid:9) (cid:9)(cid:9) (cid:16) (cid:3) (cid:1) (cid:14) (cid:2) ,(cid:15) (cid:10)   (cid:9)(cid:9) (cid:16)(cid:14) (cid:20) (cid:16)
(cid:2)(cid:10)(cid:1)(cid:1)(cid:16) (cid:16)(cid:24) (cid:6) (cid:11)(cid:9)(cid:9) (cid:1) (cid:9) (cid:11)(cid:10) (cid:9) (cid:9)(cid:9) (cid:11)(cid:9)
(cid:15) (cid:11)(cid:9) (cid:6)  (cid:27)(cid:1)(cid:16)=

(cid:10) 1 (cid:10)   (cid:9)(cid:9) (cid:15) (cid:3) (cid:16)(cid:14) (cid:9)(cid:10)(cid:10)(cid:9)(cid:9)(cid:1)$(cid:9) (cid:10)(cid:11) 	(cid:2)(cid:11)
(cid:2)(cid:5) 
(cid:2)(cid:6) (cid:1)(cid:6) (cid:16) C (cid:0)  (cid:1) (cid:10) (cid:9)(cid:15)(cid:16)(cid:9) (cid:16)(cid:1)(cid:20)(cid:9) (cid:2)(cid:9)(cid:2)

(cid:11)(cid:10) (cid:20)(cid:10) 	(cid:9) (cid:10)(cid:11)
(cid:10)(cid:11)
(cid:2)(cid:5)(cid:6) (cid:10)(cid:11)
(cid:1)	(cid:10)(cid:16)(cid:1)(cid:10)  (cid:6) (cid:9)(cid:9) (cid:15) (cid:10) (cid:1) (cid:6)	 (cid:10) 3(cid:24)

(cid:2)(cid:5) (cid:1)(cid:6) (cid:16) C  (cid:1) (cid:10) (cid:15)(cid:9)  (cid:10)(cid:11)

(cid:14) .:(cid:20)(cid:9)(cid:10)(cid:16)(cid:1)(cid:16)0 (cid:9)(cid:10)(cid:1)=

(cid:6) (cid:16) C  (cid:1) (cid:10) (cid:15)(cid:9) (cid:1) (cid:1) (cid:11)(cid:9)
	 (cid:12)	(cid:9) L(cid:10) C (cid:0)
(cid:12) (cid:11) (cid:0)(cid:8)
	 5(cid:9) (cid:10)(cid:11)

(cid:14)(cid:11) (cid:10)(cid:11)

 =C L(cid:10) (cid:6) (cid:9)(cid:9) (cid:15) (cid:3) (cid:16)
(cid:6) (cid:16) C (cid:0)  (cid:1) (cid:10) (cid:9)(cid:15)(cid:16)(cid:9) (cid:1) (cid:2) (cid:11)(cid:9)

	 (cid:12)	(cid:9)

L(cid:17)(cid:2)(cid:5)(cid:6) C

2
(cid:14)

(cid:0)

(cid:11) (cid:0)(cid:8)

(cid:14)(cid:11) (cid:10)(cid:11)

(cid:2)(cid:5)  (cid:10)(cid:11)

(cid:2)(cid:5)(cid:6)  (cid:10)(cid:11)

(cid:2)(cid:6)

	 5(cid:9) (cid:10)(cid:11)

  (cid:10)(cid:11)

 (cid:10)(cid:11)


(cid:6) (cid:9)(cid:9) (cid:15) (cid:3) (cid:16)  (cid:11)(cid:10)

(cid:10)(cid:11)
(cid:2)(cid:5)  (cid:10)(cid:11)

(cid:2)(cid:5)(cid:6)  (cid:10)(cid:11)

(cid:2)(cid:6) C L(cid:17)(cid:2)(cid:5)(cid:6)

3(cid:24) (cid:12)(cid:11)(cid:9)(cid:2)(cid:22) (cid:27)(cid:11)(cid:9)(cid:11)(cid:9) (cid:10) (cid:1)(cid:16) (cid:2)(cid:1)(cid:9)(cid:1) (cid:1) (cid:10)(cid:1),(cid:9)(cid:15)7

(cid:1)(cid:6) #(cid:9) (cid:9)(cid:1)(cid:10)(cid:9) (cid:11)(cid:9)(cid:27)(cid:1)(cid:9) (cid:16)  (cid:9) 2(cid:24)

1(cid:1)(cid:16)	(cid:9) 2= (cid:11)(cid:23)	(cid:23)(cid:4)(cid:2)  (cid:23)(cid:23)	(cid:23) (cid:23)(cid:4)(cid:9)(cid:17)(cid:23)(cid:3) (cid:2) (cid:9)(cid:4)(cid:17)
’(cid:27)#	(cid:11)(cid:25)

(cid:14) (cid:6) (cid:15)(cid:9)  (cid:1) (cid:2)(cid:10)(cid:1)(cid:9)(cid:15) (cid:1) (cid:9)(cid:9) (cid:15) (cid:10)(cid:15) (cid:15) (cid:5) (cid:11)(cid:9) (cid:6)
(cid:10)# (cid:2),(cid:16)	(cid:10)(cid:1) (cid:20)(cid:11) (cid:3) (cid:1)(cid:11) (cid:11)(cid:9)(cid:9) (cid:9)(cid:28)(cid:1) (cid:2),(cid:16)	(cid:10)	
(cid:1) (cid:20)(cid:11) (cid:0)
(cid:27)(cid:11)(cid:1)(cid:2)(cid:11) (cid:10)(cid:16)(cid:9)(cid:9) (cid:27)(cid:1)(cid:11) (cid:20)(cid:11)  (cid:15)(cid:9) 
(cid:1)(cid:24)(cid:9)(cid:24) (cid:2)(cid:11)

(cid:3) (cid:1)(cid:11) (cid:0)
 C (cid:2)(cid:11) (cid:0)
 (cid:24)

(cid:2) (cid:6) (cid:9)(cid:15)(cid:16)(cid:9) (cid:0)  (cid:1) (cid:2)(cid:10)(cid:1)(cid:9)(cid:15) (cid:1) (cid:9)(cid:9) (cid:15) (cid:10)(cid:15) (cid:15) (cid:5) (cid:11)(cid:9)
(cid:6) (cid:10)# (cid:2),(cid:16)	(cid:10)(cid:1) (cid:20)(cid:11) (cid:3) (cid:1)(cid:11) (cid:11)(cid:9)(cid:9) (cid:9)(cid:28)(cid:1) (cid:2),(cid:16)	
	(cid:10)(cid:1) (cid:20)(cid:11) (cid:0)
(cid:27)(cid:11)(cid:1)(cid:2)(cid:11) (cid:10)(cid:16)(cid:9)(cid:9) (cid:27)(cid:1)(cid:11) (cid:20)(cid:11)  (cid:15)(cid:9)
 (cid:10)(cid:15)  (cid:1)(cid:24)(cid:9)(cid:24) (cid:2)(cid:11)
  (cid:2)(cid:11)

 C (cid:2)(cid:11) (cid:0)

 C (cid:2)(cid:11) (cid:0)

(cid:3) (cid:1)(cid:11) (cid:0)

(cid:24)



(cid:27) (cid:27)(cid:9) (cid:2)(cid:10) (cid:15)(cid:9),(cid:9)  (cid:25): (cid:2)(cid:15)(cid:1)(cid:1)(cid:24)
)(cid:23)*(cid:4)(cid:4) "(cid:25)(cid:24)(cid:25) (cid:30)(cid:1)(cid:20) (cid:1) C (cid:8)(cid:10)(cid:11) (cid:10) (cid:3) (cid:17) (cid:7) (cid:8)(cid:7)(cid:14)  (cid:8)	
(cid:7)(cid:21)(cid:22) (cid:13)(cid:1) (cid:27)(cid:9)(cid:10)(cid:22) (cid:9)(cid:9) (cid:10)(cid:16)(cid:9)(cid:9)(cid:9) (cid:20)(cid:14)(cid:7)(cid:7) (cid:7)(cid:21) (cid:13)(cid:1)(cid:1) (cid:1)(cid:31)(cid:7)
(cid:20)  (cid:1)(cid:20)(cid:7) (cid:1) (cid:20) (cid:25)(cid:1) (cid:11)(cid:13)(cid:7)(cid:20)(cid:13) (cid:7) (cid:20)(cid:7)(cid:1)(cid:28)

(cid:12)(cid:1)(cid:15)(cid:9) (cid:9) (cid:2)  (cid:9)(cid:2)(cid:1) (cid:6) (cid:9) (cid:6) (cid:2),(cid:16)	(cid:10)(cid:1) (cid:1) C
(cid:8)(cid:1)(cid:11)(cid:10) (cid:3) 3(cid:4) (cid:7)(cid:8) (cid:7)(cid:24)  (cid:9) (cid:10)# (cid:11)(cid:10) (cid:1) (cid:1) (cid:20)(cid:7)(cid:1) (cid:1)(cid:6) (cid:1) (cid:10)(cid:1)	
,(cid:9) (cid:11)(cid:9) (cid:6)  (cid:27)(cid:1)(cid:16) (cid:11)(cid:9)(cid:9) (cid:2)(cid:15)(cid:1)(cid:1)=

(cid:9) (cid:11)(cid:10) (cid:1) (cid:2)(cid:10) (cid:14)(cid:9) (cid:20)(cid:1)(cid:9)(cid:27)(cid:9)(cid:15) (cid:10) (cid:10) (cid:16)(cid:9)(cid:9)(cid:10) (cid:1)$(cid:10)(cid:1) (cid:6) (cid:11)(cid:9)
(cid:1)(cid:1) (cid:8)(cid:12)(cid:1)(cid:1)(cid:1) (cid:2)(cid:15)(cid:1)(cid:1) (cid:1)(cid:15)	(cid:2)(cid:9)(cid:15) (cid:1) %&’= (cid:20)(cid:9)(cid:2) (cid:10)	
(cid:1)(cid:6)#(cid:1)(cid:16) (cid:9)(cid:9) (cid:10)(cid:16)(cid:9)(cid:9)(cid:9) (cid:10)  (cid:10)(cid:1)(cid:6)#  (cid:25): (cid:2)(cid:15)(cid:1)(cid:1)(cid:24)

(cid:10) 1 (cid:10)# (cid:9)(cid:9) (cid:15) (cid:9) (cid:1)(cid:11) (cid:1) 	(cid:9)#(cid:24)

(cid:3)(cid:20)(cid:14)(cid:24) (cid:24)(cid:14) (cid:16)(cid:24)(cid:12)(cid:12) (cid:9) (cid:16)(cid:12)(cid:16)(cid:14)  &’(cid:20)	& (cid:9) (cid:27)(cid:14)(cid:24)
(cid:14) (cid:12) (cid:9)(cid:9)(cid:12)(cid:19) +(cid:9)(cid:14)(cid:16)(cid:9)  (cid:30) &’(cid:20)	& (cid:14)(cid:12)(cid:9)(cid:12) ,(cid:12)(cid:31)(cid:12)(cid:12) (cid:31)
(cid:24)(cid:9)(cid:12)- (cid:9) 	(cid:14)(cid:27) (cid:9)%	(cid:18)	(cid:16) + (cid:26) (cid:7)   (cid:12)(cid:12) (cid:9)(cid:18) ,
(cid:12)(cid:26)(cid:14)(cid:27) (cid:9)(cid:28)(cid:12)(cid:9)(cid:27)(cid:14)(cid:27) (cid:12)(cid:9)(cid:14) (cid:26) (cid:7)   (cid:18)(cid:12) (cid:9)(cid:18) (cid:12)(cid:18)(cid:27)(cid:12)(cid:19)

:  (cid:9) (cid:11)(cid:10)  (cid:25): (cid:2)(cid:15)(cid:1)(cid:1) (cid:1) (cid:15)(cid:1)<(cid:9)(cid:9) (cid:6) (cid:11)(cid:9)
!(cid:31)(cid:1)(cid:14) (cid:7) (cid:2)(cid:15)(cid:1)(cid:1) (cid:6) (cid:25)(cid:8)  (cid:10) (cid:16)(cid:1)(cid:11)(cid:24) (cid:25)(cid:11)(cid:9)  (cid:10)(cid:9)
(cid:9)(cid:10) (cid:11)(cid:10) (cid:10)# (cid:9) (cid:6) (cid:11)(cid:9) (cid:10) (cid:16)(cid:1)(cid:11) (cid:15)(cid:9)  (cid:2)(cid:11)(cid:10)(cid:16)(cid:9)
(cid:20)(cid:9)(cid:2) (cid:1)(cid:24) (cid:25)(cid:11)(cid:1) (cid:1) 	 (cid:1) (cid:1)(cid:9) (cid:11)(cid:10) (cid:10)   (cid:20)(cid:9)(cid:2) (cid:10)(cid:11) (cid:10)(cid:9)
(cid:1) (cid:10) (cid:10)  (cid:6) (cid:10)(cid:15) (cid:10)(cid:11)
(cid:14) (cid:6) (cid:9)(cid:20)(cid:9)# (cid:9) (cid:9)(cid:9) (cid:16) (cid:3)
(cid:1) (cid:14) (cid:2) (cid:10)(cid:15) (cid:6) (cid:9)(cid:20)(cid:9)# (cid:10)(cid:1) (cid:6) (cid:9)(cid:9) (cid:15)(cid:0) (cid:15) (cid:5) (cid:3) (cid:16)(cid:14)(cid:24)  (cid:1) (cid:9)(cid:10)#

(cid:14) C (cid:10)(cid:11) (cid:0)

185 (cid:9)(cid:9) (cid:11)(cid:10) (cid:9)(cid:20)(cid:9)# ,(cid:28)(cid:9)(cid:15) (cid:1) (cid:6) (cid:25)(cid:8)  (cid:10)(cid:1),(cid:9)  (cid:25):
(cid:2)(cid:15)(cid:1)(cid:1) (cid:14)	  (cid:11)(cid:9) (cid:11)(cid:9) (cid:27)(cid:10)# (cid:10)	(cid:15)(cid:24)

"(cid:25)(cid:24) +(cid:2) !(cid:4) (cid:30) (cid:17)(cid:23) (cid:2) (cid:9)(cid:4)(cid:17)

1(cid:1) (cid:27)(cid:9) (cid:11)(cid:27) (cid:11)(cid:10) (cid:1)(cid:1) (cid:10) #  (cid:25)(cid:8) 	(cid:25) (cid:10) (cid:16)(cid:1)(cid:11)
(cid:25)(cid:8) 	5 (cid:10)(cid:1)(cid:10)(cid:1) (cid:11)(cid:9) (cid:2)(cid:10)(cid:1) (cid:6) (cid:14) (cid:9) A(cid:24)
(cid:23)(cid:2) "(cid:25)"(cid:25) (cid:25)"#	$ (cid:8) (cid:12)(cid:7)(cid:13) (cid:1)(cid:21) (cid:1)(cid:8)(cid:8)(cid:1)	
(cid:1)(cid:7)(cid:24)(cid:8)(cid:7) (cid:21) (cid:13)(cid:1) (cid:7)(cid:12)(cid:7)(cid:8)  (cid:8)(cid:8)(cid:1)(cid:1) (cid:23)(cid:1)(cid:20) J(cid:10) (cid:7)(cid:28)(cid:1)(cid:28)
(cid:7)
(cid:8)(cid:7)(cid:8)(cid:7) (cid:13)(cid:1) (cid:1)(cid:22) (cid:11) (cid:14)(cid:11) (cid:10)(cid:11) (cid:15) J(cid:10)(cid:28)
(cid:25)(cid:11)(cid:1)  (cid:9)(cid:10) (cid:6)  (cid:27) (cid:15)(cid:1)(cid:9)(cid:2) # (cid:6) (cid:11)(cid:9) (cid:10) (cid:16)(cid:1)(cid:11) (cid:2)	
	(cid:2)(cid:1)7 (cid:9)(cid:9) %A’ (cid:6) (cid:15)(cid:9)(cid:10)(cid:1) (cid:24)

(cid:9)(cid:28) (cid:27)(cid:9) (cid:10)(cid:10) #$(cid:9) (cid:11)(cid:9) (cid:14)(cid:9)(cid:11)(cid:10)(cid:20)(cid:1)	 (cid:6) (cid:14)@(cid:9)(cid:2)(cid:1)(cid:20)(cid:9) (cid:6)	(cid:2)(cid:1) (cid:12)
(cid:15)	(cid:1)(cid:16) (cid:11)(cid:9) (cid:10) (cid:16)(cid:1)(cid:11)(cid:24) (cid:25) (cid:14)(cid:9) (cid:9)(cid:2)(cid:1),(cid:2) (cid:27)(cid:9) (cid:10)	(cid:9) (cid:6)
(cid:11)(cid:9) (cid:9) (cid:6) (cid:11)(cid:1) (cid:9)(cid:2)(cid:1) (cid:11)(cid:10) (cid:10)(cid:6)(cid:9) (cid:9)(cid:10)(cid:10)(cid:9)(cid:9)(cid:1)$(cid:10)(cid:1)
(cid:9) 2(cid:10) (cid:27)(cid:9) (cid:11)(cid:10)(cid:20)(cid:9) (cid:1)(cid:5) (cid:8)(cid:10)(cid:11)
(cid:2)(cid:5)(cid:10) C E (cid:1)(cid:6) (cid:16) C  (cid:1) (cid:10) (cid:15)(cid:9)
(cid:2)(cid:5)(cid:6)  (cid:10)(cid:11)
 (cid:1)(cid:5)(cid:9)(cid:6) (cid:8)(cid:10)(cid:11)
(cid:2)(cid:6)(cid:10) C E (cid:1)(cid:6) (cid:16) C (cid:0)  (cid:1) (cid:10)
(cid:9)(cid:15)(cid:16)(cid:9)(cid:24) (cid:25)(cid:11)(cid:1) (cid:10)	(cid:1) (cid:1)  (cid:9)(cid:9)(cid:1)(cid:10)  (cid:11)(cid:27)(cid:9)(cid:20)(cid:9)7 (cid:11)(cid:9)
(cid:14)(cid:9)(cid:11)(cid:10)(cid:20)(cid:1)	 (cid:6) (cid:11)(cid:9) (cid:10) (cid:16)(cid:1)(cid:11) (cid:27)(cid:1)   (cid:14)(cid:9) (cid:11)(cid:9) (cid:10)(cid:9) (cid:6) (cid:10)#
(cid:11)(cid:9) (cid:10) (cid:1)$(cid:10)(cid:1)(cid:24)
’(cid:17)(cid:23)(cid:23) "(cid:25),(cid:25) (cid:8) ((cid:21)(cid:1) (cid:8)(cid:22) 	(cid:19)(cid:1) (cid:21) (cid:1) (cid:21)	(cid:20)	

(cid:2)(cid:5)  (cid:10)(cid:11)

(cid:7)  (cid:8)(cid:14) (cid:12) (cid:14)  (cid:14)(cid:1)(cid:20)(cid:1)(cid:8)(cid:1)(cid:28)

: (cid:10) (cid:1)(cid:9)(cid:15)(cid:1)(cid:10)(cid:9) (cid:2)(cid:9)	(cid:9)(cid:2)(cid:9) (cid:6) (cid:11)(cid:9)(cid:9) 4(cid:24)A(cid:14) (cid:27)(cid:9) (cid:16)(cid:9)
(cid:11)(cid:9) (cid:6)  (cid:27)(cid:1)(cid:16) (cid:9)	 =
-  (cid:2)! "(cid:25).(cid:25) (cid:21) (cid:23)(cid:1)(cid:20) (cid:1) (cid:8)(cid:31)(cid:7)(cid:7)(cid:24)(cid:1) (cid:19) (cid:1) (cid:26) (cid:13)(cid:1)
(cid:1) (cid:8)(cid:7)!(cid:1) #(cid:25)( (cid:20)(cid:14)(cid:7)(cid:7)(cid:28)

(cid:18)(cid:6)	(cid:10)(cid:9) # (cid:11)(cid:9) (cid:2)(cid:20)(cid:9)(cid:9) (cid:1)  (cid:9)(cid:2)(cid:9)(cid:10)(cid:1) # 	(cid:9) (cid:10)
(cid:9)(cid:28)(cid:10) (cid:9) (cid:1) %A’ (cid:15)(cid:9)(cid:10)(cid:9)(cid:24)

1(cid:1)(cid:10)  # (cid:27)(cid:9) (cid:16)(cid:1)(cid:20)(cid:9) (cid:11)(cid:9) (cid:2)(cid:20)(cid:9)(cid:16)(cid:9)(cid:2)(cid:9) (cid:11)(cid:9)(cid:9)(cid:24) : (cid:6) (cid:1)
(cid:16)(cid:1)(cid:20)(cid:9) (cid:1) %A’7 (cid:11)(cid:9)(cid:9) (cid:27)(cid:9) (cid:1) (cid:1) (cid:15)	(cid:9)  (cid:10)(cid:2)(cid:9)  (cid:1)(cid:1)(cid:10)(cid:1)(cid:24)
’(cid:17)(cid:23)(cid:23) "(cid:25)/(cid:25) (cid:1) (cid:8)(cid:1)(cid:15)(cid:10)(cid:15) (cid:19)(cid:1) (cid:8) (cid:7)!(cid:7)(cid:1) (cid:1)	(cid:1)(cid:20)(cid:1) (cid:21)
(cid:23)(cid:1)(cid:20) (cid:19)(cid:8)(cid:7)(cid:1)(cid:14) (cid:19)(cid:22) (cid:8) (cid:22)(cid:7)(cid:12) (cid:1) , (cid:21) (cid:25)"#	$ (cid:8) (cid:12)	
(cid:7)(cid:13)(cid:28) (cid:25)(cid:13)(cid:1) (cid:13)(cid:1)(cid:1) (cid:1)(cid:31)(cid:7) (cid:8) 	(cid:19)(cid:1)	(cid:1)(cid:20)(cid:1) (cid:8)(cid:1)(cid:15)(cid:10)
	(cid:20)(cid:13) (cid:13)(cid:8)
(cid:8)  (cid:13)(cid:8) (cid:1)(cid:8)(cid:8)(cid:1)(cid:1)(cid:7)(cid:24)(cid:8)(cid:7) (cid:8)L(cid:1)

(cid:3)
(cid:17) (cid:8)(cid:14) (cid:10)(cid:15)(cid:11) (cid:15) L(cid:10)(cid:15)(cid:11) (cid:21) (cid:8)(cid:22) (cid:0) (cid:15)  (cid:13)(cid:8) (cid:20)	
(cid:10) (cid:12)(cid:13) (cid:7) (cid:1)(cid:28)
(cid:23)(cid:1)(cid:12)(cid:1)  (cid:1) (cid:23)(cid:1)(cid:20) (cid:1) (cid:3) (cid:17) - (cid:8)L(cid:1)

(cid:10) (cid:7)(cid:28)(cid:1)(cid:28) L(cid:1)

(cid:15)

(cid:15)

(cid:15)

(cid:19) $(cid:1)	(cid:1)(cid:20)(cid:1) (cid:8)(cid:12)(cid:1)(cid:15)(cid:10)(cid:15) (cid:20)(cid:23)(cid:1)(cid:12)(cid:1)  (cid:12)(cid:1)(cid:28)
(cid:20) (cid:30)(cid:1)(cid:20) (cid:1) (cid:8)(cid:7)!(cid:1) #(cid:25)( (cid:20)(cid:14)(cid:7)(cid:7)(cid:28)

"(cid:25)" ’(cid:27)#	(cid:11) (cid:2) (cid:9)(cid:4)(cid:17) (cid:30) (cid:2) (cid:9)(cid:2)(cid:17)  (cid:4)(cid:17)

(cid:19) (cid:21) (cid:23)(cid:1)(cid:20) (cid:1) (cid:14)(cid:1)  (cid:8)(cid:7)(cid:21)(cid:22) #(cid:25)( (cid:20)(cid:14)(cid:7)(cid:7) (cid:13)(cid:1)

(cid:4)(cid:15) (cid:15)(cid:17)(cid:2)(cid:4)

(cid:8)(cid:21)(cid:1) (cid:8) !(cid:7)(cid:1) 	(cid:19)(cid:1) (cid:21) (cid:1) (cid:12) (cid:11)(cid:7)   (cid:7)(cid:20)(cid:1)(cid:8)(cid:1)(cid:28)

(cid:20) (cid:21) (cid:23)(cid:1)(cid:20) (cid:1) (cid:8)(cid:7)!(cid:1) #(cid:25)( (cid:20)(cid:14)(cid:7)(cid:7) (cid:11)(cid:7)(cid:13) (cid:20)  (cid:1)(cid:20)(cid:7)
(cid:1) (cid:13)(cid:1) (cid:8)(cid:21)(cid:1) (cid:8)(cid:22) 	(cid:19)(cid:1) (cid:21) (cid:1) (cid:7) (cid:11)(cid:7)   (cid:7)   (cid:8)(cid:7)(cid:21)(cid:22)
#(cid:25)( (cid:11)(cid:7)(cid:13) (cid:13)(cid:1) (cid:8)(cid:1) (cid:20)  (cid:1)(cid:20)(cid:7) (cid:1)(cid:28) *	(cid:20)(cid:7) (cid:12) (cid:11)(cid:7)  
 (cid:20)(cid:13)(cid:8)(cid:12)(cid:1)(cid:28)

(cid:21)(cid:28) M	(cid:9)  (cid:10)(cid:2)(cid:9)  (cid:1)(cid:1)(cid:10)(cid:1) (cid:27)(cid:9) (cid:20)(cid:9)  # (cid:10) (cid:10)
(cid:6) (cid:11)(cid:9) (cid:2)(cid:10)(cid:9) (cid:6) (cid:10)(cid:20)(cid:9)(cid:10)(cid:16)(cid:1)(cid:16) (cid:9)(cid:10)(cid:1) (cid:6) (cid:15)(cid:9) (cid:24) (cid:25)(cid:11)(cid:9) (cid:9)
(cid:6) (cid:11)(cid:9) (cid:6) (cid:1) (cid:1) %A’(cid:24)

 (cid:11)(cid:1) (cid:9)(cid:2)(cid:1) (cid:27)(cid:9) (cid:6)(cid:2)	  (cid:9) 2(cid:10) 	 (cid:9)(cid:10)(cid:10)(cid:9)(cid:9)(cid:1)$	
(cid:1)(cid:16) (cid:20)(cid:9)(cid:2) (cid:10)(cid:11) (cid:24) 1 (cid:1) (cid:1)(cid:2)(cid:1)# (cid:2)(cid:1)(cid:15)(cid:9) (cid:11)(cid:9) (cid:2)(cid:10)(cid:9) (cid:27)(cid:11)(cid:9)
(cid:16) C  (cid:1) (cid:10) (cid:15)(cid:9)(cid:24)  (cid:16)(cid:9)(cid:9)(cid:10)  (cid:10) (cid:2) (cid:9)(cid:9) (cid:6)(cid:27)(cid:10)(cid:15) (cid:10)
(cid:6) (cid:11)(cid:9) (cid:15)(cid:1)(cid:10)# (cid:10)(cid:28)	(cid:15)	(cid:2) / (cid:1) (cid:9)(cid:9)(cid:15)(cid:9)(cid:15) (cid:6) (cid:9)(cid:9)
(cid:15) (cid:3) (cid:16) 	 (cid:9)(cid:15)(cid:1)(cid:16) (cid:9)(cid:10)(cid:16)(cid:9) (cid:6)  (cid:9)(cid:10)(cid:20)(cid:9)  (cid:15)(cid:9)  (cid:27)(cid:11)(cid:1)(cid:2)(cid:11)
(cid:27)(cid:9) (cid:9)(cid:10) (cid:10) (cid:10) (cid:9)(cid:24)  (cid:27)(cid:9)(cid:20)(cid:9) (cid:11)(cid:1) (cid:27)	 (cid:15) (cid:10)(cid:22)(cid:9) (cid:11)(cid:9) (cid:10) 	
(cid:16)(cid:1)(cid:11) (cid:20)(cid:9)# (cid:1)(cid:9)Æ(cid:2)(cid:1)(cid:9) (cid:1)(cid:6) (cid:9)(cid:9) (cid:10)(cid:9)  (cid:10)(cid:16)(cid:9)(cid:24) 1	(cid:10)(cid:9) #
(cid:10) (cid:2) (cid:9)(cid:9) (cid:6)(cid:27)(cid:10)(cid:15) (cid:10) (cid:1)  (cid:10) (cid:27)(cid:10)# (cid:9)(cid:2)(cid:9)(cid:10)#(cid:24)

5	(cid:9) (cid:11)(cid:10) (cid:11)(cid:1) (cid:9)(cid:10)(cid:1) (cid:10)(cid:6) (cid:20)(cid:9)(cid:2) (cid:10)(cid:11) 
(cid:20)(cid:9)(cid:2) L(cid:10)(cid:11) (cid:24)  (cid:9) (cid:9)(cid:9)(cid:15)  (cid:11)(cid:27) (cid:11)(cid:10) L(cid:10)(cid:11)  (cid:21) (cid:10)(cid:11) 
(cid:6) (cid:10)# (cid:9)(cid:9) (cid:15) (cid:3) (cid:16)(cid:24) (cid:25)(cid:11)(cid:1) (cid:27)(cid:1)   (cid:1) # (cid:11) (cid:14)(cid:11) L(cid:10)(cid:11)  (cid:21)
(cid:11) (cid:14)(cid:11) (cid:10)(cid:11) (cid:24)
/(cid:9)(cid:2)(cid:10)	(cid:9) (cid:6) 	 (cid:10) (cid:1)$(cid:10)(cid:1) (cid:10)	(cid:1) (cid:27)(cid:9) (cid:11)(cid:10)(cid:20)(cid:9)
(cid:10)(cid:11)  C (cid:1)
(cid:5)(cid:0)(cid:4)

(cid:2)(cid:5)(cid:10)(cid:11)  C (cid:1)
(cid:5)(cid:0)(cid:4)

(cid:2)(cid:5)(cid:10)  (cid:12) C (cid:12)

(cid:8)(cid:10)(cid:11)

(cid:27)(cid:11)(cid:9)(cid:9) (cid:12) (cid:1) (cid:11)(cid:9) (cid:2)(cid:10) (cid:1) (cid:6)	 (cid:10) 3(cid:24)  	(cid:16)(cid:16)(cid:1)(cid:16)
(cid:11)(cid:1) (cid:1) (cid:6)	 (cid:10) 3 (cid:27)(cid:9) (cid:16)(cid:9) (cid:2)(cid:5)(cid:10)(cid:11)  C (cid:10)(cid:11)   (cid:10)(cid:11)

(cid:2)(cid:5)(cid:24)

I(cid:9)(cid:2) (cid:10)(cid:11) (cid:10)(cid:15) L(cid:10)(cid:11) (cid:10)(cid:16)(cid:9)(cid:9)  (cid:10)   (cid:15)(cid:9) (cid:10)(cid:15) (cid:9)(cid:15)(cid:16)(cid:9) (cid:11)(cid:9)
(cid:11)(cid:10) (cid:15)(cid:9) (cid:24) (cid:25)(cid:11)	 (cid:11)(cid:9)# (cid:11)(cid:10)(cid:20)(cid:9) (cid:11)(cid:9) (cid:10)(cid:9) (cid:1)(cid:10)  (cid:2)	
,(cid:16)	(cid:10)(cid:1) (cid:20)(cid:5) (cid:27)(cid:1)(cid:11) (cid:11)(cid:9) (cid:2)(cid:10)(cid:1) (cid:2)(cid:5)
 C (cid:6)(cid:24)  (cid:9) (cid:2)(cid:10) (cid:27)(cid:1)(cid:9)

(cid:2)(cid:5)L(cid:10)(cid:11)  C (cid:11)(cid:20)(cid:5) (cid:5) L(cid:10)(cid:11)  C (cid:11)(cid:20)(cid:5) (cid:5) (cid:10)(cid:11)    (cid:10)(cid:11)

C (cid:2)(cid:5)(cid:10)(cid:11)    (cid:10)(cid:11)

(cid:2)(cid:5)  L(cid:10)(cid:11)

(cid:2)(cid:5)  L(cid:10)(cid:11)
(cid:2)(cid:5) C (cid:10)(cid:11)   L(cid:10)(cid:11)

(cid:2)(cid:5)

(cid:2)(cid:5) C

L(cid:10)(cid:11)  C (cid:1)
(cid:5)(cid:0)(cid:4)

(cid:2)(cid:5)L(cid:10)(cid:11)  C (cid:10)(cid:11)   (cid:1)
(cid:5)(cid:0)(cid:4)

(cid:8)L(cid:10)(cid:11)

(cid:2)(cid:5)(cid:10)

 (cid:9) (cid:11)(cid:10)(cid:20)(cid:9) (cid:10)(cid:11)
(cid:2)(cid:2) 	(cid:15)(cid:9) (cid:11)(cid:10) L(cid:10)(cid:11)
 (cid:11)(cid:9) (cid:8) 5 (cid:1) 	(cid:9)(cid:16)(cid:10)(cid:1)(cid:20)(cid:9)  L(cid:10)(cid:11)  (cid:21) (cid:10)(cid:11) (cid:24)

 (cid:21) E7 (cid:1)(cid:9)(cid:2)(cid:1)(cid:16) 	(cid:15)(cid:10)(cid:9) 	 (cid:9) (cid:6) (cid:9) 2(cid:14) (cid:27)(cid:9)
 (cid:21) E (cid:10) (cid:27)(cid:9)  (cid:24) (cid:25)(cid:11)(cid:9)(cid:9)(cid:6)(cid:9) (cid:11)(cid:9) (cid:1)(cid:1)	

(cid:25)(cid:11)(cid:9) (cid:22)(cid:9)# (cid:1)(cid:15)(cid:9)(cid:10) (cid:1) (cid:11)(cid:10) (cid:11)(cid:9) (cid:10)(cid:20)(cid:9)(cid:10)(cid:16)(cid:1)(cid:16) (cid:9)(cid:10)(cid:1) (cid:15)(cid:9) 
(cid:1)(cid:20)(cid:10) (cid:1)(cid:15)(cid:10)(cid:9) (cid:9)(cid:10)(cid:16)(cid:9) (cid:1) (cid:9)(cid:9) (cid:15) (cid:3) (cid:16) (cid:1)(cid:9)(cid:9)(cid:15) (cid:11)(cid:8)(cid:14)
(cid:15)(cid:9) (cid:10)(cid:24) (cid:25)(cid:11)(cid:9)(cid:9)(cid:6)(cid:9) (cid:27)(cid:9) (cid:2)(cid:10) .(cid:9)	(cid:9)0 (cid:9)(cid:10)(cid:16)(cid:9) (cid:10)(cid:9)(cid:15)
(cid:1) (cid:9)(cid:20)(cid:1)	 (cid:9) (cid:1)(cid:24)(cid:9)(cid:24)  (cid:10) (cid:11)(cid:9) (cid:10)(cid:16)(cid:10)(cid:1)(cid:24) (cid:25)(cid:11)(cid:1) (cid:14)	
(cid:9)(cid:20)(cid:10)(cid:1) (cid:10)  (cid:27) 	  (cid:9)(cid:15)	(cid:2)(cid:9) (cid:11)(cid:9) 	(cid:14)(cid:9) (cid:6) (cid:9)(cid:10)(cid:16)(cid:9)
(cid:15)(cid:10)(cid:1)(cid:2)(cid:10)  # (cid:1)(cid:6) (cid:9)(cid:9) (cid:10)(cid:15) (cid:11)(cid:9) (cid:15)(cid:9) (cid:6) (cid:10)(cid:20)(cid:9)(cid:10)(cid:16)(cid:1)(cid:16) (cid:9)(cid:10)	
(cid:1) (cid:10)(cid:9) (cid:2)(cid:11)(cid:9) (cid:1) (cid:10) (cid:10)(cid:1)(cid:2)	 (cid:10) (cid:27)(cid:10)#(cid:24) 5(cid:9)(cid:2)(cid:1),(cid:2)(cid:10)  # (cid:27)(cid:9)
(cid:9)	(cid:1)(cid:9) (cid:9)(cid:9)  (cid:14)(cid:9) (cid:2)(cid:11)(cid:10)(cid:1) (cid:27)(cid:11)(cid:1)(cid:2)(cid:11) (cid:10)(cid:9) (cid:7)(cid:20) (cid:27)(cid:1)(cid:11)
(cid:9)(cid:9)(cid:2)  (cid:9) (cid:15)(cid:9)(cid:1)(cid:16)  (cid:11)(cid:9) (cid:16)(cid:10)(cid:11)=
)(cid:23)*(cid:4)(cid:4) "(cid:25)0(cid:25) .(cid:8)(cid:13) (cid:0) (cid:8)(cid:14) (cid:20)(cid:13)(cid:8)(cid:7) (cid:15) (cid:3) (cid:16) (cid:8)(cid:1) (cid:8)(cid:7)(cid:14)
 (cid:19)(cid:1) (cid:1)(cid:2) (cid:7)(cid:21) (cid:13)(cid:1)(cid:1) (cid:1)(cid:31)(cid:7) (cid:8) (cid:14)(cid:1)(cid:7)(cid:12) (cid:21) (cid:14)(cid:1)
(cid:19)	(cid:0) 	 (cid:3) (cid:1) 	(cid:20)(cid:13) (cid:13)(cid:8) (cid:1)(cid:8)(cid:20)(cid:13) (cid:20)(cid:13)(cid:8)(cid:7) (cid:15) (cid:8)(cid:7)!(cid:1) (cid:13)(cid:1) (cid:21)  (cid:11)	
(cid:7)(cid:12) (cid:1)(cid:22)- (cid:7)(cid:21) 	(cid:11)
(cid:11)  (cid:8)(cid:1) (cid:13)(cid:1) (cid:20)(cid:1)(cid:20)	(cid:7)(cid:23)(cid:1) (cid:14)(cid:1)
(cid:7) (cid:13)(cid:1) (cid:20)(cid:13)(cid:8)(cid:7) (cid:13)(cid:1) (cid:13)(cid:1) (cid:1)	(cid:1)(cid:20)(cid:1) (cid:19)	(cid:11)
(cid:11)  (cid:7)
(cid:7)(cid:20)(cid:28)

(cid:0) (cid:0) (cid:4) (cid:4) (cid:4) (cid:0) (cid:19)	(cid:11)

(cid:0) (cid:0) (cid:4) (cid:4) (cid:4) (cid:0) 	(cid:11)

(cid:4)(cid:12) (cid:24)(cid:9) (cid:24)(cid:12) ,(cid:9)(cid:16)#(cid:31)(cid:9)(cid:18) (cid:9) (cid:12)(cid:18)(cid:14)(cid:27) (cid:12)(cid:9)(cid:27)(cid:12) (cid:26)
(cid:24)(cid:12)    (cid:12)(cid:9)(cid:28)(cid:12) (cid:14)  (cid:12)(cid:12)(cid:18)(cid:12)(cid:18)(cid:19)  (cid:31)	 (cid:18) (cid:16)(cid:28)(cid:12) (cid:28)(cid:12)(cid:16)
(cid:0)(cid:0)  (cid:9)  (cid:26) ,	 (cid:31)	 (cid:18)  (cid:16)(cid:24)(cid:9)(cid:27)(cid:12) (cid:28)(cid:12)(cid:16) (cid:0)(cid:0)
 (cid:19)

(cid:5)’(cid:12)(cid:16)(cid:9)   (cid:24)(cid:9) 	 (cid:9) (cid:27)(cid:14)(cid:24) (cid:14) (cid:12)(cid:9)(cid:27)(cid:12)	(cid:26)(cid:12)(cid:12)(cid:19) &(cid:24)(cid:12) (cid:24)(cid:9)(cid:12)
1(cid:12)(cid:9)(cid:27)(cid:12) (cid:14) (cid:28)(cid:9) (cid:14)(cid:18) (cid:26) (cid:18)(cid:14)(cid:12)(cid:16)(cid:12)(cid:18) (cid:12)(cid:18)(cid:27)(cid:12)  (cid:1)  (cid:14) (cid:12)(cid:12) (cid:4) 2 (cid:12)(cid:9)
(cid:24)(cid:9) (cid:12)(cid:18)(cid:14)(cid:27) (cid:9) (cid:12)(cid:9)(cid:27)(cid:12) (cid:26) (cid:18)(cid:12)   (cid:18)(cid:12)  (cid:9) (cid:18)(cid:14)(cid:16)	(cid:12)(cid:18)
(cid:14) (cid:12)(cid:16)(cid:14) 3(cid:19)(cid:5) (cid:31)	 (cid:18)  (cid:18)(cid:14)(cid:26)(cid:30) (cid:28)(cid:12)(cid:16) (cid:0)(cid:0) (cid:19)

186E(cid:24) (cid:1)(cid:1)(cid:10) (cid:1)$(cid:9) (cid:1)  (cid:11)(cid:10) (cid:1) (cid:3) (cid:17) (cid:10)(cid:15) (cid:11) (cid:14)(cid:11) (cid:10)(cid:11) (cid:15) J(cid:10)(cid:24)
2(cid:24) 1 (cid:15)(cid:9)  (cid:3) (cid:1) (cid:15) (cid:11)(cid:9) (cid:6)  (cid:27)(cid:1)(cid:16) (cid:9)(cid:10)(cid:1) (cid:1)

(cid:11)(cid:9) (cid:15)(cid:9) (cid:6) (cid:1)(cid:2)(cid:9)(cid:10)(cid:1)(cid:16) (cid:19)=

E(cid:24) 5(cid:9) (cid:10)   (cid:9)(cid:10)(cid:16)(cid:9)  $(cid:9)(cid:24)

2(cid:24) 1 (cid:15)(cid:9)  (cid:3) (cid:1) (cid:15) (cid:11)(cid:9) (cid:6)  (cid:27)(cid:1)(cid:16) (cid:9)(cid:10)(cid:1) (cid:1)

(cid:11)(cid:9) (cid:15)(cid:9) (cid:6) (cid:1)(cid:2)(cid:9)(cid:10)(cid:1)(cid:16) (cid:19)=

(cid:10) 1 (cid:9)(cid:20)(cid:9)# (cid:9)(cid:15)(cid:16)(cid:9) (cid:0)  (cid:3) (cid:2) (cid:27)(cid:1)(cid:11) (cid:19) (cid:21) (cid:19) (cid:15)

(cid:23) 1 (cid:9)(cid:20)(cid:9)# (cid:9)(cid:15)(cid:16)(cid:9) (cid:0)  (cid:3) (cid:2) (cid:27)(cid:1)(cid:11) (cid:19) (cid:21) (cid:19) 	(cid:15)(cid:10)(cid:9)

(cid:11)(cid:9) (cid:6)  (cid:27)(cid:1)(cid:16)=

	 (cid:6) (cid:16) (cid:2)(cid:10)(cid:1) (cid:9) (cid:11)(cid:10) (cid:9) (cid:2)(cid:11)(cid:10)(cid:1) (cid:11)(cid:9) (cid:9)	
(cid:6) (cid:11)(cid:9) (cid:10)(cid:20)(cid:9)(cid:10)(cid:16)(cid:1)(cid:16) (cid:9)(cid:10)(cid:1) (cid:6) (cid:9)(cid:15)(cid:16)(cid:9) (cid:0) (cid:24)

	 1 (cid:2)(cid:11)(cid:10)(cid:1) (cid:1) (cid:16) (cid:10) (cid:10) (cid:9)(cid:10)(cid:16)(cid:9) (cid:6)   (cid:24)

(cid:9)(cid:10)(cid:16)(cid:9)  (cid:10) (cid:6)  (cid:27)=
	 (cid:12)	(cid:9) (cid:10) C (cid:0)
(cid:12)

J(cid:10)  	(cid:9)(cid:0)(cid:3)

(cid:12)	
(cid:12)

	

	 5(cid:9) (cid:2)(cid:6) =C (cid:1)(cid:5) (cid:8)(cid:10)(cid:2)(cid:5)   (cid:2)(cid:5)  (cid:0)
(cid:12)

J(cid:10)(cid:2)(cid:5)(cid:6)(cid:10)

(cid:14) (cid:9)(cid:6) (cid:11)(cid:9) (cid:10)(cid:20)(cid:9)(cid:10)(cid:16)(cid:1)(cid:16) (cid:9)(cid:10)(cid:1) (cid:6) (cid:15)(cid:9) (cid:24)

3(cid:24) (cid:8)(cid:9)(cid:20)(cid:9)(cid:9) (cid:11)(cid:9) (cid:15)(cid:9)(cid:1)(cid:16)= (cid:9) (cid:19)	 =C (cid:5)(cid:1)(cid:5)  2   (cid:19)	(cid:24)

3(cid:24) (cid:8)(cid:9)(cid:20)(cid:9)(cid:9) (cid:11)(cid:9) (cid:15)(cid:9)(cid:1)(cid:16)= (cid:9) (cid:19)	 =C (cid:5)(cid:1)(cid:5)  2   (cid:19)	(cid:24)

4(cid:24) (cid:12)(cid:11)(cid:9)(cid:2)(cid:22) (cid:27)(cid:11)(cid:9)(cid:11)(cid:9) (cid:10) (cid:1)(cid:16) (cid:2)(cid:1)(cid:9)(cid:1) (cid:1) (cid:10)(cid:1),(cid:9)(cid:15)7

(cid:1)(cid:6) #(cid:9) (cid:9)(cid:1)(cid:10)(cid:9) (cid:11)(cid:9)(cid:27)(cid:1)(cid:9) (cid:16)  (cid:9) 2(cid:24)

1(cid:1)(cid:16)	(cid:9) 3= ’(cid:27)#	(cid:11) (cid:2) (cid:9)(cid:4)(cid:17) (cid:30) (cid:2) (cid:9)(cid:2)(cid:17)  (cid:4)(cid:17)
(cid:4)(cid:15) (cid:15)(cid:17)(cid:2)(cid:4)(cid:25)

: (cid:10) (cid:9)(cid:28)(cid:10) (cid:9) (cid:27)(cid:9) (cid:2)	 (cid:15) (cid:2)(cid:11)(cid:9) (cid:16)  (cid:14)(cid:9) (cid:11)(cid:9) (cid:9) (cid:6)
(cid:9)(cid:15)(cid:16)(cid:9)7 (cid:1) (cid:1) (cid:9)(cid:10)#  (cid:9)(cid:9) (cid:11)(cid:10) (cid:11)(cid:9)# (cid:10)(cid:9) (cid:1)(cid:2) (cid:6)
(cid:10)# (cid:15)(cid:9)(cid:1)(cid:16) (cid:6) (cid:15)(cid:9)(cid:24)  (cid:27)(cid:9)(cid:20)(cid:9) (cid:1) (cid:1)(cid:16)(cid:11) (cid:14)(cid:9) (cid:10)(cid:15)(cid:20)(cid:10)	
(cid:10)(cid:16)(cid:9)	  (cid:2)(cid:11)(cid:9)  (cid:16)(cid:9) (cid:9)(cid:9) (cid:1)(cid:2)(cid:9) (cid:11)(cid:9) (cid:1)(cid:6)(cid:10)(cid:1)
(cid:1)(cid:16)(cid:11) (cid:10)(cid:16)(cid:10)(cid:9) (cid:6)(cid:10)(cid:9) (cid:11)	(cid:16)(cid:11) (cid:11)(cid:9) (cid:16)(cid:10)(cid:11)(cid:24)

(cid:25)(cid:11)(cid:9) (cid:10) (cid:16)(cid:1)(cid:11) (cid:6) (cid:10) (cid:16)(cid:10)(cid:11) (cid:27)(cid:1)(cid:11) (cid:1)(cid:2) (cid:2)(cid:11)(cid:10)(cid:1) (cid:1)
(cid:11)(cid:27) (cid:1) 1(cid:1)(cid:16)(cid:24) 3(cid:24)  (cid:9)(cid:1)(cid:9) (cid:10)(cid:9) 	(cid:10)(cid:1)$(cid:9)(cid:15) (cid:14)# (cid:11)(cid:9)
(cid:6)  (cid:27)(cid:1)(cid:16)  (cid:9)(cid:10) (cid:27)(cid:11)(cid:9) (cid:6) (cid:1) (cid:16)(cid:1)(cid:20)(cid:9) (cid:1) %A’(cid:24)
(cid:23)(cid:2) "(cid:25)1(cid:25) $(cid:8)(cid:7)(cid:12) (cid:11)(cid:7)(cid:13) (cid:13)(cid:1) (cid:1)(cid:20)(cid:14) (cid:8) (cid:13)(cid:1) (cid:21) 	
 (cid:11)(cid:7)(cid:12) (cid:1)(cid:7)(cid:1) (cid:13) (cid:14) (cid:14)	(cid:7)(cid:12) (cid:1) , (cid:21) (cid:14)(cid:1) -

(cid:8) * (cid:1)(cid:8)(cid:20)(cid:13) (cid:1)(cid:14)(cid:12)(cid:1) 	(cid:0) (cid:22) (cid:3) (cid:2) (cid:11)(cid:7)(cid:13) (cid:19)	 (cid:21) (cid:19)(cid:22) (cid:21) (cid:19)
(cid:1)(cid:8)(cid:12)(cid:1) 	 (cid:7) (cid:22) (cid:7) (cid:20)(cid:13)(cid:8)(cid:7) (cid:15) (cid:3) (cid:16)	(cid:18) (cid:8)(cid:1) (cid:23)(cid:8) (cid:7)(cid:14)(cid:28)
(cid:25)(cid:13)(cid:7) (cid:1)(cid:22) (cid:8)  (cid:13) (cid:14) (cid:21) (cid:14)(cid:1) (cid:22) C  (cid:7) (cid:13)(cid:1)
(cid:19)(cid:1)(cid:12)(cid:7)(cid:7)(cid:12) (cid:8)(cid:14) (cid:7) (cid:13)(cid:1) (cid:1)(cid:14) (cid:21) (cid:1) ,(cid:19)(cid:28)

(cid:19) * (cid:1)(cid:8)(cid:20)(cid:13) (cid:1)(cid:14)(cid:12)(cid:1) 	(cid:0) (cid:22) (cid:3) (cid:2) (cid:11)(cid:7)(cid:13) (cid:19)	 (cid:21) (cid:19) (cid:1)(cid:8)(cid:12)(cid:1)

(cid:22) (cid:7) 	 (cid:7) (cid:20)(cid:13)(cid:8)(cid:7) (cid:15) (cid:3) (cid:16)	(cid:18) (cid:8)(cid:1) (cid:23)(cid:8) (cid:7)(cid:14)(cid:28)

 (cid:8)(cid:14)(cid:14)(cid:7)(cid:7) (cid:1)(cid:22) (cid:8) (cid:13) (cid:14) (cid:14)	(cid:7)(cid:12) (cid:13)(cid:1) ! (cid:8) (cid:21)
(cid:13)(cid:1) (cid:8) (cid:12)(cid:7)(cid:13)(cid:28)

(cid:25)(cid:11)	 (cid:11)(cid:9) (cid:10) (cid:16)(cid:1)(cid:11) (cid:1) 1(cid:1)(cid:16)(cid:24) 3 (cid:1) (cid:10) (cid:9)(cid:2)(cid:1)(cid:10)  (cid:2)(cid:10)(cid:9) (cid:6) (cid:11)(cid:9)
(cid:10) (cid:16)(cid:1)(cid:11) (cid:1) 1(cid:1)(cid:16)(cid:24) 2 (cid:1)(cid:6) (cid:27)(cid:9) (cid:9)(cid:10) (cid:11)(cid:9) , (cid:10) (cid:6) (cid:6)(cid:9)
(cid:10) (cid:16)(cid:1)(cid:11) (cid:10) (cid:10) (cid:6) (cid:1)(cid:1)(cid:1)(cid:10) (cid:1)$(cid:10)(cid:1) (cid:6) (cid:11)(cid:9)  (cid:10)(cid:9) (cid:9)(cid:24)

2Æ(cid:15)(cid:4)(cid:23) (cid:4) (cid:23)(cid:23)(cid:2)(cid:4) (cid:25)(cid:11)(cid:9) (cid:10) (cid:16)(cid:1)(cid:11) (cid:1) 1(cid:1)(cid:16)(cid:24) 3
(cid:9)	(cid:1)(cid:9) (cid:5)(cid:16)(cid:5)  (cid:5)(cid:4)(cid:5) (cid:10)(cid:16)(cid:9) (cid:6) (cid:15)(cid:9)  (cid:10)(cid:15) (cid:5)(cid:16)(cid:5) 
(cid:5)(cid:4)(cid:5)  (cid:5)(cid:4)(cid:5) (cid:10)(cid:16)(cid:9) (cid:6) (cid:9)(cid:15)(cid:16)(cid:9) (cid:0) (cid:24)  (cid:27)(cid:9)(cid:20)(cid:9) (cid:27)(cid:9) (cid:2)(cid:10)
(cid:9)(cid:15)	(cid:2)(cid:9) (cid:1)  (cid:5)(cid:4)(cid:5) (cid:10)(cid:15) (cid:5)(cid:4)(cid:5)  (cid:5)(cid:4)(cid:5) (cid:9)(cid:9)(cid:2)(cid:1)(cid:20)(cid:9) #
	(cid:1)(cid:16) (cid:27) (cid:1)(cid:15)(cid:9)(cid:10)(cid:11)(cid:24) 1(cid:1) (cid:1) (cid:2)(cid:10) (cid:14)(cid:9) (cid:9)(cid:9) (cid:11)(cid:10) (cid:11)(cid:9) (cid:10) (cid:16)	
 C (cid:10)(cid:11) (cid:0)
(cid:1)(cid:11) (cid:10)(cid:1)(cid:10)(cid:1) (cid:11)(cid:9) (cid:6)  (cid:27)(cid:1)(cid:16) (cid:9)	(cid:10) (cid:1)(cid:1)(cid:9)= (cid:10)(cid:11)

(cid:6) (cid:15)(cid:0) (cid:15) (cid:5) (cid:3) (cid:16) (cid:10)(cid:15) (cid:10)(cid:11)
(cid:6) (cid:15)(cid:0) (cid:15) (cid:5) (cid:3) (cid:16) (cid:10)	
	(cid:1)(cid:16) (cid:11)(cid:10) (cid:11)(cid:9)# (cid:11) (cid:15) (cid:10)(cid:6)(cid:9) (cid:1)(cid:1)(cid:1)(cid:10) (cid:1)$(cid:10)(cid:1)(cid:24) 5(cid:9)(cid:2)(cid:15)

 C (cid:10)(cid:11) (cid:0)



(cid:6)(cid:20)(cid:12) (cid:9)	(cid:12) (cid:24)(cid:9) (cid:9)(cid:27)(cid:12) (cid:12)	(cid:14)(cid:12)(cid:18) (cid:26) (cid:28)(cid:12)(cid:16) *(cid:0) (cid:14) (cid:12)(cid:27)	
 (cid:14)(cid:27)(cid:14), (cid:12)(cid:19) &(cid:24)(cid:14) (cid:24) (cid:18) (cid:26) (cid:9)(cid:30) (cid:12)(cid:12)(cid:27)(cid:30) (cid:26)	(cid:16)(cid:14) 	(cid:12)(cid:18) (cid:14) (cid:9)(cid:16)	
(cid:14)(cid:16)(cid:12) (cid:12)(cid:19)(cid:27)(cid:19) (cid:26) (cid:26)	(cid:16)(cid:14) (cid:31)(cid:14)(cid:24)  (cid:12)(cid:19)

4(cid:24) (cid:12)(cid:11)(cid:9)(cid:2)(cid:22) (cid:27)(cid:11)(cid:9)(cid:11)(cid:9) (cid:10) (cid:1)(cid:16) (cid:2)(cid:1)(cid:9)(cid:1) (cid:1) (cid:10)(cid:1),(cid:9)(cid:15)7

(cid:1)(cid:6) #(cid:9) (cid:9)(cid:1)(cid:10)(cid:9) (cid:11)(cid:9)(cid:27)(cid:1)(cid:9) (cid:16)  (cid:9) 2(cid:24)

1(cid:1)(cid:16)	(cid:9) 4= 2Æ(cid:15)(cid:4)(cid:23) (cid:4) (cid:23)(cid:23)(cid:2)(cid:4) (cid:30) (cid:17)(cid:23) (cid:2) (cid:9)	
(cid:4)(cid:17) (cid:4) 3(cid:4)(cid:9)(cid:25) (cid:24) 	(cid:4)(cid:9) (cid:23)(cid:2)(cid:9)(cid:23)(cid:25)

(cid:9)(cid:10)(cid:10)(cid:9)(cid:9)(cid:1)$(cid:10)(cid:1) (cid:10)(cid:11) (cid:2)(cid:10) (cid:14)(cid:9) (cid:9)(cid:15) 	(cid:1)(cid:16) (cid:9)(cid:10)(cid:16)(cid:9)
 C (cid:8)(cid:2)(cid:6) (cid:5) (cid:7) (cid:3) (cid:4)(cid:10) (cid:6) (cid:15)(cid:1)(cid:9)(cid:2)(cid:9)(cid:15) (cid:9)(cid:15)(cid:16)(cid:9)  (cid:7)  (cid:3) (cid:2)
(cid:27)(cid:11)(cid:1)(cid:2)(cid:11) (cid:2)(cid:9)(cid:15)  (cid:20)(cid:9)(cid:2) (cid:1) (cid:10) (cid:6)  (cid:27)=

C (cid:0)
(cid:10)(cid:11)

(cid:12)
(cid:2)(cid:5)(cid:6) C (cid:0)
(cid:10)(cid:11)

(cid:12)

J(cid:10)  (cid:9)(cid:0)(cid:3)
J(cid:10)(cid:2)(cid:5)(cid:6)   (cid:2)(cid:6)   (cid:2)(cid:5)



(cid:12)
(cid:12)

(cid:25)(cid:11)(cid:9) (cid:9)	 (cid:1)(cid:16) (cid:10) (cid:16)(cid:1)(cid:11) (cid:1) (cid:11)(cid:27) (cid:1) 1(cid:1)(cid:16)(cid:24) 4(cid:24) (cid:9) (cid:11)(cid:10)
(cid:6) (cid:10)# (cid:1)(cid:10) (cid:2)(cid:11)(cid:1)(cid:2)(cid:9) (cid:6) (cid:9) J(cid:10) (cid:9)(cid:10)(cid:16)(cid:9) 		
(cid:15)(cid:10)(cid:9) (cid:1) (cid:9) 2 (cid:2)(cid:10) (cid:14)(cid:9) (cid:15)(cid:9) (cid:20)(cid:9)# (cid:9)Æ(cid:2)(cid:1)(cid:9) # 	(cid:1)(cid:16) (cid:15)(cid:1)	
(cid:10)(cid:2)(cid:9) (cid:10)(cid:6) %3’(cid:24)

(cid:25)(cid:11)(cid:9) (cid:9)(cid:10)(cid:16)(cid:9) 	(cid:15)(cid:10)(cid:9) 	 (cid:9) (cid:6) 	 (cid:10) (cid:16)(cid:1)(cid:11) (cid:1) (cid:20)(cid:9)# (cid:1)(cid:1)	
 (cid:10)  (cid:11)(cid:10) (cid:6) (cid:25)(cid:8) 	- (cid:10) (cid:16)(cid:1)(cid:11) (cid:11)(cid:9)# (cid:27)	 (cid:15) (cid:14)(cid:9) (cid:1)(cid:15)(cid:9)(cid:1)	
(cid:2)(cid:10)  (cid:1)(cid:6) (cid:9)(cid:9) (cid:27)(cid:9)(cid:9) (cid:10)(cid:1)(cid:16)(cid:24)  (cid:27)(cid:9)(cid:20)(cid:9) (cid:25)(cid:8) 	- (cid:9)(cid:6)
(cid:11)(cid:9) 	(cid:15)(cid:10)(cid:9) (cid:1) (cid:10)(cid:10)  (cid:9)  (cid:27)(cid:11)(cid:1) (cid:9) (cid:27)(cid:9) (cid:15) (cid:1) (cid:9)	(cid:9)(cid:1)(cid:10)  #(cid:24) :
(cid:10) (cid:9)	  (cid:27)(cid:9) (cid:16)(cid:9) (cid:2)(cid:20)(cid:9)(cid:16)(cid:9)(cid:2)(cid:9) (cid:9)(cid:1)(cid:9) (cid:20)(cid:9)(cid:15) (cid:9)(cid:10) (cid:1)(cid:9)(cid:24)

(cid:26) (cid:27)(cid:28)(cid:19)(cid:13)(cid:19)(cid:5)  (cid:19)	 

 (cid:9) (cid:11)(cid:10)(cid:20)(cid:9) (cid:2)(cid:10)(cid:9)(cid:15) (cid:6)	 (cid:10) (cid:16)(cid:1)(cid:11)= (cid:15)(cid:1)(cid:10)# (cid:10)(cid:28)	
(cid:15)	(cid:2) (cid:10) (cid:16)(cid:1)(cid:11) / (cid:10)(cid:15) (cid:11)(cid:9)(cid:9) (cid:9)(cid:9)	(cid:9)(cid:27)(cid:9)(cid:1)(cid:16)(cid:11)(cid:9)(cid:15) (cid:10) 	
(cid:16)(cid:1)(cid:11) (cid:25)(cid:8) 	- (cid:25)(cid:8) 	(cid:25) (cid:25)(cid:8) 	5(cid:24) 1 (cid:25)(cid:8) 	- (cid:10) 	
(cid:16)(cid:1)(cid:11) (cid:27)(cid:9) (cid:10)  (cid:9)(cid:28)(cid:9)(cid:1)(cid:9)(cid:9)(cid:15) (cid:27)(cid:1)(cid:11) (cid:11)(cid:9) (cid:15)(cid:10)(cid:1)(cid:16) (cid:10)	
(cid:10)(cid:9)(cid:9) (cid:25) (cid:3) E(cid:0) 2’7 (cid:10) (cid:9)(cid:9)(cid:15) (cid:1) %&’ (cid:25)(cid:8) 	- (cid:2)	
(cid:20)(cid:9)(cid:16)(cid:9) (cid:1)(cid:6) 	Æ(cid:2)(cid:1)(cid:9) # (cid:15)(cid:10)(cid:9)(cid:15)(cid:24)  (cid:9) 	(cid:9)(cid:15) (cid:11)(cid:1) (cid:10)(cid:10)	
(cid:9)(cid:9) (cid:6) (cid:11)(cid:9) (cid:9)(cid:28)(cid:9)(cid:1)(cid:9) (cid:14)(cid:9) (cid:27)(cid:24)  (cid:9) 	(cid:9)(cid:15) (cid:9)(cid:2)(cid:10)(cid:16)	 (cid:10)
(cid:16)(cid:10)(cid:11) (cid:27)(cid:1)(cid:11) A	(cid:9)(cid:1)(cid:16)(cid:11)(cid:14)(cid:11)(cid:15) #(cid:9)(cid:24) (cid:25)(cid:11)(cid:9) (cid:9)(cid:9) (cid:27)(cid:9)(cid:9)
(cid:11)(cid:1)$(cid:10)  (cid:10)(cid:15) (cid:20)(cid:9)(cid:1)(cid:2)(cid:10)  (cid:2)(cid:11)(cid:10)(cid:1) (cid:27)(cid:1)(cid:11) 	(cid:1)(cid:6) (cid:14)(cid:10)(cid:14)(cid:1) 	
(cid:1)#(cid:24)  (cid:9) (cid:9)(cid:10)(cid:9)(cid:15) (cid:11)(cid:9) (cid:10) (cid:27) (cid:6)(cid:9) (cid:27)(cid:1)(cid:11) (cid:14)(cid:10)(cid:14)(cid:1) (cid:1)(cid:1)(cid:9)
E(cid:24)67 (cid:11)(cid:9) (cid:27)(cid:9) (cid:11)(cid:10)(cid:20)(cid:9) (cid:14) C 2 (cid:6) (cid:15)(cid:9)  (cid:10)(cid:15) (cid:14) C E(cid:4)6 (cid:6)
(cid:9)(cid:15)(cid:16)(cid:9) (cid:0) (cid:24)  (cid:9) (cid:2)(cid:9)(cid:9)(cid:15) (cid:15)(cid:9) (cid:1) (cid:11)(cid:9) (cid:10)(cid:9) (cid:15)(cid:9)(cid:24)

1 / (cid:10) (cid:16)(cid:1)(cid:11) (cid:27)(cid:9) (cid:1) (cid:9)(cid:9)(cid:9)(cid:15) (cid:10) (cid:9)	(cid:9)(cid:1)(cid:10)  	(cid:15)(cid:10)(cid:9)
(cid:2)(cid:11)(cid:9)(cid:9) (cid:27)(cid:11)(cid:9) (cid:15)(cid:9) (cid:1) (cid:1)(cid:1) (cid:10)  (cid:11)(cid:10) (cid:6) (cid:25)(cid:8) 	5= (cid:27)(cid:9)
(cid:10) (cid:9)(cid:10)(cid:16)(cid:9) (cid:6) (cid:11)(cid:9)   (cid:9)(cid:6) (cid:2)(cid:9)  (cid:11)(cid:9) (cid:14)
(cid:1)(cid:16)(cid:11) (cid:2)(cid:9) (cid:10)(cid:15) (cid:14)(cid:10)(cid:2)(cid:22)(cid:24)  (cid:9) (cid:9)(cid:28)(cid:9)(cid:1)(cid:9)(cid:9)(cid:15) (cid:27)(cid:1)(cid:11) (cid:11)(cid:9) (cid:10)	
(cid:10)  (cid:9)  	(cid:15)(cid:10)(cid:9) (cid:2)(cid:11)(cid:9)(cid:9) (cid:10)(cid:15) (cid:6)	(cid:15) (cid:11)(cid:10) (cid:1) (cid:27)(cid:10) 	(cid:2)(cid:11)  (cid:27)(cid:9)(cid:24)

187(cid:25)(cid:11)(cid:9) 	(cid:1)(cid:16) (cid:1)(cid:9) (cid:6) (cid:11)(cid:9) (cid:10) (cid:16)(cid:1)(cid:11) 	(cid:14)(cid:9) (cid:6) (cid:1)(cid:9)(cid:10)	
(cid:1) (cid:27)(cid:10) (cid:9)(cid:10)	(cid:9)(cid:15) (cid:1) (cid:9) (cid:6) (cid:11)(cid:9) 	(cid:14)(cid:9) (cid:6) (cid:10)(cid:9)(cid:15)
(cid:9)(cid:10)(cid:16)(cid:9) (cid:15)(cid:1)(cid:20)(cid:1)(cid:15)(cid:9)(cid:15) (cid:14)# (cid:11)(cid:9) 	(cid:14)(cid:9) (cid:6) (cid:15)(cid:1)(cid:9)(cid:2)(cid:9)(cid:15) (cid:9)(cid:15)(cid:16)(cid:9) (cid:1)
(cid:11)(cid:9) (cid:16)(cid:10)(cid:11)(cid:24)

1 (cid:25)(cid:8)  (cid:10) (cid:16)(cid:1)(cid:11) (cid:27)(cid:9) (cid:9)(cid:10)	(cid:9)(cid:15) (cid:27) 	(cid:10)(cid:1)(cid:1)(cid:9) (cid:10)
(cid:6)	(cid:2)(cid:1) (cid:6) (cid:1)(cid:9)= (cid:11)(cid:9) (cid:20)(cid:10) 	(cid:9) (cid:6) (cid:12)(cid:1) (cid:10)(cid:15) (cid:11)(cid:9) (cid:20)(cid:10) 	(cid:9) (cid:6)
(cid:11)(cid:9) (cid:9)(cid:9)(cid:16)# (cid:11)(cid:20) (cid:5) J(cid:10)(cid:24) (cid:9) (cid:11)(cid:10) (cid:11)(cid:9) (cid:6)(cid:9) (cid:1) (cid:10)  (cid:27)(cid:9)
(cid:14)	(cid:15)  (cid:11)(cid:9) (cid:1)(cid:10)  (cid:20)(cid:10) 	(cid:9) (cid:6) (cid:11)(cid:9) (cid:9)(cid:9)(cid:16)# (cid:10)(cid:15) (cid:11)(cid:9)
 (cid:10)(cid:9) (cid:1) (cid:10) 	(cid:9) (cid:14)	(cid:15)(cid:24) 5 	(cid:1) (cid:20) (cid:6) (cid:20)(cid:9)(cid:2) (cid:1) (cid:27)(cid:10)
(cid:6) (cid:9)(cid:10)(cid:2)(cid:11) (cid:15)(cid:9)  (cid:27)(cid:9) (cid:15)(cid:9)(cid:9)(cid:1)(cid:9)
(cid:2)	(cid:9)(cid:15) (cid:10) (cid:6)  (cid:27)=
 (cid:10)(cid:14)(cid:9)  (cid:2) (cid:1)(cid:1)(cid:1)$(cid:1)(cid:16) (cid:11) (cid:14)(cid:11) (cid:10)(cid:11)
 (cid:2)(cid:24) 1 / (cid:10) (cid:16)(cid:1)(cid:11)
(cid:27)(cid:9) (cid:2)(cid:10) (cid:15)(cid:9)(cid:9)(cid:1)(cid:9)  # (cid:9) (cid:6) (cid:11)(cid:9)(cid:9) 	(cid:10)(cid:1)(cid:1)(cid:9) (cid:10)(cid:9) #
(cid:11)(cid:9) (cid:20)(cid:10) 	(cid:9) (cid:6) (cid:11)(cid:9) (cid:9)(cid:9)(cid:16)#(cid:24)

(cid:25)(cid:8)  (cid:10) (cid:16)(cid:1)(cid:11) (cid:27)(cid:9)(cid:9) (cid:15)(cid:9)(cid:9)(cid:9)(cid:15)  (cid:2)(cid:20)(cid:9)(cid:16)(cid:9) (cid:1)(cid:6) (cid:27)(cid:9) (cid:2)	 (cid:15)
,(cid:15) (cid:10) (cid:2)(cid:1)(cid:9) (cid:2)  (cid:9)(cid:2)(cid:1) (cid:1) C (cid:8)(cid:1)(cid:11)(cid:10) 	(cid:2)(cid:11) (cid:11)(cid:10)
(cid:11)(cid:20)(cid:11) (cid:5) (cid:10)(cid:11)    (cid:10)(cid:11)  (cid:21) 2E (cid:12) (cid:6) (cid:10)# (cid:9)(cid:9) (cid:15) (cid:10)(cid:15) (cid:2),(cid:16)	
	(cid:10)(cid:1) (cid:20)(cid:11) (cid:3) (cid:1)(cid:11)(cid:24) (cid:9) (cid:11)(cid:10) (cid:2)(cid:11)(cid:9)(cid:2)(cid:22)(cid:1)(cid:16) (cid:11)(cid:1) (cid:2)(cid:15)(cid:1)(cid:1) (cid:1)
(cid:9)(cid:28)(cid:9)(cid:1)(cid:20)(cid:9)(cid:24)  (cid:10)(cid:2)(cid:1)(cid:2)(cid:9) (cid:1) (cid:10)# (cid:14)(cid:9) (cid:14)(cid:9)(cid:9)  	(cid:9) (cid:10) (cid:9)
(cid:14)(cid:10)(cid:9)(cid:15)  (cid:11)(cid:9) (cid:14)(cid:9)(cid:11)(cid:10)(cid:20)(cid:1)	 (cid:6) (cid:6)	(cid:2)(cid:1) (cid:12)(cid:24)

,(cid:25)(cid:26) (cid:11)!(cid:17)(cid:23)(cid:4)(cid:15)(cid:2)  ! (cid:9)(cid:23)(cid:23)(cid:2)(cid:23)(cid:3) (cid:29) (cid:23)

 (cid:9) (cid:11)(cid:10)(cid:20)(cid:9) (cid:9)(cid:9)(cid:15) (cid:27) #(cid:9) (cid:6) (cid:14) (cid:9)= (cid:1)(cid:16) (cid:15)(cid:9) 
(cid:27)(cid:1)(cid:11) (cid:10)(cid:10)(cid:2)(cid:1)(cid:20)(cid:9) (cid:9)(cid:1)(cid:10)  (cid:10)(cid:15) (cid:27)(cid:1)(cid:11) (cid:1)(cid:28)(cid:9)(cid:15) (cid:9)(cid:1)(cid:10) (cid:24)
5(cid:1)(cid:16) (cid:9)	(cid:15)(cid:9) (cid:9)(cid:1)(cid:10)  (cid:27)(cid:9)(cid:9) (cid:16)(cid:9)(cid:9)(cid:10)(cid:9)(cid:15) (cid:10) (cid:1)(cid:15)(cid:9)(cid:9)(cid:15)(cid:9)
(cid:16)(cid:10)	(cid:1)(cid:10)= J(cid:10)(cid:2)(cid:13)(cid:0) J(cid:10)(cid:2)(cid:0) (cid:24)  E(cid:0) E(cid:4)36(cid:1)(cid:24) (cid:10)(cid:1)(cid:27)(cid:1)(cid:9) (cid:9)	
(cid:1)(cid:10)  (cid:27)(cid:9)(cid:9) (cid:9) (cid:10) (cid:6)  (cid:27)= J(cid:10)(cid:2)(cid:13)(cid:13) C J(cid:10)(cid:2)(cid:0)(cid:0) C E J(cid:10)(cid:2)(cid:13)(cid:0) C
J(cid:10)(cid:2)(cid:0)(cid:13) C (cid:26) (cid:27)(cid:11)(cid:9)(cid:9) (cid:26) (cid:27)(cid:10) (cid:16)(cid:9)(cid:9)(cid:10)(cid:9)(cid:15) (cid:10) (cid:5) E(cid:0) 2(cid:5) (cid:6)
(cid:10)(cid:10)(cid:2)(cid:1)(cid:20)(cid:9) (cid:9)(cid:1)(cid:10)  (cid:10)(cid:15) (cid:10)  E(cid:0) 2 (cid:6) (cid:1)(cid:28)(cid:9)(cid:15) (cid:9)	
(cid:1)(cid:10) (cid:24) (cid:25)(cid:11)(cid:9) (cid:1)$(cid:9) (cid:6) (cid:11)(cid:9) (cid:14) (cid:9) (cid:27)(cid:10) 3E(cid:28)3E(cid:24)  (cid:9) (cid:9)(cid:9)(cid:15)
(cid:11)(cid:9) (cid:10) (cid:16)(cid:1)(cid:11)  2EE (cid:10) (cid:9) (cid:14) (cid:9)(cid:24)
+(cid:2)(cid:15)(cid:4)(cid:10)(cid:23) (cid:23)(cid:4)(cid:2)  1(cid:1) (cid:27)(cid:9) (cid:9)(cid:9)(cid:15) (cid:11)(cid:9) (cid:14)(cid:9)	
(cid:11)(cid:10)(cid:20)(cid:1)	 (cid:6) (cid:25)(cid:8) 	- (cid:10) (cid:16)(cid:1)(cid:11) (cid:27)(cid:1)(cid:11) (cid:9)(cid:9)(cid:2)  (cid:11)(cid:9)
(cid:15)(cid:10)(cid:1)(cid:16) (cid:10)(cid:10)(cid:9)(cid:9) (cid:25)(cid:24) 1 (cid:25) C 2  # AE (cid:6) (cid:11)(cid:9)
(cid:1)(cid:10)  (cid:2)(cid:20)(cid:9)(cid:16)(cid:9)(cid:15)7 (cid:11)(cid:27)(cid:9)(cid:20)(cid:9) (cid:6) (cid:10)  (cid:9) (cid:20)(cid:10) 	(cid:9) (cid:6) (cid:25) (cid:11)(cid:9)
(cid:10) (cid:16)(cid:1)(cid:11) (cid:10) (cid:27)(cid:10)# (cid:2)(cid:20)(cid:9)(cid:16)(cid:9)(cid:15)(cid:24) (cid:25)(cid:11)(cid:9) (cid:10)  (cid:9) 	(cid:14)(cid:9) (cid:6)
(cid:1)(cid:9)(cid:10)(cid:1) (cid:27)(cid:10) (cid:10)(cid:2)(cid:11)(cid:1)(cid:9)(cid:20)(cid:9)(cid:15) (cid:10) (cid:25) C E(cid:4)98(cid:24)  (cid:9) 	(cid:9)(cid:15) (cid:11)(cid:1)
(cid:20)(cid:10) 	(cid:9) (cid:6) (cid:11)(cid:9) 	(cid:14)(cid:9)	(cid:9) (cid:9)(cid:28)(cid:9)(cid:1)(cid:9)(cid:24)

(cid:9)(cid:28) (cid:27)(cid:9) (cid:9)(cid:9)(cid:15) (cid:2)(cid:20)(cid:9)(cid:16)(cid:9)(cid:2)(cid:9) (cid:10)(cid:9) (cid:6) (cid:11)(cid:9) (cid:6)	 (cid:10) (cid:16)(cid:1)(cid:11)(cid:24)
(cid:25)(cid:8) 	5 (cid:10)(cid:15) / (cid:2)(cid:20)(cid:9)(cid:16)(cid:9)(cid:15) (cid:1) 2EE (cid:6) (cid:11)(cid:9) (cid:2)(cid:10)(cid:9) (cid:10)(cid:15)
(cid:25)(cid:8) 	(cid:25) (cid:9)(cid:20)(cid:9) (cid:2)(cid:20)(cid:9)(cid:16)(cid:9)(cid:15) (cid:27)(cid:9) (cid:14)(cid:9)(cid:20)(cid:9)(cid:15) (cid:11)(cid:10) (cid:1) (cid:27)(cid:9)
(cid:1) (cid:10)  (cid:24) (cid:25)(cid:11)(cid:9) (cid:10)(cid:20)(cid:9)(cid:10)(cid:16)(cid:9) 	(cid:14)(cid:9) (cid:6) (cid:1)(cid:9)(cid:10)(cid:1) 		
(cid:1)  (cid:2)(cid:20)(cid:9)(cid:16)(cid:9)(cid:2)(cid:9) (cid:27)(cid:10) (cid:10) (cid:6)  (cid:27)= &4(cid:24)2 (cid:6) (cid:25)(cid:8) 	- 32(cid:24)D
(cid:6) (cid:25)(cid:8) 	5 (cid:10)(cid:15) &(cid:24)2 (cid:6) /(cid:24) (cid:9) (cid:11)(cid:10) (cid:1) (cid:1)  (cid:20)(cid:9)# (cid:6)(cid:10)(cid:1)
 (cid:2)(cid:10)(cid:9) (cid:2)(cid:20)(cid:9)(cid:16)(cid:9)(cid:2)(cid:9) (cid:6) (cid:25)(cid:8)  (cid:10) (cid:16)(cid:1)(cid:11) (cid:10)(cid:15) (cid:6)
/ (cid:1)(cid:2)(cid:9) (cid:2)(cid:20)(cid:9)(cid:16)(cid:9)(cid:2)(cid:9) (cid:2)(cid:1)(cid:9)(cid:1)(cid:10) (cid:10)(cid:9) (cid:15)(cid:1)<(cid:9)(cid:9)(cid:24) (cid:9)(cid:28) (cid:9)
(cid:20)(cid:1)(cid:15)(cid:9) (cid:10) (cid:14)(cid:9)(cid:9) (cid:2)(cid:10)(cid:1)(cid:24)

 (cid:11)(cid:1) (cid:9) (cid:27)(cid:9) (cid:9)(cid:10)	(cid:9)(cid:15) (cid:10)(cid:20)(cid:9)(cid:10)(cid:16)(cid:9) (cid:20)(cid:10) 	(cid:9) (cid:6)  (cid:27)(cid:9) (cid:14)	(cid:15)
(cid:12)(cid:1) (cid:10)(cid:15) (cid:9)(cid:9)(cid:16)# (cid:11)(cid:20) (cid:5) J(cid:10) (cid:10) (cid:6)	(cid:2)(cid:1) (cid:6) (cid:1)(cid:9) (cid:6) (cid:11)(cid:9)
, 6E (cid:1)(cid:9)(cid:10)(cid:1)(cid:24) (cid:8)(cid:9)	  (cid:10)(cid:9) (cid:11)(cid:27) (cid:1) 1(cid:1)(cid:16)(cid:24) A(cid:10)(cid:14)(cid:24) 
 (cid:2)(cid:10)(cid:9) (cid:25)(cid:8) 	- (cid:10)(cid:15) (cid:25)(cid:8) 	5 (cid:6)	(cid:15) (cid:10) (cid:1)(cid:10)  	
 	(cid:1) (cid:10)(cid:15) / (cid:6)	(cid:15) (cid:10) (cid:1)(cid:10)   	(cid:1) (cid:6) (cid:10) (cid:10)  (cid:9)
	(cid:14)(cid:9) (cid:6) (cid:2)(cid:10)(cid:9)(cid:24) (cid:25)(cid:8) 	5 (cid:27)(cid:10) (cid:15)(cid:9)(cid:2)(cid:9)(cid:10)(cid:1)(cid:16) (cid:11)(cid:9) (cid:9)(cid:9)(cid:16)#
(cid:6)(cid:10)(cid:9) (cid:11)(cid:10) (cid:11)(cid:9) (cid:11)(cid:9) (cid:10) (cid:16)(cid:1)(cid:11)(cid:24) 5	(cid:1)(cid:1)(cid:16) # (cid:25)(cid:8) 	

400

200

0

−200

−400

TRW−T

200

150

100

BP
TRW−E
TRW−S

−600
0

10

20
(cid:10)

30

40

50

50
0

10

−50

−100

−150

−200

−250

x 105

4.2

4

3.8

3.6

30

40

50

20
(cid:14)

BP
TRW−E
TRW−S

−300
0

50

100
(cid:2)

150

200

0

50

150

200

100
(cid:15)

1(cid:1)(cid:16)	(cid:9) A= 2(cid:23)(cid:9)!  (cid:25)  (cid:4)(cid:28)(cid:2)  (cid:2)(cid:20)(cid:4)5 		
(cid:29)(cid:23) (cid:30) (cid:4)(cid:23)(cid:2)(cid:4)(cid:25) (cid:0)(cid:23)(cid:4)(cid:15)(cid:2)  (cid:2)(cid:20)(cid:4) 	(cid:23) (cid:15)	(cid:10)(cid:23)5
(cid:2)(cid:10)(cid:23)(cid:2)(cid:9)(cid:23) (cid:10)(cid:2) 	(cid:23) (cid:30) (cid:17)(cid:23) (cid:23)(cid:23)(cid:9)! (cid:11)(cid:20) (cid:5) J(cid:10)(cid:25) (cid:0)(cid:23)(cid:4)(cid:15)(cid:2) 
(cid:2)(cid:20)(cid:4)   (cid:23) (cid:15)	(cid:10)(cid:23) (cid:30) ’(cid:27)# (cid:2) (cid:9)(cid:4)(cid:17)5 (cid:2)(cid:10)(cid:23)	
(cid:2)(cid:9)(cid:23) (cid:10)(cid:2) 	(cid:23) (cid:30) (cid:12)(cid:1)(cid:25) (cid:2) (cid:4)(cid:9) (cid:3)(cid:23)  (cid:2)(cid:2)(cid:15)(cid:4)(cid:10)(cid:23)
(cid:23)(cid:4)(cid:2)  ’(cid:27)#	’ (cid:2) (cid:9)(cid:4)(cid:17)(cid:25) (cid:29) (cid:4)(cid:9) (cid:3)(cid:23) 
(cid:2)(cid:2)(cid:15)(cid:4)(cid:10)(cid:23) (cid:23)(cid:4)(cid:2)  (cid:17)(cid:23)(cid:23) (cid:17)(cid:23) (cid:2) (cid:9)(cid:4)(cid:17)(cid:25)
(cid:15) (cid:4)(cid:9) (cid:3)(cid:23)  (cid:4)(cid:20)(cid:23)(cid:3) (cid:23)(cid:4)(cid:2) (cid:25) (cid:3) ’	$	(cid:29)(cid:2)
(cid:3)(cid:2)(cid:2)(cid:23)  (cid:3)(cid:23) (cid:25)

(cid:25) (cid:10) (cid:16)(cid:1)(cid:11) (cid:6)(cid:10)(cid:1) (cid:9)(cid:15) (cid:2) (cid:9)(cid:9) #(cid:24) (cid:9)(cid:20)(cid:9) (cid:1) (cid:15)(cid:9)	
(cid:10)(cid:9)(cid:15) (cid:1)(cid:1) (cid:10) (cid:14)(cid:9)(cid:11)(cid:10)(cid:20)(cid:1)	 (cid:6) (cid:11)(cid:9) (cid:9) (cid:14)(cid:9) (cid:27)  (cid:1) (cid:1)
 (cid:11)(cid:27)(cid:24)

(cid:4)(cid:20)(cid:23)(cid:3) (cid:23)(cid:4)(cid:2)  (cid:25)(cid:11)(cid:9) (cid:14)(cid:9)(cid:11)(cid:10)(cid:20)(cid:1)	 (cid:6) (cid:25)(cid:8) 	- (cid:10)(cid:15)
(cid:25)(cid:8) 	5 (cid:10) (cid:16)(cid:1)(cid:11) (cid:27)(cid:10) 	(cid:14)(cid:10)(cid:1)(cid:10)  # (cid:15)(cid:1)<(cid:9)(cid:9) (cid:6) (cid:11)(cid:9)
(cid:9)(cid:20)(cid:1)	 (cid:2)(cid:10)(cid:9)(cid:24)  (cid:9) (cid:14)(cid:9)(cid:20)(cid:9)(cid:15) (cid:11)(cid:10) (cid:11)(cid:9) (cid:10)  (cid:9) (cid:20)(cid:10) 	(cid:9) (cid:6)
(cid:11)(cid:9) (cid:9)(cid:9)(cid:16)# (cid:27)(cid:10) (cid:10)(cid:2)(cid:11)(cid:1)(cid:9)(cid:20)(cid:9)(cid:15) (cid:10)(cid:6)(cid:9) (cid:10) (cid:10)   	(cid:14)(cid:9) (cid:6) (cid:1)	
(cid:9)(cid:10)(cid:1) 6	2E (cid:10)(cid:15) (cid:10)(cid:6)(cid:9) (cid:11)(cid:10) (cid:11)(cid:9) (cid:9)(cid:9)(cid:16)# (cid:1)(cid:2)(cid:9)(cid:10)(cid:9)(cid:15)(cid:24)
(cid:25)(cid:8) 	- (cid:27)(cid:1)(cid:11) (cid:15)(cid:10)(cid:1)(cid:16) (cid:10)(cid:15) (cid:25)(cid:8) 	5 (cid:10) (cid:27)(cid:10)# (cid:2)(cid:20)(cid:9)(cid:16)(cid:9)(cid:15)
(cid:11)(cid:27)(cid:9)(cid:20)(cid:9) (cid:11)(cid:9) (cid:20)(cid:10) 	(cid:9) (cid:6) (cid:11)(cid:9) (cid:9)(cid:9)(cid:16)# (cid:10) (cid:2)(cid:20)(cid:9)(cid:16)(cid:9)(cid:2)(cid:9) (cid:27)(cid:10)
 (cid:10)(cid:16)(cid:9) (cid:11)(cid:10) (cid:1) (cid:11)(cid:9) (cid:1)(cid:15)(cid:15) (cid:9)(cid:24) (cid:9)(cid:20)(cid:9) (cid:11)(cid:9) (cid:9)(cid:9)(cid:16)# (cid:14)	
(cid:10)(cid:1)(cid:9)(cid:15) (cid:14)# / (cid:27)(cid:10) (cid:10)  (cid:9) (cid:11)(cid:10) (cid:11)(cid:9) (cid:9)(cid:9)(cid:16)# (cid:6) (cid:25)(cid:8)  (cid:10) 	
(cid:16)(cid:1)(cid:11) (cid:15)(cid:9)(cid:1)(cid:9) (cid:11)(cid:9) (cid:6)(cid:10)(cid:2) / (cid:15)(cid:1)(cid:15)  (cid:2)(cid:20)(cid:9)(cid:16)(cid:9)(cid:24) (cid:25)(cid:11)(cid:1)
(cid:14)(cid:9)(cid:11)(cid:10)(cid:20)(cid:1)	 (cid:1) (cid:11)(cid:27) (cid:1) 1(cid:1)(cid:16)(cid:24) A(cid:2)(cid:24) 1 (cid:25)(cid:8) 	- (cid:10) (cid:16)(cid:1)(cid:11)
(cid:27)(cid:9) (cid:1)(cid:2)(cid:22)(cid:9)(cid:15) (cid:9)(cid:1)(cid:1)(cid:2)(cid:10)  # (cid:25) C E(cid:4)4(cid:24)

 (cid:9)(cid:6)(cid:10)(cid:2)(cid:9) (cid:6) (cid:25)(cid:8)  (cid:10) (cid:16)(cid:1)(cid:11) (cid:6) (cid:11)(cid:9) (cid:14) (cid:9)
(cid:27)(cid:1)(cid:11) (cid:1)(cid:28)(cid:9)(cid:15) (cid:9)(cid:1)(cid:10)  (cid:9)(cid:9)(cid:15) (cid:6)	(cid:11)(cid:9) (cid:1)(cid:20)(cid:9)(cid:1)(cid:16)(cid:10)(cid:1)(cid:24)

,(cid:25)(cid:24) (cid:11)(cid:23)(cid:23) (cid:2)(cid:15)(cid:17)(cid:4)(cid:9) (cid:29) (cid:23)

 (cid:9) (cid:11)(cid:10)(cid:20)(cid:9) (cid:9)(cid:9)(cid:15) (cid:11)(cid:9) (cid:10) (cid:16)(cid:1)(cid:11)  (cid:11)(cid:9) (cid:9)(cid:9)(cid:16)# (cid:6)	(cid:2)(cid:1)
(cid:10)(cid:1)(cid:1)(cid:16) (cid:1) (cid:11)(cid:9) (cid:9)(cid:9) (cid:10)(cid:2)(cid:11)(cid:1)(cid:16) (cid:14) (cid:9) %2’(cid:24) (cid:25)(cid:11)(cid:9) (cid:1)	
(cid:1) (cid:27) (cid:1)(cid:10)(cid:16)(cid:9) (cid:10)(cid:22)(cid:9) (cid:6) (cid:15)(cid:1)<(cid:9)(cid:9) (cid:20)(cid:1)(cid:9)(cid:27)(cid:1) (cid:10)(cid:15) (cid:11)(cid:9)
(cid:16)(cid:10)  (cid:1)  ,(cid:15) (cid:10) (cid:15)(cid:1)(cid:10)(cid:1)# (cid:6) (cid:9)(cid:20)(cid:9)# (cid:1)(cid:28)(cid:9)  (cid:1) (cid:11)(cid:9)  (cid:9)(cid:6) (cid:1)	
(cid:10)(cid:16)(cid:9)(cid:24) 5(cid:1)(cid:1) (cid:10) #  %2’ (cid:27)(cid:9) 	(cid:9)(cid:15)  (cid:1)(cid:9)(cid:10)(cid:2)(cid:1) (cid:15)(cid:9) (cid:24)

1881 (cid:25)(cid:8) 	- (cid:10) (cid:16)(cid:1)(cid:11) (cid:27)(cid:9) (cid:1)(cid:2)(cid:22)(cid:9)(cid:15) (cid:9)(cid:1)(cid:1)(cid:2)(cid:10)  # (cid:25) C E(cid:4)96(cid:24)

1(cid:1)(cid:16)(cid:24) A(cid:15) (cid:11)(cid:27) (cid:9)(cid:9)(cid:16)#   (cid:6) (cid:11)(cid:9) (cid:25)	(cid:22)	(cid:14)(cid:10) (cid:15)(cid:10)(cid:10)(cid:9)
	(cid:9)(cid:15) (cid:1) %2’(cid:24) (cid:9)(cid:2)(cid:1)(cid:9) 	(cid:14)(cid:9) (cid:10)(cid:9) (cid:10) (cid:6)  (cid:27)=

(cid:14) (cid:16)(cid:17)

	(cid:21)(cid:22) (cid:25) (cid:26)(cid:22)(cid:14)(cid:26)

(cid:22)(cid:29)(cid:14)(cid:26) (cid:31)(cid:22)  (cid:0)!

#

%&’	)

%&’	*

(cid:8)

(cid:0)(cid:10)

(cid:10)(cid:8)

(cid:1)(cid:9)(cid:10)

(cid:0)(cid:13)(cid:1)(cid:8)

(cid:8)(cid:12)(cid:8)(cid:11)"

(cid:1)"(cid:12)(cid:0)(cid:9)

(cid:11)(cid:0)"
(cid:1)"(cid:12)(cid:0)(cid:9) (cid:1)"(cid:12)(cid:0)(cid:9) (cid:1)"(cid:12)(cid:0)(cid:9)

(cid:0)(cid:13)(cid:11)(cid:7)(cid:7)(cid:9)(cid:11) (cid:0)(cid:11)(cid:9)(cid:8)(cid:7)(cid:7) (cid:0)(cid:11)(cid:8)(cid:11)(cid:9)
(cid:12)(cid:12)"
	(cid:1)"(cid:8)(cid:0)(cid:12)(cid:17)(cid:13) 	(cid:12)"(cid:10)(cid:10)(cid:17)(cid:9) 	(cid:0)(cid:13)(cid:9)(cid:12)(cid:17)(cid:11) 	(cid:1)(cid:10)(cid:17)(cid:12) 	(cid:13)(cid:17)(cid:8)(cid:11)
(cid:10)(cid:8)(cid:7)

"(cid:13)(cid:9)

(cid:8)(cid:10)(cid:7)

(cid:7)(cid:13)(cid:10)(cid:10)(cid:7)
(cid:0)(cid:13)(cid:0)(cid:13)(cid:0)
	(cid:9)(cid:8)"(cid:10)(cid:17)(cid:13) 	(cid:0)(cid:0)(cid:12)"(cid:17)(cid:13)

(cid:1)(cid:8)(cid:10)(cid:9)
	"(cid:1)(cid:17)(cid:11)

	(cid:13)(cid:17)(cid:13)(cid:9)(cid:11)

(cid:13)

(cid:25) (cid:27) (cid:11)(cid:27) (cid:11)(cid:9) (cid:20)(cid:10) 	(cid:9) (cid:6) (cid:11)(cid:9) (cid:9)(cid:9)(cid:16)# (cid:14) (cid:27)
(cid:6) (cid:25)(cid:8) 	- (cid:10)(cid:15) (cid:25)(cid:8) 	5 	 (cid:11)(cid:9) (cid:20)(cid:10) 	(cid:9) (cid:6)  (cid:27)(cid:9) (cid:14)	(cid:15)
(cid:12)(cid:1)(cid:24) (cid:9) (cid:11)(cid:10) (cid:27)(cid:9) 	(cid:14)(cid:10)(cid:2)(cid:9)(cid:15) 46AA64 (cid:6) (cid:10)   (cid:20)(cid:10) 	
	(cid:9) 	 (cid:1) (cid:10)(cid:9)(cid:10)  (cid:14)(cid:9) (cid:11)(cid:9) (cid:10)(cid:28)(cid:1)	 (cid:6) (cid:14) (cid:9) A(cid:24)
(cid:18)(cid:1)(cid:16) (cid:10) (cid:15)(cid:1)<(cid:9)(cid:9) (cid:1)(cid:1)(cid:1)(cid:10) (cid:1)$(cid:10)(cid:1) (cid:6) (cid:25)(cid:8) 	5 (cid:10) (cid:16)(cid:1)(cid:11)
(cid:27)(cid:9) (cid:27)(cid:9)(cid:9) (cid:10)  (cid:10)(cid:14) (cid:9)  (cid:14)(cid:10)(cid:1) (cid:10) (cid:2),(cid:16)	(cid:10)(cid:1) (cid:27)(cid:1)(cid:11) (cid:9)(cid:9)(cid:16)#
46AA642E4(cid:24)

(cid:25)(cid:8) 	5 (cid:10) (cid:16)(cid:1)(cid:11) (cid:1) (cid:10) (cid:2) (cid:9)(cid:10) (cid:27)(cid:1)(cid:9) 	 (cid:1) (cid:15)(cid:9)(cid:2)(cid:9)(cid:10)(cid:9) (cid:11)(cid:9)
(cid:9)(cid:9)(cid:16)# (cid:9) (cid:10)(cid:1)(cid:15) # (cid:11)(cid:10) (cid:11)(cid:9) (cid:11)(cid:9) (cid:10) (cid:16)(cid:1)(cid:11)(cid:24) (cid:25)(cid:11)(cid:9)
(cid:9)(cid:2)(cid:15) (cid:14)(cid:9) (cid:1) (cid:25)(cid:8) 	- (cid:10) (cid:16)(cid:1)(cid:11) (cid:27)(cid:1)(cid:11) (cid:15)(cid:10)(cid:1)(cid:16) (cid:10) 	
(cid:11)	(cid:16)(cid:11) (cid:1) (cid:11)(cid:9) (cid:14)(cid:9)(cid:16)(cid:1)(cid:1)(cid:16) (cid:11)(cid:9) (cid:9)(cid:9)(cid:16)# (cid:15)(cid:9)(cid:2)(cid:9)(cid:10)(cid:9) (cid:9)
 (cid:27) # (cid:11)(cid:10) (cid:11)(cid:9) (cid:9)(cid:9)(cid:16)# (cid:6) /(cid:24) 	 (cid:10) (cid:16)(cid:1)(cid:11) (cid:14)(cid:10)(cid:1)
 (cid:27)(cid:9) (cid:9)(cid:9)(cid:16)# (cid:11)(cid:10) / (cid:10)(cid:15)  (cid:1)(cid:16)(cid:11) #  (cid:27)(cid:9) (cid:9)(cid:9)(cid:16)# (cid:11)(cid:10)
(cid:11)(cid:9) (cid:9)(cid:28)(cid:10)(cid:1) (cid:20)(cid:9) (cid:10) (cid:16)(cid:1)(cid:11) %2’(cid:24)

(cid:29) (cid:30)(cid:13)(cid:6)	(cid:13) (cid:5)(cid:11) (cid:6)(cid:6) 	(cid:13)

 (cid:9) (cid:11)(cid:10)(cid:20)(cid:9) (cid:15)(cid:9)(cid:20)(cid:9) (cid:9)(cid:15) (cid:10) (cid:9)(cid:27) (cid:10) (cid:16)(cid:1)(cid:11) (cid:27)(cid:11)(cid:1)(cid:2)(cid:11) (cid:2)(cid:10) (cid:14)(cid:9)
(cid:20)(cid:1)(cid:9)(cid:27)(cid:9)(cid:15) (cid:10) (cid:10) (cid:9)(cid:11)(cid:15) (cid:6) (cid:15)(cid:1)(cid:9)(cid:2) (cid:10)(cid:28)(cid:1)(cid:1)$(cid:10)(cid:1) (cid:6) (cid:14)@(cid:9)(cid:2)	
(cid:1)(cid:20)(cid:9) (cid:6)	(cid:2)(cid:1) (cid:12) 	(cid:14)@(cid:9)(cid:2)  (cid:11)(cid:9) (cid:2)(cid:10)(cid:1) (cid:6) (cid:14) (cid:9) A(cid:24)
 (cid:9) (cid:16)(cid:10)(cid:20)(cid:9) (cid:10) (cid:9)(cid:2)(cid:1)(cid:9) (cid:2)(cid:11)(cid:10)(cid:10)(cid:2)(cid:9)(cid:1)$(cid:10)(cid:1) (cid:6)  (cid:2)(cid:10)  (cid:10)(cid:28)(cid:1)(cid:10) (cid:6)
(cid:11)(cid:1) (cid:6)	(cid:2)(cid:1) (cid:27)(cid:1)(cid:11) (cid:9)(cid:9)(cid:2)  (cid:25)(cid:8) 	5 (cid:10) (cid:16)(cid:1)(cid:11)(cid:24)  (cid:9)
(cid:11)(cid:27)(cid:9)(cid:15) (cid:11)(cid:10) (cid:11)(cid:9) (cid:10) (cid:16)(cid:1)(cid:11) (cid:1) (cid:16)	(cid:10)(cid:10)(cid:9)(cid:9)(cid:15)  (cid:11)(cid:10)(cid:20)(cid:9) (cid:10) 	(cid:14)	
(cid:9)	(cid:9)(cid:2)(cid:9) (cid:2)(cid:20)(cid:9)(cid:16)(cid:1)(cid:16)  	(cid:2)(cid:11) (cid:10) (cid:10)(cid:28)(cid:1)	(cid:24)

: (cid:10)   (cid:9)(cid:9)	(cid:9)(cid:27)(cid:9)(cid:1)(cid:16)(cid:11)(cid:9)(cid:15) (cid:10) (cid:16)(cid:1)(cid:11) 	 (cid:9)(cid:11)(cid:15) (cid:1) 
(cid:16)	(cid:10)(cid:10)(cid:9)(cid:9)(cid:15)  ,(cid:15) (cid:10) (cid:12) (cid:19)(cid:8)  (cid:10)(cid:28)(cid:1)	(cid:24) (cid:9)(cid:20)(cid:9)(cid:11)(cid:9) (cid:9)
(cid:9)(cid:28)(cid:9)(cid:1)(cid:9)(cid:10)  (cid:9)	  	(cid:16)(cid:16)(cid:9) (cid:11)(cid:10) (cid:11)(cid:1) (cid:1)  (cid:10) (cid:1)	(cid:9)
(cid:6) (cid:2)(cid:9)(cid:10)(cid:1) #(cid:11)(cid:9)(cid:1)(cid:2) (cid:10)(cid:15) (cid:9)(cid:10)  (cid:14) (cid:9)(cid:24) 1 (cid:11)(cid:9) (cid:9)(cid:9)
(cid:10)(cid:2)(cid:11)(cid:1)(cid:16) (cid:14) (cid:9) (cid:27)(cid:9) (cid:27)(cid:9)(cid:9) (cid:10)(cid:14) (cid:9)  (cid:14)(cid:10)(cid:1)  (cid:1)(cid:16)(cid:11) #  (cid:27)(cid:9)
(cid:9)(cid:9)(cid:16)# (cid:11)(cid:10) (cid:11)(cid:9) (cid:9)(cid:28)(cid:10)(cid:1) (cid:20)(cid:9) (cid:10) (cid:16)(cid:1)(cid:11) %2’ (cid:27)(cid:11)(cid:1)(cid:2)(cid:11) (cid:1)
(cid:2)(cid:1)(cid:15)(cid:9)(cid:9)(cid:15)  (cid:14)(cid:9) (cid:11)(cid:9)  (cid:10)(cid:2)(cid:2)	(cid:10)(cid:9) (cid:9)(cid:9)(cid:16)# (cid:1)(cid:1)(cid:1)$(cid:10)	
(cid:1) (cid:9)(cid:2)(cid:11)(cid:1)	(cid:9) (cid:6) 	(cid:2)(cid:11) (cid:14) (cid:9)(cid:24) (cid:25)(cid:8) 	5 (cid:10) (cid:16)(cid:1)(cid:11)
	(cid:9)(cid:6) (cid:14)(cid:11) (cid:25)(cid:8)  (cid:10) (cid:16)(cid:1)(cid:11) (cid:1) %&’ (cid:10)(cid:15) (cid:11)(cid:9) 	
(cid:15)(cid:1)(cid:10)# (cid:10)(cid:28)	(cid:15)	(cid:2) /(cid:24)

	 (cid:10) (cid:16)(cid:1)(cid:11) (cid:2)(cid:10) (cid:14)(cid:9) (cid:1) (cid:9)(cid:9)(cid:9)(cid:15) (cid:9)Æ(cid:2)(cid:1)(cid:9) #  # (cid:6)
(cid:10) (cid:10)(cid:1)(cid:2)	 (cid:10) (cid:2)(cid:11)(cid:1)(cid:2)(cid:9) (cid:6) (cid:9)(cid:9)(cid:24) 1	(cid:10)(cid:9) # (cid:11)(cid:1)(cid:16) (cid:9)	
(cid:20)(cid:9) 	 (cid:6) 	(cid:1)(cid:16) (cid:11)(cid:1) (cid:2)(cid:11)(cid:1)(cid:2)(cid:9) 	 (cid:11)(cid:9) (cid:1)(cid:10)  (cid:20)(cid:10) 	(cid:9) (cid:6)
(cid:11)(cid:9)  (cid:27)(cid:9) (cid:14)	(cid:15) (cid:15)(cid:9)  (cid:15)(cid:9)(cid:9)(cid:15)  (cid:1)(cid:24)

 	 (cid:9)(cid:28)(cid:9)(cid:1)(cid:9) (cid:27)(cid:9) (cid:1)(cid:2)(cid:9)(cid:15) (cid:11)(cid:10) (cid:25)(cid:8) 	5 (cid:10) (cid:16)(cid:1)(cid:11)
(cid:27)	 (cid:15) (cid:10) (cid:27)(cid:10)# (cid:2)(cid:20)(cid:9)(cid:16)(cid:9)  (cid:10) ,(cid:28)(cid:9)(cid:15) (cid:1) (cid:6) (cid:25)(cid:8)  (cid:10) 	
(cid:11)	(cid:16)(cid:11) 	(cid:2)(cid:11) (cid:2)(cid:20)(cid:9)(cid:16)(cid:9)(cid:2)(cid:9) (cid:27)	 (cid:15) 		(cid:10)  # (cid:10)(cid:22)(cid:9) 	(cid:2)(cid:11)

 (cid:16)(cid:9) (cid:11)(cid:10) (cid:10)(cid:2)(cid:11)(cid:1)(cid:9)(cid:20)(cid:1)(cid:16) (cid:10) (cid:27)(cid:9)(cid:10)(cid:22) (cid:9)(cid:9) (cid:10)(cid:16)(cid:9)(cid:9)(cid:9)(cid:24)  (cid:27)	
(cid:9)(cid:20)(cid:9) (cid:27)(cid:9) (cid:11)(cid:10)(cid:20)(cid:9)  (cid:14)(cid:9)(cid:9) (cid:10)(cid:14) (cid:9)  (cid:20)(cid:9) (cid:11)(cid:1) (cid:16)(cid:9)(cid:9)(cid:10)  (cid:2)	
(cid:20)(cid:9)(cid:16)(cid:9)(cid:2)(cid:9)(cid:24)  (cid:11)(cid:9) (cid:11)(cid:9) (cid:11)(cid:10)(cid:15) (cid:1) (cid:10)(cid:2)(cid:1)(cid:2)(cid:9) (cid:1) (cid:15)(cid:9) 
(cid:10)(cid:22)(cid:9) 	(cid:2)(cid:11) (cid:9)(cid:9)  	 (cid:11)(cid:9) (cid:10) (cid:16)(cid:1)(cid:11) (cid:10)(cid:6)(cid:9)  (cid:25):
(cid:11)(cid:10) (cid:14)(cid:9)(cid:9) (cid:10)(cid:2)(cid:11)(cid:1)(cid:9)(cid:20)(cid:9)(cid:15) (cid:1)(cid:2)(cid:9) (cid:6)	(cid:2)(cid:1) (cid:12) (cid:10)(cid:15) (cid:9) (cid:1)	
(cid:10) # (cid:11)(cid:9) 		 (cid:2),(cid:16)	(cid:10)(cid:1) (cid:27)(cid:1)    (cid:2)(cid:11)(cid:10)(cid:16)(cid:9)(cid:24)

 (cid:11)(cid:9) (cid:6)		(cid:9) (cid:27)(cid:9)  (cid:10)  (cid:9)(cid:28)(cid:9)(cid:15) (cid:9)(cid:2)(cid:11)(cid:1)	(cid:9) (cid:9)(cid:15)
(cid:1) (cid:11)(cid:1) (cid:10)(cid:9)  		(cid:15)	(cid:2) (cid:25)(cid:8)  (cid:10) (cid:16)(cid:1)(cid:11) %9’(cid:24)

+(cid:15)$  (cid:23)(cid:3)(cid:9)(cid:23)(cid:23)

 (cid:27)	 (cid:15)  (cid:1)(cid:22)(cid:9)  (cid:11)(cid:10)(cid:22) (cid:25)(cid:11)(cid:10) (cid:1)(cid:22)(cid:10) (cid:6) (cid:11)(cid:9) (cid:6)	  (cid:15)(cid:1)	
(cid:2)	(cid:1)(cid:24)

(cid:27)(cid:23)(cid:30)(cid:23)(cid:23)(cid:15)(cid:23)

(cid:2)(cid:5)(cid:7) 5(cid:19) +(cid:30)#(cid:28) (cid:19) 7(cid:12)# (cid:12) (cid:9)(cid:18) ’(cid:19) 8(cid:9),(cid:14)(cid:24)(cid:19) 9(cid:9) (cid:9)%	
(cid:14)(cid:9)(cid:12) (cid:12)(cid:12)(cid:27)(cid:30) (cid:14)(cid:14)(cid:14)(cid:25)(cid:9)(cid:14) (cid:28)(cid:14)(cid:9) (cid:27)(cid:9)(cid:24) (cid:16)	(cid:19) (cid:17)
3:(cid:5)(cid:5) (cid:28)(cid:12),(cid:12) 3(cid:6)(cid:6)(cid:5)(cid:19)

(cid:2)3(cid:7) (cid:19)9(cid:19) 9(cid:12) (cid:25)(cid:12)(cid:25)(cid:31)(cid:9) , (cid:9)(cid:18) ;(cid:19)(cid:19)  	(cid:12) (cid:16)(cid:24)(cid:12)(cid:19) <Æ(cid:16)(cid:14)(cid:12)

,(cid:12) (cid:14)(cid:12)(cid:26) (cid:9)(cid:27)(cid:9)(cid:14) (cid:26) (cid:12)(cid:9) (cid:30) (cid:28)(cid:14)(cid:14)(cid:19) (cid:20)(cid:21)(cid:22) 3(cid:6)(cid:6)=(cid:19)

(cid:2):(cid:7) &(cid:19)  (cid:12)#(cid:12) (cid:19) ? ,(cid:12) (cid:9)(cid:18) +(cid:19) (cid:9)(cid:12)(cid:19) ?%(cid:14)(cid:9)(cid:12)

(cid:14)(cid:26)(cid:12)(cid:12)(cid:16)(cid:12) (cid:9)(cid:18) (cid:16)(cid:9)(cid:14)(cid:12)(cid:18) (cid:14)(cid:14)(cid:25)(cid:9)(cid:14)(cid:19) (cid:23)(cid:17) 3(cid:6)(cid:6):(cid:19)

(cid:2)=(cid:7) 7(cid:19)  (cid:27)(cid:28)(cid:19) @(cid:28)(cid:12)(cid:27)(cid:12) (cid:12)(cid:12)	(cid:12)(cid:31)(cid:12)(cid:14)(cid:27)(cid:24)(cid:12)(cid:18) (cid:12)	
(cid:9)(cid:27)(cid:12) (cid:9)(cid:14)(cid:27) (cid:26) (cid:12)(cid:12)(cid:27)(cid:30) (cid:14)(cid:14)(cid:14)(cid:25)(cid:9)(cid:14)(cid:19) &(cid:12)(cid:16)(cid:24)(cid:14)(cid:16)(cid:9)  ’(cid:12)	
 B’	&’	3(cid:6)(cid:6)=	C(cid:6) (cid:14)(cid:26) ’(cid:12)(cid:12)(cid:9)(cid:16)(cid:24) B(cid:12)(cid:12)	
,(cid:12) 3(cid:6)(cid:6)=(cid:19)

(cid:2)"(cid:7) 5(cid:19)(cid:20)(cid:19) &(cid:12)(cid:24) (cid:9)(cid:18) (cid:19) (cid:20)(cid:12)  (cid:14)(cid:27)(cid:19) &(cid:24)(cid:12) 	(cid:14)D(cid:12)(cid:18) (cid:9)(cid:27)(cid:9)(cid:14)

(cid:9)(cid:18) (cid:16)(cid:9) (cid:14)(cid:27) (cid:9) (cid:27)(cid:14)(cid:24)(cid:19) (cid:25) 3(cid:6)(cid:6)3(cid:19)

(cid:2)E(cid:7) (cid:19)(cid:19) (cid:20)(cid:9)(cid:14)(cid:31)(cid:14)(cid:27)(cid:24) &(cid:19)B(cid:19) (cid:9)(cid:9)## (cid:9) (cid:9)(cid:18) ?(cid:19)B(cid:19) (cid:20)(cid:14)  #(cid:30)(cid:19) ?
(cid:12)(cid:31) (cid:16) (cid:9) (cid:26) 	(cid:12) ,	(cid:18)  (cid:24)(cid:12)  (cid:27) (cid:9)(cid:14)(cid:14) (cid:26)	(cid:16)	
(cid:14)(cid:19) (cid:23)(cid:17) 3(cid:6)(cid:6)3(cid:19)

(cid:2)(cid:29)(cid:7) (cid:19)(cid:19) (cid:20)(cid:9)(cid:14)(cid:31)(cid:14)(cid:27)(cid:24) &(cid:19)B(cid:19) (cid:9)(cid:9)## (cid:9) (cid:9)(cid:18) ?(cid:19)B(cid:19) (cid:20)(cid:14)  	
#(cid:30)(cid:19) ? (cid:12)(cid:14)(cid:9)(cid:14) (cid:28)(cid:14)(cid:9) (cid:9)(cid:27)(cid:12)(cid:12)(cid:12)  (cid:24)(cid:30)(cid:12)(cid:12)(cid:12)-
(cid:12)(cid:9)(cid:27)(cid:12)	(cid:9)(cid:14)(cid:27) (cid:9)(cid:18)  (cid:14)(cid:12)(cid:9)	(cid:27)(cid:9)(cid:14)(cid:27) (cid:9)(cid:9)(cid:16)(cid:24)(cid:12)(cid:19)
&(cid:12)(cid:16)(cid:24)(cid:14)(cid:16)(cid:9)  ’(cid:12) G@+H@B;	(cid:6):	(cid:5)3EC G@ +(cid:12)#(cid:12) (cid:12)(cid:30)
@B ;(cid:14)(cid:28)(cid:14)(cid:14) ?	(cid:27)	 3(cid:6)(cid:6):(cid:19)

(cid:2)(cid:3)(cid:7) (cid:19)(cid:19) (cid:20)(cid:9)(cid:14)(cid:31)(cid:14)(cid:27)(cid:24) &(cid:19)B(cid:19) (cid:9)(cid:9)## (cid:9) (cid:9)(cid:18) ?(cid:19)B(cid:19) (cid:20)(cid:14)  #(cid:30)(cid:19)
&(cid:12)(cid:12)	,(cid:9)(cid:12)(cid:18) (cid:12)(cid:9)(cid:9)(cid:12)(cid:12)(cid:14)(cid:25)(cid:9)(cid:14) (cid:26)(cid:9)(cid:12)(cid:31)# (cid:26) (cid:9)(cid:9) (cid:30)(cid:14)
(cid:26) 		(cid:18)	(cid:16) (cid:9)(cid:18) (cid:12) (cid:9)(cid:12)(cid:18) (cid:9) (cid:27)(cid:14)(cid:24)(cid:19) (cid:26)(cid:26)(cid:26) (cid:27)(cid:7)	
(cid:7)(cid:13)(cid:6)  (cid:28)(cid:7)(cid:6) (cid:27)(cid:29)(cid:0)(cid:30) ="C-(cid:5)(cid:5)3(cid:6)I(cid:5)(cid:5)=E (cid:9)(cid:30)
3(cid:6)(cid:6):(cid:19)

(cid:2)C(cid:7) (cid:19)(cid:19) (cid:20)(cid:9)(cid:14)(cid:31)(cid:14)(cid:27)(cid:24) &(cid:19)B(cid:19) (cid:9)(cid:9)## (cid:9) (cid:9)(cid:18) ?(cid:19)B(cid:19) (cid:20)(cid:14)  #(cid:30)(cid:19)
&(cid:12)(cid:12)	(cid:12)(cid:31)(cid:12)(cid:14)(cid:27)(cid:24)(cid:12)(cid:18) ,(cid:12) (cid:14)(cid:12)(cid:26) (cid:9)(cid:27)(cid:9)(cid:14) (cid:9)(cid:18) (cid:9)%(cid:14)(cid:9)(cid:12)
 (cid:12)(cid:14)(cid:9)(cid:14) ,(cid:30) (cid:12)	(cid:18)	(cid:12) (cid:9)(cid:16)(cid:24)(cid:14)(cid:27)(cid:19) (cid:17)(cid:25)	
(cid:27)(cid:17)(cid:27)(cid:25) 3(cid:6)(cid:6):(cid:19)

(cid:2)(cid:5)(cid:6)(cid:7) (cid:19)(cid:19) (cid:20)(cid:9)(cid:14)(cid:31)(cid:14)(cid:27)(cid:24) &(cid:19)B(cid:19) (cid:9)(cid:9)## (cid:9) (cid:9)(cid:18) ?(cid:19)B(cid:19) (cid:20)(cid:14)  #(cid:30)(cid:19)
&(cid:12)(cid:12) (cid:16)(cid:14)(cid:12)(cid:16)(cid:30) (cid:9)(cid:18) ,	(cid:18)  (cid:24)(cid:12) (cid:12)(cid:26)(cid:9)(cid:16)(cid:12) (cid:26)
(cid:24)(cid:12) (cid:9)%	(cid:18)	(cid:16) (cid:9) (cid:27)(cid:14)(cid:24) (cid:9)(cid:18) (cid:14) (cid:27)(cid:12)(cid:12)(cid:9) (cid:14)(cid:25)(cid:9)(cid:14)(cid:19)
(cid:25)(cid:7)(cid:6)(cid:6)(cid:13) (cid:7)(cid:31) (cid:20)	(cid:6)(cid:15) (cid:5)=3-(cid:5)=:I(cid:5)EE ?(cid:14)  3(cid:6)(cid:6)=(cid:19)

(cid:2)(cid:5)(cid:5)(cid:7) (cid:20)(cid:19) (cid:20)(cid:14)(cid:12)(cid:27)(cid:12)(cid:14)(cid:16)# (cid:9)(cid:18) &(cid:19)  (cid:12)#(cid:12)(cid:19) 9(cid:9)(cid:16)(cid:14)(cid:9)  ,(cid:12) (cid:14)(cid:12)(cid:26) 	

(cid:9)(cid:27)(cid:9)(cid:14)(cid:19) (cid:25) 3(cid:6)(cid:6)(cid:6)(cid:19)

(cid:2)(cid:5)3(cid:7) (cid:19)B(cid:19) 5(cid:12)(cid:18)(cid:14)(cid:18)(cid:14)(cid:9) (cid:20)(cid:19)&(cid:19) 9(cid:12)(cid:12)(cid:9) (cid:9)(cid:18) 5(cid:19)(cid:20)(cid:12)(cid:14)(cid:19) J(cid:12)(cid:12)(cid:9) 	

(cid:14)(cid:25)(cid:12)(cid:18) ,(cid:12) (cid:14)(cid:12)(cid:26) (cid:9)(cid:27)(cid:9)(cid:14)(cid:19) (cid:25) 3(cid:6)(cid:6)(cid:6)(cid:19)

(cid:2)(cid:5):(cid:7) ?(cid:19)(cid:19) 5	(cid:14)  (cid:12)(cid:19) @@@ (cid:9) (cid:27)(cid:14)(cid:24)  (cid:14)(cid:14)(cid:14)(cid:25)(cid:12) (cid:24)(cid:12) +(cid:12)(cid:24)(cid:12)
(cid:9)(cid:18) (cid:14)#	(cid:16)(cid:24)(cid:14) (cid:26)(cid:12)(cid:12) (cid:12)(cid:12)(cid:27)(cid:14)(cid:12)- @(cid:28)(cid:12)(cid:27)(cid:12) (cid:9) (cid:12)(cid:9)(cid:14)(cid:28)(cid:12)
 ,(cid:12) (cid:14)(cid:12)(cid:26) (cid:9)(cid:27)(cid:9)(cid:14)(cid:19) (cid:0)	(cid:7)  (cid:20)	(cid:7)(cid:6) (cid:5)=-(cid:5)EC(cid:5)I
(cid:5)(cid:29)33 3(cid:6)(cid:6)3(cid:19)

189190191192193194195196197 
		

! "#$%	&!'()+*,-	,/.0)213)	4)

FHGEIJGLKNM%FHOQP'R>S>GJTUGJVXWYPMLT[Z\SC]^K_WUK_`>K_O&MEKa=RCWbP!MLVXG

56879;:=<>9?8@A6CBED
a=R>WYPMXVXGdceZgfihJjXhJkel
monepJqoq[rLs>t,u^vJwex

 ¢¡£X¤¥>¦§8¤

O©¨>NO!]_OSeK%MXS3MLTbVXGJ_WUK_R>ªc«_¬­_GJ®>WUSCVJ¯>cR>WYP'R
NO!°`dP(O!]&TUOQMLNS>WUSCVMXS±O!]^K_Wbª²MLK_GJ&GL³P(TYMX]N]¨>NGX®´
MX®>WUTbWUKgIµª¶O!ª·®8O']^RCWU¨¸K_G¶TUOQMLNS>WbS>V%®CWUSCMX_IµPTbMJ]_]_W¹´
O!N]!»FR>O¸_OQ°`CP(K_WbGXS3P(GJª²O!]&WUK_R¼MK_RCOGXNO(KNW¹´
P!MLT­VJ`CML'MLSeKNOOX½¶M0]_ª²MXTUT=ON_GJNMLK_Oµ³¾GJ·®>WbSCMX_I
PTbMJ]_]_W
PMEKNWUGJS¢WUª²¨>TbWUOQ]©MJPP(`CNMLK_OO!]^K_WbªµMEK_WbGXS;GX³
PTbMJ]_]¿ª²Oª%®dO!N]_R>Wb¨¨C_GJ®CML®>WbTbW¹KNWUOQ]ÀO±KNO!]^K_OQ°
GJ`>µ_OQ°`CP(K_WbGXSÁGXS¢]^O!ÂXO'MLT°>MLKNMX]_O(K']²W¹KNR;]^O!ÂJ´
O!NMXTPTbMJ]_]_W
O¿TUOQMLNS>WUSCVÃMLTbVXGJ_WUK_R>ªµ]!ÄFR>ONO(´
]_`>TUKN]¶]^R>GE]^K_NGXS>V0¨8O_³¾GXNªµMLSCPOÅMX]%P(GXª²¨CMX_OQ°
KNGGXK_R>O!4P(GJª¶ª²GJS%ª²O(KNR>G°>],³¾GJGX®K'MLWbS>WUSCVPTbMJ]_]
ª²Oª%®dO!N]_R>Wb¨¨>_GJ®CML®CWUTbW¹KgI¸O!]^K_WbªµMEK_OQ]³¾NGXªÆPTbMJ]g´
]_W

O']

ÈJÉ

¤¥>ÊËÌ§8¤>Í^Ê

y¶<>|QÎ?CBE68Ï9D­Ð)a=TYMX]N]^W
OTbO!MX_SCWUS>VWY]KNR>O¨>NGX®>TbOª#GL³[WUS´
°`CPWUSCV¸Mµ¨>NO!°>WbP(K_GX³¾GX°Wb]^K_WbS>VJ`>Wb]_R>WbS>V©®8O(KgÑOO!SKgÑG»Ò¾GJ
M³¾O!Ó4P(TYMX]N]_O!]4VJWUÂJOSÅM&]_O(K=GL³TYML®8OTbO!°²KNNMXWUS>WbS>V&OÔ>MLª²¨>TbO!]!
FR>O!_OÑMLNO­ªµMLSoI_OQMX]_GXSC]³¾GX,P(GJSC]^WY°O!_WbS>VPTbMJ]_]_W
OHTbO!MX_S>´
WbS>V·MX]4K_R>OÕª²GJ]^K4³¾`>SC°>MXª²OSeKNMXTCTbO!MLNS>WbS>VK'MX]_8,¬4NO!°>WbP(K_WbS>V
GXSCO&®>WUK²ÒÖGXÕMµ³¾O×®>WUKN]'Ó)WY]MJ]]_WUª²¨>TbO%MJ])S>GJS´ØK_NWUÂoWYMLTH¨C_O´
°WYP/KNWUGJSÙPMLS¢®8OXÚÑO!PMX`C]_OGL³K_R>WY]©]_WUª²¨>TbWYP(WUKgIXcP(TYMX]N]^W
O!
TbO!MLNS>WbS>VWb]·GL³ÛKNOSiª²GXNOÅMLª²OSdML®>TbO²K_G0]^K_`C°>I»KNRCMLSiGXK_R>O!
TbO!MLNS>WbS>VÅ¨>NGX®CTUO!ª²]!&ÜÕSK_R>O¶¨>'MXP(K_WYPMLT]^WY°OJc[]_OÂJO'MLTH³ÖMX]^K
TbO!MLNS>WbS>V3MLTbVXGJ_WUK_RCª²]Ò{]^`dP'RÙMX]©ÝoÞàßU!kâáAc®dGoGe]gKNWUS>VÙß
hEá
GXS¼°O!PWb]_WUGJS±K_NOOQ]¸ßUãEáAc4MLSd°iS>O`CNMXT­S>OKg=GJ_]Åß
Eá¾ÓOÔoWY]^K
O']W¹KNRiO(Ô>P(O!TUTbOSeK·¨C_O´
R>WYP'RiVXO!S>O'MLTbTUI»TUOQMX°K_G»PTbMJ]_]_W
°WYP/KNWUÂJO¨dO!^³¾GJ_ªµMLSdP(OX
7åÚæBâ6dç,èÖåoé;Ð#ÜÕSÁK_R>O»GLK_RCOÅRCMXSC°êcKNR>ONO0MLNO0]^O!Âe´
O'MLT8NO!MLTU´A=GJ_TY°µML¨>¨CTUWYPMLK_WbGXSC]=_OQëe`>WUNWbS>V·¨>NGX®dML®>WbTUWY]^K_WYPMLS>´
]_=O!N]WbSC]^K_OQMX°GL³4°WY]NP(NO(K_O%P(TYMX]N]TbMX®dO!Tb]!)ì>GJOÔMXª²¨>TUOJcCWbS
ª²O!°WYPMXT°GXªµMLWbSC]!c­°GP/KNGX']¶GL³ÛK_O!S¼¨C_O³¾O%K_G±ªµMLXO¿°O!PW¹´
]_WUGJSC]&®CMJ]^OQ°i`>¨8GXS3¨C_GJ®CML®>WbTbWb]^K_WYPµ¨>NO!°WYP/KNWUGJSC]&GX³K_R>O¿¨CML´
K_WbOSeK&]^KNMEKNOXcê'MEKNR>OÕK_RCMXS®8OWbS>V¿VXWbÂXO!SM¿°Wb]NP(NO(KNO¶P'RCGJ]_OS
MXP(K_WbGXS³¾GJO!MJP'R¨CMEKNWUO!SJKQí4ÂJOSR>O!SK_R>O¶MXP(K_`CMXTH¨>NGX®CML´
®>WbTUWUKgIO!]^K_Wbª²MLK_OQ]&MLNO²S>GLK&NO!ëe`>Wb_OQ°êcM'MLSCeWbS>VGX³ÑOÔMXª¶´
¨>TbO!]%³¾NGXªK_R>O¿ª²GJ]^K¶TbWbXOTbI±ª²Oª·®8O¶KNG0K_RCO¸TbO!MJ]gK²TUWbXO!TUI
ª²Oª%®dO!GL³MÅPTbMJ]_]ªµMâI¸®dO·°>O!]_WU'ML®>TbOXÑFR>WY])WY]K_RCO·PMJ]^OJc

ZgF

y%z{<>9|X<i}4<>DBE6d~J9[
dMLKN]_GXSO!]_O!MXNP'Ra=OSeK_O!

4GXNeK_GES)OWbVXReK']c>)!jJXX

pL[,u/rQLuNtXv!

e

wv

J

³¾GXÕO(Ô>MLª²¨>TbOXc[WbS»°GP(`Cª¶O!SeKPMLK_O!VXGXNWbî!MEKNWUGJSc>R>O!_O%`C]_O']
ª²WUVJReKTbWbXO¶K_G0]_OOµM¿TUWY]^KGX³°>GoP`>ª²OSeKN]'MLSCXO!°»®oIK_R>O!WU
NOTbOÂEMLSCPOK_GµM¶¨CML_K_WYP(`>TYMLKNGX¨>WYPL
¬4NGX®dML®>WbTUWUKgI×O!]^K_WbªµMEKNO!]iMLNO;MLTY]^GÚWbª²¨dGJ^K'MLSeKiR>OSïK_RCO
P(TYMX]N]_W
P!MEKNWUGJSðGX`KN¨>`K']MX_O¼S>GLKi`C]_O!°ñWUS#Wb]_GXTYMEKNWUGJSð®>`K
MLNO=PGXª%®>WUSCO!°WUK_R%WUS³¾GJ_ªµMLK_WbGXS³¾NGXª×GXK_R>O!PGXª²¨dGJS>OSeK']
WbS¼M]^I]^K_Oªiì>GJ%OÔ>MLª²¨>TbOXc4WbSÃRCMXSC°NW¹K_K_O!S¼P'RCMXNMJP/K_O!
NO!P(GJVXS>WUK_WbGXSÙK_R>OiGJ`K_¨>`>KN]¿³¾NGXªòK_RCO3P(TYMX]N]^W
OMLNO`C]^OQ°
MX]WbS>¨>`KK_GMÙR>WbVXR´ATbOÂXO!T%]_I]gKNOªóR>WYP'RðWUSdP(GXN¨8GX'MEK_OQ]
°GJª²MXWUSôWUS³¾GJ_ªµMLK_WbGXSc]^`CP'RõMX]M3TYMLS>VJ`CMLVJO0ª²G°OTØÄZ\S
K_RCWb]P!MX]_OXcâ¨>NGX®CMX®>WUTbWUK_WbO!]¨>NGEÂeWY°OÑMÕ]^KNMXSC°>ML'°TYMLS>VJ`CMLVJO4³¾GJ
]_`>ª²ª²MX_WbîWbS>V%WUS³¾GJ_ªµMLK_WbGXSÅ³¾NGXªÄª%`>TUK_Wb¨>TUO]_GX`>'P(OQ]4WbSeK_G²M
]_WUS>VJTUOµ°OQP(WY]^WbGXSHµ;R>OSK_RCOÅP(GXª²¨8GXS>O!SeKN]GL³=K_R>OÅ]_I]gKNOª
MLNO°Wb]^K_NWb®>`K_OQ°êc®CMXSC°WY°oK_RP(GJSC]gKNNMXWUSeK']­ªµMâIµªµMLJOKNR>Wb]
]_`>ª²ª²MX_Wbî!MLK_WbGXS¸S>O!PO!]N]_MX_IÅMJ]=O!TUTHMJ]]gK'MLSC°>MXN°
6dè{ÏH÷QzÖ689
Îdåe÷!|â7=ÐøÜÕ`>0ª²O(KNR>G°Ú³¾GX»MXSC]_=O!_WbS>V¢K_RCO
S>O!O!°>]ÕGL³,K_RCO!]_O·NO!MLTU´A=GJ_TY°ML¨>¨>TbWYPMEKNWUGJSC]P!MLS®8O&KNR>GX`>VJReK
GL³CMJ]HM_OQ°`CP/KNWUGJS&GL³>PTbMJ]_]¨>NGX®CMX®>WUTbWUKgIO!]^K_WbªµMEKNWUGJSK_GP(TYMX]^´
]_W
O!TUOQMLNS>WbS>VCFR>ONO!°`dP/K_WbGXS±Ò¾RCWbP'RÑOSCMLª²O«_¬­_GJ®´
WbS>VJ¯eÓ]_MLK_WY]
O!]4]^K_NGXS>V·GX¨KNWUªµMLTbWUKgI%VJ`CML'MLSeK_O!O!]!½VXGoG°¶¨dO!^´
³¾GXNªµMLSCPO0WUK_RôNO!]_¨8O!P/K¸K_GÁP(TYMX]N]^W
PMLK_WbGXS¢Wbª¶¨CTUWbO!]¿VXGoG°
¨8O_³¾GXNª²MXSCP(O·W¹KNR»NO!]_¨dOQP/KKNG¿PTbMJ]_]¨>NGX®CMX®>WUTbWUKgI¿OQ]gKNWUªµML´
K_WbGXSHFR>O=O!]N]^O!SeK_WYMLTXGJ®C]_ONÂâMLK_WbGXS`>Sd°ONTUIoWbS>V)KNR>O¬4NGX®>WbS>V
NO!°`CP(K_WbGXSWY]K_RdMEKÕ¨C_GJ®CML®>WbTbW¹KgIÅOQ]gKNWUªµMLK_O!]%Ò¾WbS»MµMâIXOQ]^WYMLS
]_OSC]_OQÓ»PMLS×®8OÃOÔoK_'MXP/KNO!°³¾NGXªó¨>NO(³¾O!_O!SCP(OQ]0GEÂXO!0®8O(KN]
MEK¶°W¹ù[ONOSeK·G°>°C]&'MEK_WbGJ]!FR>OÅªµMXP'RCWUS>O!_I»K_RCMLK%ML¨C¨>TUWbO!]
K_RCWb]ÑGX®d]^O!_ÂEMEKNWUGJS¶K_G²P(TYMX]N]^W
O­TUOQMLNS>WUSCV%MLTbVXGJ_WUK_RCª²]­Wb]­K_RCO
¬4NGX®CWUS>V¶NO!°`CP(K_WbGXS

ûÁüý

¦¤

ËÆþÿÊ4¥ 

O']

PTbMJ]_]_W

FR>O!_O3MX_O3]_OÂJO'MLTO(ÔWY]gKNWUS>VÙMX¨>¨>NGJMJP'R>O!]¿³¾GJ0GX®K'MLWbS>WbS>V
P(TYMX]N]¨>NGX®CMX®>WbTUWUKgIµO!]^K_WbªµMEK_OQ]³¾NGXª
y¶<>?d?8zÖ9?ÐÜÕS>OÅP(GJª¶ª²GJS±MX¨>¨>NGJMJP'R`C]_O!]&®CMLVJVXWbS>Viß¹QáØ
í­]N]_OSeK_WYMLTbTUIJcK_RCO¼TbO!MX_S>WbS>VôMXTUVJGXNW¹KNR>ª
Wb]_`CSðGXSðªµMXSeI
K_'MLWbS>WbS>Vô]_O(K']0³¾GJ_ª²O!°Ú®oIÚ]_MXª²¨>TUWbS>VõW¹KNRð_O!¨>TYMXP(O!ª²OSeK
KNR>O0GJ_WbVXWbSCMLT)°CMEKNMJ]^OK!cMLSC°¼KNR>O0O!]^K_WbªµMEKNO!°¢¨>NGX®CML´
³¾NGXª
®>WbTUWUKgIK_RCMLK¶MXSeI±]NMLª²¨>TbOÃRdMX]%TbMX®dO!T	
ÅWY]&KNR>O©¨C_GX´
O!N]ÑKNRCMEK)GJ`K_¨C`K·³¾GX
H=FRCO
¨8GX_K_WbGXSGL³,TUOQMLNS>O!°¿P(TYMX]N]_W
NO!]_`>T¹K']GL³­KNR>O²®CMLVJVXWbS>V¸MX¨>¨>NGJMJP'Rª²MâIRdMâÂXO¶S>GLKNR>WUSCV©KNG
°G±WUK_RÙ¬4
Ò

[Ó/cÑK_R>O¨C_GJ®CML®>WbTbW¹KgIÃMJPPGX'°o´

198º
º
º
º
Ç
É
º
º
º
º
ä
º
º
ö
ö
º
º
º
º
ú
ü
º
º


Ò

ÿ

Ò

X

zÖ?8é368zÖD=Ð

WbS>ViK_G3K_R>O»°CMEKNM±VJOS>O!NMLK_WbGXS¢¨>NGP(O!]N]²KNRCMEK
RCMJ]¸®8OO!SõGJ®C]_ONÂXO!°Ù®dO³¾GXNOXc)KNR>O±¨>NGX®CMX®>WUTbWUKgIÁOQ]gKNWUªµMLK_O!]
GX®>KNMLWbS>OQ°¿K_R>NGX`>VJR®CMLVJVXWbS>VÅMLNOª²O!MJ]^`>NWbS>VµK_RCO&WUSd]gK'ML®>WbT¹´
WUKgI¸GX³KNR>O·PTbMJ]_]_W
O)TbO!MX_S>WbS>Vµª²O(KNR>G°GEÂXO!)°>MEK'Mµ¨dO!^KN`>_´

®CMLK_WbGXSC]¿ß¹QjâáNMLK_R>O!&KNRCMLSÁ¬4
[Ó,Z\SC°O!O!°êc
³¾GX¶TYMLNVXO%°>MEK'MX]_O(KN]!c,®CMLVJVXWbS>V0WUK_RÃPO_KNMXWUS3TbO!MX_SCWUS>VMLTU´
VXGJ_WUK_RCª²]ª²WbVXReK·NO!]_`>TUK&WUS±KNR>OÅ]_MXª²OÅP(TYMX]N]^W
OGJS±OÂXO!_I
N`>ScPMX`C]^WbS>VKNR>O®dMLVXVJWUSCV&¨>NGX®CMX®>WUTbWUKgI·KNG·®8OMXTUMâI]4j&GJ
)O!ÂXOSµRCOS²K_RCO)³¾`>SC°CMLª²OSeKNMXTd¨C_GP(OQ]_]4Wb]­ª·`CP'RµTbO!]N]­PO_´
KNMXWUSHZ\S»P(GJSJKNNMJ]gKQcCGJ`>¬4NGX®CWUS>VµNO!°>`CP/KNWUGJSRCMX]ÕMÅ]^Wbª²¨>TbO
VX`dML'MLSeK_O!O;W¹³>KNR>O)P(TYMX]N]_W
O!N],]_GXTbÂXO=K_R>O!WU=MX]N]^GP(WYMEKNO!°%P(TYMX]^´
]_W
P!MEKNWUGJS©¨>NGX®>TbOªµ]ÑGX¨>K_Wbª²MXTUTbIXcoKNR>OS¸K_RCONO¨8GX_K_OQ°Å¨>NGX®>´
ML®CWUTbW¹KgIÃWb]µ¨C_OQP(WY]^O!TUIÃ¬­

8Ó(;Z\S¢MJ°>°WUK_WbGXSc
`>S>TbWbXO®CMXVXVXWbS>VdcX¬4NGX®>WbS>V¨>NO!]_ONÂXOQ]WbSC°O!¨dO!SC°O!SCP(O)WbS²K_RCO
GXNWbVXWbSCMLT­°CMEKNMJ]^OKEcRCWbP'RiWY]%ëe`>WUK_O¸WUª²¨8GX_KNMXSJK·³¾GX·ªµMXSeI
TbO!MLNS>WbS>V²MLTbVXGXNWUK_R>ªµ]ÒÖ]_OOµßUâl!áH³¾GX³¾`>_K_R>O!°WY]_P`C]N]^WbGXSdÓ(
ð<BE?8zÖ9
S>GLKNR>O·MX¨>¨>NGJMJP'R0³¾GX·O(ÔoK_'MXP(K_WbS>V
¨>NGX®CMX®>WbTUWUK_WbO!]4³¾_GJªPTbMJ]_]_W
O']4WY]4KNG·K'MLJOMLSÅWbSeK_O!_SCMXTdNO¨>´
NO!]_OSeKNMLK_WbGXSõ]_`CP'RÚMX]¸K_RCOiª²MX_VJWUSõGL³²M¼]_`>¨>¨8GX_KÂXO!P(K_GJ
ªµMXP'R>WbS>O»MXSC°ÁK_'MLSd]g³¾GJ_ªW¹K¿WUSeKNGÃMiÂEMLTb`>O
	
j!(á)KNG
MXP'RCWUO!ÂXOPMLTbWb®>NMLK_WbGXS3GJSÃKNR>O¿K_'MLWbS>WbS>V]_O(K0Ò¾³¾GX²O(Ô>MLª²¨>TbOXc
`C]_WUSCV%M·]_WbVXª²GXWY°¶³¾`>SCP(K_WbGXSßUX(áÛÓ(4FR>OÕ¬­_GJ®>WUSCV_OQ°`CP/KNWUGJS
WY]Õª²GJ_O%VXOSCO'MLTÒÖ]_WUSCPO%WUK&ML¨>¨CTUWbO!]K_GP(TYMX]N]^W
O!N]ÕW¹KNR>GX`>K
MLS©WUSeK_O!_SdMLT8ª²MX_VJWUS¸]^`CP'R¸MX]Ñ°O!PWb]_WUGJSµK_NOOQ]NÓ­MLSC°©TUOQ]_]ÑMX°´
R>GPLZ\SÃ¨CML_K_WYP(`>TYMLQcWUSiKNR>O©¬­_GJ®>WUSCV_OQ°`CP/KNWUGJS3M0]_ª²MXTUT
P(TYMX]N]_W
P!MEKNWUGJS©ONNGXÑNMLK_OS>O!PO!]N]_MX_WbTbI¶Wbª²¨>TbWUOQ]VXGoG°Å¨>NGX®>´
ML®CWUTbW¹KgI»O!]^K_Wbª²MLK_OQ]ÕGEÂJOMLTbT°WY]gKN_Wb®>`KNWUGJSC]VXO!S>O'MEKNWUS>V¸K_RCO
°>MLKNM>)GVX`CMXNMXSeK_OO­GL³>KNR>Wb],ëe`CMXTUWUKgI&PMXS&®dOªµMX°>O4³¾GXMXSeI
j!(áCWbSeK_O!_ÂEMLTØcXOQ]_]_OS>´
K_'MLSd]g³¾GJ_ªµMEKNWUGJS%GX³MªµMLNVXWbS¶WbSeK_G&MÅß
K_WYMLTbTbIµ®dOQPML`d]^OK_R>OªµMLNVXWbSÅWb]=S>GXKM»«_]_`ÅP(WbOSeK]^KNMLK_WY]gKNWbP!¯
EáC³¾GX=M&°WY]_P`C]_]_WbGXS
³¾GX­¨>_GJ®CML®CWUTbW¹KgI%O!]^K_WbªµMEK_WbGXSHÝOOMXTb]_Gµß
GL³]_¨CML']^WUKgIµÂXO!N]_`C]Ñ¨>NGX®CMX®>WbTUWUKgIÅO!]^K_WbªµMEKNWUGJS¸WY]_]_`>OQ]
¿z¾BEåo|L÷¸æBEåoDzÖ|L÷QzÖ689­Ð&FRCO&K_RCWU'°0]^KNMLSd°>ML'°ML¨>¨C_GeMXP'RWb]
K_G]_WUª²¨>TbI0¨>NO!°WYP/K¨>NGX®dML®>WbTUWUK_WbO!]°WbNO!P/KNTUIJc[K_Wb¨>WYPMLTbTbI0W¹KNR
]_GXª²O³¾GXNªøGL³²TbO!MLNS>OQ°ô¨>NGX®dML®>WbTUWY]^K_WYPª²G°O!T{ÜÕ`C_O´
K_R>WY])ML¨C¨>_GeMXP'RMX]&Ò^QÓÑ¨>NGEÂoWb°´
]_`>T¹K']P!MLS®dO·ÂeWbOÑO!°¸³¾NGXª
WbS>V¶PGXª²¨CMLK_Wb®>WUTbWUKgI¶®8O(KgÑOO!S©S>GJS´A¨>_GJ®CML®CWUTbWb]^K_WYP)MXSC°Å¨>NGX®>´
JÓÅO!S>NWbP'R>WbS>VÃK_R>O±]^OK¿GX³·¨>NGX®CML´
ML®CWUTbWb]^K_WYPª¶G°O!Tb]¿MLSd°ñÒ
®>WbTUWY]^K_WYP%ª²G°O!Tb]WUK_RS>OïMLSC°»GL³ÛK_O!S®8O(K_K_O!¨dO!^³¾GJ_ª²WbS>V
ª²G°OTY]
O°WY]_PGEÂXONO!°&K_RCMLK=MNO!°`CP(K_WbGXSµ]_WUª²WbTbMX,K_G&¬4NGX®CWUS>VRCMJ°
®8OOS¸¨>`>®>TbWY]^R>OQ°Å¨>NOÂoWbGX`C]_TbI¶®oIµMXTbP'ß
lQáAFR>OÕªµMXWUS¿°W¹³Û´
³¾ONOSdP(O0WY]ÅKNRCMEK¬4NGX®>WbS>ViNOÑOWbVXReKN]µK_R>OP(TYMX]N]^OQ]©ML¨C¨>_GX´
¨>NWbMLK_O!TUI¢KNGÁGJ®KNMXWUSõ¨>NO(³¾ONOSdP(O!]¸GEÂXO!¸®8O(K']MEK0°WUù8O!_O!SeK
G°>°>]Ñ'MEK_WbGJ]ÒÖ]_OOS>OÔeK]_O!P/KNWUGJSdÓ/coR>WbTbOÕMLTYP'
]=_OQ°`CP/KNWUGJS
P'RCMXS>VXOQ]4KNR>OTbMX®dO!Tb]GX³HO(Ô>MLª²¨>TbO!]Ñ'MLSC°>GXª²TUI²³¾GJÑK_R>O]NMLª²O
¨>`>N¨8GJ]_OXO¶¨>NGEÂeWY°O·MÅK_R>O!GXNO(KNWbP!MLTH¨8O_³¾GXNªµMLSCPO·VJ`CML_´
MLSeKNOOMLSC°©¨>_OQ]^O!SeKM¶P(GJª¶¨C_O!R>OSC]_WbÂXOOÔ¨dO!_Wbª²OSeKNMXT8O!ÂEMLTU´
`CMLK_WbGXSÅGX³H¬4NGX®>WbS>VC,MXTbP'
]4ª²O(KNR>G°ÅªµMâI²®dOMLSCMXTUIoîQML®>TbO
MLSd°;ªµMâI¼RCMâÂJOVXGoG°¢Oª²¨>Wb_WYPMXTÕ¨8O_³¾GXNªµMLSCPOXc®>`K¿K_RCO
K_RCOGXNI©MXSC°©O!ÂEMLTb`CMEKNWUGJS¸RCMâÂJOS>GLK®8OOS°GJS>OIXOK!

PRQüTS

¥>Ê4¡Í

ÉVU#û¢ü

ËÌÕ§8¤Í^Ê
W

>ÓE
 
¡(¢¤£V¥V¦*§<¨

6,%"#$

>Ó%°>NMâSi³¾NGXª

]N]_`>ª²O¸ÑO¸RdMâÂXO©OÔ>MLª²¨>TbO!]¿Ò
MXSÃ`>S´
oS>GES¸°>Wb]^K_NWU®C`K_WbGXSYXÆW¹KNR¿°GJªµMLWbS[Z]\_^ÚR>O!_OMZ
Wb]
baQjc7dWb]K_R>OTYML®8OT]_¨CMXPOX
K_RCO³¾O!MEKN`>NO]_¨CMJP(OMLSC°`^
y¶<e!z{|Mf²çge!åeBKh><÷!z{6d9ieJÐ4FR>O­¬4NGX®CWUS>VNO!°`dP/K_WbGXSWY]®dMX]_O!°
`>¨8GXSKNR>O­GJ®C]^O!_ÂEMLK_WbGXSK_RCMLKM®>WbSCMX_IP(TYMX]N]^W
OHR>WbP'R¨C_O´
WY]Wbª¶¨CTUWYP(WUK_TbI»¨>NO!°>WbP(K_WbS>V¿K_RCMLK
°WYP/K']²%³¾GJMLSO(Ô>MLª²¨>TbO
ÃWb]·VXNO!MEKNOK_RdMLS±K_RCO
K_RCOÅ¨>NGX®CMX®>WUTbWUKgI0GL³P(TYMX]N]µµVXWbÂXO!S
8ÓDk
¨>NGX®CMX®>WbTUWUKgI0GL³P(TYMX]N]&j¿VXWbÂXO!S
X0Ò
O!RCWbP'R¨>NO!°WYP/K']j
ôj
³¾GX
ÑI²=O!WUVJRJKNWUSCV&K_RCO)K_'MLWbS>WbS>V·OÔ>MLª²¨>TbO!]Ñ]^`CP'RÅK_RCMLK=¨8GJ]_W¹KNWUÂJO
O(Ô>MXª¶¨CTUOQ]©MLNO-n+K_Wbª¶OQ]¿ª¶GJ_OP(GJ]^K_TbIÁK_GÁP(TYMX]N]^WU³¾I¼WbSCPGX_´
NO!P/KNTUIK_RdMLSiS>O!VJMEKNWUÂJOµO(Ô>MLª²¨>TbO!]!cW¹K¶Wb]·¨dGe]_]_WU®CTUOµKNG0TbO!MLNS
P(TYMX]N]_W

j
0]_`>VJVXO!]^KN]=KNRCMEKlX0Ò

HcK_RCMLK·Wb]!cjX»Ò
8Ó=kmX0Ò
×

8Ó(Åa=GJSoÂXO']_OTbIXcMP(TYMX]N]^W

[Ó/

O!N]ÑR>WYP'R¨>NO!°WYP/KW¹³
oEprqtsvu2w
xyiz

ug{[|

MLSC°¿j¶GLK_RCONWb]_OX
6CBE68èÖè{<Bâ~[rrE7?>2?>@r!6vWEIÒÓ
:ôÒgV



s¶q3y

prq3y²±pr³0prxyµ´
xygz_·y

©ª¬«­¯®¬°
s¯±µproEprqsvuKw
1¸!¹º?2¼»6¤½:¼K»¾>Õj
FR>WY]P(GXNGXTbTYMLNI·GXSCTUIµ°WY]_P`C]N]^OQ]l¿rcr¼2O!_NGXÑP(TYMX]N]^W
O!N]!c
]_G»WUK¶GJS>TUIiMX¨>¨>TbWUOQ]·WbS3KNR>O¿MJ]^Ioª²¨KNGLK_WYPÅTbWbª¶WUKµGL³M®CMâIXOQ]
P(GJSC]_Wb]^K_O!SJK·PTbMJ]_]_W
OQ©)GEÑOÂJOQcêK_RCOÅ¨>NGX®>WbS>VMLTbVXGJ_WUK_R>ª
PMXS®dO¨>NGEÂXOQ°¸]_GX`CSC°©O!ÂXO!S¸³¾GJ)P(TYMX]N]^W
O!N]WUK_RS>GJS>ª²WUS´
Wbª²MXTONNGX'MEK_OQ]­O&¨C_GEÂJOKNR>Wb]ª²GXNOVXOSCO'MLT[K_RCOGXNOª
XÓ(%FR>OµPGXNGXTbTbMX_I]gK'MEKNO!]ÕK_RCMLK&M
WbS]_O!P(K_WbGXS»ãiÒ¾K_R>O!GXNOª
O!)R>WYP'Rª²WUS>Wbª²WUî!O!]MµWbª¶¨8GX_KNMXSCP(OÑOWbVXReKNO!°TbGJ]N]
P(TYMX]N]_W
PMXS®dO­`C]^OQ°K_GÕ°O(KNONª¶WbS>O4WU³K_RCO­P(GJSC°WUK_WbGXSCMXTJ°WY]gKN_Wb®>`KNWUGJS
X0Ò
8ÓÕWY]ML®8GEÂXO·GJÕ®8OTbGEñM©K_R>NO!]_R>GJTb°³¾GJM©VJWUÂJOS
cXR>O!_O=K_RCO=KNR>NO!]_R>GXTY°·°O!¨dO!SC°>],GJS&K_RCOÑNOTYMEKNWUÂJO
ÂEMLTb`>OGL³
ÑOWbVXReKVXWbÂXOS¸K_G²¨8GJ]_W¹KNWUÂJOMLSC°¿S>O!VJMEKNWUÂJOÕOÔ>MLª²¨>TbO!]!
7åYÀ©è{?d6dBEz¾÷!7é;Ð­GEc>]^`C¨>¨dGe]^OKNRCMEKÑOTbO!MX_S¿M²P(TYMX]^´
O!ÂÁ1¶³¾GXÕOÂXO!_I¿P'R>GXWYP(O·GL³ÄÃ»MLSd°O!MXP'RGX³,K_R>OQ]^O·PTbMJ]_]_WU´
]_W
HcOQMXP'R¸GL³
O!N]ÑRCMJ]ÑM%ª²WUSCWUªµMLT[TbGJ]N]FR>O!Sco³¾GXMXS©WbS>¨>`K
8ÓWY]VJ_OQMEK_O!
K_RCOÅP(TYMX]N]^W
#j>cêÑO¶S>O!PO!]N]_MX_WbTUIRCMâÂJO
K_RdMLSK_R>O%K_R>NO!]_R>GJTb°_ÃH%ìCGX?Ã
8ÓPMXS>S>GLK®8O%TbO!]N]ÕK_RCMXSj>
[Ó
Á1>Ò
]lÃ3VXNGE)]!cK_RCOÅ¨>NO!°WYP/KNWUGJSC]GL³KNR>O¸]_`>®C]_O!ëe`>O!SJK·PTbMJ]_]_WU´
×
[Ó
O!N]MLNOª¶GJS>GLKNGXS>O­WUSVÃ·W¹KNR&GXS>O=¨dGJWUSeKcÃÄÆ
R>O!_O·K_R>O¶¨>NO!°WYP/KNWUGJS»P'RCMLSCVXO!]³¾_GJª·K_Gj>FR>ONO(³¾GJ_OJc
K_RCO&¬4NGX®>WbS>V¶_OQ°`CP/KNWUGJS¸NO¨8GX_KN]!½
8Ó

O']MLSC]_ÑO']ÕRCO(K_RCOÅX0Ò

%®8O!P!ML`C]_OEX0Ò

X0Ò

À

ð

ÒgâÓ

ÇÃ

X»Ò
FR>NOOWY]_]_`>O!]NOªµMXWUS½

! #"#$!%'&("*)+-,! .0/1$2)3,4657".83! #:9;,4<

)+!=/40,,/>)?8@".A),"#B3C3)"#4<$D".$EEF2GIH3G>JFKG>J!L(M0$3$!1,N

XGLK¶MXTUTÑP(TYMX]N]^W

O!·TbO!MLNS>O!N]&MX`K_GJªµMEK_WYPMXTUTbIKNMLJOµK_RCO
ÑOWbVXReKlnïMX]ÕWUS>¨C`K!O¶MX°>°>_OQ]_])K_R>WY]®oI`C]_WUSCVÅK_RCO

199
]
º



º
º
º


ö

º
ß
º
º
O
É

º





º


º
u
}



º
º
º
º



ä
º
º
º






º



Æ

º
:=åo<BE9åeB

^|XèÖ<ce0eQz,åeB&èÖåo<BE9åeB
9êÏéç­åeBÅ68@)z¾÷QåJBE<÷QzÖ689je

À©è{?d6dBEz¾÷Q7é

~·æBE6dçz{9?
×Ò
j
aeß
jáId

aoÒ

ÒÖMeÓ¸fHO(K·ß
Ò¾®8Ó¸fHO(K(Ã

Ò¾OâÓ¸fHO(KlÁ
k>OK_`>NSMLTbT

>Ó

D<÷!<ce!åe÷	

XfHO(K
×K_G
ìCGX¤
ðª²WUS>WbªµMEÔ©WbSeK_O!_ÂEMLT²	
Ná
ðª¶WbS>WbªµMEÔ©GJ¨K_WbªµMLTÃ[	iß
Ná
ñÒM
ÃjNád

'áIdEÓYaoß
ÃCáQß
aoß
ÒÖPQÓ¸fHO(K
W
Ò>Ó^ÓÑ½CÒW
 
>Ó?	=d
ÒÖ°dÓ¸fHO(K
Ò
À©è{?d6dBEz¾÷Q7é&æBE6dçz{9?
|Xè{<e<e!zåeB2eEÁ
zÖ9"!,ÏH÷
'&
XfHO(K%$
KNR>O($[K_RWbSeK_ONÂEMLT
Ná

fHO(K·ß
k>OK_`>NSª²WUS>WbªµMEÔ©GJ¨K_WbªµMLTÃY	±ß

æBEåoDz{|L÷Q6CB

#

Á1>Ò

[Ó

eQåJ÷68@ ·åoz{?d7[÷QåeD
NáA

PGJ]^K_WbS>V_OQ°`CP/KNWUGJSÁßUâlQá4³¾_GJª2Wbª²¨dGJ^K'MLSCPO¶ÑOWbVXReKNO!°
PTbMJ]_]_W
PMLK_WbGXScÕR>WbP'RÚML¨>´
¨>TbWbO!]KNG²MXSoI©P(TYMX]N]^W
fHO!MLNS>WbS>V0MP(TYMX]N]_W

PMEKNWUGJSÙKNG¼®>WbSCMX_IôPTbMJ]_]_W
O!ÑTbO!MX_SCOQ
O!³¾GX%OÂXO!_IP'R>GXWYP(OµGX³?n

Wb]KNGoG
PGXª²¨>`K'MEK_WbGXSdMLTbTUIWbSeK_OSd]^OJ·Oµ_OQ]^GJTUÂJO&K_RCWb]®oI0°WY]g´
P_OK_WbîWbS>V¶K_R>O&]_O(K)GX³jnðMLSd°©NO¨8GX_K_WbS>VµM¶¨>_GJ®CML®CWUTbW¹KgI
WbS¿K_R>O&°WY]NP(NO(K_OWbSeK_ONÂEMLTØ
O']ª²MâI
S>GXK·®8O¸P(GJSC]_Wb]^K_O!SJKQcª²OQMLS>WbS>VKNRCMEK%K_R>O©]_O!ëe`>O!SCP(O©GL³
¨>NO!°>WbP(K_WbGXSC]³¾GJ)M²VXWbÂXO!S¸OÔMXª²¨>TUOWY]S>GXK)S>O!PO!]N]_MX_WbTbI
ª²GXSCGLK_GJS>WYPLO)]_WUª²¨>TbI·]_GX_K,K_R>ONO!]_`>TUKN],GL³8K_RCO)P(TYMX]^´
]_W
O']K_G©ª²MXXOKNR>O·]_O!ëe`>O!SCP(O&ª²GJS>GLKNGXS>WYPÅÒÖMXTUTîO!_Ge]
®8O(³¾GJ_OMXTUTCGXS>OQ]NÓ(FR>WY]4VJWUÂJO!]`d]K_RCO]^GJTU`>K_WbGXSµP(GJSC]^WY]^´
KNOSeKHWUK_RKNR>O4TYMLNVXO!]^K¨8GJ]N]^Wb®>TbO4So`>ª·®8OGL³>P(TYMX]N]^W
O!N]!
T¹KNR>GX`>VJR²K_R>WY]4ªµMâI²ML¨>¨8O!MXK_G·®dOMRdMXP'[cLKNR>O¨>NGoGL³
·³¾`>SC°>MXª¶O!SeKNMLTbTbIÅ_O!TUWbO!]`C¨dGJS¸KNR>O&]_GX_K!
GX³KNR>OGJ_O!ª

k>Z\SC°>O¨8OSC°O!SeK_TbI&TUOQMLNS>O!°·]^`>®>´ØGJ¨K_WbªµMLToP(TYMX]N]^W

VX`>NO!]

TUVJGXNW¹KNR>ª

TbVXGXNWUK_R>ªÀ)MLSC°

:­åo<BE9zÖ9?HÐ¢FR>OMLTbVXGJ_WUK_R>ªµ]&³¾GX²TUOQMLNS>WbS>V»MLSd°3ªµMLoWbS>V
¨>NO!°WYP/KNWUGJSC]`C]_WbS>VK_R>O¸¬4NGX®>WbS>V¿_OQ°`CP/KNWUGJSiMLNOµ_O!¨dGJ^KNO!°
,FR>O¬4NGX®CWUS>VX´
WbS
KNMXXOQ]MX]WbS>¨>`K·MPTbMJ]_]_W
fOQMLNS>OMXTUVJGXNW¹KNR>ª
OTUOQMLNS>WbS>V
MLTbVXGJ_WUK_RCª¿cêM¸]^OKGX³4K_'MLWbS>WbS>V©OÔMXª²¨>TUOQ]ÕMXSC°»]_GXª²O%Se`Cª%´
®8O)GX³,WUK_O!NMLK_WbGXSC]!ÑÜÕSO!MJP'R¸WUK_O!NMLK_WbGXScCW¹KNO
S>O!]KNR>O&°WY]g´
P(NO(KNWUîQMEKNWUGJSÁGX³K_R>O0WbSeK_O!_ÂEMLTW¹KNR;K_R>O»TbMX_VJO!]^K²¨8GLKNOSeK_WYMLT
VJMXWUS%³¾NGXªñNO
S>Oª²OSeKÒ¾K_R>WY]WY]TUGe]_]°>O¨8OSC°O!SeK!co]^O!OÑ®8OTbGE
³¾GX4°>O(KNMXWUTY]'Ó/,ì>GXOQMXP'R¶P'R>GJ]_OS¶WUSeKNONÂâMXT>Mª¶WbS>WbªµMEÔ%P'R>GJWbPO
GL³¨C_GJ®CML®>WbTbW¹KgI²MLSC°µK_R>OP(GXNNO!]_¨dGJSC°WbS>V=O!WUVJReKÕÒ¾GJ®KNMXWUS>OQ°
®oI·WbSoÂXO_K_WbS>VO!ëe`CMLK_WbGXSQÓ,MX_O)P!MLTYP(`>TYMEKNO!°²MLSd°¶MÑOWbVXReKNO!°
P(TYMX]N]_W
æBEåoDz{|L÷!z{6d9=ÐFRCOÅ¬4NGX®>WbS>VL´\¬4NO!°>WbP(K_GXMLTbVXGJ_WUK_RCª+KNMXXOQ]
MX]¶WbS>¨>`K¶K_RCO]_O(K²GL³Õ=O!WUVJRJKNO!°¼P(TYMX]N]^W
O']·MXSC°ÃMXSÃWbS>¨>`K

O!Wb]TbO!MX_SCO!°ê

H,ZAK,K_RCOS²¨>WYP'o]KNR>Oª²WUSCWUªµMEÔ¶¨>NGX®CMX®>WUTbWUKgIWUS¶K_RCO)$[KNR²WUS´

O¶GXS	ÃKNG
HiZAKµ]_`>ªµ]&KNR>O¸¨C_OQ°WbP(K_WbGXSC]¶GX³)O!MXP'R¼P(TYMX]N]^W
°OK_ONª²WUSCO·KNR>O%So`>ª%®dO!GL³=PTbMJ]_]_W
O']K_RdMEK¨>_OQ°WYP/K²·³¾GJ
K_O!_ÂEMXT4ÒÖP(GJ`>SeK_WbS>V¶³¾_GJªjJÓ(4FR>Wb]WY]O!ëe`>WbÂEMLTbOSeKK_Gµ]_GX_K_WbS>V
K_RCOPTbMJ]_]_W
O¶¨>NO!°WYP/KNWUGJSC]&KNG±GX®K'MLWbSÃª²GXS>GXK_GJS>WbPW¹KgIiMXSC°
NO¨8GX_K_WbS>VµM²¨>_GJ®CML®CWUTbW¹KgIÅ³¾_GJªK_RCOWUSeK_O!_ÂEMXTWUSRCWbP'R¿K_RCO
¨>NO!°WYP/KNWUGJS¿P'RdMLS>VJO!]=³¾_GJª2K_GµjC
>ÒÖ®dÓWbS%¬­_GJ®>WbS>VL´\fOQMLNS>O
:­6e<eV¸åe÷Q<>zÖèIeXÐ=ÝoK_O¨d]
MLNO°O¨8OSd°OSeK)GXS¿KNR>O¨>NGX®CMX®>WUTbWY]gKNWbPTbGJ]N]Ñ³¾`>SCP/KNWUGJSGL³,WUS´
K_O!_OQ]gKQñ)O!_O»=O»°>O!]NP(NWU®8OK_RCO!]_O]^K_O¨d]µ³¾GX©Kg=GÃGL³K_RCO
ª²GJ]^KPGXª²ª²GXS>TbIÕ`d]^OQ°¨>NGX®CMX®>WUTbWY]gKNWbPTbGJ]N]ê³¾`CSCP/KNWUGJSC]½P(NGJ]N]
OSeKN_GJ¨eIÚMLSd°ð]_ëe`CMX_OQ°×ONNGXQ
Z\SñGJN°O!0KNGõ°OK_ONª²WUSCO
K_RCOª²WbS>Wbª²MLÔÅWUSeKNONÂâMXTêMLSC°ÅK_R>Oª²WUSCWUªµMEÔÅ¨C_GJ®CML®>WbTbW¹KgI²³¾GJ
OQ°0®>`KP(GJSoÂXOSCWUO!SJKMX]N]^`>ª²¨KNWUGJSK_RdMEKMXTUT,P(TYMX]N]_W
O!N]ÕMLNO
P(GJ_NO!P(K!
Xa=NGJ]N]ÑOSeK_NGX¨oIÅWY]VXWbÂXO!S¸®oI

K_RCO!]_OÅTUGe]_]&³¾`>SCP(K_WbGXSC]!c,=OÅªµMXXOµKNR>O¸]_GXª²ORdMEK&`>S+*g`d]gKNW¹´

CÒÖMJÓMLSd°

[Ó

ÃÒ

¤

ôjJÓTUS

ÃHÒ8Ó
ÃY	±ß
67Aß
TUGe]_]ÑGJS
Ã)TbS
8243
²Ã)TbS

/8Ò
'áWb]VJWUÂJOS¸®eI[½

Ã¼TbGJ]N]GXS¿Ã>á
ôÒgl'Ã[ÓoTUS

¢Òg¤[Ã8ÓTUS

67"9



;:

FR>Oª²WbS>Wbª²MLÔ©GX¨>K_Wbª²MXT

ðQÓoTbS



-dÒ
+243
67ªµMEÔ
ª¶WbS10
+243
¢ª²WUS)0
67!ª²MLÔ
+243
FR>WY]Wbª²¨>TUWbO!]ÑKNRCMEK
Ã

67

2ML

ÃY	±ß

MLNV±ªµMEÔ

FR>OÑª²WUSCWUªµMEÔ%WUSeK_O!_ÂEMXTJWY]K_R>OÑWbSJKNONÂEMLToR>WYP'R%P(NO!MLK_OQ]
KNR>OµTbMX_VJO!]^KÕ¨8GLKNOSeK_WYMLT4P'RCMXS>VXO¶WbSTbGJ]N]R>OSNO
S>OQ°
®8OK_RCO&]^OK
GX³K_'MLWbS>WUSCV0O(Ô>MLª²¨>TbO!]·R>GJ]_O©P`>_NOSeK·¨C_GJ®CML®>WbTbWb]^K_WYP
¨>NO!°>WbP(K_WbGXS¿Wb]

µ=<>?A@BDCE>?AFB
@GCEF
R>O!_OIH3ÒÓHWY]4ÝoRCMXS>S>GJS%O!SJKN_GJ¨oIÅÒ¾WbS¶SdMEKN]'ÓGL³êMÕPGXWbS
WUK_R®>WYMX]I8
GJS¸KNR>OK_'MLWbS>WbS>VÅ]_O(K!ÑÝo`>¨>¨8GJ]_O=OTbO(K
¤O
==TbS

NáA4FR>OP'R>GJ]_OSKJWUSeKNONÂâMXTêWb]!½
#NgÒ^¤OÓoTbS
ÃQP
¤
OQMLS]_ëe`CMX_OQ°©O!_NGXÑWY]VXWbÂXO!S¸®oI
ßUÒD¶X0Ò
'áWb]VJWUÂJOS¸®eI[½
67Øß
Ã8ÓTJµôÒg¤`Ã8Ó
ÃUJ
+243
67"S
ÃVJXW
²ÃÒ^¤'Ã[ÓJ¤¢Òg¤`Ã8Ó

ðÒ/(ÓY
"#! #"#²)+!"#²"#X^2C!"#5< #$2)²)4
$3"*)".40$=]
40)?)+!)²)+!V8@\
 .$
on
{l
pAukjmly
onqp
cdfehg

67ªµMLÔ
ª²WUS-0
8243
+243
;ª²WbS10
R243
67ªµMEÔ

ÃY	±ß
TbGJ]N]GXS
ÃÒg¤

FR>Oª²WbS>Wbª²MLÔ©GX¨>K_Wbª²MXT

FR>WY]Wbª²¨>TUWbO!]ÑKNRCMEK

TbGJ]N]ÑGXSEÃ>á

8Ó_Ó



á

 #$

Z[
,%jM`_4a

200









Ó
Á





º
º
º
º
º
º
º

º


º
º
º
º
º
º
º
º
º
º
,




.


.

.
5

5

.
5

5


0


0




.


º
5
.
3
5



5
.
Ã

.
,




J
.
5

5

.
Ã
5

5

.
.
.
Ã
·
b
¨
w
i
b
w
S
c
°
c
p
°
W
FR>Oª²WbS>Wbª²MLÔ©WbSJKNONÂEMLTêWY])]^Wbª²WUTYMLNTbIÅVXWbÂXO!S©®oI

MX_V±ªµMEÔ

67

2ML

UÒµ

Ó

ÁLÒ8Ó

>Ó8Ò

=
>Ò


:

Ä

³¾GJ

>Ó^Ó



S>OQ°¿®eIÅK_R>OªµML¨C¨>WUSCVC½

Z\S&MÑK_'MLSd]_°`dP/K_WbÂXO]_O(K_K_WbS>VCcâ`C]_WUSCVK_R>OKNO!]^KH]^OK°WY]gKN_Wb®>`KNWUGJS
K_G²ÑOWbVXReKK_R>Oª²WbS>Wbª²MLÔ¸WbSeK_ONÂEMLTêWY]M²®dOK^KNOKNRCMLS
ðÏè¾÷QzÖ|Xè{<e<e
<eQådÐì>GJÑK_R>Oª·`CT¹KNWbPTbMJ]_]ÑPMJ]^OW¹KNR
TYML®8OTY]c4ÑO]^Wbª²¨>TUI3MX¨>¨>TbI±K_R>O¿®>WbSCMLNI±ª²O(K_RCGo°ÃK_G
®>WbSCMLNIÅ¨>NGX®CTUO!ª²]°>O
j
0;

¢&P'R>GXWYP(OQ]GL³gFR>WY])ª²O(KNR>G°VXWbÂXOQ]`C])¨C_GJ®CML®>WbTU´
³¾GX
õÅPTbMJ]_]_O!]!c,]^G0ÑOÅPMXS
WUKgIOQ]gKNWUªµMEKNO!]
O!]^K_WbªµMEKNOK_R>O%¨>NGX®CMX®>WUTbWUKgI©GL³,KNR>O·TYMX]^KÕP(TYMX]N])MJPP(GJN°>WUS>V¶KNG
×¤
	


>ÓòÒWdÒ
Ã
Ä
£oÍ^£iÊµ¤

FR>O·³¾GXTbTUGEWbS>V²K_RCOGXNOª]_R>GE)]K_RdMEKKNR>O·¨C_GJ®>WUSCVÅ_OQ°`CP(´
K_WbGXSÃWb]·WUS>RCONOSeK_TbINGX®C`C]gK¶MLVJMXWUSd]gK·PTbMJ]_]_W
PMEKNWUGJS±ON_GJN]!
ÓMXSC°
²Ò^

ì>GJ,K_R>O)K_R>O!GXNOªcLNOª²Oª%®dO!(
O!µÁ`CSC°O
TbO(KÑK_R>OÕWUª²¨8GX_KNMLSdP(OÑOWbVXReKNO!°µTbGJ]N]4GX³HM·P(TYMX]N]_W
°WY]gKN_Wb®>`KNWUGJSYX
ÒIÁÓ

ÉlUñû¢ü

ËÕÌ§8¤>ÍgÊ

¥>Ê­¡ÕÍ

Q)ü

ÒÓ

ý

>Ó

®8O

Ã



K_RCOS

Ógª²WUS

>Ó¶WY]©M±S>GJ_ªµMXTUWbî!MLK_WbGXS¢P(GXS>´

TbO!MLNS>OQ°µ`>SC°O!¬4NGX®>WbS>V·RdMâÂXOÕMâÂJO'MLVJO_O!TbML´

7åo6CBEåoé
O!N]=Á
P(TYMX]N]_W
K_WbÂXOWbª²¨dGJ^K'MLSCPO=O!WUVJRJKNO!°©TUGe]_]

]^KNMLSeKQ
FR>WY]KNR>OGJ_O!ª×MLSCMXTUIoîOQ]ê¨>NGX®>WbS>VÕWUSKNR>O­TbWbª¶WUKMX]HK_R>O=Se`Cª%´
®8OGL³êP(TYMX]N]_W

R>O!_Oi
O!N],MX¨>¨>NGJMXP'RCO!]`>S>WU³¾GXNª²TUI&GEÂJOK_RCOÑ`CS>W¹K
WbSJKNONÂEMLTØÕWb]NP(NO(KNWUîQMEKNWUGJSKNG0WbSJKNONÂEMLTY]GL³)]_WUî!O»MJ°>°>]&MLK
ª²GJ]^KtEJ+Yâã%K_G²KNR>OO(Ô¨8O!P/KNO!°]NëJ`dMLNO!°ÅO!_NGXQ
ïÒÖ¬­_GJ®>WbS>VÙí4N_GJ0FH'MLSd]g³¾GJ_ªµMEKNWUGJSdÓ¿ZA³µK_RCO
',
ÒIX0Òg
[Ó²
ÃÒ8ÓWY]ÑK_RCO¨>_GJ®>WbS>V²¨>_OQ°WYP/K_WbGXSH


R>O!_O
FR>WY]Wb]M¿]^K_NGXS>V¸K_R>O!GXNOª
&%261!¼>('
ONNGX­WbS¸K_R>O¨>NGX®CMX®>WbTUWUKgI²¨>_OQ°WYP/K_WbGXSd]­KNG·KNR>O
2)%2ÅWbª²¨dGJ^K'MLSCPO¶ÑOWbVXReKNO!°TUGe]_]GX³=KNR>OÅP(TYMX]N]^W
O!N]!+*Õ]g´
WbS>V¶K_R>O&MâÂJO'MLVXOÕTUGe]_]ÑGEÂJO?nÚ_OQ]^`>TUKN]WbSM¶ª¶GJ_O¨8GE=O!^³¾`CT
]^KNMEKNOª²OSeKKNRCMLS±`C]_WUSCVK_R>OµªµMEÔWbªµMLT4TbGJ]N]cH®dOQPML`d]^OµWUK&Wb]
O']%R>WbP'RÁRCMâÂJO¸]_ª²MXTUT
O!MJ]^WbO%K_G±GJ®KNMXWUSÁM]_O(KµGL³P(TYMX]N]^W
MâÂXO!NMXVXOTbGJ]N]4KNRCMLS©K_G%GX®K'MLWbS¸M·]_O(KGL³P(TYMX]N]^W
O']!cJMLTbT[W¹KNR
GL³8K_RCOMâIXO!]GJ¨K_WbªµMLTdPTbMJ]_]_W
O,ª²O!MXSC],K_RdMEK4KNR>OK_RCOGXNOª
ML¨C¨>TUWbO!]=OÂJOSÅRCOSÅKNR>OÕ³¾`>SC°>MXª¶O!SeKNMLT8S>GJWb]_O'MEKNOWY]­TYMLNVXOJ

M]_ª²MXTUT=TUGe]_]!,*Õ]^WbS>V»MTbGJ]N]KNRCMEK·WY]&NOTYMEKNWUÂJO¶K_GKNR>OÅTbGJ]N]

WbS»KNR>Oµ]^O!SC]_O·KNRCMEK&WUKK_WbO!]K_RCO

,ªµMEÔa<X»ÒgQÓ6>X0Ò{jJÓd


ÃHÒ

! 
[Ó^Ó

J$#

Á!Ó

jC

prxy=´

prxy=´
s¶q!yy<

)GXK_OKNRCMEKR>OSKNR>O­¨C_GJ¨dGJ^KNWUGJSGX³¨dGe]^WUK_WbÂXO­MXSC°S>O!VJMEKNWUÂJO
JÓÑK_RCO·®8GX`>SC°GJS
K_RCO¶O!_NGXÕWUS»K_R>O²¨>NGX®dML®>WbTUWUKgI¨>NO!°WYP/KNWUGJSC]Wb]O(Ô>MJP/K_TbIK_RCO
MâÂXO!NMXVXOÕ_O!TbMLK_WbÂXOWUª²¨8GX_KNMLSdP(O=O!WUVJReK_O!°¸TbGJ]N]c

æBE668@/.,fOKlÁ0Æ
«21c¦(31¨
798
¥g°
¥¤¦#§<¨
798
¥g°

-%Ò{jJÓ
O(Ô>MXª¶¨CTUOQ])WY])®CMXTbMXSCP(OQ°Ò%Ò^QÓ

[Óg
[Ó^Ó
ÒIX0Òg
ÃÒ
Ùª²WUS
ÁÓ(cK_R>O!S
S!4
yj
pr³
pr³65
prq3y1pr±pr³
s¯q3yUj'±pr³65
©ª¬«­;:
®¬°
on
prxyUj'³
pr³65
prxyy
xy
oEpAu2w
prxyy<
{?oEp>=!w
xy1pr³
prxy#j'³65
on
pr³
prxyy
prxyUj'³
oEpAu2w
xy
{tpAukj`oEpAu2w
prxyUj'³
prxyy<
xyy1pr³
xy j-u6y<
prxyUj`³
pr³
prxyy1p
:?
Ú­MXSC°X0Ò^
8Ó?kRÃ,@
ôj>cÑORdMâÂXO
prxyµ´
±pr³
xyjD·Äw
s¶³
·DC
X0ÒÖjeÓ
)GLKNWbPOK_RCMLK³¾GX)MLTbTÃcE
ÇÃX0Ò{jJÓ
ôÒgV`Ã8Ó X0ÒgâÓ
ÃF
8Ò

ONWUK_WbS>V)WUK_RMX0Ò^
Ã,@

FR>O!_O³¾GXNOXco=ORdMâÂXO
[Ó^Ó

R>WYP'RPMLS¿®8O_O´ØNW¹K_K_O!S¿MJ]
Á1>Ò

oEpAu2w
Á0Æ

8Ó'Ã

8Ó¿Ã

prxyyw
oEpAuKw
ÇX»ÒgQÓ
4)O!SCP(O
ªµMLÔaKX0ÒgâÓ>X»ÒÖjJÓd3

ªµMEÔa<X0Ò^QÓ6>X0Ò{jJÓd

8ÓBA

X0Ò^

[Ó^Ó

¥g°

[Ó

[Ó

Á0Æ



X»Òg

ÔO!°®C`C°VXOKGX³

JÓ
WbÂXOS%M
³¾GJ®CWUSCMX_IONNGX']cK_R>O]_POSCMX_WbG
R>WYP'RôªµMEÔWbª²WUî!O!]¸¨>_GJ®CML®CWUTbW¹KgI¢O!_NGX¸O!]^K_Wbª²MLK_OQ]©RCMJ]¸MXTUT
8Ó
O!N]HON_WbS>VÕWUS%GXS>O°Wb_OQP/K_WbGXS¸Ò¾OWUK_RCO³¾GXÃHA
P(TYMX]N]_W
[Ó^Ó&®dOQPML`d]^O²KgÑGON_GJN]WbSi°W¹ù[ONOSeK%°>WUNO!P(´
GXlÃvkX0Òg
K_WbGXSd]MLNO±P!MLSCPOTbO!°ôWUSK_RCO3]^GJ^KNWUS>VÁ¨>RCMJ]^O±GX³¶¬4NGX®CWUS>VX´
¬4NO!°>WbP(K_GXQì>`>_K_RCONª¶GJ_OJcON_GJN]=®oI¸PTbMJ]_]_W
O']=SCO!MLNOÑKNG
[Ó/c,]^WbSCPO
8ÓMX_O²¨>NO(³¾O!_NO!°K_GO!_NGX']Õ³ÖML³¾NGXª
X0Òg
X0Ò^
K_RCO%Wbª²¨dGJ^K'MLSCPO·ÑOWbVXReK_OQ°0TbGJ]N])¨CMâIJO!°®oIK_RCO¶MJ°ÂXO!N]NMLNI
X0Òg
[Ó/
WbSCP(NO!MJ]^OQ]ª²GXS>GXK_GXSCWbP!MLTbTUIW¹KNRñ°WY]gK'MLSCPO3³¾NGXª
[Ó/coMLTbTK_RCO
ÃÒ
FR>O!_O³¾GXNOXcLR>O!S¶K_R>O)¬­_GJ®>WUSCV¨C_OQ°WbP(K_WbGXS¶Wb]
³¾GXHRCWbP'R·K_R>OÑP(GXNNO!]_¨dGJSC°WbS>V²Ã%MX_O4®8O(KgÑOO!S
P(TYMX]N]_W
ÃÒ8ÓMXSC°ÅKNR>O&P(GJ_NO!P(KÑ¨C_GJ®CML®>WbTbW¹KgI
8ÓÑVJWUÂJOÕWbSCP(GJ_NO!P(K
X0Ò^
O']²VXWbÂXOP(GJ_NO!P(K
¨>NO!°WYP/KNWUGJSC]µR>O!_OQMX]¶KNR>O0GLKNR>OÅPTbMJ]_]_W
¨>NO!°WYP/KNWUGJSC]!
8Ó¿Ò¾WU³KNR>OP(TYMX]^´
X0Ò^
ÃJA
WY]%SCGXS´AîO!_G0GJS>TbI±³¾GX
[ÓKATÃLA
O!N]&ON&WUSiGJS>O©°WbNO!P/KNWUGJSdÓGJÅX0Òg
8Ó©Ò¾WU³
]_W
K_RCOP(TYMX]N]^W
O!N]ONWbS²K_R>OGXK_R>O!­°Wb_OQP/K_WbGXS8Ó/,FRe`d]cJ=OPMXS
NO(´A_WUK_OO!ëe`CMLK_WbGXS
ªµMLÔaKX0ÒgâÓ>X»ÒÖjJÓd

]&MNO!]_`>TUK!cHK_R>OÅWbSeK_O!VX'MLSC°GL³O!ëe`CMLK_WbGXS

ÃÒ
²MX]
X0Òg

[ÓA

[Óg'Ã

O!N]WÁ

ÃÒ

HG

8Ò

X0Ò^
ªµMEÔaKX0ÒgâÓ>X»ÒÖjJÓd

7

PO



NM

2013
5



5


5


}

k


º
Ò


.
Ã



.

.
&


.
Ã
	


 
É
¦
S
É
º





º






,

Ò


,
º
ä
º






9


Ò
Á

"


Ò
:

,
.

#


.
º
º
º
º
,
.
J
#


"


Ò
0
s
¥
°

ª
°
°
4
°
°
y
W
s
9

°
°
:
s
9

¥
§
:
°
°
°
°
°
°
W
s
¥
°
9

7
8
¥
§
:
°
°
5
°
°
°
5
°
W
s
¥
°
9

7
8
¥
§
:
5
°
°

°


Ò


Ò
0
s
N
u
°
¥
§
:
5
°
°
<
P
?




#
,

,

ß
Á
Æ



Á

Ò



á
#


,



 
Á
Æ






#


Ò
I
º

º

º

.
º

.

º


.

º
.
º
,


M
M
M
M
G




0






M
M
M
M
M
#


ÃÒ

[Óg

ÒIX0Òg

[Ó^ÓJ

,ªµMLÔaKX0ÒgâÓ>X»ÒÖjJÓd

ÑI©]_GXTbÂeWbS>V¶K_RCOWUSeK_O!VX'MLTØco=OVXOK

Z\SK_RCWb])K_R>O!GXNOªcCÑOª²O!MX]_`>NOK_R>O·¨>_GJ®CML®CWUTbWb]^K_WYPTbGJ]N]`C]g´
8Ó(%ÑO!P!ML`C]_O·KNR>WY]°Wb]^K_NWU´
WbS>V©KNR>O¶K_N`>Oµ°WY]gKN_Wb®>`KNWUGJSX0Ò^
®>`KNWUGJSWb]`>S>oS>GES¿³¾GXª¶Ge]gKÕ_OQMLTU´ØÑGXNTb°¸¨>NGX®>TbOªµ]!c>WUKWb]
Wbª¶¨8GX_KNMXSeKKNG`>SC°O!N]^KNMXSC°0KNR>O²WUª²¨>TbWYPMEKNWUGJSC]GL³=K_R>O²KNR>O(´
GXNOª
K_G3ª²OK_NWbP!]µK_RdMEK©GJS>TUIÁ`C]_OK_R>OP(TYMX]N]µTYML®8OTY]ÚO
P(GJSC]_Wb°O!K_R>OQ]^OµWbª²¨>TbWbP!MEK_WbGXSd]³¾GXKNR>_O!OµGL³=K_R>OQ]^Oµª²O(KN_WYP]
WbS¸KNR>O³¾GXTbTbGEWUS>V²]_`>®C]_O!P/KNWUGJSC]!

7åReêÏ<BEåoD;åJBâBE6dB©é3åe÷BEzÖ|¿@A6CB

|JèÖ<e<eQz,|X<÷QzÖ689

xyy

)GXK_OKNRCMEK

§<¨

FR>O¶TUGe]_]ÕWbS»KNR>O¶]Nëe`CMLNO!°0ON_GJª²O(KN_WYP&³¾GJPTbMJ]_]_W
WY]°O

SCO!°MX]

PMLK_WbGXS





xy

xyy

ÒD
ÃÒ8Ó^Ó
·prxyj`oEpAu2w
prq%j[oEpAuKw
{¯p
pAuQj`oEpAu2w
·prxyUj`oEpAu2w
{¯p
xyy
·prxyUj[oEpAuKw
{tpAukj`oEpAu2w
xy
oEpAu2w
xyy
xy<@{-oEpAuKw
·prxy#j`oEpAu2w
uqj0oEpAuKw
·prxyAoEpAu2w
j
·prxyUj[oEpAuKw
xy#j[oEpAuKw
{oEpAu2w
·prxyUj[oEpAuKw
{

oEpAuKw
xy
xy{

·prxy
xyy
xyy

xyy
{¯p

{Çp
xy
xy

xyy

xyy

xy

©«­
§6«­
oEpAuKw
oEpAuKw









dÒ

2jeÓoTbS

|JèÖ<e<eQz,|X<÷QzÖ689
dÒ

R>O!_OñWb])]_GXª²O¨>NGX®>TbOªÆ°O¨8OSC°>OSeKP(GJSC]gK'MLSeK!
a=GXSd]^OQëJ`COSeK_TbIXcoGX¨>K_Wbª¶WbîWbS>V¶K_RCO&]_ëe`CMX_OQ°ÅONNGXÑª¶OK_NWbPÕ³¾GJ
P(TYMX]N]_W
P!MEKNWUGJS©Wbª¶¨CTUWYP(WUK_TbI¸GJ¨K_Wbª²WUî!O!]ÑKNR>O&]_ëe`CMX_OQ°©O!_NGXWbS
K_RCO¨>_GJ®CML®CWUTbW¹KgI©O!]^K_Wbª²MLK_OJ
7å|LBE6e<e²åo9[÷BE6

ÐD
!ê¢é3åe÷BEz{|¸@A6dB
FR>OÅTbGJ]N]WbS±K_R>O¸P(NGJ]N]OSeK_NGX¨oI»ª²OK_NWbPµWY],

õa=NGJ]N]¶OSeK_NGX¨oI3°WUù8O!N]
QÓTUS
³¾`>SC°CMLª²OSeKNMXTUTbI¿³¾_GJªÀK_R>O¶]_ëe`CMX_OQ°ON_GJ)ª²O(K_NWYP&®8O!PMX`C]_O
WUKÑWY]ÒÛK_RCOGXNO(KNWbP!MLTbTUI>Ó4`>So®dGJ`>SC°OQ°ê=a=GXSC]_O!ëe`>O!SeK_TbIXcJK_R>OGX¨>´
K_WbªµMLT4]^K_'MEKNOVXIGX³=MLSMX°ÂJO']_MX_WYMLT®CWUSCMX_I0PTbMJ]_]_W
OWb]ÕKNG
ONÅ]_WUª%`>T¹K'MLS>O!GX`C]_TbIÃWUK_R;MLTbTP(TYMX]N]_W
O!N]²GJS¢GXS>O0]_Wb°>OGL³
8Ó/cÑ¨>NG°`CP(WbS>ViMLSÁ`>So®8GX`>SC°>O!°ÁTUGe]_]¶R>O!SÁK_R>O°WY]g´
X0Ò^
P(NO(KNWUîQMEKNWUGJSVJGoO!]KNG»j>ì>GJ·P(NGJ]N]OSeKN_GJ¨eI»=O©P!MLS±GXSCTUI
¨>NGEÂXO·M©ª·`CP'R=OQMLJO)KNR>OGJ_O!ª½ª¶WbS>WbªµMLT,ON_GJWbª²¨>TUWbO!]
ÃÒ8ÓÑWY]GX¨>K_Wbª²MXTê`>¨¿K_G²KNR>O&°WY]_P_OK_Wbî!MEKNWUGJS
Z\S±¨>'MXP/KNWbPOXcHK_R>WY]ÑGX']gK&PMJ]^Oµ®8ORdMâÂeWbGXP!MLS±®dO¸MâÂXGXWY°OQ°ê
ÃÒ8ÓML¨C¨>_GeMXP'R>OQ]
FR>O²MX]_Ioª¶¨>K_GLKNO·KNGHøWY]ÂXONI]^TbGEðMX]
[Ó²WbSJKNGiK_RCO
ÃÒ
j±GX»XÚa=GJSC]_O!ëe`>OSeKNTUIJcÑÑO0PMXS¢¨>_GM*gO!P(K
jXj>3_jc
j
S>OQMLNO!]^K­OTbOª²OSeKÑWUSµKNR>OWUSeK_O!_ÂEMXTß
JXEá>MXSC°µWbSCP(`>
MªµMEÔWbª²MXTTUGe]_],GX³[MX®dGJ`K4TbGXV[Òg8YLj
¸j
jXjC
jXjCQÓ
jXjCÒÖR>OSmX0ÒgâÓ
j
X0ÒÖjeÓ^Ó/cÑR>WbTUO¨>NO!]_ONÂoWUSCVMLTbª²GJ]^K
MLTbTêGL³K_RCO&°IoSCMLª²WYPÕ'MLSCVXOX

;hc

é
Ð
	
f²BEDåeBâz{9?Ð²Z\S]_GXª²O²]^WUK_`CMLK_WbGXSC]!cêÑO%ªµMâI®8O
hdå
©åoè{<÷!z
WbSJKNONO!]^K_OQ°±GXS>TbIWbS±K_RCOÅ_O!TbMLK_WbÂXOµGJN°O!_WbS>VGJ&NMXS>oWUSCVGL³

!è{zÖ|J<÷!z{6d9ie%@A6dB©6dBâDåeBEzÖ9?éÃåJ÷!BEzÖ|@e

eQz

[Ó

eJÐ

ÃÒ

<>9<>è¾

O(Ô>MXª¶¨CTUOQ]VJWUÂJOS%®eI&K_R>OP(TYMX]N]¨>NGX®CMX®>WUTbWUKgIO!]^K_Wbª²MLK_OQ]
*)S´
³¾GX_K_`CSCMEKNOTbIXc8ÂXONI¸]_ªµMLTbTHO!_NGX']WUS0K_R>O&GJN°>ONWUS>VµWUK_R»_O´
jáeP!MLSNO!]_`>T¹KWUS&ÂJONITYMLNVXOª²WY]^GJN°O!_WbS>Ve]êW¹KNR
]_¨dOQP/KHKNG·ß
j!(á[Z\SÅ¨CML_K_WYP(`CTbMX!ce]^`>¨C¨dGe]^OK_RCMLK
NO!]_¨dOQP/K­KNG%M&]_`>®C]_O(KÑGL³­ß
8Ó
jc
ÃÒ
K_RCOµGX¨KNWUªµMLT4MXSC]_=O!WY]
>c®>`KKNR>OÅMLSd]^ÑOÑO
Æj
¨>NGEÂoWb°OµWY]
ãJXJXCÅZA³OÂXO!_IGLKNR>O%OTbOª²OSeK·WbS
K_RCOGX'°ONWUSCV%WY]WbS¸KNR>OWbSJKNONÂEMLT­Ò{j
ãJXJXc_j
XÓ(cLKNR>OSKNR>Wb]
]_ª²MXTUTONNGXNO!]_`>T¹K']WbS»MµÂJONI¸TYMLNVXOGJN°>ONWUS>V©ON_GJ)W¹KNR
NO!]_¨dOQP/KK_G²KNR>O&]^OKGL³,OTbOª²OSeKN]!
À
*aÓ4Wb]
GXSCOPGXª²ª²GXS>TbIµ`C]_O!°¸_O!TbMLK_WbÂXOGX'°ONWbS>V·ª²O(KN_WYPL­Ý`>¨>¨8GJ]_O
8Ó
×
ÚJc3X0Ò
ÑORCMâÂXOÑGXS>OOÔ>MLª²¨>TbOÑWUK_RµTYML®8OT
8Ó
ñjCcMLSC°
$ÃOÔMXª¶´
µÒ
MLSd°»¬4NGX®CWUS>V¸O!]^K_WbªµMEK_OQ]
¨>TbO!]WUK_RTYML®8OT
ôj>ccX0Ò
ð8Y+$»R>O!_O&¬­_GJ®´
ð
8Ó
8Ó
Æ+Y8$¶Z\SKNR>WY]]^OK^K_WbS>VdcK_RCO
Æ
WbS>VO!]^K_Wbª²MLK_OQ]
µÒ
SCO!°¸WUS±ß¹(áÛÓÑWY]j>ÕO!]_¨>W¹KNOK_R>WY]ÑK_O!_NWU®CTUO¨dO!^´
*aðÒÖMJ]°O
³¾GXNªµMLSCPOXc,KNR>OP(TYMX]N]^W
O']%S>OOQ°3ON¶GXS>TbIiGXSCPOX3FR>WY]¶Wb]
ÔoOQ°»Wbª²¨dGJ^K'MLSCPO²=O!WUVJRJKNO!°»TUGe]_]'MEK_O¶³¾GJ
TbO!]N]K_RCMXSMXSeI
]_`ÅP(WbOSeK_TbI©TYMLNVXO
$
¥dÍ

_OQM`>SC°>O4KNR>OÕ)Üa¼P(`C_ÂJO&Ò
×

ü

ý%û¢ü

üHÉ

¤¦

¤£

£oÌ

QáÒ

ïML'P'R>WbÂXOÅß

KNR>O+*a=Z

³¾NGXªÆK_R>O+*a=ZªµMXP'R>WbS>O&TbO!MX_SCWUS>V©_O!¨dGe]^WUK_GJ_Iß
`d]gKNNMXTUWYMLSa=_OQ°W¹KQc>Ñ_OQMX]^K!cDWYML®8O(KNO!]!cCí­P'RCGoP!ML'°WbGXVX'MLªc
EáÒ-a=`>¨
LjJjLã-a=`>¨¼ÒÖÑW¹´

)O!_O%=O¶¨>NO!]_OSeKKNR>O¶_OQ]^`>TUKN]ÕGX®>KNMLWbS>OQ°®oI0ML¨>¨>TbIoWUSCVÅK_RCO
¬4NGX®CWUS>V²NO!°`dP/K_WbGXSKNG
³ÛKNOOS¼Ò¾®>WbSCMLNI>Ó°>MLKNMX]_O(K']½=OTbOÂJOS
°`>TUK!c
)O!¨CMEKNW¹KNWb]!cZ\GXS>Ge]^¨CR>ONOXc_´AÂo]^´Ae¨Hc¸fWbÂXO!!c¿`C]_R>NGeGJªc
ÝoWYP'>Ó/c8Kg=GÅ³¾_GJª
X©MLSC°»aÜÕZgfÓMLSC°Kg=G²³¾NGXªÀK_RCO
GXTbGXVJIÅMLSC°¬­ReI]_WbP!]NÓ(
O%`C]_O&³¾GJ`>°WUù8O!_O!SJK®CMX]_O%PTbMJ]_]_W
OÕTUOQMLNS>O']MâÂEMLWbTYML®>TbO
WUK_R>WbS±K_R>O¸ªµMXP'R>WbS>OµTbO!MLNS>WbS>V¿K_GoGXT=O!EM3ß¹âQáA½&K_RCO©Xãe
°OQP(WY]^WbGXS·K_NOOÑTUOQMLNS>OQcQK_R>O)ÝÜ;]^`>¨C¨dGJ^K,ÂXOQP/K_GJ,ª²MJP'R>WbS>O
Ò{ÝÞÕ»ÓHTUOQMLNS>OÑÒ¾TbWUSCO!MLXO!_S>O!TYÓ(cEMLWbÂXO=ÑMâIJO!]MXSC°TbGXVJWb]^K_WYP
NOVXNO!]N]_WUGJSHì>GJ­P'R>GoGJ]_WbS>VK_R>O=O!WUVJRJK']cJ=O`d]^OKNR>O¬­_GJ®´
WbS>VÂâMX_WYMLSeKK_RCMLK4MEK^KNOª²¨K']K_GGX¨KNWUª²WbîOP(NGJ]N]OSeK_NGX¨oI³¾GJ
!jJj²W¹KNO'MEKNWUGJSC]Õì>GXÕ_OQMLTbWUî!WUSCV²K_R>O¶WUª²¨8GX_KNMXSCP(O&ÑOWbVXReKNO!°
P(TYMX]N]_W
MLTbTbI0K_G0K_R>O¸=O!WUVJRJK']NÓÕ³¾GJK_RCO¸°OQP(WY]^WbGXSK_NOO©TUOQMLNS>O&MXSC°
³¾GXÑTbGXVXWY]^K_WYPNOVJ_OQ]_]_WUGJScXMXSC°ÅVJWUÂJO)K_RCOÑOWbVXReK']=°WbNO!P/KNTUI¶KNG
K_RCOTUOQMLNS>O']=³¾GXÝoÞMXSC°MXWUÂJOMâIJO!]ÒÖ]_OOÅßUâl!á¾Ó/
OMX_OWbSeK_ONO!]^K_OQ°&WbSµP(GXª²¨CMX_WbS>VK_R>O¨8O_³¾GXNªµMLSCPO=GX³CK_RCO
¬4NGX®CWUS>VµNO!°>`CP/KNWUGJSW¹KNR0]gK'MLSC°>MXN°ª²OK_R>G°>])³¾GXGJ®KNMXWUS>´
WbS>V¸¨C_GJ®CML®>WbTbW¹KgIO!]^K_WbªµMEKNO!]³¾_GJªK_R>OQ]^O²P(TYMX]N]^W
O!N]!-ÕO!PW¹´
]_WUGJSK_NOOQ]HMLSd°&MXWUÂJO=MâIXOQ]ê¨>NGo°>`CP(OÑMLS&WbSeK_ONSCMXTJ]NP(GXNO4WbS
j!(áXKNRCMEKPMLS®8O4`C]_O!°·MX]M)PTbMJ]_]¨>_GJ®CML®CWUTbW¹KgI
K_RCO­WbSJKNONÂEMLTCß
O!]^K_WbªµMEKNOXcQ®>`KHKNR>OIMLNO,oS>GESK_G)®8O4WbSCMXP!P(`>'MEKNO)ß¹QhâáØì>GJ
K_RCWb]NO!MJ]^GJScE®8O!]_Wb°OQ]K_OQ]gKNWUS>VKNR>OWb4¨8O_³¾GXNª²MXSCP(OJcE=ORCMâÂJO
MLTY]_G»KNO!]^K_O!°¼ÑOTbT¹´AoS>GESÃª²O(KNR>G°>]²³¾GJ¶GJ®KNMXWUSCWUS>V±®8O(K_K_O
KNR>O!]_O»PTbMJ]_]_W
¨>NGX®CMX®>WbTUWUKgI¼OQ]gKNWUªµMLK_O!]Å³¾_GJª
O']½®CMLVJVXWbS>V
O!N]'ÓMLSC°iP!MLTbWU®CNMLK_WbGXS`C]g´
³¾GX%°O!PWb]_WUGJS±K_NOOQ]ÅÒgQjXjP(TYMX]N]_W
WbS>V¿M¸]^WbVXª²GJWb°³¾`CSCP/KNWUGJS»³¾GJÕMLWbÂXO%MâIJO!]·ß
kEáA·ÝoWbSCP(O%K_RCO
O°GoO!],SCGLK¨>NGo°>`CP(O¨>NGX®CMX®>WbTUWUKgIO!]^K_WbªµMEK_OQ]c
ÝoÞÀPTbMJ]_]_W
ÑO%RCMâÂJO·KNO!]^K_OQ°»GJS>TUIKNR>Oµ]gK'MLSC°CML'°ª²O(K_RCGo°³¾GJGJ®KNMXWUS>´
WbS>V¨>NGX®CMX®>WUTbWUK_WbO!]³¾NGXªÝÞÕ
ÒÖMXTb]_GMâÂEMLWbTbMX®>TUO²WbSiO!EMJÓ/½
PMXTUWb®>'MEKNWUGJS©`C]_WUSCVÅM¶]_WbVXª²GXWY°Å³¾`CSCP/KNWUGJS±ßUX(áØ

P!MEKNWUGJSc,=O¸`C]^O¸_OT*gO!P(K_WbGXSÃ]NMLª²¨>TbWUSCVÃÒ¾¨>NGX¨8GX_K_WbGXS>´

202,
.
#



 
Ð
~
ä
º
º
,
.
J

¥
Z
]
Z
s
¥
:
Z
]
Z
:
Z
]
Z
<
s
¥
§
:
Z
]
Z
s
¥
§
]
Z
]
s
¥
§
p
]
Z
Z
s
¥
§
p
]
Z
º
 
ä



0




0




º
º

.
.
.




 
.
.
}




.





.



º
º
º

ý
º


º
º
º
º
º
º
ª²OQMLSC]=K_RdMEKK_R>OPTbMJ]_]_W

P(NGJ]N]=OSeK_NGX¨oI²GL³

eQÏèÖ÷0eJÐ¶FR>Oµ¬­_GJ®>WUSCV©NO!°`CP(K_WbGXS0GJ`K^´
O³¾GJ»MLTbT·°>MLKNMJ]^OKN]®>`K

WbSK_R>OK*a=ZNO¨8GJ]_WUK_GXNIXcd=O%`C]_O&K_RCO%]^KNMLSd°>ML'°]^¨CTUWUK!ì>GJ

MLSC°i³¾GX%K_R>O¿ªµM+*gGXNWUKgIGX³)K_R>O¿°>MEK'MX]_O(K']%MXTb]_G

ì>GJ·°>MLKNMX]_O(K']K_RdMEK·RCMâÂJOÅM]gK'MLSC°CML'°»KNNMXWUSCWUS>V QKNO!]^K·]^¨>TbWUK
K_RCO·GLKNR>O°>MLKNMX]_O(K']c8ÑO&NMXSC°GJª¶TbI]^¨>TbWUKÕKNR>O%°>MLKNM©WUSeK_G¸M
K_'MLWbS>WbS>V]^OKW¹KNR±hJhÀGX³­KNR>OµO(Ô>MLª²¨>TbO!]MXSC°M¸KNO!]^K·]^OK
WUK_RkXkïGL³K_R>OOÔ>MLª²¨>TbO!]!
O%`C]_O%K_R>NOO¶°W¹ù[ONOSeKª²O(K_NWYP]Õ³¾GXMX]N]^OQ]_]_WbS>VµK_RCO¶MJPP(`>´
'MXP(IGX³4K_R>O²¨>NGX®dML®>WbTUWUKgIO!]^K_WbªµMEK_OQ]½Õ_GoGXKÕª²O!MXS]NëJ`dMLNO!°
ONNGXÒ{)»Ý>Ó(coP_Ge]_]4OSeK_NGX¨oIÒØaÕíÑÓ4MXSC°ÅMLNO!M`CSC°O=K_RCO
*aÓ/ì>GJ=ª²GXNOÕ°>O(KNMXWUTY]ÑML®8GX`K=K_R>OQ]^Oª²O(K^´
)ÜaÁP(`>NÂXO¶Ò
NWbP!]©MLSd°ÙMLSôMXSCMLTbI]^WY]ÅGX³K_R>O!WUP'RCMXNMJP/K_O!_WY]^K_WYP]!c)]^O!OÃß
ãXáØ
FR>O)NO!]_`>TUKN]­GXS¶K_R>OK_OQ]gK=]_O(K=`C]^WbS>V¶aí)ce)»Ý²MLSd°
*a
ÕMXSC°¶k>,)GLKNOÑK_RCMLK
MLNO]^R>GESHcL_OQ]^¨8O!P(K_WbÂXO!TUIJcEWUS¶KNMX®>TbO!]Xc
³¾GX¸)»ÝÁMLSC°ÙaíïK_R>O0]_ªµMLTbTUO!µK_R>OÂEMXTU`>OKNR>O0®8O(K_K_O
*aðK_RCOµTbMX_VJOK_RCOµÂâMXTU`CO
K_RCOÅ¨dO!^³¾GJ_ªµMXSCP(OJcR>WbTUOµ³¾GJ
K_RCO®dOK^K_O!K_R>O¨8O_³¾GXNªµMLSCPOX)GXK_OMLTY]_G·KNRCMEK
*a¢GXSCTUI
ª²O!MJ]^`>NO!])R>GEÚ=O!TUTHK_R>O%¨>_GJ®CML®CWUTbW¹KgI¸O!]^K_WbªµMEK_OQ])'MLS>¸K_RCO
O(Ô>MXª¶¨CTUOQ]·³¾NGXª
K_R>Oª²GJ]^Kµ¨>_GJ®CML®CTUO¸K_GK_RCO¿TbO!MJ]gKµ¨>NGX®>´
ML®CTUOÅª²O!ª·®8O¶GL³K_RCO¸P(TYMX]N]!cRCWUTbO¸)ÝiMLSC°ÁaÕíðMXTb]_G
ª²O!MJ]^`>NOK_R>O&P!MLTbWU®CNMLK_WbGXS©GX³HKNR>OO!]^K_WbªµMEK_OQ]
¿åe|Jz
¨8O_³¾GXNª²]»MÁ]_WbS>VXTbO3Xãe¢P(TYMX]N]^W
`C]_R>NGoGXª
GX`>K_¨8O_³¾GXNª²]MLVJVXWbS>VÃJãJCcGXSôK_R>OKNR>_O!Oª²OK_NWbP!]
OÑ¨>_OQ°WYP/K_OQ°
¨>NGX®CMX®>WbTUWUKgIµGXS>O³¾GJMXS¸OÔ>MLª²¨>TbOÕR>Ge]^OTYML®8OTêWY]îO!_GÒ¾GJ
ÂoWbPO(´AÂXO!N]NMJÓ(ÅFR>Wb]&Wb]GX³ÛK_O!SKNR>O©P!MX]_O%³¾GJK_RCOÅXãe¿PTbMJ]_]_WU´
O!!cX]_R>GEWbS>VÕK_RCMLK4W¹K'],WUSeK_O!_SdMLT>]NP(GXNO!],MX_OÑS>GLKNO!MJ]^GJSCML®>TbO
P(TYMX]N],¨>NGX®CMX®>WbTUWUKgI·OQ]gKNWUªµMEKNO!]³¾GJ­P(NGJ]N],OSeK_NGX¨oI&TbGJ]N]!MLVX´
VXWbS>V±]^GJTUÂJO!]%K_RCWb]²¨>NGX®CTUO!ª
®oIiKNMXeWbS>V±MX°ÂEMXSJK'MLVJO¸GX³K_RCO
WbSC]gK'ML®>WbTbW¹KgIµGX³K_R>OTbO!MLNS>O!=GEÂJO=°>W¹ù[ONOSeKÑK_'MLWbS>WUSCV%]_O(KN]=KNG
MâÂXO!NMXVXOGX`>KO(ÔoK_NOª²O&NO!]_`>TUKN]!))GEÑOÂJOQc>WUS0P!MX]_O!]R>ONO
-a=`>¨0Jµ°>MEK'MX]_O(K/Ó
K_RCONO&Wb]S>GÅWbSC]^KNML®CWUTbW¹KgI±Ò¾TbWbXOKNR>O
®CMXVXVXWbS>V¨8O_³¾GXNª²]K_R>O]NMLª²OMJ],K_RCO)®CMX]_O)P(TYMX]N]_W
O!N]!FRCO
]NMLª²O=GJ`>Tb°%®8OK_N`>OW¹³[=O)MX¨>¨>TbI&®CMXVXVXWbS>VÕK_GGLKNR>OTbO!MX_S>´
O']ÑK_RdMEKMLNO]gK'ML®>TbO&]^`dP'R¿MJ])ÝoÞÕ
eQÏèÖ÷0eJÐ¸FR>OÅ¬­_GJ®>WUSCV¸NO!°`dP/K_WbGXS±GJ`K_¨8O_³¾GXNªµ]
ö
K_RCOÝoÞøWUK_R¢]_WUVJª¶GJWb°ÃPMLTbWb®>NMLK_WbGXSi³¾GJ%ª²Ge]gKµ°>MEK'MX]_O(K']
GXSMLTbTKNR>NOO·ª²OK_NWbP!]FR>O
*aª²O(KN_WYP%_OQ]^`>TUKN]]_R>GE×M
VXNO!MLK_O!ÑMJ°ÂEMLSeKNMXVXOGL³¬­_GJ®>WbS>V·GEÂJO]^WbVXª²GXWY°©P!MLTbWU®CNMLK_WbGXS
K_RdMLSK_RCO4KgÑGGLK_RCOHª²OK_NWbP!]HFRCWb]HWb]H¨>_GJ®CML®CTUI°`>O4KNGK_RCO
³ÖMXP(KK_RCMLK&K_RCOÅ]^WbVXª²GXWY°±PMXTUWb®>'MEK_WbGXSªµMLWbSeKNMLWbSC]KNR>O©]NMLª²O
'MLS>oWbS>V¿MJ]VXWbÂXO!S®oIKNR>O©ÝoÞÕòªµMX_VJWUSC]R>WbTbOÅ¬4NGX®>WbS>V
PMXSVJWUÂJO¶M¿®8O(K_K_O'MLSCeWbS>V¿®CMX]_O!°GXSK_RCO¶NO!]_`>TUKN]GX³­K_RCO
°WUù8O!_O!SeK)=O!WUVJRJKNO!°¿P(TYMX]N]^W
eQÏèÖ÷0eJÐÃFR>O¸¬­_GJ®>WbS>V0NO!°`CP(K_WbGXS3GJ`K^´
	<>z
¨8O_³¾GXNª²]M
Oô³¾GXª²GJ]^K
°>MLKNMX]_O(K']GJSK_RCO¶P_Ge]_]OSeK_NGX¨oIMLSC°0]Nëe`CMLNO!°O!_NGXÕª²O(K^´
NWbP!]ÀÜÕSôK_R>O
*aÀª²O(K_NWYPLcR>GE=O!ÂXO!!cMÁ]_WUS>VJTUO±MXWUÂJO
MâIXOQ]&P(TYMX]N]^W
O!·`C]_`CMLTbTbI¨8O_³¾GXNªµ]·]_TUWbVXReKNTUI®dOK^KNO¶K_RCMXS
¬4NGX®CWUS>VMXWUÂJOÑMâIXOQ]FR>Wb],ªµMâI®8O°`>O=K_GMXWUÂJOÑMâIXOQ]
O!]^K_WbªµMEKNO!]µ'MLS>oWbS>V=O!TUT·Ò{MLTUK_R>GJ`>VXRÁWUK_R¢K_O!_NWb®>TUO¨>NGX®>´
ML®CWUTbW¹KgIiOQ]gKNWUªµMLK_O!]'Ó/c=R>WbTUO¬4NGX®CWUS>VO!]^K_WbªµMEKNO!]¶RCMâÂXO¿TbO!]N]
NO!]_GXTb`K_WbGXS¿TUOQMX°WbS>V²KNGµª¶GJ_OKNWUOQ]ÑFR>ONO!]_`>T¹K'])MLTY]_G²]_R>GE
K_RdMEKÕMLWbÂXO­MâIJO!]êWUK_R·]_WbVXª²GXWY°PMXTUWb®>'MEK_WbGXSGJ`K_¨8O_³¾GXNªµ]
¬4NGX®CWUS>V)ÕMLWbÂXOÑÑMâIJO!]êGJS&ª²GJ]^K°>MLKNMJ]^OKN]WbS·MXTUTJK_R>NOO=ª²O(K^´
NWbP!]&ÕMLWbÂXO²ÑMâIJO!]Wb]S>GXKM¸ÂXO!_IMXP!P(`>'MEKNO%PTbMJ]_]_W
O']Õ]_G

MLSd°¸ÕMLWbÂXOMâIXO!]!

O!N]!

hdå;y¶<X8å!e±BEå

]_WbS>VXTbOïÕMLWbÂXOïÑMâIJO!]õP(TYMX]N]^W

eQzÖ689ô÷!BEåeå±BEå

©å


Ä,4<B
Ä,4<B
@"#%!#"
@"#%
Ä,4<B
%40%
@"#%
%
%
Ä,4<B
%
%
$#"
Ä,4<B
%

6) 01)

Ä,4<B
µ83C3 #)
Ä,4<B
C!A),  .".$
".40 #4<% 
$%40%
Ä,4<B
,A)
Ä,4<B
Ä,4<B
&'(%
".B1)
Ä,4<B)"
%c4<%
/ +!42/6, 83"#4
!)"*)"#
Ä,4<B
0%
'I4<$!40!+31,
,40B%c4<%
+

,.-
0%
57
,0/
0%
%c".5<1,
¿C!+@,424<
$)"
Ä,4<B
+# @"#/
Ä,4<B
@"#/
FMX®>TUOãd½,ÑOQ]gK)ª²O(KNR>G°¿¨dO!°>MEK'MX]_O(K1 âª²O(KN_WYPL


Ä,4<B
Ä,4<B
@"#%!#"
@"#%
Ä,4<B
%40%
@"#%
Ä,4<B#"
%
Ä,4<B
%
%
$#"
Ä,4<B
%

e!÷!zÖ|

K_RCOÅ¬4NGX®>WbS>V¿_OQ°`CP/KNWUGJScHRCWbP'R±NOTbWUOQ]GXSK_RCMLK·MXP!P(`>'MXPI
³¾GX²°WUù8O!_O!SeK¶ÑOWbVXReK¶]_O(K_K_WbS>VJ]!cWY]%SCGLK%GJ¨K_WbªµMLTØÃÜÕS3K_RCO
GLKNR>O·RCMLSC°cK_RCOÅ]^WbVXª²GXWY°±ML¨>¨C_GeMXP'R»RdMX]&M]_O¨CMXNMLK_O
K^´
K_WbS>Vµ]^KNMLVJOÕRCWbP'R¿PMLS¿NO¨CMXWUÑ®CMX°©O!]^K_WbªµMEK_OQ]ÑK_G²]^GJª²OOÔo´
K_O!SeK!ì>`>_K_R>O!_ª²GJ_OJcCKNR>O%]_WUVJª²GXWY°K_'MLSC]^³¾GXNªµMEKNWUGJS¿ªµMXWUS´
KNMXWUSd]ÕMX¨>¨>NGâÔoWbªµMEKNOTbI©KNR>O¶]NMLª²O&'MLSCeWbS>V¸GL³4O(Ô>MXª¶¨CTUOQ]ÕMJ]
K_RCOGJ_WbVXWbSCMXT8ÕMLWbÂXOÑMâIJO!]ÑP(TYMX]N]^W
O!!ceTUOQMX°WbS>V%K_GµML¨C¨>_GâÔWU´
ªµMEKNOTbIµK_R>O&]NMLª²O
*aÕ
e<e!z{6d9=ÐñFR>O»¬­_GJ®>WbS>Vi_OQ°`CP(K_WbGXS¢¨dO!^´
:­68?8z
©åo?CBEå
³¾GXNªµ]H®8O(K_K_O!KNRCMLS¶M]_WUSCVXTbO=fGJVXWY]gKNWbP=OVJ_OQ]_]_WbGXSP(TYMX]N]^W
O!
³¾GX%GX¨KNWUª²WbîWbS>V»P_Ge]_]^´ØO!SeK_NGX¨oIXÅZ\S¼]^GJª¶OÅP!MX]_O!]!cfHGXVJWb]^K_WYP
O!VXNO!]N]^WbGXSÅIoWbOTY°>]M²P(NGJ]N]­O!SeK_NGX¨oIµGL³;cR>WbTbO&¬4NGX®>WbS>V
VXWbÂXOQ]·M»_OQMX]_GXSCMX®>TUO©_OQ]^`>TUK!ì>GJ·KNR>O©KgÑG»GXK_R>O!·ª²O(KN_WYP]
K_RCONOWY]S>GXK)MµP(TbO!ML°WUù[ONOSCPOX
FGVXO(KM®dOK^K_O!HWY°O!MGX³R>WbP'RMXTUVJGXNW¹KNR>ªµ]êMLNO¨dO!^³¾GJ_ª²WbS>V
®8O!]^K!c[=O%RCMâÂXO·GXS>O&TYMX]^KK'ML®>TbO%PGXSC]_WY]gKNWUS>V©GL³K_RCO%ª²O(KNR>G°
K_RdMEKTbO!°KNGÅ®8O!]^K)K_OQ]gK¨8O_³¾GXNªµMLSCPO³¾GXÕO!MXP'Rª²O(KN_WYP&MXSC°
XjGJ`KGX³dão)OÔo¨8ONWU´
°>MLKNMX]_O(K,WbS·K'ML®>TbOãC¬­_GJ®>WbS>VWbSC],WbS
ª²OSeKN],MXVJMLWbSC]^KHKNR>O=GXK_R>O!HKNO!]^K_OQ°·MLTUK_O!_SdMEK_WbÂXOQ]­Ò{Xãe>cLMXWUÂJO
MâIXOQ]c­ÝoWbVXª²GJWb°ÁMXWUÂJO¿MâIXOQ]c­ÝWUVJª¶GJWb°ÁÝoÞÕ3c­MLVXVJO!°
K_O!_OQ]gKNWUSCV%KNG²S>GLKNOK_RCMLKK_R>O¨8O_³¾GXNªµMLSCPOÕGX³KNR>O&°O!PWb]_WbGXS
K_NOOJc8JãJCcCWY])ÂJONI©VXGoG°ê)FR>WY]Õª²MâI¿®8O%°`>O2KNGµK_R>O·³ÖMXP(K
K_RdMEK,K_R>OGXK_R>O!TUOQMLNS>O']HK_RCMLK4=OMLNO`C]^WbS>VMLNOÑTUWbS>O!MXÒ¾ÑO
RCMâÂJOÕS>GXKK_NWUOQ°°W¹ù[ONOSeKXO!_SCOTY]Ñ³¾GXÝoÞ»Ó/
ìWUSdMLTbTUIJcK_GµVJWUÂJOMXS¿WY°OQM%GX³KNR>O&]_¨dO!O!°¿GL³P(GJSeÂJONVXO!SCP(OÕGL³
¬4NGX®CWUS>VµWbS¨>'MXP(K_WYP(OXcd=O·¨>TUGXKKNR>O·P(NGJ]N]O!SJKN_GJ¨oI©¨8O_³¾GX_´
ªµMLSCPO&Ò¾`C]_WbS>V&XãeJÓMLVeMLWbSC]^KKNR>O)So`>ª·®8OGX³[¬­_GJ®>WbS>VW¹KNO_´
MEKNWUGJSC][³¾GJNO¨>NO!]_OSeKNMLK_WbÂXO,°>MEK'MX]_O(K']êWUS
VX`>NOX¬4NGX®>WbS>V
]_OOªµ]KNG&P(GXSoÂJONVXO4KNG&M_OQMX]_GXSCMX®>TbO­¨>NGX®CMX®>WbTUWUKgI&O!]^K_WbªµMEKNO
ME³ÛKNO
Xj%GJ)]^G²WUK_O!NMLK_WbGXSC]!

ÕO!P(WY]_WUGJSF_O!O¶MXSC°fGXVJWb]^K_WYP²OVJ_OQ]_]_WbGXSdÓ(·ZAKWb]MXTb]_G¿WUS´

Í^£o§êÌ£o£oÍgÊ

¬4NGX®CWUS>VñWb]¢MðVJOS>O!NMXT©KNO!P'R>SCWbëe`>Oõ³¾GX¢P(GJSeÂJO_K_WbS>VñMXSeI
O!±TUOQMLNS>O±WbSJKNG×MõPTbMJ]_]±¨>NGX®dML®>WbTUWUKgI×O!]^K_WbªµMEKNGXQ
P(TYMX]N]_W
)87
g0 #4V4<"#B3 .)+
&(+!"#/>+"#$3+!1,"*)
56'
,40:3N

6)j)+3(83"#%<$M499

"#465K>,o\!)²)4t)+3'i8!) 1)N

203



º

º
º
º


º
º

º
º



p
y

[

[

[




[

[

*

[






+
,
,








/


º
º

º
º
3
4
É
º
p
9
;
y


2u




		

6) 01)
=83C3 *)
C!A),  .".$
"#4< #4<%
,A)
&'(%
";B1)
/ +!42/6, 83"#4
!)"*)"#
'I4<$34<!+31,
+

,(-
5@
,0/
%c"#5K1,
¿C3+3,424<
+! 3"#/
@"#/

0%
--

=7u


	






	

	




Ä,4<B

	
	






	
;

		

	


@"#%)"








	

-@u


		


		

		



!

Ä,4<B)"



2u



	
;








	

! 	

-7u
=7u

FML®>TbOµX½­a=NGJ]N]ÑOSeK_NGX¨oIÅNO!]_`>TUKN]!,FRCO®dOQ]gK)NO!]_`>TUKN]Ñ³¾GXOQMXP'R¿P(TYMX]N]^W

7"#%

2u





	




 

	
;

	

	



! 	



,40B


;

	

;


;
;


;

-


! 	

%40%
;
=@u


		
!;
		
;
		
		

Ä,4<B%4<%





	

1

	
	
		
! 

	

MLSC°¿MXWUÂJOMâIJO!]'Ó­MX_OWbS¿®8GXTY°ê


;

u8-@u
7u8-

u8-
O&Ò{Xãe>c>ÝoÞ

6) 01)
=83C3 *)
C!A),  .".$
"#4< #4<%
,A)
&'(%
";B1)
/ +!42/6, 83"#4
!)"*)"#
'I4<$34<!+31,
+

,(-
5@
,0/
%c"#5K1,
¿C3+3,424<
+! 3"#/
@"#/
FMX®>TbO







;

2u8-
=-
;

		
-

0%








-




2u8-
=@u







!	 

Ä,4<B
 
		

	
		
	
	
		

7u

=-7u

=@u

u<u

@"#%)"


	






"


2u8-


	

		
;

!

Ä,4<B)"





	






	





! 




;

;


!;






u8--

7"#%




	

=-





	
!;

	

		




	



!


! 

,40B





	

;1

	


	



	

=7u

u8-

%40%
2u
	
!;
		
" 
	
	


!;
		

;

Ä,4<B%4<%
	


	
		
!;1

	

!
	


!

>½­Ýëe`CMLNO!°©ON_GJ_OQ]^`>TUKN]!FR>O®8O!]^K)_OQ]^`>TUKN]Ñ³¾GJO!MJP'R¿PTbMJ]_]_W

OÒÖJãJCcCÝoÞÕ

MLSd°¿ÕMLWbÂXOMâIXO!]'ÓÑMLNOÕWbS®dGJTb°

) 1)
µ83C! *)
µC3A), 0 #".0$
"#4< #40% 
,0A)
&'
".0B>)
/>+342/, 8@".4

6)"*)".
'40$!40!+!>,
+

,.-
57
,0/
%"#5K>,
¿C!+3,4240
W+! @"#/
7"#/
FML®>TbO¶kC½
®8GXTY°ê


;
;


;1

--
		
1
;

%
-7u









	

			


			
;

,40B




	

	

		



	








---
			



		

@"#%!#"
=7u
-@u

		
	



--
u0u
		
;


Ä,4<B#"





	
;

		

	


1

		



		


			

	


	

	

		

@"#%


	




=-





	

	

 

	





=-

	

	

		

		
	

Ä,4<B
-7u
;






;


;
;

--
-

		

%40%
-7u





	

	
-

--
			

;

Ä,4<B%40%




		

	

u<u


u8-
;;

	

		



		

	
			



		

_OQMÅ`>SC°>OK_R>Oµ)ÜaNO!]_`>TUKN]!&FR>O%®8O!]^K_OQ]^`CT¹K']³¾GJO!MXP'RP(TYMX]N]^W

O²ÒÖJãJCcÝoÞÕMLSC°MXWUÂJO¶MâIXOQ]NÓMLNO·WbS

204


[

[


[

 
=
N

=
N
-
=
N
-

-
=
N
;
 
 
=
N
=
N
 
=
N
=
N
u
=
N
;
=


 
 
=
N

=
N
=
 
=
N
=

u
=
N


 
=
N

-

=
N
=
N
=
=
N
=
u
N
=

=
N



=
N



=
N


;
=
N
=
N
=
=
N

=



 
=
N

=

=
N
 
=
N
u
=
N

u
N

=
N
-


=
N

=
N
-
=

=
N

=
N
*
=
N
=
N
=
N

-
;
u
N

u

=
N
-

N
 
=
N

=
N

u

 
=
N
=
N

=


=
N


-
=
N


-
 
=
N
u
+
,
,

 
=
N
=

-
=
N
u
=
N

u

=
N

u

=
N
u
 
=
N
=
N

=
N
-

=
=
N
-
;
=
=
N

-

=
N
=
=

=
N
=
=
N
=
N

=
N
=
=


 
=
N
=
N

=
;
 
=
N
-
=
N

-

/
 
=
N
=
=
N

=

=
N
=
N
=
 
=
N
u


º



[

[


[

=
N

=
N
u
=
N



=
N
=
N

=
N

=
N



=
N

=

=
N


=
=
N

=
N
=
N


 
=
N
=

u
=
N
=
=
N
=
;

=
N
=
=
N

=
N
=
;
=

=
N
-
=
N
-
=
N
=
N

=
N
=
N

=
N

=
N

=
N

;

=
N



=
N

=
N

=
N



=
N
=
=
N
=
=
N

u


=
N
-
=
N
=
=
N
=
N
=
N
-
=
N
*
=
N

-
=
=
N
=
N
=
N

=
N

=

=
N
-
=
N

=

=
N
;
=
N

-
;
=
N

;
-
=
N

;
u
=
N

=


=
N
=
N
=
N
=
N

=
N

+
,
,

=
N

=
N
=
N
u

-
=
N

=
=
=
N

=
=
=
N
u
;

=
N
=
=
N
u
=
N
u
=
N
=
N
-
=
N
=
N
=
=
N

=
N
=
=

=
N
u


=
N

=
N
=
=


=
N
;
=
N


;
=
N
=
N

-
=
=
N

-
=
=
N

/
=
N
u

;
=
N
-
=
N

=
;
=
N
=
N
=
=
N
u
º




[

[

[

=
N

=
N

=
N
-
=
N
-
=
;
=
N
-
=

=
N
-
=
=
=
N
-
=
N

=
N

=
N


=
N
=
N
-
=
N
-


=
N
-
=
N
-
=
N
-

u

=
N

=

=
N

=

=
N
-
=
N



=
N



=
N

%
=
N
;
=
=
=
N
u
=
N
;


=
N

=
N

=
N

=



=
N

u
;
=
N

-

=
N

u

=
N
-
=
N
-
=
N


=
N
;
=
N
=
N

=

=
N
=
N
*
=
N
=
N

=
N
=
N

=
N

=
N

=
N

-
;
=
N
-
=
N
-


=
N
-

=
=
N
-
=
N
-
=
;

=
N
;
=
=
=
N
;
=
=
=
N
;
-

=
N

=

=
N

u

+
,
,

=
N

=
N
=
N

=
N
-
=
N
;
=
N

=

=
N



=
N

=
N

=

=
N

u
=
=
N
=
=
N
=
N

=

=
N
=
N

=
N

/
=
N
-
=
N
-
=
N
-

=
=
N
-

-
=
N
-

-
=
N
-

º
pAu

<ih

-6<ih
=6<
u<u/<

Diabetes
Hepatitis
Adult
COIL
Sick

y
p
o
r
t
n
e
−
s
s
o
r
C

2
.
1

0
.
1

8
.
0

6
.
0

4
.
0

2
.
0

0
.
0

0

20

40

60

80

100

Iterations

ìWUVJ`>NO»X½a=_Ge]_]%OSeKN_GJ¨eIÂ]±KNR>OSo`>ª·®8O²GL³¬4NGX®>WbS>V
WUK_O'MEKNWUGJSC]Ñ³¾GX%NO¨>NO!]_OSeK'MEK_WbÂXO°>MLKNMX]_O(K']Ò¾`C]_WUSCVÅXãeJÓ/

]^R>GE)]·K_RdMEK²K_R>O¿¨>NGX®>WbS>V_OQ°`CP(K_WbGXSÃWY]¶=O!TUT
FR>O!GXNOª
³¾GX`CSC°O!°½VJGoGo°¨8O_³¾GXNª²MXSCP(O¶GXSK_RCO²P_OQMEKNO!°P(TYMX]N]^W
PML´
K_WbGXS¨>NGX®>TbOªµ])Wbª²¨>TbWUOQ]ÕVJGoGo°0¨dO!^³¾GJ_ªµMLSdP(O&WUK_R_OQ]^¨8O!P(K
K_G;¬­_GJ®>WUSCVÃ¨>NGX®CMX®>WbTUWUKgI¢O!]^K_Wbª²MLK_OQ]ÀíÔ¨dO!_Wbª²OSeKNMXT_O´
]_`>T¹K']&]_R>GEðKNRCMEK·¬­_GJ®>WUSCV¿MJP'R>WUO!ÂXOQ]]gKN_GJS>V¸¨8O_³¾GXNªµMLSCPO
NOTYMEK_WbÂXO¶KNG»MÂEMLNWUOKgI»GL³GXK_R>O!©ÒÛKgIo¨>WYPMXTUTbI»ª²GXNOÅ]_¨dOQP(WYMLTU´
WbîO!°dÓK_OQP'R>S>WYëe`>O!]·`C]^WbS>V0MÂEMX_WbO(KgIGL³)P(TYMX]N]_W
O!&TbO!MLNS>O!N]!
FR>WY]P(GXª%®>WbSCMEKNWUGJS0GL³­¨8GJ]_WUK_WbÂXO¶_OQ]^`>TUKN]ÕWY]Õ`CS>ªµMEKNP'RCO!°0®oI
MLSoI©MXT¹KNONSCMEKNWUÂJOÕª²OK_R>G°ê
Z\S0³¾`>K_`>NO·ÑGXN[cdÑO·ÑGX`>TY°TbWUJO&KNG¸ÂEMLTbWY°>MEKNO&K_RCO%ª²O(KNR>G°
GXSª%`>T¹KNWbPTbMJ]_])¨>_GJ®>TbOªµ])MX])GX`KNTUWbS>O!°WbS0]_O!P/KNWUGJSk>
Tb]_GCc
³¾`>_K_R>O!Å]gKN`C°IoWbS>VK_R>O®8ORCMâÂoWbGX²GL³°W¹ù[ONOSeKÅ°WY]_P_OK_Wbî!ML´
K_WbGXSÙ]NP'R>O!ª¶OQ]²³¾GX¸P'R>GoGJ]_WUS>VKNR>O0ÑOWbVXReKN]ÅPGX`>TY°¢TbO!MX°¼KNG
OSCRCMLSCPOª²OSeK']ÅGL³KNR>O¬­_GJ®>WbS>ViO!]^K_WbªµMEK_OQ]µ³¾GJ¸°WUù8O!_O!SeK
¨8O_³¾GXNª²MXSCP(OP_WUK_O!_WYM>

û¢ü

u/<

üHÉ

N#µ%<,&²  =Nµ,   @lN
Nj40)+
pP=
C3$
83>,t$Y
&
@/1".1$!/
i40!C@)1,
 

P=
49' # #".$34<"#µ)
µ,B!0$!
i+

0"#%0$N
6,) #1))¼$
N
lN1&g,"
pP=
A)"#M6)".$3%/4<$!83"*)"#4<$!0 @,4<B!0B!"# #"*)"#
,C3 *)N
0J.-G/&0>J¬J132!G+4
&%
P=
"W1, .0%@N
"#$!%Å)+!
N
$3$!1))
=Ky
A)"#M)
4<A)>,".4,
 21
p

 #8M0$!8
,
1,B@,"./ + #N
N=$31, 0 #"	6)".40$ÇB4<C!$!83:9
40,Å)+!
,
/1C3,5K<N
/ +!$3"#/0 i,140,)

'(
6,)$2) 
=$3".5<1,"*)( 
N@!,$3¿5K>,C!
@40V0
 @3)4)"#/
'I$ GGF¬JÂL!G! "6L$#J3J%&(')*0JG+G>J,>G
@3,"#$3%<1,
@N
;
"#5K
N5/ +!$!"#/ v

g0 #"#B3, )"#40$`409
=Ky

p

;

/

pAu

<y

p

, 8

i ;"

\!/"#$2)

pAu8--
83N
y{z
"W1, .0%@N

Ä,4<N1'I$=ÂN&µ,,Ä$

i4<3C3)1,7/"#$!/1

!,)$2) 
;; 
4,)
=1, u

,=
¿ # #4<$µ$!"#5K1,"*). 2N
g6,$!%0".
$
¿"61". 
) ="#$!"#$3%?"#$
"#/C! #/C
 )VN
VN!g6,C
p
 @"#
409!C!1,57"#8Â #6,$
0$l3"#,"#/ !$
0/1(
 
1),"#/j
'$7 GGF0¬J18ÅL3G92G>J!L
40,M0$3/Å/1,"*)1,".@N
"#$!%_1,9
J3LIG+>J,&0L;0J,&('*)*JG+G>J< G=J8>VJ<?@'.GF2GABC+D0E0G++4&JF
7N
AF&0LG&IHJ¬J¬J
 	
,N

+

,
µN
¿1,/
%WN
µN
 .
$
3N
pAu
'
--
 #,$3"#$!%
M/>+3"#$!
4<"*)4,
409
8!6) 0B!0
K;LNMNM(O*PQ(Q0RNRNR*STNUNV
SGWUNT
SYX(ZWQ[D\,]X1^_(`Q0ab(c1XOdVNTeM1d(_NfNg
!,)$2)E49
g0 #"*9¬4,$!". 
==$3"#5K1,"*)( Ç49
,5@"#$3( 
i4<3C3)1,7/"#$!/0N
'I$39¬4,M)"#4<$E0$
²N
8@/"#"#4<$
03"*,
NIj3,1C!$
80$!8
@/ +
VN
pAu8--
)+340,1)"#/l%<$31, 0 #"	6)".40$`49j40$
 #"#$!l .,$!"#$3%¿$
8¼0$

3 ."#/6)"#4<$:)4?B4240A)".$3%3N!'I$8k1%1 J<&(',F)*0l=H,%7LIG+m&0JFFn40Do
G>J< G+/ 
LIG+lpn<q
;;
,u
u0u8-
)4
1,
N="#$!%
&ÂN'N
A)".M6)
0 #/
/Mp
Ä,4<B
B!"# #"*)".1N'$3 GGF¬J1rL!G
i40$
83"*)"#4<$!0 
i .
%1>H3G&0Jt)*0JG+G>J, Gu0JvH.&ND1¬JG$-G&>J¬J1

 @3,"#$3%<1,N
,u
0y
P=
N!g+!
N
>))"./ +
0$!8
N
---Ky
'
+


Fµ$!"
(,/>+3".5<
N9'
,5@"#$3( 
K;LMNMO*PQNQewZNZxSTNU(V
SGWUNTSYX(Z(Wg
'$@9¬40,M6)"#4<$-0$!8
40,$!".1 
5K>,"#). Y409g ."*9
!,)$2)Â409
i40!C3)>,@/"#$3/<N
%1iC3$ %WN
NÄ9
N¿C! # #1,
4))4<Cy ÂN&µ,, 00$!8
¿C! # #1,
G+%1&('
G>L?|/}0q~I2D;D}0F?L!GVL&KF2G>N@@,".$3%<1,
N&=$V/ .Ä3,4<B!0B3". #"*)( V1A)".M6)
NE,%0"#$!$7)C
=<y
$3"#)"#5Ki5< #C
$
/ .0"
8V/4<A)
)"#40$Â49
\!1,N'I$u8}0>H
0J)*L;oGnG>J/¬LCE0G=-G& J¬J23GnG+E0G>J!LIGG>J3L
J3LIG+>J,&(o
L;J<&('*)*0JG+G>J< Gi0J8H&ND1¬JG-G& J¬J
=<y

,40B
3N
&=C@)!C3)¼9
40,
7C!!4,)
 ;6))
0B3"# ."#A)"#/
---<y
i4<!,"#4<$3)4(µ1%<C! .6,"618
"W/1)4,E0/ +!"#$3$
%c"
¿1)+!478@N1'$
N7/>+
6,) .>)) 
4< 
4<@9Y 
lN
74< . N
 #"#+!42478
N7/>+7C!C@,M0$3
#FE0&0J, G+B¬J!-
&0;2GBH&;¬J)x'	&Do
8@N
/
iG++/ 
'Y
Ä,N
@N
u6,
ÄN
,465K40A)M0$!8
jiN
8@C!/1)"#4<$
4<"#$!%04<
pP=
"#$!%0N'$.H&ND1¬JG-G&>J¬J1 
8¼=$
40,Ä,4<B!0B3". #"*)( 
 
7N
 #C7&i1,N
2u
--1,
@40 ;
lN
@N
N|-G& J¬J.?x¬L
4<@90$!8
7/>+
4< 
pP=
>tG+ JGq'
'
,1N
N
3NgVN=C!"#$! .0$
NI)y,~/&li=q8H.&ND1
JG
pAu8--
F¿4,%K0$
J10N
-G& J
@0$
E6)4
M0$!$cN
C39
$
(Nj3, 0$
'>N
N¯"*))$
NAF&0LG&
pAu
---Ky
H,&N1LD&'
l¬J¬J~
l&(D1¬JG
'.G& J¬J
LG('
Cl=H,'.G+lMG>J!LG&L;0J
k1&0E0&
?x¬L
G+
LIGD7Jq%
&0J
¿40,%K$
K;LNMNM(O*PQ(Q0RNRNR*SUNV
SGR^NTw^M1d
S^U
SG`NQ\,]NQ0RXew^NQ(g
C39¬M$!$cN
µN
&=B3) "#$!"#$!%¯/ #"
N=<87,4($! 
$
p
=7u6y
8@/"#"#4<$¯),D0$!8
,4<
B!"# #"*)( ¶1A)".M6)M9
B@, )8¶@,4<B
 2".$Y/ .0"
6eo
1,N'I$3 GGF0¬J1r:L!G
$!0"#5K
J!LIG+ J<&L;0J<&')*0JG+G>J, G!0JH&ND1¬JG=-G/&0>J¬J1
LIGG>J!L
 
¿4,%K$
0C39
M0$3$N
@N
,=@uy

=-
Ni4<A)
Nc08@,4$!  @N%0$3%09¬4, 8y g0$
µB
pP=
,4040,)"#4<$!)
7$!"*)"#5K
%6,$!"#$!%
B! 
i4<A)
J3LIG+>J,&(o
`"#%<+2)"#$!%3N9'$3 GGF¬J8YML!GN
L;J<&('I)*0JG+G>J, Gu0JvA=&0LG&uH$
J¬J
 ;


 _303 #

N|,

'I$

N'

,1N

$

<y

:s|s*s:

,=

205º
º


ü
¥
§
ü
£
:
*
*
,


=

y


,

,
=

,



,
:

<

8
=

y
p
,
=

y
 

,
,
:

<

=
=
N
[


7

=
=
,

,


:

<
[
,
=
=

y
N


,
:
p

=
=

y
-
,

:
;
<

/

8

y
N
 
N
'



8
:


y
N

,
,
,
u
 

-
N
:

<
*
=
=
*
\
s
p

%
,
=
 
u



:

<
*


N


 
,


:
N

+

y
,

/
8
+
N
p
z
,
:
u


=
=
,
:
p
'
%
,

=
=
N
:

N

8
/

,


/


p
y


:
u

<



=

y
9
,
B
/
;


u
+
:
u

<

N
/
=

:
u

<

y

+
:
u
;
<
*
8
/

F
N
+
:
u

<

8

 
/
=
N
,


\
s
:
p
'
%
,

u
+
:
u

<

8
[
N
=

y
,

p
'





y
,





Loss Functions for Discriminative Training of Energy-Based Models.

Yann LeCun and Fu Jie Huang

The Courant Institute, New York University

fyann,jhuangfug@cs.nyu.edu

http://yann.lecun.com

Abstract

Probabilistic graphical models associate a prob-
ability to each conﬁguration of the relevant vari-
ables. Energy-based models (EBM) associate an
energy to those conﬁgurations, eliminating the
need for proper normalization of probability dis-
tributions. Making a decision (an inference) with
an EBM consists in comparing the energies asso-
ciated with various conﬁgurations of the variable
to be predicted, and choosing the one with the
smallest energy. Such systems must be trained
discriminatively to associate low energies to the
desired conﬁgurations and higher energies to un-
desired conﬁgurations. A wide variety of loss
function can be used for this purpose. We give
sufﬁcient conditions that a loss function should
satisfy so that its minimization will cause the sys-
tem to approach to desired behavior. We give
many speciﬁc examples of suitable loss func-
tions, and show an application to object recog-
nition in images.

1 Introduction

Graphical Models are overwhelmingly treated as proba-
bilistic generative models in which inference and learning
are viewed as probabilistic estimation problems. One ad-
vantage of the probabilistic approach is compositionality:
one can build and train component models separately be-
fore assembling them into a complete system. For example,
a Bayesian classiﬁer can be built by assembling separately-
trained generative models for each class. But if a model
is trained discriminatively from end to end to make deci-
sions, mapping raw input to ultimate outputs, there is no
need for compositionality. Some applications require hard
decisions rather than estimates of conditional output dis-
tributions. One example is mobile robot navigation: once
trained, the robot must turn left or right when facing an ob-
stacle. Computing a distribution over steering angles would
be of little use in that context. The machine should be
trained from end-to-end to approach the best possible de-
cision in the largest range of situations.

Another implicit advantage of the probabilistic approach
is that it provides well-justiﬁed loss functions for learn-
ing, e.g. maximum likelihood for generative models, and
max conditional likelihood for discriminative models. Be-
cause of the normalization, maximizing the likelihood of
the training samples will automatically decrease the likeli-
hood of other points, thereby driving machine to approach
the desired behavior. The downside is that the negative log-
likelihood is the only well-justiﬁed loss functions. Yet, ap-
proximating a distribution over the entire space by max-
imizing likelihood may be an overkill when the ultimate
goal is merely to produce the right decision.

We will argue that using proper probabilistic models, be-
cause they must be normalized, considerably restricts our
choice of model architecture. Some desirable architectures
may be difﬁcult to normalize (the normalization may in-
volve the computation of intractable partition functions),
or may even be non-normalizable (their partition function
may be an integral that does not converge).

This paper concerns a more general class of models called
Energy-Based Models (EBM). EBMs associate an (un-
normalized) energy to each conﬁguration of the variables
to be modeled. Making an inference with an EBM con-
sists in searching for a conﬁguration of the variables to be
predicted that minimizes the energy, or comparing the ener-
gies of a small number of conﬁgurations of those variables.
EBMs have considerable advantages over traditional prob-
abilistic models: (1) There is no need to compute partition
functions that may be intractable; (2) because there is no
requirement for normalizability, the repertoire of possible
model architectures that can be used is considerably richer.

Training an EBM consists in ﬁnding values of the trainable
parameter that associate low energies to “desired” conﬁg-
urations of variables (e.g. observed on a training set), and
high energies to “undesired” conﬁgurations. With prop-
erly normalized probabilistic models, increasing the like-
lihood of a “desired” conﬁguration of variables will auto-
matically decrease the likelihoods of other conﬁgurations.
With EBMs, this is not the case: making the energy of de-
sired conﬁgurations low may not necessarily make the en-
ergies of other conﬁgurations high. Therefore, one must
be very careful when designing loss functions for EBMs 1.

1it is important to note that the energy is quantity minimized

206We must make sure that the loss function we pick will ef-
fectively drive our machine to approach the desired behav-
ior. In particular, we must ensure that the loss function has
no trivial solution (e.g. where the best way to minimize
the loss is to make the energy constant for all input/output
pair). A particular manifestation of this is the so-called col-
lapse problem that was pointed out in some early works that
attempted to combined neural nets and HMMs [7, 2, 8].

This energy-based, end-to-end approach to learning has
been applied with great success to sentence-level handwrit-
ing recognition in the past [10]. But there has not been
a general characterization of “good” energy functions and
loss functions. The main point of this paper is to give suf-
ﬁcient conditions that a discriminative loss function must
satisfy, so that its minimization will carve out the energy
landscape in input/output space in the right way, and cause
the machine to approach the desired behavior. We then pro-
pose a wide family of loss functions that satisfy these con-
ditions, independently of the architecture of the machine
being trained.

2 Energy-Based Models

Let us deﬁne our task as one of predicting the best conﬁgu-
ration of a set of variables denoted collectively by Y , given
a set of observed (input) variables collectively denoted by
X. Given an observed conﬁguration for X, a probabilistic
model (e.g. a graphical model) will associate a (normal-
ized) probability P (Y jX) to each possible conﬁguration
of Y . When a decision must be made, the conﬁguration of
Y that maximizes P (Y jX) will be picked.
An Energy-Based Model (EBM) associates a scalar energy
E(W; Y; X) to each conﬁguration of X; Y . The family of
possible energy functions is parameterized by a parameter
vector W , which is to be learned. One can view this en-
ergy function as a measure of “compatibility” between the
values of Y and X. Note that there is no requirement for
normalization.

The inference process consists in clamping X to the ob-
served conﬁguration (e.g. an input image for image clas-
siﬁcation), and searching for the conﬁguration of Y in a
set fY g that minimizes the energy. This optimal conﬁgu-
ration is denoted (cid:20)Y : (cid:20)Y = argminY 2fY gE(W; Y; X). In
many situations, such as classiﬁcation, fY g will be a dis-
crete set, but in other situations fY g may be a continu-
ous set (e.g. a compact set in a vector space). This paper
will not discuss how to perform this inference efﬁciently:
the reader may use her favorite and most appropriate opti-
mization method depending upon the form of E(W; Y; X),
including exhaustive search, gradient-based methods, vari-
ational methods, (loopy) belief propagation, dynamic pro-
gramming, etc.

Because of the absence of normalization, EBMs should
only be used for discrimination or decision tasks where
only the relative energies of the various conﬁgurations of

during inference, while the loss is the quantity minimized during
learning

Figure 1: Two energy surfaces in X; Y space obtained
by training two neural nets to compute the function Y =
X 2 (cid:0) 1=2. The blue dots represent a subset of the train-
ing samples. In the left diagram, the energy is quadratic
in Y , therefore its exponential is integrable over Y . This
model is equivalent to a probabilistic Gaussian model of
P (Y jX). The right diagram uses a non-quadratic saturated
energy whose exponential is not integrable over Y . This
model is not normalizable, and therefore has no probabilis-
tic counterpart.

Y for a given X matter. However, if exp((cid:0)E(W; Y; X)) is
integrable over Y , for all X and W , we can turn an EBM
into an equivalent probabilistic model by posing:

P (Y jX; W ) =

exp((cid:0)(cid:12)E(W; Y; X)
Ry exp((cid:0)(cid:12)E(W; y; X))

where (cid:12) is an arbitrary positive constant. The normaliz-
ing term (the denominator) is called the partition function.
However, the EBM framework gives us more ﬂexibility be-
cause it allows us to use energy functions whose exponen-
tial is not integrable over the domain of Y . Those models
have no probabilistic equivalents.

Furthermore, we will see that training EBMs with certain
loss functions circumvents the requirement for evaluating
the partition function and its derivatives, which may be in-
tractable. Solving this problem is a major issue with prob-
abilistic models, if one judges by the considerable amount
of recent publications on the subject.

Probabilistic models are generally trained with the maxi-
mum likelihood criterion (or equivalently, the negative log-
likelihood loss). This criterion causes the model to ap-
proach the conditional density P (Y jX) over the entire do-
main of Y for each X. With the EBM framework, we al-
low ourselves to devise loss functions that merely cause
the system to make the best decisions. These loss functions
are designed to place minY 2fY g E(W; Y; X) near the de-
sired Y for each X. This is a considerably less complex
and less constrained problem than that of estimating the
“correct” conditional density over Y for each X. To con-
vince ourselves of this, we can note that many different
energy functions may have minima at the same Y for a
given X, but only one of those (or a few) maximizes the
likelihood. For example, ﬁgure 1 shows two energy sur-
faces in X; Y space. They were obtained by training two
neural nets (denoted G(W; X)) to approximate the func-
tion Y = X 2 (cid:0) 1=2.
In the left diagram, the energy
E(W; Y; X) = (Y (cid:0) G(W; X))2 is quadratic in Y , there-

207Figure 2: Examples of EBMs. (a) switch-based classiﬁer; (b) a regressor; (c) constraint satisfaction architecture. Multidi-
mensional variables are in red, scalars in green, and discrete variables in green dotted lines.

fore its exponential is integrable over Y . This model is
equivalent to a probabilistic Gaussian model for P (Y jX).
The right diagram uses a non-quadratic saturated energy
E(W; Y; X) = tanh(cid:0)(Y (cid:0) G(W; X))2(cid:1) whose exponen-
tial is not integrable over Y . This model is not normaliz-
able, and therefore has no probabilistic counterpart, yet it
fulﬁlls our desire to produce the best Y for any given X.

2.1 Previous work

Several authors have previously pointed out the shortcom-
ings of normalized models for discriminative tasks. Bot-
tou [4] ﬁrst noted that discriminatively trained HMMs are
unduly restricted in their expressive power because of the
normalization requirements, a problem recently named “la-
bel bias” in [9]. To alleviate this problem, late normal-
ization schemes for un-normalized discriminative HMMs
were proposed in [6] and [10]. Recent works have revived
the issue in the context of sequence labelling [5, 1, 14].

Some authors have touted the use of various non-
probabilistic loss functions, such as the Perceptron loss or
the maximum margin loss, for training decision-making
systems [7, 10, 5, 1, 14]. However, the loss functions in
these systems are intimately linked to the underlying archi-
tecture of the machine being trained. Some loss functions
are incompatible with some architectures and may possess
undesirable minima. The present paper gives conditions
that “well-behaved” loss functions should satisfy.

Teh et al. [15] have introduced the term “Energy-Based
Model” in a context similar to ours, but they only consid-
ered the log-likelihood loss function. We use the term EBM
in a slightly more general sense, which include the possibil-
ity of using other loss functions. Bengio et al. [3] describe
an energy-based language model, but they do not discuss
the issue of loss functions.

2.2 Examples of EBMs

EBM for Classiﬁcation: Traditional multi-class classiﬁers
can be viewed as particular types of EBMs whose archi-
tecture is shown in ﬁgure 2(a). A parameterized discrimi-
nant function G(W; X) produces an output vector with one
component for each of the k categories (G0; G1:::; Gk(cid:0)1).
Component Gi is interpreted as the energy (or “penalty”)
for assigning X to the i-th category. A discrete switch
module selects which of the components is connected to the
output energy. The position of the switch is controlled by
the discrete variable Y , which is interpreted as the category.
The output energy is equal to E(W; Y; X) = Pk(cid:0)1
i=0 (cid:14)(Y (cid:0)
i)G(W; X)i, where (cid:14)(Y (cid:0) i) is equal to 1 for Y = i and 0
otherwise (Kronecker function), and G(W; X)i is the i-th
component of G(W; X). Running the machine consists in
ﬁnding the position of the switch (the value of Y ) that min-
imizes the energy, i.e. the position of the switch that selects
the smallest component of G(W; X).
EBM for Regression: A regression function G(W; X)
with the squared error loss (e.g. a traditional neural net-
work) is a trivial form of minimum energy machine (see
ﬁgure 2(b)). The energy function of this machine is de-
ﬁned as E(W; Y; X) = 1
2 jjG(W; X) (cid:0) Y jj2. The value of
Y that minimizes E is simply equal to G(W; X). There-
fore, running such a machine consists simply in computing
G(W; X) and copying the value into Y . The energy is then
zero. This architecture can be used for classiﬁcation by
simply making fY g a discrete set (with one element for
each category).
EBM for Constraint Satisfaction: sometimes, the depen-
dency between X and Y cannot be expressed as a function
that maps X’s to Y ’s (consider for example the constraint
X 2 + Y 2 = 1). In this case, one can resort to modeling
“constraints” that X and Y must satisfy. The energy func-
tion measures the price for violating the constraints. An
example architecture is shown in ﬁgure 2(c). The energy
is E(W; Y; X) = C(Gx(Wx; X); Gy(Wy; Y )), where GX

208and Gy are functions to be learned, and C(a; b) is a dissim-
ilarity measure (e.g. a distance).

computed as part of the energy-minimizing inference pro-
cess. Section 4 reports experimental results obtained with
such a system.

2.3 Deterministic Latent Variables

Many tasks are more conveniently modeled by architec-
tures that use latent variables. Deterministic latent vari-
ables are extra variables (denoted by Z) that inﬂuence the
energy, and that are not observed. During an inference, the
energy is minimized over Y and Z:

( (cid:20)Y ; (cid:20)Z) = argminY 2fY g; Z2fZgE(W; Y; Z; X)

By simply redeﬁning our energy function as:

(cid:20)E(W; Y; X) = min
Z2fZg

E(W; Y; Z; X)

We can essentially ignore the issue of latent variables.

Latent variables are very useful in situations where a hid-
den characteristic of the process being modeled can be in-
ferred from observations, but cannot be predicted directly.
This occurs for example in speech recognition, handwrit-
ing recognition, natural language processing, and biolog-
ical sequence analysis, and other sequence labeling tasks
where a segmentation must be performed simultaneously
with the recognition. Alternative segmentations are of-
ten represented as paths in a weighted lattice. Each path
may be associated with a category [10, 5, 1, 14]. The
path being followed in the lattice can be viewed as a dis-
crete latent variable. Searching for the best path using
dynamic programming (Viterbi) or approximate methods
(e.g.
beam search) can be seen as a minimization of
the energy function with respect to this discrete variable.
For example, in a speech recognition context, evaluating
minZ2fZg E(W; Y i; Z; X i) is akin to “constrained seg-
mentation”: ﬁnding the best path in the lattice that produces
a particular output label Y i.

An EBM framework with which to perform graph manipu-
lations and search, while preserving the ability to compute
partial derivatives for learning is the Graph Transformer
Network model described in [10]. However, that paper
only mentions two loss functions (generalized perceptron
and log-likelihood), without a general discussion of how to
construct appropriate loss functions.

Rather than give a detailed description of latent-variable
EBM for sequence processing, we will describe an applica-
tion to visual object detection and recognition. The archi-
tecture is shown in ﬁgure 3. The input image is ﬁrst turned
into an appropriate representation (e.g. a feature vector)
by a trainable front-end module (e.g. a convolutional net-
work, as in [11]). This representation is then matched to
models of each category. Each model outputs an energy
that measures how well the representation matched the cat-
egory (a low energy indicates a good match, a high energy
a bad match). The switch selects the best-matching cate-
gory. The object models take in latent variables that may be
used to represent some instantiation parameters of the ob-
jects, such as the pose, illumination, or conformation. The
optimal value of those parameters for a particular input is

3 Loss Functions for EBM Training.

In supervised learning, the training set S is a set of pairs
S = f(X i; Y i) ; i = 1::P g where X i is an input, and Y i
is a desired output to be predicted. Practically every learn-
ing methods can be described as the process of ﬁnding the
parameter W 2 fW g that minimizes a judiciously chosen
loss function L(W; S). The loss function should be a mea-
sure of the discrepancy between the machine’s behavior
and the desired behavior on the training set. Well-behaved
loss functions for EBMs should shape the energy landscape
so as to “dig holes” at (X; Y ) locations near training sam-
ples, while “building hills” at un-desired locations, partic-
ularly the ones that are erroneously picked by the inference
algorithm. For example, a good loss function for the regres-
sion problem depicted in ﬁgure 1 should dig holes around
the blue dots (which represent a subset of the training set,
while ensuring that the surrounding areas have higher en-
ergy.

In the following, we characterize the general form of loss
functions whose minimization will make the machine carve
out the energy landscape in the right way so as to approach
the desired behavior. We deﬁne the loss on the full training
set as:

L(W; S) = R   1

P

P

X

i=1

L(W; Y i; X i)!

(1)

where L(W; Y i; X i) is the per-sample loss function for
sample (X i; Y i), and R is a monotonically increasing
function. Loss functions that combine per-sample losses
through other symmetric n-ary operations than addition
(e.g. multiplication, as in the case of likelihood-like loss
functions) can be trivially obtained from the above through
judicious choices of R and L. With this deﬁnition, the loss
is invariant under permutations of the samples, and under
multiple repetitions of the same training set. In the follow-
ing we will set R to the identity function. We assume that
L(W; Y i; X i) has a lower bound over W for all Y i; X i.
At this point, we can note that if we minimize any such
loss on a training set over a set of functions with ﬁnite VC-
dimension, appropriate VC-type upper bounds for the ex-
pected loss will apply, ensuring the convergence of the em-
pirical loss to the expected loss as the training set size in-
creases. Therefore, we will only discuss the conditions un-
der which a loss function will make the machine approach
the desired behavior on the training set.

Sometimes, the task uniquely deﬁnes a “natural” loss func-
tion (e.g. the number of mis-classiﬁed examples), but more
often than not, minimizing that function is impractical.
Therefore one must resort to surrogate loss functions whose
choice is up to the designer of the system. One crucial, but
often neglected, question must be answered before choos-
ing a loss function: “will minimizing the loss cause the

209Figure 3: Example of a switch-based Energy-Based Model architecture for object recognition in images, where the pose of
the object is treated as a latent variable.

learning machine to approach the desired behavior?” We
will give general conditions for that.

The inference process produces the Y that minimizes
(cid:20)E(W; Y; X i). Therefore, a well-designed loss function
must drive the energy of the desired output (cid:20)E(W; Y i; X i)
to be lower than the energies of all the other possible out-
puts. Minimizing the loss function should result in “holes”
at X; Y locations near the training samples, and “hills” at
un-desired locations.

3.1 Conditions on the Energy

The condition for the correct classiﬁcation of sample X i is:

Condition 1 (cid:20)E(W; Y i; X i) < (cid:20)E(W; Y; X i) ;
fY g; Y 6= Y i

8Y 2

To ensure that the correct answer is robustly stable, we may
choose to impose that the energy of the desired output be
lower than the energies of the undesired outputs by a mar-
gin m:

Condition 2 (cid:20)E(W; Y i; X i) < (cid:20)E(W; Y; X i) (cid:0) m ; 8Y 2
fY g; Y 6= Y i

We will now consider the case where Y is a discrete vari-
able. Let us denote by (cid:22)Y the output that produces the small-
est energy while being different from the desired output Y i:
(cid:22)Y = argminY 2fY g;Y 6=Y i (cid:20)E(W; Y; X i). Condition 2 can
be rewritten as:

Condition 3 (cid:20)E(W; Y i; X i) < (cid:20)E(W; (cid:22)Y ; X i) (cid:0) m ; (cid:22)Y =
argminY 2fY g;Y 6=Y i (cid:20)E(W; Y; X i)

the continuous Y case, we can simply de-
For
ﬁne (cid:22)Y as
the lowest-energy output outside of a
ball of a given radius around the desired output:
argminY 2fY g;jjY (cid:0)Y ijj>(cid:15)

(cid:20)E(W; Y; X i)

3.2 Sufﬁcient conditions on the loss function

We will now make the key assumption that L de-
pends on X i only indirectly through the set of energies

f (cid:20)E(W; Y; X i) ; Y 2 fY gg . For example, if fY gis the
set of integers between 0 and k (cid:0) 1, as would be the case
for the switch-based classiﬁer with k categories shown in
ﬁgure 2(a), the per-sample loss for sample (X i; Y i) should
be of the form:

L(W; Y i; X i) = L(Y i; (cid:20)E(W; 0; X i); : : : ; (cid:20)E(W; k(cid:0)1; X i))
(2)
With this assumption, we separate the choice of the loss
function from the details of the internal structure of the ma-
chine, and limit the discussion to how minimizing the loss
function affects the energies.

We must now characterize the form that L can take such
that its minimization will eventually drive the machine to
satisfy condition 3.

We must design L in such a way that minimizing it will de-
crease the difference (cid:20)E(W; Y i; X i)(cid:0) (cid:20)E(W; (cid:22)Y ; X i), when-
ever (cid:20)E(W; (cid:22)Y ; X i) < (cid:20)E(W; Y i; X i) + m. In other words,
whenever the difference between the energy of the incor-
rect answer with the lowest energy and the energy of the
desired answer is less than the margin, our learning proce-
dure should make that difference larger. We will now pro-
pose a set of sufﬁcient conditions on the loss that guarantee
this.

Since we are only concerned with how the loss inﬂuences
the relative values of (cid:20)E(W; Y i; X i), and (cid:20)E(W; (cid:22)Y ; X i),
we will consider the shape of loss surface in the space of
(cid:20)E(W; Y i; X i) and (cid:20)E(W; (cid:22)Y ; X i), and view the other argu-
ments of the loss (the energies for all the other values of Y )
as parameters of that surface:

L(W; Y i; X i) = Q[Ey]( (cid:20)E(W; Y i; X i); (cid:20)E(W; (cid:22)Y ; X i))

where the parameter [Ey] contains the vector of energies
for all values of Y except Y i and (cid:22)Y .
We can now state sufﬁcient conditions that guarantee
that minimizing L will eventually satisfy condition 3.
In all the sufﬁcient conditions stated below, we assume
that
there exist a W such that condition 3 is satis-
ﬁed for a single training example (X i; Y i), and that
Q[Ey]( (cid:20)E(W; Y i; X i); (cid:20)E(W; (cid:22)Y ; X i)) is convex (convex in

210its 2 arguments, but not necessarily convex in W ). The
conditions must old for all values of [Ey].

Condition 4 The
minima
Q[Ey]( (cid:20)E(W; Y i; X i); (cid:20)E(W; (cid:22)Y ; X i)) are
plane (cid:20)E(W; (cid:22)Y ; X i) < (cid:20)E(W; Y i; X i) + m.

of
in the half-

This condition on the loss function clearly ensures that min-
imizing it will drive the machine to ﬁnd a solution that sat-
isﬁes condition 3, if such a solution exists.

Another sufﬁcient condition can be stated to characterize
loss functions that do not have minima, or whose minimum
is at inﬁnity:

Condition 5 the
of
Q[Ey]( (cid:20)E(W; Y i; X i); (cid:20)E(W; (cid:22)Y ; X i))
the margin
line (cid:20)E(W; (cid:22)Y ; X i) = (cid:20)E(W; Y i; X i) + m, has a positive
dot product with the direction [-1,1].

gradient
on

This condition guarantees that minimizing L will drive the
energies (cid:20)E(W; (cid:22)Y ; X i) and (cid:20)E(W; Y i; X i) toward the half-
plane (cid:20)E(W; (cid:22)Y ; X i) < (cid:20)E(W; Y i; X i) + m.
Yer another sufﬁcient condition can be stated to character-
ize loss functions whose minima are not in the desired half-
plane, but where the possible values of (cid:20)E(W; (cid:22)Y ; X i) and
(cid:20)E(W; Y i; X i) are constrained by their dependency on W
in such a way that the minimum of the loss while satisfying
the constraint is in the desired half-plane:

@W

@W

@W

> 0

following must

(cid:20)E(W; (cid:22)Y ; X i) =
hold:

the
(cid:0) @ (cid:20)E(W; (cid:22)Y ;X i)
i : @L(W;Y i;X i)

Condition 6 On the margin line
(cid:20)E(W; Y i; X i) + m,
h @ (cid:20)E(W;Y i;X i)
This condition ensures that an update of the parame-
ters W to minimize the loss will drive the energies
(cid:20)E(W; (cid:22)Y ; X i) and (cid:20)E(W; Y i; X i) toward the desired half-
plane (cid:20)E(W; (cid:22)Y ; X i) < (cid:20)E(W; Y i; X i) + m.
We must emphasize that these are only sufﬁcient condi-
tions. There may be legitimate loss functions (e.g. non-
convex functions) that do not satisfy them, yet have the
proper behavior.

3.3 Examples of Loss Functions

We can now give examples of loss functions that satisfy the
above criteria, and examine whether some of the popular
loss functions proposed in the literature satisfy it.
Energy Loss: The simplest and most widely used
loss is the energy loss, which is simply of the form
Lenergy(W; Y i; X i) = (cid:20)E(W; Y i; X i). This loss does not
satisfy condition 4 or 5 in general, but there are cer-
tain forms of (cid:20)E(W; Y i; X i) for which condition 6 is sat-
isﬁed. For example, let us consider an energy of the form
E(W; Y; X) = PK
k=1 (cid:14)(Y (cid:0) k):jjU k (cid:0) G(W; X)jj2. Func-
tion G(W; X) could be a neural net, on top of which are
placed K radial basis functions whose centers are the vec-
tors U k. If the U k are ﬁxed and all different, then the en-

ergy loss applied to this machine fulﬁlls condition 6. Intu-
itively, that is because by pulling G(W; X) towards one of
the RBF centers, we push it away from the others. There-
fore when the energy of the desired output decreases, the
other ones increase. However, if we allow the RBF centers
to be learned, condition 6 is no longer fulﬁlled. In that case,
the loss has spurious minima where all the RBF centers are
equal, and the function G(W; X) is constant and equal to
that RBF center. The loss is zero, but the machine does
not produce the desired result. Picking any combination of
loss and energy that satisfy any of the conditions 4, 5, or 6
solves this collapse problem.
Generalized Perceptron Loss: We deﬁne the generalized
Perceptron loss for training sample (X i; Y i) as:

Lptron(W; Y i; X i) = (cid:20)E(W; Y i; X i)(cid:0) min
Y 2fY g

(cid:20)E(W; Y; X i)
(3)
It is easy to see that with E(W; Y i; X i) = (cid:0)Y i:W T X i,
and fY g = f(cid:0)1; 1g, the above loss reduces to the tradi-
tional linear Perceptron loss. The generalized perceptron
loss satisﬁes condition 4 with m = 0. This loss was used
by [10] for training a commercially deployed handwriting
recognizer that combined a heuristic segmenter, a convolu-
tional net, and a language model (where the latent variables
represented paths in an interpretation lattice). A similar
loss was studied by [5] for training a text parser. Because
the margin is zero, this loss may not prevent collapses for
certain architecture.
Generalized Margin Loss: A more robust version of the
Perceptron loss is the Margin Loss, which directly uses the
energy of most offending non-desired output (cid:22)Y in the con-
trastive term:

Lmargin(W; Y i; X i) = Qm[ (cid:20)E(W; Y i; X i)(cid:0) (cid:20)E(W; (cid:22)Y ; X i)]
(4)
where Qm(e) is any function that is monotonically increas-
ing for e > (cid:0)m. The traditional “hinge loss” used with
kernel-based methods, and the loss used by the LVQ2 algo-
rithm are special cases with Qm(e) = e + m for e > (cid:0)m,
and 0 otherwise. Special forms of that loss were used in [7]
for discriminative speech recognition, and in [1] and [14]
for text labeling. The exponential loss used in AdaBoost is
a special form of equation (4) with Qm(e) = exp(e). A
slightly more general form of the margin loss that satisﬁes
conditions 4 or 5 is given by:

Lgmargin(W; Y i; X i) = Qgm[ (cid:20)E(W; Y i; X i); (cid:20)E(W; (cid:22)Y ; X i)]
(5)
when

with the condition that @Qgm(e1;e2)
e1 + m > e2. An example of such loss is:

> @Qgm(e1;e2)

@e1

@e2

L(W; Y i; X i) = Q+( (cid:20)E(W; Y i; X i))+Q(cid:0)( (cid:20)E(W; (cid:22)Y ; X i))
(6)
where Q+(e) is a convex monotonically increasing func-
tion, and Q(cid:0)(e) a convex monotonically decreasing func-
tion such that if dQ+
de je2 = 0 then
e1 + m < e2. When (cid:20)E(W; Y i; X i) is akin to a distance
(bounded below by 0), a judicious choice for Q+ and Q(cid:0)

de je1 = 0 and dQ(cid:0)

211is:

L(W; Y i; X i) = (cid:20)E(W; Y i; X i)2+(cid:20) exp((cid:0)(cid:12) (cid:20)E(W; (cid:22)Y ; X i))
(7)
where (cid:20) and (cid:12) are positive constants. A similar loss func-
tion was recently used by our group to train a pose-invariant
face detection [12]. This system can simultaneously detect
faces and estimate their pose using latent variables to rep-
resent the head pose.
Contrastive Free Energy Loss: While the loss functions
proposed thus far involve only (cid:20)E(W; (cid:22)Y ; X i) in their con-
trastive part, loss functions can be devised to combine all
the energies for all values of Y in their contrastive term:

L(W; Y i; X i) = (cid:20)E(W; Y i; X i)(cid:0)

(8)

F ( (cid:20)E(W; 0; X i); : : : ; (cid:20)E(W; k (cid:0) 1; X i))

F can be interpreted as a generalized free energy of the en-
semble of systems with energies (cid:20)E(W; Y; X i) 8Y 2 fY g.
It appears difﬁcult to characterize the general form of F
that ensures that L satisﬁes condition 5. An interesting spe-
cial case of this loss is the familiar negative log-likelihood
loss:

Lnll(W; Y i; X i) = (cid:20)E(W; Y i; X i) (cid:0) F(cid:12)(W; X i)

(9)

with

log Z

1
(cid:12)

Y 2fY g

F(cid:12)(W; X i) = (cid:0)

exp[(cid:0)(cid:12) (cid:20)E(W; Y; X i)]!
(10)
where (cid:12) is a positive constant. The second term can
be interpreted as the Helmholtz free energy (log parti-
tion function) of the ensemble of systems with energies
(cid:20)E(W; Y; X i) 8Y 2 fY g. This type of discriminative loss
with (cid:12) = 1 is widely used for discriminative probabilis-
tic models in the speech, handwriting, and NLP commu-
nities [10, 2, 8]. This is also the loss function used in the
conditional random ﬁeld model of Lafferty et al [9].

We can see that loss (9) reduces to the generalized Percep-
tron loss when (cid:12) ! 1. Computing this loss and its deriva-
tive requires computing integrals (or sums) over fY g that
may be intractable. It also assumes that the exponential of
the energy be integrable over fY g, which puts restrictions
on the choice of E(W; Y; X) and/or fY g.

4 Illustrative Experiments

To illustrate the use of contrastive loss functions with non-
probabilistic latent variables, we trained a system to recog-
nize generic objects in images independently of the pose
and the illumination. We used the NORB dataset [11]
which contains 50 different uniform-colored toy objects
under 18 azimuths, 9 elevations, and 6 lighting conditions.
The objects are 10 instance from 5 generic categories: four-
legged animals, human ﬁgures, airplanes, trucks, and cars.
Five instances of each category were used for training, and
the other ﬁve for testing (see ﬁgure 4). A 6-layer convolu-
tional network trained with the mean-square loss achieves

Figure 4: Invariant object recognition with NORB dataset.
The left portion shows sample views of the training in-
stances, and the right portion testing instances for the 5
categories.

6.8% test error on this set when fed with binocular 96 (cid:2) 96-
pixel gray-scale images [11].

We used an architecture very much like the one in ﬁgure 3,
where the feature extraction module is identical to the ﬁrst
5 layers of the 6-layer convolutional net used in the refer-
ence experiment. The object model functions were of the
form: Ei = jjWi:V (cid:0) F (Z)jj, i = 1::5, where V is the
output of the 5-layer net (100 dimensions), Wi is a 9 (cid:2) 100
(trainable) weight matrix. The latent variable Z has two
dimensions that are meant to represent the azimuth and el-
evation of the object viewpoint. The set of possible values
fZg contained 162 values (azimuths: 0-360 degrees every
20, elevations: 30-70 degrees every 5). The output of F (Z)
is a point on an azimuth/elevation half-sphere (2D surface)
embedded in the 9D hypercube [(cid:0)1; +1]9. The minimiza-
tion of the energy over Z is performed through exhaustive
search (which is relatively cheap).

We used the loss function (7). This loss causes the con-
volutional net to produce a point as close as possible to
any point on the half-sphere of the desired class, and as far
as possible from the half-sphere of the best-scoring non-
desired class. The system is trained “from scratch” includ-
ing the convolutional net. We obtained 6.3% error on the
test set, which is a moderate, but signiﬁcant improvement
over the 6.8% of the control experiment.

5 Discussion

Efﬁcient End-to-End Gradient-Based Learning To per-
form gradient-based training of all the modules in the ar-
chitecture, we must compute the gradient of the loss with
respect to all the parameters. This is easily achieved with
the module-based generalization of back-propagation de-
scribed in [10]. A typical learning iteration would involve
the following steps: (1) one forward propagation through
the modules that only depend on X; (2) a run of the energy-
minimizing inference algorithm on the modules that de-
pend on Z and Y ; (3) as many back-propagations through
the modules that depend on Y as there are energy terms
in the loss function; (4) one back-propagation through the
module that depends only on X; (5) one update of the pa-
rameters.

212Efﬁcient Inference: Most loss functions described in this
paper involve multiple runs of the machine (in the worst
case, one run for each energy term that enters in the loss).
However, the parts of the machine that solely depend on
X, and not on Y or Z need not be recomputed for each run
(e.g. the feature extractor in ﬁgure 3), because X does not
change between runs.

If the energy function can be decomposed as a sum of func-
tions (called factors) E(W; Y; X) = Pj Ej(Wj ; Y; Z; X),
each of which takes subsets of the variables in Z and Y as
input, we can use a form of belief propagation algorithm
for factor graphs to compute the lowest energy conﬁgura-
tion [13]. These algorithms are exact and tractable if Z
and Y are discrete and the factor graph has no loop. They
reduce to Viterbi-type algorithms when members of fZg
can be represented by paths in a lattice (as is the case for
sequence segmentation/labeling tasks).
Approximate Inference: We do not really need to assume
that the energy-minimizing inference process always ﬁnds
the global minimum of E(W; Y; X i) with respect to Y .
We merely need to assume that this process ﬁnds approxi-
mate solutions (e.g. local minima) in a consistent, repeat-
able manner. Indeed, if there are minima of E(W; Y; X i)
with respect to Y that our minimization/inference algo-
rithm never ﬁnds, we do not need to ﬁnd them and increase
their energy. Their existence is irrelevant to our problem.
However, it is important to note that those unreachable re-
gions of low energy will affect the loss function of proba-
bilistic models as well as that of EBMs if the negative log-
likelihood loss is used. This is a distinct advantage of the
un-normalized EBM approach: low-energy areas that are
never reached by the inference algorithm are not a concern.

6 Conclusion and Outlook

Most approaches to discriminative training of graphical
models in the literature use loss functions from a very small
set. We show that energy-based (un-normalized) graphical
models can be trained discriminatively using a very wide
family of loss functions. We give a sufﬁcient condition that
the loss function must satisfy so that its minimization will
make the system approach the desired behavior. We give a
number of loss functions that satisfy this criterion and de-
scribe experiments in image recognition that illustrate the
use of such discriminative loss functions in the presence of
non-probabilistic latent variables.

Acknowledgments

The authors wish to thank Leon Bottou, Yoshua Bengio,
Margarita Osadchy, and Matt Miller for useful discussions.

References

[1] Yasemin Altun, Mark Johnson, and Thomas Hof-
mann. Loss functions and optimization methods for
discriminative learning of label sequences. In Proc.
EMNLP, 2003.

[2] Y. Bengio, R. De Mori, G. Flammia, and R. Kompe.
Global optimization of a neural network-hidden
Markov model hybrid. IEEE Transaction on Neural
Networks, 3(2):252–259, 1992.

[3] Y. Bengio, R. Ducharme, P. Vincent, and C. Jauvin.
A neural probabilistic language model. Journal of
Machine Learning Research, 3:1137–1155, February
2003.

[4] L. Bottou.

Une Approche

de
l’Apprentissage Connexionniste:
`a
la Reconnaissance de la Parole. PhD thesis, Uni-
versit´e de Paris XI, 91405 Orsay cedex, France,
1991.

th´eorique
Applications

[5] Michael Collins. Discriminative training methods for
hidden markov models: Theory and experiments with
perceptron algorithms. In Proc. EMNLP, 2002.

[6] J. S. Denker and C. J. Burges. Image segmentation
In The Mathematics of Induction.

and recognition.
Addison Wesley, 1995.

[7] X. Driancourt and L. Bottou. MLP, LVQ and DP:
Comparison & cooperation.
In Proceedings of the
International Joint Conference on Neural Networks,
volume 2, pages 815–819, Seattle, 1991.

[8] P. Haffner. Connectionist speech recognition with a
In Eurospeech’93, Berlin,

global MMI algorithm.
September 1993.

[9] John Lafferty, Andrew McCallum, and Fernando
Pereira. Conditional random ﬁelds: Probabilistic
models for segmenting and labeling sequence data. In
Proc. International Conference on Machine Learning
(ICML), 2001.

[10] Yann LeCun, Leon Bottou, Yoshua Bengio, and
Patrick Haffner. Gradient-based learning applied to
document recognition. Proceedings of the IEEE,
86(11):2278–2324, November 1998.

[11] Yann LeCun, Fu-Jie Huang, and Leon Bottou. Learn-
ing methods for generic object recognition with in-
variance to pose and lighting. In Proc. CVPR, 2004.

[12] M. Osadchy, M. Miller, and Y. LeCun. Synergistic
In Proc. NIPS,

face detection and pose estimation.
2004.

[13] Kschischang F. R., B. J. Frey, and H.-A. Loeliger.
Factor graphs and the sum-product algorithm. IEEE
Trans. Information Theory, 47(2):498–519, February
2001.

[14] Ben Taskar, Carlos Guestrin, and Daphne Koller.
Max-margin markov networks. In Proc. NIPS, 2003.

[15] Y. W. Teh, M. Welling, S. Osindero, and Hinton G.
E. Energy-based models for sparse overcomplete rep-
resentations. Journal of Machine Learning Research,
4:1235–1260, 2003.

213Probabilistic Soft Interventions in Conditional Gaussian Networks

Florian Markowetz, Steﬀen Grossmann, and Rainer Spang

firstname.lastname@molgen.mpg.de
Dept. Computational Molecular Biology

Max Planck Institute for Molecular Genetics

Berlin, Germany

Abstract

We introduce a general concept of proba-
bilistic interventions in Bayesian networks.
This generalizes deterministic interventions,
which ﬁx nodes to certain states. We pro-
pose “pushing” variables in the direction of
target states without ﬁxing them. We formal-
ize this idea in a Bayesian framework based
on Conditional Gaussian networks.

1 Introduction

In modern biology, the key to infering gene function
and regulatory pathways are experiments with inter-
ventions into the normal course of action in a cell. A
common technique is to perturb a gene of interest ex-
perimentally and to study which other genes’ activity
or phenotypic features are eﬀected. Bayesian networks
present a prominent approach to derive a theoretical
model from these experiments (Pe’er et al., 2001; Yoo
et al., 2002; Friedman, 2004): genes are represented by
vertices of a network and the task is to ﬁnd a topol-
ogy, which explains dependencies between the genes.
When learning from observational data only, groups of
Bayesian networks may be statistically indistinguish-
able (Verma and Pearl, 1990). Information about ef-
fects of an intervention helps to resolve such equiva-
lence classes by including causal knowledge into the
model (Tian and Pearl, 2001). The ﬁnal goal is to
learn a graph structure which not only represents sta-
tistical dependencies, but also causal relations between
genes.
Manipulating the expression level of a gene can be
done in a variety of ways (Alberts et al., 2002). A
gene’s expression level can be down-regulated by sev-
eral techniques including
1. creating animals or cell lines in which the gene is

non-functional. This is called a knockout.

2. exposing a cell or animal to environmental stress
to inhibit the function of certain genes or proteins.
3. partially destroying the RNA transcribed from the
gene which itself is left intact. This is the recently
introduced method of RNA interference (RNAi).

All three examples have in common that the gene’s
expression level is pushed towards a “no expression”
state. Only in the ﬁrst example, however, the inter-
vention leads to a completely unfunctional gene.
In
RNAi the gene is still active, but silenced. It is less
active than normal due to human intervention. Hence,
we do not ﬁx the state of the gene, but push it towards
lower activities. In addition this pushing is random-
ized to some extent: the experimentalist knows that
he has silenced the gene, but he can not say exactly
by how much.
It is crucial that models reﬂect the way data was gen-
erated in the perturbation experiments. In Bayesian
structure learning, Tian and Pearl (2001) show that
interventions can be modeled by imposing diﬀerent pa-
rameter priors when the gene is actively perturbed or
passively observed. They only distinguish between two
kinds of interventions: most generally, interventions
that change the local probability distribution of the
node within a given family of distributions, and as a
special case, interventions that ﬁx the state of the vari-
able deterministically. The ﬁrst is called a mechanism
change; it does not assume any prior information on
how the local probability distribution changes. The
second type of intervention, which ﬁxes the state of
the variable, is called a do-operation and is treated
in detail in (Pearl, 2000; Spirtes et al., 2000). A do-
operation is used in almost all applications of inter-
ventional learning in Bayesian networks (e.g. Yoo and
Cooper, 2003; Yoo et al., 2002; Steck and Jaakkola,
2002; Tong and Koller, 2001; Pe’er at al., 2001; Mur-
phy, 2001; Cooper, 2000; Cooper and Yoo, 1999).
To model biological experiments as described above
we focus on interventions, which speciﬁcally concen-

214trate the local distribution at a certain node around
some target state. We will call them pushing interven-
tions, they are examples of mechanism changes with
prior knowledge. The do-operator is a special case of
a pushing intervention, which we call a hard interven-
tion. In this paper, we generalize hard interventions to
soft interventions: The local probability distribution
only centers more around the target value without be-
ing ﬁxed. This generalization is necessary to cope with
experiments as in the gene perturbation examples 2
and 3 above. If we treat them as unfocussed mecha-
nism changes we lose valuable information about what
kind of intervention was performed. Thus, we need a
concept of interventions, which is more directed than
general mechanism changes, but still softer than de-
terministic ﬁxing of variables.
The goal of the paper is to develop a theory for learning
a Bayesian network when data from diﬀerent (hard or
soft) pushing interventions of the network is available.
We ﬁrst explain how soft interventions can be modeled
by changing the prior distribution in Section 2. A soft
intervention can be realized by introducing a “push-
ing parameter”, which captures the pushing strength.
We propose a concrete parametrization of the pushing
parameter in the classical cases of discrete and Gaus-
sian networks. Hard interventions, which have been
formally described by choosing a Dirac prior in (Tian
and Pearl, 2001), can then be interpreted as inﬁnite
pushing.
Section 3 summarizes the results in the general setting
of Conditional Gaussian networks. This extends the
existing theory on learning with hard interventions in
discrete networks to learning with soft interventions in
networks containing discrete and Gaussian variables.
The concluding Section 4 deals with probabilistic soft
interventions:
in this set-up the pushing parameter
becomes a random variable and we assign a hyperprior
to it. Hence, we account for the experimentalists lack
of knowledge on the actual strength of intervention by
weighted averaging over all possible values.

2 Pushing interventions in Bayesian

networks

A Bayesian network is a graphical representation of
the dependency structure between the components of a
random vector X. The individual random variables are
associated with the vertices of a directed acyclic graph
(DAG) D, which describes the dependency structure.
Once the states of its parents are given, the proba-
bility distribution of a given node is ﬁxed. Thus, the
Bayesian network is completely speciﬁed by the DAG
and the local probability distributions (LPDs).

Although this deﬁnition is quite general, there are ba-
sically three types of Bayesian networks which are used
in practice: discrete, Gaussian and Conditional Gaus-
sian (CG) networks. CG networks are a combination
of the former two and will be treated in more detail
in Section 3, for the rest of this section we focus on
discrete and Gaussian networks.
In discrete and Gaussian networks, LPDs are taken
from the family of the multinomial and normal distri-
bution, respectively. In the theory of Bayesian struc-
ture learning, the parameters of these distributions are
not ﬁxed, but instead a prior distribution is assumed
(Cooper and Herskovits, 1992; Geiger and Heckerman,
1994; Bøttcher, 2004). The priors usually chosen be-
cause of conjugacy are the Dirichlet distribution in the
discrete case and the Normal-inverse-χ2 distribution in
the Gaussian case. Averaging the likelihood over these
priors yields the marginal likelihood – the key quantity
in structure learning (see Section 3).
An intervention at a certain node in the network can in
this setting easily be modeled by a change in the LPDs’
prior. When focusing on (soft) pushing interventions,
this change should result in an increased concentration
of the node’s LPD around the target value. We model
this concentration by introducing a pushing parame-
ter w which is meant to measure the strength of the
pushing — a higher value of w results in a stronger con-
centration of the LPD. We now explain in more detail
how this is done for discrete and Gaussian networks.
Since the joint distribution p(x) in a Bayesian network
factors according to the DAG structure in terms only
involving a single node and its parents, it will suﬃce
to concentrate on one such family of nodes.

2.1 Pushing by Dirichlet priors

We denote the set of discrete nodes by ∆ and a dis-
crete random variable at node δ ∈ ∆ by Iδ. The set of
possible states of Iδ is Iδ. The parametrization of the
discrete LPD at node δ is called θδ. For every conﬁgu-
ration ipa(δ) of parents, θδ contains a vector of proba-
bilities for each state iδ ∈ Iδ. Realizations of discrete
random variables are multinomially distributed with
parameters depending on the state of discrete parents.
The conjugate prior is Dirichlet with parameters also
depending on the state of discrete parents:
Iδ | ipa(δ), θδ ∼ Multin(1, θδ|ipa(δ)),
θδ|ipa(δ) ∼ Dirichlet(αδ|ipa(δ)).

(1)

We assume that the αδ|ipa(δ) are chosen to respect like-
lihood equivalence as in (Heckerman et al., 1995). Do-
ing a pushing intervention at node δ amounts to chang-
ing the prior parameters such that the multinomial
density concentrates at some target value j. We for-

215the pushing operator as in the case of discrete nodes;
which one to use will be clear from the context. Again
wγ ∈ [0,∞] represents intervention strength.
The exponential function maps the real valued w into
the interval [0, 1]. The exponential decay towards 0
ensures that by increasing w interventions quickly gain
in strength. The interventional prior mean m0 is a
convex combination of the original mean m with a
“pushing” represented by k11. If w = 0 the mean of
the normal prior and the scale of the inverse-χ2 prior
remain unchanged. As w → ∞ the scale s02 goes to
0, so the prior for σ2 tightens at 0. At the same time,
the regression coeﬃcients of the parents converge to 0
and β0 goes to value k. All in all, with increasing w
the distribution of Yγ peaks more and more sharply at
Yγ = k.
Note that the discrete pushing parameter wδ and the
Gaussian pushing parameter wγ live on diﬀerent scales
and will need to be calibrated individually.

2.3 Hard pushing

Hard pushing means to make sure that a certain node’s
LPD produces almost surely a certain target value. It
has been proposed by Tian and Pearl (2001) to model
this by imposing a Dirac prior on the LPD of the node.
Although the Dirac prior is no direct member of nei-
ther the Dirichlet nor the Normal-inverse-χ2 family of
distributions it arises for both of them when taking
the limit w → ∞ for the pushing strength. Tian and
Pearl (2001) give an example for discrete networks,
which can easily be extended to Gaussian networks by

p(βγ, σ2

γ | do(Yγ = k)) =

γ − k) Y

d(β(0)

d(β(i)

γ ) · d(σ2
γ).

(5)

i∈pa(γ)

Here, d(·) is the Dirac function. Averaging over this
prior sets the variance and the regression coeﬃcients
to zero, while β(0)
is set to k. Thus, the marginal
distribution of Yγ is ﬁxed to state k with probability
one.

γ

2.4 Modeling interventions by policy

variables

Hard interventions can be modeled by introducing a
policy variable as an additional parent node of the vari-
able at which the intervention is occuring (Pearl, 2000;
Spirtes et al., 2000; Lauritzen, 2000). In the same way
we can use policy variables to incorporate soft inter-
ventions. For each node v, we introduce an additional
parent node Fv (“F” for “force”), which is keeping
track of whether an intervention was performed at Xv
or not, and if yes, what the target state was. For a

Figure 1: Examples of pushing a discrete variable with
three states. Each triangle represents the sample space
of the three-dimensional Dirichlet distribution (which
is the parameter space of the multinomial likelihood of
the node). The left plot shows a uniform distribution
with Dirichlet parameter α = (1, 1, 1). The other two
plots show eﬀects of pushing with increasing weight:
w = 3 in the middle and w = 10 at the right. In each
plot 1000 points were sampled.

malize this by introducing a pushing operator P de-
ﬁned by

P(αδ|ipa(δ), wδ, j) = αδ|ipa(δ) + wδ · 1j,

(2)
where 1j is a vector of length |Iδ| with all entries zero
except for a single 1 at state j. The pushing parame-
ter wδ ∈ [0,∞] determines the strength of intervention
at node δ: if wδ = 0 the prior remains unchanged, if
wδ = ∞ the Dirichlet prior degenerates to a Dirac dis-
tribution and ﬁxes the LPD to the target state j. Fig-
ure 1 shows a three-dimensional example of increasing
pushing strength wδ.

2.2 Pushing by Normal-inverse-χ2 priors

The set of Gaussian nodes will be called Γ and we de-
note a Gaussian random variable at node γ ∈ Γ by Yγ.
In the purely Gaussian case it depends on the values
of parents Ypa(γ) via a vector of regression coeﬃcients
βγ. If we assume that βγ contains a ﬁrst entry β(0)
γ ,
the parent-independent contribution of Yγ, and attach
to Ypa(γ) a leading 1, we can write for Yγ the standard
regression model (Bøttcher, 2004):

γ ∼ N(Y>
Yγ | βγ, σ2
γ),
pa(γ)βγ, σ2
γ ∼ N(m, σ2
βγ | σ2
γM−1),
γ ∼ Inv-χ2(ν, s2).
σ2

(3)

We assume that the prior parameters m, M, ν, s2 are
chosen as in (Bøttcher, 2004). To push Yγ to a value k
we exchange m and s2 by (m0, s02) = P((m, s2), wγ, k)
deﬁned by

m0 = e−wγ · m + (1 − e−wγ ) · k11,
s02 = s2/(wγ + 1),

(4)

where k11 is a vector of length |ipa(γ)| + 1 with all
entries zero except the ﬁrst, which is k. We use P for

216discrete variable Iδ, the policy variable Fδ has state
space Iδ ∪ ∅ and we can write

p(θδ|ipa(δ),fδ) =

(Dirichlet(αδ|ipa(δ))

Dirichlet(α0

δ|ipa(δ)

)

=

if Fδ = ∅,
if Fδ = j,

(6)

δ|ipa(δ)

= P(αδ|ipa(δ), wδ, j) is derived from
where α0
αδ|ipa(δ) as deﬁned in Eq. 2. For a continuous vari-
able Yγ, the policy variable Fγ has state space IR ∪ ∅
and we can write

p(βγ|fγ , σ2

γ|fγ

) =

(

=

N(m, M) · Inv-χ2(ν, s2)
N(m0, M) · Inv-χ2(ν, s02)

if Fγ = ∅,
if Fγ = k,

(7)

where (m0, s02) = P((m, s2), wγ, k) as deﬁned in Eq. 4.
Equations 6 and 7 will be used in section 3.2 to
compute the marginal likelihood of Conditional Gaus-
sian networks from a mix of interventional and non-
interventional data.

3 Pushing in Conditional Gaussian

networks

In this section we summarize the results in the gen-
eral framework of Conditional Gaussian networks and
compute a scoring metric for learning from soft inter-
ventions.

3.1 Conditional Gaussian networks

Conditional Gaussian (CG) networks are Bayesian net-
works encoding a joint distribution over discrete and
continuous variables. We consider a random vector X
splitting into two subsets: I containing discrete vari-
ables and Y containing continuous ones. The depen-
dencies between individual variables in X can be repre-
sented by a directed acyclic graph (DAG) D with node
set V and edge set E. The node set V is partitioned as
V = ∆ ∪ Γ into nodes of discrete (∆) and continuous
(Γ) type. Each discrete variable corresponds to a node
in ∆ and each continuous variable to a node in Γ. The
distribution of a variable Xv at node v only depends
on variables Xpa(v) at parent nodes pa(v). Thus, the
joint density p(x) decomposes as

p(x) = p(i, y) = p(i)p(y|i)

= Y

p(iδ|ipa(δ)) ·Y

δ∈∆

γ∈Γ

p(yγ|ypa(γ), ipa(γ)). (8)

The discrete part, p(i), is given by an unrestricted
discrete distribution. The distribution of continuous
random variables given discrete variables, p(y|i),
is

multivariate normal with mean and covariance matrix
depending on the conﬁguration of discrete variables.
Since discrete variables do not depend on continuous
variables, the DAG D contains no edges from nodes in
Γ to nodes in ∆.
For discrete nodes, the situation in CG networks is
exactly the same as in the pure case discussed in Sec-
tion 2: The distribution of Iδ|ipa(δ) is multinomial and
parametrized by θδ. Compared to the purely Gaussian
case treated in Section 2, we have for Gaussian nodes
in CG networks an additional dependency on discrete
parents. This dependency shows in the regression co-
eﬃcients and the variance, which now not only depend
on the node, but also on the state of the discrete par-
ents:

Yγ | βipa(γ), σ2

ipa(γ) ∼ N(Y>

pa(γ)βipa(γ), σ2

ipa(γ)). (9)
As a prior distribution we again take the conjugate
normal-inverse-χ2 distribution as in Eq. 3. For further
details on CG networks we refer to (Lauritzen, 1996;
Bøttcher, 2004).

3.2 Learning from interventional and

non-interventional data

Z

Assuming an uniform prior over network structures D,
the central quantity to be calculated is the marginal
likelihood p(d|D) (Heckerman et al., 1995). In the case
of only one type of data it can be written as

Θ

p(d|D) =

p(d|D, θ)p(θ|D) dθ.

(10)
Here p(θ|D) is the prior on the parameters θ of the
LPDs. If the dataset contains both interventional and
non-interventional cases, the basic idea is to choose pa-
rameter priors locally for each node as in Eq. 6 and 7
according to whether a variable was intervened in a
certain case or not. We will see that this strategy ef-
fectively leads to a local split of the marginal likelihood
into an interventional and a non-interventional part.

3.2.1 A family-wise view of marginal

likelihood

To compute the marginal likelihood of CG networks on
interventional and non-interventional data, we rewrite
Eq. 10 in terms of single nodes such that the theory
of (soft) pushing from Section 2 can be used. In the
computation we will use the following technical utili-
ties:

1. The dataset d consists of N cases x1, . . . , xN ,
which are sampled independently. Thus we can
write p(d|D, θ) as a product over all single case
likelihoods p(xc|D, θ), c = 1, . . . , N.

2172. The joint density p(x) factors according to the
DAG D as in Eq. 8. Thus for each case xc we can
write p(xc|D, θ) as a product over node contribu-
tions p(xc

pa(v), θv) for all v ∈ V .

v|xc

3. We assume parameter independence: the param-
eters associated with one variable are indepen-
dent of the parameters associated with other vari-
ables, and the parameters are independent for
each conﬁguration of the discrete parents (Heck-
erman et al., 1995) This allows us to decompose
the prior p(θ|D) in Eq. 10 into node-wise pri-
ors p(θv|ipa(v)|D) for a given parent conﬁguration
ipa(v).

4. All interventions are soft pushing. For a given
node, intervention strength and target state stay
the same in all cases in the data, but of course dif-
ferent nodes may have diﬀerent pushing strengths
and target values. This constraint just helps us to
keep the following formulas simple and can easily
be dropped.

These four assumptions allow a family-wise view of the
marginal likelihood. Before we present it in a formula,
it will be helpful to introduce a batch notation.
In
CG networks, the parameters of the LPD at a certain
node depend only on the conﬁguration of discrete par-
ents. This holds for both discrete and Gaussian nodes.
Thus, when evaluating the likelihood of data at a cer-
tain node, it is reasonable to collect all cases in a batch,
which correspond to the same parent conﬁguration:
p(d|D, θ)

= Y
= Y

c∈d

v∈V

Y

p(xc|D, θ) = Y
Y
Y

c∈d

v∈V
p(xc

v|ic

ipa(v)

c:ic

pa(v)=ipa(v)

p(xc

v|xc

pa(v), θv)

pa(v), ypa(v), θv)

(11)

The last formula is somewhat technical: If the node v
is discrete, then ypa(v) will be empty, and usually not
all parent conﬁguration ipa(v) are found in the data, so
some terms of the product will be missing.
For each node we will denote the cases with the same
joint parent state by Bipa(v). When learning with inter-
ventional data, we have to distinguish further between
observations of a variable which were obtained pas-
sively and those that are result of intervention. Thus,
for each node v we split the batch Bipa(v) into one con-
taining all observational cases and one containing the
interventional cases:

ipa(v) = {c ∈ d : ic
Bobs

ipa(v) = {c ∈ d : ic
Bint

pa(v) = ipa(v)
and no intervention at v},
pa(v) = ipa(v)
and intervention at v}.

If there is more than one type of intervention applied
to node v, the batch containing interventional cases
has to be split accordingly. Using this notation we
can now write down the marginal likelihood for CG
networks in terms of single nodes and parents:

p(d|D) =Y
Y
Y
Y

v∈V

ipa(v)

Z
Z

Θ

v∈V

Y
Y

Bobs

ipa(v)

p(xo

v|ipa(v), yo

pa(v), θv)p0(θv|D) dθv ×

p(xe

v|ipa(v), ye

pa(v), θv)p00(θv|D, wv) dθv.

ipa(v)

Θ

Bint

ipa(v)

(12)

At each node, we use distributions and priors as de-
ﬁned in Eq. 6 for discrete nodes and Eq. 7 for Gaussian
nodes. The non-interventional prior p0 corresponds to
Fv = ∅ and the interventional prior p00 corresponds to
Fv equalling some target value. We denoted the in-
tervention strength explicitly in the formula, since we
will focus on it further when discussing probabilistic
soft interventions in Section 4.
Equation 12 consists of an observational and an inter-
ventional part. Both can further be split into a discrete
and a Gaussian part, so we end up with four terms to
consider.

3.2.2 Discrete observational part

To write down the marginal likelihood of discrete ob-
servational data, we denote by niδ|ipa(δ) the number of
times we passively observe Iδ = iδ in batch Bobs
, and
by αiδ|ipa(δ) the corresponding pseudo-counts of the
Dirichlet prior. Summation of αiδ|ipa(δ) and niδ|ipa(δ)
over all iδ ∈ Iδ is abbreviated by αipa(δ) and nipa(δ),
respectively. Then, the marginal likelihood of the dis-
crete data d∆ can be written as

ipa(δ)

 

Y

p(d∆ | D) =Y
Y

δ∈∆

Γ(αipa(δ))

Γ(αipa(δ) + nipa(δ))

ipa(δ)
Γ(αiδ|ipa(δ) + niδ|ipa(δ))

×

!

(13)

,

iδ∈Iδ

Γ(αiδ|ipa(δ))

This result was ﬁrst obtained by Cooper and Her-
skovits (1992) and is further discussed in (Heckerman
et al., 1995).

3.2.3 Discrete interventional part

Since interventions are just changes in the prior, the
marginal likelihood of the interventional part of dis-
crete data is of the same form as Eq. 13. The prior
parameters αiδ|ipa(δ) are exchanged by α0
=

iδ|ipa(δ)

218.

ipa(δ)

iδ|ipa(δ)

P(αiδ|ipa(δ), wδ, j) as given by Eq. 2, and the counts
niδ|ipa(δ) are exchanged by n0
taken from batch
Bint
In the limit wδ → ∞ this part converges to one and
vanishs from the overall marginal likelihood p(d|D).
This special case was already shown in (Cooper and
Yoo, 1999; Tian and Pearl, 2001).

3.2.4 Gaussian observational part

ipa(γ)

All cases yγ in batch Bobs
are sampled independently
from a normal distribution with ﬁxed parameters. If
we gather them in a vector yγ and the corresponding
states of continuous parents as rows in a matrix Pγ,
we yield the standard regression scenario

yγ ∼ N(Pγβγ, σ2

γI),

(14)
where I is the identity matrix. As a prior distribu-
tion we choose normal-inverse-χ2 as shown in Eq. 3.
γ yields a multi-
Marginalizing with respect to βγ and σ2
variate t-distribution of dimension |Bobs
|, with loca-
ipa(γ)
tion vector Pm, scale matrix s(I + PM−1P>), and ν
degrees of freedom. The density function can be found
in many textbooks (e.g. Gelman et al., 1996).
When using data from diﬀerent batches, every parame-
ter above carries an index “ipa(γ)” indicating that it de-
pends on the state of the discrete parents of the Gaus-
sian node γ. Multiplying t-densities for all nodes and
conﬁgurations of discrete parents—the outer double-
product in Eq. (12)—yields the marginal likelihood of
the Gaussian part. See Bøttcher (2004) for details.

3.2.5 Gaussian interventional part

ipa(γ)

Here we consider cases yγ in batch Bint
. We col-
lect them in a vector and can again write a regression
model like in Eq. 14. The diﬀerence to the observa-
tional Gaussian case lies in the prior parameters. They
are now given by Eq. 4. The result of marginaliza-
tion is again a t-density with parameters as above, just
m, s are exchanged by (m0, s0) = P((m, s), wγ, k). The
Gaussian interventional part is then given by a prod-
uct of such t-densities over nodes and discrete parent
conﬁgurations.
If we use the hard intervention prior in Eq. 5 instead,
the Gaussian interventional part integrates to one and
vanishs from the marginal likelihood in Eq. (12). This
is the extension of the results in (Cooper and Yoo,
1999) to Gaussian networks.

4 Probabilistic soft interventions

In Section 2 we introduced the pushing operator
P(·, wv, tv) to model a soft intervention at a discrete

or Gaussian node v. The intervention strength wv is
a parameter, which has to be chosen before network
learning. There are several possibilities, how to do it:

• If there is solid experimental experience on how
powerful interventions are, this can be reﬂected in
an appropriate choice of wv. An obvious problem
is that wv needs to be determined on a scale that
is compatible with the Bayesian network model.
• If there is prior knowledge on parts of the network
topology, the parameter wv can be tuned until the
result of network learning ﬁts the prior knowledge.

Note again that by the parametrization of pushing
given in Section 2, the pushing strengths for discrete
and Gaussian nodes live on diﬀerent scales and have
to be calibrated separately.
However, a closer inspection of the biological experi-
ments, which motivated the theory of soft pushing in-
terventions, suggests to treat the intervention strength
wv as a random variable: In gene silencing an inhibit-
ing molecule (a double-stranded RNA in case of RNAi)
is introduced into the cell. This usually works in a
high percentage of aﬀected cells. In the case of suc-
cess, the inhibitor still has to spread throughout the
cell to silence the target gene. This diﬀusion process is
stochastic and consequently causes experimental vari-
ance in the strength of the silencing eﬀect.
These observations suggest to assign a prior distri-
bution p(wv) to the intervention strength. That is,
we drop the assumption of having one intervention
strength in all cases, but instead average over possi-
ble values of wv. For simplicity we assume there is
only a limited number of possible values of wv, say,
w(1)
v , with an arbitrary discrete distribution
assigned to them. Then we can express our inabil-
ity to control the pushing strength in the experiment
deterministically by using a mixed prior of the form:

v , . . . , w(k)

kX

p(θv|D) =

qk p(θv|D, w(k)
v ).

(15)

i=1

Here, the mixture coeﬃcients qk = p(w(k)
v ) are the
prior probabilities of each possible pushing strength.
The terms p(θv|D, w(k)
v ) correspond to Dirichlet den-
sities in the discrete case and Normal-inverse-χ2 den-
sities in the Gaussian case.
In RNAi experiments,
w(1)
can be estimated from the empirical dis-
tribution of measured RNA degradation eﬃciencies in
repeated assays.
Mixed priors as in Eq. 15 are often used in biological
sequence analysis to express prior knowledge which is

v , . . . , w(k)

v

219not easily forced into a single distribution. See (Durbin
et al., 1998) for details.
If we substitute the prior p00(θv|D, wv) in the interven-
tional part of Eq. 12 with the mixture prior in Eq. 15,
the marginal likelihood of a family of nodes is a mix-
ture of marginal likelihoods corresponding to certain
values w(k)

v weighted by mixture coeﬃcients qk.

5 Conclusion

Our work extends structure learning from interven-
tional data into two directions: from learning discrete
networks to learning mixed networks and from learning
with hard interventions to learning with soft interven-
tions.
Soft interventions are focussed on a speciﬁc target
value of the variable of interest and concentrate the
local probability distribution there. We proposed
parametrizations for pushing discrete and continuous
variables using Dirichlet and Normal-inverse-χ2 priors,
respectively.
We computed the marginal likelihood of CG networks
for data containing both observational and (soft) in-
terventional cases. In Bayesian structure learning, the
marginal likelihood is the key quantity to compute
from data. Using it (and possibly a prior over network
structures) as a scoring function, we can start model
search over possible network structures. For networks
with more than 5 nodes, exhaustive search becomes in-
feasible; often used search heuristics include hill climb-
ing or MCMC methods. For a survey see Heckerman
et al. (1995) and references therein.
Since in biological settings the pushing strength is un-
known we proposed using a mixture hyperprior on it,
resulting in a mixture marginal likelihood. This makes
the score for each network more time-consuming to
compute. Searching in the space of DAGs may be-
come infeasible even with quick search heuristics. But
in applications there is often a large amount of biolog-
ical prior knowledge, which limits the number of path-
way candidates from the beginning. When learning
network structure we usually don’t have to optimize
the score over the space of all possible DAGs but are
limited to a few candidate networks, which are to be
compared. This corresponds to a very rigid structure
prior.
Due to measurement error or noise inherent in the ob-
served system it may often happen that a variable,
at which an intervention took place, is observed in a
state diﬀerent from the target state. In the hard in-
tervention framework, a single observation of this kind
results in a marginal likelihood of zero. Modeling in-

terventions as soft pushing mends this problem and
makes structure learning more robust against noise.
This is a central beneﬁt of our approach.

Acknowledgements

This work was done within the context of the Berlin
Center for Genome Based Bioinformatics (BCB), part
of the German National Genome Research Network
(NGFN) and supported by BMBF grants 031U109C
and 03U117. We thank Dennis Kostka as well as the
rest of CMB for helpful discussions.

References

B. Alberts, A. Johnson, J. Lewis, M. Raﬀ, K. Roberts,
and P. Walter. Molecular Biology of the Cell. Garland
Science, New York, 4 edition, 2002.
S. G. Bøttcher. Learning Bayesian Networks with
Mixed Variables. PhD thesis, Aalborg University, Den-
mark, 2004.
G. F. Cooper. A Bayesian Method for Causal Model-
ing and Discovery Under Selection. In Proceedings of
UAI 16, pages 98–106, 2000.
G. F. Cooper and E. Herskovits. A Bayesian Method
for the Induction of Probabilistic Networks from Data.
Machine Learning, 9:309–347, 1992.
G. F. Cooper and C. Yoo. Causal discovery from a
mixture of experimental and observational data.
In
Proceedings of UAI 15, pages 116–125, 1999.
R. Durbin, S. Eddy, A. Krogh, and G. Mitchison. Bio-
logical sequence analysis. Cambridge University Press,
1998.
N. Friedman. Inferring Cellular Networks Using Prob-
abilistic Graphical Models. Science, 303(5659):799–
805, 2004.
D. Geiger and D. Heckerman. Learning Gaussian Net-
works. In Proceedings of UAI 10, pages 235–243, 1994.
A. Gelman, J. B. Carlin, H. S. Stern, and D. B. Ru-
bin. Bayesian Data Analysis. Chapman and Hall-
CRC, 1996.
D. Heckerman, D. Geiger, and D. M. Chickering.
Learning Bayesian Networks: The Combination of
Knowledge and Statistical Data. Machine Learning,
20(3):197–243, Sep. 1995.
S. L. Lauritzen. Graphical Models. Clarendon Press,
Oxford, 1996.
S. L. Lauritzen.
Causal Inference from Graphical
Models. In: O. E. Barndorﬀ-Nielsen, D. R. Cox, and
C. Kl¨uppelberg (eds.) Complex Stochastic Systems.
Chapman and Hall, London, 2000.

220K. P. Murphy. Active Learning of Causal Bayes Net
Structure, Tech. Rep., UC Berkeley, 2001.
J. Pearl. Causality: Models, Reasoning and Inference.
Cambridge University Press, Cambridge, 2000.
D. Pe’er, A. Regev, G. Elidan, and N. Friedman. Infer-
ring subnetworks from perturbed expression proﬁles.
Bioinformatics, 17(90001):S215–S224, 2001.
P. Spirtes, C. Glymour, and R. Scheines. Causation,
Prediction, and Search. MIT Press, Cambridge, MA,
second edition, 2000.
H. Steck and T. S. Jaakkola. Unsupervised active
learning in large domains. In Proceedings of UAI 18,
pages 469–476, 2002.
J. Tian and J. Pearl. Causal discovery from changes:
a Bayesian approach. In Proceedings of UAI 17, pages
512–521, 2001.
S. Tong and D. Koller. Active Learning for Structure
in Bayesian Networks.
In Proceedings of IJCAI 17,
2001.
T. S. Verma and J. Pearl. Equivalence and synthesis
of causal models. In Proceedings of UAI 6, pages 255–
268, 1990.
C. Yoo and G. F. Cooper. An evaluation of a system
that recommends microarray experiments to perform
to discover gene-regulation pathways. Journal Artiﬁ-
cial Intelligence in Medicine, 2003.
C. Yoo, V. Thorsson, and G. F. Cooper. Discovery of
causal relationships in a generegulation pathway from
a mixture of experimental and oberservational DNA
microarray data. In Proceedings of PSB 7, pages 498-
509, 2002.

221Unsupervised Learning with Non-Ignorable Missing Data

Benjamin M. Marlin, Sam T. Roweis, Richard S. Zemel

Department of Computer Science

University of Toronto

Toronto, Ontario

Abstract

In this paper we explore the topic of un-
supervised learning in the presence of non-
ignorable missing data with an unknown
missing data mechanism. We discuss sev-
eral classes of missing data mechanisms for
categorical data and develop learning and in-
ference methods for two speci(cid:12)c models. We
present empirical results using synthetic data
which show that these algorithms can recover
both the unknown selection model parame-
ters and the underlying data model param-
eters to a high degree of accuracy. We also
apply the algorithms to real data from the
domain of collaborative (cid:12)ltering, and report
initial results.

1

Introduction

In large, real world data sets (such as those commonly
used for machine learning research), the presence of a
certain amount of missing data is inevitable. Proba-
bilistic methods o(cid:11)er a natural framework for dealing
with missing data, and there is a large body of work
devoted to statistical analysis in this setting.

There are two important classes of missing data: miss-
ing data that is ignorable, and missing data that is
non-ignorable.
Ignorable missing data includes data
that is missing completely at random (MCAR), and
data that is missing at random (MAR). Intuitively,
missing data is ignorable if the probability of observ-
ing a data item is independent of the value of that data
item. Conversely, missing data is non-ignorable if the
probability of observing a data item is dependent on
the value of that data item.

The majority of statistical literature deals with the
case where missing data is missing at random. How-
ever, there are several important cases where the miss-

ing at random assumption fails to hold. Well studied
examples from statistics include non-response in sur-
veys, panel data studies, and longitudinal studies. In
surveys non-ignorable missing data often results from
asking questions about income where the probability
of non-response has been found to vary according to
the income of the respondent. In such cases comput-
ing statistics like average income without taking the
missing data mechanism into account will result in a
biased estimator.

A much more complex domain where missing data may
be non-ignorable is rating-based collaborative (cid:12)ltering
[5]. The data in this domain often comes from recom-
mender systems where users rate di(cid:11)erent items and
receive recommendations about new items they might
like. When a user is free to chose which items they
rate, we hypothesize that many users will exhibit a
bias toward rating items they like (and perhaps a few
they strongly dislike). Thus the probability of observ-
ing a rating for a given item will depend on the user’s
rating for that item, and the missing ratings will not be
missing at random. The best known methods for pre-
dicting user ratings are based on using unsupervised
learning techniques to estimate the parameters of a
probabilistic model over rating pro(cid:12)les. Just as in the
simple mean income estimation problem, the model
parameter estimates will be biased in the presence of
non-ignorable missing data.

In this paper we consider the general problem of learn-
ing latent variable models in the presence of non-
ignorable missing data with an unknown missing data
mechanism. We present learning methods based on the
Expectation Maximization (EM) algorithm for several
di(cid:11)erent models. We present empirical results on sev-
eral synthetic data sets showing that the learning pro-
cedure recovers the data and selection model param-
eters to a high degree of accuracy. We also present
interesting results on real data from the collaborative
(cid:12)ltering domain.

222L((cid:18)jY obs) = log f (Y obsj(cid:18)) = log Z f (Y obs; Y misj(cid:18))dY mis

L((cid:18); (cid:22)jY obs; R) = log f (Y obs; Rj(cid:18); (cid:22)) = log Z f (RjY obs; Y mis; (cid:22))f (Y obs; Y misj(cid:18))dY mis

LMAR((cid:18); (cid:22)jY obs; R) = log f (RjY obs; (cid:22)) + log Z f (Y obs; Y misj(cid:18))dY mis = L((cid:18)jY obs) + L((cid:22)jY obs; R)

(1)

(2)

(3)

2 Non-Ignorable Missing Data Theory

We begin with technical de(cid:12)nitions of ignorable and
non-ignorable missing data due to Little and Rubin,
and review the theory of maximum likelihood estima-
tion with non-ignorable data.

Let Y denote a complete data set and let Y obs and
Y mis be the observed and missing elements of Y . Let
R be a matrix of response indicators where Rij =
1 if Yij
is observed and 0 otherwise. We de(cid:12)ne
f (Y; Rj(cid:18); (cid:22)) = f (Y j(cid:18))f (RjY; (cid:22)) to be the joint distri-
bution over the data and response indicators. We refer
to f (Y j(cid:18)) as the data model and f (RjY; (cid:22)) as the se-
lection model.

In the presence of missing data the correct maximum
likelihood inference procedure is to maximize the full
data likelihood L((cid:18); (cid:22)jY obs; R) = log f (Y obs; Rj(cid:18); (cid:22))
shown in equation 2 as opposed to the observed data
log likelihood shown in equation 1. The only case
where it is acceptable to rely on the observed data
likelihood is when the missing at random (MAR) con-
dition holds. The MAR condition is satis(cid:12)ed when
f (RjY obs; Y mis; (cid:22)) = f (RjY obs; (cid:22)) for all (cid:22), and (cid:22) and
(cid:18) are distinct parameters. If we suppose that the MAR
condition holds we (cid:12)nd that the full data log likelihood
and the observed data log likelihood will give identical
inferences for (cid:18), as shown in equation 3.

When missing data is missing not at random (MNAR)
this convenient result does not hold, and maximum
likelihood estimation of the data model parameters (cid:18)
based only on the observed likelihood will be biased.
To obtain correct maximum likelihood estimates of the
data model parameters a selection model is needed
along with the data model [3, p. 218]. In most cases
the parameters of the selection model will also be un-
known. Fortunately the parameters of the combined
data and selection model can be estimated simultane-
ously by maximizing the full data log likelihood using
the standard EM algorithm.

n

Ymn

Rmn

M

N

Figure 1: Combined data and selection model.

ment ymn is categorical, and is drawn from the set of
possible values f1; :::; V g. We will assume that the yn
are independent, that any element ymn may be unob-
served, and that the selection process is unknown.

To specify a model for non-ignorable missing data
we must choose a data model and a selection model.
We choose a multinomial mixture model for the data
model. This is a simple model for categorical data that
has proved to be quite robust in the collaborative (cid:12)l-
tering domain [5]. Several other models for categorical
data could also be used including the aspect model [2]
and the URP model [4].

The more interesting choice is the choice of a selec-
tion model.
In general, the probability that a par-
ticular variable is observed can depend on any other
variable in the data model. Learning such an unstruc-
tured model would be intractable, so we must assume
additional independence structure. To begin with, we
assume that the probability of being observed is inde-
pendent for each component of the data vector; this
is formalized in equation 4.
(Analogous simplifying
assumptions have been used previously in similar dis-
crete, non-ignorable contexts [6].)

3 Non-Ignorable Missing Data Models

P (rjy; z) =

M

Y

m=1

(cid:22)ymmz

(rm)(1 (cid:0) (cid:22)ymmz)(1(cid:0)rm)

(4)

Suppose we are given a data set containing N data
vectors yn, each of length M . The value of each ele-

If we represent the Bernoulli observation parameters
P (rm = 1jym = v; Z = z) = (cid:22)vmz using conditional

223q
b
m
Z
probability tables and combine this selection model
with the multinomial mixture data model, we obtain
a simple, tractable model for non-ignorable missing
data. We call this the CPT-vmz model since the (cid:22)vmz
probabilities are represented by conditional probabil-
ity tables (CPTs), and the selection probability de-
pends on the settings of the variables v, m, and z.
This combined data and selection model is depicted
graphically in (cid:12)gure 1.

The variables in the model are the latent variable
Zn, the data variables Ymn, and the corresponding re-
sponse indicators Rmn. Recall that m indexes dimen-
sions of the data vectors, and n indexes data cases.
We suppress the data case index for simplicity when it
is clear that we are referring to a single, generic data
case. The parameters are the prior mixing proportions
(cid:18), the component distributions (cid:12), and the selection
model parameters (cid:22). To generate data from the com-
bined multinomial mixture data model and CPT-vmz
selection model we begin by sampling a state z of the
latent variable Z according to P (Z = zj(cid:18)) = (cid:18)z. We
then sample a value v for each element ym according
to P (ym = vjZ = z; (cid:12)) = (cid:12)vmz. This is simply the
standard generative process for the multinomial mix-
ture model. Next, for each element ym, we sample a
response indicator variable according to the selection
probability P (rm = rjym = v; M = m; Z = z; (cid:22)) =
(cid:22)vmz. We then discard the values of ym for which
rm = 0.

Depending on the type of selection e(cid:11)ect that is
present in the data, it may be desirable to further
constrain the selection model. Imposing independence
and factorization conditions on the Bernoulli proba-
bilities (cid:22)vmz results in a range of selection models
with di(cid:11)erent properties.
In this paper we concen-
trate on two models in particular: a model we call
CPT-v that makes the additional independence as-
sumption P (rmjym; m; z) = P (rmjym), and a model
we call LOGIT-v,mz which proposes a functional de-
composition of P (rmjym; m; z) based on the logistic
function.

3.1 The CPT-v Model

While the CPT-vmz model is highly (cid:13)exible and can
model a range of very di(cid:11)erent selection e(cid:11)ects, this
(cid:13)exibility may result in over (cid:12)tting on many data sets.
By contrast the CPT-v model asserts that only the
value of a random variable a(cid:11)ects its chance of being
observed or missing. The CPT-v model is highly con-
strained, but this makes it appealing when we have
limited observations and cannot robustly (cid:12)t the full
CPT-vmz model. Examples of the type of e(cid:11)ects this
model captures are \mostly high values are observed",
or \only extreme values are observed". However, it can

Algorithm 1 Expectation Maximization Algorithm
for the CPT-v model

E-Step:
(cid:21)vmzn   ((cid:14)(ymn; v)(cid:22)v(cid:12)vmz)rmn ((1(cid:0)(cid:22)v)(cid:12)vmz)1(cid:0)rmn
(cid:13)mzn   PV
(cid:30)zn   (cid:18)zn QM
PK

m=1 (cid:13)mzn
0 QM

v=1 (cid:21)vmzn

m=1 (cid:13)mzn

z=1 (cid:18)z

M-Step:

n=1 (cid:30)zn(cid:21)vmzn=(cid:13)mzn

PN

z=1 (cid:30)zn

n=1 (cid:30)zn

n=1 PK

(cid:18)z   PN
(cid:12)vmz   PN
PN
n=1 (cid:30)zn
z=1 (cid:30)zn PM
n=1 PK
(cid:22)v   PN
PN
n=1 PK
z=1 (cid:30)zn PM

m=1 rmn(cid:21)vmzn=(cid:13)mzn

m=1 (cid:21)vmzn=(cid:13)mzn

not e(cid:14)ciently represent e(cid:11)ect of the type \data item
m is observed almost always." As we will see, the strict
assumptions of the CPT-v model can cause problems
during model (cid:12)tting if the data contains strong item-
based e(cid:11)ects.

Equation 5 gives the full data likelihood for the CPT-
v model. We de(cid:12)ne the intermediate variables (cid:21)vmzn
and (cid:13)mzn in equations 6 and 7.

L((cid:18); (cid:12); (cid:22)j[y]obs; [r]) =

N

X

n=1

log

K

X

z=1

(cid:18)z

M

Y

m=1

(cid:13)mzn

(5)

(cid:21)vmzn = ((cid:14)(ymn; v)(cid:22)v)rmn (1 (cid:0) (cid:22)v)1(cid:0)rmn (cid:12)vmz

(6)

(cid:13)mzn =

V

X

v=1

(cid:21)vmzn

(7)

The posterior distribution over settings of the latent
variable Z is given in equation 8 using the intermediate
variables. Of course, the intractable, full posterior over
both ymis

n , and Zn is never needed during learning.

P (zjyobs

n ; rn) = (cid:30)zn =

m=1 (cid:13)mzn

(cid:18)z QM
z=1 (cid:18)z 0 QM

PK

m=1 (cid:13)mzn

(8)

Expectation maximization updates can now be found
by maximizing the expected complete log likelihood
with respect to the data model and selection model
parameters. We show the EM algorithm for the CPT-
v model in algorithm 1.

3.2 The LOGIT-v,mz Model

The CPT-v model makes the very strong assumption
that a single value-based selection e(cid:11)ect is responsible
for generating all missing data. We would like to allow
di(cid:11)erent e(cid:11)ects for di(cid:11)erent data items m, as well as
allowing the setting of the latent variable z to in(cid:13)u-
ence the missing data process. As a modeling choice of
intermediate complexity, we propose the LOGIT fam-
ily of selection models. The main feature of LOGIT

224models is the assumption that the selection model pa-
rameters (cid:22)vmz result from the interaction of multiple
lower dimensional factors.
In particular, these mod-
els allow all of v; m; z to in(cid:13)uence the probability of a
data element being missing, but constrain the e(cid:11)ects
to a particular functional family.

In the case of LOGIT-v,mz two factors are proposed.
One factor (cid:27)v models a value-based e(cid:11)ect, while the
other factor !mz models a joint element index/latent
variable e(cid:11)ect. This latter e(cid:11)ect can include factors
that are item-speci(cid:12)c (a given data item m can have its
own probability of being missing), and latent variable-
speci(cid:12)c (each mixture component z generates its own
pattern of missing data). The values of these factors
can be arbitrary real numbers and they are combined
to obtain the selection probabilities through the logis-
tic function as seen in equation 9. This parameteriza-
tion was selected because it is more (cid:13)exible than simple
factorizations, such as a product of Bernoulli probabil-
ities. Suppose a data set contains strong value-based
selection e(cid:11)ects for most data items, but the values for
one data items are always observed regardless of their
values. LOGIT-v,mz can account for this by setting
!mz to a large value. The logistic combination rule
then allows !mz to override (cid:27)v and produce a selection
probability of 1 for just this data item. In a product
of distributions decomposition this simply is not pos-
sible. As we will later see, this (cid:13)exibility is needed
for modeling \blockbuster" e(cid:11)ects in the collaborative
(cid:12)ltering domain.

(cid:22)vmz =

1

1 + exp(cid:0)((cid:27)v+!mz)

(9)

Given values for the selection model parameters (cid:27)v
and !mz, we can compute the complete set of selection
probability parameters (cid:22)vmz according to equation 9.
If we then rede(cid:12)ne the intermediate variable (cid:21)vmzn
according to equation 10, the full likelihood and the
posterior over the latent variable have exactly the same
form for the LOGIT-v,mz model as they do for the
CPT-v model.

(cid:21)vmzn = ((cid:14)(ymn; v)(cid:22)vmz)rmn (1 (cid:0) (cid:22)vmz)1(cid:0)rmn (cid:12)vmz

(10)
Unlike the CPT-v case, closed form selection model
parameter updates cannot be found for LOGIT-v,mz.
Instead, numerical optimization methods must be used
to adapt these parameters. We sketch a suitable EM
algorithm for the LOGIT-v,mz model in algorithm
2. Note that to ensure the full likelihood is non-
decreasing, line search must be used to determine ac-
ceptable step sizes (cid:11) at each iteration.

Algorithm 2 Expectation Maximization Algorithm
for the LOGIT-v,mz model

E-Step:
(cid:22)vmz  
(cid:21)vmzn   ((cid:14)(ymn; v)(cid:22)vmz)rmn (1 (cid:0) (cid:22)vmz)1(cid:0)rmn (cid:12)vmz

1+exp(cid:0)((cid:27)v +!mz )

1

m=1 (cid:13)mzn

m=1 (cid:13)mzn

z=1 (cid:30)zn

n=1 (cid:30)zn(cid:21)vmzn=(cid:13)mzn

n=1 (cid:30)zn

N

K

(cid:30)zn  

M-Step:

v=1 (cid:21)vmzn

(cid:13)mzn   PV
(cid:18)zn QM
PK
z=1 (cid:18)z 0 QM
(cid:18)z   PN
(cid:12)vmz   PN

PN
n=1 PK
PN
Xz=1

(cid:27)   (cid:27) (cid:0) (cid:11)(cid:27)

n=1 (cid:30)zn

!   ! (cid:0) (cid:11)!

Xn=1
Xn=1

N

(cid:30)zn

M

Xm=1

(cid:14)(ymn; v)(rmn (cid:0) (cid:22)vmz)

(cid:30)zn

V

Xv=1

(rmn (cid:0) (cid:22)vmz)

4 Synthetic Data Experiments

Our (cid:12)rst goal is to examine whether,
in situations
where the assumptions underlying them are satis(cid:12)ed,
the proposed models are able to recover both the un-
known selection mechanism and a correct model of the
data. To this end, we generated synthetic data sets
patterned after real data sets from the collaborative
(cid:12)ltering domain.

4.1 Generating Synthetic Data

We generate complete synthetic data sets according to
a hierarchical Bayesian procedure.
In particular, we
choose a K = 6 component multinomial mixture data
model with M =100 data variables, and V = 5 values
per variable. The mixture model parameters are sam-
pled from an appropriate length Dirichlet prior (uni-
form, strength two). We sample n=5000 data cases
from the mixture model to form a single, complete
data set.

To generate data that conforms to the CPT-v selection
model, we created several sets of selection parameters
and used these to sample the complete data. For the
purpose of these experiments we use a CPT-v selection
model with a special functional form that allows the
strength of the missing data e(cid:11)ect to be easily quanti-
(cid:12)ed. In particular we let (cid:22)v(s) = s(v (cid:0) 3) + 0:5, where
s is the parameter that controls the strength of the
e(cid:11)ect. Note that since the underlying data distribu-
tion is uniform across values, any choice of s in the
range 0 < s < 0:25 yields an overall observation rate
of 0:5. We create ten sets of observation probabilities
by evenly varying the parameter s from 0 to 0:225.

225l

i

)
e
u
a
v
|
g
n
s
s
m
(
p

i

1

0.8

0.6

0.4

0.2

0

s=0.000

s=0.025

s=0.050

s=0.075

s=0.100

s=0.125

s=0.150

s=0.175

s=0.200

s=0.225

1 2 3 4 5

1 2 3 4 5

1 2 3 4 5

1 2 3 4 5

1 2 3 4 5

1 2 3 4 5

1 2 3 4 5

1 2 3 4 5

1 2 3 4 5

1 2 3 4 5

Figure 2: Selection probabilities for the e(cid:11)ect (cid:22)v(s) = s(v (cid:0) 3) + 0:5. The parameter s controls the strength of
the missing data e(cid:11)ect. Here we show (cid:22)v(s) at ten equally spaced values on the interval 0 (cid:20) s (cid:20) 0:225.

r
o
r
r

E
e

 

l

t
u
o
s
b
A
 
n
a
e
M

1.4

1.3

1.2

1.1

1

0.9

0.8

0.7
0

Prediction Error vs Effect Strength

MM All
MM Train
Logit−vmz All
Logit−vmz Train
CPT−v All
CPT−v Train

0.05

0.15
0.1
Effect Strength

0.2

0.25

r
o
r
r

E
e

 

l

t
u
o
s
b
A
 
n
a
e
M

1.4

1.3

1.2

1.1

1

0.9

0.8

0.7
0

Prediction Error vs Effect Strength

MM All
MM Train
Logit−vmz All
Logit−vmz Train

0.05

0.15
0.1
Effect Strength

0.2

0.25

Figure 3: M AEAll and M AET r versus strength of
the CPT-v missing data e(cid:11)ect for the multinomial
mixture, CPT-v, and LOGIT-v,mz models.

Figure 4: M AEAll and M AET r versus strength of
the LOGIT-v,mz missing data e(cid:11)ect for the multi-
nomial mixture, and LOGIT-v,mz models.

The resulting parameters are shown in (cid:12)gure 2. These
ten sets of observation parameters were used to sample
ten di(cid:11)erent training sets from the complete data set.

To generate data that conforms to the LOGIT-v,mz
model we need to de(cid:12)ne the selection model param-
eters (cid:27)v and !mz. We create 10 di(cid:11)erent selection
models by setting:

(cid:27)v(s) = log((cid:22)v(s)=(1 (cid:0) (cid:22)v(s)))

!mz = log((cid:25)mz=(1 (cid:0) (cid:25)mz))

The (cid:25)mz values are sampled from a Beta prior. Note
that we have chosen these values so that when the lo-
gistic function is applied to (cid:27)v(s) the result is (cid:22)v(s),
and when it is applied to !mz the result is (cid:25)mz. We
compute the corresponding set of selection probabil-
ities (cid:22)vmz(s) and use these to sample ten di(cid:11)erent
training sets.

4.2 Experimental Procedure

The mixture of multinomials model, the CPT-v model,
and the LOGIT-v,mz model were trained until conver-
gence of their respective likelihood functions on all ten

of the CPT-v training sets, and all ten of the LOGIT-
v,mz training sets. After training, each model was
used to predict the complete data vector ^yn for each
data case n given the training set (observed) values for
that data case. We repeat this training and prediction
process three times with di(cid:11)erent initializations to ac-
count for local minima.

In order to judge the performance of each model under
increasing missing data e(cid:11)ect strength, we use the true
and predicted ratings to measure a quantity called the
mean absolute error (MAE), which is commonly used
as an error measure in the collaborative (cid:12)ltering do-
main. We measure the MAE restricted to the training
data as de(cid:12)ned in equation 11, as well as the MAE
computed over the complete data set as seen in equa-
tion 12. Note that on a real data set we have no choice
but to compute the MAE restricted to the observed
ratings, which corresponds to equation 11. If a given
model accurately learns both the data model and se-
lection model parameters for each setting of the e(cid:11)ect
strength s, the computed M AEAll values should be
approximately constant indicating little degradation
in performance.

226M AET r =

M AEAll =

1
N

N

M

X

n=1

X

m=1

1

N M

N

M

X

n=1

X

m=1

rmnjymn (cid:0) ^ymnj

m=1 rmn

PM
jymn (cid:0) ^ymnj

(11)

(12)

It is very important to note that under a non-ignorable
selection model, the value of M AET r as de(cid:12)ned by
equation 11 is a biased estimate of E[jy (cid:0) ^yj], were
we to sample items uniformly at random. Since the
selection model is non-ignorable and also unknown, it
is not possible to introduce a correction factor that
will allow for an unbiased estimate of E[jy (cid:0) ^yj] from
the training data alone. On the other hand, the value
of M AEAll as computed by equation 12 is unbiased
because it is computed from the complete set of true
ratings. However, such a complete set of ratings is not
currently available for real data sets.

4.3 Results

In (cid:12)gure 3 we show the results of the synthetic data
experiment with the CPT-v selection model e(cid:11)ect. At
s = 0, corresponding to the (cid:12)rst histogram in (cid:12)gure 2,
the selection e(cid:11)ect is constant across values v and is
thus ignorable. In this case we would expect M AET r
to be approximately equal to M AEAll.
In addition
we would expect all three models to achieve approxi-
mately the same prediction performance since all three
are based on an underlying multinomial mixture data
model. The experimental results we obtain at s = 0
are exactly in line with the theory.

As we increase s we would expect that the value
of M AEAll would increase for the multinomial mix-
ture model since its parameter estimates are based
only on the observed training data. Both the CPT-v
and LOGIT-v,mz models have the capacity to exactly
model this selection e(cid:11)ect. If these models learn ac-
curate data and selection model parameters then the
measured value of M AEAll should be approximately
constant. A further note is that LOGIT-v,mz actu-
ally has excess capacity when applied to the CPT-v
selection e(cid:11)ect data, so over (cid:12)tting may be an issue.

As we see in (cid:12)gure 3 the M AEAll curves follow ex-
actly the trends we have predicted for each of the
models. However, the M AET r curves exhibit an in-
teresting downward trend indicating that error on the
training set actually decreases as the missing data ef-
fect strength is increased. This is not unexpected in
the mixture of multinomials model since it is able to
concentrate more of its capacity on fewer rating val-
ues and thus achieve lower error on the training data.
CPT-v and LOGIT-v,mz exhibit a slight decrease in

error on the training set as the selection strength is in-
creased, but it is not accompanied by a corresponding
increase on the complete data set.

In (cid:12)gure 4 we show the results of the synthetic data ex-
periment with the LOGIT-v,mz selection e(cid:11)ect. The
most notable result of this experiment is the fact that
the learning procedure for the CPT-v model, algo-
rithm 1, converges to a \boundary solution" for the
(cid:22)v parameters for all values of the e(cid:11)ect strength s.
Speci(cid:12)cally, at convergence the (cid:22) values have the form
(cid:22)1 = c, (cid:22)j (cid:25) 1, where c re(cid:13)ects the global sparsity rate
and 2 (cid:20) j (cid:20) 5. This appears to indicate that the CPT-
v model lacks the capacity to model the LOGIT-v,mz
missing data e(cid:11)ect. This failure of the CPT-v model
may result from the presence of strong item-based ef-
fects in the LOGIT-v,mz data. For example, suppose
an item is always observed regardless of its value. The
only way CPT-v can explain this is by increasing the
values of (cid:22). Of course it cannot increase all the val-
ues of (cid:22) since it must still explain the fraction of data
that is missing. The most likely solution appears to be
exactly the boundary solution explained above. This
problem may also simply be a failure of the maximum
likelihood framework. We plan to explore a Bayesian
approach to prediction to determine if the problem
actually lies with the model, or the estimation and
prediction techniques.

The trends for the mixture of multinomials model are
quite similar to the previous case with similar explana-
tions applying. The trends for the LOGIT-v,mz model
are also similar to the previous case. One slight di(cid:11)er-
ence is that the M AEAll curve is more noisy and in-
creases somewhat with s. The most likely explanation
is an insu(cid:14)cient amount of training data to properly
estimate all the !mz parameters. The previous case is
easier for the LOGIT-v,mz model in this respect since
the CPT-v data contains no item or latent variable-
based e(cid:11)ects.

Perhaps the most important point illustrated by (cid:12)g-
ures 3 and 4 is that estimating the prediction error on
the observed data only can be an arbitrarily poor esti-
mate of the error on the complete data set in the pres-
ence of a non-ignorable missing data e(cid:11)ect. In both
graphs we see that the multinomial mixture model at-
tains the lowest error on the observed data, when in
fact its true error rate is the highest among the three
models.

5 Real Data Experiments

Unfortunately, the task of evaluating a method for un-
supervised learning in the presence of non-ignorable

227n
o

i
t
c
e
e
S

l

 
f

o

 
y
t
i
l
i

b
a
b
o
r
P

0.07

0.06

0.05

0.04

0.03

0.02

0.01

0

EachMovie Marginal Selection Probabilities

1

2

3

4

Rating Value

5

6

Figure 5: EachMovie marginal selection probabilities
P (r = 1jy = v). Computed under a learned LOGIT-
v,mz model from parameters (cid:27); !; (cid:12); (cid:18).

Figure 6: EachMovie Full Data Log Likelihood

Full Data Log Likelihood

LOGIT-v,mz

Multinomial Mixture

(cid:0)8:750368 (cid:2) 106
(cid:0)1:164895 (cid:2) 107

missing data on real data sets is problematic. Stan-
dard evaluation procedures involve measuring predic-
tion error on held out observed data. This hold-out
method entails an inherent bias in our case, as it is
only possible to evaluate predictions for items that are
not missing. That is, unlike the case for synthetic
data, evaluating MAEAll is impossible for real data. A
learning method based on the MAR assumption would
be expected to perform at least as well as one based
on MNAR on such a biased hold-out experiment: a
system can safely ignore any dependence of the item’s
response on missing values if it is never evaluated on
missing items.

We are currently considering a novel interactive data
gathering procedure designed to collect exactly the
type of data needed to validate the proposed models.
The main idea is to conduct an interactive, two stage
survey.
In the (cid:12)rst stage participants would be free
to select and rate any number of items they wished.
This data would then form the training set, and would
likely contain a strong non-ignorable missing data ef-
fect. In the second stage of the survey a di(cid:11)erent set of
items would be randomly selected for each participant
to rate. Ratings for these randomly sampled items
would then form the test set. While this might be dif-
(cid:12)cult for items like movies, it is quite simple for items
like music where a clip can be played if the partici-
pant is not familiar with a particular randomly chosen
item. Since the test data is a randomly chosen set of
items, evaluating prediction error on the test set gives

an unbiased estimate of the error on the whole data
set.

It is still interesting to observe what the proposed mod-
els learn on currently available real data sets, even if
this results can not be considered conclusive. We note
that not all currently available ratings-based collab-
orative (cid:12)ltering data can be used with the proposed
models. The key assumption is that users are free
to rate items at will. Any source of data where the
users are constrained to rate a sequence of items de-
termined solely by a recommender system violates this
assumption. In this case the proposed models would
essentially be learning the selection bias caused by the
recommender system attempting to predict items it
thinks the user will like. While this may actually be
an interesting method to test the e(cid:14)cacy of a recom-
mender system, it is not what we intend here.

We chose to apply the CPT-v and LOGIT-v,mz mod-
els to a well known collaborative (cid:12)ltering data set:
EachMovie. EachMovie is a collaborative (cid:12)ltering data
set collected from a movie recommender system op-
erated by the Compaq Systems Research Center.
It
contains about 1600 movies and 70000 users. Each-
Movie is well known to contain a \blockbuster" ef-
fect where several movies have been rated by almost
all users, while others are rated by just a few users.
EachMovie also contains a fairly strong user-based ef-
fect: the number of movies rated per user ranges from
one to several thousand. EachMovie is widely believed
to contain quite a substantial bias toward high rating
values. The underlying recommender system used to
collect the data also allowed for free user interaction,
which satis(cid:12)es our main requirement.

EachMovie appears too complicated for the CPT-v
model using maximum likelihood learning. As in the
synthetic LOGIT-v,mz experiment, CPT-v converges
to uninformative boundary solutions on EachMovie.
On the other hand, LOGIT-v,mz appears to converge
to parameter estimates that are in very good align-
ment with the e(cid:11)ects that are thought to occur in the
data set.

After convergence, we can examine the learned param-
eters (cid:27); !; (cid:12); (cid:18) and use them to compute the marginal
probability P (r = 1jy = v) as a summary of the
learned selection e(cid:11)ect (averaged across all items and
settings of the latent variable). We show the computed
marginal selection probabilities for EachMovie in (cid:12)g-
ure 5. This (cid:12)gure exhibits a de(cid:12)nite skew toward high
ratings values, although the dip at the highest rating
value is somewhat suspect.

While we cannot compute an unbiased estimator of the
expected mean absolute error for the data set, we can
compute another quantity that will allow us to com-

228stantially better than comparable models which do not
account for the missing data mechanism. Finally, we
have applied these models to a real world collaborative
(cid:12)ltering data set, EachMovie, obtaining initial results
that support several \folk beliefs" about the patterns
of missing data in this data set.

Acknowledgments

We thank Nathan Srebro for helpful comments and
discussions about missing data and collaborative (cid:12)l-
tering. His comments on an internal presentation of
this work were instrumental in revising this paper.
We thank Krisztina Filep for reviewing the (cid:12)nal draft.
Lastly, we thank the Compaq Computer Corporation
for the use of the EachMovie data set.

References

[1] K. Goldberg, T. Roeder, D. Gupta, and C. Perkins.
Eigentaste: A constant time collaborative (cid:12)lter-
ing algorithm.
Information Retrieval Journal,
4(2):133{151, July 2001.

[2] T. Hofmann. Learning What People (Don’t) Want.
In Proceedings of the European Conference on Ma-
chine Learning (ECML), 2001.

[3] R. J. A. Little and D. B. Rubin. Statistical analysis
with missing data. John Wiley & Sons, Inc., 1987.

[4] B. Marlin. Modeling user rating pro(cid:12)les for col-
laborative (cid:12)ltering.
In Proceedings of the Seven-
teenth Annual Conference on Neural Information
Processing Systems (NIPS-2003), 2003.

[5] B. Marlin. Collaborative (cid:12)ltering: A machine
learning perspective. Master’s thesis, University
of Toronto, January 2004.

[6] E. A. Ramalho and R. J. Smith. Discrete choice
models for nonignorable missing data. In Proceed-
ings of the Econometric Society Fifty-Seventy Eu-
ropean Meeting (ESEM’2002), 2002.

pare the LOGIT-v,mz model with a MAR multinomial
mixture model: the full data likelihood. The mixture
of multinomials model has no explicit selection model
and optimizes only an observed data likelihood as seen
in equation 1. However, as we see in equation 3 we can
obtain the full data likelihood from the observed data
likelihood by accounting for the likelihood of the re-
sponse indicators. If we suppose a simple MAR scheme
with a global observability parameter (cid:22), the log likeli-
hood of the complete set of response indicators is given
by log((cid:22))Pn Pm rmn + log(1 (cid:0) (cid:22))Pn Pm(1 (cid:0) rmn).
In this case the maximum likelihood estimator for (cid:22) is
simply (cid:22) = 1

NM Pn Pm rmn.

We show the full data likelihood values for the LOGIT-
v,mz model and the multinomial mixture model com-
puted for the EachMovie data set in (cid:12)gure 6. We see
that LOGIT-v,mz obtains a signi(cid:12)cantly higher full
data log likelihood value than the simple MAR multi-
nomial mixture model.

6 Extensions and Future Work

In addition to the research directions mentioned in the
previous sections, we are also considering extensions of
the proposed framework that will allow us to model a
wider range of missing data problems. In the original
framework, the binary response value Rm for an item
m is determined by the presence of a rating Ym for that
item. We might also decouple these two variables, and
allow a response to exist for an item (Rm = 1) when
the rating is not known. This situation often arises
in Web-based systems where we may have information
about many items a user has viewed, but a relatively
small number of ratings. Only minor changes are re-
quired to reformulate the proposed models to handle
this type of data.

7 Conclusions

In this paper, we have proposed several probabilistic
selection models which treat missing data as a system-
atic (non-ignorable) rather than random (ignorable)
e(cid:11)ect. Coupled with a basic discrete latent variable
model for user-item data, these selection mechanisms
allow us to model data sets in which known (or sus-
pected) response biases exist. We have derived e(cid:14)cient
learning and inference algorithms to jointly estimate
the data and selection model parameters in an unsu-
pervised way, and veri(cid:12)ed that these algorithms can
recover both the unknown selection model parameters
and the underlying data model parameters to a high
degree of accuracy under a wide variety of conditions.
We have also shown that when an unbiased estimate
of their performance is available, our models do sub-

229 
	
		  !

#M)

acef

acbd

3j4587B9I;F<46>?;@:AC.;F7(;FEHGI;2EKJG
L>MEHNB469FG2EO;QPk@:A+S,7BG2TMEH>MU:;F@B>

%hg%(-.-.i
C.467:;I;2VH4BW8SlX[ZB\8]6Z`_

mn'0#M)oqp

346587:92;2<=46>`;@BArs7:;2TM46<R7(;2EKJG
L>8EtN`49DGIEt;QPR@:AS7`GIT8Et>MUB;2@`>

C.4^7(;I;FVt4`WMSlX[Z`\M]6Z?_

S4GI;F7B9I;.PEH>`;F92@&&J
EH>MU>8@:;F7:;2EH@B>7:>8GI@`<=4j87`GIEKJA07BJ;DGEt>
G246J;FEt@`>À&W?4j&48>M4;FTM4VH467B92>8Et>MU5M92@`MVH4<ÈEt>GI4^J;2EH@B>É7:>8
EH>`;F92@&&J
4;FTM4>M4±@`&Q46J
;2EHNB4kEH>Ä,C&46J;FEt@`>8G=_&WÊs58924^GI46>`;
9F46G254^J;2EHNB46VtP7!UB9D7B&EH4>?;7:VHUB@`92Et;2T8<ËA@B9@B5&;FEt<=EHEH>MU!;2TM4J
9FEO
;24692EH@B>Ì7B>87q<=4
;FTM@&wA@B9GI46Vt4^J;FEt>MU;2TM47:<=@BM>?;k@BA9246UB&
VK7:9FEt^7(;2EH@B>cwÍ¨&54692EH<=4>?;F7BV924^GIMVt;FGR7B924!EH>GI4^J;2EH@B>ÏÎY7:>Ð\
J
@`>8J
VH8&4^G;2TM457:5~49^
}~z&{M|Õ=}ÕI®jxBz
{M¬n®

ÒÓÔ
v|}MØ

«Ö[×Æ«

¬z&|z&¯I¬

{¯

ß


é?ê

V¿

0è
ß

@8
'0-

ßà
àÈç

àôó

é?ê

²·>G25~46J;F9F7BV~JVtGQ;F49FEt>MUWB;FTM4M7(;D7EKGn7GI4;@BAÙD¤ÛÚ¤ÛÜt¡:Ý¤ÛÞ*¤0£
Ù

GF7(;2EKGIAP?EH>MU
ÁMW4;Qn464>s587BEt9DG@BA5@`Et>?;FGâDã¿äkEt>l7
2á
TM4=<R7(;F92Et¨,
G24
;åRWæ
EHGJ67:VHVt4^Y;2TM4
åæ
Ù¤ÛÚ¤ÛÜH¡(Ý¤ÛÞ¿ëÚ=¡:Þ*Ý¤Oì`S4&4>8@:;24.P
]^ö
åcï(ð?ñ^âFò
sî
;2T84Y÷(ø(Üù&ÚR£@:A>8@.M4kâRú°åû7:>8.P,íü7l&EK7:U`@B>87BV<R7(;F92Et¨
ãIâRú°åR,TM4kN`@BVHM<=4k@:A7YGI4;ý¦þÿåEKG
A@B9F<=46qEt;2TÐí
å+ï(ðý
U4=7BGFGIM<=4;2T87:;>M@!>M@&&4=T87BG
S[
à 
é
NB@`Vt8<4Á8
d
f
-%(#M)i
rs7:>.Pl5892@`5469I;FEt4^G@:AGI5~46J
;29D7:V
#M/
	
J
VH8GI;24692EH>MU7:9F44VH4U?7:>?;2VHP4¨&5M924^G2G246EH>=;24692<RG@BA~;FTM4jGI;2@&JDT87`GQ
;2EKJÞ*ÝF¡(¥MÙ¤ÛÞ¿¤0ø(¥YÚ=¡:Þ*Ý¤OìÇ@B&;D7:EH>M46.PR>M@B9F<R7:VHEt6Et>8U;FTM492@(G
@:A;2@RGI8<Æ;2@]`
ÀBö
í
@B9ß
(í=
TMEKG<R7(;F92Et¨J67:>!4N?EH446!7`G&4
>MEt>8U7Rrs7:9F´B@(NR9D7:>8M@B<
7:VH´@(N`49åRWß=46Et>MU;2T84Þ¿Ý2¡:¥MÙ¤ÛÞ*¤0ø:¥¢~Ý2øD¡¤ÛÜ¤ÛÞ*ë&¼
â
äæ
â¿Å³TM44EHUB46>.Nh7BVt846G@BAÈ7B924]
à 
á!"á$#%#&#~á!('lá
]7:>y;2TM4J@B9F924^GI5~@B>&Et>8Un46EtU`4>.NB4^J;2@`9FG7B924*
,+@B;24
EKGG2P.<<=4;29FEHJBW&;2TM44EHUB4>.N(7:VHM4^G@:A
;2T7(;~46J67:8G24
7:9F4924^7:VM7B>8;FTM44EHUB46>.NB46J
;2@`9FGVHEt>M4^7:9FVtPEt>8M45~4>8&46>?;6348>M4
0é?ê
:å+ï(ðå
sà
.¶7:>8,;FT.8G;FT87(;.EKG7
²³;=EHG467`GIPY;2@YNB49FEtAPl;FT87(;/0.
ÙÞ³¡:Þ*¤0ø:¥~¡:Ýë21(¤KÙÞ¿Ý¤

ù&Þ¿¤0ø(¥@:A;FTM4Yrs7B92´`@(NJDT87BEt>c43M@`97G24
;
ýµþ
å+ï(ð:ý7Båcï(ð¿åÿ;2TM4R5M9F@B7:MEHVtEt;QP
åWc4&4>M@B;24=.P5.6
@:Aý°M>8&469;2T84GQ;D7(;2EH@B>7:9FP&EHGI;29FEHM&;2EH@B>c

#&#%#

í-

.P

346587:92;2<=4>?;@BAC?;D7(;FEHGI;2EKJG
L>MEHNB49DG2EO;QPR@BAS,7BG2TMEH>MU:;F@B>

"$#&%('*)+#,"$-.'0/21
C&467(;2;2VH4BWMSYX[ZB\M]^Z`_

uwvyx`z.{8|}~z

C.54^J;F9F7BVJ
VH8GI;24692EH>MU[EKG7;F46JDTM>MEK?M4A@`98>8MEt>MU
UB9F@BM58GyEH>87(;F7!J@B>8G2EHGI;2EH>MU@:AGIEH<=EtVK7:9FEt;2EH46G=~4

;Qn464>R587BEt9DG@BA5@`Et>?;FG6SY4y7:5M5892@?7BJDT;2TM4y5M9F@BMVH4<
@:AVH467B92>MEH>MU;2TM4=G2Et<=EHVH7B92Et;QPs7BGy7A8>8J;FEt@`>Y@BAn@:;FTM49
@B8G249FNB4^!A467:;2M9F46G6WEt>Y@B9D&49j;2@@B5&;FEt<=EH4RG254^J;29D7:V
J
VH8GQ;F49FEt>8U9F46G2MVO;DG@B>AM;2M9F4M7(;D7M+T8EHG587B5469+A@`9I
<MVK7(;F46G7R>84@B&Q4^J;FEtN`4A@B9VH467B92>8Et>MU=EH>lG254^J;29D7:V
J
VH8GQ;F49FEt>8U8W;2T87:;87:VK7:>J
46Gk7qJ
VH8GQ;F49FEt>8U7BJJM9D7BJ
P
;249F<!W:;FTM4j ?¡F¢~W&7B>8=7GQ;D7:MEHVtEt;QP;F49F<!W:;2T84£
¤O ?£¥? ?¡F¢
EO;FT;2T84VK7(;F49EH>;FTM492@`Vt4@BAj7s9F4U`MVK7:9FEt649^sSY4
&49FEtN`47B>7:VHUB@`92Et;2TM<¦;F@Y@`5&;2EH<=Et64k;FTMEHG@`&Q46J
;2EHNB4BW
7:>8G24<=EH7B&;2@`<R7(;2EKJ<=4
;FTM@&MG;F@JDTM@`G24;2TM4@`5&;2EH<R7:V
9246UBMVK7:9FEt^7(;FEt@`>§9F4VHEt<=EH>87:9FP4
¨&5~49FEt<=4>?;DGJ@B>&92<
;2TM4N(7:VHEK&EO;QPk@:A;2TM47B5M5M9F@`7BJDTc
ª`«

z&{M¬­®j}~zM¯Q¬

ST8EtVH4=;2TM46924=T87`G464>,<JDTY5M9F@BU`924^G2GjEH>@`&;F7BEt>8Et>MU!~4
;2;249
G25~46J;F9F7BVJ
VH8GQ;F49FEt>8U`GEO;FTG2EH<EHVK7:9FEO;FEt4^GUBEHNB4>@B9J
@`>8GI;29F8J;F46
.PyT87:>W^;2TM4n5M92@`MVH4<°@:AM7:&;F@B<R7(;FEHJ67:VHVtPj46GI;2EH<R7(;2EH>MU;2TM4G2EH<
EHVK7:9FEO;FEt4^GA9F@B<±M7:;F7T7BGn924^J
4EHNB4^=Vt4^G2G7(;2;246>`;FEt@`>TMEKGnVHEH<Et;FG
;FTM47:585MVtEKJ7:;2EH@B>@:AGI5~46J
;29D7:VJ
VH8GI;24692EH>MU;2@=;2T847BMEHVtEt;QP@:A;2T84
M@B<R7:EH>4
¨&5~492;FGk;2@U`M46GFG=;FTM4J@B9F924^J;RA4^7(;28924^Gk7:>w;2TM46Et9
@`5&;2EH<R7:VJ@B<8Et>87:;2EH@B>A@`9467`JDTl5M9F@BMVH4<!²³;<R7B´B46Gj;FTM4=924
G2MVt;FG@:A;2T84J
VH8GI;24692EH>MU7:VHUB@`92Et;2T8<µG24>8G2Et;2EHNB4;F@R;2TM4587:92;2EKJ
M
VK7:9AM>J;2EH@B>RJDTM@?GI46>r@B9F4@(N`49^W6Et;UB@.46G7BU`7BEt>8GI;;2TM4U`9F7BEt>@:A
<R7B>?P=G28JJ46GFGQAMV~7:5M5892@?7BJDTM4^GEt>k<=7`JDTMEH>M4VH467:9F>MEH>MU8W?TMEKJDTREHG
;F@J@B>8G2EHM497VH7B92U`4>?8<~49@:A5~@`GFGIEHMVHPEH929F4VH4N(7B>`;A467(;FM9F46G6W
Et;2T8Et>,79246UBMVK7:9FEt646G24
;2;2EH>MU;2T87:;VH4
;DGy;2TM4RM7:;F7GI46Vt4^J;;2T84
A46¶9F4VH4N(7B>`;@`>M46G6
r4EHV³¾
77B>8!C.TME¿WÀ:Á`ÁM]67.W
²·>¸J
@`>?;29D7BGI;¹;F@º589246N?EH@BG»n@`92´½¼
Â7`JDT7B>8Ã`@B9DM7B>WMÀ:ÁBÁBÄhÅ¿W8TM49F4y;2TM4A@&J
G7`G@B>!&4
>MEt>8U
7?87BVtEt;QPYJ92Et;24692EH@B>Y;2@~4@`5&;2EH<=Et646,
96
;;2TM4k587:9D7:<=4
;F49DG
@`>!;29D7:EH>MEH>MUM7:;F78WTM46924n4;F7:´`47:>s7B5M5M9F@`7`JDT!JVt@?GI469;F@;2T84
5892EH>8J
EH5MVH46Gj7:~@(NB4BS4M4
8>M47:>s@`&Q46J
;2EHNB4;FT87(;y87:VK7:>J
46G7
;F49F<ÆA@`9jJ
VH8GI;24692EH>MUR7BJ6J
M9D7BJP@B>!;F9F7BEt>MEH>MURM7:;F7REt;2Ts7RGI;F7:
8EtVHEO;QP;F49F<±TMEHJDT7BJ;DGn7`G79246UBMVK7:9FEt649^cSTMEHVH4;FTMEHGG24
;I;FEt>8U
EKGJ
@`<=<@`>;2@<R7:>.P5M9F@BMVH4<RG6W(;2T84GI5~46JEOJA@`92<Ç@:A~;2TM4;Q@
;F49F<RGEHG57:92;2EKJ
MVK7:9;2@RG254^J;F9F7BVJ
VH8GQ;F49FEt>8U8

230#
b
©
«
Ñ
Ô
«
|
«
­
Ö
«
­
W

à
¼

Å
í

õ

í


e


à
à
õ

)

ã
*
'
à
¼
.

Å
.
í

à
à

éa
.

àpo

.~jß

ýã`_ö

)X$J
VH8GI;249FEH>MU<;
g/::%('g^-?%h'
ã=?>ò
ñ=
-s"4859
#&#%#
Et>?;2@È;FTM4$&EKGQ
EKGÌ&48>M4^µ7`G7È587:92;2Et;2EH@B>µ@:A;2T84ÇGI4;Ïå
ã=
TM4[Úù&ÜÞ¿¤A@¡(ë[¥ø(ÝCB
G24
;FG2=
Q@`Et>?;>8@B>M46<5M;QP
#%#&#
ÚR¡(ÜO¤ED6£F1HGù&ÞJILKNMNOù&ÞQPJVtGQ;F49FEt>MUJ
9FEt;249FEH@B>ÿ¼
r4EHV³¾
7MWÀBÁBÁ`À?W
R7B>8C&TME*WÀ:Á`ÁBÉ^Å
=7VW
ã^=
XCZ
É?ö
;ö
SUT7=7VW
å+ï(ð=
XCZ\[
Y]X
XCY
T849F4
Ä.ö

=7VW
é

éa
T84&48>MEt;2EH@B>@:A6STb=7V6WEHG~46GI;<=@B;2EHNh7:;24^.P;2TM4rs7B92´`@(N
ýcd_æ
&¼
9D7:>&@B<Ë7:VH´sN.EH4k3j4
8>84N,a
ýÅn7`G;2T84
;F@
5892@`87:MEHVHEO;QP@:A;2TM49F7B>8&@`<ÿ7:VH´kUB@`Et>8U=A92@`<µG24
;jýfeÏå
G24
;g_heå$EH>@`>M4GQ;F45kEtAc;FTM4J
M9F9F4>?;GI;F7:;24yEHGEH>ý7:>R;2T84
9D7:>&@B<Æ7:VH´REKGEt>!Et;FGGI;F7:;2EH@B>87B92P&EKGI;29FEtMM;2EH@B>.
ß
ýã`_ö
=7VW

éa
0éè
0éè
ia
å+ï(ð(ý
å+ï(ð:ý
_`ö
²³;A@BVHVH@(Gc;FT87(;;2T84<MVt;2EH7hP>M@`92<R7:VHEH46J
&;9F45M9F46G24>?;FGc;2T84
G2M<±@BA;2TM4k2@B&;2¿@BAÛ³JVt8GI;2469^l;29D7:>8G2EO;FEt@`>5M9F@B87BMEHVtEt;2EH46G7(;;2T84
JVtGQ;F49VH4NB46V*
Ê?ö
imrnCm6n
;cö
SUTb=7V6W
im6nCm
XqY
X[
Y]X
XCY
;cöEHGG2<R7:VHVA@B97J492;F7BEt>s57:92;2Et;2EH@B>s;W;FTM4>Y;2T84
²³AgSUTb=7V6W
W(@`>8J
4;FTM47BVt´EKGEt>EO;^W:EKGG2<R7:VHV*
5892@`87:MEHVHEO;FEt4^G+@BA84N(7`&Et>8U=
7MW8ÀBÁBÁ`À6ÅEO;EHGGITM@(>Y;2T7(;;FTM4tSUT7=7VW
²·>Ì¼
;öA@B97B>?P
r46EtV³¾
JVtGQ;F49FEt>MU7;kEKGVH@(n469@`M>8&4^.P7A8>8J;FEt@`>@BA;FTM4>.M<~49
@BAJVt8GI;2469FG
;æ.7B>8@:A;2TM446EtU`4>.N(7:VHM46G@:Au
oûà
ÎBö
ö
SUT7=7VW
;ö
ávo
XCY
S4RJ7BVtV+;2TM4=>M@`>&³>M4U?7(;2EHNB4&EEw~469246>8J
44;Qn464>l;2TM4NSUT7=7VW
7B>8EO;DGVt@(49~@BM>k;FTM4 ?¡F¢6u
\?ö
;cö
SUT7=7VW
;ö
oc~
xzy|{}
7MWÀBÁBÁ?À6Å;FT87(;=;FTM4!U`7:5EHGRÁYEEw!ËT87`G
>84J67:>G2TM@(û¼
r46EtV³¾
96

;;W
¢¤0£FGF£&@¤KÙ£GFø:¥MÙÞ·¡(¥8Þ£
¤O ?£¥8÷(£^GÞ·ø(ÝDÙNI
7O],P*
T84>M46NB49âDã¿ä7:9F4nEH>;FTM4GF7:<=4
A@B97BVtV(t
;FT87(;EKG*
JVtGQ;F49^
{8¬vjÕ
Ô]
«ÖÇÓ
Ô
W(A@`9TMEHJDT;2T84
S47BGFGI8<4n;2T7(;n4T87hN`47yM7(;D7jG24
;@BA~G2Et64
J@B9F924^J;J
VH8GI;249FEH>MU7;]nEKGU`EtN`4>i3M@B94^7BJDT587:EH9@:AM7(;D7y5@`Et>?;FG
âDã³äEt>k;2TM4M7:;F7G24
;4y7BVHG2@<=4^7BG2M924y7G24
;@:AcA467(;FM9F46G6T84
y·&EH<=4>8G2Et@`>87:VN`46J
;2@B9@BAcA467:;2M9F46GEKG&46>M@:;F46.P
Z?ö
#&#%#
ßFè
2A@B97:VHV+âDã³ä8
T84A4^7(;28924^Gj7B924RÙë(ÚÚ=£Þ¿Ý¤
G
W;FT87(;EHG
S47:VKGI@7`G2G2M<=4A@`9+>8@(,;2T87:;+;FTM4A4^7(;FM924^G+7B924n>M@B>M¿>M46U`7:;2EHNB4

#&#%#

ö

2è
ß

Ìà

XCY

|{

2è

ö

]Bã

]`W



#%#&#

à$

' z'

Á8ã

úU
^

9F45M9F4

[7:>8=;FT87(;7:>kEt>8J924^7BG24EH>
2è
2è
G24>?;FG+7&4^J
9F467BG24EH>;2TM4GIEH<=EtVK7:9FEt;QP~4
;Q44>â~7B>8ä
>M4J7B>
;2T8Et>M´@:A~;2T84M7(;D75@`Et>?;DG7BGN`46J
;2@B9DGEH>=G2@B<=4y·&EH<46>8G2Et@`>87:V
G2587BJ4BWEt;2TÐ;FTM4!A467:;2M9F46G=9F45M9F46G24>?;FEt>MU&EKGQ;D7:>8J46G=~4
;Q44>
5~@BEH>`;DG+7BVt@`>MU;FTM4?J@.@B9D&Et>7(;247(¨&46G6
M9+A@B9F<8VH7:;2EH@B>TM@(
4N`49EKGG2EHUB>MEtJ7B>?;2VHPk<=@B9F4UB46>M49D7:V¿WMEH>!;2T87:;EO;7BJ6J
@B<=@&M7:;246G
&EKG2G2EH<EHVK7:9FEO;QPA467:;2M9F46G;2T87:;M@k>M@B;yJ
@`<=4A9F@B<7kÍ8J
VHEHMEH7B>
G2587BJ4y9F458924^GI46>`;D7(;FEt@`>k@:A+;2TM487(;F78
TM4wÙ¤ÛÚ¤ÛÜt¡(Ý¤ÛÞ¿ëqEHG7B>
7:VH<=@`GI;4NB4692P.TM46924hökMEQw49F4>?;2EK7:8Vt4
EH>?;2@7
AM>8J
;2EH@B>
öEt;2T
>M@`>&¿>84U`7:;2EHNB4GFJ7BVH7B9G2Et<=EHVH7B92Et;QP
úU

ö;FT87(;n<=7B58G7A467(;FM9F4NB4^J;2@`9
]`
4B
U
]`
7NB46J
;2@`9@:A+57:9D7:<=4
;F49DG4;
öµA@`9âDã¿ä

ß
]Bã
]6Á`ö
#&#%#Qç
' ¡' 
ú
è
ß6ÅK0è
]B]^ö
ú
]^ÀBö
0è
ß
è
`
¢46924`W;2TM4lVt4;I;2469È&46>M@:;F46Gk@B;2Tw;2T84lGIEH<=EtVK7:9FEt;QPAM>J;2EH@B>
öA@B98¨.4^sM7:;F7G24
;
öW7:>8;2TM4kÙD¤ÛÚ¤ÛÜt¡:Ý¤ÛÞ*ë!ÚR¡(Þ¿Ý¤Oì
]
7:>8l587:9D7:<=4
;F49yNB4^J;2@`9
TM4<=7:;29FEHJ46Gy@BM;F7:EH>M4^A9F@B<
À`ö7:9F4j9F46G254^J;FEtN`4VHPk&4>8@:;24^!í
ö.P
ö
ã(
S4R7B>`;;F@!Vt4^7:9F>Y;FTM4R@B5M;2EH<=7BV587B9F7B<4;2469FG
@:A;2TM4G2EH<Et
VK7:9FEO;QPAM>8J
;2EH@B>A9F@B<»7R;F9F7BEt>MEH>MUG24
;yEt>8JVt&Et>8Uk@B>84@B9j<@`924
M7:;F7G24
;DG;F@BUB4;2TM469Et;2T;FTM4EH9nJ@B9F924^J;JVt8GI;24692EH>MU?G3M@`9nG2Et<
5MVHEHJEO;QP`W47BGFGIM<=4;2T87:;Rn4T87hNB4@B>84M7:;F7,G24
;R&46GFJ
9FEt~46
;2@`UB4
;FTM49jEO;FTsEt;FGJ@B9F924^J;JVt8GI;24692EH>MU;,
.Pk;FTM4A4^7(;FM924^G
J
VH8GI;249DG6T84U`4>M469F7BVtEH67:;2EH@B>!;2@<=@B9F4;FT87:>@B>M4
T87hN.EH>MU
M7:;F7=GI4;EHGEH<=<=46&EK7(;F4B
7`G5M9F@B5~@`G246ÈEH>
TMEKG5892@`MVt46<
77B>8!C.TME¿WÀ:Á`ÁM]67^Å
r4EHV³¾
;2T849F4BW;FTM47:&;FTM@B9DGyEt>?;F92@&&8J47;D7:9FUB4;£T87hN.Et>MUs¤

Á=@B;2TM4692EKGI4`TM4
EtAâDã³äR7:9F4Et>;FTM4GF7:<=4J
VH8GQ;F497B>8¤

587B9F7B<4;2469FGn7:9F4;2T84>k@`5&;2EH<=Et646k?P=<R7:´.EH>MU
ön<R7(;DJDT¤
EH>75¥³MEtN`49FUB4>J
4G24>8G24;FT87(;=924&¦846J
;FG;2TM49D7:>8&@`<
7:VH´
EH>`;F49F5M9F4
;F7:;2EH@B>Ì@BA;FTM4qGIEH<=EtVK7:9FEO;QPw<R7(;F92Et¨ÿTMEKG!7:5M5M9F@`7`JDT
@B9F´B46ln46VtV@`>YEH<R7:U`4=G24U`<=4>?;F7:;2EH@B>Y87(;F78WM&;EKG>M@B;7:5&
5M9F@B5M9FEK7(;24A@`9UB46>M49D7:VM58M925~@`G24VH467:9F>MEH>MU8i3M@`97:>.PJVtGQ;F49FEt>MU
;2T849F4yJ67:>k~47:>kEH>&8>8EO;QPR@BA,<R7(;F92EKJ
4^Gn;2T87:;7B924j5469IA4^J;A@B9
;2T7(;J
VH8GI;249FEH>MU8Ð²·<=5@?GIEH>MUq7Y;F7:9FUB4;R£@:Ay7B>.P,A@B9F<
EtVHV
@(NB469FJ@B>8GI;29D7:EH>;2TM45M9F@BMVH4<7:>EHGj46?MEHN(7:VH4>?;;F@kEH>?;29F@.M8J
EH>MU7yMEH7`GWBTMEHJDT=<R7hP@`9<=7hP>M@:;M;;FTM45M9F@BMVH4<
7(;T87B>8
²·>!¼
Â7BJDT!7:>Ã`@B9DM7:>cW&ÀBÁBÁBÄhÅ87:>=7:>MU`Vt44;Qn464>=GI88GI57BJ
4^GcEKG
8G2467`Gn7J
9FEO;F49FEt@`>=A@B9Vt4^7:9F>MEt>8U;2TM4j587:9D7:<=4;249DG@BAcGI5~46J
;29D7:V
J
VH8GI;24692EH>MU8WB;2T.8GMEHG2546>8G2Et>MUEt;2T=;FTM4;D7:9FUB4
;¤:TMEKG7:>MU`Vt4
EKG<=Et>MEH<=Et646=TM46>/
öT87`G§?§ÍYA@`9;2TM4U`EtN`4>=J
VH8GI;249FEH>MU8
5&;FEt<=EHEH>MU;2T8EHGnJ
9FEO;F49FEt@`>EKGMEQ¨J
8VO;Et>R5M9D7BJ
;2EKJ
4MM4;2@;2TM4
>M4646;2@,&EQw49F4>?;FEH7:;24!7sAM>J;2EH@B>Ð@:A;2TM4!4EHUB46>.NB46J
;2@`9FG@:Ay7
<R7(;F92Et¨k
;;2TM4<R7:;29FEO¨k46Vt46<=4>?;FG6
¢46924`W.n4y7BM&9F46GFGVH467B92>8Et>MU?PR4¨&5MVtEKJ
Et;2VHP=4>&A@`9FJEt>8U;2T7(;;2TM4
VH467:9F>M4^57:9D7:<=4
;F49DGEt>&8J
4j7UB@.@&=J
VH8GQ;F49FEt>8U@B>;2T84;29D7:EH>&
ãz;,öTMEHVt4©kI4
¨.;F9F7`J;2EH>MU7`GVHEO;2;2VH4YEH>&A@B9F<R7(;FEt@`>
EH>MUM7:;F7
A9F@B<
;2TM4y;F9F7BEt>MEHU87(;F77BGn5@?G2G2EHMVt4|l7`GEHVtV~4GITM@(>kEt>k;2TM4
>M4¨?;G246J
;2EH@B>

96

231
e
b
f
à

ã

ã
>

õ
à
>
ó

ó
õ
=
X
ö
X
õ
õ
à
ó
ó
õ
à
à
 
à
 
à
õ
õ
õ
à
>
ó

ó
Z
n
Z
)
>
ó

õ
õ
X
õ
æ
õ
)
>
ó


X
õ
õ
õ
à
õ
)
>
ó


X
õ
õ


ã
*
>
X

à
*
X

o

Õ
Ô
«
¯
ç

¼



"


Å
0
õ

à



á
à



õ
õ


õ
õ
ö


à

õ

à
õ

à
¼


Y

'

õ

õ

ö
î

õ
ö
î
¼

Å

Y

'
õ

õ
õ




õ

õ
õ

õ



o
¼

à
]
à
õ

õ


õ

b+d

f¯

f6¯
ö2ö

}~z&¯\¬
¬v«
Ô
­b
g6-?%('0)o²·>;FTM4J
@`>?;24
¨.;c@BA.G25~46J
#8/0'gF®
-g^#&%(o-?gg:B/
;F9F7BVJ
VH8GQ;F49FEt>8U8W4J67:>ÐG27:;2EKGQAP,;FTM489FGI;=@:A;FTM47:~@(NB4924
?MEH9F4<=4>?;FGn.P=4>&A@`9FJEt>MU;2TM4?87:VHEt;QP@BA;2TM4j;29FM4J
VH8GI;249FEH>MU
ö
TM4?87BVtEt;QPq@:Ay7lJ
VH8GI;24692EH>MU,J7:>4!<=467:
;R
96
;,k
G2M9F46k?PR46EO;FTM49Et;FGSUT7=7VW@B9EO;DGU`7:5ci38@B97U`EtN`4><=7:;29FEO¨
W`7J
VH8GI;24692EH>MUy;2T87:;<=Et>8Et<=EH46G;2TM49FGI;7:VKGI@<=EH>MEt<=EH4^G;2T84
G246J@B>8WG2@q;FTM4YJ92Et;24692EK7q7:9F446?MEHN(7:VH4>?;6H¢@(n46NB49^WEOA@B>84
ÜH£F¡:Ý¥MÙW;FTM4>;2T84J
9FEO;F49FEH7!7:9F4=>M@:;4^?MEtN(7BVt46>`;|u@B&;D7:EH>MEH>MU
7kGI<R7:VHViSTb=7V6WEH<=5MVHEt4^G;FT87(;j;2TM4@°w~³&EK7:U`@B>87BVMVH@.JD´&G@:A
7B924>M467B92VHPÁMWnTMEHVt4!7YG2<R7:VHVU`7B5&@.46G=>M@B;=J67:9F92PqG28JDT7B>
EH<=5MVHEHJ67(;2EH@B>cN¢4>J
4BWc;2TM4RU?7:5Y5M&;FGA449J
@`>8GI;29D7:EH>`;DGy@B>
T8EtVH4jGI;2EHVtV~~4EH>MU7B>REt>&EHJ67(;F@B9@:Ac7U`@?@&JVtGQ;F49FEt>MUW?7B>8=4
JDT8@?@?GI4yEt;7BG7=J
9FEO;F49FEt@`>@BAJVt8GI;24692EH>MUR?87:VHEt;QPB
b+d&³
#M/:B/
±g6'
-=-.'0o~-.)+o~#z±Y#8)+iYg
g^#z²'*/0'0g^®
g^-?%h'*)+o,+@46>&A@B9DJ
4;2TM4RG246J@B>89F46?MEH9F4<=4>?;6W4EHVHV<=7:¨.
ö2ö+@
>g·
EH<=Et64k;FTM44EHUB4>8U`7:52´µ>
à¶
<=@B;2EHNh7:;24;2TMEKGJDTM@BEKJ
4`W@B>M4=J7B>l9F46J7BVtV+;2T84A07`J;;2T87:;7VK7:9FUB4
46EtU`4>MU?7:5Et>¸¹<R7:´`46G;FTM4kG2M8G2587BJ4=G2587B>M>M46,.Ps*
#%#&#
GI;F7BMVH4R;2@s5~492;289287:;2EH@B>8G6!TM4RA@BVHVH@(Et>MU9F46G2MVt;6W5M9F@(NB46EH>
;FTM47B5M546>8&Et¨W?U`EtN`46G7MEt9F46J
;9246VH7:;2EH@B>8G2TMEH5R4;Qn464>G254^J;F9F7BV
JVtGQ;F49FEt>MUR7B>8;FTM44EHUB46>MU`7B5
;¹¿æ
38@B9R;Q@qJ
VH8GI;249FEH>MU`G=Et;2TÇæ
;æ
4s&4
>M4;2T84
àºo
MEHGI;F7B>8J
4@:Ai;Y7B>8N;¹.P
å+ï(ðj=
=¹
Xg½
]6É?ö
;ã\;
å+ï(ðj=
å+ï(ðj=
m6nhé°¼
&EKGQ;D7:>8J4ÿEKG
T8EHG
ÁMWH]
Å³WM&;ÈEHG
G2P.<<=4;29FEHJBWÌ9F7B>MUB4^G$EH>
>8@:;q7Ì<=4
;F92EKJ:¾+@:;24;2T7(;
;ã\;¹tölEKG§4^7:92
c7B>8J7`GQ;F49^W]6ZBÊ`Z^Å´.>M@(>ûEt>¦GQ;D7(;2EKGI
AM>8J;FEt@`>WÏ¼
G©À
G2@B>]¿
<=467BG2M9F4¹@BA°&46587:92;28924µA9F@B<
EH>8&45~4>&4>8J4B
;FEHJ6G±7BG±7
T84Ë&EHGI;F7B>8J
4
J
9FEO;F49FEt@`>ü5892@B
EHGÿ46?MEHN(7:VH4>?;ÆEO;FT
¢M~492;7:>8!X9D7:8Et4`W]6ZB\?_6Å¿WlEO;FT¹;FTM4<=@.MEOM
5~@`G246¹.PË¼
J67(;FEt@`>;2T87:;°4^7BJDTû87(;F7ÿ5@`Et>?;EHG¶4EHUBT?;24^.PµEt;FG°N`@BVt
8<4,í=QÆTM4M>.4EHUBT?;24^
&EKGQ;D7:>8J4l7BG7:VKGI@8GI4^ÌEH>
Â7BJDT!7:>8Ã`@B9DM7:>WMÀBÁBÁ:ÄhÅ³
ÂÁ©Ã
BÅ@¡(ëcGÜù.ÙÞ·£
Ý¤Û¥. (Ù @¤ÛÞAÆ
£Þ;ã\;¹ÄD£$Þj@ø
%h-
;ã;¹KöÉÂÎ`Ï
;ö
ã
;¹töÈÇµÉÊ´<>Ë/ÌrÆM£¥¡Í
àÓÒ
xzy|{
xy|{
ÐÑ
BÅ@¡:ëNG
Üù.ÙÞ·£
Ý¤Û¥. /@¤ÛÞÖÆ
/*/0#&%®ÕÔ
£
Þ];ÊD£¡
;cö£
xzy|{
7:9FUB<=EH>
ÇÉH´
¡(¥r1µ;,
SUT7=7VW
;¹tö&ËØÌrÆM£¥
;ã\;,6öÉ
²·>n@`9FMG6W6;2TM47:~@(NB4;2T84@B9F4<7:>EO;DG+J@B9F@BVHVH7B92PG2TM@(;2T7(;6W(EtA
48>87JVtGQ;F49FEt>MUEt;2T7GI<R7:VHV:46>M@BMU`TU`7:59F4VK7(;FEtN`4+;F@;2T84
46EtU`4>MU?7:5W6;2T84>;FT87(;J
VH8GI;249FEH>MUEKG+7BVHG2@Nk2GI;F7BMVH4%lMW^EH>;2TM4G24>8G24
;FT87(;7:>.P@B;2TM469JVtGQ;F49FEt>MUEO;FTG2<R7:VHVU`7:5lEtVHV>M46J46GFG27B92EHVHP
9^
;;F@
~4J
VH@`G24j;2@=EO;^²³Ac;FTM44EHUB46>MU`7B5kEKGG2z¨J
EH4>?;2VHPVK7:9FUB4y
;FTM4R~46GI;7(;I;D7:EH>87:8Vt4RU?7:5W;FTM4>;FTM49F4REHG46GFGI46>`;FEH7BV7!M>MEK`84
7hP,@:Ay@B&;D7:EH>MEt>8U7UB@.@&57:92;2Et;2EH@B>EH>;2T87:;/=ÐX>.Pq;Q@
57:92;2Et;2EH@B>8GEt;2T7G2<R7:VHVMU`7B5T87hN`4;2@~4J
VH@`G24;2@467`JDT=@:;2T849^
-/0-.#&%()+'*)+oU:B%('g6-?%('
)+@(Ðn4M4
8>M4jVt4^7:9F>MEH>MUEt>G25~46J

é°¼

;29D7:V~J
VH8GI;249FEH>MU7BGnGI@`VtN.EH>MU;2T84A@BVHVH@(Et>MU@B5&;FEt<=EH67(;FEt@`>R5M9F@B&
VH4<

õÖÙ

|{M|

{8x

Á8ã

xzy|{

öIö
$SY4JDTM@`G24;F@@B5&;FEt<=EH4

<=7:¨Ú´
õAÙ
xzy|{
EKG7GITM@`9I;+A@B9F<[A@B9

]Ä?ö
öIö
]^_Bö
öÄÛÇ
TM46924
ÂnPG2EH<MVt;F7B>M4@`8GIVHP
xy|{
}Ü
^Ý
7BJDT8Et46N?EH>MU7yG2<=7BVtV?U`7B5A@B9,;,7B>87VH7B92U`44EHUB46>MU`7B5A@B9
ö
W
44>&A@`9FJ4;2T87:;;,EKG~@:;2Ts7Jk2UB@.@&¡l=7:>87JkFGQ;D7:MVH4%lRJVtGQ
;24692EH>MU
7BVtV@:;FTM49=J
VH8GI;24692EH>MU`GEt;2TÐGI<R7:VHVU`7B57:9F4JVt@?GI4k;2@
;FTMEKGT87BGy~446>´.>M@(>Y;2@!5M9F46MEHJ
;U`@.@.YUB46>M49D7:VHEH67(;FEt@`>
;,ö
5~492A@B9F<=7B>8J
4EH>@B;2TM469Vt4^7:9F>MEH>MURGI4;I;2EH>MU?G
M9yA@B9F<8VH7:;2EH@B>EHG9F4<=EH>MEHGFJ
46>?;@BA;FTM4CÞjrüA@B9F<8VH7:;2EH@B>
4s<R7(¨&Et<=EH4l7 kFGQ;D7:MEHVHEO;QPzl,5~4>87BVO;QP`WTMEtVH4l46>8G2M92EH>MU,;FT87(;
;2T84l;F9F7BEt>MEH>MU87(;F77:9F4s4VHVyJVt8GI;246924^
T84l587B9F7B<4;2469/Ç
J
@`>?;29F@BVKG;FTM4!;29D7BM4
³@°wÌ~4
;Q44>;2T84!;Qn@,UB@?7:VKG
Ç46Et>MU7
U`7B5WEt;FG=N(7BVtM4!EKG@`M>8&4^EH>¼
Å³ÐT.8G6Wn7`G79FMVH4@BA

;2T.M<A@B9;FTM4JDTM@`EHJ4y@BA,Ç&W87=N(7BVtM4EH>¼t]6Á
ã]
ÅcG2TM@`MVH

9F45M9F46G24>?;7U`@.@.l4>M@`MUBT,?87:VHEt;QP!A@B9;,h=²·>,GI4^J;2EH@B>,Ên4
UBEHNB47<=4
;FTM@&kA@`9GI46<=EO·7:&;F@B<R7(;FEHJ67:VHVtPG24VH46J
;2EH>MU=EO;DGN(7:VHM4B
>M4qJ7B>¶7BVHG2@ÐJ@B>8G2EK&49!@:;FTM49!A@`92<MVK7(;2EH@B>Gk;FT87(;87BVH7B>8J
4
;2T84sU`7B5Ì7:>8w46EtU`4>MU?7:5 3M@`94
¨M7:<=5MVH4BW7`JJ@B9D&Et>8UY;F@q;2T84

@B9F4<
]BW7w>87:;2M9D7:V@`5&;2EH<R7:VHEO;QP°J
9FEO;F49FEt@`>¶@BMVK°4Õß¹
öR@(N`49Uß¹
;ö^°´
>=õ
xzy%{
~46J7B8G24;2TM4YVH7:;I;F49J@B>?;F7BEt>G7&EHN.EHG2Et@`>.P;FTM4s46EtU`4>MU?7:5
C.EH>8J
4;FTM44EHUB46>MU`7B5kEKG;QP.5MEKJ7:VHVHPk7=GI<R7:VHV>.M<469J
@B<=5MM;246
7BGj;FTM4R&EQw49F4>J
4=@:An;Qn@!J
@`>8GI4^J
&;FEtN`446EtU`4>.N(7:VHM46G6WGIJDTY7:>
@B5~49D7(;FEt@`>EKGM>8GI;F7BMVH4>?8<4692EKJ7BVtVHPB
áqÓ
öL>MVtEH´B4;2TM4
¢46924n45M9F46G24>?;;FTM4G2@BVH&;2EH@B>;F@5M9F@BMVH4<
õAÙ
CÞyrôA@B9F<8VH7:;2EH@B>WEH>Ï@`M9k@`5&;2EH<=Et^7(;2EH@B>Ï5M92@`MVH4<
>M4Et;2T849
@BMQ46J;FEtN`4>M@`9J
@`>8GI;29D7:EH>`;DG7:9F4J
@`>.NB4
¨sTM46924A@B9F4BWn4k@B5&
;2EH<=Et64;2T84587:9D7:<=4;249DG.PA@`VtVH@(Et>8U;FTM4U`9F7`&Et46>?;6W8GI;F7B9I;FEt>MU
A9F@B<±GI<R7BVtV¿W.5@?GIEt;2EHNB4`W?9D7:>&@B<
N(7:VHM46GnA@B9n;2T84j587B9F7B<=4
;2469FG
TM4=J
@`>8GQ;F9F7BEt>846!@B5M;2EH<EH67:;2EH@B>Y5M92@`MVH4<
]6Ä:D]^_BöEHGy46?MEHN(7(
VH4>?;EO;FT!<EH>MEH<=Et6Et>MU
]6Ê`ö
ö2ö
ßã
àpä
;2T87:;!M45~4>8MG@`>åÇ&±²³AæÇEKG´.>M@(>cWbc7BUB9D7:>MU`4
A@B9!7:>
G2EH<MVt;F7B>M4@`8GIVHP
<8VO;FEt5MVHEH49<=4
;FTM@&MG;QP.5MEKJ7BVtVHPR8>8
7B>8
Ân469I;DGI46´(7BG6W~]^ZBZ`Z^Å¿¢46924TM@(4NB4694JDTM@.@?GI4;F@;D7:´B47k&EtAÛ
A49F4>?;7:5M5M9F@`7`JDTW6;2T87:;EHVtV?~4&4^G2J92EH~46EH>;2T84n>M4¨.;G246J
;2EH@B>
3M@`9n>8@(W`4jEHVHVJ@B>8G2EK&49n@B5&;FEt<=EHEH>MUA@`9
EO;FT7M¨&46
+@46N(7:VH87(;F4=;2TM4RU`9F7`&Et46>?;@BAbßãn4=9FEO;F4=;2TM4J92Et;24692EH@B>,7BG
;2T84GI8<ÿ@:A;FTM4µSUT7=7VW7:>8!7AM>J;2EH@B>@BA;2TM446EtU`4>.N(7:VHM46G
rs4EHV¿¾
@:Aç=YSY4AM92;2TM4699F46J67:VHV;FT87(;¼
7=7:>C.T8E*WÀBÁBÁ8].Å;2TM4
4EHUB46>.Nh7BVt846GR@BA
ö7B9244^?87:V;2@q;FTM4l46EtU`4>.N(7:VHM46GR@BA;2TM4
TM49F4

öQí
G2P?<=<=4
;F92EKJ<R7(;F92Et¨/è
é
EH>sW¡èW7:>8Ú$;F@RGIEH<=5MVtEt8P>M@:;D7(;2EH@B>
A@B9F4n4&9F@B5;2T84

ÔÓ

xy|{

é

zM¯

«Ö

¯\â¯

232ª
Ô
Ô
g
e
õ



e
e
-
d
g
e
-
f

>
õ

õ

)


õ

õ


*
>
à
æ
»
õ
¹
ö
à
]
)
]
o
ó
ó
m
Z
n
Z
õ
X
Z
ö
"
X
¹
X
Z
õ
¼
o
)
]
)
o
»
õ
"
»
7
»
¼

e
-
f
o
õ
õ
»
õ
Ë
9
f
%
f
Ã
o
õ
>
à
×
¼
Z
×
Y
>
õ
»
õ
Ò
Ë

e
f
ö
"
>
õ

õ

õ
G
#
;
#

õ
;

õ

õ

õ




o

"

à

õ

õ

à

z

Ô
z
Ô


õ

õ
;

ö
)
´
"
>
õ

õ

õ
ä
ä

¼

ä

õ

õ

ö
à
í
õ

ö
"

õ

õ

ö
"

í
ï

æHæ

êìëríÖî|ï,ð

96

96

96





;;F@



þ

í
ïrþ

ñJòôó<õ¤ö?÷ùøÅúíüû6ýFïrþÿ 
í
ï

	
þñ




#%$
')()*,+.-
!
 
 /ñ
í/,ïþ
í/iï0
í/,ïþ

	
#.$
'213*,+.-
EKGGI;29D7:EHUBT?;IA@`927:9DW7BGI
TM4&49FEHNh7:;2EHNB4s@BAß
G2M<=EH>MUk;FT87(;y;2T84587B9I;FEH7BVM49FEtN(7(;FEtN`46G5476
J7:>Y4=J
@`<=5M&;24^
;F9F7`J;D7:MVHPBw²·>Ð;2TM4sA@BVHVt@(EH>MUn4sG2TM@(ÆTM@(¹;2@,@`&;F7BEt>Ð;2T84
U`9F7`&EH4>?;@:A;2TM4GI4^J
@B>k;F49F<!WTMEKJDT!Et>.N`@BVHNB46G;FTM446EtU`4>.N(7:Vt
498;:=<
7:VKG2@5M9F46G24>?;FGn>M@5892@`MVt46<!W?G2@
öÍNh7BVt7(;2EH>MU
846Gn@:A]è
4A@&J
8G@B>;2TM4&49FEtN(7:;2EHNB46G@BA46EtU`4>.N(7:VHM46G7B>8@:AGI8<=G@:A
;;2@;FTM44VH4<=4>?;DG@:Aè
46EtU`4>.N(7:VHM46G
²³;EKG´.>M@(>=;FT87(;A@B97G2P.<<=4;29FEHJ<=7:;29FEO¨NèWB;FTM4yM49FEtN(7(;FEtN`4
;;FTM4<R7(;F92Et¨4VH4<=46>`;DGT87`G;2T84
@BA7G2EH<58Vt446EtU`4>.N(7:VHM4
4¨&5M924^G2G2EH@B>
**
]hÎBö
EKG7
T849F4<*YEHG;2TM4R46EtU`4>.NB4^J;2@`9J
@B9F9F46G25@`>8&EH>MUk;F@
²³A
èöEKGj>M@:;&EEw~469246>`;FEH7BMVH47:;7è
<MVt;2EH5MVt44EHUB46>.Nh7BVt84BW~;2TM46>
+õ
²·>5M9D7BJ
;2EKJ
4BWcTM4>Y;Qn@@:An;2TM4R46EtU`4>.N(7:VHM46Gy@BA?è
öy7:9F4;F@.@
JVt@?GI4`W?;2TM4y4N(7:VH87:;2EH@B>k@BA;2T84yU`9F7`&EH4>?;n~46J@B<=46G>.M<=49FEHJ67:VHVtP
EH>8GI;F7BMVt4`ÆSTM46>°@`5&;2EH<=Et6Et>8U
]6Ê`ö
Wj9F46M8J
EH>MU;2TM4¸SUT7=7VW
;F49F<ÈT87BG;2TM4;246>8&4>J
P=;2@5M8G2TR;2T8489DGI;
46EtU`4>.N(7:VHM46G;2@B
7:9D]BW;2T.8GyGI46>8&EH>MUR;FTM4@`5&;2EH<=Et^7(;2EH@B>!;F9F7:Q46J
;2@B9FPkEH>?;2@k7B>
EH>8GI;F7BMEtVHEt;QP@`>M4B ¢@(4N`49^W:Et;EHGn@`9I;FT>M@B;2EH>MU;2T84GQ;D7:MEHVHEt
]6Ê?öÍ>MA@B9DJ
EH>MU
EH>MU=4qw46J
;5MVK7hPB46k.PR;2TM446EtU`4>MU?7:5k;249F<ÆEH>
@`>M4=VH7B92U`446EtU`4>MU?7:5W]´
WA@`9;2TMEKG5M9F@B8Vt46<WcT87BGy;FTM4R4qw46J
;
@BA4>MVK7:9FUBEH>MU=;2T84&EKGQ;D7:>8J46G4;Qn464>s7:VHVc@BA
²·>
#%#&#^>g·
A07`J;^WBEH>R@BM94¨.5~49FEH<46>?;FG6W:;2T84GIEH<=5MVH4UB9D7B&EH4>?;UBEHNB46>.PA@B92
](Î:öEKGGI;F7BMVH4A@B9y7:VHV+MM;;2T844
¨.;F9246<46VtPVK7:9FUB4N(7:VHM46G
<MVK7
@BA
?@
f
47A9B
A@`9
Ín7BJDTÌU`9F7`&EH4>?;GI;2465¶J
@`<=5M92EKG246G7:>Ì46Nh7BVt7(;2EH@B>¶@:A
;FTM4&4^G2J4>?;&EH924^J;FEt@`>=7B>8=GI46NB469F7BV?46N(7:VH87(;FEt@`>8G@:Aiß
A@`9;2T84
mHGJI
VHEH>M4GI4^7:9DJDTcSEt;2T;FTM4A467:;2M9F46G
UBEHNB46>WBJ@B<=5M&;FEt>MUs;F7B´B4^G
ö@B5~49D7(;2EH@B>GWJ@B<=5M&;FEt>MU;2T84/STb=7V6W7:>847DFE
4J6
õç
ãF4J8
ö7B>84N(7:VH87:;2EH>MUy;2TM4587B9I;FEH7BV&&49FEtN(7:;2EHNB46GK476
;D7:´`46G
ö
y+@J@B<=5MVH4
;F4;FTM446Nh7BVt7(;2EH@B>l@:A
9F46?MEH9F46G7B>M@:;FTM49
ßãk7B>8R@:A+EO;DGnU`9F7`&EH4>?;6W?n4y7:VKGI@>M44^R;2T8489DGI;
]j4EHUB4>M
of~
öySY4=J
@`<=5M&;24;2TM46<EO;FT
N(7BVtM4^Gj7B>846EtU`4>.NB4^J;2@`9FG@BA¤è
;FTM4srs7:;2VK7:ML;N7OQP!AM>8J
;2EH@B>Ð;2T87:;kJ7BVtVKGR7:>ÐEO;F49D7(;FEtN`45M9F@&J
4
¹EKGR;2T84
¹WTM46924
MM924T8@`G24!;2EH<4l5469kEt;249D7(;FEt@`>EKG
ço
>.M<469@:A4EHUB46>.Nh7BVt846G9F46?MEH924^R²·>,@BM94¨.5~49FEH<46>?;FG6Wc4
]6Á?öT?Gy;2TM4=9FM>M>MEH>MU;2EH<=45~49
GI4
<R7(¨
oÓ~
¹tö
U`9F7`&EH4>?;GI;2465!EHG
~qço

g6#&g^'

õ0ç

õç

õç

ÔÖ

«Ö

ãõ

}~zM¯

ãcõ

«ÿÓ

|{8|

Et;2T

N(7BVtM4^G

Q@9FMVH4k¼
]^Á

S47BVHG2@k8G24VtEH>M4=GI4^7:9DJDTl7:VH@B>MUk;2TM4=&EH924^J;FEt@`>l@:A&46GFJ
46>`;j;2@
8>8;2TM4@B5&;FEt<R7BV`GI;245GIEH47(;+4^7BJDTEt;2469F7:;2EH@B>cT845M9F@&J
46MM924
48G24EHG;2TM4X9F<=E
Ân469I;DGI46´(7BG6W~]^ZBZ`Z^Å¿TMEKG;D7:´`46G7
47ATB
GI;245@:A+G2EH4SR;2T8489DGI;n;FEt<=4yTM4>5ß
öVU
47A9B
W&@:;FTM49FEHG24SREKG924^&8J46?P7A07`J
æHæ
;2@`9n@BA+À&S4y7BVtVH@(wM5;F@ÉBÁ924^&8J;FEt@`>8G6W?8&;n;FTM4j7BVtU`@B9FEO;FTM<
J7B>Ì~4l467`GIEHVHP;FM>M46¶GI@;2T87:;EH>Ì5M9D7BJ;FEHJ4l<=@`GI;GI;24658G7B924
;F7B´B46>!7:AÛ;2469Q8GQ;]
QÀA8>8J;FEt@`>4N(7:VH87(;FEt@`>8G6TM4EH<58Vt46<46>&
;F7:;2EH@B>@BA&;2TM47B87:5&;FEtN`4nGI;245GIEH4nEHG+TM@(4NB469>M@B;G2M5~49`¦8M@BGW
7BGn;QP.5MEKJ7BVtVHPk7(;;FTM446UBEH>M>MEH>MUR7:>87(;;2T844>8@:A+;2TM4VH467:9F>&
EH>MU8W.GI<R7BVtVH49GQ;F45G2Et646G7B924jJDTM@`G24>SEt;2TR;FTM4j7`M7:5&;FEtN`4GI;245
G2Et64BW(;FTM4UB9D7B&EH4>?;&46GFJ
46>`;8G287:VHVHP;F7B´B46G+VH46GFG;2T87B>]^ÁBÁGI;24658G
;2@7:;I;D7:EH>7U`@.@.G24
;c@BA
7:;I;F7BEt>8Et>MUJ@B>.NB4692U`4>8J4+@`>8J
4
>M4^7:9;FTM4@B5M;2EH<M<EKGGIVH@(49^W
;QP.5MEKJ7:V`@:A&UB9D7BMEt46>`;c7BVtU`@B9FEO;FTM<RG
Xw;QP.5MEKJ7BVM<=4
;2T8@.@:AGI5~44^&Et>8UM5=;2T844EHUB46>?N(7BVtM4J@B<=5M&;D7(
;2EH@B>lEt>GI5~46J
;29D7:V+JVtGQ;F49FEt>MUEHG;2@8G24G2587:9DGI4GIEH<=EtVK7:9FEO;QP<R7(
;29FEKJ
46GnEH>8GQ;F467`R@:AAMVHV@B>M4^G@`9;2T847+P.GI;297X
@B<±7B5M5M9F@h¨.EH<R7(;D7:EH@B>
A@B9R46EtU`4>.NB4^J;F@B9DG°¼
38@(Vt´`46G4
;7BV*HW8À:Á`Á:ÄhÅjT846G24;F92EKJD´&GRJ7B>
~47:VKGI@R7B5M5MVHEt4^k;F@RVt4^7:9F>MEH>MURGI5~46J
;29D7:VJ
VH8GI;24692EH>MU8W8Vt4^7B&EH>MU;2@
7B8&EO;FEt@`>87:V;FEt<=4GF7hN.Et>MU?G
®jÕQ|{8¯\â|zM¯Q¬
Ô
ÒÔ
§nTM@.@`G2EH>MUk;FTM47:<=@`M>?;y@BA9F4U`MVH7B92EH67:;2EH@B>EKGJ
9FEt;2EKJ7:VA@`9;2TM4
Et>?;F@,7B>[Z=N.EK7Y;2TM4
G28JJ46GFG@BAjVH467B92>MEH>MUÂP,;29D7:>8G2VK7(;2EH>MU
@B5M;2EH<EH67:;2EH@B>q5M9F@B8Vt46<
öW@B>M4RU`4
;DG7T87B>8&VH4@B>,;FTM4@`9I
õÖÙ
&469@BA<R7:UB>8EO;F8&4k@BA\Z=TMEKJDTJ7B>48G246qT84>;FTM49F4kEKG
UB@.@&5M9FEt@`9´?>8@(Vt4^&UB47B@`&;;2TM45M92@`MVH4<Ç@`9TM46>7JDTM467B5
+@(¹n4sG2TM@(¹7qG2EH<58Vt4<=4
;FTM@&ÐA@B9
G2@BVH&;2EH@B>wEKG=>M44^&46
G24<=EO·7:M;2@B<R7:;2EKJ7:VHVHPGI46Vt4^J;2EH>MU
e,_^`bac`ed;fghaci;jk
/*o
%('g
Nh7BVt846GG2587:>8>MEt>8U7,924^7BG2@B>87BMVH4
]Bç§nTM@.@?GI4s7G24
;ý@:A
9D7:>MU`4BW.4B
ã]6Á
U¼O]^Á
ú!ý
À&g38@B9
7?öt3EH>8ml
7B92U`<EH>
ßùã
xy|{Vn
;,6ö
´<>
~ö§n@`<=5M&;24
ãö2öã
ãpo
ãpoEKGG2<R7:VHV*WMM;
ÉM
G2@,;2T7(;
rs7:>.87BVKö-§nT8@?@?GI4
ãcW;2TM4
ãN&G
EKGGI;2EHVHV9F467`GI@`>87:8VtPYVH7B92U`4Bs²·>7l5MVH@:;@BA
EHVHV+~4>M4^7:9;2TM4Vt@(499FEHUBT?;jJ
@`92>849@BA;2TM4
&4^GIEH9F46
5MVH@:;^
3EtU`M9F4y]G2TM@(G7:>4
¨M7:<=5MVH4@:A~G28JDT=758Vt@B;6+@:;F4;2T87:;<@`924
;2T7:>R@B>84
N(7BVtM4<=7hP4j>M467B9;2T84´.>M44@:A;2TM4jJ
M9FNB4`TMEKG
7:VHUB@`92Et;2T8<°J@BMVK~4n9F4
>M46W^A@`9+4¨&7B<=5MVt4.P7MEH>87:9FPGI4^7:9DJDT
@B>
W&8&;;2TM4TM@`54yEHGn;FT87(;;2T84y5892@`MVt46<±EHG>M@B;G2@=GI46>8GIEt;2EHNB4
;2@;FTM4N(7:VHM4@:A+;2TM49F4U`MVH7B92EHEH>MU587:9D7:<=4;249^
rts

²·>;2TMEKGG246J
;2EH@B>n45892@(N.EK&4;2TM4&4;F7BEtVKG7:>9F46G2MVt;FG@BA~4¨&5469I
EH<46>?;FGR9FM>wEO;FTw;2TM4VH467B92>8Et>MUq7BVtU`@B9FEO;FTM<
5M9F46G24>?;24^ÐTM49F4B
TM4kG2EH<EHVK7:9FEO;QPEHG&4
>M467`G
7`GQ
WEt;2T
à
rF
G2M<=465~@`G2EO;FEtN`4B$TM4YEt>8EO;FEH7BV4EHUBT?;FGkn46924lJDT8@`G24>Ð;2@4
ßFè
EH>?N`49DGI46VtP5892@`5@`9I;FEt@`>87:V+;2@!;FTM4RN(7:9FEH7B>8J
4@:An;2TM4
VH467:9F>MEH>MUA@`9n4^7BJDT5M9F46G25~46J
Et84^
;Qn@@B5&;FEt<R7:V
N(7:VHM46G7:>8

ÓÔ

Ôc«

{¯

zMx

uQXAÛ;F49

233ð








ð










"
&








"
&


4

õ

4


>

>
è
à
0
õ


õ

õ
o
õ
>


ã

õ
ä

Á
9
±
b
f
)
4

ã

C
"
C
"
4

4

C
"
õ

o
o
¹
à
õ
À
o
ã
C
"


ö
)
ß

)
R
4

W
4

"
W
à

"


Y
Õ
Ô
z
{

Ô
z
Ô
{
ä
ä

]
f
ä

"
"
Å
ä
õ

ã
à

õ

ö
õ
Ò
ã
à
õ

õ
l

x
ã
à

B
õ
õ
ä
x
Ò
x
Ò
ä
ä
ä
q

õ

ã

ö


ä
ä
0.06

p
a
g

0.04

0.02

0
10−10

  16

10−8

1.2

1

0.8

0.6

0.4

0.2

0

 0.5

0.25

   1

   2

   4

10−2

100

VI
CE

0.25

0.5

1

2

4
alpha

8

16

1

0.9995

0.999

0.9985

0.998

0.9975

   8
10−4

10−6

eigengap

~K{}w¡{%9|=~c|~c\T{%¢
~hFbFcwJ9) w)|=Jw)~c79y
3EHUBM9F4]uvxw)y=w)z.{}|~c

~{}wy=w2{{}w.}\
3{%\w2{cw)z.}|w)|=~Kw)z2{}|
ñt
~±T~t|=~cw)w)~cw)~	{{}w)ª{£w2{e²w9¦x}w¬	­¯{}w
|=~{V|£yTw)y=w¥¤¡|,{}¥|={}
w9z%t
£{}wy=wT}~cw
JTy=¦wJ §¨H©y¦cª{}w2}|=~¬«	¦9y=|,{­¯®
î°
 Sª¸£w\y=wT}~cw
~tw2
9~h{}w´z)y9|,µpz)T{}|
}²KT{}|
J3}|3{}|
®H|=~c®
cy
{{}w¯7w.}¦{}cw£}w)J¦cy3}|=·T{}|
~¥p3%9²w2{}w.
¶
í ³
·2w2
z.½FT}w£~
~9yey
c|T
{}w{}pT{¡{}cw
{}c|=cT{%Tw2{ Hº
|²|=yT}|,{­h²K3{}|=¹
9»¼
7:MVH4=]u¡ÆÇxÈÉÊ0ËÈÍÌÎpÏKËÐQÇÑ¨ÉÊ0ÊÒÈ2ÓÇÔÇ¬ÇÕeÖÇÏT× ØtÇxÙ;Ë)ÈJÚ
J@B9F924^GI5~@B>&Et>8U587B9F7B<4;2469FGnn46924JDTM@?GI46>TM4y89FGI;@B5&;FEt<R7:V
®´{}w¬{%T|~c|=~Ý3{%5w2{§{}cwÑpT%T²w2{}w2}K¤w2}w
|=§{}wÑ|=·)w
7`GJDTM@`G24>87`GI4^Y@`>;2TM4kG2<R7:VHVt4^GQ;<=EKG2JVH7`G2G2EtJ7:;2EH@B>492
Û;Ü
|ª­Sc|=²w)~c|
®~
|{}cw~¦²w2
~9xw
~Í9~
y=wT}~cw
õ§Þ	ßà
9F@B9@`>k;FTM4;F9F7BEt>MEH>MURG24
;6WEO;FT;2EH46GU`@BEH>MU;2@=;2T84GI<R7BVtVH46GI;
mH¾T84
c}w)w)~	{}w¯cw2}w\T}w´{}
{}w\3{%x w
wz%
w)~¬pTw
ãMè
Et;FGJ@B9F924^GI5~@B>&Et>8U587:9D7:<=4;249DGnEtVHV4&46>M@:;F46
{}w¡y
¤w)ª{á{%9|=~|=~c\z2yT|,µpz3{}|
 Hw¡z)y9|,µzT{}|
~w2
~hw2
7BGJDTM@?GI46>l8G2EH>MU!;2TM4G24VH46J
;C.4VH46J
;XVH5MT877:VHUB@B
G246J@B>8
¶
eâã3ä
å
T~pÑº£©¦x{\T}wK7w2%TJw
Jw2Kæç§|=~cw)w)~cw)~	{
{}w)ª{Fw2{}) 
9FEt;2TM<ûM46GFJ
9FEt~46YEt>qC.4^J;2EH@B>,ÊMW+7:>8YEO;DG587:9D7:<=4;249DGjEtVHV~4
mH¾
C&4VH46J;FEt>8Uy7yGIEH>MU`Vt4
ã&è
M4>M@B;246
EHGVH46GFG+JVt4^7:9EH>;2T8EHGG246J

+J&;
§Í
1:¤ÛÚ
xzy|{
Et>3EHUBM9F4=]67Et;J7:>!~4GI464>;2T7(;~@:;2TlÀ7B>8
@`>8<=4
;2T8@.
ZB4
·É
Ä
Ä8
ÄB4
Q_
Ä7B9245~@`GFGIEHMVH4J7:>&EH87(;24^GA@B97B>=@B5&;FEt<R7:V
²·>=;2TM4^GI4G2Et;287:
ZM
É:4
Q_
Î&
ÁB4
·É
;FEt@`>8G6W&EO;7B5M54^7:9DGn;2T87:;9F467`GI@`>87:8Vt4yJ7:>&EH87(;24^GA@B9
VH467`;F@
Î.
Z:4
Q_
Ê8ßÎ(4
·É
G2EH<EHVK7:9J
VH8GQ;F49FEt>8Uk9F46G2MVO;DGy²·>l@`9FM49;F@;F46GI;y4^7BJDTsN`46J;F@B9j@:A
]^Ê
]BH]4
³Ä
Î&
À:4
·É
46EtU`4>.NB4^J;F@B9DG@:A;2TM4J
@`929F46G25@`>8&EH>MU
57:9D7:<=4
;F49DG;2TM489FGI;
ö<R7(;F92Et¨k49F4J
VH8GI;249F468G2EH>MU=´`³<=467B>8GW8EO;FT<MVt;2EH5MVH4
9D7:>&@B<
A@`9<=@`924Et>MA@B92
<R7:;2EH@B>@B>!Et>8EO;FEH7BVtEH67:;2EH@B>8GG244R¼
78WÀ:Á`ÁBÉ^Å³

]^_BÁ
À:Á`Á
Ä`Á`Á
Î(Á`Á
U`7B5W46EtU`4>MU?7:57B>8>M@`92<R7BVtEH4^J
&;R@(N`49;FTM4;246>ÐGF7:<=5MVH46G
8G2Et>8U
7`G=;2TM44EHUBT?;DG7:5M58VtEH46;2@,;FTM4A4^7(;28924^GÌ²·>
;2T8EHGjGIEt;287:;2EH@B>;2T84
n²·>7:VHV
J7`GI4^G;FTM4Vt4^7:9F>M46q57:9D7:<=4
;F49DG49F4k5~@`G2EO;FEtN`47B>87B5M5M9F@h¨?
EH<=7:;246VtP4^?87:VA@B9;FTM4!<4^7:>MEH>MUBAMVA467:;2M9F46G=7:>ÁY@B>;2TM4
>M@`EHG2Ps&EH<46>8G2Et@`>8GWcTMEHJDTVH467Bl;2@UB9F467:;JVtGQ;F49FEt>MU?Gy@B>Y;2TM4
;24^GQ;87(;F7=GF7:<=5MVH46G6

7:>@B92;2T8@B>M@`92<R7:VnEt>8EO;FEH7BVtEH67:;2EH@B>8G

Þ49F<=7=7B>8rs4EHV¿¾

7B924EK&46>`;FEHJ67:V;F@R;2T84

]BH]4³É
ÉM
Á:4¿Ä
_&
ÄB4¿Ä
Ä8
Á:4¿Ä

]BßÀ
]BßÀ
]BßÀ

mH¾

mH¾

ãMè

ãMè

ã&è

®-

/0/%Á

d&³2Â

Àb
T8489DGI;G24
;n@BAc4
¨&5~49FEt<=46>`;DG7BGn9FM>@B>GIEH<8VH7:;246kM7(;D7MW.7
8MVtVL¿
GQ³4P`4EH>Y;Qn@&EH<=4>8G2Et@`>8G6=T84=87(;F7!J@B>8G2EHGI;@:A7:>Et>&
>8499FEH>MUJ
@`>?;F7:EH>MEH>MU7:585M92@h¨&EH<R7(;246VtPÄ`ÁpÃ[@BA~;FTM4j87(;F75@`Et>?;FG
Et;2TÏ;2TM49F4<R7:EH>MEH>MUM7:;F75@`Et>?;FGkA@B9F<=Et>8U7:>¶@B&;F4992EH>MU
ST8EtVH4;2TMEKGM7:;F7jEHG7:92;2EtJ
EK7:V¿W(VH7B92U`4nEt;2T8Et>JVt8GI;2469&EKGQ;D7:>8J46G6W
7lGI<R7:VHV>.M<469@BA>84EHUBT.@`9FGA@B94^7BJDTq5~@BEH>?;6W7:>8q7sTMEtU`T
5~@`GFG2EtMEHVHEO;QPR@BAc@(NB469I¿M;I;FEt>8U<R7:´`4VH467:9F>MEH>MU>8@B>&¿;29FEtN.EK7:V¿XVHG2@8W
;FTM4<=4^7:>MEH>MU:A8V8A4^7(;28924^G467`JDT=;F7B´B4>G2457:9D7(;246VtP&@>8@:;nJ@B92
9F4VK7(;F4Rn46VtVnEO;FT,;2TM4J
VH8GQ;F49FEt>8U8W<=7B´.Et>MU!;FTM4TMEHUBTq4EHUBT?;2
EH>MU@BA@B;2T<=4^7:>MEH>MU:A8V8A4^7(;28924^GEH<5~@B92;F7B>?;nEH>R;2TM4jVt4^7:9F>MEH>MU
1:¤ÛÚÈ>M@BEKGIP!&EH<=4>8G2Et@`>8G;2@;FTM4MMVHVj¿
GQ
5892@&J
4^G2G6S4=7BM&4^5M
46PB4`WTMEKJDTl49F4G2P.<<=4;29FEHJ9F7B>8&@B<»<R7(;F92EKJ
4^G&4^GIEHUB>846!;F@
T7hNB4Y;2TM4qGF7:<=4,<4^7:>7BG;2T84q<4^7:>MEH>MUBAMVA467:;2M9F46G6µT84
4EHUBT?;DG49F4kVH467:9F>M4^,A@B9=7sN`46J;F@B9@:A
G6W.Pq<=Et>MEH<=Et6Et>8U
]6Ê?öTM4MEHGI;F7B>8J
4<=4
;F92EKJ8GI4^A@`9J
9F467(;FEt>8U;2T84;Qn@y<=467:>M
Äh%u2æOSTM46924ÄB
ßFè
EH>MUBAMVc&EH<=4>8G2Et@`>8G7BG
EKG;2T84
¨.·J
@.@B9D&EH>87(;F47B>8ÄB
IÅ
EKG;FTM4RP?³J@?@`9FMEt>87:;247BGFGI@&J
EK7(;F46YEO;FT
;FTM4â
5@`Et>?;^SY4;24^GQ;F46;FTM44EHUBT?;DG@B>!;F4>sEH>8&46546>8&46>`;
GF7:<=5MVH46G@BAÉ`ÁBÁ=M7(;D75@`Et>?;FG6
7:8Vt4q]5M9F46G24>?;DG=;2TM4s7hN`49D7:U`4@BAj;FTM4lJ
VK7BGFG2EOJ67(;FEt@`>46929F@B9^W

ÄBu

mn-?gg6-?%

è

TM4kG246J@B>8,G24
;@BA4¨&54692EH<=4>?;FGEKG5~492A@B9F<=46@B>;2T84-4;I
;2469éè4^J
@BU`>MEt;2EH@B>±M7(;D7[GI4;A9F@B<½;FTM4ÏL§n²J¥3y3
7B9FJDT8EtN`4
C.VH7:;24`W]6Z`ZM]DÅ³Í7`JDTVt4;I;2469jT7BGG2Et¨?;F446>A467:;2M9F46G6WeÄ
}ë
2ê
WEH>&
Áy;F@R]6ÊMW`7BGFGI@&J
EK7(;F46EO;FT=EO;^C&@B<=44
¨M7:<
;246UB469Nh7BVt846A92@`<
5MVH46G@:Ac;2TM47(;2;29FEtMM;246G7B924;2TM4yTM4EHUBT?;7:>8kEH&;2Tk@BA;2T84y~@h¨
7:>;2T84<=4^7:>s¨l7B>8sP5~@`G2Et;2EH@B>8Gy@:A;2TM4JkI@`>(l(³5MEt¨&4VKGTM4
7:9F9F7hPREKG&48>M46TM46924u
&EKGQ;D7:>8J48GI4^A@B9J
9F467:;2EH>MU;2TM4
ÄB0è
EtA©ÄB0è
@:;FTM49FEHG24
TMEKG&EKGI;F7:>J
47BGJDT8@`G24>~46J7B8G24EO;G2J67:VH46G&@(>!;FTM4A4^7(
;28924^GjEH>?;2@q¼
ÁMWH]
Å7:>8l4^J7B8GI4=Et;7`Gj~4VHEH4NB4^;FT87(;7!GI<R7BVtV
&EEw~469246>8J
44;Qn464>;Qn@RVK7:9FUB47:;I;29FEHM&;24Nh7BVt846G7BGVH46GFGEH>&
A@B9F<R7(;FEtN`4=;2T87B>,7lGI<R7:VHV&EEw49F4>8J44;Qn464>;Q@sGI<R7:VHVn7:;I
Gy4PB4
;29FEHM&;24N(7:VHM46G6jT8EHGM7:;F7G24
;J
@`<58Vt46<46>?;FG;2TM4MMVHVj¿

àíì

ð|

<ï
<ï

:ï
:ï

2è

234#
²
:


{


ñ




~



~

ï



í
ï


ñ

®





~
¼

 
ä
ä
W

ä

6
ä

ä
ä
o

õ


¿
@
Á
ä
¿
õ

u
à
æ
)

"





{

ñ



~






í
ï
+


ç
I
M
ä

´
X
]
Á
À
Á
Ä
Á
À
Á


6


¿
@
Ô
d
¼



Á

à

à
Á
×
î
î
ð
×
î
ð
·
î
ð
7B>8

mH¾

Xç§n²C¿7:>8

87(;F7GI4;n~46J67:8G24;FTM4jr8VO;FEO³7hP/+@B9F<=7BVtEH4^RJ
&;EKGU`924^7(;2469
;FT87:>wÁMWn;2T84!JVtGQ;F49DGR7:9F4&46>8G24!7B>8;2TM469247:9F4924^&M>8M7B>?;
A4^7(;FM924^G
T844¨.5~49FEH<46>?;FG&46GFJ
9FEt~46TM49F4k9F458924^GI46>`;=7:VHV@:A;2T844¨.
5~49FEH<46>?;FG4RT87hN`4&@B>M4k@B>;2TMEKG87(;F783M4;2@;FEt<=4k7B>8
<=46<@`92PVHEH<Et;F7:;2EH@B>8GG2<R7:VHVGI88GI4;FGy@:An;2TM4RVH4
;2;2469FG49F44¨.
58Vt@`924^
Â4
;Q446>;2T84l;F9F7BEt>MEH>MU7B>8;F46GI;G24
;DGk4^7BJDTÌVH4
;2;249
7B5M5~467:9DG7B5M5M9F@h¨&Et<R7(;F4VHPRÎB_:Á;FEt<=4^GTM4;29D7:EH>MEt>8UG24
;n@BA;2T84
C&rØ¿87(;F7J
@`>8GIEKGI;246l@:A_BÁk@&J6J
M9F9246>8J
4^G@BA467`JDTsVH4
;I;F49^W;2T84
SlX
¿7:>
Í²C¿.;F9F7BEt>8Et>MU87(;F7=J@B>?;F7BEt>M4^]6ÁBÁ@BA4^7BJDTVt4;I;24696W
7B>8l;2TM4;29D7:EH>MEH>MU!GI4;yA@`9y;2TM4
Xç§n²Qr¸¿M7(;D7kT87`
ÀBÁBÁ@:A467BJDTVt4;I;F49^SY47:VKG2@JDTM@?GI4j;2@=9F4
·G27B<=5MVt4G24
;FG@BAn]^_BÁ
VH4
;2;2469FG6WnÀB_;2EH<=46GA9F@B<
467`JDT@:A;2TM4;24^GQ;M7:;F7lG24
;^W;F@l;F46GI;
;FTM4!587:9D7:<=4;249DG@`>G2<R7:VHVt469M7:;F7GI88GI4;FG6W~46J67:8G24kEt;R7`G
>8@:;24^R@B>k;2TM47:92;2EtJEH7BVM7:;F7;FT87(;VK7:9FUB49M7(;D7G24
;DG5M9F@(N.EHM46
A@`9R4;I;F49J
VH8GI;24692EH>MU`G=46NB46>Et;2TÐ;2T84VH467B92>846587:9D7:<=4
;F49DG
7B5M5MVHEt4^
7:8Vt4ÀkUBEHNB46Gj;FTM4R924^GI8VO;DGj@BA;FTM4RVt4^7:9F>MEH>MU4¨&54692EH<=4>?;FGyA@`9
~@:;FT
@`>k;FTM4;29D7:EH>MEH>MUR7:>8;F46GI;M7(;D7G24
;DG
ãMè
ãMè
GJDTM@?GI46>k.PR;FTM4y;Qn@<=4
;2T8@.8G&EQw49^W&TMEKJDT
T84y@`5&;2EH<R7:V
EKG&M4yEt>587:92;;2@;2T84A07`J;;FT87(;Et;EKG9D7:9F4BW?EH>4Et;2TM469<4;2TM@&W
;F@kT87hN`47kM>MEK`84@`5&;2EH<R7:V
7:>8!;FEt4^Gyn46924M46J
EK&4^l&EEw~469I
46>?;2VHP4;Qn464>;2TM4<=4;2TM@&MG6X°5M92EH@B9FEEO;<=EHUBT?;4y;FTM@BMU`T?;
JDT8@`G24>A92@`<±;2TM4§Í@`>;2TM4;F9F7BEt>MEH>MURG24
;<=EtU`T?;
;FT87(;;FTM4
@(N`49M;j;2TM4;29D7:EH>MEt>8UkM7(;D7MWM&;;FTM4;F46GI;§Í¿
G&@k>M@:;jG2TM@(
<8JDTs46N?EK&46>8J
4@:A@(NB469I¿M;2;2EH>MUREt>l;2TM4^GI44
¨&5~49FEt<=4>?;DGyTMEHG
<R7hP.~4j~46J67:8G24;FTM4Vt4^7:9F>MEH>MU7BVtU`@B9FEO;FTM<Æ&@.46G>M@B;<EH>MEH<=Et64
;FTM4kJVt8GI;24692EH>MU!49F9F@B9&EH924^J;2VHPBc@<R7B´B4G2M924;FT87(;VH467B92>846
57:9D7:<=4
;F49DG7BGnEt>A07BJ
;Et<=5M9F@(N.Et>MU;2TM4JVt8GI;24692EH>MUW?4J
VH8GQ
;F49F46;2TM49F4
·G27B<58Vt4^R;24^GQ;M7:;F78G2Et>MU587B9F7B<4;2469nN(7:VHM4^G7BVtV
4^?87:V.;F@ÁMH]BW`7B>8;2TM4^GI47B9245M9F46G24>?;F46Et>=;FTM4VH7`GQ;J@BVHM<=>=@:A
7:8Vt4jÀMi+@:;F47:VKGI@;2TM4J@B>8G2EKGQ;F4>?;n&4^J
9F467BG24EH>t§ÍqEO;FTR;2T84
EH>8J924^7BG24@:A;2T84;24^GQ;GIEH4`S4j7:;I;F92EHM&;F4;2T8EHG;2@;FTM4jG2<=@.@:;2TM
EH>MU=4qw46J
;@:A7VH7B92U`4yGF7:<=5MVH4GIEH4@`>k;FTM44EHUB46>?N`46J
;2@B9DG6
²³;yEHGjEH>`;F49F46GI;2EH>MUR;F@7BG2´TM4
;FTM49j;2TM46924EHGy7kJ@B<=<=@B>sG24
;y@:A
EH<=5@`9I;D7:>?;yA467(;FM9F46G7BJ92@?G2GVt4;I;2469FG6µ3EHUBM9F4RÀ5MVH@:;DGj;2TM4=587:
mH¾W7BGFGIEHUB>M4^;F@=467BJDTA467:;2M9F4A@B9;FTM48N`4&EOAÛ
9D7:<=4;249DG6W
A469246>?;GIMGI4;FG;24^GQ;F46TM4
7B924N`49FPkGIEH<=EtVK7:97B>8!7:9F4
>8@:;yG2TM@(>ySTMEHVt4;FTM49F4EKGN(7B92EK7(;FEt@`>sEt>l;2TM4<R7:U`>MEO;F8&4@:A
;FTM4587:9D7:<=4;249DG6WB;FTM49F4yG2446<RG;F@~4GI@`<=4y7BUB9F44<=46>`;Et>;2T84
4EHUBT?;DGG24VH46J
;2467BGEt<=5~@B92;F7B>`;^,²³;R7B5M5~467:9DG;FT87(;=A4^7(;28924^G
;Q4VHNB4y7:>8RA@BM92;2464>k7B924j9246VH7:;2EHNB4VHPEt<=5~@B92;F7:>?;A@B97:VHV@BA;2T84
87(;F7RG24
;DGW~TMEHVt4@B>M4`WM;Q@8WMNB47:>!>MEt>84&@>M@B;j7:5854^7:9;F@
~4N`49FPsEt<=5~@B92;F7B>`;A@`9J
VH8GI;249FEH>MU!;2TM4^GI4G2M8G24
;DGTM4587:
rØ¿7:5854^7:9;F@
Cr¿7:>
9D7:<=4;249DGVH467B92>M4^A92@`<û;FTM4kVH4
;2;2469FG
;FTM4s@B;2TM469FG6°+@,AM92;2TM469;F46GI;
~4;FTM4s<=@`GI;&EEw~469246>?;A92@`<
;FTMEKGEH&4^7k@BA7J
@`<<=@`>YG24
;@:AnA467(;FM9F46G6W;2TM4
ã&è
VH467B92>846
A9F@B<û;2TM4
C&rØ¿GI88GI4;6Wn46924R7B5M5MVHEt4^l;F@!;2TM4k@:;2T849G2M8G24
;FG
7B>8;2TM4jJ
VH8GQ;F49FEt>8Uy46929F@B9DG+A@B9;FTM4<MVO;FEt58Vt4&EKG0Q@BEH>`;;246GI;G24
;FG
7B9249F45~@B92;24^Et>s7:MVH4ÀMTM46P&@k>M@:;jMEQw49yGIMGQ;D7:>?;2EK7:VHVtP
G2MU`UB46GI;2EH>MU;2T87:;;2TMEKGM7:;F7=G24
;T87`G924^&M>8M7B>?;A4^7(;FM924^G
@0ò
g^#z²'0/0'0gF®
XVtVy@:A;FTM4l4¨&54692EH<=4>?;FG5M9F4N.Et@`8G2VtPÐ&EHGFJ
G2G246ÌJDT8@`G24sJ
VH8GQ
;F49FEt>8U`G.Pk<=EH>MEH<EHEH>MUR;FTM4U?7:5WMT8EtVH4<R7:EH>?;F7:EH>MEH>MUR7RVK7:9FUB4

ãMè

ã&è

%(-

0.5

0.45

0.4

0.35

s
t

0.3

i

h
g
e
w

0.25

0.2

SMx20
WA
EI
ACI
ACIM

0.15

0.1

0.05

0

1

2

3

4

5

6

9

8

10
7
Features

11

12

13

14

15

16

®áy=w3}~w¬T%9²w.{}w2}

~Ñ9y=yµp7w\cT{%

3EtU`M9F4Àzu´
²T}|=
{}cwVy=w2{{}w2}
w2{}®

4EHUB46>MU`7B5T8EHGGI4;@:A4
¨&5~49FEt<=4>?;DG7:9F4&46G2EHUB>M4^l;F@lG2TM@(
;2T7(;;FTM4J
VH8GI;24692EH>MU`G7`JDTMEH4NB4^?P@B5&;FEt<=EHEH>MU=;2T8EHGjJ
9FEO;F49FEt@`>
7:9F4RJ
VH@`G24;2@!;2T84R@B5&;FEt<R7:VnJ
VH8GQ;F49FEt>8U8S4R5469IA@`92<=4^7!G24
;
@:AG2Et<=5MVH4!4
¨&54692EH<=4>?;FG6WJ
@B>GQ;F928J
;2EH>MUq7<=7:;29FEO¨wWn9F46G2MVt;I
GW?;2@TMEKJDTk47BM&4^9D7:>8M@B<±>M@`EHG24B
EH>MUEH>!7µÇEO;FT§§Í¿
7:MVH4RÉU`EtN`46Gj;2T84RNh7BVt84@BA;FTM4R@`M>8YEt>qTM46@B9F4<
]R7BG7
AM>8J
;2EH@B>!@:A;2T84>M@BEKGI4`WM7hNB469F7BUB46=@(N`49]6Á>M@`EHG24924^7:VHEt^7(;FEt@`>8GW
A@B9;2TM4JVt8GI;24692EH>MU!@BM;F7:EH>M4^Y.Pl;2TM4krs4EHV¿¾
7:·C.T8EGI5~46J
;29D7:V7BVO
UB@`92Et;2T8<
_=A@`9;FTMEHGM7:;F7GI4;6
XGn@B>84J7B>kGI464BW`;2TM4j@`M>8REKGEH>&A@`92<R7(;FEtN`4M5R;F@G2EtU`>MEtJ7B>`;
>M@`EHG24kVH4N`4VKG
7:9F4R´.>M@(>WEt>,;FTM4k~46GI;J67BG246G;FTM4k~@BM>qJ7:>q9F458924^GI46>`;7
5M9F@.@:A.;2T87:;c;FTM4@`5&;2EH<R7:V.J
VH8GQ;F49FEt>8UA@B9c;2TMEKG+87(;F7GI4;+T87`G~44>
7BJ
;287BVtVHPRA@`M>8
¯Ix.}®x.x.¯Q¬

Cz+\èÿ@:Aj7B@`&;!]^öC&Et>8J4k;FTM4>M@&&4N`@BVHM<=46G

7=7:>8C.TME¿WÀBÁBÁM]6?Å

}Õ2®x.¯Q¬

r46EtV³¾

­}¬

S4T87hNB4yEH>`;F92@&&J
46!7=>M46°J92Et;24692EH@B>A@B9Vt4^7:9F>MEt>8U;FTM4G2Et<
EHVH7B92Et;QPkEH>lG254^J;29D7:VJ
VH8GI;249FEH>MU8TM4J92Et;24692EH@B>@`5&;2EH<=Et646G;2TM4
?87:VHEt;QP@:A;2TM4;D7:9FUB4
;J
VH8GI;24692EH>MU8WBTMEtVH4J
@`>8GQ;F9F7BEt>8Et>MUj;2T84587(
9D7:<=4
;F49DG
7BGRVHEt;I;2VH4Y7`GR5~@`GFGIEHMVH4Et>;FTM4s5M9F@&J
4^G2G6¶TMEKGEKG
7BJDT8Et46NB46Ð.PJDT8@?@?GIEH>MU,;FTM4sU`7B57BG=;FTM4lJ
VH8GI;24692EH>MU?87BVtEt;QPBW
7:>q.P7`M&EH>MUs;FTM4GF?87:9F464EHUB46>MU`7B57BG7s9F4UB8VH7B92EH67:;2EH@B>
;24692<!
>M4@:A;2TM4R&EE¨J
MVt;2EH46G@BAVt4^7:9F>MEH>MUkEH>YG254^J;F9F7BVJVtGQ
;24692EH>MUyEHG+;FTM4>?8<4692EKJ7BV.@B5&;FEt<=EH67(;FEt@`>@BA8;2T84JDT8@`G24>J92Et;24692EK7MW
7BG;2TM46PR@:AÛ;F4>k&46546>8@`>
;FTM92@`MUBTAM>8J;FEt@`>8Gn@:A;2T84j46EtU`4>&
N(7:VHM46G7:>RNB4^J;2@`9FG@:A]@`9n7:>8@:;2T849<=7:;29FEO¨TM4yUB9D7B&EH4>?;FG
@:AGI8JDTkAM>8J
;2EH@B>8G7:9F44¨&546>8GIEHNB4j;2@=J
@`<=5M&;247:>@:AÛ;F4>M>&
M9JDTM@`EHJ4@:A@B&Q4^J;2EHNB4AM>8J
;2EH@B>7BVHG2@5~492A@B9F<RGc4VHV
GI;F7:8Vt4`
EH>;FTMEKG924^GI5~46J
;6W:EH>;2T87:;EO;J67:>4@`5&;2EH<=Et646.P7y9F7:;2TM469M>&
G2@B5MTMEKGI;2EKJ7(;F46UB9D7BMEt46>`;&4^G2J4>?;7BVtU`@B9FEO;FTM<!kTMEKGEHG587:92;2VHP
&M4;2@;FTM446EtU`4>MU?7:5;F49F<¶TMEKJDTT87`G;FTM44&w~4^J;+@BAM4>MT7:>8JEt>MU
;2T84>?8<4692EKJ7BVGQ;D7:MEHVHEO;QP@BA+;FTM45M9F@BMVH4<!
G24<=Et·ö7B&;2@`<=7:;I
TM47B<@`M>?;@:A~9246UBMVK7:9FEt^7(;FEt@`>EKGGI46Vt4^J;F46
EKJ7:VHVHP@`>q;2T84k;F9F7BEt>MEH>MUlG24
;R7:VH@B>84BWEO;FT>M@lAM92;2TM4697`hQ8GI;I
<=4>?;FG@`>;2T84;F46GI;G24
;^
AcJ
@B89FG24BW&G2@B<=4@`?N.EH@B8GnN(7:9FEH7:;2EH@B>8G
7:9F45~@`GFG2EtMVH4BWcVtEH´B48G2Et>MU<8VO;FEt5MVH4;29D7:EH>MEH>MUG24
;DGW4¨M7:<=Et>8Et>MU
ãÐUB9D7:58T@`>;FTM4!;24^GQ;M7(;D7MW@B9@B;2TM469R54692<=EKG2G2Et8Vt4
;2T84
;28>MEt>8U`G@`>;FTM4;24^GQ;87(;F7=@`9@B>!7:>!EH>8&45~4>&4>?;N(7:VHEKM7(;FEt@`>
G24
;6S4T87hN`4y7hN`@BEK&46;2TM4^GI4TM46924`WM7BG@`M9A@.J8G7BGn;2@RN(7BVO
EKM7(;F4;2T845~@(n469@:A;FTM49F4U`MVK7:9FEt^7(;2EH@B>!8G2EH>MUR;29D7:EH>MEH>MU87(;F7

ãã

235ñ
ñ
ñ
ñ
ñ


6

ä
¿
ä
ä


6
ñ
ñ

6
ñ
¿
a

e
-
f



~



¼

o
à
õ
ó
ô
«
|
«
«
«
x




õ

Ò
x
Á8

ÁBÄ`\

Á8t]^Ê

ÉB4
³Ä

ÁM

-./

]BÎh4³Ê

À`_&
ÊMH]^ö

]^ÁMß_:Z

]^À&
Ê8
\?ö

Ä8Î(É

ÉMßÀ
Á`ÀB\`ö

ÁM

]`
ÁBÁ`Ê`ö

ÁM

-!/*-
g6i-

7:8Vt4Àzu¡ÆKÇxÈÉÊËÈÍÎpÌFõáÇË)Ë)ÇÏKÇÕeÖÇÏT× ØtÇxÙbËÈ
c}w)w2~{´{}cw
JTy¦cwz.
w)~ø	­Ñ{}wy
¤w2ª{
wy=w2{{}w2¦cw2{}S3}wc
|cw±|=~±{}cwÍµ}ª{\z
y¦c²~e hwÍ®
¦cz
y¦c²~£{}|,{}y=w
y=¦c²~±J|=7w2´{}cw7w2%TJw¶úT~ptª{%T~pcT%
¢Q9~t{}w±ùFw)}9²cyw2¯z
~øw2
{%9|=~|=~¬¶¡e{}wS{%T|~c|=~¬T~pt{}w)ª{\z)yT|=µzT{}|
¶
}
c}w)w2~{
~t|=~5p3}w)~	{}w)|=
y=¦²~cþ{}|,{}yw)
}T²y=wtT{%w2{}
7w2£{}cwKûJü}w
²ý{}w{}w)ª{\3{%x wz
®Væü9ç¯y=w2{{}w2}£®
cw)|T{}|
ö;÷
îCë
w)~¬	­h{}cwSvw)y=w)z2{þy=Í²w2{}
{}w
¤w2}w9cy=|=w; w\z
~px|=~{
{}w)w´}9²w´}w)¦cy={}F¤¡w)~¯{}cw´pT%T²w2{}w2}Fz
}w2
y¦c²~
z%
~w.
~	{%T|~cá{}cw¡3Jw2%99wz)yT|=µzT{}|
²vh£z
7w.H{}cw}w
}9²y=w\{}w)ª{Hw2{}á¤¡cw)~S{}w¡T%9²w.{}w2}yw)T}~w)S®0
®0
yTw)y=w5
ÿ 
îCë
{}w2¡cT{%\w2{}) |=~p9y=y,­	{}wyTª{z
{}wþv
¦cw2{¡3}w£9cy=|=w{
{}cw
y¦c²~Kc}w)w)~	{}©{}cwV7w2%TJw´¶5¤¡cw)~§T%T²w2{}w2}Tyybw«	¦9yp{
}T²y=w{}w2ª{FT{% 
{}wV}w
çx =æ\T}w´Ty=|=w§{
ÿ 
má¾
2ê
%ë
ãMè
ã&è
,A92@`<¹C&r
ãMè
è4^G27B<58Vt4
è4^G27B<=5MVt4
è4^G27B<=5MVt4
è46GF7:<=5MVH4
c4^GQ;
+46GI;
c9D7:EH>
+9D7:EH>
§Í
§Í
§Í
§Í
§Í
§Í
§Í
§Í
7hN.U¬Ã
7hN?UÑÃ
7hN?U¥Ã
7hN.U¬Ã
GF8ö
+jX
À&
]B]
À&
ÁM
]B
Ä
ÉMßÀ
_&
Z`ö
À&
Ä8
À&
Z8ßÎ
Î.
\Mß_
ÊM
\M
Z`ö
ZM
É?À&
]Ä
]^ÊM
]hÀ
]6ÉM
Ê`ö
À&ß_Bö
ÀBÉM
\Mß_
]hÎ&
ÉB\
ÄBÄ

GF8ö
\`ö
Ä8
É`ö
]B
À&H]^ö
ÊM
Z`ö
ZMßÀBö

GF8ö
]^ÀM
Z?ö
Ê`ö
À&
É`ö
Î.
ZMß_Bö
Ä8
Á`ö

G2ö
À&ß_Bö
\`ö
]B
_&
É`ö
ÉM
Á`ö
Î.H]^ö

ÊM
Ä8
\MH]
]hÎ.
]^_&

Á8

]^Á

ÁM
ÁM]
]64
IÎ:ö

Á8t]
É:4
Q_Bö

Á8
Ä`4
³Ä?ö

_MßÎ
_M
]hÀ&
]h_&ßÀ
Ä?ÉM

ÀM]B
\M
ÀM]B
É?À&ßÀ
]^ZM

CMr
SlX
Xç§n²
X²`§r
Í²
7:8Vt4É(uFùw2¦y,{}
w\²K9J~c|,{}¦pcw
w
}w)²
æ9
{}wV
¦~p|=F|=~x®
Àf~b
)i
ÁBÁ:Ä
7BVt@`>M4BÐTM4!4
¨&5~49FEt<=4>?;D7:V924^GI8VO;DGR7:9F4N`49FP5892@`<EKG2Et>MUWn7`G
;FTM4=7:VHUB@B9FEt;2TM<J
VH8GI;2469FGy~@:;2TGI57:9DGI47:>8lMVt@&JD´.PsM7:;F7MW7B>8
46VtEH<=Et>7(;24^G;2TM4>8@BEKGIPRA4^7(;FM924^G?¦7hVH46GFGIVHPB
T84GQ;D7:MEHVtEt;QP;2TM46@B9F4<Æ]7B>8=EO;DGJ
@`92@`VtVK7:9FPJ7B>=4GI4^@`&;I
G2EK&4@BA+GI5~46J
;29D7:VVt4^7:9F>MEt>8U83M@`9EH>8GQ;D7:>8J4BW?;2T84j~@BM>kJ7B>R;246VtV
@`>M4RTM@(ÇA07:97!U`EtN`4>,J
VH8GQ;F49FEt>8UEKG
;;2T84M>M´.>M@(>,@B5M
96
;FEt<R7BVJ
VH8GI;249FEH>MU@B>q7M7:;F7G24
;6W7:>Y46NB46>WcEH>,;2TM4RVH8JD´.EH46GI;
J67BG246G6W(5M9F@(NB4;FT87(;;FTM44^GQ;J
VH8GI;24692EH>MU7`GA@`M>8TM4;FTM4@B
9F4<È<R7:´`46G>M@4¨.58VtEKJ
Et;2VHPR7BGFGIM<=5&;FEt@`>8G7B@`&;;FTM4GIEH<=EtVK7:9FEO;QP
<R7:;29FEO¨i¢@(n46NB49^W:@`>M4GITM@`MVK~47h7:9F4;FT87(;>8@:;4N`49FP
EHVHVT87hNB47=J
VH8GI;249FEH>MU=UB@.@&k46>M@BMU`Tk;F@G27:;2EKGQAP;2TM4~@BM>
S4J@B>8JVt&4.PY9F4<R7B92´.EH>MU;2T87:;A9F@B<
;2TM45~49DG254^J;2EHNB4k@:A
VH467B92>8Et>MUWM;FTMEHGj@B9F´EKGQ8GI;7R46UBEH>M>MEH>MU8jX[A9D7:<=45~49FT87:5G
G2@BVHEKk46>M@BMU`Tk;F@7:VHVt@(Ï@B>M4;F@;FTMEH>M´k@BA+;FTM4PB4;8>87:>8G249F46
?M4^GQ;FEt@`>8G7(;;2TM4!J
@`924@:AjGI;F7:;2EKGQ;FEHJ67:VVt4^7:9F>MEt>8U8WVHEt´`4GF7:<=5MVH4
J@B<=5MVH4
¨&Et;QPBW5M9FEH@B9=´.>M@(Vt4^&UB4`WUB46>M49D7:VHEt^7(;FEt@`>@`M>8MG=7B>8
G2@!@B>SY4RT8@B5~4R;2T87:;@BM9A&;2M9F4R@B9F´sEtVHVJ@B>?;29FEt8&;24=;F@
;FTM46G247:9F467`G
f
:|	)
/0-.io
T84y7B&;2TM@`9FGnUB9D7(;F4
AMVHVHP=7`JD´.>M@(Vt4^&UB4Ã`EH<ÆÂn892´`4A@B9TMEKGEt>&
N(7BVt87BMVH4y7`&N.EHJ4j@`>&EE¨J
MVt;@B5&;FEt<=EH67:;2EH@B>8G6T8EHG@B9F´=7`G
57:92;2EK7:VHVtPRG2M5M5~@B92;246?PN+yCz3JÞ²ÍèÍU`9F7B>`;3jrlC.³Z`\M]6Á.Î:ÀBÊMW
+yCz3²Q£è,UB9D7:>?;cÁBÉ8]6É`ÉBÉBZ7:>y;2TM4L>MEHNB469FG2EO;QPj@:AMS,7BG2TMEH>MU:;F@B>
è\è3U`9F7B>`;À:Ê`\:Ä
ÔDÔ
%T~e
t % 
û9ç9ç
%c9~;ûTçJç
9z%¬9~
 
w3}~|=~øw2z2{%9yVz2y¦cª{}w2}|=~x M~x}¦~;Vv T~p
vx9¦y 

®w2¹xw2}|=²w)~	{}¡
¤¡|=~{}p3{
c{}|=²|=·)|=~Í{}w£z.}|={}w.}|
x{}|²KTy  
w´{
~Ñc}w)w)~	{}w§w2}wJ9z%|=w)7w)Fz)y=¦ª{}w.}|~cKz)y
{}w
®á{}cw~
|=wÍ9cw)h{
{}cw
²KT{}|,¹¯|=V9|Jw)~Ñ|~¬{}cw\z
cw2µ~w¯|=~
ª{%; þcw2
y=¦²~¬cwJx|~cJ) ´cwS7w.%9Jw
¦c~p
Jw2æ)çK}w2y=|=zT{}|
|=w²KTJ~c|={}¦cw
|=w\y=w)7w)y|=þx}w)w)~	{}w¯|=~Ñw9z%Ñz
~c´T{þw9z%Ñ~
y=¦c²~e 5w´z9~Ñw)w\{}p3{þ¦cÑ{
®
	x 
}²K3{}|=7wJ 

}) !#"$&%(')!+*,$&-/.02143!6587 .&9:;<'=7!?>(.076"$&%@%@')!/A,BC %;D$&9+%
wx|,{
T²Sx}|xJwJ#¯\ #hªJI}w)) 
E4FHG
 M*N7!#1
æ6KK2K
w2{}w)½99)/LS 4I 
w2{}w)½99)eæ6KK2K

'O!P$0.Q#.07@A.R9:S
9+')!/A9 H{}w2~pÍvz)|=w)~	{}|,µpzJp9²c}|c9wJT¯´û\wc|,{}|
~; 
¤¡y=½7w)Fw2{F9y  =bûTçJç
~9|w9Kvb =S©¦~cc?© =
¤¡y=½7w))S =
w2y
T~pU¯9y=|=½Pc 
¦c|=~K¦c|~cÍ{}w£~	­xª{
 vxw2z2{%9ye9
ûTçJç 
; ,3RVVVXW.0!%&4"Y;<'=7!%Z7!U>[;<;D$&.!\!T21
²w2{}
C %@')%+!T]^2S
ûæY cûJûJü	 
'aA$&!#"&$.pûb
"_/'O!P$`3!;D$Y1)1
 ;9~¥¡%9c|w9fI 
¦cw2{F9~hF%T|=wJ;æ6Ke7ü
¦w2{
æ8K2eJü
Zd
²pT}|=~cSp3{}|,{}|
~) hg/7 -i.!T1f7R5?j1k%@%'
l
"@;<'=7!cû	=æ6K2	6cxû	æ6ex 
 Wm_$+jf_/'<S=BTnY-.0$0po`')%S
æ8K2bK
T~zTª{}w2
T~zTª{}w2Qæ8K2b2K

;<.'=qY-/;<'=7!c |=y=w2­	 
hw)|=y=r
x;ûTçJç7û
hw)|=y=r
x#t 
 cwþ²¦y,{}|=z)¦c{áy=w)²²Kx QQw)z%~c|
û9çJçJû
{[xæ3	#sþ~c|=7w2}|,{­
®fø9c|=~9{
~e 
zTyQùFw)
xft bT~p¬v| Pc 
T~phvx| û9ç9çxæ)
hw)|=y=r
wT}~
ûTçJçæ
hw)|=y=r
|=~hw)J²w)~	{%3{}|
~5	­Ñ%9~p
²ý¤9y=½) §~
w)w)~eþ ftÍ =uLV|=w2{
 =wx|,{
})[ !#"&$&%w')!*?$&-/.01
{}w2}|=z%eþ v 9~e}w2e
3!8587.9x;<'=7 !x>(.076"$&%@%@')!/ApBC %@;D$&9p%}x
y=¦c²wVæ6	x7p99w)(eJ	6c/e7 Kx
T²Sc}|xJwJ#¯\ #hªJI}w)) 
%9~
hw)|=y=r
 
û9ç9çxæ)
xTt 9~¬vxc| #c 
hw)|=y=r
T~phvx| û9ç9çxæ2
~e 
¤Ty½¥|w.¤
®Kw)z2{%9ySw)J²w)~	{%3{}|
~yJJ9½½
yx
}).;<'
~;þ =áwc|,{
þ HT~pøù|=z%p3%c
l
"Y'=13!;D$Y1)1
'aA$&!#"$!T
B;z;<')%@;<'="Y%{3BMWi{WMB 
®§²KTz.c|=~w
­
|,{
 |s£©¯}w)
æ6K2Kæ
vxyT{}w9Qæ6KKxæ
vxyT{}w9:LS 
y=w3}~|=~KcT{%99w)) 
w2}²KLS p9~}hw)|=y=r
w.}²KS9~hw)|=y=r
xbû9çJç	
xmt 
ûTçJç2	
 F
³
ç2	
²p3}|
®w2z2{%9y;z)y=¦ª{}w2}|=~cK9y=
}|={}c²) ù
ç7ü
çæJ
s~|=7w2}|,{­
~e 
®MøT|=~T{
¦c²|={{}w)
û9ç9ç2	
 h¦cy,{}|z2yT
¦e©vb u\ H9~v| c 
¦h9~¯vxc| ûTçJç2	
:~
w)z.{%9y¡z)y=¦ª{}w2}|=~cc 
~3!;D$&.&!#;<'=7!#21Nj7!656$&.0$&!T"$U7!j79pS
Q#-/;D$&.U')%@'=7! 

9z%e© 9~p

-?)g

Ôc«



236



î
ë

ñ




í
ï



¼







ñ










¼

²





¼


6


6

à
Á
#
]
ä
Ã
Ã
õ
ä
Ã
Ã
õ
õ
õ
Ä
Á
\
\
õ
À
\
õ
Á
õ
Á
Ê
õ
\
Á
É
\
õ
\
õ
\
õ
Ä
É
Ê
õ
\
\
Á
õ
õ
É
õ
\
Ä
É
õ
]
É
õ
É
õ
õ
À
Z
Ä
õ
Ä
É
õ
Á
õ
Ä
õ













í
ï






~


û


8
f
'
d

Ä
Ê
\
Ê
d
õ
õ
õ
õ
õ
õ
õ
]

d

{
}
Ô
x




í
ï
 





í
ï









í
ï


²

í
û
ï


d

í
ï
 





d
 
í
ï


í
ï
¼





í
ï
 

¼



¼
³




í
ï
¼


²







í
ï




³
í
ï
z


~


¼
¼


í
ï
 

~
í
ï
¬{

;ö

{M¬¬
ÚsÔ
Ô,
38@B97:>.PJVt8GI;24692EH>MUb;k7:>8M¨&46=<R7(;F92Et¨W:Et;2TèY&48>M4^7`G
;FTM4Et>8MEHJ67(;2@`9NB46J
;2@`9+@BAJ
VH8GI;249
EH>=GI4^J;2EH@B>=_4&4>8@:;24.P
úÚ;WcÄ
èöWP
W#
Å³W
#&#&#
`é
;2T84R@B92;2TM@`>M@B9F<R7:V<R7(;F92Et¨sA@B9F<=46Et;2T,;2T84R4EHUB4>.N`46J;F@B9DG
&EK7:U
@BA6è,7BGJ@BVHM<=>8GT.8G6Wi
öY0²³;EHG
#&#%#
ènöÄ
4^7BG2Pk;F@kG2TM@(°;2T87:;SUT7=7VW
7B>8
XCY
SUTb=7V6W
3M@`9;Qn@yJ
VH8GQ;F49FEt>8U`G,;ã;¹
;ö
;cö
xzy|{
XqY
44
¨&5M9F46GFGc;FTM4EH9924^GI5~46J
;2EHNB4`ãmæ¹.Et>;2T847BG2EHG&48>M46.Pw
ýç¹cEO;FTlýã8ýb¹~4EH>MU
7`G,
<R7(;F92EKJ
4^G
ýãµ¹
çUo
@BAJ@?4&¨J
EH4>?;FG64;
ýç¹
]6\?ö


æ¹p

ýç¹
Et;2T
<R7(;F92EKJ
4^G
ýã
oÚo
ò=
¸
mn-
;öÉÓÇÍÞÖÆM£¥¶ætæ
kæHæ
Í<@,Æ8£
Ý2£
xzy|{
Ý2£·¢~Ý2£
Ù£
¥Þ0ÙÞÖÆM£:Ý2øD£
¥¤Ûù.Ùy¥ø(ÝÚ/Ë
ætæ
Ç´µ>»¡(¥r1kæHæ
ff6¯
?¿;2TJ
@`Vt8<>@:Aý
;FTM4
3j4>M@B;24.PýZ
%
ènö}Ä
ènö&ýx
XCY
XqY
~
XCY
XCY

Òà
]6Z?ö
À:Á?ö

>g·
+@(W&8G2Et>MU;FTM4T.P?5~@:;FTM46G2EKGW&4T87hNB4
ætæ
æHæ

>g·
6
××

~

£~

À&]hö

XqY

XCY

××

æHæ

XCY
>g·

ætæ

>g·
XCY
>
XCY
kæHæ
GDø(¥r1(¤ÛÞ¿¤0ø(¥MÙø
#£¥¤yÙDÙù&ÚR£ÞAÆ8¡(ÞnÞAÆ8£
1B£D¨¥~£F1tF£
ýãYD£¡(Ù
ø(ÝF£%Ë
ãY¬
&EK7:Uñ2¬
#&#&#
¡ù&¥8¤ÛÞ·¡(ÝëÚ=¡:Þ*Ý¤OìËhÌrÆM£¥­¬

ætæ

¸
mn-
¡:¥61Üt£
Þ(nã2ýã
D£y :¤Û÷(£¥ë
@¤ÛÞÖÆ
]`ã
#%#&#o

ÀBÀ`ö

À:É?ö
À(Ä.ö
Æ8ø(ÜE1
ÀB_`ö

¡
ÞAÆ8£Fø:Ý2£Ú§¦
£ÞnÞÖÆM£Z©ªM«ÿø
ø:Ý/

ætæ

ætæ

]`ã

ãhætæ

ff6¯

TM4J
@`Vt8<>G@:Aý[7:9F4y@`9I;FTM@B>8@B9F<=7BV*TM49F4
A@`924

%
@B9
~4R;2TM4G2EH>MUBMVK7:9N(7BVtM4^G@:ANRkTM46>W
4;
ã
#%#&#o
G28JDT;2T87:;
;2T849F4yEKG7M>MEt;F7B92Pk<=7:;29FEO¨
&EK7:Uñ
À:Ê`ö
#%#&#
C.EH>8J
4kæHæ
n4T87hN`4;FT87(;
kætæ
7B>8;FTM49F4
A@`924
XCY
À:Ê`öj4R7:VKGI@T87hNB4;2T87:;¬
/3M9F@B<
7:>8
U°]
A@B97BVtV]
TMEKJDTEH<=5MVHEt4^G,¬
]Bã
"jà
#%#&#o
+@B;247BVHG2@;2T87:;EtAæHæ
kætæ
WM;2T84>.Pk;FTM4<§7B8JDT.P`
æ¹³ætæ
C&JDT.7:92;2yEt>M4^?87:VHEO;QPætæ
æ0
æ¹¿æHæ
¸
¤yÙDÙù&Ú=£ÞÖÆM¡:ÞÞÖÆM£µGFø:¥61:¤ÛÞ*¤0ø:¥MÙø
ÞÖÆM£Dø(ÝF£
Ú¦µÆMø:ÜE1
m-
ýãRãµ¹0ãýç¹*ã
¡(¥r1=Üt£ÞnãMýã
ãæ¹¡(¥61
D£¡(Ù1`£z¨¥~£F1ND£&B
ø(ÝF£%Ë/ÌrÆM£¥
oc~
õ¯®
ff6¯
4;
%
æHæ
4;8GVH@?@`´k7(;;FTM489DGQ;;F49F<ÿ@:A+;2TM4MEQw49F4>8J47:~@(NB4`
¶åð
±a±
±k±²
±k±
±a±²
³{´f³µ
³µ
³´


ÂPN.EH9I;FM4@BA;2TM4GIEH>MUB8VH7B9N(7:VHM4&4^J
@`<5~@`G2Et;2EH@B>EH>
ÀBÊ`ö
J7B>~49FEO;2;24>7`G
åº
¬(>ò
Et;2T
åºJ
@`<=5MVt4¨kM>MEt;F7B92Pk<=7:;29FEHJ46G6TM49F4
A@`924
æHæ
#&#&#


·

À:\`ö
À:Z`ö
ÉBÁ`ö

	xæ

H¸

À`Î:ö

]^ö

³µ

%
&EK7:Uñ2¬
ãY¬
&EK7:U8ñ2¬
&EK7:Uñ2¬
ã&¬

öæHæ
öæHæ
ÉM]^ö7B>8Vt46<<R7=Én4@`&;F7BEt>

#&#%#
#&#%#
æHæ

É`ÀBö
ÉBÉ`ö
É:Ä?ö
É`_Bö
ÉBÊ`ö

ã&¬

ætæ
ætæ

ætæ
ætæ

æHæ

ætæ

æHæ

ætæ

ætæ

æHæ

æHæ

æHæ

æHæ

æHæ

ætæ

TM46>WM8G2Et>8U4^?87(;FEt@`>
æHæ

æHæ

LG2EH>MU=>M@(Ï4^`7(;2EH@B>

ætæ

ætæ

æHæ

XCY
õjo
É`Á`ö7B@(N`4j4@B&;D7:EH>
ætæ

æHæ

ætæ

É?Î:ö
ÉB\`ö

ætæ

ÉBZ`ö
h¼
Ä`Á`ö
Ä8]^ö
ÉÐÉ;FTM45M9F@?@BA

õ½

æHæ
õ
o
oc~
oc~

]^ö
]hö

7:>
XG
@:A;2T84;2TM46@B9F4<ÆEKG8>MEKGIT846

æHæ

µ0æ¹³æHæ

237

¬
©

X
=
X
X
à
í
"

X
à
¼
Ä

Ä
>
X
à
]
)

X
õ
à
)
è
à
õ


ã

'
õ
à
 
>

Ä
X
0
õ

)
X
õ
à
õ
)
 
>


X
à
à
ý
à
ý
ý
¹
à
õ


#
õ
"

É
Ò
"

X
>
ó

Ä
X
0
õ

)
X
à
>
ó

ý
0

X

0
õ

)
X
õ
à
>
ó

'
ó

Y

ý
"

X
õ
á
>
ó

>
ó

Y

ý
"

X



>
ó

'
ó

Y

ý
"

X


¾
1

õ
>
ó

>
ó

Y

ý
"

X
~

"


>
ó


X
~
Ç


"


>
ó


X
õ
]
)
>
ó

Y

ý
"
X

ö
~
Ç
õ

 
o
)
>
ó

>
ó

Y

ý
"
X
¢
~
Ç
õ
à

>
"

~
Ç
õ



Ã


ý

ý
0

ý
à

å
0

"

"
"
ã
¬
"
>
ò

å

õ

å

"
X
U
]
)
Ò

à
Ë
ý
0
ý
à

à

ý
0

ý
~

0


ý
0

ý
à

)

0


X
à

å
"

å
0
"

ý
0

ý

å
"
à

)

"

ã
"
>
ò
õ
"

É
Ò
 
>


"
X
É
Ò

"
X
É
Ò
õ
"
X
à
]
)

"
X

å

å

"
X
)
Ò
à

"

"


Ò
Ò

#
?



ý
¹
Ò


0

¹
"

á
o
)
"
Ò
õ

0

¹

à
ý
0
ý
¹

õ
à

ý
0

ý
¹
~

0

¹

õ
á
°
°
°

ý
0

ý
¹

)

0

¹

°
°
°
õ
²










³


ð



¹



í
ï
õ

ý

ý
à

å
Î

"
ã

õ

å
Î
ã


ý
0

ý
¹

X
"
"
à

å
0
º

"
ã
¬
>
ò

å
0
Î

ý
¹

X
"
"
õ
à

"
ã
¬
>
ò

å
0
Î

ý
¹

X
"
"
õ
á
õ
]
)
Ò

å
0
Î

ý
¹

X
"
"
õ
à
õ
]
)
Ò

ý
¹

X
"
"
õ
õ

ý
0

ý
¹
"

á
õ
]
)
Ò
ö
>
ó


ý
¹

X
"
"
õ
á
õ
]
)
Ò
ö
)
Ò
ö
õ
õ

0

¹
"

á
»

ý
0

ý
¹

)

0

¹
"
õ
á
õ
]
)
Ò
ö
)
Ò
ö
)
Ò
ö
"
õ
á
o
)
õ
®
"
Ò
õ
»
à
]
)

>
"

õ
®
"

o
Approximate Inference for Inﬁnite Contingent Bayesian Networks

Brian Milch, Bhaskara Marthi, David Sontag, Stuart Russell, Daniel L. Ong and Andrey Kolobov

Computer Science Division

University of California

Berkeley, CA 94704

fmilch,bhaskara,russell,dsontag,dlong,karaya1g@cs.berkeley.edu

Abstract

In many practical problems—from tracking air-
craft based on radar data to building a bibli-
ographic database based on citation lists—we
want to reason about an unbounded number of
unseen objects with unknown relations among
them. Bayesian networks, which deﬁne a ﬁxed
dependency structure on a ﬁnite set of variables,
are not the ideal representation language for this
task. This paper introduces contingent Bayesian
networks (CBNs), which represent uncertainty
about dependencies by labeling each edge with
a condition under which it is active. A CBN
may contain cycles and have inﬁnitely many vari-
ables. Nevertheless, we give general conditions
under which such a CBN deﬁnes a unique joint
distribution over its variables. We also present a
likelihood weighting algorithm that performs ap-
proximate inference in ﬁnite time per sampling
step on any CBN that satisﬁes these conditions.

1 Introduction

One of the central tasks an intelligent agent must perform is
to make inferences about the real-world objects that under-
lie its observations. This type of reasoning has a wide range
of practical applications, from tracking aircraft based on
radar data to building a bibliographic database based on ci-
tation lists. To tackle these problems, it makes sense to use
probabilistic models that represent uncertainty about the
number of underlying objects, the relations among them,
and the mapping from observations to objects.

Over the past decade, a number of probabilistic model-
ing formalisms have been developed that explicitly repre-
sent objects and relations. Most work has focused on sce-
narios where, for any given query, there is no uncertainty
about the set of relevant objects. In extending this line of
work to unknown sets of objects, we face a difﬁculty: un-
less we place an upper bound on the number of underlying

TrueColorn

BallDrawnk = n

N

ObsColork

BallDrawnk

K

Figure 1: A graphical model (with plates representing repeated
elements) for the balls-and-urn example. This is a BN if we dis-
regard the labels BallDrawnk = n on the edges TrueColorn !
ObsColork for k 2 f1; : : : ; Kg, n 2 f1; 2; : : :g. With the labels,
it is a CBN.

objects, the resulting model has inﬁnitely many variables.
We have developed a formalism called BLOG (Bayesian
LOGic) in which such inﬁnite models can be deﬁned con-
cisely [7]. However, it is not obvious under what conditions
such models deﬁne probability distributions, or how to do
inference on them.

Bayesian networks (BNs) with inﬁnitely many variables
are actually quite common: for instance, a dynamic BN
with time running inﬁnitely into the future has inﬁnitely
many nodes. These common models have the property that
each node has only ﬁnitely many ancestors. So for ﬁnite
sets of evidence and query variables, pruning away “bar-
ren” nodes [15] yields a ﬁnite BN that is sufﬁcient for an-
swering the query. However, generative probability models
with unknown objects often involve inﬁnite ancestor sets,
as illustrated by the following stylized example from [13].
Example 1. Suppose an urn contains some unknown num-
ber of balls N, and suppose our prior distribution for N
assigns positive probability to every natural number. Each
ball has a color—say, black or white—chosen indepen-
dently from a ﬁxed prior. Suppose we repeatedly draw a
ball uniformly at random, observe its color, and return it
to the urn. We cannot distinguish two identically colored
balls from each other. Furthermore, we have some (known)
probability of making a mistake in each color observation.

238¥
¥
¥
¥
Given our observations, we might want to predict the total
number of balls in the urn, or solve the identity uncertainty
problem: computing the posterior probability that (for ex-
ample) we drew the same ball on our ﬁrst two draws.

Fig. 1 shows a graphical model for this example. There is
an inﬁnite set of variables for the true colors of the balls;
each TrueColorn variable takes the special value null when
N < n. Each BallDrawnk variable takes a value between 1
and N, indicating the ball drawn on draw k. The ObsColork
variable then depends on TrueColor(BallDrawnk). In this BN,
all the inﬁnitely many TrueColorn variables are ancestors
of each ObsColork variable. Thus, even if we prune barren
nodes, we cannot obtain a ﬁnite BN for computing the pos-
terior over N. The same problem arises in real-world iden-
tity uncertainty tasks, such as resolving coreference among
citations that refer to some underlying publications [10].

Bayesian networks also fall short in representing scenarios
where the relations between objects or events—and thus
the dependencies between random variables—are random.
Example 2. Suppose a hurricane is going to strike two
cities, Alphatown and Betaville, but it is not known which
city will be hit ﬁrst. The amount of damage in each city de-
pends on the level of preparations made in each city. Also,
the level of preparations in the second city depends on the
amount of damage in the ﬁrst city. Fig. 2 shows a model for
this situation, where the variable F takes on the value A or
B to indicate whether Alphatown or Betaville is hit ﬁrst.

In this example, suppose that we have a good estimate of
the distribution for preparations in the ﬁrst city, and of the
conditional probability distribution (CPD) for preparations
in the second city given damage in the ﬁrst. The obvious
graphical model to draw is the one in Fig. 2, but it has a
ﬁgure-eight-shaped cycle. Of course, we can construct a
BN for the intended distribution by choosing an arbitrary
ordering of the variables and including all necessary edges
to each variable from its predecessors. Suppose we use the
ordering F; PA; DA; PB; DB. Then P (PAjF = A) is easy
to write down, but to compute P (PAjF = B) we need to
sum out PB and DB. There is no acyclic BN that reﬂects
our causal intuitions.

Using a high-level modeling language, one can represent

F

F=B

F=A

PB

DB

PA

DA

Figure 2: A cyclic BN for the hurricane scenario. P stands for
preparations, D for damage, A for Alphatown, B for Betaville,
and F for the city that is hit ﬁrst.

scenarios such as those in Figs. 1 and 2 in a compact and
natural way. However, as we have seen, the BNs corre-
sponding to such models may contain cycles or inﬁnite an-
cestor sets. The assumptions of ﬁniteness and acyclicity are
fundamental not just for BN inference algorithms, but also
for the standard theorem that every BN deﬁnes a unique
joint distribution.

Our approach to such models is based on the notion of
context-speciﬁc independence (CSI) [1]. In the balls-and-
urn example, in the context BallDrawnk = n, ObsColork has
only one other ancestor — TrueColorn. Similarly, the BN
in Fig. 2 is acyclic in the context F = A and also in the con-
text F = B. To exploit these CSI properties, we deﬁne two
generalizations of BNs that make CSI explicit. The ﬁrst
is partition-based models (PBMs), where instead of spec-
ifying a set of parents for each variable, one speciﬁes an
arbitrary partition of the outcome space that determines the
variable’s CPD. In Sec. 2, we give an abstract criterion that
guarantees that a PBM deﬁnes a unique joint distribution.

To prove more concrete results, we focus in Sec. 3 on
the special case of contingent Bayesian networks (CBNs):
possibly inﬁnite BNs where some edges are labeled with
conditions. CBNs combine the use of decision trees for
CPDs [1] with the idea of labeling edges to indicate when
they are active [3]. In Sec. 3, we provide general conditions
under which a contingent BN deﬁnes a unique probability
distribution, even in the presence of cycles or inﬁnite an-
cestor sets. In Sec. 4 we explore the extent to which results
about CBNs carry over to the more general PBMs. Then
in Sec. 5 we present a sampling algorithm for approximate
inference in contingent BNs. The time required to generate
a sample using this algorithm depends only on the size of
the context-speciﬁcally relevant network, not the total size
of the CBN (which may be inﬁnite). Experimental results
for this algorithm are given in Sec. 6. We omit proofs for
reasons of space; the proofs can be found in our technical
report [8].

2 Partition-based models

We assume a set V of random variables, which may
be countably inﬁnite. Each variable X has a domain
dom (X); we assume in this paper that each domain is at
most countably inﬁnite. The outcome space over which we
would like to deﬁne a probability measure is the product
space › , £(X 2 V)dom (X). An outcome ! 2 › is an as-
signment of values to all the variables; we write X(!) for
the value of X in !.

An instantiation (cid:190) is an assignment of values to a subset
of V. We write vars ((cid:190)) for the set of variables to which
(cid:190) assigns values, and (cid:190)X for the value that (cid:190) assigns to a
variable X 2 vars ((cid:190)). The empty instantiation is denoted
?. An instantiation (cid:190) is said to be ﬁnite if vars ((cid:190)) is ﬁ-
nite. The completions of (cid:190), denoted comp((cid:190)), are those

239U

U=0

U=1

V

X

W

Figure 3: A simple contingent BN.

outcomes that agree with (cid:190) on vars ((cid:190)):

comp((cid:190)) , f! 2 › : 8X 2 vars ((cid:190)) ; X(!) = (cid:190)X g

If (cid:190) is a full instantiation — that is, vars ((cid:190)) = V — then
comp((cid:190)) consists of just a single outcome.

To motivate our approach to deﬁning a probability measure
on ›, consider the BN in Fig. 3, ignoring for now the la-
bels on the edges. To completely specify this model, we
would have to provide, in addition to the graph structure,
a conditional probability distribution (CPD) for each vari-
able. For example, assuming the variables are binary, the
CPD for X would be a table with 8 rows, each correspond-
ing to an instantiation of X’s three parents. Another way of
viewing this is that X’s parent set deﬁnes a partition of ›
where each CPT row corresponds to a block (i.e., element)
of the partition. This may seem like a pedantic rephrasing,
but partitions can expose more structure in the CPD. For
example, suppose X depends only on V when U = 0 and
only on W when U = 1. The tabular CPD for X would
still be the same size, but now the partition for X only has
four blocks: comp(U = 0; V = 0), comp(U = 0; V = 1),
comp(U = 1; W = 0), and comp(U = 1; W = 1).
Deﬁnition 1. A partition-based model ¡ over V consists of

† for each X 2 V, a partition ⁄¡
X of › where we write
‚¡
X (!) to denote the block of the partition that the out-
come ! belongs to;
† for each X 2 V and block ‚ 2 ⁄¡
tribution p¡(Xj‚) over dom (X).

X, a probability dis-

A PBM deﬁnes a probability distribution over ›. If V is
ﬁnite, this distribution can be speciﬁed as a product expres-
sion, just as for an ordinary BN:

P (!) , Y

X 2 V

p¡(X(!)j‚¡

X (!))

(1)

Unfortunately, this equation becomes meaningless when
V is inﬁnite, because the probability of each outcome !
will typically be zero. A natural solution is to deﬁne the
probabilities of ﬁnite instantiations, and then rely on Kol-
mogorov’s extension theorem (see, e.g., [2]) to ensure that
we have deﬁned a unique distribution over outcomes. But
Eq. 1 relies on having a full outcome ! to determine which
CPD to use for each variable X.

How can we write a similar product expression that in-
volves only a partial instantiation? We need the notion of a
partial instantiation supporting a variable.
Deﬁnition 2. In a PBM ¡, an instantiation (cid:190) supports
a variable X if there is some block ‚ 2 ⁄¡
X such that
comp((cid:190)) (cid:181) ‚. In this case we write ‚¡
X ((cid:190)) for the unique
element of ⁄¡

X that has comp((cid:190)) as a subset.

Intuitively, (cid:190) supports X if knowing (cid:190) is enough to tell
us which block of ⁄¡
X we’re in, and thus which CPD to
use for X.
In Fig. 3, (U = 0; V = 0) supports X, but
(U = 1; V = 0) does not. In an ordinary BN, any instan-
tiation of the parents of X supports X.

An instantiation (cid:190) is self-supporting if every X 2 vars ((cid:190))
is supported by (cid:190). In a BN, if U is an ancestral set (a set
of variables that includes all the ancestors of its elements),
then every instantiation of U is self-supporting.
Deﬁnition 3. A probability measure P over V satisﬁes a
PBM ¡ if for every ﬁnite, self-supporting instantiation (cid:190):

P (comp((cid:190))) = Y

X 2 vars((cid:190))

p¡((cid:190)X j‚¡

X ((cid:190)))

(2)

A PBM is well-deﬁned if there is a unique probability mea-
sure that satisﬁes it. One way a PBM can fail to be well-
deﬁned is if the constraints speciﬁed by Eq. 2 are incon-
sistent: for instance, if they require that the instantiations
(X = 1; Y = 1) and (X = 0; Y = 0) both have probability
0.9. Conversely, a PBM can be satisﬁed by many distribu-
tions if, for example, the only self-supporting instantiations
are inﬁnite ones — then Def. 3 imposes no constraints.

When can we be sure that a PBM is well-deﬁned? First,
recall that a BN is well-deﬁned if it is acyclic, or equiv-
alently, if its nodes have a topological ordering. Thus, it
seems reasonable to think about numbering the variables in
a PBM. A numbering of V is a bijection … from V to some
preﬁx of N (this will be a proper preﬁx if V is ﬁnite, and
the whole set N if V is countably inﬁnite). We deﬁne the
predecessors of a variable X under … as:

Pred…[X] , fU 2 V : …(U ) < …(X)g

Note that since each variable X is assigned a ﬁnite number
…(X), the predecessor set Pred…[X] is always ﬁnite.

One of the purposes of PBMs is to handle cyclic scenarios
such as Example 2. Thus, rather than speaking of a single
topological numbering for a model, we speak of a support-
ive numbering for each outcome.
Deﬁnition 4. A numbering … is a supportive numbering
for an outcome ! if for each X 2 V,
the instantiation
Pred…[X](!) supports X.
Theorem 1. A PBM ¡ is well-deﬁned if, for every outcome
! 2 ›, there exists a supportive numbering …!.

240The converse of this theorem is not true: a PBM may hap-
pen to be well-deﬁned even if some outcomes do not have
supportive numberings. But more importantly, the require-
ment that each outcome have a supportive numbering is
very abstract. How could we determine whether it holds
for a given PBM? To answer this question, we now turn to
a more concrete type of model.

3 Contingent Bayesian networks

Contingent Bayesian networks (CBNs) are a special case
of PBMs for which we can deﬁne more concrete well-
deﬁnedness criteria, as well as an inference algorithm. In
Fig. 3 the partition was represented not as a list of blocks,
but implicitly by labeling each edge with an event. The
meaning of an edge from W to X labeled with an event E,
which we denote by (W ! X j E), is that the value of W
may be relevant to the CPD for X only when E occurs. In
Fig. 3, W is relevant to X only when U = 1.

Using the deﬁnitions of V and › from the previous section,
we can deﬁne a CBN structure as follows:
Deﬁnition 5. A CBN structure G is a directed graph where
the nodes are elements of V and each edge is labeled with
a subset of ›.

In our diagrams, we leave an edge blank when it is labeled
with the uninformative event ›. An edge (W ! X j E) is
said to be active given an outcome ! if ! 2 E, and active
given a partial instantiation (cid:190) if comp((cid:190)) (cid:181) E. A variable
W is an active parent of X given (cid:190) if an edge from W to
X is active given (cid:190).

Just as a BN is parameterized by specifying CPTs, a CBN is
parameterized by specifying a decision tree for each node.
Deﬁnition 6. A decision tree T is a directed tree where
each node is an instantiation (cid:190), such that:

† the root node is ?;
† each non-leaf node (cid:190) splits on a variable X T
that the children of (cid:190) are f((cid:190); X T
dom¡X T

(cid:190) ¢g.

(cid:190) such
: x 2

(cid:190) = x)

U=1

U=0

W=1

W=0

V=1

V=0

(a)

V=1

V=0

(b)

Figure 4: Two decision trees for X in Fig. 3. Tree (a) respects
the CBN structure, while tree (b) does not.

Two decision trees are shown in Fig. 4. If a node splits on
a variable that has inﬁnitely many values, then it will have

inﬁnitely many children. This deﬁnition also allows a de-
cision tree to contain inﬁnite paths. However, each node
in the tree is a ﬁnite instantiation, since it is connected to
the root by a ﬁnite path. We will call a path truncated if
it ends with a non-leaf node. Thus, a non-truncated path
either continues inﬁnitely or ends at a leaf. An outcome !
matches a path (cid:181) if ! is a completion of every node (in-
stantiation) in the path. The non-truncated paths starting
from the root are mutually exclusive and exhaustive, so a
decision tree deﬁnes a partition of ›.
Deﬁnition 7. The partition ⁄T deﬁned by a decision tree
T consists of a block of the form f! 2 › : ! matches (cid:181)g
for each non-truncated path (cid:181) starting at the root of T .

So for each variable X, we specify a decision tree TX, thus
deﬁning a partition ⁄X , ⁄(TX ). To complete the param-
eterization, we also specify a function pB(X = xj‚) that
maps each ‚ 2 ⁄X to a distribution over dom (X). How-
ever, the decision tree for X must respect the CBN structure
in the following sense.
Deﬁnition 8. A decision tree T respects the CBN structure
G at X if for every node (cid:190) 2 T that splits on a variable W ,
there is an edge (W ! X j E) in G that is active given (cid:190).

For example, tree (a) in Fig. 4 respects the CBN structure
of Fig. 3 at X. However, tree (b) does not: the root instan-
tiation ? does not activate the edge (V ! X j U = 0), so
it should not split on V .
Deﬁnition 9. A contingent Bayesian network (CBN) B
over V consists of a CBN structure G B, and for each vari-
able X 2 V:

† a decision tree T B
partition ⁄B
X );
X
† for each block ‚ 2 ⁄B
pB(Xj‚) over dom (X).

, ⁄(T B

X that respects GB at X, deﬁning a

X, a probability distribution

It is clear that a CBN is a kind of PBM, since it deﬁnes a
partition and a conditional probability distribution for each
variable. Thus, we can carry over the deﬁnitions from the
previous section of what it means for a distribution to sat-
isfy a CBN, and for a CBN to be well-deﬁned.

We will now give a set of structural conditions that ensure
that a CBN is well-deﬁned. We call a set of edges in G
consistent if the events on the edges have a non-empty in-
tersection: that is, if there is some outcome that makes all
the edges active.
Theorem 2. Suppose a CBN B satisﬁes the following:

(A1) No consistent path in G B forms a cycle.
(A2) No consistent path in G B forms an inﬁnite reced-
ing chain X1 ˆ X2 ˆ X3 ˆ ¢ ¢ ¢ .
(A3) No variable X 2 V has an inﬁnite, consistent set
of incoming edges in GB.

Then B is well-deﬁned.

241A CBN that satisﬁes the conditions of Thm. 2 is said to be
structurally well-deﬁned. If a CBN has a ﬁnite set of vari-
ables, we can check the conditions directly. For instance,
the CBN in Fig. 2 is structurally well-deﬁned: although it
contains a cycle, the cycle is not consistent.

The balls-and-urn example (Fig. 1) has inﬁnitely many
nodes, so we cannot write out the CBN explicitly. How-
ever, it is clear from the plates representation that this
CBN is structurally well-deﬁned as well:
there are no
cycles or inﬁnite receding chains, and although each
ObsColork node has inﬁnitely many incoming edges, the
labels BallDrawnk = n ensure that exactly one of these
edges is active in each outcome.
In [8], we discuss the
general problem of determining whether the inﬁnite CBN
deﬁned by a high-level model is structurally well-deﬁned.

H

GB=0

GA=0

GA

GB

GA

GA:

GB:

GB=1

GB=0

GA=1

GA=0

0.9

H=1

H=0

0.9

H=1

H=0

0.9

0.1

0.1

0.9

GA:

GB:

H=1

H=0

H=1

H=0

H

H=1

H=0

0.9

GB=1

GB=0

GA=1

GA=0
0.9

GB

0.9

0.1

0.9

0.1

4 CBNs as implementations of PBMs

Figure 5: Two CBNs for Ex. 3, with decision trees and probabil-
ities for GA and GB.

In a PBM, we specify an arbitrary partition for each vari-
able; in CBNs, we restrict ourselves to partitions generated
by decision trees. But given any partition ⁄, we can con-
struct a decision tree T that yields a partition at least as
ﬁne as ⁄—that is, such that each block ‚ 2 ⁄T is a subset
of some ‚0 2 ⁄. In the worst case, every path starting at the
root in T will need to split on every variable. Thus, every
PBM is implemented by some CBN, in the following sense:
Deﬁnition 10. A CBN B implements a PBM ¡ over the
same set of variables V if, for each variable X 2 V, each
block ‚ 2 ⁄B
X, and
pB(Xj‚) = p¡(Xj‚0).
Theorem 3. If a CBN B implements a PBM ¡ and B is
structurally well-deﬁned, then ¡ is also well-deﬁned, and
B and ¡ are satisﬁed by the same unique distribution.

X is a subset of some block ‚0 2 ⁄¡

Thm. 3 gives us a way to show that a PBM ¡ is well-
deﬁned: construct a CBN B that implements ¡, and then
use Thm. 2 to show that B is structurally well-deﬁned.
However, the following example illustrates a complication:
Example 3. Consider predicting who will go to a weekly
book group meeting. Suppose it is usually Bob’s responsi-
bility to prepare questions for discussion, but if a historical
ﬁction book is being discussed, then Alice prepares ques-
tions. In general, Alice and Bob each go to the meeting
with probability 0.9. However, if the book is historical ﬁc-
tion and Alice isn’t going, then the group will have no dis-
cussion questions, so the probability that Bob bothers to go
is only 0.1. Similary, if the book is not historical ﬁction and
Bob isn’t going, then Alice’s probability of going is 0.1. We
will use H, GA and GB to represent the binary variables
“historical ﬁction”, “Alice goes”, and “Bob goes”.

This scenario is most naturally represented by a PBM. The
probability that Bob goes is 0.1 given ((H = 1)^(GA = 0))
and 0.9 otherwise, so the partition for GB has two blocks.
The partition for GA has two blocks as well.

The CBNs in Fig. 5 both implement this PBM. There are
no decision trees that yield exactly the desired partitions for
GA and GB: the trees in Fig. 5 yield three blocks instead
of two. Because the trees on the two sides of the ﬁgure
split on the variables in different orders, they respect CBN
structures with different labels on the edges. The CBN on
the left has a consistent cycle, while the CBN on the right
is structurally well-deﬁned.

Thus, there may be multiple CBNs that implement a given
PBM, and it may be that some of these CBNs are struc-
turally well-deﬁned while others are not. Even if we are
given a well-deﬁned PBM, it may be non-trivial to ﬁnd a
structurally well-deﬁned CBN that implements it. Thus,
algorithms that apply to structurally well-deﬁned CBNs —
such as the one we deﬁne in the next section — cannot be
extended easily to general PBMs.

5 Inference

In this section we discuss an approximate inference al-
gorithm for CBNs. To get information about a given
CBN B, our algorithm will use a few “black box” ora-
cle functions. The function GET-ACTIVE-PARENT(X; (cid:190))
returns a variable that is an active parent of X given
(cid:190) but is not already included in vars ((cid:190)).
It does this
taking the branch
X ,
by traversing the decision tree T B
associated with (cid:190)U when the tree splits on a variable
U 2 vars ((cid:190)), until it reaches a split on a variable not in-
cluded in vars ((cid:190)). If there is no such variable — which
means that (cid:190) supports X — then it returns null. We
also need the function COND-PROB(X; x; (cid:190)), which re-
turns pB(X = xj(cid:190)) whenever (cid:190) supports X, and the func-
tion SAMPLE-VALUE(X; (cid:190)), which randomly samples a
value according to pB(Xj(cid:190)).
Our inference algorithm is a form of likelihood weight-

242function CBN-LIKELIHOOD-WEIGHTING(Q, e, B, N )

returns an estimate of P (Qje)
inputs: Q, the set of query variables

e, evidence speciﬁed as an instantiation
B, a contingent Bayesian network
N , the number of samples to be generated

W ˆ a map from dom (Q) to real numbers, with values

lazily initialized to zero when accessed

for j = 1 to N do

(cid:190), w ˆ CBN-WEIGHTED-SAMPLE(Q, e, B)
W[q] ˆ W[q] + w where q = (cid:190)Q

return NORMALIZE(W[Q])

function CBN-WEIGHTED-SAMPLE(Q, e, B)

returns an instantiation and a weight

(cid:190) ˆ ?; stack ˆ an empty stack; w ˆ 1
loop

if stack is empty

if some X in (Q [ vars (e)) is not in vars ((cid:190))

PUSH(X , stack)

else

return (cid:190), w

while X on top of stack is not supported by (cid:190)

V ˆ GET-ACTIVE-PARENT(X , (cid:190))
push V on stack

X ˆ POP(stack)
if X in vars (e)

x ˆ eX
w ˆ w £ COND-PROB(X , x , (cid:190))

else

x ˆ SAMPLE-VALUE(X , (cid:190))

(cid:190) ˆ ((cid:190), X = x )

the algorithm begins by pushing N onto the stack. Since
N (which has no parents) is supported by ?, it is im-
mediately removed from the stack and sampled. Next,
the ﬁrst evidence variable ObsColor1 is pushed onto the
stack. The active edge into ObsColor1 from BallDrawn1
is traversed, and BallDrawn1 is sampled immediately be-
cause it is supported by (cid:190) (which now includes N). The
edge from TrueColorn (for n equal to the sampled value of
BallDrawn1) to ObsColor1 is now active, and so TrueColorn
is sampled as well. Now ObsColor1 is ﬁnally supported by
(cid:190), so it is removed from the stack and instantiated to its
observed value. This process is repeated for all the obser-
vations. The resulting sample will get a high weight if the
sampled true colors for the balls match the observed colors.

Intuitively, this algorithm is the same as likelihood weight-
ing, in that we sample the variables in some topological or-
der. The difference is that we sample only those variables
that are needed to support the query and evidence variables,
and we do not bother sampling any of the other variables
in the CBN. Since the weight for a sample only depends
on the conditional probabilities of the evidence variables,
sampling additional variables would have no effect.
Theorem 4. Given a structurally well-deﬁned CBN B,
a ﬁnite evidence instantiation e, a ﬁnite set Q of query
variables, and a number of samples N,
the algorithm
CBN-LIKELIHOOD-WEIGHTING in Fig. 6 returns an es-
timate of the posterior distribution P (Qje) that converges
with probability 1 to the correct posterior as N ! 1. Fur-
thermore, each sampling step takes a ﬁnite amount of time.

Figure 6: Likelihood weighting algorithm for CBNs.

6 Experiments

ing. Recall that the likelihood weighting algorithm for
BNs samples all non-evidence variables in topological or-
der, then weights each sample by the conditional probabil-
ity of the observed evidence [14]. Of course, we cannot
sample all the variables in an inﬁnite CBN. But even in a
BN, it is not necessary to sample all the variables: the rele-
vant variables can be found by following edges backwards
from the query and evidence variables. We extend this no-
tion to CBNs by only following edges that are active given
the instantiation sampled so far. At each point in the algo-
rithm (Fig. 6), we maintain an instantiation (cid:190) and a stack
of variables that need to be sampled. If the variable X on
the top of the stack is supported by (cid:190), we pop X off the
stack and sample it. Otherwise, we ﬁnd a variable V that is
an active parent of X given (cid:190), and push V onto the stack.
If the CBN is structurally admissible, this process termi-
nates in ﬁnite time: condition (A1) ensures that we never
push the same variable onto the stack twice, and conditions
(A2) and (A3) ensure that the number of distinct variables
pushed onto the stack is ﬁnite.

As an example, consider the balls-and-urn CBN (Fig. 1).
If we want to query N given some color observations,

We ran two sets of experiments using the likelihood weight-
ing algorithm of Fig. 6. Both use the balls and urn setup
from Ex. 1. The ﬁrst experiment estimates the number of
balls in the urn given the colors observed on 10 draws; the
second experiment is an identity uncertainty problem. In
both cases, we run experiments with both a noiseless sen-
sor model, where the observed colors of balls always match
their true colors, and a noisy sensor model, where with
probability 0.2 the wrong color is reported.

The purpose of these experiments is to show that inference
over an inﬁnite number of variables can be done using a
general algorithm in ﬁnite time. We show convergence of
our results to the correct values, which were computed by
enumerating equivalence classes of outcomes with up to
100 balls (see [8] for details). More efﬁcient sampling al-
gorithms for these problems have been designed by hand
[9]; however, our algorithm is general-purpose, so it needs
no modiﬁcation to be applied to a different domain.

Number of balls:
In the ﬁrst experiment, we are predict-
ing the total number of balls in the urn. The prior over the
number of balls is a Poisson distribution with mean 6; each

243y
t
i
l
i

b
a
b
o
r
P

y
t
i
l
i

b
a
b
o
r
P

 0.18

 0.16

 0.14

 0.12

 0.1

 0.08

 0.06

 0.04

 0.02

 0

 0.18

 0.16

 0.14

 0.12

 0.1

 0.08

 0.06

 0.04

 0.02

 0

 2

 4

 8

 10
 6
Number of Balls

 12

 14

 2

 4

 8

 10
 6
Number of Balls

 12

 14

y
t
i
l
i

b
a
b
o
r
P

y
t
i
l
i

b
a
b
o
r
P

 0.08

 0.07

 0.06

 0.05

 0.04

 0.03

 0.02

 0.01

 0

 0

 0.08

 0.07

 0.06

 0.05

 0.04

 0.03

 0.02

 0.01

 0

 0

 1e+06

 2e+06

 3e+06

 4e+06

 5e+06

Number of Samples

 1e+06

 2e+06

 3e+06

 4e+06

 5e+06

Number of Samples

Figure 7: Posterior distributions for the total number of balls
given 10 observations in the noise-free case (top) and noisy case
(bottom). Exact probabilities are denoted by ’£’s and connected
with a line; estimates from 5 sampling runs are marked with ’+’s.

Figure 8: Probability that N = 2 given 10 observations (5 black,
5 white) in the noise-free case (top) and noisy case (bottom).
Solid line indicates exact value; ’+’s are values computed by 5
sampling runs at intervals of 100,000 samples.

ball is black with probability 0.5. The evidence consists
of color observations for 10 draws from the urn: ﬁve are
black and ﬁve are white. For each observation model, ﬁve
independent trials were run, each of 5 million samples.1

Fig. 7 shows the posterior probabilities for total numbers of
balls from 1 to 15 computed in each of the ﬁve trials, along
with the exact probabilities. The results are all quite close
to the true probability, especially in the noisy-observation
case. The variance is higher for the noise-free model be-
cause the sampled true colors for the balls are often incon-
sistent with the observed colors, so many samples have zero
weights.

Fig. 8 shows how quickly our algorithm converges to the
correct value for a particular probability, P (N = 2jobs).
The run with deterministic observations stays within 0.01
of the true probability after 2 million samples. The noisy-
observation run converges faster, in just 100,000 samples.

Identity uncertainty:
In the second experiment, three
balls are drawn from the urn: a black one and then two
white ones. We wish to ﬁnd the probability that the second
and third draws produced the same ball. The prior distribu-

1Our

Java implementation averages about 1700 sam-
ples/sec. for the exact observation case and 1100 samples/sec. for
the noisy observation model on a 3.2 GHz Intel Pentium 4.

tion over the number of balls is Poisson(6). Unlike the pre-
vious experiment, each ball is black with probability 0.3.

We ran ﬁve independent trials of 100,000 samples on the
deterministic and noisy observation models. Fig. 9 shows
the estimates from all ﬁve trials approaching the true proba-
bility as the number of samples increases. Note that again,
the approximations for the noisy observation model con-
verge more quickly. The noise-free case stays within 0.01
of the true probability after 70,000 samples, while the noisy
case converges within 10,000 samples. Thus, we perform
inference over a model with an unbounded number of ob-
jects and get reasonable approximations in ﬁnite time.

7 Related work

There are a number of formalisms for representing context-
speciﬁc independence (CSI) in BNs. Boutilier et al. [1]
use decision trees, just as we do in CBNs. Poole and
Zhang [12] use a set of parent contexts (partial instantia-
tions of the parents) for each node; such models can be
represented as PBMs, although not necessarily as CBNs.
Neither paper discusses inﬁnite or cyclic models. The idea
of labeling edges with the conditions under which they are
active may have originated in [3] (a working paper that is
no longer available); it was recently revived in [5].

244y
t
i
l
i

b
a
b
o
r
P

 0.4

 0.35

 0.3

 0.25

 0.2

 0

 0.4

y
t
i
l
i

b
a
b
o
r
P

 0.35

 0.3

 0.25

 0.2

 0

 20000

 40000

 60000

 80000

 100000

Number of Samples

 20000

 40000

 60000

 80000

 100000

Number of Samples

Figure 9: Probability that draws two and three produced the same
ball for noise-free observations (top) and noisy observations (bot-
tom). Solid line indicates exact value; ’+’s are values computed
by 5 sampling runs.

Bayesian multinets [4] can represent models that would
be cyclic if they were drawn as ordinary BNs. A multi-
net is a mixture of BNs:
to sample an outcome from a
multinet, one ﬁrst samples a value for the hypothesis vari-
able H, and then samples the remaining variables using
a hypothesis-speciﬁc BN. We could extend this approach
to CBNs, representing a structurally well-deﬁned CBN as
a (possibly inﬁnite) mixture of acyclic, ﬁnite-ancestor-set
BNs. However, the number of hypothesis-speciﬁc BNs re-
quired would often be exponential in the number of vari-
ables that govern the dependency structure. On the other
hand, to represent a given multinet as a CBN, we simply
include an edge V ! X with the label H = h whenever
that edge is present in the hypothesis-speciﬁc BN for h.

There has also been some work on handling inﬁnite ances-
tor sets in BNs without representing CSI. Jaeger [6] states
that an inﬁnite BN deﬁnes a unique distribution if there is
a well-founded topological ordering on its variables; that
condition is more complete than ours in that it allows a
node to have inﬁnitely many active parents, but less com-
plete in that it requires a single ordering for all contexts.
Pfeffer and Koller [11] point out that a network containing
an inﬁnite receding path X1 ˆ X2 ˆ X3 ˆ ¢ ¢ ¢ may
still deﬁne a unique distribution if the CPDs along the path
form a Markov chain with a unique stationary distribution.

8 Conclusion

We have presented contingent Bayesian networks, a for-
malism for deﬁning probability distributions over possi-
bly inﬁnite sets of random variables in a way that makes
context-speciﬁc independence explicit. We gave structural
conditions under which a CBN is guaranteed to deﬁne a
unique distribution—even if it contains cycles, or if some
variables have inﬁnite ancestor sets. We presented a sam-
pling algorithm that is guaranteed to complete each sam-
pling step in ﬁnite time and converge to the correct poste-
rior distribution. We have also discussed how CBNs ﬁt into
the more general framework of partition-based models.

Our likelihood weighting algorithm, while completely gen-
eral,
is not efﬁcient enough for most real-world prob-
lems. Our future work includes developing an efﬁcient
Metropolis-Hastings sampler that allows for user-speciﬁed
proposal distributions; the results of [10] suggest that such
a system can handle large inference problems satisfactorily.
Further work at the theoretical level includes handling con-
tinuous variables, and deriving more complete conditions
under which CBNs are guaranteed to be well-deﬁned.

References
[1] C. Boutilier, N. Friedman, M. Goldszmidt, and D. Koller.
In

Context-speciﬁc independence in Bayesian networks.
Proc. 12th UAI, pages 115–123, 1996.

[2] R. Durrett. Probability: Theory and Examples. Wadsworth,

Belmont, CA, 2nd edition, 1996.

[3] R. M. Fung and R. D. Shachter. Contingent inﬂuence di-
agrams. Working Paper, Dept. of Engineering-Economic
Systems, Stanford University, 1990.

[4] D. Geiger and D. Heckerman. Knowledge representation
and inference in similarity networks and Bayesian multinets.
AIJ, 82(1–2):45–74, 1996.

[5] D. Heckerman, C. Meek, and D. Koller. Probabilistic mod-
els for relational data. Technical Report MSR-TR-2004-30,
Microsoft Research, 2004.

[6] M. Jaeger. Reasoning about inﬁnite random structures with

relational Bayesian networks. In Proc. 6th KR, 1998.

[7] B. Milch, B. Marthi, and S. Russell. BLOG: Relational
In ICML Wksp on Sta-

modeling with unknown objects.
tistical Relational Learning, 2004.

[8] B. Milch, B. Marthi, S. Russell, D. Sontag, D. L. Ong, and
A. Kolobov. BLOG: First-order probabilistic models with
unknown objects. Technical report, UC Berkeley, 2004.

[9] H. Pasula. Identity Uncertainty. PhD thesis, UC Berkeley,

2003.

[10] H. Pasula, B. Marthi, B. Milch, S. Russell, and I. Shpitser.
Identity uncertainty and citation matching. In NIPS 15. MIT
Press, Cambridge, MA, 2003.

[11] A. Pfeffer and D. Koller. Semantics and inference for recur-

sive probability models. In Proc. 17th AAAI, 2000.

[12] D. Poole and N. L. Zhang. Exploiting contextual indepen-

dence in probabilistic inference. JAIR, 18:263–313, 2003.

[13] S. Russell.

Identity uncertainty.

In Proc. 9th Int’l Fuzzy

Systems Assoc. World Congress, 2001.

[14] S. Russell and P. Norvig. Artiﬁcial Intelligence: A Modern

Approach. Morgan Kaufmann, 2nd edition, 2003.

[15] R. D. Shachter. Evaluating inﬂuence diagrams. Op. Res.,

34:871–882, 1986.

245Hierarchical Probabilistic Neural Network Language Model

Frederic Morin

Dept. IRO, Universit´e de Montr´eal
P.O. Box 6128, Succ. Centre-Ville,

Montreal, H3C 3J7, Qc, Canada
morinf@iro.umontreal.ca

Yoshua Bengio

Dept. IRO, Universit´e de Montr´eal
P.O. Box 6128, Succ. Centre-Ville,

Montreal, H3C 3J7, Qc, Canada

Yoshua.Bengio@umontreal.ca

Abstract

In recent years, variants of a neural network ar-
chitecture for statistical language modeling have
been proposed and successfully applied, e.g. in
the language modeling component of speech rec-
ognizers. The main advantage of these architec-
tures is that they learn an embedding for words
(or other symbols) in a continuous space that
helps to smooth the language model and pro-
vide good generalization even when the num-
ber of training examples is insufﬁcient. How-
ever, these models are extremely slow in com-
parison to the more commonly used n-gram mod-
els, both for training and recognition. As an al-
ternative to an importance sampling method pro-
posed to speed-up training, we introduce a hier-
archical decomposition of the conditional proba-
bilities that yields a speed-up of about 200 both
during training and recognition. The hierarchical
decomposition is a binary hierarchical cluster-
ing constrained by the prior knowledge extracted
from the WordNet semantic hierarchy.

1 INTRODUCTION

The curse of dimensionality hits hard statistical language
models because the number of possible combinations of n
words from a dictionnary (e.g. of 50,000 words) is im-
mensely larger than all the text potentially available, at least
for n > 2. The problem comes down to transfering prob-
ability mass from the tiny fraction of observed cases to all
the other combinations. From the point of view of machine
learning, it is interesting to consider the different principles
at work in obtaining such generalization. The most funda-
mental principle, used explicitly in non-parametric mod-
els, is that of similarity:
if two objects are similar they
should have a similar probability. Unfortunately, using a
knowledge-free notion of similarity does not work well in

high-dimensional spaces such as sequences of words. In
the case of statistical language models, the most success-
ful generalization principle (and corresponding notion of
similarity) is also a very simple one, and it is used in in-
terpolated and back-off n-gram models (Jelinek and Mer-
cer, 1980; Katz, 1987): sequences that share shorter subse-
quences are similar and should share probability mass.

However, these methods are based on exact matching
of subsequences, whereas it is obvious that two word se-
quences may not match and yet be very close to each other
semantically. Taking this into account, another principle
that has been shown to be very successful (in combina-
tion with the ﬁrst one) is based on a notion of similarity
between individual words:
two word sequences are said
to be “similar” if their corresponding words are “similar”.
Similarity between words is usually deﬁned using word
classes (Brown et al., 1992; Goodman, 2001b). These
word classes correspond to a partition of the set of words
in such a way that words in the same class share statisti-
cal properties in the context of their use, and this partition
can be obtained with various clustering algorithms. This is
a discrete all-or-nothing notion of similarity. Another way
to deﬁne similarity between words is based on assigning
each word to a continuous-valued set of features, and com-
paring words based on this feature vector. This idea has
already been exploited in information retrieval (Schutze,
1993; Deerwester et al., 1990) using a singular value de-
composition of a matrix of occurrences, indexed by words
in one dimension and by documents in the other.

This idea has also been exploited in (Bengio, Ducharme
and Vincent, 2001; Bengio et al., 2003): a neural network
architecture is deﬁned in which the ﬁrst layer maps word
symbols to their continuous representation as feature vec-
tors, and the rest of the neural network is conventional and
used to construct conditional probabilities of the next word
given the previous ones. This model is described in de-
tail in Section 2. The idea is to exploit the smoothness of
the neural network to make sure that sequences of words
that are similar according to this learned metric will be as-
signed a similar probability. Note that both the feature vec-

246tors and the part of the model that computes probabilities
from them are estimated jointly, by regularized maximum
likelihood. This type of model is also related to the popular
maximum entropy models (Berger, Della Pietra and Della
Pietra, 1996) since the latter correspond to a neural network
with no hidden units (the unnormalized log-probabilities
are linear functions of the input indicators of presence of
words).

This neural network approach has been shown to gener-
alize well in comparison to interpolated n-gram models and
class-based n-grams (Brown et al., 1992; Pereira, Tishby
and Lee, 1993; Ney and Kneser, 1993; Niesler, Whittaker
and Woodland, 1998; Baker and McCallum, 1998), both
in terms of perplexity and in terms of classiﬁcation error
when used in a speech recognition system (Schwenk and
Gauvain, 2002; Schwenk, 2004; Xu, Emami and Jelinek,
2003). In (Schwenk and Gauvain, 2002; Schwenk, 2004),
it is shown how the model can be used to directly improve
speech recognition performance. In (Xu, Emami and Je-
linek, 2003), the approach is generalized to form the vari-
ous conditional probability functions required in a stochas-
tic parsing model called the Structured Language Model,
and experiments also show that speech recognition perfor-
mance can be improved over state-of-the-art alternatives.
However, a major weakness of this approach is the very
long training time as well as the large amount of compu-
tations required to compute probabilities, e.g. at the time
of doing speech recognition (or any other application of
the model). Note that such models could be used in other
applications of statistical language modeling, such as auto-
matic translation and information retrieval, but improving
speed is important to make such applications possible.

The objective of this paper is thus to propose a
much faster variant of the neural probabilistic language
model.
It is based on an idea that could in principle
deliver close to exponential speed-up with respect to the
number of words in the vocabulary. Indeed the computa-
tions required during training and during probability pre-
diction are a small constant plus a factor linearly propor-
tional to the number of words |V | in the vocabulary V .
The approach proposed here can yield a speed-up of order
O( |V |
log |V | ) for the second term. It follows up on a proposal
made in (Goodman, 2001b) to rewrite a probability func-
tion based on a partition of the set of words. The basic
idea is to form a hierarchical description of a word as a se-
quence of O(log |V |) decisions, and to learn to take these
probabilistic decisions instead of directly predicting each
word’s probability. Another important idea of this paper
is to reuse the same model (i.e. the same parameters) for
all those decisions (otherwise a very large number of mod-
els would be required and the whole model would not ﬁt
in computer memory), using a special symbolic input that
characterizes the nodes in the tree of the hierarchical de-
composition. Finally, we use prior knowledge in the Word-

Net lexical reference system to help deﬁne the hierarchy of
word classes.

2 PROBABILISTIC NEURAL

LANGUAGE MODEL

The objective is to estimate the joint probability of se-
quences of words and we do it through the estimation of the
conditional probability of the next word (the target word)
given a few previous words (the context):

P (w1, . . . , wl) = Y

t

P (wt|wt−1, . . . , wt−n+1),

where wt is the word at position t in a text and wt ∈ V ,
the vocabulary. The conditional probability is estimated
by a normalized function f (wt, wt−1, . . . , wt−n+1), with
Pv f (v, wt−1, . . . , wt−n+1) = 1.

In (Bengio, Ducharme and Vincent, 2001; Bengio et al.,
2003) this conditional probability function is represented
by a neural network with a particular structure. Its most
important characteristic is that each input of this function
(a word symbol) is ﬁrst embedded into a Euclidean space
(by learning to associate a real-valued “feature vector” to
each word). The set of feature vectors for all the words
in V is part of the set of parameters of the model, esti-
mated by maximizing the empirical log-likelihood (minus
weight decay regularization). The idea of associating each
symbol with a distributed continuous representation is not
new and was advocated since the early days of neural net-
works (Hinton, 1986; Elman, 1990). The idea of using neu-
ral networks for language modeling is not new either (Mi-
ikkulainen and Dyer, 1991; Xu and Rudnicky, 2000), and
is similar to proposals of character-based text compression
using neural networks to predict the probability of the next
character (Schmidhuber, 1996).

the model

There are two variants of

in (Bengio,
Ducharme and Vincent, 2001; Bengio et al., 2003): one
with |V | outputs with softmax normalization (and the target
word wt is not mapped to a feature vector, only the context
words), and one with a single output which represents the
unnormalized probability for wt given the context words.
Both variants gave similar performance in the experiments
reported in (Bengio, Ducharme and Vincent, 2001; Bengio
et al., 2003). We will start from the second variant here,
which can be formalized as follows, using the Boltzmann
distribution form, following (Hinton, 2000):

f (wt, wt−1, . . . , wt−n+1) =

e−g(wt,wt−1,...,wt−n+1)
Pv e−g(v,wt−1,...,wt−n+1)

where g(v, wt−1, . . . , wt−n+1) is a learned function that
can be interpreted as an energy, which is low when the tuple
(v, wt−1, . . . , wt−n+1) is “plausible”.

247Let F be an embedding matrix (a parameter) with row
Fi the embedding (feature vector) for word i. The above
energy function is represented by a ﬁrst transformation of
the input label through the feature vectors Fi, followed by
an ordinary feedforward neural network (with a single out-
put and a bias dependent on v):

g(v, wt−1, . . . , wt−n+1) = a0. tanh(c + W x + U F 0

v) + bv
(1)

where x0 denotes the transpose of x, tanh is applied ele-
ment by element, a, c and b are parameters vectors, W and
U are weight matrices (also parameters), and x denotes the
concatenation of input feature vectors for context words:

x = (Fwt−1 , . . . , Fwt−n+1 )0.

(2)

Let h be the number of hidden units (the number of rows
of W ) and d the dimension of the embedding (number
of columns of F ). Computing f (wt, wt−1, . . . , wt−n+1)
can be done in two steps: ﬁrst compute c + W x (requires
hd(n − 1) multiply-add operations), and second, for each
v ∈ V , compute U F 0
v (hd multiply-add operations) and
the value of g(v, ...) (h multiply-add operations). Hence
total computation time for computing f is on the order of
(n − 1)hd + |V |h(d + 1).
In the experiments reported
in (Bengio et al., 2003), n is around 5, |V | is around 20000,
h is around 100, and d is around 30. This gives around
12000 operations for the ﬁrst part (independent of |V |) and
around 60 million operations for the second part (that is
linear in |V |).

Our goal in this paper is to drastically reduce the sec-
ond part, ideally by replacing the O(|V |) computations by
O(log |V |) computations.

3 HIERARCHICAL DECOMPOSITION

CAN PROVIDE EXPONENTIAL
SPEED-UP

In (Goodman, 2001b) it is shown how to speed-up a max-
imum entropy class-based statistical language model by
using the following idea.
Instead of computing directly
P (Y |X) (which involves normalization across all the val-
ues that Y can take), one deﬁnes a clustering partition for
the Y (into the word classes C, such that there is a deter-
ministic function c(.) mapping Y to C), so as to write

P (Y = y|X = x) =
P (Y = y|C = c(y), X)P (C = c(y)|X = x).

This is always true for any function c(.) because
P (Y |X) = Pi P (Y, C = i|X) = Pi P (Y |C =

i, X)P (C = i|X) = P (Y |C = c(Y ), X)P (C =
c(Y )|X) because only one value of C is compatible with
the value of Y , the value C = c(Y ).

Although any c(.) would yield correct probabilities, gen-
eralization could be better for choices of word classes that
“make sense”, i.e.
those for which it easier to learn the
P (C = c(y)|X = x).

If Y can take 10000 values and we have 100 classes with
100 words y in each class, then instead of doing normaliza-
tion over 10000 choices we only need to do two normal-
izations, each over 100 choices. If computation of condi-
tional probabilities is proportional to the number of choices
then the above would reduce computation by a factor 50.
This is approximately what is gained according to the mea-
surements reported in (Goodman, 2001b). The same pa-
per suggests that one could introduce more levels to the
decomposition and here we push this idea to the limit. In-
deed, whereas a one-level decomposition should provide a
= p|V |, a hierarchical de-
speed-up on the order of
composition represented by a balanced binary tree should
provide an exponential speed-up, on the order of
log2 |V |
(at least for the part of the computation that is linear in the
number of choices).

|V |√|V |

|V |

Each word v must be represented by a bit vector
(b1(v), . . . bm(v)) (where m depends on v). This can be
achieved by building a binary hierarchical clustering of
words, and a method for doing so is presented in the next
section. For example, b1(v) = 1 indicates that v belongs
to the top-level group 1 and b2(v) = 0 indicates that it be-
longs to the sub-group 0 of that top-level group.

The next-word conditional probability can thus be rep-

resented and computed as follows:

m

P (v|wt−1, . . . , wt−n+1) =
Y

j=1

P (bj(v)|b1(v), . . . , bj−1(v), wt−1, . . . , wt−n+1)

This can be interpreted as a series of binary stochastic
decisions associated with nodes of a binary tree. Each node
is indexed by a bit vector corresponding to the path from
the root to the node (append 1 or 0 according to whether the
left or right branch of a decision node is followed). Each
leaf corresponds to a word. If the tree is balanced then the
maximum length of the bit vector is dlog2 |V |e. Note that
we could further reduce computation by looking for an en-
coding that takes the frequency of words into account, to
reduce the average bit length to the unconditional entropy
of words. For example with the corpus used in our experi-
ments, |V | = 10000 so log2 |V | ≈ 13.3 while the unigram
entropy is about 9.16, i.e. a possible additional speed-up
of 31% when taking word frequencies into account to bet-
ter balance the binary tree. The gain would be greater for

248larger vocabularies, but not a very signiﬁcant improvement
over the major one obtained by using a simple balanced
hierarchy.

sense to force the word embedding to be shared across all
nodes. This is important also because the matrix of word
features F is the largest component of the parameter set.

The “target class” (0 or 1) for each node is obtained di-
rectly from the target word in each context, using the bit
encoding of that word. Note also that there will be a target
(and gradient propagation) only for the nodes on the path
from the root to the leaf associated with the target word.
This is the major source of savings during training.

During recognition and testing, there are two main cases
to consider: one needs the probability of only one word,
e.g.
the observed word, (or very few) , or one needs the
probabilities of all the words. In the ﬁrst case (which oc-
curs during testing on a corpus) we still obtain the exponen-
tial speed-up. In the second case, we are back to O(|V |)
computations (with a constant factor overhead). For the
purpose of estimating generalization performance (out-of-
sample log-likelihood) only the probability of the observed
next word is needed. And in practical applications such as
speech recognition, we are only interested in discriminat-
ing between a few alternatives, e.g. those that are consistent
with the acoustics, and represented in a treillis of possible
word sequences.

This speed-up should be contrasted with the one
provided by the importance sampling method proposed
in (Bengio and Sen´ecal, 2003). The latter method is based
on the observation that the log-likelihood gradient is the
average over the model’s distribution for P (v|context) of
the energy gradient associated with all the possible next-
words v. The idea is to approximate this average by a
biased (but asymptotically unbiased) importance sampling
scheme. This approach can lead to signiﬁcant speed-up
during training, but because the architecture is unchanged,
probability computation during recognition and test still re-
quires O(|V |) computations for each prediction. Instead,
the architecture proposed here gives signiﬁcant speed-up
both during training and test / recognition.

4 SHARING PARAMETERS ACROSS

THE HIERARCHY

If a separate predictor is used for each of the nodes in the
hierarchy, about 2|V | predictors will be needed. This rep-
resents a huge capacity since each predictor maps from the
context words to a single probability. This might create
problems in terms of computer memory (not all the models
would ﬁt at the same time in memory) as well as overﬁtting.
Therefore we have chosen to build a model in which pa-
rameters are shared across the hierarchy. There are clearly
many ways to achieve such sharing, and alternatives to the
architecture presented here should motivate further study.

Based on our discussion in the introduction, it makes

Since each node in the hierarchy presumably has a se-
mantic meaning (being associated with a group of hope-
fully similar-meaning words) it makes sense to also as-
sociate each node with a feature vector. Without loss
of generality, we can consider the model
to predict
P (b|node, wt−1, . . . , wt−n+1) where node corresponds to
a sequence of bits specifying a node in the hierarchy and b
is the next bit (0 or 1), corresponding to one of the two chil-
dren of node. This can be represented by a model similar to
the one described in Section 2 and (Bengio, Ducharme and
Vincent, 2001; Bengio et al., 2003) but with two kinds of
symbols in input: the context words and the current node.
We allow the embedding parameters for word cluster nodes
to be different from those for words. Otherwise the archi-
tecture is the same, with the difference that there are only
two choices to predict, instead of |V | choices.

More precisely, the speciﬁc predictor used in our exper-

iments is the following:

P (b = 1|node, wt−1, . . . , wt−n+1) =
sigmoid(αnode + β0. tanh(c + W x + U Nnode))

where x is the concatenation of context word features
as in eq. 2, sigmoid(y) = 1/(1 + exp(−y)), αi is a bias
parameter playing the same role as bv in eq. 1, β is a weight
vector playing the same role as a in eq. 1, c, W , U and F
play the same role as in eq. 1, and N gives feature vector
embeddings for nodes in a way similar that F gave feature
vector embeddings for next-words in eq. 1.

5 USING WORDNET TO BUILD THE

HIERARCHICAL DECOMPOSITION

A very important component of the whole model is the
choice of the words binary encoding, i.e. of the hierar-
chical word clustering. In this paper we combine empir-
ical statistics with prior knowledge from the WordNet re-
source (Fellbaum, 1998). Another option would have been
to use a purely data-driven hierarchical clustering of words,
and there are many other ways in which the WordNet re-
source could have been used to inﬂuence the resulting clus-
tering.

The IS-A taxonomy in WordNet organizes semantic
concepts associated with senses in a graph that is almost a
tree. For our purposes we need a tree, so we have manually
selected a parent for each of the few nodes that have more
than one parent. The leaves of the WordNet taxonomy are
senses and each word can be associated with more than one

249sense. Words sharing the same sense are considered to be
synonymous (at least in one of their uses). For our pur-
pose we have to choose one of the senses for each word
(to make the whole hierarchy one over words) and we se-
lected the most frequent sense. A straightforward extension
of the proposed model would keep the semantic ambiguity
of each word: each word would be associated with sev-
eral leaves (senses) of the WordNet hierarchy. This would
require summing over all those leaves (and corresponding
paths to the root) when computing next-word probabilities.

Note that the WordNet tree is not binary: each node
may have many more than two children (this is particu-
larly a problem for verbs and adjectives, for which Word-
Net is shallow and incomplete). To transform this hierar-
chy into a binary tree we perform a data-driven binary hi-
erarchical clustering of the children associated with each
node, as illustrated in Figure 1. The K-means algorithm is
used at each step to split each cluster. To compare nodes,
we associate each node with the subset of words that it
covers. Each word is associated with a TF/IDF (Salton
and Buckley, 1988) vector of document/word occurrence
counts, where each “document” is a paragraph in the train-
ing corpus. Each node is associated with the dimension-
wise median of the TF/IDF scores. Each TF/IDF score
is the occurrence frequency of the word in the document
times the logarithm of the ratio of the total number of doc-
uments by the number of documents containing the word.

6 COMPARATIVE RESULTS

Experiments were performed to evaluate the speed-up and
any change in generalization error. The experiments also
compared an alternative speed-up technique (Bengio and
Sen´ecal, 2003) that is based on importance sampling (but
only provides a speed-up during training). The experiments
were performed on the Brown corpus, with a reduced vo-
cabulary size of 10,000 words (the most frequent ones).
The corpus has 1,105,515 occurrences of words, split into
3 sets: 900,000 for training, 100,000 for validation (model
selection), and 105,515 for testing. The validation set was
used to select among a small number of choices for the size
of the embeddings and the number of hidden units.

The results in terms of raw computations (time to pro-
cess one example), either during training or during test
are shown respectively in Tables 1 and 2. The computa-
tions were performed on Athlon processors with a 1.2 GHz
clock. The speed-up during training is by a factor greater
than 250 and during test by a factor close to 200. These are
impressive but less than the |V |/ log2 |V | ≈ 750 that could
be expected if there was no overhead and no constant term
in the computational cost.

It is also important to verify that learning still works

 
 
 
 

 

 

 

 


 

 

 

 

























Figure 1: WordNet’s IS-A hierarchy is not a binary tree:
mostnodes have many children. Binary hierarchical clus-
teringofthesechildrenisperformed.

and that the model generalizes well. As usual in statis-
tical language modeling this is measured by the model’s
perplexity on the test data, which is the exponential of
the average negative log-likehood on that data set. Train-
ing is performed over about 20 to 30 epochs according to
validation set perplexity (early stopping). Table 3 shows
the comparative generalization performance of the differ-
ent architectures, along with that of an interpolated trigram
and a class-based n-gram (same procedures as in (Bengio
et al., 2003), which follow respectively (Jelinek and Mer-
cer, 1980) and (Brown et al., 1992; Ney and Kneser, 1993;
Niesler, Whittaker and Woodland, 1998)). The validation
set was used to choose the order of the n-gram and the
number of word classes for the class-based models. We
used the implementation of these algorithms in the SRI
Language Modeling toolkit, described by (Stolcke, 2002)
and in www.speech.sri.com/projects/srilm/.
Note that better performance should be obtainable with
some of the tricks in (Goodman, 2001a). Combining the
neural network with a trigram should also decrease its per-

250architecture
original neural net
importance sampling
hierarchical model

Time per Time per
ex. (ms)
epoch (s)
462.6
416 300
6.73
6 062
1 609
1.79

speed-up

1
68.7
258

Table 1: Training time per epoch (going once through all
thetrainingexamples)andperexample. Theoriginalneu-
ral net is as described in sec. 2. The importance sam-
plingalgorithm(BengioandSen´ecal,2003)trainsthesame
model faster. The hierarchical model is the one proposed
here, and it yields a speed-up not only during training but
forprobabilitypredictionsaswell(seethenexttable).

architecture
original neural net
importance sampling
hierarchical model

Time per
example (ms)
270.7
221.3
1.4

speed-up

1
1.22
193

Table 2: Testtimeperexampleforthedifferentalgorithms.
SeeTable1’scaption. Itisattesttimethatthehierarchical
model’sadvantagebecomesclearincomparisontotheim-
portancesamplingtechnique,sincethelatteronlybringsa
speed-upduringtraining.

plexity, as already shown in (Bengio et al., 2003).

As shown in Table 3, the hierarchical model does not
generalize as well as the original neural network, but the
difference is not very large and still represents an improve-
ment over the benchmark n-gram models. Given the very
large speed-up, it is certainly worth investigating variations
of the hierarchical model proposed here (in particular how
to deﬁne the hierarchy) for which generalization could be
better. Note also that the speed-up would be greater for
larger vocabularies (e.g. 50,000 is not uncommon in speech
recognition systems).

7 CONCLUSION AND FUTURE WORK

This paper proposes a novel architecture for speeding-up
neural networks with a huge number of output classes and
shows its usefulness in the context of statistical language
modeling (which is a component of speech recognition and
automatic translation systems). This work pushes to the
limit a suggestion of
(Goodman, 2001b) but also intro-
duces the idea of sharing the same model for all nodes of
the decomposition, which is more practical when the num-
ber of nodes is very large (tens of thousands here). The
implementation and the experiments show that a very sig-
niﬁcant speed-up of around 200-fold can be achieved, with
only a little degradation in generalization performance.

trigram
class-based
original neural net
importance sampling
hierarchical model

Validation
perplexity
299.4
276.4
213.2
209.4
241.6

Test
perplexity
268.7
249.1
195.3
192.6
220.7

Table 3: Testperplexityforthedifferentarchitecturesand
for an interpolated trigram. The hierarchical model per-
formed a bit worse than the original neural network, but
isstillbetterthanthebaselineinterpolatedtrigramandthe
class-basedmodel.

From a linguistic point of view, one of the weaknesses
of the above model is that it considers word clusters as de-
terministic functions of the word, but uses the nodes in
WordNet’s taxonomy to help deﬁne those clusters. How-
ever, WordNet provides word sense ambiguity information
which could be used for linguistically more accurate mod-
eling. The hierarchy would be a sense hierarchy instead of
a word hiearchy, and each word would be associated with
a number of senses (those allowed for that word in Word-
Net). In computing probabilities, this would involve sum-
ming over several paths from the root, corresponding to the
different possible senses of the word. As a side effect, this
could provide a word sense disambiguation model, and it
could be trained both on sense-tagged supervised data and
on unlabeled ordinary text. Since the average number of
senses per word is small (less than a handful), the loss in
speed would correspondingly be small.

Acknowledgments

The authors would like to thank the following funding or-
ganizations for support: NSERC, MITACS, IRIS, and the
Canada Research Chairs.

References

Baker, D. and McCallum, A. (1998). Distributional clus-

tering of words for text classiﬁcation. In SIGIR’98.

Bengio, Y., Ducharme, R., and Vincent, P. (2001). A neural
probabilistic language model. In Leen, T., Dietterich,
T., and Tresp, V., editors, Advances in Neural Infor-
mation Processing Systems 13, pages 933–938. MIT
Press.

Bengio, Y., Ducharme, R., Vincent, P., and Jauvin, C.
(2003). A neural probabilistic language model. Jour-
nal of Machine Learning Research, 3:1137–1155.

Bengio, Y. and Sen´ecal, J.-S. (2003). Quick training of
probabilistic neural nets by importance sampling. In

251Niesler, T., Whittaker, E., and Woodland, P. (1998). Com-
parison of part-of-speech and automatically derived
category-based language models for speech recog-
nition.
In International Conference on Acoustics,
Speech, and Signal Processing, pages 177–180.

Pereira, F., Tishby, N., and Lee, L. (1993). Distributional
clustering of english words.
In 30th Annual Meet-
ing of the Association for Computational Linguistics,
pages 183–190, Columbus, Ohio.

Salton, G. and Buckley, C. (1988). Term weighting ap-
proaches in automatic text retrieval. Information Pro-
cessing and Management, 24(5):513–523.

Schmidhuber, J. (1996).

Sequential neural text com-
IEEE Transactions on Neural Networks,

pression.
7(1):142–146.

Schutze, H. (1993). Word space.

In Giles, C., Hanson,
S., and Cowan, J., editors, Advances in Neural Infor-
mation Processing Systems 5, pages pp. 895–902, San
Mateo CA. Morgan Kaufmann.

Schwenk, H. (2004). Efﬁcient training of large neural net-
works for language modeling. In IEEE joint confer-
ence on neural networks.

Schwenk, H. and Gauvain, J.-L. (2002). Connectionist
language modeling for large vocabulary continuous
speech recognition.
In International Conference on
Acoustics, Speech, and Signal Processing, pages 765–
768, Orlando, Florida.

Stolcke, A. (2002). SRILM - an extensible language mod-
eling toolkit. In Proceedings of the International Con-
ference on Statistical Language Processing, Denver,
Colorado.

Xu, P., Emami, A., and Jelinek, F. (2003). Training con-
nectionist models for the structured language model.
In Empirical Methods in Natural Language Process-
ing, EMNLP’2003.

Xu, W. and Rudnicky, A. (2000). Can artiﬁcial neural net-
work learn language models. In International Confer-
ence on Statistical Language Processing, pages M1–
13, Beijing, China.

Proceedings of AISTATS’2003.

Berger, A., Della Pietra, S., and Della Pietra, V. (1996). A
maximum entropy approach to natural language pro-
cessing. Computational Linguistics, 22:39–71.

Brown, P., Pietra, V. D., DeSouza, P., Lai, J., and Mercer,
R. (1992). Class-based n-gram models of natural lan-
guage. Computational Linguistics, 18:467–479.

Deerwester, S., Dumais, S., Furnas, G., Landauer, T., and
Harshman, R. (1990).
Indexing by latent semantic
analysis. Journal of the American Society for Infor-
mation Science, 41(6):391–407.

Elman, J. (1990). Finding structure in time. Cognitive Sci-

ence, 14:179–211.

Fellbaum, C. (1998). WordNet: An Electronic Lexical

Database. MIT Press.

Goodman, J. (2001a). A bit of progress in language mod-
eling. Technical Report MSR-TR-2001-72, Microsoft
Research.

Goodman, J. (2001b). Classes for fast maximum entropy
In International Conference on Acoustics,

training.
Speech, and Signal Processing, Utah.

Hinton, G. (1986). Learning distributed representations of
concepts. In Proceedings of the Eighth Annual Con-
ference of the Cognitive Science Society, pages 1–12,
Amherst 1986. Lawrence Erlbaum, Hillsdale.

Hinton, G. (2000). Training products of experts by min-
imizing contrastive divergence.
Technical Report
GCNU TR 2000-004, Gatsby Unit, University Col-
lege London.

Jelinek, F. and Mercer, R. L. (1980). Interpolated estima-
tion of Markov source parameters from sparse data.
In Gelsema, E. S. and Kanal, L. N., editors, Pattern
Recognition in Practice. North-Holland, Amsterdam.

Katz, S. M. (1987). Estimation of probabilities from sparse
data for the language model component of a speech
recognizer. IEEE Transactions on Acoustics, Speech,
and Signal Processing, ASSP-35(3):400–401.

Miikkulainen, R. and Dyer, M. (1991). Natural language
processing with modular neural networks and dis-
tributed lexicon. Cognitive Science, 15:343–399.

Ney, H. and Kneser, R. (1993). Improved clustering tech-
niques for class-based statistical language modelling.
In European Conference on Speech Communication
and Technology (Eurospeech), pages 973–976, Berlin.

252Greedy Spectral Embedding

Marie Ouimet

Dept. IRO, Universit´e de Montr´eal
P.O. Box 6128, Downtown Branch
Montreal, H3C 3J7, Qc, Canada

ouimema@iro.umontreal.ca

Yoshua Bengio

Dept. IRO, Universit´e de Montr´eal
P.O. Box 6128, Downtown Branch
Montreal, H3C 3J7, Qc, Canada

bengioy@iro.umontreal.ca

Abstract

Spectral dimensionality reduction methods and
spectral clustering methods require computation
of the principal eigenvectors of an n (cid:2) n ma-
trix where n is the number of examples. Fol-
lowing up on previously proposed techniques to
speed-up kernel methods by focusing on a sub-
set of m examples, we study a greedy selection
procedure for this subset, based on the feature-
space distance between a candidate example and
the span of the previously chosen ones.
In the
case of kernel PCA or spectral clustering this
reduces computation to O(m2n). For the same
computational complexity, we can also compute
the feature space projection of the non-selected
examples on the subspace spanned by the se-
lected examples, to estimate the embedding func-
tion based on all the data, which yields consid-
erably better estimation of the embedding func-
tion. This algorithm can be formulated in an on-
line setting and we can bound the error on the
approximation of the Gram matrix.

1 Introduction

Many interesting algorithms have been proposed in re-
cent years to perform non-parametric unsupervised learn-
ing, either for clustering (spectral clustering) or for mani-
fold learning. Many of these methods can be seen as ker-
nel methods with an adaptive, data-dependent kernel (Ben-
gio et al., 2004). Like other kernel methods, methods such
as LLE (Roweis and Saul, 2000), Isomap (Tenenbaum, de
Silva and Langford, 2000), kernel Principal Components
Analysis (PCA) (Sch¨olkopf, Smola and M¨uller, 1998),
Laplacian Eigenmaps (Belkin and Niyogi, 2003) and spec-
tral clustering (Weiss, 1999; Ng, Jordan and Weiss, 2002),
typically require computation of the principal eigenvectors
of an n (cid:2) n matrix, where n is the number of examples.
In this paper we follow-up on previous work to speed-

up kernel methods, such as (Smola and Sch¨olkopf, 2000;
Smola and Bartlett, 2001; Williams and Seeger, 2001;
Harmeling et al., 2002; Lawrence, Seeger and Herbrich,
2003; Engel, Mannor and Meir, 2003) but focus on spec-
tral methods for unsupervised learning. Like in these
methods, the main speed-up is obtained by focusing on a
subset of the examples, chosen using a greedy selection
algorithm. We call the set of selected examples the dic-
tionary. Assuming that the kernel is positive semi-deﬁnite
(which is not always exactly true, but is a good approxima-
tion), the above methods are equivalent to a special form
of kernel PCA. The criterion used for greedy selection is
the distance in feature space between a candidate exam-
ple and its projection on the subspace spanned by the se-
lected examples. This is a reasonable criterion because the
embedding of a new x will be expressed as a linear com-
bination of the KD(x; xi), with xi a dictionary example and
KD the data-dependent kernel associated with the particular
method. However, if only the selected examples are used
to derive the embedding (i.e. the principal eigenvectors of
the feature space covariance matrix), then the resulting em-
bedding will be biased, since the dictionary examples will
tend to be distributed more uniformly than the original data
(to better cover more directions in feature space). In addi-
tion, this projection of the non-dictionary examples can be
used to enrich the estimation of the feature space covari-
ance matrix. The resulting algorithm is O(m2n), where m is
the dictionary size, and requires O(m2) memory. We show
how using a generalized eigen-decomposition algorithm it
is possible to take advantage of the sparseness of the kernel.
Finally, we also show an efﬁcient way to obtain the kernel
normalization required in kernel PCA (additive normaliza-
tion) and in spectral clustering (divisive normalization).

In section 3 we give more justiﬁcation as well as the details
of this algorithm. We put it in perspective of previously
proposed methods in section 4. In section 5 we show with
several experiments that the greedy approximation works
well and works better than (a) the same algorithm with a
randomly selected dictionary (but all the data to estimate
the eigenvectors), and (b) using only m random points to
estimate the eigenvectors.

2532 Spectral Embedding Algorithms and

Motivation

Let D = fx1; : : : ; xng represent a training set, with xi a train-
ing example. Spectral embedding algorithms (Sch¨olkopf,
Smola and M¨uller, 1998; Weiss, 1999; Roweis and Saul,
2000; Tenenbaum, de Silva and Langford, 2000; Ng, Jor-
dan and Weiss, 2002; Belkin and Niyogi, 2003) provide a
vector-valued coordinate for each training example, which
would ideally correspond to its coordinate on a mani-
fold near which the data lie. As discussed in (Bengio
et al., 2004), spectral embedding methods can generalize
the training set embedding to a new example x through the
Nystr¨om formula

fk(x) =

pn
(cid:21)k

n

Xi=1

vikKD(x; xi)

(1)

for the k-th embedding coordinate, where KD is a kernel
that is deﬁned using D (hence called data-dependent), and
(vk; (cid:21)k) is the k-th (eigenvector,eigenvalue) pair of the ma-
trix M with entries Mi j = KD(xi; x j). Note that this for-
mula reduces to fk(xi) = pnvik for training examples. De-
pending on the choice of algorithm, the embedding can be
further scaled separately in each dimension (e.g. by a fac-
tor p(cid:21)k for kernel PCA, metric multidimensional scaling
(MDS), Isomap, and spectral clustering, and by a factor pn
for LLE). Note that KD is guaranteed to be positive semi-
deﬁnite for some of these methods (e.g. LLE, kernel PCA,
spectral clustering, Laplacian Eigenmaps) but not for oth-
ers (e.g. Isomap, MDS) but it is usually close to positive
semi-deﬁnite (e.g.
for Isomap the kernel converges to a
positive semi-deﬁnite one as n ! 1).
Assuming KD positive semi-deﬁnite, there exists a “fea-
ture space” (cid:30)(x) in which KD is a dot product KD(x; y) =
(cid:30)(x):(cid:30)(y). Eq. 1 therefore shows that the function of inter-
est (the embedding of x) can be written as a dot product
between (cid:30)(x) and a vector which is a linear combination of
the feature space vectors (cid:30)(xi) associated with the training
examples:

fk(x) = (cid:30)(x):(

pn
(cid:21)k

n

Xi=1

vik(cid:30)(xi)):

(2)

If we are going to work with a subset of the examples
(the dictionary) to deﬁne the embedding, we can reduce
the above linear combination to one over dictionary exam-
ples. There is a simple way to use a dictionary to reduce
computation. We ﬁrst compute the Gram matrix of the dic-
tionary examples and its principal eigenvectors. Then we
use the Nystr¨om formula as above to predict the embed-
ding of the other examples. This is essentially the basis
for the “Landmark Isomap” algorithm (de Silva and Tenen-
baum, 2003), as shown in (Bengio et al., 2004). This is one
of the methods that we will evaluate experimentally, and
compare to the proposed algorithm, on a Gaussian kernel
with additive normalization (corresponding to kernel PCA

or metric MDS) and one with divisive normalization (corre-
sponding to spectral clustering or to Laplacian Eigenmaps
with Gaussian kernel).

In the two cases that we study here, the data-dependence of
the kernel is due to this normalization. The data-dependent
kernel KD is obtained from a data-independent kernel ˜K as
follows. For additive normalization (kernel PCA, metric
MDS) we have

KD(x; y) = ˜K(x; y) (cid:0) Ev[ ˜K(v; y)]

(cid:0) Ew[ ˜K(x; w)] + Ev;w[ ˜K(v; w)]

(3)

and for divisive normalization (for a positive kernel) we
have

˜K(x; y)

:

(4)

KD(x; y) =

pEv[ ˜K(v; y)]Ew[ ˜K(x; w)]

j=1

n Pn

1

p(cid:21)k Pn

In both cases this normalization requires estimation of
Ex[ ˜K(x; y)] which is normally done with the training
set average of the kernel over one of its arguments:
˜K(xi; x j). We discuss below how to
Ex[ ˜K(xi; x)] = 1
avoid this computation which would make the whole algo-
rithm running time O(n2).
3 Proposed Algorithm
Let C denote the covariance matrix of the examples in fea-
ture space. One interpretation of the eigenvectors of the
Gram matrix is that they correspond to the eigenvectors of
i=1 vik(cid:30)(xi). Again, this
C, which can be written as
interpretation is only valid for positive semi-deﬁnite ker-
nels, or when working in the subspace associated with non-
negative eigenvalues (i.e. with the projection of the (cid:30)(x) on
that subspace).
Let P be the subspace spanned by the dictionary examples
in feature space (or the restriction to non-negative eigen-
values). If (cid:30)(xt) is not far from its projection on P, i.e. it is
well approximated by a linear combination of the examples
spanning P, than we can replace it by this projection with-
out making a big error. Proposition 1 below formalizes this
idea, and Figure 1 shows a geometric interpretation of the
projection of (cid:30)(xt) on the span of the dictionary examples in
feature space. Therefore, instead of using a random subset
of examples for the dictionary and only using the dictio-
nary to estimate the eigenvectors of C, we propose (1) to
select the dictionary examples according to their distance
to P, and (2) to use the dictionary examples as well as the
projection of the out-of-dictionary examples to estimate the
principal eigenvectors of C, thus giving rise to a more pre-
cise estimate, almost as good as using the whole data set,
according to our experiments. It turns out that (2) comes
for free (i.e. for the same cost) once we have accepted to
do the computations for (1). Another important consider-
ation is that the selected examples may have statistics that
are different from the original examples. For example, if
they are chosen as a good “cover” of the training examples,
the relative density of dictionary examples will be smaller

254p(cid:14)t

(cid:30)(xt)

)

(cid:30)(xd(1)

(cid:30) ( x d ( 2 ))

)

(cid:30)(xd(1)

at1

d ( 2 ))

(cid:30) ( x

a t 2

Figure 1: Out-of-dictionary example (cid:30)(xt) is approximated in feature space by a linear combination of the dictionary
examples (cid:30)(xd(i)); i = 1 : : : m.

Algorithm 1 Greedy Spectral Embedding Algorithm.
Arguments: randomly ordered data set D, tolerance (cid:15), em-
bedding dimension p.
1: n = jDj, initialize D = fx1g, M1 = (KD(x1; x1)),
2: for t = 2 to n do
3:
4:
5:
6:
7:
8:

1 = (cid:16)KD(x1; x1)(cid:0)1(cid:17).
M(cid:0)1
for i = 1 to mt(cid:0)1 do
end for
compute matrix-vector product ˆat = M(cid:0)1

compute (cid:11) = 1 (cid:0)Pi ˆati and (cid:12) = Pi; j(M(cid:0)1

compute (kt(xt))i = KD(xt; xd(i))

t(cid:0)1kt(xt)
t(cid:0)1)i j.

Bi j = AitA jt where Ait recovered from cache or
computed with eq. 10.

end for

20:
21: end for
22: Find the p principal eigenvectors uk and eigenvalues
(cid:21)k of the generalized eigen-problem with left matrix
B = A0A and right matrix M(cid:0)1
n .

23: Embeddings of all examples are given by vk = Auk for

24: The embedding of a test example x is given by fk(x)
pn ,

k-th coordinate.

with fk(x) as in eq. 1.

9:

(cid:12) M(cid:0)1

compute projection weights
t(cid:0)1[1; : : : ; 1]0
at = ˆat + (cid:11)
compute projection error
(cid:14)t = KD(xt; xt) (cid:0) kt(cid:0)1(xt)0 ˆat + (cid:11)2
(cid:12) .
if (cid:14)t > (cid:15) then
mt = mt(cid:0)1 + 1, D   D [ fxtg
M(cid:0)1
is set according to eq. 9.
t

else

10:
11:
12:
13:
14:
end if
15:
16: end for
17: for i = 1 to mn do
18:
19:

for j = 1 to mn do

mt = mt(cid:0)1, M(cid:0)1

t = M(cid:0)1
t(cid:0)1

than the true data density in areas of high density of the
original examples. You can observe that phenomenon in
the center image of ﬁgure 2: the region corresponding to
digit 1 is much more dense and contains only 4 dictionary
points. Since the directions with high variance are differ-
ent for the dictionary points, using only this selected subset
to form a Gram matrix without projecting the other points
would give a completely different embedding.

Computing the distance between (cid:30)(xt) and the span of the
dictionary examples in feature space can be reduced to
computations with the kernel, thanks to the kernel trick:

(cid:14)t (cid:17) min
at

jj(cid:30)(xt) (cid:0)

mt

Xi=1

ait(cid:30)(xd(i))jj2

(5)

where d(i) is the index of the i-th dictionary example, and
mt is the size of the dictionary after seeing t examples. We

found better results with the constraint Pi ait = 1. This
constraint has the effect of making the solution indepen-
dent to translations in feature space, since ((cid:30)(xt) (cid:0) b) (cid:0)
Pmt
i=1 ait((cid:30)(xd(i)) (cid:0) b) = (cid:30)(xt) (cid:0)Pmt
i=1 ait(cid:30)(xd(i)). In this paper
we consider an application of these ideas to an online set-
ting (or to reduce memory requirements, at most 2 passes
through the data). Let at = (a1t; : : : ; amtt), let Mt(cid:0)1 be the
Gram matrix of the dictionary examples after seeing t (cid:0) 1
examples, and let kt(cid:0)1(x) be the vector with mt elements
KD(x; xd(i)). The solution for at without constraint is

ˆat (cid:17) M(cid:0)1

t(cid:0)1kt(cid:0)1(xt):

(6)

The solution with constraint can then be obtained as fol-
lows:

at = ˆat +

(cid:11)

(cid:12)

M(cid:0)1
t(cid:0)1[1; : : : ; 1]0

(7)

where 0 denotes transposition, (cid:11) = 1 (cid:0) Pi ˆati and (cid:12) =
Pi; j(M(cid:0)1
t(cid:0)1)i j. The corresponding value of the projection dis-

tance is then obtained as follows:

(cid:14)t = ˆ(cid:14)t +

(cid:11)2
(cid:12)

;

(8)

2551 (cid:0)Pi ˆAti
Pi; j(M(cid:0)1

n )i j

where ˆ(cid:14)t = KD(xt; xt)(cid:0)kt(cid:0)1(xt)0 ˆat. We introduce the param-
eter (cid:15) that controls the accuracy of the approximation. xt is
added to the dictionary if (cid:14)t > (cid:15), which means that xt is
far from its projection on P in feature space. When a point
is added to the dictionary, M(cid:0)1
t needs to be computed. To
do so efﬁciently (in O(m2
t ) computations), we can take ad-
vantage of our knowledge of M(cid:0)1
t(cid:0)1 and the matrix inversion
lemma:

M(cid:0)1

t =

1

ˆ(cid:14)t   ˆ(cid:14)t M(cid:0)1
(cid:0)ˆa0t

t(cid:0)1 + ˆat ˆa0t

(cid:0)ˆat
1

!

(9)

following the recursive update approach in (Engel, Mannor
and Meir, 2003) for kernel regression.

After we have selected the dictionary, we want to compute
the projection of all the examples on its span. This will
be different from the projection computed online in eq. 7
because it will use the ﬁnal dictionary and M(cid:0)1
instead of
n
M(cid:0)1
t(cid:0)1:

ˆAt (cid:17) M(cid:0)1

n kn(xt)

At (cid:17) ˆAt +

M(cid:0)1

n [1; : : : ; 1]0:

(10)

Let A denote the matrix with rows At. It can be shown that
the complete Gram matrix is approximated by AMnA0. We
can bound the error on each entry of the Gram matrix by
the same parameter we used to select dictionary examples:

Proposition 1
For all xt; xu 2 D; jKD(xt; xu) (cid:0) (AMnA0)tuj (cid:20) (cid:15):
Proof: Let rt = (cid:30)(xt)(cid:0)Pmn
i=1 ait(cid:30)(xd(i)). Notice that if xt 2 D;
then krtk = 0; otherwise, krtk = p(cid:14)t and rt is orthogonal
to the span of (cid:30)(xd(i)); i = 1; :::; mn: Then we have

KD(xt; xu) = (cid:30)(xt):(cid:30)(xu)

i=1 aiu(cid:30)(xd(i)))

i=1 ait(cid:30)(xd(i))

= (rt +Pmn
= rt:ru + rt:Pmn
+(Pmn
= rt:ru + (Pmn

i=1 ait(cid:30)(xd(i))):(ru +Pmn
i=1 ait(cid:30)(xd(i))):(Pmn

i=1 aiu(cid:30)(xd(i)) + ru:Pmn
i=1 aiu(cid:30)(xd(i)))
i=1 ait(cid:30)(xd(i))):(Pmn

= rt:ru + (AMnA0)tu:

i=1 aiu(cid:30)(xd(i)))

So we have

jKD(xt; xu) (cid:0) (AMnA0)tuj
= jrt:ruj (cid:20) p(cid:14)tp(cid:14)u (cid:20) (cid:15):

The eigenvectors of AMnA0 would give us the embedding
of all the training examples, but this is an n (cid:2) n matrix. We
want to take advantage of its factorization. Note that if uk is
an eigenvector of MnA0A then vk = Auk is an eigenvector of
AMnA0 with the same eigen values. Unfortunately, MnA0A
is not symmetric, But we can still compute the eigenvectors
efﬁciently in time O(m3), by solving the m (cid:2) m generalized
eigen-system Lu = (cid:21)Ru with left matrix L = A0A and right
matrix R = M(cid:0)1
(which we already have from our recursive
n
updates). Finally this gives rise to algorithm 1.

3.1 Computational Cost and Memory Usage
The expensive steps of the algorithm 1 are step 6 (O(m2
t(cid:0)1)
per step, O(nm2) overall), step 12 (O(m2
t(cid:0)1) per step, O(nm2)
overall), step 19 (O(nm2)), step 22 (O(m3)), and step 23
(O(pnm)). The memory usage is O(m2) to store Mt (which
becomes Mn at the end), if the ait are recomputed in step
23, or O(nm) to store A if they are not recomputed (de-
pending on how large n is and how much memory is avail-
able). Hence time is O(nm2) and memory either O(m2) or
O(nm) (time-memory trade-off only in the constant factor
for time).

=

(KD(x1; x1)),

t = (cid:16)KD(x1; x1)(cid:0)1(cid:17).
M(cid:0)1

fx1g, Mt
= 0 or something for m+

Algorithm 2 Constructs a dictionary of speciﬁed size mn
with an almost minimal level of error.
Arguments: randomly ordered data set D, wanted subset
size mn.
1: Initialize D =
2: Set (cid:15) +
n > mn
3: Set (cid:15)(cid:0) = 1 or something for m(cid:0)n < mn
4: Check that m(cid:0)n < mn by running steps 2 to 16 of algo. 1
using (cid:15)(cid:0); D; Mt; M(cid:0)1
and data set D (cid:0) D; stopping if
m(cid:0)t > mn: Store the obtained dictionary and corre-
sponding matrices in D(cid:0); M(cid:0)t ; M(cid:0)t (cid:0)1
return D(cid:0); M(cid:0)t ; M(cid:0)t (cid:0)1

:

t

= (cid:15)(cid:0)

(cid:15) +
(cid:15)(cid:0) = 10(cid:15)(cid:0)
goto step 4

5: if m(cid:0)t = mn then
6:
7: else if m(cid:0)t > mn then
8:
9:
10:
11: else
12:
13: end if
14: for i = 1 to 40 do
15:
16:

Set D = D(cid:0); Mt = M(cid:0)t ; M(cid:0)1

t = M(cid:0)t (cid:0)1

t

+ ((cid:15)(cid:0) (cid:0) (cid:15) +)=2

Set (cid:15)0 = (cid:15) +
Run steps 2 to 16 of algo. 1 using (cid:15)0; D; Mt; M(cid:0)1
and data set D (cid:0) D; stopping if m0t > mn: Store the
obtained dictionary and corresponding matrices in
D0; M0t ; M0t (cid:0)1:
if m0t = mn then

else if m0t > mn then

Set (cid:15)(cid:0) = (cid:15)0; D = D0; Mt = M0t ; M(cid:0)1

return D0; M0t ; M0t (cid:0)1
Set (cid:15) +

17:
18:
19:
20:
21:
22:
end if
23:
24: end for
25: Run steps 2 to 16 of algo. 1 using (cid:15) +; D; Mt; M(cid:0)1
t = mn: Store
and data set D (cid:0) D; stopping when m+
the obtained dictionary and corresponding matrices in
D+; M+

t = M0t (cid:0)1

= (cid:15)0

else

t

t ; M+

t (cid:0)1
26: return D+; M+

:
t ; M+

t (cid:0)1

Although the goal was to get an online algorithm, it is also
possible to formulate the method in a setting more similar

2560
1

0
1

0
1

v2

v2

v2

 

v1

v1

v1

 

Figure 2: First two dimensions of the embeddings obtained with kernel PCA on classes 0 (+) and 1 ((cid:2)) of the MNIST data
set ((cid:27) = 31:6, n = 1300). The dictionary points are noted by _. The image on the left is the embedding obtained with the
full Gram matrix. With 34 points in the dictionary, we obtain an almost identical embedding. Even with only 4 points, the
embedding is reasonable and similar.

to previously proposed methods where instead of specify-
ing the accuracy parameter (cid:15), we specify the subset size
m. To do so, one needs to ﬁrst search for a good value
of (cid:15) before applying algorithm 1. This can also be done
in O(nm2) operations and O(m2) in memory usage. Algo-
rithm 2 constructs a dictionary of the wanted size with an
almost minimal error level. Beginning with an (cid:15) that gives
a too small dictionary and one giving a too large dictionary,
it does a binary search for the right (cid:15) while always keeping
small dictionaries and only adding points to it. It ﬁrst adds
to the dictionary the points that are the farthest from P and
gradually adds points that are closer and closer. This en-
sures that the error level will be near optimal. One gets the
desired embedding by running steps 17 to 24 of algorithm 1
with the obtained dictionary and corresponding matrices.

3.2 Additive and Divisive Normalizations

We have not discussed how to perform additive or divisive
normalization yet. If we compute the usual complete train-
ing set averages to estimate Ex[ ˜K(x; y)], then the whole al-
gorithm becomes O(n2) because we have to compute the
values of the data-independent kernel ˜K(xi; x j) for all data
pairs. There are two solutions to this problem, which gave
similar results in our experiments. One is to use a random
subset of the examples (or the dictionary examples) to esti-
mate these averages. If we average over less than m2 exam-
ples the overall algorithm would remain O(nm2). The other
solution is to compute the exact normalization associated
with the implicit estimated Gram matrix AMnA0.
Proposition 2

Additive normalization of AMnA0 can be obtained by using
instead of AMnA0 the Gram matrix ˜AMn ˜A0 with ˜A = A (cid:0) B,
and B the matrix whose rows are all identical and equal to
the average row of A, Et[At]. Similarly, divisive normaliza-
tion can be obtained by using the Gram matrix ˜AMn ˜A0 with
˜Ai(cid:1) =
pnAi(cid:1)
The proof
to
KD(xi; x j) in eq. 3 and 4. Using this proposition, the al-

is straightforward comparing

Ai(cid:1)
(MnEt[At]) :

˜AiMn ˜A j0

gorithm remains the same except that the matrix A is re-
placed by ˜A in the last steps (22 and 23). Under constraint
Pi ait = 1, additive normalization before or after the com-

putation of A made no empirical difference, since the ap-
proximation is invariant to a translation in feature space.
The only difference is the number of points over which the
averages are made. This is not the case for the divisive nor-
malization, where if we want to compute the approxima-
tion in the feature space induced by the normalized kernel,
the normalization should be applied before, using a sub-
set of the examples. For this normalization, the constraint

Pi ait = 1 does not help and could be removed, but it did
not make a measurable difference in the experiments.
4 Related work
Other sparse greedy kernel methods in O(m2n) have been
proposed.
(Smola and Bartlett, 2001) and (Lawrence,
Seeger and Herbrich, 2003) present algorithms for greedy
Gaussian processes. The main difference with our method
is that they do m passes on the whole data set (or a ran-
dom subset of it to reduce computation) and each time
they select the example that improves the most a global
criterion. They also use a recursive update for inverting
In (Smola and Sch¨olkopf, 2000) the setting is
matrices.
very general, aiming to approximate a matrix K by ˜K, a
lower rank matrix, by minimizing the Frobenius norm of
the residual K (cid:0) ˜K. This is again done with m passes to
select the best basis function among a random subset of all
the n (cid:0) mt function. Our algorithm is different from these
methods by requiring at most 2 passes on the data set. In-
stead, the approximation we use is close to the approach
presented in (Engel, Mannor and Meir, 2003) where it was
used in a sequential and supervised setting to perform Ker-
nel RLS. (Williams and Seeger, 2001) suggests to com-
pute the eigen-decomposition on a subset of m examples
and then use the Nystr¨om formula to get an approxima-
tion of the eigen-decomposition for the n (cid:0) m other points.
They argue that their method, although less precise than
(Smola and Sch¨olkopf, 2000), is much faster. In our ex-
periments, we will compare our greedy technique to this

257Kernel PCA on MNIST (classes 0 and 1)

Kernel PCA on the spiral

e=0.001 m<=19 s=1
e=0.01   m<=14 s=1
s=1

e=0.001  m<=125 s=31.6
e=0.005  m<=58   s=31.6
e=0.009  m<=37   s=31.6
 s=31.6

 0.01

 0.001

 0.0001

 1e-05

 1e-06

r
o
r
r
e
 
n
o
i
t
a
z
i
l
a
r
e
n
e
G

 0

 200

 400

 600

 800  1000  1200  1400

 0

 200

 400

 600

 800  1000  1200  1400  1600

Training set size

Training set size

Spectral Clustering on MNIST (classes 0 and 1)

Spectral Clustering on the spiral

e=0.001 m<=19 s=1
e=0.1     m<=7   s=1
s=1

e=0.0008 m<=145 s=31.6
e=0.004   m<=70   s=31.6
e=0.008   m<=44   s=31.6
s=31.6

 0.1

 0.01

 0.001

 0.0001

r
o
r
r
e
 

n
o
i
t
a
z
i
l
a
r
e
n
e
G

 0.001

 0.0001

 1e-05

 1e-06

 0.001

 0.0001

 1e-05

r
o
r
r
e
 
n
o
i
t
a
z
i
l
a
r
e
n
e
G

r
o
r
r
e
 

n
o
i
t
a
z
i
l
a
r
e
n
e
G

 0

 200  400  600  800  1000  1200  1400  1600

 0

 200

 400

 600

 800  1000  1200  1400  1600

Training set size

Training set size

Figure 3: Even for really small dictionary sizes, the generalization performance is comparable to the one obtained with
the Gram matrix of the whole training set. Curves corresponding to the dictionary methods are indexed with (cid:27), the
standard deviation of the Gaussian kernel, (cid:15), the accuracy parameter and m, the resulting maximum number of points in
the dictionary (obtained for the maximum n). The curves corresponding to non-dictionary methods are indexed with (cid:27)
only. There are 3 principal components for MNIST and 2 for the spiral. The individual experiments associated with the
symbols (cid:4) and (cid:4) have the same running time, but the generalization performance is far better for the dictionary method.
We observe the same phenomenon for symbols (cid:155) and (cid:155) corresponding to a longer running time. More details on the
relationship between running time and generalization error are given in table 1.

Nystr¨om method showing that for the same computational
time we get better performance. Another related method is
(Harmeling et al., 2002) in which we search for the largest
random subset of examples for which the Gram matrix is
of full rank and project all the examples on this subset.
This technique is more computationally expensive than the
greedy selection since it requires to do several matrix de-
compositions to compute the rank. We will also see in the
experimental section that random subset selection leads to
larger subsets for the same error level.

5 Experimental Evaluation

The new algorithm was evaluated on two data sets: a 2-D
artiﬁcially generated spiral, and images of the digits 0 and
1 from the MNIST data set (scaled down from 28 (cid:2) 28 to
14 (cid:2) 14). Two embedding methods were compared and

evaluated out-of-sample using the Nystr¨om formula: spec-
tral clustering and kernel PCA, both with the Gaussian ker-
nel, with different values of standard deviation (shown in
Figure 3). An example of the embeddings obtained with
the dictionary method on the MNIST data set is given in
ﬁgure 2.

The goals of the experiments were (1) to verify that the al-
gorithm worked (in the sense of giving an embedding close
to the one obtained when training with the whole data set)
and (2) to verify that it worked better than (a) the same
algorithm with randomly selected dictionary (Harmeling
et al., 2002) and (b) training on a small subset and gener-
alization with the Nystr¨om formula (Williams and Seeger,
2001; Bengio et al., 2004). To compare the embeddings
given by these different methods, we will need a reference
embedding. We ﬁrst divide our data set in three parts: D1,

258Table 1: Comparison between generalization errors for the dictionary and non-dictionary methods at a ﬁxed running time.
The errors and the n corresponds to the ones in Figure 3 for MNIST. Some of these results are plotted in Figure 3 with
square and circle symbols. Similar results are obtained for a ﬁxed memory space.

WITHOUT DICTIONARY

WITH DICTIONARY

TIME KPCA (s) MAX. SIZE GEN. ERROR (cid:6)95% C.I.

1:48e(cid:0)4 (cid:6) 8:9e(cid:0)6
1:48e(cid:0)4 (cid:6) 8:9e(cid:0)6
8:27e(cid:0)6 (cid:6) 4:0e(cid:0)7
3:47e(cid:0)6 (cid:6) 1:4e(cid:0)7

MAX. SIZE
n = 1300, m = 34
n = 1300, m = 55
n = 1300, m = 126

GEN. ERROR (cid:6)95% C.I.

6:64e(cid:0)6 (cid:6) 2:3e(cid:0)7
6:40e(cid:0)6 (cid:6) 2:1e(cid:0)7
3:99e(cid:0)6 (cid:6) 1:5e(cid:0)7

05:71
05:72
06:46
14:02

n = 250
n = 250
n = 550
n = 1300

TIME SC (s)

05:80
05:95
07:18
14:06

n = 325
n = 400
n = 700
n = 1300

2:41e(cid:0)4 (cid:6) 1:2e(cid:0)5
2:37e(cid:0)4 (cid:6) 1:2e(cid:0)5
1:58e(cid:0)4 (cid:6) 7:3e(cid:0)6
7:93e(cid:0)5 (cid:6) 3:4e(cid:0)6

n = 1300, m = 41
n = 1300, m = 65
n = 1300, m = 138

5:16e(cid:0)5 (cid:6) 2:3e(cid:0)6
5:61e(cid:0)5 (cid:6) 2:5e(cid:0)6
8:74e(cid:0)5 (cid:6) 3:8e(cid:0)6

D2, D3, where D2 and D3 are large. We compute a refer-
ence embedding by applying standard kernel PCA or spec-
tral clustering to D2 [ D3 and keeping the part correspond-
ing to D2. We then train the methods we want to compare
on D1. Using the obtained eigenvectors, we compute the
out-of-sample embedding for every element of the test set
D2 with the Nystr¨om formula. We will compare this em-
bedding to the reference embedding of D2 by aligning them
with a simple linear regression (that maps each example’s
coordinate in one embedding with the same example’s co-
ordinate in the other embedding). In our experiments, the
reported generalization error is the average squared differ-
ence between the corresponding points of these aligned em-
beddings. We also show the 95% conﬁdence intervals as-
sociated to the standard errors of these averages. For the
spiral data, we used sets of sizes jD1j (cid:20) 3333, jD2j = 3330
and jD3j = 3332. For the MNIST data, jD1j (cid:20) 3365,
jD2j = 3267 and jD3j = 3332.
In the experiments shown in Figure 3, we verify that the
greedy algorithm works about as well as when we use the
full Gram matrix. On the horizontal axis, we vary the size
of the training set D1 and on the vertical axis, we show
the out-of-sample errors obtained with the Nystr¨om for-
mula. The dictionary method (curves indexed with (cid:15); m; (cid:27))
is trained with ﬁxed values of (cid:15), yielding different subset
sizes as the training set grows. The largest subset size ob-
tained is shown as “m (cid:20) :::”. To compare, we compute the
eigenvectors of the full Gram matrix corresponding to same
training set (ordinary kernel PCA and spectral clustering).
The corresponding generalization errors are reported by the
curves indexed with (cid:27) only (full black curves). The main
feature to note is that for a training set of size n, the re-
sults with the dictionary of size m (cid:28) n are very close to the
results using ordinary training with all the examples, i.e.
the greedy algorithm generalizes about as well as full train-
ing. The other important conclusion from this ﬁgure is that
the dictionary method works much better than the simple
Nystr¨om method with eigenvectors estimated on a random
dictionary (compare for example the error of the full Gram

matrix method trained with a dataset of size n = 125 with
the dictionary method for n = 1400 and m = 125 for ker-
nel PCA on MNIST). To be more fair, one can compare the
Nystr¨om method to the dictionary method at equal running
time instead of equal subset size. Table 1 shows that for
the same running time, the dictionary method yields quite
smaller generalization error. In ﬁgure 3 and in table 1 you
can notice a slight increase in error as the dictionary grows
for spectral clustering on the MNIST data set, but as ex-
pected, the curve for the larger dictionary is closer to the
one for the whole dataset. This increase in error is proba-
bly due to overﬁtting; using a small dictionary is a way to
regularize. Finally, in Figure 4 we compare the proposed
selection algorithm vs a random selection procedure.
In
both cases we project the other points on the span of the
subset in feature space. We also show the performance of
the Nystr¨om technique with the eigen-decomposition made
on a random subset of points, ignoring the other points of
the training set. In these experiments we used a training set
of size 3365 and show the test set error for different values
of subset size m. The ﬁrst thing we notice is that projecting
the other examples makes a huge difference. For this data
set, we need a subset of size about 900 for the Nystr¨om
technique to achieve the performance we get with less than
100 points in the subset if we project the 3265 other points.
Although the greedy selection and the random selection be-
have the same for subsets of size 65 and more, this is not
the case for smaller sizes. The greedy selection strategy
reduces generalization error signiﬁcantly, the more so for
smaller dictionaries, as expected. Note that for this prob-
lem a greedy dictionary of size 44 gave performances sim-
ilar to when the complete Gram matrix was used, as shown
in ﬁgure 3, but ﬁgure 4 suggests that a dictionary of size
about 22 would have been enough. For these dictionary
sizes, the performance of the random dictionary method is
not as good and consequently, an approach like (Harmeling
et al., 2002) will need to pick a subset of size at least 65 to
reach about the same error level.

259Kernel PCA on MNIST (classes 0 and 1)

and the Canada Research Chairs.

 0.0004

 0.00035

 0.0003

 0.00025

 0.0002

 0.00015

 0.0001

 5e-05

r
o
r
r
e
 
n
o
i
t
a
z
i
l
a
r
e
n
e
G

 0

 10

Nystr(cid:246)m
95% C.I.
Random
95% C.I.
Greedy
95% C.I.

 100

 1000

Subset Size

Figure 4: Comparison of the dictionary method vs the
Nystr¨om method where the eigen-decomposition is made
only on a random subsets of the training set. We show two
subset selection strategies for the dictionary method: the
proposed greedy selection and a simple random selection.
These experiments were performed with a training set of
size 3365, with 3 principal components.

6 Conclusion

Spectral embedding methods are useful for manifold learn-
ing (non-linear dimensionality reduction) and clustering
(spectral clustering) but require an expensive O(n3) oper-
ation with O(n2) memory requirement, with n the number
of examples. In this paper we propose an efﬁcient algo-
rithm that yields almost as good results and reduces com-
putation to O(nm2) and memory to O(m2) where m is the
size of a small subset of selected examples (the dictionary).
The algorithm selects examples greedily and sequentially
based on their distance to the span of the already selected
ones, in the kernel feature space. It then uses the projec-
tion of all n examples on that span to estimate the required
eigenvectors. We show how to formulate kernel PCA and
spectral clustering within this framework.
In theory one
can also write a functional form for other data dependant
kernels like LLE and Isomap kernels, but the update of
the matrix becomes relatively ineffective in these cases and
should be the subject of future research. Experiments show
that for kernel PCA and spectral clustering, the selection
method is signiﬁcantly better than random selection, and
better than simply using the Nystr¨om method to generalize
(as in Isomap’s landmark variant (de Silva and Tenenbaum,
2003)). In fact it worked almost as well as training with all
the data.

Acknowledgements

The authors would like to thank the following funding or-
ganizations for support: NSERC, FQRNT, MITACS, IRIS,

References

Belkin, M. and Niyogi, P. (2003). Laplacian eigenmaps for
dimensionality reduction and data representation. Neural
Computation, 15(6):1373–1396.

Bengio, Y., Delalleau, O., Le Roux, N., Paiement, J.-F., Vincent,
P., and Ouimet, M. (2004). Learning eigenfunctions links
spectral embedding and kernel PCA. Neural Computation,
to appear.

de Silva, V. and Tenenbaum, J. (2003). Global versus local meth-
ods in nonlinear dimensionality reduction.
In Becker, S.,
Thrun, S., and Obermayer, K., editors, Advances in Neural
Information Processing Systems 15, pages 705–712, Cam-
bridge, MA. MIT Press.

Engel, Y., Mannor, S., and Meir, R. (2003). The kernel recur-
sive least squares algorithm. Technical Report submitted to
Trans. Sig. Proc., MIT.

Harmeling, S., Ziehe, A., Kawanabe, M., and M¨uller, K.-R.
(2002). Kernel feature spaces and nonlinear blind souce
separation.
In Dietterich, T. G., Becker, S., and Ghahra-
mani, Z., editors, Advances in Neural Information Process-
ing Systems 14, Cambridge, MA. MIT Press.

Lawrence, N., Seeger, M., and Herbrich, R. (2003). Fast sparse
gaussian process methods: The informative vector machine.
In Becker, S., Thrun, S., and Obermayer, K., editors, Ad-
vances in Neural Information Processing Systems 15, pages
609–616. MIT Press.

Ng, A. Y., Jordan, M. I., and Weiss, Y. (2002). On spectral clus-
tering: analysis and an algorithm. In Dietterich, T., Becker,
S., and Ghahramani, Z., editors, Advances in Neural Infor-
mation Processing Systems 14, Cambridge, MA. MIT Press.

Roweis, S. and Saul, L. (2000). Nonlinear dimensionality reduc-
tion by locally linear embedding. Science, 290(5500):2323–
2326.

Sch¨olkopf, B., Smola, A., and M¨uller, K.-R. (1998). Nonlinear
component analysis as a kernel eigenvalue problem. Neural
Computation, 10:1299–1319.

Smola, A. and Sch¨olkopf, B. (2000). Sparse greedy matrix ap-
proximation for machine learning.
In Langley, P., editor,
International Conference on Machine Learning, pages 911–
918, San Francisco. Morgan Kaufmann.

Smola, A. J. and Bartlett, P. (2001). Sparse greedy gaussian pro-
cess regression. In Leen, T., Dietterich, T., and Tresp, V.,
editors, Advances in Neural Information Processing Systems
13.

Tenenbaum, J., de Silva, V., and Langford, J. (2000). A global ge-
ometric framework for nonlinear dimensionality reduction.
Science, 290(5500):2319–2323.

Weiss, Y. (1999). Segmentation using eigenvectors: a unifying
In Proceedings IEEE International Conference on

view.
Computer Vision, pages 975–982.

Williams, C. K. I. and Seeger, M. (2001). Using the Nystr¨om
method to speed up kernel machines. In Leen, T., Dietterich,
T., and Tresp, V., editors, Advances in Neural Information
Processing Systems 13, pages 682–688, Cambridge, MA.
MIT Press.

260FastMap, MetricMap, and Landmark MDS

are all Nystr¨om Algorithms

John C. Platt

Microsoft Research
1 Microsoft Way

jplatt@microsoft.com

Abstract

This paper uniﬁes the mathematical foun-
dation of three multidimensional scaling al-
gorithms: FastMap, MetricMap, and Land-
mark MDS (LMDS). All three algorithms
are based on the Nystr¨om approximation of
the eigenvectors and eigenvalues of a matrix.
LMDS is applies the basic Nystr¨om approx-
imation, while FastMap and MetricMap use
generalizations of Nystr¨om, including deﬂa-
tion and using more points to establish an
embedding. Empirical experiments on the
Reuters and Corel Image Features data sets
show that the basic Nystr¨om approximation
outperforms these generalizations: LMDS is
more accurate than FastMap and MetricMap
with roughly the same computation and can
become even more accurate if allowed to be
slower.

1 INTRODUCTION

Multidimensional Scaling (MDS) [4]
is an impor-
tant method for visualizing and processing high-
dimensional or graphical data. MDS takes as input
a distance matrix between items. It produces a coor-
dinate vector for each item in a Euclidean space whose
dimension is user-speciﬁable. This process is known as
embedding.
MDS is applicable to two diﬀerent tasks: 1) dimen-
sionality reduction, which measures a set of distances
between items, then applies MDS to the resulting (per-
haps sparse) distance matrix; and 2) converting graphs
to vectors, where a data set is expressed as a set of
similarity relationships between items that is then con-
verted into a simple table of vectors.
The original MDS algorithms from the 1960s [4] are
not appropriate for large scale applications because

they require an entire N × N distance matrix to be
stored in memory and may have O(N 3) complexity.
However, in the last 10 years, several scalable MDS
algorithms have been proposed. For example, Falut-
sos and Lin [7] proposed FastMap, which is an MDS
method that determines one coordinate at a time by
examining a constant number of rows of the distance
matrix. Wang, et. al [12] proposed an improvement on
FastMap, called MetricMap, which attempts to do the
entire projection at once. de Silva and Tennenbaum [5]
proposed Landmark MDS (LMDS) as another attempt
at scalable MDS.
FastMap, MetricMap, and LMDS are all classical
MDS algorithms that start with a distance matrix as-
sumed to have been computed from points in a low-
dimensional space. They then (approximately) mini-
mize a quadratic cost function between the resulting
embedding coordinates and the original (hidden) coor-
dinates that created the distance matrix. Another set
of MDS algorithms are based on spring models [3, 14].
These spring models minimize a cost function that is
non-quadratic in the coordinates: the squared diﬀer-
ence between embedded and observed distances be-
tween items. Recent work has also accelerated these
spring models, but they are prone to local minima [3].
Spring models are not considered in this paper.
The proliferation of MDS algorithms may lead to frus-
tration amongst practitioners because it is unclear how
the algorithms relate to one another or how they com-
pare against each other. This paper attempts to clarify
the situation in two ways. First, this paper shows that
FastMap, MetricMap, and LMDS are all algorithms
based on the Nystr¨om approximation of the eigenvec-
tors of a large matrix [1, 13], based only on a rectangu-
lar sub-matrix of the large matrix. LMDS uses the ba-
sic Nystr¨om approximation, FastMap uses Nystr¨om to
ﬁnd one eigenvector at a time, and MetricMap uses an
irregular sub-matrix to ﬁnd the eigenvectors. The pa-
per presents empirical comparisons between FastMap,
MetricMap, and LMDS, to determine which variation

261of Nystr¨om is optimal.

2 MATHEMATICAL

BACKGROUND

This section presents a step-by-step introduction to
Classical MDS and the Nystr¨om eigenvector approxi-
mation. The LMDS algorithm is then derived based
on the combination of the two, as ﬁrst described in [2].

2.1 REVIEW OF CLASSICAL MDS

FastMap, MetricMap, and LMDS are all multi-
dimensional scaling (MDS) algorithms [4] that map
a matrix of dissimilarities D between N items to a
k-dimensional coordinate vector for each item (~xi).
This paper’s derivation for all three of these algorithms
starts with metric MDS, which assumes that the en-
tries in the dissimilarities matrix are Euclidean dis-
tances. These three algorithms then utilize classical
MDS, which chooses the k-dimensional coordinates to
minimize the squared diﬀerence between the distances
in the embedded and the original spaces.
Classical MDS proceeds in two steps. First, the dis-
tance matrix D undergoes “double-centering” to con-
vert it from a distance matrix to a new matrix K:

where P

i ci = 1 and ei is the vector of all ones.

If
the original distance matrix D is a Euclidean distance
matrix in d-dimensional space, then K is a matrix of
dot products between coordinate vectors in that same
space [11]. This is also known as a Gram or kernel
matrix. If the original distance matrix is Euclidean,
then K is symmetric and positive semi-deﬁnite. The
parameters ci in (1) determine the origin of the coordi-
nate vectors (which is not constrained by the distance
matrix D).
The second step of classical MDS is to extract the
coordinate vectors from the kernel matrix K through
eigenvector decomposition.
If the matrix D is sym-
metric, then K is symmetric and can be decomposed
into

K = QΛQT

(2)
where Q is a matrix whose columns are orthonormal
eigenvectors and Λ is a diagonal matrix of eigenval-
ues. The k-dimensional coordinate vectors that would
give rise to the kernel matrix K are the scaled rows
of Q. In order to minimize the diﬀerence between the

Kij = −1
2

 
ij − ej
D2
X

X
ij +X

cjD2

i

j

i,j

−ei

ciD2
ij

cicjD2
ij

 ,

(1)

embedded and original distances with a ﬁxed number
of dimensions k, the eigenvectors with the top k eigen-
values are retained. Assuming that the eigenvalues are
ordered by decreasing eigenvalue, the jth component
of point i’s coordinate vector is:

xij =pλjQij,

(3)

where λj is the jth eigenvalue and here the index j
runs only from 1 to k, rather than to N (the size of
K).

2.2 THE NYSTR ¨OM APPROXIMATION

There are numerous ways of performing the decompo-
sition (2). If only the top k eigenvectors are needed,
then orthogonal iteration or Lanczos iteration can be
applied [8].
However, the three MDS algorithms that are the sub-
ject of this paper use an approximation method from
physics, called the Nystr¨om approximation [1, 13]. To
use Nystr¨om, ﬁrst choose m items in the distance and
kernel matrix at random. Without loss of generality,
permute the m items to be the ﬁrst rows and columns
of these matrices. The K and D can then be parti-
tioned into submatrices:

A

BT

K =

B
C , D =

E

FT

F

G ,

(4)

where A and E have dimension m× m; B and F have
dimension m× (N − m); and C and G have dimension
(N − m) × (N − m).
The Nystr¨om approximation permits the computation
of the coordinates ~xi using only the information in
matrices A and B. Nystr¨om assumes that K is posi-
tive semi-deﬁnite, and hence a Gram matrix. Thus, K
should be expressible in terms of dot products between
columns of matrices X and Y [1]:

(cid:20) XT X XT Y

YT X YT Y

(cid:21)

K =

.

(5)

Identifying the submatrices in (5) with those in K in
(4) yields

A = XT X,
B = XT Y.

(6)

The ﬁrst equation in (6) is standard in classical MDS:
the solution for X is to eigendecompose A:

A = UΓUT ,

and then assign the coordinates

X = Γ1/2

[k] UT

[k],

(7)

(8)

262where the subscript [k] indicates the submatrices cor-
responding to the eigenvectors with the k largest pos-
itive eigenvalues. The coordinates corresponding to B
can be derived by solving the linear system:

Y = X−T B = Γ−1/2

[k] UT

[k]B.

(9)

Combining equations (8) and (9) together and writing
the coordinate as rows in a matrix results in

γjUij
p BpiUpj/

√

γj

if i ≤ m;
otherwise,

(10)

(cid:26) √
P

xij =

where Uij is the ith component of the jth eigenvector
of A and γj is the jth eigenvalue of A. As in (3)
the j index only runs from 1 to k, in order to make a
k-dimensional embedding.
The Nystr¨om approximation can be understood by
plugging (8) and (9) back into (6). Nystr¨om approxi-
mates the full matrix K by

(cid:20) A

(cid:21)

˜K =

B

BT BT A−1B

.

(11)

This approximation is exact when K is of rank m or
less. The quality of the approximation is proportional
to ||C − BT A−1B||.
To turn Nystr¨om into an MDS method, matrices A
and B must be derived only from submatrices E and F
(from D). This can be done by choosing the centering
coeﬃcients in equation (1) to be

ci =

(cid:26) 1/m if i ≤ m;
 

0

X

otherwise,

which yields the centering formulas

Aij = −1
2

−ej

1
m

 

1
m

iq +

ij − ei
E2
X
X

E2

q

1
m

p

p
1
m2

E2
pj

E2
pq

X
X

p,q

1
m

p

Bij = −1
2

ij − ei
F 2

qj − ej
F 2

(12)

!

(13)

!

E2
ip

,

(14)
where the constant centering term in (14) is dropped,
because it introduces an irrelevant shift of origin.
Note that Nystr¨om can also be used to approximately
solve spectral clustering problems [1], by using a nor-
malized graph Laplacian, instead of a centering ma-
trix, to transform a data matrix into a kernel matrix.

2.3 LMDS

The combination of equations (13) and (14), followed
by (7), then (10) is almost the LMDS algorithm [5].
LMDS is so named because Classical MDS is ﬁrst ap-
plied to a subset of the points (in A), called “land-
marks.”
The only diﬀerence between the algorithm derived here
and LMDS is the centering formula (14). In [5], the
centering formula

 

Bij = −1
2

ij − ei
F 2

1
m

E2
ip

(15)

!

X

p

is used. This simpliﬁcation does not aﬀect the results,
because it adds a vector proportional to ei to every
column of B. Equation (9) shows that the columns of
B are only involved in dot products with the eigenvec-
tors of A. It is easy to show that ei is an eigenvector
of A with eigenvalue zero. Therefore, all other eigen-
vectors must be orthogonal to ei. Therefore, adding a
vector proportional to ei to the columns of B does not
change the embedding results.
The computational complexity of LMDS is O(N mk +
m3). For large N, the computation time is dominated
by computing the input distances from raw input data
and projecting the distances in (10).

3 UNIFICATION OF THE THREE
ALGORITHMS

While LMDS, FastMap, and MetricMap were all pro-
posed independently and appear to be distinct algo-
rithms, we will see in the following section that they
are all, in fact, applications of the Nystr¨om approxi-
mation.

3.1 FASTMAP

(cid:21)

A =

Consider LMDS for k = 1 and m = 2. In this case, we
are trying to ﬁnd a one-dimensional embedding using
two landmark points. If the distance between the two
landmarks is d12 and the distance from each landmark
to all other points is d1i or d2i, then LMDS produces:

12 −d2
−d2
d2
12
√
12/2, and its corre-
The largest eigenvalue for A is d2
sponding eigenvector is [1 − 1]T /
2. After centering,
1i − d2
2i − d2
d2
(cid:1)

Using this in equation (10) yields a coordinate

12/2
12/2

(cid:20) d2
(cid:20) d2
(cid:0)d2

1
2

B =

(16)

(17)

(cid:21)

1
4

12

12

.

.

−1
√
2
2

1i − d2
√
2
d12/

2i

= d2

2i − d2
2d12

1i

,

(18)

xi =

263which is exactly one iteration of FastMap [7], except
for an unimportant shift in the origin.
The k = 1, m = 2 case assumes that the principal
eigenvector of the data lies on the line connecting
points 1 and 2. This can be a poor estimate of this
eigenvector. So, FastMap proposes a heuristic that
scans a number of rows of the distance matrix D, look-
ing for two points that are far away from one another,
assuming that the principal eigenvector is more likely
to lie along the line connecting two points that are dis-
tant. Notice that if FastMap is going to generate m
rows of a distance matrix per iteration, those rows can
easily be added to the Nystr¨om approximation to in-
crease the accuracy of the eigenvalue and eigenvector
estimate, instead of being used in a heuristic.
One iteration of FastMap generates only one embed-
ding dimension at a time. Because FastMap is esti-
mating the leading eigenvectors of a kernel matrix, it
is legitimate to perform deﬂation. That is, each sub-
sequent call to FastMap operates in a subspace that
is orthogonal to previous dimensions, with previous
eigenvectors projected away. Typically, deﬂation is
performed by deducting a rank-one matrix from the
kernel matrix. However, we cannot manipulate the
entire kernel matrix. Therefore, FastMap computes
the distances in the deﬂated space by deducting the
squared distance between embedded coordinates from
the original squared distance:

i,j,original −X

(xin − xjn)2.

(19)

D2

ij = D2

n

This is legitimate, because the deﬂated space is or-
thogonal to any embedded dimensions. Notice that
this deﬂation can result in negative squared distances
when the original distance matrix is not Euclidean.
LMDS has a similar problem with negative eigenval-
ues of A. FastMap produced negative distances for the
Corel Features dataset in Section 4, while on the same
data set, LMDS did not produce negative eigenval-
ues. These negative eigenvalues can be compensated
by adding a small amount to the diagonal of A.
The computational complexity of FastMap is O(N k2),
because the computation is dominated by k deﬂation
iterations, each operating on N data samples, each of
which takes O(k) operations, due to (19).

3.2 METRICMAP

MetricMap [12] can be understood as a Nystr¨om ap-
proximation by revisiting Landmark MDS. In LMDS,
m rows of the distance matrix D are used to com-
pute coordinates for every item. This rectangular slice
is used both to ﬁnd the coordinates of the landmarks
(the m items corresponding to the m rows) at equation

(8) and the remainder of the rows (equation (9)).
MetricMap uses a generalization of the Nystr¨om ap-
proximation with diﬀerent sized submatrices A and B
in (8) and (9). MetricMap prescribes that A have di-
mension 2k × 2k, while B have dimension k × k [12].
Because the dimensions of A and B no longer match,
the solution to the linear system in (9) is no longer
correct. Instead, MetricMap derives embedding coor-
dinates X from the 2k × 2k matrix A, using classical
MDS from the k largest (in absolute value) eigenvalues
of A. Only k landmarks from the 2k embedded points
are used:

[k,k]U[k,k],

(20)
where the subscript [k, k] indicates the sub-matrices
indexed by the k largest eigenvalues and the k selected
landmarks.
The k landmark rows of A that are selected by this
procedure are also the rows used to generate B. Thus,
equation (9) becomes

ˆX = Γ1/2

Y = ˆX−T B = Γ−1/2

[k,k] U−T

[k,k]B.

(21)

The submatrix U[k,k] must be inverted because it is
no longer an orthogonal matrix. For speed, U[k,k] un-
dergoes LU decomposition, and each column of B is
backsubstituted.
Note also that, as described in [12], MetricMap uses
centering coeﬃcients ci = δi1 (the ﬁrst is one, the rest
zero). This causes an unimportant shift in the origin
of the coordinate system.
The computational complexity of MetricMap is
O(N k2 + k3).
In Landmark MDS, if m scales as k,
then the computational complexity of MetricMap is
the same as LMDS. LMDS may have an advantage in
only requiring O(k2) work for every point in B, rather
than O(km). However, because MetricMap uses dif-
ferent dimensions for A and B, it is not known when
MetricMap will yield an exact answer.
The uniﬁcation of LMDS with MetricMap illustrates
that the Nystr¨om approximation can be generalized by
allowing rows(A)≥rows(B). Unlike the basic Nystr¨om
approximation, there are three free parameters: the
ﬁnal embedding dimension k, the number of rows in
B and the number of rows in A. The only required
relationship between these is that rows(A)≥rows(B)≥
d. Thus, the restriction in [12] of rows(A)= 2 rows(B)
is not required.

4 ACCURACY AND SPEED

COMPARISONS

The main point of Section 3 is that FastMap, Metric-
Map, and LMDS are all applications of the Nystr¨om

264approximation. One important diﬀerence is that Fast-
Map performs deﬂation, while MetricMap and LMDS
require solving an eigensystem. Empirical testing can
determine whether deﬂation is better than solving an
eigensystem: does the eigensystem cause noticeable
slowing? Does it yield extra accuracy?
Another diﬀerence is that MetricMap uses a matrix
A that has more rows than B, unlike FastMap and
LMDS. Does using a larger matrix help the quality of
the embedding?
To answer these questions, FastMap, MetricMap, and
LMDS are compared on two medium-to-large data
sets: the Reuters collection (a UCI KDD dataset [9])
and the Corel Image Features data set (also from UCI
KDD).

4.1 REUTERS

The Reuters data set is a collection of Reuters news
articles, stored in SGML. The algorithms are tested
on the ModApte training set of Reuters, consisting of
9603 labeled documents, categorized with 115 labels,
with multiple labels per document allowed.
The documents are converted into features vectors in a
standard way. If the news article has an identiﬁed title
and body, words in those are used. Otherwise, words
in the text of the news article are used. All words
are folded to lower case and then stemmed. Com-
mon words are removed from the list, and the remain-
ing unique stemmed words in the corpus became fea-
tures. The feature dimensionality is 22226, which is
extremely high:
larger than the number of examples
in the set.
Each document i is represented by the standard tf-idf
vector representation, denoted by tik, which is nor-
malized to unit length. The distance squared matrix
is then computed via

ij = 1 −X

D2

tiktjk

(22)

m = 600, which measures LMDS in a regime of high
quality. MetricMap is run with rows(A) = 2 rows(B),
as suggested by [12].

4.1.1 Relative Distance Error

The RMS relative distance error is measured by taking
100 documents at random from the set and measuring
the 100 × 100 distance matrix, both in the original
unembedded space, and in the embedded space, while
varying the dimension k of the embedding. The RMS
relative distance error is deﬁned to be

Error =

(sEi/ti − 1)2

(23)

s 1

X

10000

i

where ti is the true (unembedded) distance, Ei is the
estimated distance (in the embedded space), and s is
a scaling factor. The lower this quantity, the better
the embedding.
All three algorithms tend to underestimate the true
distance between objects. However, in most applica-
tions, absolute distance is not needed: mean relative
distance between items is the important quantity. A
linear rescaling of the distance is thus harmless. Such
a rescaling is reﬂected in s, which is the optimal scal-
ing that maps Ei into ti. This scaling is chosen to
minimize the cost function in (23):

P
P

i Ei/ti
i E2
i /t2
i

s =

.

(24)

LMDS

LMDS

Fast- Metric-

Number of
Dimensions m = 600 m = 3k Map
0.694
0.659
0.564
0.441
0.413
0.348

0.659
0.536
0.458
0.386
0.338
0.298

0.611
0.577
0.466
0.418
0.339
0.298

5
10
20
50
100
200

Map
0.841
0.652
0.863
0.725
0.573
0.587

k

where the ith document is the ith row in tik.
FastMap, LMDS, and MetricMap are applied to the
resulting distance matrix. The quality of the algo-
rithms is measured in three ways: how much RMS rel-
ative distance error is introduced by the embedding,
the F1 retrieval quality score of the nearest neighbor
in the embedded space, and CPU time. Two diﬀerent
settings of m are chosen for the LMDS experiments.
First, m = 3k is run. FastMap uses a heuristic to ﬁnd
the two farthest points that requires 3k distance rows
to be computed. In order to match the computation
of FastMap, LMDS is run with the same number of
rows. The second experiment uses LMDS run with

Table 1: RMS relative distance error on Reuters (lower
is better).

The RMS error for Reuters is shown in Table 1. Three
conclusions can be reached from this table.
First, when LMDS is only allowed to access m = 3k
distance rows (the same as FastMap), it still outper-
forms FastMap and MetricMap. This is because the
heuristic in FastMap does not work well on text feature
vectors: there are many documents that have very lit-
tle overlap with each other, because their words do not
overlap. The heuristic picks two examples that have
little overlap as pivot points. The FastMap algorithm

265then assigns most documents to the center of the co-
ordinate, because most documents have little overlap
with either of the two pivot points. Thus, it requires
roughly twice as many dimensions to reach the same
RMS error.
Second, further accuracy gains for LMDS can usually
be had by increasing m above 3k, although those gains
are slight. These gains are shown in more detail, be-
low.
Third, the extra information in the 2k×2k matrix A in
MetricMap does not help the quality of the embedding:
in fact, it actively harms it.

4.1.2 F1 Retrieval Metric

Another metric for the algorithms is how the dimen-
sionality reduction aﬀects text retrieval and catego-
rization. This is tested by ﬁnding, for each document,
the nearest other document in the mapped space.
Then, for all nearest neighbor pairs and for all labels,
a standard microaveraged F1 retrieval score is com-
puted. Let A = the number of labels that are shared
by any nearest pair. Let B = the number of labels
that appear on one of the pair, but not the other. The
F1 score is then F1 = A/(A + B/2). The higher this
quantity, the better the mapping is for text retrieval.

Fast- Metric-

LMDS

LMDS

Number of
Dimensions m = 600 m = 3k Map
0.467
0.521
0.629
0.709
0.724
0.753

0.520
0.625
0.714
0.754
0.768
0.768

0.458
0.581
0.653
0.717
0.757
0.768

5
10
20
50
100
200

Map
0.396
0.412
0.489
0.430
0.434
0.346

Table 2: F1 retrieval metric on Reuters (higher is bet-
ter).

The F1 metric for Reuters is shown in Table 2. There
are several interesting results in this table. First, the
F1 retrieval metric when applied to the original un-
mapped distances is 0.719. Thus, above 100 dimen-
sions, the F1 score for the mapped distances can be
better than the unmapped. These algorithms are im-
plementing a form of Latent Semantic Analysis [6],
which is known to improve retrieval.
Second, the
F1 scores roughly track distance error: LMDS with
m = 600 beats LMDS with m = 3k beats FastMap
beats MetricMap. Finally, for dimensions above 100,
gains in F1 performance start to asymptote.

Fast- Metric-

LMDS

LMDS

Number of
Dimensions m = 600 m = 3k Map
0.2
0.4
0.7
2.3
6.6
20.0

51.6
51.7
51.9
52.3
53.0
55.7

0.2
0.4
0.8
2.5
8.4
55.7

5
10
20
50
100
200

Map
0.1
0.1
0.3
0.9
2.9
14.9

Table 3: CPU time (in seconds) on Reuters (lower is
better).

4.1.3 CPU Time versus Accuracy

The CPU time for the three algorithms is shown in
Table 3. The experiments are run on an unloaded 2.4
GHz Xeon PC running Windows Server 2003 with 1.5
GB of RAM. The datasets are small enough to ﬁt into
memory. Proﬁling the code shows that the time is
dominated by the computation of the distance matrix
elements: the eigendecomposition and projection take
very little extra time.
Comparing FastMap and LMDS with m = 3k is illus-
trative. For dimensions less than 200, the timings are
very comparable. With m = 3k, LMDS does not in-
cur a signiﬁcant time penalty, but provides increased
performance over FastMap. MetricMap is fastest, but
the poor accuracy results in Table 2 indicate that the
algorithm should be avoided.

Algorithm

m

RMS

dist error

F1

CPU time

FastMap
LMDS
LMDS
LMDS
LMDS
LMDS
LMDS

(150)
60
100
150
200
300
600

0.441
0.424
0.428
0.417
0.403
0.380
0.386

0.709
0.687
0.704
0.717
0.730
0.742
0.753

2.3
0.9
1.5
2.5
4.0
8.1
52.2

Table 4: Comparing performance of LMDS and Fast-
Map on Reuters for diﬀerent m (k = 50).

To better understand the behavior of LMDS, the tests
are run for a ﬁxed dimensionality k = 50 and for dif-
ferent values of m. The accuracy and CPU results are
shown in Table 4. This table illustrates that LMDS
permits a time/accuracy trade-oﬀ by varying m. In-
creasing m above 3k will increase the accuracy, at the
cost of increased CPU. For this problem, the analy-
sis time is not burdensome, so the increase accuracy
is worthwhile. Eventually, the eigenvectors and eigen-
values of K are accurately estimated, so increasing m
further does not help the accuracy.

2664.2 COREL IMAGE FEATURES

The Corel Image Features is a UCI KDD data set con-
sisting of features extracted from 68,040 images. Four
sets of features are extracted: 32 color histograms, 32
color layout histograms, 9 color moments, and 16 tex-
ture features. Each of these features is continuous. No
labels are provided in the data set. Images with miss-
ing features are ignored, leaving 66,615 images. The
Corel Image Features dataset probes the algorithms in
a diﬀerent way. The data set size is larger and more
realistic.
We computed an overall distance between two image
feature vectors by ﬁrst computing the distance be-
tween each set of features. For the color histograms
and color layout histograms, we used the chi-squared
distance [10]:

ij =X

Dchi

n

2(hin − hjn)2
hin + hjn

(25)

where hin is the nth histogram bin for ith image. For
color moments and texture features, we used Euclidean
distance (not squared).
At this point, there are four distances for each pair
of images. These distances are combined into a sin-
gle distance by a weighted sum, where the weights are
computed so that the average of each of the four dis-
tances is unity across the database:

+

Dtotal

ij =

+

Dmoments

DcolorHist

ij
2.457

Dlayout
ij
2.006

Dtexture
7.212 .
(26)
Again, the Corel Features dataset stresses the algo-
rithms more than Reuters: the distance is not a Eu-
clidean distance, but a sum of heterogeneous distances,
which can provoke negative eigenvalues.

ij
4.295

ij

+

4.2.1 Relative Distance Error

Fast- Metric-

LMDS

LMDS

Number of
Dimensions m = 150 m = 3k Map
0.545
0.384
0.254
0.147
0.124
N/A

0.516
0.326
0.142
0.075
0.069
0.108

0.529
0.377
0.174
0.086
0.082
0.108

1
2
5
10
20
50

Map
0.540
0.482
0.373
0.390
0.546
0.530

Table 5: RMS relative distance error on Corel Image
Features (lower is better).

Because there are no image labels provided, we test
the eﬀectiveness of each algorithm with RMS relative
distance error, as computed in (23). These accuracy

results are shown in Table 5. There are severable no-
table features of the data in this table. First, Fast-
Map yielded negative pivot distances for k = 50. That
is, even the two farthest points in the database have
negative squared distance after 50 rounds of deﬂation:
no result for k = 50 could be produced by FastMap.
Second, LMDS provides a noticeable improvement in
accuracy for k > 1, even when m = 3k. LMDS with
m = 150 is even more accurate. Third, as in Reuters,
MetricMap has far worse accuracy than either of the
other algorithms. Finally, the innate dimensionality of
this data set may be less than 50, because the results
for k = 50 are worse than for k = 20. This can happen,
because the original distance matrix is non-Euclidean.

4.2.2 CPU Time versus Accuracy

Fast- Metric-

LMDS

LMDS

Number of
Dimensions m = 150 m = 3k Map
0.2
0.5
1.4
2.7
5.6
N/A

13.3
13.3
13.4
13.5
13.7
14.4

0.2
0.5
1.3
2.6
5.3
14.4

1
2
5
10
20
50

Map
0.1
0.2
0.5
0.9
1.9
5.5

Table 6: CPU time (in seconds) on Corel Image Fea-
tures (lower is better).

CPU times for the algorithms on this dataset are
shown in Table 6. None of the CPU times are onerous.
As in Reuters, LMDS for m = 150 is dominated by
the computation of the distance matrix. However, for
m = 3k, LMDS is competitive with FastMap. Metric-
Map is substantially faster (because it computes the
fewest distance matrix elements), but its poor accu-
racy is not worth the increased speed.

Algorithm
FastMap
LMDS
LMDS
LMDS
LMDS
LMDS
LMDS

m
(60)
40
60
100
150
200
300

RMS dist error CPU time

0.124
0.125
0.082
0.072
0.069
0.069
0.067

5.6
3.6
5.4
9.0
13.7
18.7
30.5

Table 7: Comparing performance of LMDS and Fast-
Map on Corel Image Features for diﬀerent m (k = 20).

Finally, the performance of LMDS is examined as a
function of m for ﬁxed k = 30 in Table 7. As m in-
creases, LMDS surpasses the performance of FastMap
until m = 100, where the accuracy is reaches a plateau
and further increases in m do not help.

2675 CONCLUSIONS

This paper has shown that FastMap, MetricMap, and
Landmark MDS (LMDS) all utilize the Nystr¨om ap-
proximation to the eigenvectors of a large matrix. This
uniﬁcation highlights how the algorithms are related
and can lead to future work.
These algorithms use diﬀerent variations on the
Nystr¨om approximation.
LMDS uses the basic
Nystr¨om approximation. FastMap uses deﬂation to
embed items one dimension at a time. MetricMap uses
an expanded matrix to ﬁx the embedding of the land-
mark points. However, empirical evidence has shown
that the variations of the Nystr¨om algorithm are not
beneﬁcial for MDS.
The deﬂation in FastMap limits the time/accuracy
tradeoﬀ that is inherent in the basic all-dimensions-
at-once Nystr¨om approximation. By increasing m (the
number of rows computed in the original distance ma-
trix), LMDS becomes more accurate, but the computa-
tion of the distance matrix elements require more time.
FastMap freezes this tradeoﬀ by choosing a constant
number of rows per dimension. Even with the same
number of rows of the distance matrix, LMDS is more
accurate. Thus, the all-dimensions-at-once LMDS al-
gorithm is preferred.
MetricMap uses a larger matrix than basic Nystr¨om to
compute the embedding coordinates of the landmark
points. Empirically, this causes a substantial decrease
in accuracy. This decrease in accuracy is probably
because increasing the size of the A matrix does not
improve the ﬁtting of the landmark points: the number
of landmark points grows as the dimension of A. Thus,
the extra data in A is not used to eliminate noise in
the position on the landmark points.
In conclusion, the basic Nystro ¨m approximation in
LMDS is faster and more accurate than the Nystro ¨m
variations proposed in FastMap and MetricMap. This
superiority may carry over to other data sets and ap-
plications other than MDS.

Acknowledgements

I would like to thank Chris Burges and Dimitris
Achlioptas for discussions and help with the paper.

References

[1] S. Belongie, C. Fowlkes, F. Chung, and J. Malik.
Spectral partitioning with indeﬁnite kernels using
the Nystr¨om extension. In Proc. ECCV, 2002.

[2] Y. Bengio, J.-F. Paiement, and P. Vincent. Out-
of-sample extensions for LLE, Isomap, MDS,

Eigenmaps and spectral clustering. In S. Thrun,
L. Saul, and B. Sch¨olkopf, editors, Proc. NIPS,
volume 16, 2004.

[3] M. Chalmers. A linear iteration time layout
algorithm for visualizing high-dimensional data.
In Proc. IEEE Information Visualization, pages
127–132, 1996.

[4] T. Cox and M. Cox. Multidimensional Scaling.
Number 59 in Monographs on Statistics and Ap-
plied Probability. Chapman & Hall, 1994.

[5] V. de Silva and J. B. Tenenbaum. Global versus
local methods in nonlinear dimensionality reduc-
tion. In S. Becker, S. Thrun, and K. Obermayer,
editors, Proc. NIPS, volume 15, pages 721–728,
2003.

[6] S. C. Deerwester, S. T. Dumais, T. K. Landauer,
G. W. Furnas, and R. A. Harshman. Indexing by
latent semantic analysis. Journal of the Amer-
ican Society of Information Science, 41(6):391–
407, 1990.

[7] C. Faloutsos and K. Lin. FastMap: a fast al-
gorithm for indexing, data-mining, and visualiza-
tion.
In Proc. ACM SIGMOD, pages 163–174,
1995.

[8] G. Golub and C. V. Loan. Matrix Computations.

Johns Hopkins University Press, 1983.

[9] S. Hettich and S. Bay. The UCI KDD archive.
[http://kdd.ics.uci.edu] Irvine, CA: UCI, Dept.
Information and Computer Science.

[10] A. Papoulis. Probability, Random Variables, and

Stochastic Processes. McGraw Hill, 1991.

[11] B. Sch¨olkopf. The kernel trick for distances. In

Proc. NIPS, pages 301–307, 2000.

[12] J. T.-L. Wang, X. Wang, K.-I. Lin, D. Shasha,
B. A. Shapiro, and K. Zhang. Evaluating a class
of distance-mapping algorithms for data mining
and clustering. In Proc. ACM KDD, pages 307–
311, 1999.

[13] C. Williams and M. Seeger. Using the Nystr¨om
method to speed up kernel machines. In Advances
in Neural Information Processing Systems, vol-
ume 13, pages 682–688, 2001.

[14] M. Williams and T. Munzner. Steerable, progres-
sive multidimensional scaling. In Proc. IEEE In-
formation Visualization, pages 57–64, 2004.

268Bayesian Conditional Random Fields

Yuan (Alan) Qi

MIT CSAIL

32 Vassar Street

Cambridge, MA 02139

Martin Szummer
Microsoft Research
Cambridge, CB3 0FB

United Kingdom

Thomas P. Minka
Microsoft Research
Cambridge, CB3 0FB

United Kingdom

alanqi@csail.mit.edu

szummer@microsoft.com

minka@microsoft.com

Abstract

We propose Bayesian Conditional Random
Fields (BCRFs) for classifying interdependent
and structured data, such as sequences, images
or webs. BCRFs are a Bayesian approach to
training and inference with conditional random
ﬁelds, which were previously trained by maxi-
mizing likelihood (ML) (Lafferty et al., 2001).
Our framework eliminates the problem of overﬁt-
ting, and offers the full advantages of a Bayesian
treatment. Unlike the ML approach, we estimate
the posterior distribution of the model parameters
during training, and average over this posterior
during inference. We apply an extension of EP
method, the power EP method, to incorporate the
partition function. For algorithmic stability and
accuracy, we ﬂatten the approximation structures
to avoid two-level approximations. We demon-
strate the superior prediction accuracy of BCRFs
over conditional random ﬁelds trained with ML
or MAP on synthetic and real datasets.

1 Introduction

Traditional classiﬁcation models assume that data items are
independent. However, real world data is often interde-
pendent and has complex structure. Suppose we want to
classify web pages into different categories, e.g., home-
pages of students versus faculty. The category of a web
page is often related to the categories of pages linked to
it. Rather than classifying pages independently, we should
model them jointly to incorporate such contextual cues.

Joint modeling of structured data can be performed by gen-
erative graphical models, such as Bayesian networks or
Markov random ﬁelds. For example, hidden Markov mod-
els have been used in natural language applications to as-
sign labels to words in a sequence, where labels depend
both on words and other labels along a chain. However,

generative models have fundamental limitations. Firstly,
generative models require speciﬁcation of the data genera-
tion process, i.e., how data can be sampled from the model.
In many applications, this process is unknown or impracti-
cal to write down, and not of interest for the classiﬁcation
task. Secondly, generative models typically assume condi-
tional independence of observations given the labels. This
independence assumption limits their modeling power and
restricts what features can be extracted for classifying the
observations. In particular, this assumption rules out fea-
tures capturing long-range correlations, multiple scales, or
other context.

Conditional random ﬁelds (CRF) are a conditional ap-
proach for classifying structured data, proposed by Lafferty
et al. (2001). CRFs model only the label distribution condi-
tioned on the observations. Unlike generative models, they
do not need to explain the observations or features, and
thereby conserve model capacity and reduce effort. This
also allows CRFs to use ﬂexible features such as complex
functions of multiple observations. The modeling power
of CRFs has shown great beneﬁt in several applications,
such as natural language parsing (Sha & Pereira, 2003),
information extraction (McCallum, 2003), and image mod-
eling (Kumar & Hebert, 2004).

To summarize, CRFs provide a compelling model for struc-
tured data. Consequently, there has been an intense search
for effective training and inference algorithms. The ﬁrst
approaches maximized conditional likelihood (ML), either
by generalized iterative scaling or by quasi-Newton meth-
ods (Lafferty et al., 2001; Sha & Pereira, 2003). However,
the ML criterion is prone to overﬁtting the data, especially
since CRFs are often trained with very large numbers of
correlated features. The maximum a posteriori (MAP) cri-
terion can reduce overﬁtting, but provides no guidance on
the choice of parameter prior. Furthermore, large margin
criteria have been applied to regularize the model parame-
ters and also to kernelize CRFs (Taskar et al., 2004; Laf-
ferty et al., 2004). Nevertheless, training and inference for
CRFs remains a challenge, and the problems of overﬁtting,
feature and model selection have largely remained open.

269In this paper, we propose Bayesian Conditional Random
Fields (BCRF), a novel Bayesian approach to training and
inference for conditional random ﬁelds. Applying the
Bayesian framework brings principled solutions and tools
for addressing overﬁtting, model selection and many other
aspects of the problem. Unlike ML, MAP, or large-margin
approaches, we train BCRFs by estimating the posterior
distribution of the model parameters. Subsequently, we can
average over the posterior distribution for BCRF inference.

The complexity of the partition function in CRFs (the de-
nominator of the likelihood function) necessitates approx-
imations. Previous deterministic approximations includ-
ing expectation propagation (EP) (Minka, 2001) or varia-
tional methods do not directly apply. In order to incorpo-
rate the partition function, we apply an extension of EP, the
power EP method (Minka, 2004). Furthermore, we ﬂatten
the approximation structures for BCRFs to avoid two-level
approximations. This signiﬁcantly enhances the algorith-
mic stability and improves the estimation accuracy.

We ﬁrst formally deﬁne CRFs, present the power EP
method, and ﬂatten the approximation structure for train-
ing. Then we propose an approximation method for model
averaging, and ﬁnally show experimental results.

2 From conditional random ﬁelds to BCRFs

A conditional random ﬁeld (CRF) models label variables
according to an undirected graphical model conditioned on
observed data (Lafferty et al., 2001). Let x be an “input”
vector describing the observed data instance, and t be an
“output” random vector over labels of the data components.
We assume that all labels for the components belong to a
ﬁnite label alphabet T = {1, . . . , T}. For example, the in-
put x could be image features based on small patches, and
t be labels denoting ’person, ’car’ or ’other’ patches. For-
mally, we have the following deﬁnition of CRFs (Lafferty
et al., 2001):
Deﬁnition 2.1 Let G = (V,E) be a graph such that t is
indexed by the vertices of G. Then (x, t) is a conditional
random ﬁeld (CRF) if, when conditioned on x, the random
variables ti obey the Markov property with respect to the
graph: p(ti|x, tV−i) = p(ti|x, tNi) where V− i is the set
of all nodes in G except the node i, Ni is the set of neigh-
bors of the node i in G, and tΩ represents the random vari-
ables of the vertices in the set Ω.

Unlike traditional generative random ﬁelds, CRFs only
model the conditional distribution p(t|x) and do not explic-
itly model the marginal p(x). Note that the labels {ti} are
globally conditioned on the whole observation x in CRFs.
Thus, we do not assume that the observed data x are con-
ditionally independent as in a generative random ﬁeld.

BCRFs are a Bayesian approach to training and inference
with conditional random ﬁelds. In some sense, BCRFs can
be viewed as an extension of conditional Bayesian linear
classiﬁers, e.g., Bayes point machines (BPM)
(Herbrich
et al., 1999; Minka, 2001), which are used to classify inde-
pendent data points.

According to the Hammersley-Clifford theorem, a CRF de-
ﬁnes the conditional distribution of the labels t given the
observations x to be proportional to a product of potential
functions on cliques of the graph G. For simplicity, we
consider only pairwise clique potentials such that

Y

{i,j}∈E

p(t|x, w) =

1

Z(w)

where

Z(w) =X

t

Y

{i,j}∈E

gi,j(ti, tj, x; w)

(1)

gi,j(ti, tj, x; w)

(2)

is a normalizing factor known as the partition function,
gi,j(ti, tj, x; w) are pairwise potentials, and w are the
model parameters. Note that the partition function is a
complicated function of the model parameter w. This
makes Bayesian training much harder for CRFs than
for Bayesian linear classiﬁers, since the normalizer of a
Bayesian linear classiﬁer is a constant.

In standard conditional random ﬁelds, the pairwise poten-
tials are deﬁned as

gi,j(ti, tj, x; w) = exp(wT

ti,tj

φi,j(x, ti, tj))

(3)

where φi,j(x, ti, tj) are features extracted for the edge be-
tween vertices i and j of the conditional random ﬁeld, and
wti,tj are elements corresponding to labels {ti, tj} in w,
T,T ]T. There are no restric-
where w = [wT
tions on the relation between features.

1,2, . . . , wT

1,1, wT

Instead of using an exponential potential function, we pre-
fer to use the probit function Ψ(·) (the cumulative distri-
bution function of a Gaussian with mean 0 and variance
1). This function is bounded, unlike the exponential, and
permits efﬁcient Bayesian training. Furthermore, to incor-
porate robustness against labeling errors, we allow a small
probability  of a label being incorrect, thus bounding the
potential away from 0. Speciﬁcally, our robust potentials
are:

gi,j(ti, tj, x; w) = (1 − )Ψ(wT

(1 − Ψ(wT

ti,tj

φi,j(x, ti, tj))+

ti,tj
φi,j(x, ti, tj))).

(4)

Given the data likelihood and a Gaussian prior p0(w) ∼
N (w; 0, diag(α)), the posterior of the parameters is

p(w|t, x) ∝ 1

Z(w) p0(w) Y

{i,j}∈E

gi,j(ti, tj, x; w)

(5)

270Expectation Propagation exploits the fact that the posterior
is a product of simple terms. If we approximate each of
these terms well, we can get a good approximation of the
posterior. Mathematically, EP approximates p(w|t, x) as

q(w) = p0(w)

1

˜Z(w)

˜gi,j(w)

(6)

Y

{i,j}∈E

1

˜R(w)

=

where ˜R(w) = p0(w)Q{i,j}∈E ˜gi,j(w) is the numerator

˜Z(w)

(7)

1

˜Z(w)

in q(w). The approximation terms ˜gi,j(w) and
have
the form of a Gaussian, so that the approximate posterior
q(w) is a Gaussian, i.e., q(w) ∼ N (mw, Σw). We can ap-
proximate the pairwise potential functions gi,j(ti, tj, x; w)
by ˜gi,j(w) in the numerator ˜R(w), just as in Bayesian lin-
ear classiﬁers (Minka, 2001). The main difﬁculty here is
how to approximate the denominator Z(w) by ˜Z(w) and
incorporate it into q(w).

3 EP and Power EP

This section reviews EP and presents power EP algorithms
for BCRFs. Power EP is an extension of EP to make the
computations more tractable. It was ﬁrst used by Minka
and Lafferty (2002), in the case of positive powers. How-
ever, power EP also works with negative powers, and this is
one of the key insights that makes BCRF training tractable.

Given a distribution p written as a product of terms, and
an approximating family q as in the previous section, Ex-
pectation Propagation tries to make q “close” to p in the
sense of the Kullback Leibler divergence KL(p||q) =

R p(w) log(p(w)/q(w))dw. This is done by minimizing

the divergence with respect to each term individually, hold-
ing the other terms ﬁxed. We repeatedly cycle through all
the terms until a ﬁxed point is reached.

For the gk terms, where k indexes edges, the algorithm ﬁrst
computes q\k(w), which represents the “rest of the distri-
bution.” Then it minimizes KL-divergence over ˜gk, hold-
ing q\k ﬁxed. This process can be written succinctly as
follows:

q\k(w) ∝ q(w)/˜gk(w)
(8)
˜gk(w)new = argmin KL(gk(w)q\k(w) || ˜gk(w)q\k(w))
(9)

= proj

gk(w)q\k(w)

/q\k(w)

(10)

h

i

q(w)new = q\k(w)˜gk(w)new
Here proj is a “moment matching” operator: it ﬁnds the
Gaussian having the same moments as its argument, thus
minimizing KL. Algorithmically, (8) means “divide the
Gaussians to get a new Gaussian, and call it q\k(w).” Sim-
ilarly, (9) means “construct a Gaussian whose moments

(11)

match gk(w)q\k(w) and divide it by q\k(w), to get a new
Gaussian which replaces ˜gk(w).” This is the basic EP al-
gorithm.

Power EP introduces a power nk into EP and modiﬁes the
updates as follows:

q\k(w) ∝ q(w)/˜gk(w)1/nk
˜gk(w)new =

proj

(cid:16)

h

q(w)new = q(w)

gk(w)1/nk q\k(w)
˜gk(w)new
˜gk(w)

i

/q\k(w)

(cid:17)nk

(12)

(13)

(14)

As shown by Minka (2004), this update seeks to mini-
mize a different measure of divergence, the α-divergence,
where α = 2/nk − 1. Note that α can be any real num-
ber. By picking the power nk appropriately, the updates
can be greatly simpliﬁed. (This result is originally due to
Wiegerinck and Heskes (2002). They discussed an algo-
rithm called “fractional belief propagation” which is a spe-
cial case of power EP, and all of their results also apply to
power EP.)

We will use this update for the denominator term, so that
gk becomes 1/Z, ˜gk becomes 1/ ˜Z, and pick nk = −1:

q\z(w) ∝ q(w)/ ˜Z(w) = ˜R(w)/ ˜Z(w)2
/q\z(w)
˜Z(w)new = proj

h

i

q(w)new = q(w)

Z(w)q\z(w)
˜Z(w)
˜Z(w)new

(15)

(16)

(17)

In this way, we only need the moments of Z(w), not
1/Z(w).

4 Approximating the partition function

In the moment matching step, we need to approximate the
moments of Z(w)q\z(w). Murray and Ghahramani (2004)
have proposed approximate MCMC methods to approxi-
mate the partition function of an undirected graph. This
section presents an alternative method.

For clarity, let us rewrite the partition function as follows:

Z(w) =X
Z(w, t) = Y

t

k∈E

Z(w, t)

gk(ti, tj, x; w)

(18)

(19)

where k = {i, j} indexes edges. To compute the mo-
ments of w, we can use EP recursively, to approximate
Z(w, t)q\z(w) as a function of w and t. The approxi-
mation will have a factorized form:

q(w)q(t) = ˜Z(w) ˜Z(t)q\z(w)

˜Z(w) ˜Z(t) = Y

˜fk(w) ˜fk(ti) ˜fk(tj)

(20)

(21)

k∈E

271q\k(ti)q\k(tj)

y , V\k
y )

q\k(ti)q\k(tj)

w − V\k

y )−1(cid:0)my − m\k

w AkDAT

(cid:1)
k V\k

w

y

Vw = V\k
c = (V\k
D = (V\k

where

ti,tj

ti,tj

q\k(ti)q\k(tj)Zti,tj

q\k(ti, tj)

Z =X
=X
R fk(y)yN (y|m\k
P
R fk(y)yyTN (y|m\k
P

Zti,tj myti,tj
Z

ti,tj

=

Z

Z

ti,tj

Zti,tj Gyti,tj
Z

my =

y , V\k
y )

Gy =

=

where

zti,tj =

ρti,tj =

Zti,tj =

y

y eT

k + 1

q
ekm\k
ekV\k
y eT
q
1
Z
ekV\k
Z
Ψ(yi,j)N (y|m\k
Ψ(eky)N (y|m\k
=
R Ψ(eky)yN (y|m\k
=  + (1 − 2)Ψ(zti,tj )

k + 1

Zti,tj
y ρti,tj eT
k

=
y + V\k
= m\k
y −
= V\k
(cid:0) ρti,tj (ekmyti,tj
ekV\k
y e0

y eT
k

V\k

myti,tj

Gyti,tj

(1 − 2N (zti,tj|0, 1))
 + (1 − 2)Ψ(zti,tj )

y )dy

y , V\k
y , V\k

y )dy

y , V\k

y )dy

(cid:1)ekV\k

y

+ ρti,tj )

k + 1

y )(V\k

y )−1

y )−1(Gy − mymT
y )−1 − (V\k
Z

Ψ(yti,tj )N (y|m\k

y , V\k

y )dy

(32)

(33)

(34)

(35)

(36)

(37)

(38)

(39)

(40)

(41)

(42)

(43)

(44)

(45)

(46)

(47)

(48)

i

fk(w) =X
˜fk(ti)new =X

˜fk(w)new = proj

ti,tj

h
Z

where ˜fk(w) ˜fk(ti) ˜fk(tj) approximates gk(ti, tj, x; w) in
the denominator. Note that this q(w) is the same as the
overall q(w) at the convergence.

Because the approximation is factorized, the computation
will have the ﬂavor of loopy belief propagation. The initial
˜fk will be 1, making the initial q(w) = q\z(w) and q(t) =
1. The EP update for ˜fk is:
q\k(w) ∝ q(w)/ ˜fk(w)
q\k(ti) ∝ q(ti)/ ˜fk(ti)

(22)

(23)

(similarly for j)
gk(ti, tj, x; w)q\k(ti)q\k(tj)

(24)

/q\k(w)

q\k(w)fk(w)
gk(ti, tj, x; w)q\k(w)q\k(tj)dw

(25)

tj

w

q(w)new = q\k(w) ˜fk(w)new
q(ti)new = q\k(ti) ˜fk(ti)new

(26)

(27)

(28)

These updates are iterated for all k, until a ﬁxed point is
reached. A straightforward implementation of the above
updates costs O(d3) time, where d is the dimension of the
parameter vector w, since they involve inverting the covari-
ance matrix of w. However, as shown in the next section,
it is possible to do them with low-rank matrix updates, in
O(d2) time.

5 Efﬁcient low-rank matrix computation for

moments

First, let us deﬁne φk(m, n, x) as shorthand of φk(ti =
m, tj = n, x), where φk(ti, tj, x) are feature vectors ex-
tracted at edge k = {i, j} with labels ti and tj on nodes i
and j, respectively. Then we have

0

φk(1, 2, x)

. . .

. . .
0
0

0
. . .

φk(T, T, x)

Ak =

fk(y) =X

y = AT

k w
Ψ(yti,tj )q\k(ti)q\k(tj)

ti,tj

where yti,tj = wTφk(ti, tj, x). Clearly, we can rewrite
q(w) as fk(y)q\k(w). Since the dimensionality of y is
usually a lot smaller than that of w, the exact term fk(y)
only constrains the distribution q(w) in a smaller subspace.
Therefore, it is sensible to use low-rank matrix computation
to obtain mw and Vw, the mean and variance of q(w).
The derivation is omitted because of the space limitation.
The details can be found in Qi (2004). Here, we simply
give the updates:

(cid:18) φk(1, 1, x)

0
0

(cid:19)

(29)

(30)

where ek is a vector with all elements being zeros except
its kth element being one.
We update q(ti) and q(tj) as follows:
Zti,tj q\k(ti)q\k(tj)

q(ti, tj) =

q(ti) =X

Z
q(ti, tj),

q(tj) =X

q(ti, tj)

(50)

(49)

mw = m\k

w + V\k

w Akc

(31)

tj

ti

2726 Flattening the approximation structure

In practice, we found that the approximation method, pre-
sented in Sections 3 and 4, led to non-positive covariance
matrices in training. In this section, we examine the reason
for this problem and propose a method to ﬁx it.

The approximation method has two levels of approxima-
tions, which are visualized at the top of Figure 1. At the
upper level of the top graph, the approximation method iter-
atively reﬁnes the approximate posterior q(w) based on the
term approximation ˜Z(w); at the lower level, it iteratively
reﬁnes ˜Z(w) by smaller approximation terms { ˜fk(w)}.
A naive implementation of the two-level approximation
will always initialize the approximation terms { ˜fk(w)}
as 1, such that the iterations at the lower level start from
scratch every time. Thus, removing the denominator ˜Z(w)
in the upper level amounts to removing all the previous ap-
proximation terms { ˜fk(w)} in the lower level. The naive
implementation requires the “leave-one-out” approxima-
tion q\z(w) ∝ q(w)
to have a positive deﬁnite covariance
matrix. Since this requirement is hard to meet, the training
procedure often skips the whole denominator Z(w) in the
upper level. This skipping would dramatically decrease the
approximation accuracy in practice.

˜Z(w)

A better idea is to keep the values of the approximation
terms and initialize the approximation terms using the val-
ues obtained from the previous iterations. By doing so, we
do not require the covariance of q\z(w) to be positive deﬁ-
nite anymore. Instead, we need that of q\k(w) in equation
(22) to be positive deﬁnite, which is easier to satisfy. Now,
when the iterations in the lower level start, q\k(w) usually
has a positive deﬁnite covariance. However, after a few
iterations, the covariance of q\k(w) often becomes non-
positive deﬁnite again. The underlying reason is that the
partition function Z(w) is a complicated function, which
is difﬁcult to be accurately approximated by EP.

To address the problem, we ﬂatten the two-level approx-
imation structure by expanding ˜Z(w) in the upper level.
Now we focus on q(w), which is of our interest in training,
without directly approximating the difﬁcult partition func-
tion Z(w) in the intermediate step. The ﬂattened structure
is shown at the bottom of the Figure 1. Speciﬁcally, the
approximate posterior q(w) has the following form:

q(w) ∝ p0(w)Y

1Q

k∈E ˜fk(w)

˜gk(w)

k∈E

(51)

Equation (51) uses the approximation term ˜fk(w) for each
edge rather than using ˜Z(w). It is also possible to interpret
the ﬂattened structure from the perspective of the two-level
approximation structure. That is, each time we partially
update ˜Z(w) based on only one small term approximation
˜fk(w), and then reﬁne q(w) before updating ˜Z(w) again
based on another small term approximation.

Figure 1: Flattening the approximation structure. The up-
per graph shows the two-level approximation structure of
the methods described in the previous sections. The lower
graph shows the ﬂattened single-level approximation struc-
ture.

With the ﬂattened structure, the deletion steps for removing
˜gk(w) and ˜fk(w) remain the same as before. The moment
matching steps are the same too. We only need to assign
negative power one to the approximation terms in the de-
nominators. Speciﬁcally, we have the following updates:

hk =(cid:0)D−1 − AT

(cid:1)−1

µk = c + hkAT
ξk = 2hold
Vw = V\k

k − hk ηk = 2µold
w − V\k
−1
k + AT

k − µk
k V\k

w Ak(ξ

w Ak)−1AT

k V\k

w

w Ak

k V\k
k mw

(52)
(53)
(54)

(55)
k m\k
w +
(56)

w − V\k

w Ak(ξ

mw = m\k
VwAkηk

−1
k + AT

k V\k

w Ak)−1AT

where c and D are deﬁned in Equations (33) and (34).
Note that the above computation takes O(d2) time, while
a simple implementation of the two-level approximation
would take O(d3) time due to the inverse of the covariance
matrix of ˜Z(w).
As a result of structure ﬂattening, we have the following
advantages over the previous two approaches. First, in our
experiments, training can converge easily. Instead of itera-
tively approximating Z(w) in the lower level based all the
small terms as before, a partial update based on only one
small term makes training much more stable. Second, we
can obtain a better “leave-one-out” posterior q\k(w), since
we update q(w) more frequently than in the previous two
cases. A more reﬁned q(w) leads to a better q\k(w), which
in turn guides the KL mininmization to ﬁnd a better new
q(w). Finally, the ﬂattened approximation structure allows
us to process approximation terms in any order. We found
empirically that, compared to using a random order, it is
better to process the denominator term { ˜fk(w)} right after
processing the numerator term {˜gk(w)}, which is associ-

IterationsIterationsIterationsRemove the intermediate level273ated with the same edge as { ˜fk(w)}.
Using the ﬂattened structure and pairing the processing of
the corresponding numerator and denominator terms, we
can train BCRFs robustly. For example, on the tasks of
analyzing synthetic datasets in the experimental section,
training with the two-level structure breaks down by skip-
ping { ˜Z(w)} or { ˜fk(w)} and fails to converge. In contrast,
training with the ﬂattened structure converges successfully
and leads to a test error around 10%.

i )q\k(t?
j )

q(t?

i , t?

Zt?

j ) =

i ) =X
j ) =X

tj

q(t?

q(t?

i ,t?
j

q\k(t?
Z
j )
i , t?

q(t?

q(t?

j )
i , t?

(61)

(62)

(63)

ti

where φk is the feature vector extracted at the kth edge.
Note that the deletion and inclusion steps for q(t?) are sim-
ilar to those in BCRF training.

7 Inference by approximate model

averaging

8 Experimental results

Unlike traditional classiﬁcation problems, where we have a
scalar output for each input, a BCRF jointly labels all the
hidden vertices in an undirected graph. The trained BCRF
infer the lables by model averaging, which makes full use
of the training data by employing not only the estimated
mean of the parameters, but also the estimated uncertainty
(variance).
Given a new graph x?, a BCRF trained on (x, t) can ap-
proximate the predictive distribution as follows:

p(t?|x?, w)p(w|t, x)dw

p(t?|x?, w)q(w)dw

(57)

(58)

Z(w)

{i,j}∈E

gi,j(t?

i , t?

j , x?; w)dw

Z
Z
Z q(w)

Y

p(t?|x?, t, x) =

≈

=

where q(w) is the approximation of the true posterior
p(w|t, x). Since the exact integration for model averaging
is intractable, we need to approximate this integral.

We can approximate the predictive posterior term by term
as in EP. But typical EP updates will involve the updates
over both the parameters and the labels. That is much
more expensive than using a point estimate for inference,
which invloves only updates of the labels. To reduce the
computational complexity, we propose the following ap-
proach. It is based on the simple fact that without any la-
bel, the test data point does not offer information about the
parameters in the conditional model, since we do not cou-
ple BCRFs with semi-supervised learning. Since q(w) is
unchanged, we can only update q(t?) when incorporating
one term gi,j(t?
j , x; w). Speciﬁcally, given the poste-
rior q(w) ∼ N (mw, Vw), we use the factorized approx-
j ) as

imation q(t?) = Q

i ) and update q(t?

i ) and q(t?

i , t?

i q(t?

follows:

q

w

=

k m\k
φT
k V\k
w φk + 1
φT
=  + (1 − 2)Ψ(zt?

i ,t?
j

zt?

i ,t?
j

Zt?

i ,t?
j

(59)

(60)

)

This section compares BCRFs with CRFs trained by max-
imum likelihood (ML) and maximum a posteriori (MAP)
methods on several synthetic datasets and a document la-
beling task, demonstrating BCRFs’ superior test perfor-
mance. MAP-trained CRFs include CRFs with probit po-
tential functions (4) and CRFs with exponential potential
functions (3). We used probit models as potential functions
by setting  = 0 in equation (4). In BCRF training, we
used a small step size to avoid divergence (see details in
Qi (2004)). For comparsion, the errors were counted on all
vertices in the test graphs.

8.1 Synthetic CRFs classiﬁcation

All the synthetic datasets were sampled from CRFs with
probit potential functions (4). On these synthetic datasets,
we compared the test performance of BCRFs and MAP-
trained probit CRFs for different sizes of training sets and
different graphical structures.

The labels of the vertices in synthetic graphs are all binary.
The parameter vector w has 24 elements. The feature vec-
tors {φi,j} are randomly sampled from one of four Gaus-
sians. We can easily control the discriminability of the data
by changing the variance of the Gaussians. Based on the
model parameter vector and the sampled feature vectors,
we can compute the joint probability of the labels as in
equation (1) and randomly sample the labels. For BCRFs,
we used a step size of 0.8 for training. For MAP-trained
CRFs, we used quasi-Newton methods with the BFGS ap-
proximation of Hessians (Sha & Pereira, 2003).

8.1.1 Different training sizes for loopy CRFs

Each graph has 3 vertices in a loop. In each trial, 10 loops
were sampled for training and 1000 loops for testing. The
procedure was repeated for 10 trials. A Gaussian prior with
mean 0 and diagonal variance 5I was used for both BCRF
and MAP CRF training. For ML- and MAP-trained CRFs,
we applied the junction tree algorithm for inference. For
BCRFs, we used approximate model averaging for infer-
ence. We repeated the same experiments by increasing the
number of training graphs from 10 to 30 to 100.

274Figure 2: Test error rates for MAP-trained CRFs and
BCRFs on synthetic datasets with different numbers of
training loops. The results are averaged over 10 runs. Each
run has 1000 test loops. Non-overlapping of error bars, the
standard errors scaled by 1.64, indicates 95% signiﬁcance
of the performance difference.

Figure 3: Test error rates for MAP-trained CRFs and
BCRFs on synthetic datasets with different numbers of
training chains. The results are averaged over 10 runs.
Each run has 1000 test chains. Though the error bars over-
lap a little bit, BCRFs still outperform ML- and MAP-
trained CRFs at 95% signiﬁcance according to t-tests.

The results are visualized in Figure 2. According to t-
tests, which have stronger test power than the error bars in
Figure 2, BCRFs outperform ML- and MAP-trained CRFs
in all cases at 98% statistical signiﬁcance level. When
more training graphs are available, MAP-trained CRFs and
BCRFs perform increasingly similarly, though still statis-
tically differently. The reason is that the posterior is nar-
rower than in the case of fewer training graphs, such that
the posterior mode is closer to the posterior mean.

8.1.2 Different training sizes for chain-structured

CRFs

We then changed the graphs to be chain-structured. Specif-
ically, each graph has 3 vertices in a chain. In each trial,
10 chains were sampled for training and 1000 chains for
testing. The procedure was repeated for 10 trials. A Gaus-
sian prior with mean 0 and diagonal variance 5I was used
for both BCRF and MAP CRF training. Then we repeated
the same experiments by increasing the number of training
graphs from 10 to 30 to 100. The results are visualized
in Figure 3. Again, BCRFs outperform ML- and MAP-
trained CRFs with high statistical signiﬁcance.

8.2 FAQ labeling

introduced by McCallum et al.

We compared BCRFs with MAP-trained probit and ex-
ponential CRFs on the frequently asked questions (FAQ)
dataset,
(2000). The
dataset consists of 47 ﬁles, belonging to 7 Usenet news-
group FAQs. Each ﬁles has multiple lines, which can be
the header (H), a question (Q), an answer (A), or the tail

(T). Since identifying the header and the tail is relatively
easy, we simplify the task to label only the lines that are
questions or answers. To save time, we truncated all the
FAQ ﬁles such that no ﬁle has more than 500 lines. On av-
erage, the truncated ﬁles have 479 lines. The dataset was
randomly split 10 times into 19 training and 28 test ﬁles.
Each ﬁle was modeled by a chain-structured CRF, whose
vertices correspond to lines in the ﬁles. The feature vec-
tor for each edge of a CRF is simply the concatenation of
feature vectors extracted at the two neighboring vertices.

Figure 4: Test error rates of different algorithms on FAQ
dataset. The results are averaged over 10 random splits.
Non-overlapping of the error bars, the standard errors mul-
tiplied by 1.64, indicates that BCRFs outperform MAP-
trained CRFs with probit and exponential potentials at 95%
statistical signiﬁcance level.

The test performance is visualized in Figure 4. According
to t-tests, BCRFs outperform ML- and MAP-trained CRFs
with probit or exponential potentials on the truncated FAQ
dataset at 98% statistical signiﬁcance level.

1030501001015202530Number of Training graphsTest error rate (%)ML−CRFMAP−CRFBCRF−MA1030501002224262830323436Number of Training graphsTest error rate (%)ML−CRFMAP−CRFBCRF−MABCRF−MAMAP−Exp−CRF MAP−Probit−CRF0.51.01.5Test error rate (%)2758.3 Comparing computational complexity

Acknowledgment

In general, the computational cost of ML and Bayesian
training depends on many factors. On the one hand, for
ML and MAP training, the cost of the BFGS algorithm is
O(d max{d,|E|}) per iteration, where d is the length of w,
and |E| is the total number of edges in training graphs. The
cost of BCRF training is O(|E|d2) per iteration. There-
fore BCRF training is about as min{d,|E|} times expen-
sive as ML and MAP training per iteration. On the other
hand, BCRF training generally takes much fewer iterations
to converge than BFGS training. Moreover, in BFGS train-
ing there is an embedded inference problem to obtain the
needed statistics for optimization. This inference problem
can be relatively expensive and cause a big hidden constant
in O(d max{d,|E|}), the BFGS cost per iteration. On syn-
thetic data where the number of edges is limited, BCRF
training is at least as efﬁcient as BFGS training. For ex-
ample, given the 10 training sets in Section 8.1.2, each
of which has 30 chain-structured CRFs, BCRF and BFGS
training on a Pentium 4 3.1GHz computer used 8.81 and
21.16 seconds on the average, respectively. On real-world
data, many factors play together to determine the efﬁciency
of a training method. On a random split of the FAQ dataset
where the total number of edges in graphs is more than
8000, it took about 9 and 2 hours (443 and 130 iterations)
for BFGS to train probit and exponential CRFs, while it
took BCRF training about 6 hours (30 iterations).

9 Conclusions

This paper has presented BCRFs, a new approach to train-
ing and inference on conditional random ﬁelds. In train-
ing, BCRFs approximate the posterior distribution of the
parameters using a variant of the power EP method. Also,
BCRFs ﬂatten approximation structures to increase the al-
gorithmic stability, efﬁciency, and prediction accuracy. In
testing, BCRFs use approximate model averaging. On syn-
thetic data and FAQ ﬁles, we compared BCRFs with ML-
and MAP-trained CRFs.
In almost all the experiments,
BCRFs outperformed ML- and MAP-trained CRFs signiﬁ-
cantly.

Compared to ML- and MAP-trained CRFs, BCRFs can ap-
proximate model averaging over the posterior distribution
of the parameters, instead of using a MAP or ML point es-
timate of the parameter vector for inference. Furthermore,
BCRF hyperparameters can be optimized in a principled
way, such as by maximizing the evidence, with parame-
ters integrated out. EP returns an estimate of the evidence
as a by-product. Similarly, we can use the method by Qi
et al. (2004) to do feature selection with BCRFs and to ob-
tain sparse kernelized BCRFs. More importantly, the tech-
niques developed for BCRFs have promise for Bayesian
learning in Markov networks.

Y. Qi was supported by the Things That Think consortium at the
MIT Media laboratory before he moved to CSAIL. Thanks to
Andrew McCallum for providing the features used in the FAQ
dataset and Fei Sha for offering the maximum likelihood training
code for CRFs with exponential potentials.

References

Herbrich, R., Graepel, T., & Campbell, C. (1999). Bayes point
machine: Estimating the Bayes point in kernel space. IJCAI
Workshop SVMs (pp. 23–27).

Kumar, S., & Hebert, M. (2004). Discriminative ﬁelds for

modeling spatial dependencies in natural images. Advances in
Neural Information Processing Systems 16.

Lafferty, J., McCallum, A., & Pereira, F. (2001). Conditional

random ﬁelds: Probabilistic models for segmenting and
labeling sequence data. Proc. 18th International Conf. on
Machine Learning (pp. 282–289). Morgan Kaufmann, San
Francisco, CA.

Lafferty, J., Zhu, X., & Liu, Y. (2004). Kernel conditional

random ﬁelds: Representation and clique selection. Proc.
International Conf. on Machine Learning.

McCallum, A. (2003). Efﬁciently inducing features of
conditional random ﬁelds. Proceedings of the 16th
Conference in Uncertainty in Artiﬁcial Intelligence.

McCallum, A., Freitag, D., & Pereira, F. (2000). Maximum

entropy Markov models for information extraction and
segmentation. Proc. 17th International Conf. on Machine
Learning (pp. 591–598). Morgan Kaufmann, San Francisco,
CA.

Minka, T. P. (2001). Expectation propagation for approximate

Bayesian inference. Uncertainty in AI’01.
http://www.stat.cmu.edu/˜minka/papers/ep/.

Minka, T. P. (2004). Power EP.

http://www.stat.cmu.edu/˜minka/.

Minka, T. P., & Lafferty, J. (2002). Expectation propagation for

the generative aspect model. Proc UAI.

Murray, I., & Ghahramani, Z. (2004). Bayesian learning in

undirected graphical models: Approximate MCMC
algorithms. UAI.

Qi, Y. (2004). Extending expectation propagation for graphical

models. Doctoral dissertation, MIT.

Qi, Y., Minka, T. P., Picard, R. W., & Ghahramani, Z. (2004).

Predictive automatic relevance determination by expectation
propagation. Proceedings of Twenty-ﬁrst International
Conference on Machine Learning.

Sha, F., & Pereira, F. (2003). Parsing with conditional random

ﬁelds (Technical Report MS-CIS-02-35). University of
Pennsylvania.

Taskar, B., Guestrin, C., & Koller, D. (2004). Max-margin

Markov networks. In S. Thrun, L. Saul and B. Sch¨olkopf
(Eds.), Advances in neural information processing systems 16.

Wiegerinck, W., & Heskes, T. (2002). Fractional belief

propagation. NIPS 15.

276Poisson-Networks: A Model for Structured Point Processes

Shyamsundar Rajaram

ECE Department
University of Illinois

Urbana, USA

Thore Graepel

MLP Group

Microsoft Research

Cambridge, UK

Ralf Herbrich

MLP Group

Microsoft Research

Cambridge, UK

Abstract

Modelling structured multivariate point pro-
cess data has wide ranging applications like
understanding neural activity, developing
faster ﬁle access systems and learning depen-
dencies among servers in large networks. In
this paper, we develop the Poisson network
model
for representing multivariate struc-
tured Poisson processes. In our model each
node of the network represents a Poisson pro-
cess. The novelty of our work is that wait-
ing times of a process are modelled by an ex-
ponential distribution with a piecewise con-
stant rate function that depends on the event
counts of its parents in the network in a gen-
eralised linear way. Our choice of model al-
lows to perform exact sampling from arbi-
trary structures. We adopt a Bayesian ap-
proach for learning the network structure.
Further, we discuss ﬁxed point and sampling
based approximations for performing infer-
ence of rate functions in Poisson networks.

1 Introduction

Structured multivariate point processes appear in
many diﬀerent settings ranging from multiple spike
train recordings, ﬁle access patterns and failure events
in server farms to queuing networks. Inference of the
structure underlying such multivariate point processes
and answering queries based on the learned structure
is an important problem. For example, learning the
structure of cooperative activity between multiple neu-
rons is an important task in identifying patterns of
information transmission and storage in cortical cir-
cuits [Brillinger and Villa, 1994, Aertsen et al., 1989,
Oram et al., 1999, Harris et al., 2003, Barbieri et al.,
2001, Brown et al., 2004]. Similarly, learning the access
patterns of ﬁles can be exploited for building faster ﬁle

access systems.
Consider V time series of events ti. We would like to
ﬁnd a compact representation of the joint probability
distribution of the V time series. Assuming each time
series is modelled by an inhomogeneous Poisson pro-
cess, a unique representation is obtained in terms of
V rate functions λi(t) each of which depends on all
events of the V times series up to time t. Clearly, we
need further assumption on the rate functions to infer
the rate functions from a ﬁnite amount of data. The
proposed approach makes four crucial assumptions:

1. The rate function of each process depends only on
the history in a short time window into the past.

2. The rate function of each process depends only
on a small number of other processes. Adopting
a directed graph notation, these are also referred
to as parent nodes.

3. The rate function of each process depends only on

the empirical rates of its parents.

4. The rate function of each process is parameterised

by a generalised linear model.

The standard approach adopted in modelling such
time series is by discretising the time axis into in-
tervals of ﬁxed length δ and transforming the time
series into a sequence of counts per interval. The de-
pendency structure between nodes of such a network,
which is also known as a dynamic Bayesian network
(DBN) [Dean and Kanazawa, 1989, Murphy, 2001],
can be modelled using transition probabilities between
states at time t and t + δ given the states of all the
parents of each node at time t. This approach suﬀers
from the problem that the discretisation is somewhat
arbitrary: A small value of δ will result in a redundant
representation and a huge computational overhead but
a large value of δ may smooth away important details
in the data.

277We overcome the issues of discretisation by consider-
ing the limit δ → 0 and thus modelling the waiting
time in each time series directly. Nodelman et al.
[2002] and Nodelman et al. [2003] use a similar continu-
ous time approach for modelling homogeneous Markov
processes with a ﬁnite number of states.
In their
work the rate functions depend on the current state of
the parents only which leads to an eﬃcient and exact
learning algorithm. In our setup, we model the wait-
ing times as an exponential distribution with piecewise
constant rates that depend on the count history of par-
ent nodes.
The paper is structured as follows: In Sec. 2 we in-
troduce our Poisson network model.
In Sec. 3 we
describe an eﬃcient technique for performing exact
sampling from a Poisson network. We describe pa-
rameter estimation and structure learning using ap-
proximate Bayesian inference techniques in Sec. 4. In
Sec. 5 we discuss approximate marginalisation and in-
ference based on sampling and ﬁxed point methods.
Finally, we describe experiments on data generated
by our sampling technique for performing parameter
learning, structure estimation and inference in Sec. 6.

2 The Poisson Network Model
Consider time series data ti ∈ (R+)Ni from V point
processes. Each element of ti = [ti,1, . . . , ti,Ni] corre-
sponds to series of times ti,j at which a particular event
occurred. We model each time series as an inhomoge-
neous Poisson process and the modelling problem is to
capture the dependency between diﬀerent processes,
both qualitatively (structure) and quantitatively (pa-
rameters).
A Poisson process is an instance of a counting process
which is characterised by a rate function λ(t). If the
rate function is constant over time, the Poisson process
is called homogeneous, otherwise it is called inhomo-
geneous [Papoulis, 1991]. A very useful property of a
homogeneous Poisson process is that the waiting time
between two consecutive events is exponentially dis-
tributed with rate λ, that is,

∀t ∈ R+ : p(t|λ) := λ exp(−λt) .

Note that the mean of the waiting time distribution is
given by λ−1.
The waiting time distribution for a non-homogeneous
process is a generalized exponential distribution.
In
the special case of a piecewise constant rate function
λ(t), the waiting time has a piecewise exponential dis-
tribution.
Proposition 1 (Piecewise Exponential Distribu-
tion). Suppose we are given l rates λ ∈ (R+)l and l

Figure 1:
Illustration of a Poisson network with a cy-
cle unwrapped in time. Note that we use dashed lines to
indicate parent relationships in Poisson networks. These
arrows should always be interpreted as pointing forward in
time.

sets Tk of non-overlapping intervals where the aver-
age waiting time in each of the intervals T in Tk is
governed by λk. The waiting time of the piecewise ex-
ponential distribution has the following density:

l(cid:89)
(cid:88)
(cid:88)

k=1

[t0,t1)∈Tk

p(t|λ,T )

ak(t,Tk)

bk(t,Tk)

:=

:=

:=

ak(t,Tk) exp(−λkbk(t,Tk)),

λk

It∈[t0,t1),

(t1 − t0)It>t1 + (d − t0)It∈[t0,t1).

[t0,t1)∈Tk

In the Poisson network model we aim at modelling
the independence relations between the V processes.
Similarly to Bayesian networks, the independence re-
lations are implicitly represented by the connectivity
of a directed graph. Hence, the network structure
can be fully represented by all parent relationships,
M := {π(i) ⊆ {1, . . . , V }}. Interestingly, the seman-
tics of a parent relationship is slightly diﬀerent from
Bayesian networks: Since the rate function of each
node only depends on the past history of its parents,
cycles w.r.t. the parent set M are permissible (see Fig-
ure 1).
We model the dependency of a node i on its par-
ents π(i) = {p1, . . . , pmi} by constraining the rate
function λi(t) to be a function of the event counts
of all parents in time windows of length φ, ni(t) :=
[ni,p1(t), . . . , ni,pmi
(t)] where ni,pj represents the num-
ber of events of node pj in the time window [t− φ, t).1
We consider a generalized linear model for the rate
function λ(t) in terms of the counts ni(t). Possible link
functions include the probit or sigmoid function which
exhibit a natural saturation characteristic. However,
in the following we will consider the canonical link

1Note that we will treat φ as a ﬁxed quantity throughout

the paper.

t−1BAABtAtBt+1t+1ABt−1278function for the Poisson model resulting in:

λi(t; wi, xi) = exp

wi,jxi,j(t)

 ,

(1)

(cid:88)

j∈π(i)

wi,0 +
(cid:179)
:= ln
:= ni,j(t)

φ

.

(cid:180)

1 + ˆλi,j(t)

,

xi,j(t)

ˆλi,j(t)

where wi,0 represents a bias term and translates into
a multiplicative base rate exp(wi,0). We deﬁne

Note that ˆλi,j(t) is the empirical rate of node j w.r.t.
node i. Alternatively, the rate function can be writ-
ten in a way that is more amenable for inference (see
Sec. 5):

λi(t) = exp(wi,0)

1 + ˆλi,j(t)

.

(cid:89)

(cid:179)

j∈π(i)

(cid:180)wi,j

Figure 2: Poisson networks for illustrating sampling.

durations τl,j are deﬁned by
:= ˘tl,1 − tl−1 ,
:= ˘tl,j − ˘tl,j−1 ,
:= tl − ˘tl,kl .

τl,1
τl,j
τl,kl+1

j ∈ {2, . . . , kl}

A positive value for wi,j indicates an excitatory eﬀect
and a negative value corresponds to an inhibitory ef-
fect on the rate. The rate of each node at any given
time instant is a function of the empirical rate of its
parents resulting in an inhomogeneous process. Note
that in practice there are only ﬁnitely many diﬀerent
count vectors due to the ﬁnite length time windows.
The piecewise constant characteristic of the rate func-
tion and the absence of cycles in the Poisson network
enables us to do exact sampling (see Sec. 3).
Let us derive the probability distribution of the time
series corresponding at given nodes. Consider the
l − 1th and lth events occurring at times tl−1 and tl in a
given node and the instants at which the count vector
changes in this interval be represented as ˘tl,1, . . . , ˘tl,kl.2
The probability density of an event at time tl given
the previous event happened at tl−1 is denoted by
p(tl|tl−1, w, M). This density is a product of probabili-
ties of non-occurrence of an event in each of the disjoint
subintervals, i.e. (tl−1, ˘tl,1], (˘tl,1, ˘tl,2], . . . , (˘tl,kl−1, ˘tl,kl]
and the probability density of occurrence of an event
at tl in the subinterval (˘tl,kl , tl]:

p(tl|tl−1, w, M) = λl,kl+1

exp (−λl,jτl,j)

j=1

where λl,j is the rate as in (1) for a node which is
a function of the event counts of its parents in the
jth subinterval corresponding to the lth event and the

2We drop the node subscript and suppress the depen-
dence on the time series of all parent nodes for better
readability.

kl+1(cid:89)

 ,

N(cid:89)

The probability density for the time series t =
[t1, . . . , tN ] of a given node is obtained as the product
of the probability densities for each of the mutually
exclusive subintervals (t0, t1], . . . , (tN−1, tN ],

p(t|w, M) =

p(tl|tl−1, w, M) ,

(2)

l=1

where the initial time t0 is assumed to be 0.

3 Sampling from a Poisson Network

The piecewise constant behavior of the rate function
λ(t) and the absence of cycles in the network allows
us to perform exact sampling from a Poisson Network.
Let us consider the simple case of sampling from a sin-
gle node network as shown in Fig. 2 (a). Sampling is
straightforward in this case, because the node repre-
sents a homogeneous Poisson process. The standard
way to sample from a homogeneous Poisson process is
to make use of the property that the waiting times be-
tween two adjacent events are iid and are distributed
exponentially with rate parameter λ.
Let us consider a two node network shown in Fig. 2
(b). Sampling for node A can be done in a straight-
forward way as explained above because at any time t,
At is independent of Bt. The rate function for node B
can be calculated using (1) once the whole time series
for node A is known. The rate function for B is piece-
wise constant because of the ﬁnite number of events
for node A in the time window [t − φ, t] for varying
t. Sampling from a waiting time distribution with a

(a)AAABB(b)(c)279Figure 3: (a) An arbitrary Poisson network. (b) SCC’s indicated by ellipses. (c) Directed acyclic graph C(cid:48) represents
the SCC formed by nodes C and D. (d) Topological ordering where the number (1(cid:48) and 1 can be sampled independently
of each other in parallel) written adjacent to the node indicates the order.

piecewise constant rate function is done by rejection
sampling. Denote the current value of the rate func-
tion by λ(t) and assume the rate remains unchanged
until time ˆt. Sample τ from the waiting time distri-
bution with parameter λ(t). Accept τ if t + τ ≤ ˆt
and reject τ otherwise. The sampling time is now up-
dated to ˆt or t + τ depending on whether the sample
is rejected or accepted, respectively.
Now, let us consider a two node network as shown in
Fig. 2 (c) where there exists a cyclic relationship be-
tween nodes A and B. It is worth mentioning again
that node B depends on the event counts of node A
in the past only and vice versa. Sampling from the
nodes cannot be done in an independent way because
of the cyclic relationship. Let the values λA(t) and
λB(t) of the rate functions for nodes A and B, respec-
tively, be calculated by (1) and assume that the rates
remain constant until ˆtA, ˆtB (excluding the mutual in-
teraction in the future). Sample waiting times τA and
τB for both nodes using the rates λA(t) and λB(t), re-
spectively. The sample corresponding to max(τA, τB)
is rejected because an earlier event at the other node
might have changed the value of the rate function; the
other sample is accepted if it is within the constant
time interval of the ﬁring rate. The sampling time is
updated to min(ˆtA, ˆtB) or t + min(τA, τB) depending
on whether the other sample was rejected or accepted,
respectively.
This sampling technique can be generalised to an ar-
bitrary number of nodes. We note that the structure
of the network can be made use of in order to per-
form sampling in a very eﬃcient way. The two key
observations are that,

1. Certain groups of nodes have to sampled from in
a synchronized, dependent way because of mutual
dependence of nodes in the group.

2. Sampling has to be done in a certain order.

The ﬁrst observation is illustrated in Fig. 3 (b) and
such groups of nodes are known as strongly connected
components (SCC) in graph theory [Cormen et al.,
2001]. A strongly connected component is a directed
subgraph with the property that for all ordered pairs
of vertices (u, v), there exists a path from u to v. A
variant of depth ﬁrst search can be used to ﬁnd all the
SCCs of a graph. A directed acyclic graph graph is
obtained by replacing each SCC by a single node as
shown in Fig. 3 (c). Now we observe that the nodes
of the directed acyclic graph can be sampled from in
such a way that, when sampling a given node, its par-
ents have been sampled before (see Fig. 3 (d)). Topo-
logical sorting is a method to compute such an order
eﬃciently (see Cormen et al. [2001]).

4 Parameter Estimation and

Structure Learning

Given time series data T := [t1, . . . , tV ] we are inter-
ested in ﬁnding the most plausible structure M∗ and
parameter estimates for w in the linear model of the
rate functions (see (1)). We take a Bayesian approach
to the problem of parameter estimation which, at the
same time, provides a score over structure M by the
marginalised likelihood. We choose a Gaussian prior
distribution over the weights

V(cid:89)

p(W|M) =

N (wi; 0, σ2I) .

i=1

Using Bayes rule, we obtain the posterior
p(W|T, M) = p(T|W, M)p(W|M)

p(T|M)

.

(d)ABECDABECDABEC’ABEC’21’31(a)(b)(c)280The structure learning problem can be written as,

4.2 Variational Approach

M∗

:= argmax

= argmax

p(M|T)
p(T|M)p(M)

p(T|M) =

p(M)

:=

p(ti|{tj|j ∈ π(i)})

p(π(i)) ,

M

M

V(cid:89)
V(cid:89)

i=1

i=1

where we make use of a structural prior p(M) that
factors over the parents of the V nodes. Note that
p(ti|{tj|j ∈ π(i)}) corresponds to (2) marginalised
over w. In contrast to structure learning in Bayesian
networks which requires optimisation over the set of
directed acyclic graphs, no such constraints are im-
posed in Poisson network or continuous time Bayesian
networks [Nodelman et al., 2003]. Hence, the struc-
ture learning problem can be solved by ﬁnding the
most likely parents of each node independently.
In
theory the exact structure can be learned without re-
gard to the number of parents. However, in practice
the running time of the learning procedure is a func-
tion of the number of parents of a node and hence while
learning structures we ﬁx the maximum number of par-
ents. Now we present two approximate Bayesian infer-
ence techniques for parameter estimation and struc-
ture learning.

4.1 Laplace Approximation

In the Laplace approximation [Kass and Raftery,
1995], the posterior is approximated by a multivari-
ate Gaussian density,

p(wi|T, M) ≈ N (wi; wMAP, Σ) ,
where wMAP is the mode of the posterior,
p(T, wi|M) ,

wMAP := argmax

wi

and the covariance matrix Σ is given by

Σ :=

ln(p(T, wi|M))|w=wMAP

The marginalised likelihood can be obtained by,
p(T|M) =

p(T, wi|M) dwi

(cid:162)−1

.

wi

(cid:161)−∇∇T
(cid:90)
(cid:90) (cid:112)
(cid:112)

≈

=

(2π)mi|Σ| .

The variational approach to solving problem of param-
eter estimation and structure learning is to introduce
a family of probability distribution qθ(wi) parame-
terised over θ which gives rise to a lower bound on
the marginalised likelihood3:

(cid:191)

(cid:181)

(cid:182)(cid:192)

ln (p(T|M)) ≥ LM (θ) ,
p(wi|M)
qθ(wi)

,

qθ

ln

LM (θ) :=

+(cid:104)ln (p(T|wi, M))(cid:105)qθ
which follows from an application of Jensen’s inequal-
ity to the concave logarithm function [Jordan et al.,
1999]. This lower bound on the log-marginal probabil-
ity is a function of the parameters θ of the distribution
q. This bound is tight if we choose qθ(wi) to be the
true posterior p(wi|T, M). We also observe that the
lower bound is the sum of two terms which correspond
to the negative of the Kullback-Leibler divergence be-
tween the prior term and the distribution qθ(wi) and
the second term is the log-likelihood of the data aver-
aged over qθ(wi).
The idea of the variational approximation Bayesian
algorithm is to maximize the lower bound LM with
respect to the parameters of the q distribution. The
structure learning problem can be posed as maximiza-
tion of the lower bound LM (θ) which can be written
as,

(cid:183)

(cid:184)

M∗ := argmax

M

max

θ

LM (θ)

.

Similar to the Laplace approximation, we choose
qθ(wi) to be a multivariate Gaussian N (wi; µ, Σ). For
a given network structure M, we can use conjugate
gradients to ﬁnd the maximum of LM (µ, Σ). Note
that the gradients are given by

∇µ(LM (µ, Σ)) = −µ +

xi,ki . . .

N(cid:88)
(cid:195)

i=1

ki(cid:88)

j=1

ki(cid:88)

− N(cid:88)
− N(cid:88)

i=1

i=1

j=1

τi,jxi,j exp

i,jΣxi,j + 2µT xi,j
xT

∇Σ(LM (µ, Σ)) = − 1

2σ2 I +

2

(Σ)−T . . .

1
2

(cid:195)

1
2 τi,jxi,jxT

i,j exp

i,jΣxi,j + 2µT xi,j
xT

2

(cid:33)

,

(cid:33)

.

(2π)mi|Σ|N (wi; wMAP, Σ) dwi

5 Inference in a Poisson network

The mode wMAP is found by the conjugate gradients
algorithm using the gradient of ln(p(T, wi|M)) w.r.t.
w (see also (2)).

Once the network structure and parameters are
learned, several queries regarding the distribution rep-
resented by the network can be answered. A common
3We use the shorthand notation (cid:104)f (·)(cid:105)q to denote an

expectation of f w.r.t. the distribution q.

281inference problem that is encountered in a Bayesian
network is one where data is available for some nodes
(denoted by MD), there are a few query nodes (de-
noted by MQ) whose behavior has to be estimated
from the data and the remaining nodes are hidden
nodes (denoted by MH for which no data is available.
We pose an analogous problem for Poisson networks.
The rate of any arbitrary node can be computed if the
time series data for all its parents are known for the pe-
riod of interest. However, certain conﬁgurations of the
problem involving hidden nodes are not easy to solve
because of the problem of entanglement as mentioned
in Nodelman et al. [2002]. The standard procedure
in a Bayesian network is to marginalise over all the
hidden nodes and obtain an estimation for the query
nodes using the data in observed nodes. Marginalis-
ing over a hidden node amounts to integrating over
all possible time series for a particular node which,
in general, is impossible. Hence, approximations are
necessary.

5.1 Inference by Sampling

A straightforward way to solve the inference problem is
to perform marignalisation of the hidden nodes by us-
ing a few instantiations of them which can be obtained
by sampling from the network. The samples can then
be used to obtain averaged rate estimates at each of
the query nodes. The sampling procedure is the same
as our procedure in Sec. 3 with a minor modiﬁcation
that the sampling is to be performed conditioned on
the data that has been observed in the data nodes
MD. We observe that if the data for a node i is com-
pletely known, then the parent nodes of i do not have
any inﬂuence on i in the subsequent sampling process.
Hence, we can safely remove all the parental relation-
ships for all the fully observed nodes and obtain a new
network M(cid:48) = M − {i → j, i ∈ MD, j ∈ π(i)}. Sam-
pling is done from the new network M(cid:48) for all the
unobserved nodes and then average ﬁring rates can be
obtained for all the query nodes.

5.2 Estimation of Steady State Rate

An alternative way to solve the inference problem is to
approximate the empirical rate ˆλ with a steady state
rate. According to our model, the rate of a node can
be written as,

wi,0 +

V(cid:88)

(cid:179)

j=1

(cid:179)

λi(t) = exp

wi,j ln

1 + ˆλi,j(t)

(cid:180)(cid:180) . (3)

Figure 4: The random Poisson network graph that gen-
erated the samples in Fig. 5. Red arrow indicates an in-
hibitory inﬂuence and the blue arrow indicates an excita-
tory inﬂuence.

whole time series is observed. Hence, we approximate
the empirical rate by the true rate,

(cid:90) t

t−φ

V(cid:88)

ˆλi,j(t) = ni,j(t)

φ

≈ 1
φ

λj(˜t)d˜t ≈ λj(t) ,

where we assume that the length of time window, φ,
is very small. Substituting back in (3) we obtain

ln(λi(t)) ≈ wi,0 +

wi,j ln (1 + λj(t)) .

(4)

j=1

We make the assumption that the rate is constant in
the time interval [t−φ, t] and hence the Poisson process
of each of the parents j, j ∈ {1, . . . , V } is assumed
to be a homogeneous Poisson process with rate λj(t).
Now, (4) can be constructed for all nodes that are
not observed and the set of equations have the form
λ(t) = F (λ(t)), F : RV → RV , whose solution are
the ﬁxed points of the system. We perform ﬁxed point
iterations starting from randomly initialized values for
λi(t), i ∈ {1 . . . V }.
In experiments we observe that
at convergence, the estimated rate corresponds to the
mean rate in the time interval [t− φ, t] calculated from
actual data.

6 Experimental Results

In this section, we test the presented methods on data
sampled using the algorithms from Sec. 3. We show
experiments of approximate inference of rate using a
sampling based approximation and a ﬁxed point ap-
proximation.

We notice that this is (1) if we consider wi,j = 0 for
all the pairs of nodes which are not dependent. The
empirical rate ˆλi,j(t) cannot be obtained unless the

Sampling Firstly, we generate a random graph (see
Fig. 4) with V nodes. As mentioned before, because of
computational issues we ﬁx the maximum number of

21543282Figure 5: Samples generated from a random network with
V = 5 and maximum number of parents is 2

parents πmax for every node. Now, our eﬃcient sam-
pling technique given in Sec. 3 is used to generate sam-
ples from the network. Samples generated from a ran-
domly generated network with V = 5 and πmax = 2 is
as shown in Fig. 5. The time window duration φ was
ﬁxed to 1 second.

Parameter estimation and structure learning
The Laplace and variational approximation developed
in Sec. 4.1 and Sec. 4.2 are tested using samples gen-
erated from random graph structures. We observed
that the posterior distribution p(wi|T, M) can be
approximated very well by a multivariate Gaussian.
Thus, both approximations methods perform very ac-
curately. Fig. 6 shows the parameter estimation and
structure learning results obtained using variational
approximations for a 15 node network with maximum
number of parents restricted to 2. The results indicate
that the few edges that were missed by the structure
learning algorithm (circles) correspond to weak depen-
dencies i.e., edges with weights close to zero. The re-
sults of the Laplace approximation is similar to the
variational approximation except that the variational
approximation had higher conﬁdence in its estimate.

Approximate Inference of rates The approxi-
mate inference techniques developed in Sec. 5 was
tested on a random graph having 10 nodes. Samples
were generated from the network using our sampling
technique. Nodes were chosen at random and marked
as observed, hidden and as query nodes. The inference
task was to estimate rates for all the nodes marked
as query nodes. The samples generated for the ob-
served nodes were made use of to perform inference

Figure 6: Results for parameter estimation and structure
learning using the variational approximation for a network
with 15 nodes in which maximum number of parents is 2.
Each node i with a parent j has a true expected weight
wi,j (x-axis) and a posterior estimate (y-axis) shown as a
5%-95% posterior quantile interval with a mark indicating
the mean. The empty circles indicate the edges that were
not identiﬁed by the structure learning algorithm.

of rates using the sampling based approximation and
the ﬁxed point approximation. The results shown in
Fig. 7 shows that the ﬁxed point approximation tech-
nique (which is signiﬁcantly faster than the sampling
based approximation) closely tracks the true rate.

7 Conclusions and Discussion

Poisson networks are models of structured multivariate
point processes and have the potential to be applied
in many ﬁelds. They are designed such that sampling
and approximate learning and inference are tractable
using the approaches described above. In particular,
structure learning is carried out in a principled yet
eﬃcient Bayesian framework.
Future applications of the Poisson network model in-
clude biological problems such as analysing multiple
neural spike train data Brown et al. [2004] as well as
application in computer science such as prediction of
ﬁle access patterns, network failure analysis and queu-
ing networks.
A promising direction for future research is to combine
Poisson networks with continuous time Bayesian net-
works in order to be able to model both event counts
and state (transitions). For example, consider ﬁle ac-
cess events and the running states of CPU processes.
Clearly, they exhibit an interesting relationship the
discovery of which would it possible to predict and

010203040506070809010000.51node 1010203040506070809010000.51node 2010203040506070809010000.51node 3010203040506070809010000.51node 4010203040506070809010000.51time(s)node 5−2−1.5−1−0.500.511.522.5−2−1.5−1−0.500.511.522.5True weightsEstimated weightsParameter Estimation results using variational approximation283point process analysis. Advanced Methods of Physi-
ological System Modelling, 3:111–127, 1994.

E. N. Brown, R. E. Kass, and P. P. Mitra. Multiple
neural spike train data analysis: state-of-the-art and
future challenges. Nature Neuroscience, 7:456–461,
April 2004.

T. Cormen, C. Leiserson, R. Rivest, and C. Stein.
Introduction to Algorithms, Second Edition. MIT
Press, 2001.

T. Dean and K. Kanazawa. A model for reasoning
about persistence and causation. Computational In-
telligence, 5:142–150, 1989.

K. D. Harris, J. Csicsvari, H. Hirase, G. Dragoi, and
G. Buzsaki. Organization of cell assemblies in the
hippocampus. Nature, 424:552–556, July 2003.

M. I. Jordan, Z. Ghahramani, T. Jaakkola, and L. K.
Saul. An introduction to variational methods for
graphical models. Machine Learning, 37(2):183–233,
1999.

R. E. Kass and A. E. Raftery. Bayes factors. Journal
of the American Statistical Association, 90:773–795,
1995.

K. P. Murphy. Dynamic Bayesian Networks: Repre-
sentation, Inference and Learning. PhD thesis, UC
Berkeley, Computer Science Division, 2001.

U. Nodelman, C. Shelton, and D. Koller. Continuous
time Bayesian networks. In Proceedings of the 18th
Annual Conference on Uncertainty in Artiﬁcial In-
telligence (UAI-02), pages 378–387, San Francisco,
CA, 2002. Morgan Kaufmann Publishers.

U. Nodelman, C. Shelton, and D. Koller. Learning
continuous time Bayesian networks. In Proceedings
of the 19th Annual Conference on Uncertainty in
Artiﬁcial Intelligence (UAI-03), pages 451–458, San
Francisco, CA, 2003. Morgan Kaufmann Publishers.
M. W. Oram, M. C. Wiener, R. Lestienne, and B. J.
Richmond.
Stochastic nature of precisely timed
spike patterns in visual system neuronal responses.
Journal of Neurophysiology, 81(6):3021–3033, 1999.
A. Papoulis. Probability, Random Variables, and
Stochastic Processes. Mcgraw-Hill, New York, 3 edi-
tion, 1991.

Figure 7: Inference of rate functions

hence optimise process-ﬁle interactions. Similarly, in
biological application external stimuli can be modelled
as states inﬂuencing physiological events such as neu-
ral spike activity.
Finally, it would be of great interest to study the infor-
mation processing potential of Poisson networks in the
sense of artiﬁcial neural networks (see Barber [2002]).

Acknowledgments Shyamsundar would like to
thank Microsoft Research for providing funding for
this project during an internship in Cambridge and
Thoams Huang for generous support. We are very in-
debted to Ken Harris for interesting discussions about
biological applications of Poisson networks, and we
would like to thank Tom Minka for interesting dis-
cussions about approximate inference.

References

A. M. Aertsen, G. L. Gerstein, M. K. Habib, and
G. Palm. Dynamics of neuronal ﬁring correlation:
modulation of ”eﬀective connectivity”. Journal of
Neurophysiology, 61(5):900–917, 1989.

D. Barber. Learning in spiking neural assemblies.
In Advances in Neural Information Processing Sys-
tems, pages 165–172, 2002.

R. Barbieri, M. C. Quirk, L. M. Frankb, M. A. Wil-
son, and E. N. Browna. Construction and analysis
of non-poisson stimulus-response models of neural
spiking activity. Journal of Neuroscience Methods,
105(1):25–37, 2001.

D. R. Brillinger and A. E. P. Villa. Examples of
the investigation of neural information processing by

0501001502002503003504004505000.30.320.340.360.380.40.42timeRatefixed−point approxActual firing rateSampling approximation284Deformable Spectrograms

Manuel Reyes-Gomez

LabROSA

Department of Electrical Engineering

Columbia University

Nebojsa Jojic

Microsoft Research
One Microsoft Way

Redmond,WA.

Daniel P.W. Ellis

LabROSA

Department of Electrical Engineering

Columbia University

mjr59@ee.columbia.edu

jojic@microsoft.com

dpwe@ee.columbia.edu

Abstract

Speech and other natural sounds show high
temporal correlation and smooth spectral evolu-
tion punctuated by a few, irregular and abrupt
changes.
In a conventional Hidden Markov
Model (HMM), such structure is represented
weakly and indirectly through transitions be-
tween explicit states representing ‘steps’ along
such smooth changes.
It would be more efﬁ-
cient and informative to model successive spec-
tra as transformations of their immediate prede-
cessors, and we present a model which focuses
on local deformations of adjacent bins in a time-
frequency surface to explain an observed sound,
using explicit representation only for those bins
that cannot be predicted from their context. We
further decompose the log-spectrum into two ad-
ditive layers, which are able to separately explain
and model the evolution of the harmonic exci-
tation, and formant ﬁltering of speech and sim-
ilar sounds. Smooth deformations are modeled
with hidden transformation variables in both lay-
ers, using Markov Random ﬁelds (MRFs) with
overlapping subwindows as observations; infer-
ence is efﬁciently performed via loopy belief
propagation. The model can ﬁll-in deleted time-
frequency cells without any signal model, and an
entire signal can be compactly represented with
a few speciﬁc states along with the deformation
maps for both layers. We discuss several possible
applications for this new model, including source
separation.

1 Introduction

Hidden Markov Models (HMMs) work best when only a
limited set of distinct states need to be modeled, as in the
case of speech recognition where the models need only be
able to discriminate between phone classes. When HMMs

are used with the express purpose of accurately modeling
the full detail of a rich signal such as speech, they require a
large number of states. In [1](Roweis 2000), HMMs with
8,000 states were required to accurately represent one per-
son’s speech for a source separation task. The large state
space is required because it attempts to capture every pos-
sible instance of the signal. If the state space is not large
enough, the HMM will not be a good generative model
since it will end up with a “blurry” set of states which repre-
sent an average of the features of different segments of the
signal, and cannot be used in turn to “generate” the signal.

In many audio signals including speech and musical instru-
ments, there is a high correlation between adjacent frames
of their spectral representation. Our approach consists
of exploiting this correlation so that explicit models are
required only for those frames that cannot be accurately
predicted from their context.
In [2](Bilmes 1998), con-
text is used to increase the modelling power of HMMs,
while keeping a reasonable size parameters space, how-
ever the correlation between adjacent frames is not explic-
ity modeled. Our model captures the general properties of
such audio sources by modeling the evolution of their har-
monic components. Using the common source-ﬁlter model
for such signals, we devise a layered generative graphi-
cal model that describes these two components in separate
layers: one for the excitation harmonics, and another for
resonances such as vocal tract formants. This layered ap-
proach draws on successful applications in computer vision
that use layers to account for different sources of variability
[3, 4, 5](Jojic 2001,Levin 2002,Jojic 2003). Our approach
explicitly models the self-similarity and dynamics of each
layer by ﬁtting the log-spectral representation of the signal
in frame t with a set of transformations of the log-spectra
in frame t−1. As a result, we do not require separate states
for every possible spectral conﬁguration, but only a limited
set of “sharp” states that can still cover the full spectral va-
riety of a source via such transformations. This approach is
thus suitable for any time series data with high correlation
between adjacent observations.

We will ﬁrst introduce a model that captures the spectral de-

285where t is the time-frame index, k indexes the frequency
bands, NF is the size of the discrete Fourier transform,
H is the hop between successive time-frames, w[τ] is the
NF -point short-time window, and x[τ] is the original time-
domain signal. We use 32 ms windows with 16 ms hops.
Using the subscript C to designate current and P to in-
dicate previous, the model predicts a patch of NC time-
frequency bins centered at the kth frequency bin of frame t
as a “transformation” of a patch of NP bins around the kth
bin of frame t − 1, i.e.

~X [k−nC ,k+nC ]

t

≈ ~T k

t · ~X [k−nP ,k+nP ]

t−1

(1)

t

where nC = (NC − 1)/2, nP = (NP − 1)/2, and T k
is
the particular NC × NP transformation matrix employed at
that point on the time-frequency plane. We use overlapping
patches to enforce transformation consistency,
[5](Jojic
2003).
Figure 1 shows an example with NC = 3 and NP = 5 to
illustrate the intuition behind this approach. The selected
patch in frame t can be seen as a close replica of an up-
ward shift of part of the patch highlighted in frame t − 1.
This “upward” relationship can be captured by a transfor-
mation matrix such as the one shown in the ﬁgure. The
patch in frame t − 1 is larger than the patch in frame t
to permit both upward and downward motions. The gen-
erative graphical model for a single layer is depicted in
T } repre-
ﬁgure 2. Nodes X = {X 1
sent all the time-frequency bins in the spectrogram. For
now, we consider the continuous nodes X as observed, al-
though below we will allow some of them to be hidden
when analyzing the missing data scenario. Discrete nodes
T } index the set of transfor-
T = {T 1
mation matrices used to model the dynamics of the signal.
Each NC × NP transformation matrix ~T is of the form:

t , ..., X K

t , ..., T K

1 , ..., X k

1 , X 2

1 , T 2

1 , ..., T k

 ~w 0 0


0 ~w 0
0 0 ~w

(2)

Figure 1: The NC = 3 patch of time-frequency bins out-
lined in the spectrogram can be seen as an “upward” ver-
sion of the marked NP = 5 patch in the previous frame.
This relationship can be described using the matrix shown.

Figure 2: a) Graphical model b) Graphical simpliﬁcation.

formation ﬁeld of the speech harmonics, and show how this
can be exploited to interpolate missing observations. Then,
we introduce the two-layer model that separately models
the deformation ﬁelds for harmonic and formant resonance
components, and show that such a separation is necessary
to accurately describe speech signals through examples of
the missing data scenario with one and two layers. Then we
will present the complete model including the two defor-
mation ﬁelds and the “sharp” states. This model, with only
a few states and both deformation ﬁelds, can accurately re-
construct the signal. This paper fully describes the oper-
ation and implementation of this complete model, which
was only described as future work in [6](Reyes-Gomez
2004).

Finally, we brieﬂy describe a range of existing applications
including semi-supervised source separation, and discuss
the model’s possible application to unsupervised source
separation.

2 Spectral Deformation Model

Figure 1 shows a narrow band spectrogram representation
of a speech signal, where each column depicts the en-
ergy content across frequency in a short-time window, or
time-frame. The value in each cell is actually the log-
magnitude of the short-time Fourier transform; in decibels,
τ =0 w[τ]x[τ − t · H]e−j2πτ k/NF )),
xk

t = 20log(abs(PNF −1

i.e. each of the NC cells at time t predicted by this matrix
is based on the same transformation of cells from t − 1,
translated to retain the same relative relationship. Here,
NC = 3 and ~w is a row vector with length NW = NP − 2;
using ~w = (0 0 1) yields the transformation matrix shown
in ﬁgure 1. To ensure symmetry along the frequency axis,
we constrain NC, NP and NW to be odd. The complete
set of ~w vectors include upward/downward shifts by whole
bins as well as fractional shifts. An example set, containing

Xt-17Xt-18Xt-19Xt-16Xt-14Xt-15Xt-13Xt-12Xt-11Xt3Xt2Xt1Xt9Xt8Xt7Xt6Xt5Xt40 0 1 0 00 0 0 1 00 0 0 0 1NC=3NP=5Transformationmatrix T=•a)b)X01X02X03X04X05X11X12X13X14X15Ttt-1XTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT14T21T15T12T11T13T23T31T22timefrequency286each ~w vector as a row, is:



0
0
0
0
0
0
0
0
0
0
.
.
.75 .25
0
1

0
1
0
.25 .75
0
.75 .25
0
0
0
1
0
.25 .75
.
.
.
0
0
0
0
0
0



(3)

The length NW of the transformation vectors deﬁnes
the supporting coefﬁcients from the previous frame
~X [k−nW ,k+nW ]
(where nW = (NW − 1)/2) that can “ex-
t−1
plain” X k
t .

Figure 4: Example transformation map showing corre-
sponding points on original signal.

Figure 5: Graphical representation of the two-layer source-
ﬁlter transformation model.

For harmonic signals in particular, we have found that a
model using the above set of ~w vectors with parameters
NW = 5, NP = 9 and NC = 5 (which corresponds to
a model with a transformation space of 13 different matri-
ces T) is very successful at capturing the self-similarity and
dynamics of the harmonic structure.

The transformations set could, of course, be learned, but in
view of the results we have obtained with this predeﬁned
set, we defer the learning of the set to future work. The
results presented in this paper are obtained using the ﬁxed
set of transformations described by matrix 3.

The clique “local-likelihood” potential between the time-
frequency bin X k
t , its relevant neighbors in frame t, its rel-
evant neighbors in frame t− 1, and its transformation node

T k
t has the following form:

(cid:16) ~X [k−nC ,k+nC ]
N(cid:16) ~X [k−nC ,k+nC ]

ψ

t

t

(cid:17)
, Σ[k−nC ,k+nC ](cid:17)

=

, ~X [k−nP ,k+nP ]

, T k
t−1
t
~X [k−nP ,k+nP ]
t−1

; ~T k
t

(4)
The diagonal matrix Σ[k−nC ,k+nC ], which is learned, has
different values for each frequency band to account for
the variability of noise across frequency bands. For the
transformation cliques, the horizontal and vertical transi-
), are
tion potentials ψhor(T k
represented by transition matrices.
For observed nodes X ,
inference consists in ﬁnding
probabilities for each transformation index at each time-
frequency bin. Exact inference is intractable and is ap-
proximated using Loopy Belief Propagation [7, 8] (Yedidia
2001,Weiss 2001) Appendix A gives a quick review of
the loopy belief message passing rules, and Appendix B
presents the speciﬁc update rules for this case.

t−1) and ψver(T k

t , T k−1

t , T k

t

The transformation map, a graphical representation of the
expected transformation node across time-frequency, pro-
vides an appealing description of the harmonics’ dynamics
as can be observed in ﬁgure 4. In these panels, the links
between three speciﬁc time-frequency bins and their corre-
sponding transformations on the map are highlighted. Bin
1 is described by a steep downward transformation, while
bin 3 also has a downward motion but is described by a less
steep transformation, consistent with the dynamics visible
in the spectrogram. Bin 2, on other hand, is described by
a steep upwards transformation. These maps tend to be
robust to noise (see ﬁg 7), making them a valuable repre-
sentation in their own right.

3 Inferring Missing Data

If a certain region of cells in the spectrogram are missing,
like in the case of corrupted data, the corresponding nodes
in the model become hidden. This is illustrated in ﬁgure 3,
where a rectangular region in the center has been removed
and tagged as missing. Inference of the missing values is
performed again using belief propagation, the update equa-
tions are more complex since there is the need to deal with
continuous messages, (Appendix C). The posteriors of the
hidden continuous nodes are represented using Gaussian
distributions, the missing sections on ﬁgure 3 part b), are
ﬁlled in with the means of their inferred posteriors, ﬁgure
3 part c), and d). The transformation node posteriors for
the missing region are also estimated, in the early stages on
the “ﬁll-in” procedure the transformation belief from the
“missing” nodes are set to uniform so that the transforma-
tion posterior is driven only by the reliable observed neigh-
bors, once the missing values have been ﬁlled in with some
data, we enable the messages coming from those nodes.

b) Transformation Mapa) SignalGreen:Identity transformYellow/Orange: Upward motion(darker is steeper)Blue: Downward motion(darker is steeper)123XTFtt-1FTHHtt-1287Figure 3: Missing data interpolation example a) Original, b) Incomplete, c) After 10 iterations, d) After 30.

Figure 6: (a) Spectrogram with deleted (missing) regions. (b) Filling in using a single-layer transformation model. (c)
Results from the two-layer model.

4 Two Layer Source-Filter Transformations

Many sound sources,
including voiced speech, can be
successfully regarded as the convolution of a broad-band
source excitation, such as the pseudo-periodic glottal ﬂow,
and a time-varying resonant ﬁlter, such as the vocal tract,
that ‘colors’ the excitation to produce speech sounds or
other distinctions. When the excitation has a spectrum con-
sisting of well-deﬁned harmonics, the overall spectrum is in
essence the resonant frequency response sampled at the fre-
quencies of the harmonics, since convolution of the source
with the ﬁlter in the time domain corresponds to multiply-
ing their spectra in the Fourier domain, or adding in the log-
spectral domain. Hence, we model the log-spectra X as the
sum of variables F and H, which explicitly model the for-
mants and the harmonics of the speech signal. The source-
ﬁlter transformation model is based on two additive layers
of the deformation model described above, as illustrated in
ﬁgure 5. Variables F and H in the model are hidden, while,
as before, X can be observed or hidden. The symmetry be-
tween the two layers is broken by using different parame-
ters in each, chosen to suit the particular dynamics of each
component. We use transformations with a larger support
in the formant layer (NW = 9) compared to the harmon-
ics layer (NW = 5). Since all harmonics tend to move
in the same direction, we enforce smoother transformation
maps on the harmonics layer by using potential transition
matrices with higher self-loop probabilities. An example
of the transformation map for the formant layer is shown
in ﬁgure 7, which also illustrates how these maps can re-

main relatively invariant to high levels of signal corruption;
belief propagation searches for a consistent dynamic struc-
ture within the signal, and since noise is less likely to have a
well-organized structure, it is properties of the speech com-
ponent that are extracted. Inference in this model is more
complex, but the actual form of the continuous messages
is essentially the same as in the one layer case (Appendix
C), with the addition of the potential function relating the
t and F k
signal X k
t
at each time-frequency bin:

t with its transformation components H k

ψ(X k

t , H k

t , F k

t ) = N (X k

t ; H k

t + F k

t , σk)

(5)

The ﬁrst row of ﬁgure 10 shows the decomposition of a
speech signal into harmonics and formants components,
illustrated as the means of the posteriors of the continu-
ous hidden variables in each layer. The decomposition is
not perfect, since we separate the components in terms of
differences in dynamics; this criteria becomes insufﬁcient
when both layers have similar motion. However, separa-
tion improves modeling precisely when each component
has a different motion, and when the motions coincide, it
is not really important in which layer the source is actu-
ally captured. Figure 6 a) shows the ﬁrst spectrogram from
ﬁgure 10 with deleted regions; notice that the two layers
have distinctly different motions.
In b) the regions have
been ﬁlled via inference in a single-layer model; Notice
that since the formant motion does not follow the harmon-
ics, the formants are not captured in the reconstruction. In
c) the two layers are ﬁrst decomposed and then each layer
is ﬁlled in; the ﬁgure shows the addition of the ﬁlled-in

a)b)c)d)a)Missing Sectionsb) Fill-in; one layerc) Fill-in; two layers288Figure 7: Formant tracking map for clean speech (left panels) and speech in noise (right panels).

Figure 8: Left: Graphic model of the matching-tracking model; Right: Entropy Map and Entropy Edges

version in each layer.

5 Matching-Tracking Model

Prediction of frames from their context is not always possi-
ble such as when there are transitions between silence and
speech or transitions between voiced and unvoiced speech,
so we need a set of states to represent these unpredictable
frames explicitly. We will also need a second “switch” vari-
able that will decide when to “track” (transform) and when
to “match” the observation with a state. The ﬁrst row of
ﬁgure 8 shows a graphical representation of this model. At
each time frame, discrete variables St and Ct are connected
to all frequency bins in that frame. St is a uniformly-
weighted Gaussian Mixture Model containing the means
and the variances of the states to model. Variable Ct takes
two values: When it is equal to 0, the model is in “tracking
mode”; a value of 1 designates “matching mode”. The po-
tentials between observations xk
t , harmonics and formants
hidden nodes hk
t and f kt respectively, and variables St and
Ct is given by:
t , f k
t , f k

(7)
Inference is done again using loopy belief propagation.
Deﬁning φ as a diagonal matrix, the M-Step is given by:

ψ(cid:0)xk
ψ(cid:0)xk

t , σk(cid:1)
(cid:1)

t , hk
t , hk

t ; hk

j , φk
j

(6)

t + f k
t ; µk

t , St, Ct = 0(cid:1) = N(cid:0)xk
t , St = j, Ct = 1(cid:1) = N(cid:0)xk
P
P
t(Q(St = j)Q(Ct = 0)Xt)
P
t(Q(St = j)Q(Ct = 0))
t(Q(Ct = 1)(xk
P
P
t(Q(St = j)Q(Ct = 0)(Xt − µj))2

t − (f k
t(Q(Ct = 1))

t(Q(St = j)Q(Ct = 0))

t + hk

P

t )))2

µj =

σk =

φj =

Q(St) and Q(Ct) are obtained using the belief propagation
rules. Q(Ct = 0) is large if eqn. 6 is larger than eqn. 7. In
early iterations when the means are still quite random, eqn.
6 is quite large, making Q(Ct = 0) large with the result
that the explicit states are never used.

To prevent this we start the model with large variances φ
and σ, which will result in non-zero values for Q(Ct = 1),
and hence the explicit states will be learned.

As we progress, we start to learn the variances by anneal-
ing the thresholds i.e. reducing them at each iteration. We
start with a relatively large number of means, but this be-
comes much smaller once the variances are reduced; the
lower-thresholds then control the number of states used in
the model. The resulting states typically consist of single
frames at discontinuities as intended. Figure 9 a) shows
the frames chosen for a short speech segment, (the spectro-
gram on ﬁgure 3.), the signal can be regenerated from the
model using the states and both estimated motion ﬁelds.
The reconstruction is simply another instance of inferring
missing values, except the motion ﬁelds are not reestimated
since we have the true ones. Figure 9 shows several stages
of the reconstruction.

6 Applications

(8)

We have built an interactive model that implements for-
mant and harmonics tracking, missing data interpolation,
formant/harmonics decomposition, and semi-supervised
source separation of two speakers. Videos illustrating the
use of this demo are available at: http://www.ee.
columbia.edu/˜mjr59/def_spec.html.

Clean SignalClean Formants MapNoisy SignalNoisy Formants Mapa) Matching-Tracking ModelTFTHt+1t+1ttFHXt+1St+1StSt+2Ct+1Ct+2CtTFTHt+1t+1ttFHXt+1St+1StSt+2Ct+1Ct+2Cta) Composed Signallb) Entropy Mapsc) EntropyEdges289Figure 9: Reconstruction from the matching-tracking representation, starting with just the explicitly-modeled states, then
progressively ﬁlling in the transformed intermediate states.

Figure 10: First row: Harmonics/Formants decomposition (posterior distribution means). Row 2: Harmonics/Formants
tracking example. The transformation maps on both layers are used to track a given time-frequency bin. Row 3: Semi-
supervised Two Speakers Separation. a) The user selects bins on the spectrogram that she believes correspond to one
speaker. b) The system ﬁnds the corresponding bin on the transformation map. c) The system selects all bins whose
transformations match the ones chosen; the remaining bins correspond to the other speaker.

Formants and Harmonics Tracking: Analyzing a signal
with the two-layer model permits separate tracking of the
harmonic and formant ‘ancestors’ of any given point. The
user clicks on the spectrogram to select a bin, and the sys-
tem reveals the harmonics and formant “history” of that
bin, as illustrated in the second row of ﬁgure 10.

Semi-Supervised Source Separation: After modeling the
input signal, the user clicks on time-frequency bins that ap-
pear to belong to a certain speaker. The demo then masks
all neighboring bins with the same value in the transfor-
mation map; the remaining unmasked bins should belong
to the other speaker. The third row of ﬁgure 10 depicts an
example with the resultant mask and the “clicks” that gen-
erated it. Although far from perfect, the separation is good
enough to perceive each speaker in relative isolation.

Missing Data Interpolation and Harmonics/Formants

Separation: Examples of these have been shown above.

Features for Speech Recognition: The phonetic distinc-
tions at the basis of speech recognition reﬂect vocal tract
ﬁltering of glottal excitation. In particular, the dynamics of
formants (vocal tract resonances) are known to be power-
ful “information-bearing elements” in speech. We believe
the formant transformation maps may be a robust discrimi-
native feature to be use in conjunction with traditional fea-
tures in speech recognition systems, particularly in noisy
conditions; this is future work.

7 Potential Unsupervised Source Separation

Applications

The right hand of ﬁgure 8 illustrates the entropy of the
distributions inferred by the system for each transforma-

a) Statesb) Reconstruction; Iter. 1c) Reconstruction; Iter. 3d) Reconstruction; Iter. 5e) Reconstruction; Iter. 8=+Selected BinHarmonic TrackingFormant TrackingFormantsHarmonicsSignala).c).b).290Figure 12: Factor Graph

8 Conclusions

We have presented a harmonic/formant separation and
tracking model that effectively identiﬁes the different fac-
tors underlying speech signals. We show that this model
has a number of useful applications, several of which have
already been implemented in a working real-time demo.
The model we have proposed in this paper captures the de-
tails of a speech signal with only a few parameters, and is
a promising candidate for sound separation systems that do
not rely on extensive isolated-source training data.

9 Appendices

A: Loopy Belief Propagation

The sum-product algorithm [9](Kschischang 2001) can be
used to approximate inference on graphical models with
loops. The algorithm update rules applied to the factor
graph representation of the model are:
Variable to local function:

mf→x(x)

(9)

mx→f (x) = Y
f(X) Y

h∈n(x)\f

mf→x(x) = X

Local function to variable:

∼x

y∈n(f )\x

my→f (y)

(10)

where X = n(f) is the set of arguments of the function f.

B: Update Rules for the Spectral Deformation Model

Figure 12 depicts a section of the factor graph represen-
tation of our model. Function nodes hk
repre-
sent respectively the potential cliques (transition matrices)
). Function node ψk
ψhor(T k
t ,
which represents the local likelihood potential deﬁned in
eq. 4, is connected to NC “observation” variables in frame

t−1) and ψver(T k

t , T k−1

t and vk
t

t , T k

t

Figure 11: First pane shows the composed spectrogram,
second and third spectrograms correspond to the individ-
ual sources, vertical lines correspond to the frames learned
as states. Notice how the model captures the switches of
dominant speaker.

tion variable on a composed signal. The third pane shows
‘entropy edges’, boundaries of high transformation uncer-
tainty. With some exceptions, these boundaries correspond
to transitions between silence and speech, or when oc-
clusion between speakers starts or ends. Similar edges
are also found at the transitions between voiced and un-
voiced speech. High entropy at these points indicates that
the model does not know what to track, and cannot ﬁnd a
good transformation to predict the following frames. These
“transition” points are captured by the state variables when
the Matching-Tracking model is applied to a composed sig-
nal, ﬁgure 11, the state nodes normally capture the ﬁrst
frame of the “new dominant” speaker. The source sepa-
ration problem can be addressed as follows: When multi-
ple speakers are present, each speaker will be modeled in
its own layer, further divided into harmonics and formants
layers. The idea is to reduce the transformation uncertainty
at the onset of occlusions by continuing the tracking of the
“old” speaker in one layer at the same time as estimating
the initial state of the “new” speaker in another layer – a
realization of the “old-plus-new” heuristic from psychoa-
coustics. This is part of our current research.

vtTkt-1Tkthktψktxktψkt-1xkt-1vkt-1Tk-1t-1Tk-1thk-1tψk-1txk-1tψk-1t-1xk-1t-1kvtvtTkt-1Tkt-1TktTkthkthktψktψktxktψkt-1xkt-1ψkt-1ψkt-1xkt-1xkt-1vkt-1Tk-1t-1Tk-1tTk-1thk-1tψk-1txk-1tψk-1tψk-1txk-1txk-1tψk-1t-1xk-1t-1xk-1t-1k291t ) = (X

t

t

..xk+nC

], nC = (NC - 1)/2 ) and to NP “obser-

t ([xk−nC
vation” variables in frame t − 1.
When variables xk
t are actually observed, only discrete
messages between function nodes hk
t and variable
nodes T k
t are required by the algorithm. Applying recur-
sively the above update rules, we obtain the following for-
ward recursion for the horizontal nodes on the grid:

t , vk

mT k

t →hk

t

(T k

t (T k
hk

t , T k

t−1)mT k

t−1→hk

t−1

(T k

t−1))

T k

t−1

ψ( ~X [k−nC :k+nC ]

t

, ~X [k−nP :k+nP ]

t−1

, T k

t )
t )g(T k
(11)

(T k

t →T k

t ) = mvk

t ). A similar
where g(T k
backward recursion can also be found. The messages for
the vertical chains can be updated through analogous up-
ward/downward recursions.

t )mvk+1

t →T k

(T k

t

t

C: Loopy Belief with Continuous-Valued Messages

The message from function node ψk
form.

t to variable xi

j has the

mψk

Z

j) =

j

(xi
t →xi
1
C

~y,~z

exp

1
2 (αxi

j−Γ~y+~z)

0

Σ

−1
[r−nC :r+nC ](αxi

j−Γ~y+~z)

N (~y; µy, Σy)N (~z; µz, Σz)d~yd~z

(12)
Where j is either t − 1 or t and i ∈ [k − nP , k + nP ]
if j = t − 1 or i ∈ [k − nC, k + nC] if j = t. Vector ~y
is formed by the values on X [r−nP :r+nP ]
j if
j = t − 1 or the whole vector if j = t. Vectors ~z and
~X [r−NC :r+NC ]
have an analogous relationship. Vector α
and matrix Γ come from the most likely (or weighted mean)
of the transformation matrix used at T k
t .

other than xi

t−1

t

individual variables xs

Vectors ~y and ~z are obtained by concatenating individual
r. Therefore N (~y; µy, Σy) and N (~z; µz, Σz)
variables xs
should be obtained by completing the square of the
multiplication of the gaussian messages from the rele-
r to the function node ψk
t .
vant
For simplicity and to speed up the process we approx-
imate them instead by delta functions δ(~y − µy) and
δ(~z − µz), where µy and µz are obtained as explain be-
j) =
low. Then the messages reduce to: mψk
1
C exp
t ), is equal to
The posterior probability of node xk
the multiplication of all its incoming messages. We ap-
proximate this multiplication with a Gaussian distribution,
t ) = N (xk
0(xk
). Minimizing their KL diver-
q
gence we ﬁnd:

j−Γµy+µz).

j−Γµy+µz)

t , q(xk

Σ−1(αxi

t ; µxk

t →xi

1
2 (αxi

, φxk

(xi

0

j

t

t

PNC +NP
PNC +NP
(Γi~yi − ~zi)
iΣ−1
α
i
iΣ−1
i α−1
α

i=1

i=1

i

0

0

µxk

t

=

(13)

j

(xk

t →ψi

The values displayed by the missing data application are
these mean values. The means of the variable to local func-
t ), have the same form as
tion nodes messages, mxk
in equation 13, just subtracting the numerator and denom-
inator factor corresponding to the incoming message from
the corresponding function. Since we use diagonal vari-
ances, parameters µy and µz in 12 are found by concate-
t ).
nating the means of the relevant messages mxk
When using the two layer model, an extra message comes
from the other layer adding extra factors in the numerator
and denominator of equation 13.

t →ψi

(xk

j

Acknowledgements

This work was supported by Microsoft Research and by
the NSF under grant no. IIS-0238301. We want to thank
Sumit Basu for insightful feedback on this research. Any
opinions, ﬁndings and conclusions or recommendations ex-
pressed in this material are those of the author(s) and do not
necessarily reﬂect the views of the NSF.

References

[1] S. Roweis, “One-microphone source separation”, Ad-

vances in NIPS, MIT Press, 2000.

[2]

J. Bilmes, “Data-driven extensions to HMM statistical
dependencies”, Proc. ICSLP, 1998.

[3] N. Jojic and B. Frey, “Learning ﬂexible sprites in

video layers”, Proc. CVPR, 2001.

[4] A. Levin, A. Zomet, and Y. Weiss “Learning to
perceive transparency from the statistics of natural
scenes”, Proc. NIPS, 2002.

[5] N. Jojic, B. Frey, and A. Kannan, “Epitomic Analysis

of Appearance and Shape”, Proc. ICCV, 2003.

[6] M. Reyes-Gomez, N. Jojic, and D. Ellis, “To-
wards single-channel unsupervised source separation
of speech mixtures:The layered harmonics/formants
separation-tracking model”, SAPA04. Korea 2004.

[7]

J.S. Yedidia, W.T. Freeman, and Y. Weiss, “Under-
standing Belief Propagation and its Generalizations”,
Exploring Artiﬁcial Intelligence in the New Millen-
nium, Chapter 8.

[8] Y. Weiss and W.T. Freeman, “Correctness of Belief
Propagation in Gaussian Graphical Models of Arbi-
trary Topology”, Neural Computation, V13, No 10,
pp 2173-2200, 2001.

[9] F. Kschischang, B. Frey, and H.-A. Loeliger, “Fac-
tor Graphs and the Sum-Product Algorithm”, IEEE
Transactions on information theory, Vol. 47 No. 2,
2001.

292Audio demonstrations at http:// www.comm.utoronto.ca/ (cid:24)rennie/srcsep

Variational Speech Separation of More Sources than Mixtures

Steven J. Rennie, Kannan Achan, Brendan J. Frey, Parham Aarabi
Department of Electrical and Computer Engineering, University of Toronto

rennie@eecg.utoronto.ca

Abstract

We present a novel structured variational infer-
ence algorithm for probabilistic speech separa-
tion. The algorithm is built upon a new genera-
tive probability model of speech production and
mixing in the full spectral domain, that utilizes
a detailed probability model of speech trained in
the magnitude spectral domain, and the position
ensemble of the underlying sources as a natural,
low-dimensional parameterization of the mixing
process. The algorithm is able to produce high
quality estimates of the underlying source con-
ﬁgurations, even when there are more underly-
ing sources than available microphone record-
ings. Spectral phase estimates of all underlying
speakers are automatically recovered by the algo-
rithm, facilitating the direct transformation of the
obtained source estimates into the time domain,
to yield speech signals of high perceptual quality.

1 Introduction

The speech separation problem is one that has been very
heavily researched, and whose solution under practical
conditions still alludes us today. Several existing ap-
proaches work well under various problem assumptions
– such as negligible or stationary reverberation, instanta-
neous mixing, or more microphones recordings than speech
sources – but break down when these conditions are re-
laxed.

Two important directions of progress in speech separation
research have been the incorporation of detailed informa-
tion about the nature of speech into the estimation process,
and the utilization of multiple signal mixtures (Frey et al.
2001; Bell and Sejnowski 1995). Currently the emphasis of
much research is on utilizing these methodologies simulta-
neously (Attias 2003; A.Acero, Altschuler and Wu 2000;

Rennie et al. 2003). Approximate inference techniques
have been applied to the problem to facilitate the incorpo-
ration of more representative models of speech production
and mixing into the estimation process, with success (At-
tias 2003; Rennie et al. 2003). Spatially selective (e.g.
beamforming) algorithms, on the other hand, have demon-
strated signiﬁcant results via the utilization of source posi-
tion or direction information, despite the fact that the ma-
jority of existing techniques do fully decoupled source esti-
mation, and do not incorporate prior information about the
nature of speech (Aarabi and Shi 2004; Cohen and Berdugo
2002; Nix, Kleinschmidt and Hohmann 2003).

In this paper, we present a novel structured variational in-
ference algorithm for probabilistic speech separation. The
algorithm is built upon a new generative probability model
of speech production and mixing in the full spectral do-
main, that utilizes a detailed probability model of speech
trained in the magnitude spectral domain, and the posi-
tion ensemble of the underlying sources as a natural, low-
dimensional parameterization of the mixing process.

For the case where the locations of the underlying speakers
are known, the algorithm is able to produce high quality es-
timates of the underlying source conﬁgurations, even when
there are more underlying sources than available micro-
phone recordings. When only noisy estimates of the posi-
tions of the underlying speakers are available, the algorithm
is automatically able to reﬁne the position estimates, im-
proving the achieved separation results substantially. The
algorithm also automatically recovers high ﬁdelity esti-
mates of the spectral phase of the underlying speakers, fa-
cilitating the direct transformation of the obtained source
estimates into the time domain, to yield speech signals of
high perceptual quality.

2 The Mixing Process

We model the signal received by microphone m of a col-
lection of microphones M as a scaled, time-delayed com-

293bination of all underlying speech sources, and noise:

X

xm(t) =

km;szs(t (cid:0) (cid:28)m;s) + nm(t)

(1)

S

where (cid:28)m;s and km;s are the time delay and intensity decay
associated with the propagation of source signal s to micro-
phone observation m, and nm represents all noise corrup-
tion (including transduction noise, other acoustic sources,
and reverberation when present).

Both the propagation delay and the intensity decay asso-
ciated with a given source are a function of the position
of the source, (cid:26)s, relative to that of the microphone, (cid:26)m,
and the propagation media. Under generally encountered
indoor conditions (negligible wind and temperature gradi-
ents), the relationship between (cid:28)m;s and (cid:26)s given (cid:26)m can
be approximated to high ﬁdelity as frequency independent
and geometric:

(cid:28)m;s = (cid:28)m;s((cid:26)s) =

k(cid:26)s (cid:0) (cid:26)mk

vs

(2)

where vs is the speed of sound in air. Similarly, under gen-
erally encountered room conditions the intensity decay as-
sociated with atmospheric effects such as wind and tem-
perature gradients, and molecular absorption, are negligi-
ble compared to the intensity decay associated with the ge-
ometric spread of the acoustic signal from its origin. As
such the intensity of the source signal decay is proportional
to one over the distance from the source:

km;s = km;s((cid:26)s) =

ks (cid:1) gm

k(cid:26)s (cid:0) (cid:26)mk

(3)

where gm is the gain associated with the mth transducer,
and ks is a generally unknown constant that equalizes the
source signals observed at the microphones relative to a
chosen reference.

An equivalent representation of the relation (1) in the fre-
quency domain is given by:
2
664

3
775 = A!((cid:26))

3
775 +

n1!
n2!

x1!
x2!

2
664

3
775

2
664

(4)

z1!
z2!
:

:

:

xM!

zS!

nM!

where the matrix Aw((cid:26)) consists of 2 (cid:2) 2 blocks
Awm;s((cid:26)s) of the form:
(cid:20)

(cid:21)

Awm;s ((cid:26)s) = km;s

cos !(cid:28)m;s
(cid:0) sin !(cid:28)m;s

sin !(cid:28)m;s
cos !(cid:28)m;s

(5)

and zs! is the Short-Time Discrete Fourier Transform of
the sth (sampled) sound source signal at center frequency
! in vectored form:
P
P

#

"

Ref
Imf

n zs[n]w[n]e(cid:0)j 2(cid:25)k
n zs[n]w[n]e(cid:0)j 2(cid:25)k

N ng
N ng

; ! = k

N !s

zs! =

(6)

and xm! is similarly deﬁned. Here w[n] is a (gener-
ally non-rectangular) windowing function that is non-zero
over N contiguous samples of the sampled source signal
zs[n] = zs(nTs) that we wish to generate a spectral rep-
resentation of, and ws = 2(cid:25)=Ts is the sampling rate, in
radians per second.

Applying (4) over segments of length such that the error in
the relation due to windowing and the assumption of signal
stationarity is minimal (typically 10-20 ms for speech), we
have for each segment, given the source position ensemble
(cid:26) = f(cid:26)sg, a system of linear equations constraining the
underlying source signal spectra. Furthermore we have ex-
pressed the mixing process in terms of the underlying low
dimensional manifold – deﬁned by the positions of the un-
derlying speakers – which relates the observed mixtures to
the direct signal component of the speech sources.

3 Modelling Speech in the Full Spectral

Domain

When doing speech separation on real microphone record-
ings in the frequency domain, the mixing process has both
amplitude and phase components, and so to incorporate
prior information about the nature of speech it is essential
to move to the full spectral domain, so that both amplitude
and phase corruption can be ﬁltered.

Here the ﬁdelity of the recovered spectral magnitude and
phase estimates will be coupled for each source, and across
sources: therefore even in cases where we are interested
only in recovering the magnitude spectrum of a given
speaker (for input to a machine recognition system, for ex-
ample) phase representation during source inference is crit-
ical.

In cases where a time domain estimate of one or more
sources is of interest, the spectral phase of the estimate
recovered in the frequency domain will greatly affect the
perceptual quality of the obtained result. Recent research
efforts on the reconstruction of speech given only it’s en-
ergy spectrum have demonstrated the importance of phase
on perceptual quality, and the difﬁculty of the problem
(Achan, Roweis and Frey 2003).

Although it is well known that the spectral phase of speech
is coupled across harmonics, this knowledge is difﬁcult
to utilize in practice, as frequency sampling complicates
the theoretically straightforward relationship. The deﬁni-
tion of spectral phase relationships across adjacent analysis
frames are similarly complicated by the discretization of
frequency. No one has yet identiﬁed any utility in the phase
of speech for as a feature for sound discrimination or recog-
nition. The magnitude spectrum of speech (or transform of
the magnitude spectrum), on the other hand, is established
as an excellent feature domain for speech analysis. Speech
sounds are characterized by their spectral magnitude pro-

294ﬁle across frequency, and across time. LPC and Gaussian-
based (HMM,Mixture) models are the current representa-
tions of choice for capturing these relationships (Rabiner
and Juang 1993; Frey et al. 2001; Attias 2003). These ob-
servations collectively lead us to seek a probability model
of speech in the full spectral domain that incorporates de-
tailed information about the nature of speech (as charac-
terized in the magnitude spectral domain), and is phase-
invariant across both frequency and time.

Based on the forgoing discussion then, we deﬁne a phase-
invariant model of speech in the full spectral domain as
follows. We map a learned HMM model of speech in the
magnitude spectral domain into the full spectral domain by
rotating the (diagonal covariance) Gaussian state emission
distributions, at each frequency, at discrete, regular inter-
vals, and introducing phase covariance proportional to the
chosen interval size. The result is a generative model of
speech in the full spectral domain that is approximately
phase-invariant:

p(zs) =

X

T (cid:0)1Y

1
Z(cid:18)s

p(cs0 )

p(cst+1 jcst )

cs;(cid:18)s

t=0

Im{        }        

sz  
w,

t 

q s  
c  s t 
,  

w,

q s  
c  s t 
,  

p_
=    
4
t 
p_
=    
4
t 

w,

q s  
c  s t 
,  
w,
q s  
c  s t 
,  

w,

=  0  
t 

=  0  
t 

p_
4

Re{        }        

sz  
w,

t 

Figure 1: By rotating the source models learned in the mag-
nitude spectral domain at discrete, regular intervals, and in-
troducing phase covariance proportional to the chosen rota-
tion interval size, a phase invariant model of speech in the
full spectral domain is obtained.

TY

t=0

p(zst jcst ; (cid:18)st )

(7)

4 A Generative Model for the Speech

Production and Mixing

p(zst jcst ; (cid:18)st ) = N (zs;t; (cid:22)cs

t ;(cid:18)s

t

; (cid:6)cs

t ;(cid:18)s

t

);

p(cst+1 jcst ) = acs

t+1 ;cs

t

; p(cs0) = (cid:25)cs

(cid:22)cs

t ;(cid:18)s

t

= R(cid:18)s

(cid:22)cs

t

t

; (cid:6)cs

t ;(cid:18)s

t

= R(cid:18)s

t

(cid:6)cs;t RT
(cid:18)s

t

where the random variables cst and (cid:18)st represent the un-
derlying state conﬁguration, and the coarse phase of speech
source s during time frame t, respectively. (cid:22)cs
and (cid:6)cs
are the mean and diagonal covariance of the emission dis-
tribution of state cst for (cid:18)st = 0, and R(cid:18)s;t is a determin-
istic rotation matrix given (cid:18)s;t.

t

t

Figure 1 illustrates how the resulting MOG models of
speech in the full spectral domain at each frequency, for
a given speech class, are approximately phase invariant as
desired.

Note that in the case that the HMM emissions are deﬁned as
zero-mean, the model collapses to the more standard model
utilized in (Ephraim and Rabiner 1989; Attias 2003), the
(cid:18)st variable becomes redundant, and phase invariance is
automatically achieved. This close relationship allows for
the seamless substitution of the more standard model into
our source inference algorithm when desired. In particu-
lar, we have found that by utilizing the zero-mean source
model inference result to initialize source inference un-
der the full probability model (utilizing the non-zero mean
source model), the estimation was sped up substantially.

Based on the foregoing a generative probability model for
speech production and mixing over a set of temporally ad-
jacent or overlapping analysis frames T can be written as
follows:
Y

p(c; (cid:18); z; (cid:26); x)

Y

=

p(cs) (cid:1)

s

s;t

p((cid:18)st )p(zst jcst ; (cid:18)st ) (cid:1)
Y

Y

p((cid:26)s) (cid:1)

p(xtjzt; (cid:26))

s

t

acs

t+1 ;cs

t

(cid:1)

T (cid:0)1Y

t=0

(cid:25)cs

=

Y

1
Z(cid:18)
TY

s

Y

t=0

N (zs;t; ks(cid:22)cs
Y

t

t ;(cid:18)s

Y

; k2
s

(cid:6)cs

t ;(cid:18)s

t

) (cid:1)

N ((cid:26)s; %; &) (cid:1)

N (x!;t; A!((cid:26))z!;t; (cid:9)!)

(8)

s

t

!

where we have modelled noise in the mixing relationship
as zero-mean and Gaussian, and treated the positions of the
underlying speakers as stationary Gaussian random vari-
ables over set of analysis frames (analysis window); an ac-
curate assumption in most settings for analysis windows
on the order of 500 ms. Note that the scale equalization pa-
rameters ks have been moved into the deﬁnition of source
models since they are independent of the microphones. The
mixing matrix retains its dependence on scale as a function
of source position.

295S
m
m
S
c1,t-1

c2,t-1

cS,t-1

c1,t

1,t-1

2,t-1

...

z1,t-1

z2,t-1

S,t-1

...

1,t

2,t

zS,t-1

z1,t

c2,t

z2,t

cS,t

zS,t

S,t

...

c1,t+1

c2,t+1

cS,t+1

1,t+1

2,t+1

z1,t+1

z2,t+1

S,t+1

...

zS,t+1

...

x1,t-1

x2,t-1

...

xM,t-1

x1,t

x2,t

...

xM,t

x1,t+1

x2,t+1

...

xM,t+1

...

...

1

2

...

S

Figure 2: A Bayes net depicting the dependencies that exist between random variables of the speech production and mixing
process.

Under this description the generation process for each anal-
ysis frame proceeds as follows:

(cid:15) A speech sound is emitted from each speaker in ac-
cordance with the conditional prior p(cst+1 jcst ) =
acs

.

t+1 ;cs

t

(cid:15) The coarse phase of each speaker at each frequency is

uniformly generated from the domain of (cid:18)st.

(cid:15) Given cst and (cid:18)s;t, and instance of the speech sound is
generated from the distribution of the speciﬁed speech
cluster for all speakers.

(cid:15) A position ensemble is sampled from the distribution

of (cid:26).

(cid:15) Given (cid:26) and

observa-
Q
tions are generated according to p(xtjzt; (cid:26)) =

the microphone

Q

zt,

! N (x!;t; A!((cid:26))z!;t; (cid:9)!).

t

Figure 2 depicts a Bayes net of the generative model pre-
sented above.

5 Source Inference

Given our generative probabilistic description of speech
production and mixing, the problem of estimating the con-
ﬁguration of the underlying sources over an analysis win-
dow given observed microphone mixtures becomes one of
simultaneous probabilistic learning and inference, as gen-
erally both the conﬁguration of the underlying sources and
the parameters of the model f(cid:9); k; %; &g will be unknown.

Because the decision about the conﬁguration of the under-
lying sources is fully coupled by the observed microphone
data, even when the positions of the underlying sources are
known, exact inference is exponential in the representation
complexity of the underlying speech model, and hence gen-
erally intractable to compute. However the relationship be-
tween the observed mixtures and the underlying sources
given the source positions constructed in Section 2 is lin-
ear, and the source model deﬁned in Section 3 is built upon
Gaussian basis functions, and so the system is conditionally
amenable to variational approximate inference techniques
(Jordan et al. 1999).

In general however, the position of the underlying sources
will not be known, and so a posterior distribution over the
source positions must simultaneously estimated. Unfortu-
nately the entries of the mixing matrix are non-linear in the
time delays deﬁned by the source positions, and the delays
themselves are a non-linear function of the source positions
(cid:26), and so density estimation and propagation through these
relationships is difﬁcult (and fully coupled) problem, not
amenable to analytic approaches.

Here we will concentrate on the case when rough estimates
of the underlying source positions are available, and col-
lapse the position ensemble distribution estimation prob-
lem onto a point, making it a parameter to be reﬁned dur-
ing source inference. In making this assumption we remind
the reader that source localization in of itself is a very dif-
ﬁcult problem, with today’s best acoustic techniques gen-
erally requiring many more microphones than sources to
achieve position estimates of ﬁdelity (DiBiase, Silverman

296r
r
r
q
q
q
q
q
q
q
q
q
and Brandstein 2001; Aarabi 2003). Note however, that
it is the utilization of a naturally existing parameter (the
source locations) in deﬁning the mixing process that makes
the requirement that some information about the parameter
be available plausible.

We achieve simultaneous learning of the unknown param-
eters of the model and inference of the conﬁguration of the
underlying sources by iterating between inferring a struc-
tured variational approximation to the posterior distribution
of the underlying sources given the current model param-
eters to deﬁne an approximate E-Step and obtain a lower
bound the data likelihood, and maximizing the bound with
respect to the model parameters f(cid:26); k; (cid:9)g to deﬁne the M-
Step of our Expectation-Maximization algorithm for infer-
ring the conﬁguration of the underlying sources.

E-Step: We deﬁne the form of the variational surrogate as:

Y
q(z; (cid:18); c)

Y

=

q(cs0 )
Y

t

Y

s

q(cst+1 jcst ) (cid:1)

Y

Y

q((cid:18)s!;t ) (cid:1)

s;t;!

Y

Y

!;t

q(z!;t)

=

(cid:31)s0

(cid:31)st+1;t

(cid:13)(cid:18)s

!;t

s

t

s;t;!

t;!

N (z!;t; (cid:17)!;t; (cid:10)!;t)
(9)

where f(cid:31); (cid:13); (cid:17); (cid:10)g are the variational parameters to be
found so that q best approximates the true posterior of
the hidden random variables under our speech separation
model. To identify q we minimize the Kullback-Leibler
(KL) divergence of p(z; (cid:18); c; x) from q(z; (cid:18); c). Exploiting
the conditional independencies, conditional linearity, and
Gaussian decomposition of the underlying model p given
the model parameters, and the chosen form of the varia-
tional surrogate, we arrive at the set of coupled ﬁxed point
equations for the variational parameters, given in appendix
A, that may be iterated to identify q. The computational
complexity of the inference algorithm is linear (as opposed
to exponential) in the representation complexity of the uti-
lized speech model.

M Step: The update for the source positions (cid:26) is obtained
by solving:

[f@L=@(cid:26)sx

i

g = 0

(10)

The form of @L=@(cid:26)sx
is given in the appendix. The closed
form updates for ks and (cid:9)! can also be found in the ap-
pendix.

i

6 Results

A database of dictated speech, consisting of 18 minutes of
data (3 mins. x 6 female speakers) from the Wall Street
Journal database (WSJ) was used to train a 128-component,
speaker independent, diagonal covariance Gaussian emis-
sion HMM model of speech in the magnitude spectral do-
main. This model was used to deﬁne the (common) source

prior in the full spectral domain that was utilized in all
our experiments, by isotropically expanding the learned
covariances, and rotating the model at intervals of (cid:25)=32
(as described in section 3). A 128-component zero-mean,
speaker independent, diagonal covariance Gaussian emis-
sion HMM model was also trained in the magnitude spec-
tral domain, and mapped directly into the complex domain.
For both models, several training trials, (100 EM itera-
tions each) were performed, and the model that maximized
the probability of a 12 minute validation database (deﬁned
analogously to how the training set was deﬁned) was se-
lected.

A test database of 1 minute of WSJ speech data from each
speaker in the training database was used to deﬁne the
speech sources for all test scenarios presented. Simulated
microphone recording were generated via the standard im-
age method (Allen and Berkley 1979), with additional 20
dB Gaussian noise corruption. All simulated scenarios
were set in a 7 by 6 by 2.5 m room, with all source and mi-
crophone heights set at 1.5m. The horizontal coordinates
of the sources and microphones are given in Appendix B.
In all the forthcoming results, a non-overlapping, 20 frame
analysis window (T = 20) was employed, with the 0-4kHz
region of the half overlapped, hanning-windowed FFTs of
the data (16ms segments) deﬁning each processing frame.

To speed up source inference, for all test scenarios the zero-
mean speech model-based version of our speech separation
algorithm was ﬁrst run until convergence, and the inference
result was then used to seed our full speech separation al-
gorithm, which was run for an additional 10 EM iterations
to yield ﬁnal source estimates. It worthy of note that in all
(non-reverberative) test scenarios, the additional iterations
with the non-zero mean source model resulted in substan-
tial (5% to 15%) increases in SNR gain.

Figure 3 depicts spectrograms of a typical microphone
recording, and typical separation results achieved for the
case of zero reverberation, known source position informa-
tion, 6 underlying speech sources, and only 4 available mi-
crophone observations (Figure 4 depicts the spatial setup of
this test scenario). The separation result achieved via norm-
constrained inversion of the data likelihood (a beamformer
utilizing all source position information):

z(cid:3)
!;tnc = (AT

!

A! + 0:1I)(cid:0)1AT
!

x!;t; all !; t

(11)

are included for comparative purposes. Looking at the re-
sults, we can see that our variational inference algorithm
is able to yield a dramatic improvement over the norm-
constrained inversion based estimate, and recovers a high
ﬁdelity estimate of the underlying source, despite the fact
that there are two more sources than microphones, and the
sources have strongly overlapping spectral-temporal fea-
ture content.

Table 1 summarizes the SNR gain results obtained (relative
to taking a microphone reading as the source estimates) for

297)
z
H
k
(
 
y
c
n
e
u
q
e
r
F

)
z
H
k
(
 
y
c
n
e
u
q
e
r
F

)
z
H
k
(
 
y
c
n
e
u
q
e
r
F

)
z
H
k
(
 
y
c
n
e
u
q
e
r
F

4

3

2

1

0

4

3

2

1

0

4

3

2

1

0

4

3

2

1

0

0

0

0

0

Microphone 4

2

Time (s)

Norm−Constrained Source Estimate (Source 4)

2

Time (s)

Variational Source Estimate (Source 4)

2

Time (s)

Actual Source Configuration (Source 4)

2

Time (s)

4

4

4

4

Figure 3: Our algorithm is capable of producing high quality estimates of the magnitude spectra of the underlying sources even
when there are more underlying sources than available microphone observations. The obtained SNR Gain over taking a microphone
observation as our estimate, and the norm-constrained estimate (11) in this frame is 14.5 and 10.4 dB, respectively.

)

m

(
 

e

t

a
n
o
d
r
o
o
c
 
y

5

4

3

2

1

Mic. 3

Mic. 4

Source 2

Source 4

Source 1

Source 3

Mic. 1

Source 5

Source 6

Mic. 2

1

2

3

4

x coordonate (m)

5

6

Table 1: Source vector SNR gain performance of our algorithm
as a function of microphone noise corruption level and the number
sources and microphones. All gains are calculated in the time
domain, and reported in decibels.

Number of

Sources

Number of
Microphones

Reverberation Time (s)

0

0.05

4
5
6
4
3

4
4
4
2
2

23.6 (5.3)
18.0 (4.77)
14.5 (4.37)
5.3 (2.0)
9.6 (2.9)

0.3 (1.0)
0.3 (1.4)
0.4 (0.9)
0.9 (1.1)
1.3 (1.4)

Figure 4: Physical setup of the 4 microphone, 6 speech source
test scenario

the case of known source position information, for vari-
ous source to microphone count combinations, and rever-
beration times. The average gain of applying the norm-
constrained data inversion (beamforming) estimate (11) has
also been included in brackets for comparative purposes.

For non-reverberative mixing, our variational algorithm

is able to greatly improve upon the beamforming esti-
mate (11), and yields high SNR gain results, even when
there are more sources than microphones. The algo-
rithm is automatically able to recover high ﬁdelity esti-
mates of the spectral phase of all sources, to facilitate
the direct transformation of the obtained estimates into
the time domain, to yield speech signals of high percep-
tual quality. Audio demonstrations can be listened to at
www.comm.utoronto.ca/˜rennie/srcsep.

It is difﬁcult to directly compare our results to existing
work. The best performing spatial ﬁltering algorithms that

298we are aware of are the aggressive beamforming techniques
(Cohen and Berdugo 2002; Aarabi and Shi 2004), which
have demonstrated SNR gains in the range of 10 dB at
sub-zero dB SNRs. These techniques perform decoupled
source inference, and do not incorporate prior informa-
tion about the nature of speech into the estimation process.
Here to no surprise, we have demonstrated much higher
ﬁdelity results, by addressing the shortcomings of these al-
gorithms.

Perhaps the most advanced information processing algo-
rithms for speech separation we are aware of are those pre-
sented in (Attias 2003). SNR gain results of 3.7 dB and
4.4 dB are reported for the case of 5 sources and 5 mi-
crophones and 10 dB microphone noise corruption, and 3
microphones and 2 sources and 10 dB microphone noise
corruption, respectively. In this case, however, no knowl-
edge of the spatial locations of the underlying sources was
utilized.

In (Nix, Kleinschmidt and Hohmann 2003) a particle ﬁl-
tering algorithm for simultaneous source separation and
source direction estimation is presented. Excellent source
direction estimation results are presented, but source sepa-
ration performance results are omitted.

Looking now at our results for reverberant mixing, we can
see that in sharp contrast to the non-reverberant mixing re-
sults, the algorithm performed very poorly. In (Attias 2003)
for example, source vector gains of 7+ dB are reported for
more serious reverberative conditions than tested here. We
expected the spatial selectivity inherent to the problem for-
mulation to be able to combat some reverberation. Further
analysis revealed, however, that the likelihood associated
with a given source under the model was only discrimina-
tive against sounds immediately around the other sources.
The results give us a renewed interest in the operation of the
aggressive beamforming techniques (Cohen and Berdugo
2002; Aarabi and Shi 2004) which are highly spatially dis-
criminative.

7 Concluding Remarks

In this paper, a novel structured variational learning and in-
ference algorithm for probabilistic speech separation, built
upon a new generative probability model of speech produc-
tion and mixing, was presented. For the case of multi-path
free mixing, and known source position information, ex-
cellent separation results were demonstrated. Even in sce-
narios where there were more sources than microphone ob-
servations, the algorithm has demonstrated the ability to
automatically recover high quality estimates of the magni-
tude and phase spectrum of all underlying sources, yielding
time domain source estimates of high perceptual quality.
We are currently investigating the performance of the al-
gorithm when only noisy position estimates are available.
Preliminary results have indicated that when the available

source position estimates are within 0.25 meters of the their
true values, our algorithm is able to consistently reﬁne the
source position estimates; a capability that has yielded a
SNR gain performance increase (over assuming the noisy
position estimates are correct) consistently over 5 dB and
often exceeding 10 dB. More generally the problem of si-
multaneous source localization and separation constitutes
a difﬁcult and open problem; extensions to the presented
model may be able to break ground.

We are also interested in pursuing further the presented
model of speech in the full spectral domain. Relationships
between frequency harmonics, though difﬁcult to utilize in
discrete fourier domains, could potentially be exploited by
dynamically tuning the analysis frame length to place the
pitch period and associated harmonics at the sampled fre-
quencies.

Perhaps the most interesting, and most challenging direc-
tion of future work in this research area however, is to in-
vestigate new ways of dealing with reverberation.

References

A.Acero, Altschuler, S., and Wu, L. 2000. Speech/noise
separation using two microphones and a vq model of
speech signals. In Proceedings of the Internatirional
Conference on Spoken Language Processing.

Aarabi, P. 2003. The fusion of distributed microphone ar-
rays for sound localization. EURASIP Journal of Ap-
plied Signal Processing (Special Issue on Sensor Net-
works), No. 4:338:347.

Aarabi, P. and Shi, G. 2004. Phase-based dual-microphone
IEEE Transactions on

robust speech enhancement.
Systems, Man, and Cybernetics Part B, 34.

Achan, K., Roweis, S., and Frey, B. 2003. Probabilistic
inference of speech signals from phaseless spectro-
grams. In Neural Information Processing Systems 16.

Allen, J. and Berkley, D. 1979.

ﬁciently simulating small room acoustics.
65(4):943:950.

Image method for ef-
JASA,

Attias, H. 2003. New em algorithms for source separation
and deconvolution. In Proceedings of the IEEE 2003
International Conference on Acoustics, Speech, and
Signal Processing.

Bell, A. and Sejnowski, T. 1995.

An information-
maximization approach to blind separation and blind
deconvolution. Neural Computation, 7:1129–1159.

Cohen, I. and Berdugo, B. 2002. Microphone array
In

postﬁltering for nonstationary noise suppression.
ICASSP.

299DiBiase, J., Silverman, H., and Brandstein, M. 2001. Ro-
bust localization in reverberant rooms. M.S. Brand-
stein and D.B. Ward (eds.), Microphone Arrays:Signal
Processing Techniques and Applications.

Ephraim, Y. and Rabiner, L. 1989. A minimum discrimi-
nation information approach for hidden markov mod-
eling.
IEEE Transactions on Information Theory,
35:1001–1013.

Frey, B., Kristjansson, T., Deng, L., and Acero, A. 2001.
Learning dynamic noise models from noisy speech for
robust speech recognition. In Proceedings of the 2001
Neural Information Processing Systems (NIPS).

Jordan, M. I., Ghahramani, Z., Jaakkola, T., and Saul,
L. K. 1999. An introduction to variational methods
for graphical models. Machine Learning, 37(2):183–
233.

Nix, J., Kleinschmidt, M., and Hohmann, V. 2003. Compu-
tational auditory scene analysis by using statistics of
high-dimensional speech dynamics and sound source
direction. In EUROSPEECH.

Rabiner, L. and Juang, B. 1993. Fundamentals of Speech

Recognition. Prentice-Hall, New Jersey.

Rennie, S., Aarabi, P., Kristjansson, T., Frey, B., and
Achan, K. 2003. Robust variational speech separa-
tion using fewer microphones than speakers. In Pro-
ceedings of the 2003 IEEE Conference on Acoustics,
Speech, and Signal Processing.

Appendix A: E and M Step Updates

(cid:31)cs

t ;cs

t(cid:0)1

/ acs

t ;cs

t(cid:0)1

(cid:21)cs

e

;cs

t

t(cid:0)1

(12)

(cid:21)cs

;cs

t

t(cid:0)1

1

= (cid:0)

log j(cid:6)cs

j +

2
T (cid:6)(cid:0)1

cs ;(cid:18)s!

((cid:22)cs ;(cid:18)s

!;t

(cid:0) (cid:17)!;t

) +

X! X(cid:18)s

!;t

f(cid:13) (cid:18)s

!;t

((cid:22)cs ;(cid:18)s

!;t

(cid:0) (cid:17)!;t

)

Tr[(cid:6)(cid:0)1

cs ;(cid:18)s

(cid:10)s

!;t

]g (cid:0) D (acst+1

;cst

k(cid:31)cst+1

;cst

!;t

) + Xcst+1

(cid:21)cst+1

;cst

(cid:13)S

!;t

;(cid:18)2!;t

(cid:6)(cid:0)1

c

S

t

]

;(cid:18)

S

!;t

(cid:13) (cid:18)1!;t

(cid:6)(cid:0)1
c1t

;(cid:18)1!;t

(cid:22)c1t

;(cid:18)1!;t

; :::;

(cid:16)!

t

!;t

t

S

S

(cid:31)cSt X(cid:18)
(cid:31)c1t X(cid:18)1!;t

Xc
= [Xc1t
(cid:31)cSt X(cid:18)
Xc

!;t

S

S

t

(cid:13) S

!;t

;(cid:18)2!;t

(cid:6)(cid:0)1

c

S

t

;(cid:18)

S

!;t

(cid:22)c

;(cid:18)

S

t

S

!;t

]

@L=@(cid:26)sx

i

=Xw Xt

T r[((cid:9)(cid:0)1

! (A!(cid:17)!;t (cid:0) x!;t)(cid:17)T

!;t +

(cid:9)(cid:0)1

! A!(cid:10)T

!;t)(@A!=@(cid:26)sx

)T ]

i

(16)

(x! (cid:0) A!(cid:17)!;t)(x! (cid:0) A!(cid:17)!;t)T

(17)

(cid:9)! =XT

ks =

p

(cid:0)b2

s + 2

s (cid:0) 4ascs
b2
2as

(18)

as = dim(zs )T

bs = Xt;cs

t

(cid:31)cs

t X!;(cid:18)s

!;t

(cid:13)(cid:18)s

!;t

(cid:17)T

!;t (cid:6)(cid:0)1

cs ;(cid:18)s

(cid:22)cs ;(cid:18)s

!;t

!;t

cs = (cid:0) Xt;cs

t

(cid:31)cs

t X!;(cid:18)s

!;t

(cid:13)(cid:18)s

!;t

((cid:17)T

!;t (cid:6)(cid:0)1

cs ;(cid:18)s!

(cid:17)!;t

+T r[(cid:6)(cid:0)1

cs ;(cid:18)s

(cid:10)!;t ])

!;t

Appendix B: Test Scenario Details

XSYM - X source, Y microphone test scenario
SP - Source positions
MP - Microphone positions

4S4M:
SP = (0.7,3.6),(3.5, 5.3),(2.8,1.8),(5.3,3.0)
MP = f(0,0),(6.5, 0),(0 5.5),(6.5,5.5)g

5S4M:
SP = f(0.7,3.6),(3.5,5.3),(1.4,1.8),(5.3,3.0),(4.2,1.2)g
MP = f(0,0),(6.5, 0),(0 5.5),(6.5,5.5)g

6S4M:
SP = f(0.7,3.6),(3.5,5.3),(1.4,1.8),(5.3,4.0),(5.6,2.1),(4.2,1.2)g
MP = f(0,0),(6.5, 0),(0 5.5),(6.5,5.5)g

(cid:20)(cid:18)s

!;t

= (cid:0)

1

2 Xcs

t

(cid:13) (cid:18)s

!;t

/ e

(cid:20)(cid:18)s

!;t

(cid:31)cs

t

f((cid:22)cs;(cid:18)s

!;t

(cid:0) (cid:17)!;t)T

(cid:1)

(cid:6)(cid:0)1

cs;t;(cid:18)s

((cid:22)cs;(cid:18)s

!;t

(cid:0) (cid:17)!;t)

!;t

(cid:17)!;t = (cid:10)!;t(AT

! (cid:9)(cid:0)1

! x!;t + (cid:16)!;t)

(cid:10)!;t = (AT

! (cid:9)(cid:0)1

! A! + (cid:8)!;t)(cid:0)1

(cid:8)!;t = diag[Xc1t

(cid:31)c1t X(cid:18)1!;t

(cid:13)1!;t

;(cid:18)1!;t

(cid:6)(cid:0)1
c1t

;(cid:18)1!;t

; :::;

(13)

3S2M:
SP = f(0.5,1.5),(3.0,3.0),(6.3,1.2)g
MP = f(1.5,0),(3, 0)g

4S2M:
SP = f(0.5,1.5),(1.4,3.6),(4.6,3.0),(6.3,1.2)g
MP = f(1.5,0),(3, 0)g

(14)

(15)

300Learning Bayesian Network Models from Incomplete Data using

Importance Sampling

Carsten Riggelsen and Ad Feelders

Institute of Information & Computing Sciences

Utrecht University

P.O. Box 80098, 3508TB Utrecht

The Netherlands

Abstract

We propose a Bayesian approach to learning
Bayesian network models from incomplete
data. The objective is to obtain the posterior
distribution of models, given the observed
part of the data. We describe a new algo-
rithm, called eMC4, to simulate draws from
this posterior distribution. One of the new
ideas in our algorithm is to use importance
sampling to approximate the posterior distri-
bution of models given the observed data and
the current imputation model. The impor-
tance sampler is constructed by deﬁning an
approximate predictive distribution for the
unobserved part of the data.
In this way
existing (heuristic) imputation methods can
be used that don’t require exact inference for
generating imputations.
We illustrate eMC4 by its application to mod-
eling the risk factors of coronary heart dis-
ease. In the experiments we consider diﬀerent
missing data mechanisms and diﬀerent frac-
tions of missing data.

1

Introduction

Bayesian networks are probabilistic models that can
represent complex interrelationships between random
variables.
It is an intuitively appealing formalism
for reasoning with probabilities that can be employed
for diagnosis and prediction purposes. Furthermore,
learning Bayesian networks from data may provide
valuable insight into the (in)dependences between the
variables.

In the last decade, learning Bayesian networks from
data has received considerable attention in the re-
search community. Most learning algorithms work un-
der the assumption that complete data is available. In

practical learning problems one frequently has to deal
with missing values however. The presence of incom-
plete data leads to analytical intractability and high
computational complexity compared to the complete
data case. It is very tempting to “make the problem
go away” either by deleting observations with missing
values or using ad-hoc methods to ﬁll in (impute) the
missing data. Such procedures may however lead to
biased results, and, in case of imputing a single value
for the missing data, to an overconﬁdence in the results
of the analysis.

We avoid such ad-hoc approaches and use a method
that takes all observed data into account, and cor-
rectly reﬂects the increased uncertainty due to miss-
ing data. We do assume however that the missing
data mechanism is ignorable as deﬁned by Little and
Rubin (1987). Essentially this means that the proba-
bility that some component is missing may depend on
observed components, but not on unobserved compo-
nents.

Our approach is Bayesian in the sense that we are
not aiming for a single best model, but want to ob-
tain (draws from) a posterior distribution over possi-
ble models. We show how to perform model averaging
over Bayesian network models, or alternatively, how
to get a range of good models, when we have incom-
plete data. We develop a method that can handle a
broad range of imputation methods without violating
the validity of the models returned. Our approach is
not restricted to any imputation technique in particu-
lar, and therefore allows for imputation methods that
do not require expensive inference in a Bayesian net-
work.

This paper is organised as follows.
In section 2 we
brieﬂy review previous research in this area and show
how our work ﬁts in. In section 3 we describe model
learning from complete data. In sections 4 and 5 we
introduce a new algorithm, called eMC4, for Bayesian
network model learning from incomplete data. We per-
formed a number of experiments to test eMC4 using

301real life data. The results of those experiments are re-
ported in section 6. Finally, we summarize our work
and draw conclusions.

2 Previous research

Here we brieﬂy review relevant literature on learning
Bayesian networks from incomplete data. Two pop-
ular iterative approaches for learning parameters are
Expectation-Maximization (EM) by Dempster et al.
(1977) and a simulation based Gibbs sampler (Geman
and Geman, 1984) called Data Augmentation (DA) in-
troduced by Tanner and Wong (1987). For Bayesian
networks EM was studied by Lauritzen (1995). The
Expectation step (E-step) involves the performance of
inference in order to obtain suﬃcient statistics. The
E-step is followed by a Maximization step (M-step) in
which the Maximum Likelihood (ML) estimates are
computed from the suﬃcient statistics. These two
steps are iterated until the parameter estimates con-
verge.

Data Augmentation (DA) is quite similar but is non-
deterministic. Instead of calculating expected statis-
tics, a value is drawn from a predictive distribution
and imputed. Similarly, instead of calculating the ML
estimates, one draws from the posterior distribution
on the parameter space (conditioned on the suﬃcient
statistics of the most recent imputed data set). Based
on Markov chain Monte Carlo theory this will eventu-
ally return realizations from the posterior parameter
distribution. There are also EM derivatives that in-
clude a stochastic element quite similar to DA (see
McLachlan and Krishnan, 1997).

Bound and Collapse (BC) introduced by Ramoni and
Sebastiani (2001) is a two-phase algorithm. The bound
phase considers possible completions of the data sam-
ple, and based on that computes an interval for each
parameter estimate of the Bayesian network. The col-
lapse phase computes a convex combination of the in-
terval bounds, where the weights in the convex com-
bination are computed from the available cases. The
collapse phase seems to work quite well for particu-
lar missing data mechanisms but unfortunately is not
guaranteed to give valid results for ignorable mecha-
nisms in general.

Learning models from incomplete data so to speak
adds a layer on top of the parameter learning methods
described above. For EM, Friedman (1998) showed
that doing a model selection search within EM will re-
sult in the best model in the limit accoring to some
model scoring criterion. The Structural EM (SEM)
algorithm is in essence similar to EM, but instead of
computing expected suﬃcient statistics from the same
Bayesian network model throughout the iterations, a

model selection step is employed. To select the next
model, a model search is performed, using the expected
suﬃcient statistics obtained from the current model
and current parameter values.

Ramoni and Sebastiani (1997) describe how BC can be
used in a model selection setting. As remarked before
however, BC is not guaranteed to give valid results
for ignorable mechanisms in general, and the risk of
obtaining invalid results unfortunately increases when
the model structure is not ﬁxed.

In contrast to SEM, our aim is not to select a sin-
gle model, but to obtain a posterior probability distri-
bution over models that correctly reﬂects uncertainty,
including uncertainty due to missing data. Therefore
our approach is more related to the simulation based
DA described above.

3 Learning from complete data

In this section we discuss the Bayesian approach to
learning Bayesian networks from complete data. First
we introduce some notation. Capital letters denote
discrete random variables, and lower case denotes a
state. Boldface denote random vectors and vector
states. We use Pr(·) to denote probability distribu-
tions (or densities) and probabilities. D = (d1, . . . , dc)
denotes the multinomial data sample with c i.i.d. cases.
A Bayesian network (BN) for X = (X 1, . . . , X p)
represents a joint probability distribution.
It con-
sists of a directed acyclic graph (DAG) m, called the
model, where every vertex corresponds to a variable
X i, and a vector of conditional probabilities θ, called
the parameter, corresponding to that model. The
joint distribution factors recursively according to m as
i=1 Pr(X i|Π(X i), θ), where Π(X i) is

Pr(X|m, θ) = (cid:81)p

the parent set of X i in m.

Since we learn BNs from a Bayesian point of view,
model and parameter are treated as random variables
M and Θ. We deﬁne distributions on parameter space
PrΘ(·) and model space PrM (·). The superscript is
omitted and we simply write Pr(·) for both. The dis-
tribution on the parameter space is a product Dirich-
let distribution which is conjugate for the multinomial
sample D, i.e. Bayesian updating is easy because the
posterior once D has been taken into consideration is
again Dirichlet, but with updated hyper parameters.
The MAP model is found by maximizing with respect
to M

Pr(M |D) ∝ Pr(D|M ) · Pr(M )

(1)

where Pr(D|M ) is the normalizing term in Bayes the-
orem when calculating the posterior Dirichlet

Pr(D|M ) = (cid:90) Pr(D|M, Θ) Pr(Θ|M )dΘ (2)

302where Pr(D|M, Θ) is the likelihood, and Pr(Θ|M ) is
the product Dirichlet prior. In Cooper and Herskovits
(1992) a closed formula is derived for (2) as a function
of the suﬃcient statistics for D and prior hyper pa-
rameters of the Dirichlet. This score can be written as
a product of terms each of which is a function of a ver-
tex and its parents. This decomposability allows local
changes of the model to take place without having to
recompute the score for the parts that stay unaltered,
that is, only the score for vertices whose parents set
has changes needs to be recomputed.

Instead of the MAP model, we may be interested in
the expectation of some quantity ∆ of models using
Pr(M |D) as a measure of uncertainty over all models

E[∆] = (cid:88)M

∆M · Pr(M |D) ≈

1
q

q

(cid:88)i=1

∆mi

(3)

where the Monte Carlo approximation is obtained by
sampling {mi}q

i=1 from Pr(M |D).

It is infeasible to calculate the normalizing factor
Pr(D) required to obtain equality in equation (1).
Madigan and York (1995) and Giudici and Castelo
(2003) propose to use (enhanced) Markov chain Monte
Carlo Model Composition (eMC3) for drawing mod-
els from this distribution leaving the calculation of
the normalizing term implicit. It is a sampling tech-
nique based on Markov chain Monte Carlo Metropolis-
Hastings sampling summarized in the following iter-
ated steps. At entrance assume model mt:

1. Draw model mt+1 from a proposal distribution
Pr(M |mt) resulting in a slightly modiﬁed model
compared to mt (addition, reversal or removal of
an arc).

2. The proposed model mt+1 is accepted with prob-

ability

α(mt+1, mt) = min(cid:110)1,

Pr(D|mt+1) Pr(mt+1)

Pr(D|mt) Pr(mt) (cid:111),

otherwise the proposed model
mt+1 def= mt.

is rejected and

For t → ∞ the models can be considered samples from
the invariant distribution Pr(M |D). Note that in step
two the normalizing factor Pr(D) has been eliminated.
For enhanced MC3 a third step is required, Repeated
Covered Arc Reversals (RCAR) which simulates the
neighbourhood of equivalent DAG models. We refer
to Kocka and Castelo (2001) for details.

4 Learning from incomplete data

Running standard eMC3 can be quite slow, especially
for large models and data sets. In the presence of miss-

ing data, a prediction ‘engine’ (predicting missing com-
ponents) so to speak has to be wrapped around eMC3.
Obtaining a prediction engine which will always make
the correct predictions is infeasible to construct, and
when the engine itself has to adapt to the ever chang-
ing model this becomes even worse. An approximate
predictive engine is usually easier to construct, but will
obviously sometimes make slightly wrong predictions.
In this section we show how approximation can be used
together with eMC3 to obtain realizations from the
posterior model distribution such that prediction er-
rors are corrected for.

Our goal is to compute (3) when we have missing data.
To be more precise, if we write D = (O, U) to denote
the observed part O and the unobserved part U, our
goal is to get draws from Pr(M |O) such that we can
use the approximation in (3). Due to incompleteness
the integral in (2) no longer has a tractable solution.
Our approach is instead to rewrite the posterior model
distribution such that U can be “summed out” by way
of “ﬁlling in”. Note that the desired model posterior
can be written as

Pr(M |O) = (cid:88)U

Pr(M |O, U ) Pr(U |O).

(4)

The ﬁrst term is the distribution given in (1) involv-
ing the prior and the marginal likelihood (2). The
second part is the predictive distribution which can be
considered the predictor of the missing data based on
the observed part. We explicitly model the predictive
distribution as a BN with model M (cid:48), the imputation
model. We therefore write

Pr(M |O, M (cid:48)) =(cid:88)U

Pr(M |O, U, M (cid:48)) Pr(U |O, M (cid:48)) (5)

We assume that M is independent of M (cid:48) given O and
U , i.e. once we are presented with complete data, the
imputation model has become irrelevant

Pr(M |O, U, M (cid:48)) = Pr(M |O, U ).

The Monte Carlo approximation of (5) is calculated as

Pr(M |O, M (cid:48)) ≈

1
n

n

(cid:88)i=1

Pr(M |O, U i)

where U i ∼ Pr(U |O, M (cid:48)) for i = 1, . . . , n. So, if we
could compute realizations from this predictive distri-
bution we could approximate Pr(M |O, M (cid:48)). Unfor-
tunately we can not use simple sequential Bayesian
updating (Spiegelhalter and Lauritzen, 1990) for de-
termining Pr(U |O, M (cid:48)). Instead of sampling from the
true predictive distribution, we deﬁne an approximate
predictive distribution which can act as a proposal dis-
tribution for suggesting imputations. The predictive

303distribution can be rewritten such that it can act as
a quality measure for a proposed imputation. This
is accomplished by using importance sampling. De-
note the approximate predictive distribution Pr∗(U )
and rewrite (5)

Pr(M |O, M (cid:48)) = (cid:88)U

Pr(M |O, U )

Pr(U |O, M (cid:48))

Pr∗(U )

Pr∗(U )

Sample U i ∼ Pr∗(U ) for i = 1, . . . , n and use that
sample in the importance sampling approximation

Pr(M |O, M (cid:48)) ≈

1
W

n

(cid:88)i=1

Pr(U i|O, M (cid:48))

Pr∗(U i)

Pr(M |O, U i) (6)

(cid:124)

wi

(cid:123)(cid:122)

(cid:125)

where W = (cid:80)n

rewrite the predictive distribution

i=1 wi is the normalizing constant. Now

Pr(U i|O, M (cid:48)) = Pr(U i, O|M (cid:48))

1

Pr(O|M (cid:48))

where the term Pr(U i, O|M (cid:48)) is given by (2). Through
normalization the denominator Pr(O|M (cid:48)) disappears
as it is independent of U . It therefore suﬃces to cal-
culate the weights as

wi =

Pr(U i, O|M (cid:48))

Pr∗(U i)

(7)

where the numerator can be computed eﬃciently and
the denominator is the probability of the proposal.
The marginal likelihood in the numerator is in this
context not used as a scoring criterion for models. In-
stead we use it as a scoring criterion for imputations.
The denominator compensates for the bias introduced
by drawing from Pr∗(U ) rather than the correct pre-
dictive distribution.

Given a set {U i}n
i=1 that has been sampled from
Pr∗(U ), sampling from the mixture approximation (6)
of Pr(M |O, M (cid:48)) is done as follows:

1. The probability of selecting sample U i augment-
ing O is proportional to the importance weight
wi.

2. The now complete sample (O, U i) is used for sam-

pling models from Pr(M |O, U i) using eMC3.

We can now draw from Pr(M |O, M (cid:48)), but our goal was
to obtain draws from Pr(M |O), i.e. we need samples
from the posterior model distribution given observed
data without conditioning on the imputation model
M (cid:48). The desired distribution is obtained by Gibbs
sampling. Given an imputation model ml draw the
following

ml+1 ∼ Pr(M |O, ml)

...

Algorithm eMC4(n, q, k)

r ← 0
for l ← 0 to k

W ← 0
U 0 ← U r
for i ← 0 to n

1 m0 ← G = (V = X, E = ∅)
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19

draw r ∼ Pr(i) = wi/W
m0 ← ml
for t ← 0 to q

ml+1 ← mq+1
LogToFile(ml+1)

wi ← Pr(O, U i|ml) / Pr∗(U i)
W ← W + wi
if i (cid:54)= n then draw U i+1 ∼ Pr∗(U )

mt ← RCAR(mt)
draw mt+1 ∼ Pr(M |mt)
B ← Pr(O, U r|mt+1) / Pr(O, U r|mt)
draw α ∼ Bernoulli(min{1, B})
if α (cid:54)= 1 then mt+1 ← mt

Figure 1: The eMC4 algorithm

which for l → ∞ results in a chain of realizations from
Pr(M |O). This in eﬀect allows us to calculate (3).

When n is large, the mixture approximation is close
to the real distribution Pr(M |O, M (cid:48)). However, the
invariant model distribution is reached for any value
assigned to n if we make sure that one of the imputa-
tion proposals is the current imputation, i.e. the aug-
mented data sample that was selected at the last mix-
ture draw before entering the eMC3 loop. By this
overlap, n is indirectly increased every time the mix-
ture is set up. From a practical point of view however,
n does have an impact on how well the model Markov
chain mixes. Small n implies slow mixing depending
on how far the approximate predictive distribution is
from the real predictive distribution.

We do not discuss parameter estimation in this paper,
but merely mention that using the importance sampler
presented above, it is also possible to approximate the
posterior parameter distribution. In (6) simply plug
in Pr(Θ|M (cid:48), O, U i) instead of Pr(M |O, U i) to obtain
the required posterior.

To summarize, ﬁgure 1 contains the pseudo-code for
the algorithm called enhanced Markov Chain Monte
Carlo Model Composition with Missing Components,
or for short, eMC4. In line 1 an initial empty graph
is deﬁned.
In lines 6–9 the imputations take place
and the importance weights are calculated. Line 10
is the ﬁrst step in drawing from the mixture. Lines

30412–17 perform the eMC3 algorithm based on the aug-
mented sample selected.
In the absence of relevant
prior knowledge, a uniform model prior is assumed in
line 15. Angelopoulos and Cussens (2001) discuss the
construction of informative model priors. The choice
of k (number of iterations of the Gibbs model sampler)
depends on when the Markov chain of models has con-
verged. Monitoring the average number of edges is one
method for doing so suggested by Giudici and Green
(1999). Once this average stabilizes the chain has con-
verged.

5 Proposal distribution Pr∗(U )

We can choose freely the approximate predictive dis-
tribution from which samples are drawn for (6), but
of course some choices are better than others. Ideally,
the appoximate predictive distribution should be close
to the real predictive distribution, because otherwise n
is required to be large to obtain enough samples from
the region where the mass of the real distribution is
located. Existing imputation techniques can be used,
as long as they can be cast in the form of a distribu-
tion from which imputations can be drawn. Naturally
it is also a requirement that Pr∗(U ) has support when
Pr(U |O, M (cid:48)) has support. A uniform proposal distri-
bution is probably unwise unless a very small fraction
of data is missing. On the other hand, a distribution
based on M (cid:48) with parameters estimated using EM is
not needed. Employing the BC algorithm for param-
eter estimation using M (cid:48) could be interesting, since
it is fast and is reported to often give reasonable re-
sults. Alternatively, a simple available cases analysis
may prove to be good enough.

It is not a requirement to use the actual imputation
model M (cid:48) as the basis for Pr∗(U ).
In fact Pr∗(U )
need not be modeled as a BN at all. However, an
imputation method that does not take the indepen-
dences portrayed by M (cid:48) into account will have a hard
time proposing qualiﬁed imputations, because the de-
gree of freedom is simply too high (assuming that
nothing is known about the missing data mechanism).
Similarly, the parameter does not need to be derived
from the data; however, since the missing data mech-
anism is assumed to be ignorable, all information we
need to impute (predict) is contained (indirectly) in
O, and therefore predictions should at least depend
on observed values. We propose to model Pr∗(U ) def=
Pr(U |O, M (cid:48), θ) as a BN with model M (cid:48) and parameter
θ = E[Θ|O, U M (cid:48)
], where expectation is with respect
to Pr(Θ|M (cid:48)), and (O, U M (cid:48)
) is the augmented sample
from which M (cid:48) was learned. The latter makes sense
because (O, U M (cid:48)
) is the sample from which the model
was learned and therefore reﬂects the most appropriate

sample on which to base the parameter.

In order do draw multivariates we propose the fol-
lowing method based on Gibbs sampling, where re-
alizations are drawn on a univariate level. Denote
a case j in D by dj = (x1
j ) = (oj , uj) =
(oj , (u1
)), where oj and uj refer to the ob-
served and unobserved part of the case. The j’th case
for U t is sampled as follows

j , . . . , ur(j)

j , . . . , xp

j

u1,t
j ∼ Pr(U 1

j |u2,t−1

j

, . . . , ur(j),t−1

j

, oj , M (cid:48), θ)

...
∼ Pr(U r(j)

j

ur(j),t
j

|u1,t
j

, . . . , ur(j)−1,t

j

, oj , M (cid:48), θ).

Based on Markov chain Monte Carlo theory, corre-
lated multivariate realizations uj ∼ Pr(U j|oj , M (cid:48), θ)
are obtained when t → ∞. Since each draw in the
Gibbs sampler is univariate, and the entire Markov
blanket of variable U i has evidence, inference does not
require any advanced techniques.

With the suggested Gibbs sampler we eﬀectively col-
lect all realizations including samples in the burn-in
phase. The idea is to let the importance sampler de-
cide on the quality of the proposed imputations.

We can calculate the importance weights eﬃciently
without explicitely knowing the actual probabilities
Pr(U i|O, M (cid:48), θ). This can be seen by rewriting the
importance weights from (7):

wi =

=

Pr(U i, O|M (cid:48))
Pr(U i|O, M (cid:48), θ)
Pr(U i, O|M (cid:48)) · Pr(O|M (cid:48), θ)

Pr(U i, O|M (cid:48), θ)

.

By normalization of these weights, Pr(O|M (cid:48), θ) can-
cels out, and it suﬃces to calculate the weights as

wi =

Pr(U i, O|M (cid:48))
Pr(U i, O|M (cid:48), θ)

,

the ratio of the marginal likelihood over the likelihood
given θ. This ratio is easily obtained because both
probabilites can be computed eﬃciently in closed form.
In summary, we can propose imputations eﬃciently
and we can compute the “quality” of such a propsal
eﬃciently as well.

When the structural diﬀerence between the imputa-
tion model M (cid:48) and the exit model M is kept relatively
small (dependent on q), we can make the following
observations when θ is assigned E[Θ|O, U M (cid:48)

]:

(1) Multivariate predictions based on the two models
are correlated. Hence n need not be large in order
to compensate for the predictive diﬀerence. However,
we may still need many realizations U i
in order to

305F

B E

D

F

B E

D

F

B E D

F

B E

D

}}}

A

C

27%

}}}

A

C

21%

C

A

9%

}}}

9%

C

A

Complete (total 60 models visited)

F

B E

D

F

B E

D

F

B E

D

F

B E

D

}}}

A

C

25%

}}}

A

C

11%

}}}

7%

C

A

}}}

5%

C

A

Mechanism 1: 5–10% missing (total 137 models visited)

F

B E

D

F

B E

D

F

B E

D

F

B E

D

}}}

A

C

18%

}}}

7%

C

A

}}}

6%

C

A

Mechanism 1: 10–15% missing (total 168 models visited)

F

B E D

F

B E D

F

B E

D

F

C

A

7%

C

A

6%

}}}

5%

C

A

}}}

5%

C

A

B E D

AAA

C

A

5%

Mechanism 1: 15–20% missing (total 188 models visited)

F

B E D

F

B E D

F

B E

D

F

B E D

C

A

12%

C

A

12%

}}}

9%

C

A

C

A

8%

Mechanism 2: 20–30% missing (total 152 models visited)

Figure 2: Top four visited models. Note that all edges are reversible.

capture the entire distribution. Correlation between
multivariate predictions allows us to keep n relatively
small and only move slightly in a direction towards a
‘better’ prediction.

(2) Because models are correlated and as a conse-
quence also the predictions, the ﬁrst predictions ob-
tained by running the Markov blanket Gibbs sampler
may be good. The Gibbs sampler so to speak picks up
from where it left the last time and continues imputa-
tion using the new model. This means that the there
is a fair chance that an initial imputation is actually
selected.

F

Bo

E /

D

F

B E

D

~}}}

/ A

C

}}}

A

C

RF

B

RE Do

RF

RB RE RD

"FFFF

}{{{

RC RA

cGGGG

cGGGG

C

A

;wwww

Figure 3: Top: Generating model (left), Essential
graph (right). Bottom: Mechanism 1 (left), Mecha-
nism 2 (right).

6 Experimental evaluation

In this section we perform a small experimental evalu-
ation of eMC4 and brieﬂy discuss the results. Because
our approach is Bayesian, comparison of the results
with model selection methods for incomplete data such
as SEM is not very useful.

We used a data set from Edwards and Havr´anek (1985)
about probable risk factors of coronary heart disease.
The data set consists of 1841 records and 6 binary
variables, A: smoking, B: strenuous mental work, C:
strenuous physical work, D: blood pressure under 140,
E: ratio β to α proteins less than 3, F : family history

of coronary heart disease. Because several DAGs en-
code the same set of assumptions about independence,
we depict results as essential graphs, a canonical repre-
sentation of an equivalence class (see Chickering, 1995;
Kocka and Castelo, 2001).

Based on an eMC3 run using the 1841 complete
records, the 1st model in ﬁgure 3 is a highly probable
model (although edge F −B is not strongly supported).
The 2nd model in the ﬁgure is the corresponding essen-
tial graph of the DAG. The parameter corresponding
to the DAG model was determined based on the afore-
mentioned data set, and 1800 new records were sam-
pled from the BN. Incomplete sets were generated by

306o
/


~
O
O
/


"
o
o
o
}
c
O
O
c
O
O
;
applying missingness mechanism one in ﬁgure 3 on the
complete sample. This graph explicitly deﬁnes how re-
sponse Ri of variable i depends on observed variables.
Since for all i, Ri only depends on completely observed
variables, the missingness mechanism is clearly ignor-
able. Three incomplete sets were generated with 5–
10%, 10–15% and 15–20% missing components. The
probability of non-response of variable i conditional
on a parent conﬁguration of Ri was selected from the
speciﬁed interval.

On the basis of the generating model and the missing-
ness mechanism, we would expect the following results.
Since response of C only depends on B and the asso-
ciation C − B is strong, a big fraction of components
can be deleted for C without destroying support for
the edge in the data. Association D − E is also strong
so discarding components for E will probably not have
a major impact on the edge either. Association E − A
is inﬂuenced by B and D because the response is de-
termined by those variables. Values for E and A may
be absent often and therefore information about the
association might have changed. This may also be the
case for the edges C − E and C − A.

We ran eMC4 using each incomplete data set. Param-
eter q (number of eMC3 iterations) was set to 150 and
n to 25 (number of imputations).
It took about 15
minutes on a 2 GHz machine before the Markov chain
appeared to have converged.

In ﬁgure 2 the top four models are depicted along with
their sampling frequencies. Notice the presence of the
strong associations C − B and D − E everywhere, as
expected. When the fraction of missing components
for two associated variables increases it has a big im-
pact on the support of such an association.
Indeed,
from the ﬁgure we see that the support for associations
between variables A, C and E has changed. The sam-
ple frequencies and the number of visited models also
suggest that the variance of the posterior distribution
becomes bigger when more components are deleted.
There is no longer a pronounced ‘best’ model.

The plot in ﬁgure 4 shows this more clearly. Here
the cumulative frequencies are plotted against models
(sorted on frequency in descending order). A steep
plot indicates a small variance. For complete data the
10 best models account for 90% of the distribution
whereas for 15–20% missing components only 50% of
the distribution is accounted for by the best 10 mod-
els. To investigate the similarity of the models between
the three incomplete sets, we used equation (3) to cal-
culate ∆, where ∆M is set to 1 when there is an edge
between two vertices of interest in M . This results
in the expected probability of the presence of edges
as seen in ﬁgure 4. We can see, as we would expect,

Complete
Mech1 5-10
Mech2 20-30
Mech1 10-15
Mech1 15-20

0

10

20

30

40

50

60

Complete
Mech1 5-10
Mech1 10-15
Mech1 15-20

0
.
1

8
.
0

6
.
0

4
.
0

2
.
0

0
.
0

1.0

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0.0

B-F E-F C-F A-F D-F E-B C-B A-B D-B C-E A-E D-E A-C D-C D-A

Figure 4: Top: Cumulative frequencies. Bottom: Ex-
pected probability of edges.

that the distance between points of complete data and
incomplete data is dependent on the fraction of miss-
ing components. Diamonds (15–20%) have the biggest
distance to triangles (complete), and plusses (5–10%)
the smallest.

As we saw for mechanism one, discarding components
for two associated variables can have a big impact
on the presence of the corresponding edge in sampled
models. For strongly associated variables the impact
is less pronounced. We created another incomplete
data set using mechanism two in ﬁgure 3. For the
associated variables C, E and A the mechanism only
discards components that we think will not severely
impact these associations. For the strong association
E −D discarding components on both should not mat-
ter. We expect that we are able to remove a substan-
tial fraction of components and still obtain reasonable
models. We selected the fraction of missing compo-
nents in the interval 20–30%. In the last row in ﬁgure
2 we see that although a substantial fraction of compo-
nents were deleted, the models learned are quite simi-
lar to the models from the complete set.

307To illustrate that it is not the fraction of missing
components that determines the variance but rather
the fraction of missing information (Little and Rubin,
1987), we plotted the cumulative frequency in ﬁgure 4.
The variance of the posterior distribution is similar to
the variance of the posterior for mechanism one with
5–10% missing components. This means that although
the fraction of missing components is much higher than
5–10%, the uncertainty due to missing data has not
changed substantially.

7 Conclusion

We have presented eMC4 for simulating draws from
the posterior distribution of BN models given in-
complete data.
In contrast to existing methods for
learning with incomplete data, we take
BN model
a Bayesian approach and approximate the posterior
model distribution given the observed data. Diﬀer-
ent imputation methods may be used, and speciﬁcally
we describe a method that does not require exact in-
ference in a BN. By using importance sampling we
give all multivariate realizations of the Markov chain
a ‘chance’ of being selected rather than just returning
the last realization as in traditional Gibbs sampling.
Importance sampling makes it possible to exploit qual-
iﬁed, yet not perfect imputation proposals. From a
computational point of view specifying an approximate
distribution is cheaper than a perfect one.

Valuable insight is gained when sampling models from
the posterior; an illustration of the kind of information
one can derive from posterior realizations is given in
section 6. A posterior distribution is more informative
than just a single model. This is especially true in
the case of incomplete data, since the increased uncer-
tainty due to missing data is reﬂected in the probabil-
ity distribution.

References

N. Angelopoulos and J. Cussens. Markov chain Monte
Carlo using trees-based priors on model structure. In
J. Breese and D. Koller, editors, Proc. of the Conf.
on Uncertainty in AI, pages 16–23, 2001.

D. Chickering. A transformational characterization of
equivalent Bayesian networks.
In P. Besnard and
S. Hanks, editors, Proc. of the Conf. on Uncertainty
in AI, pages 87–98, 1995.

G. Cooper and E. Herskovits. A Bayesian method for
the induction of probabilistic networks from data.
Machine Learning, 9(4):309–347, 1992.

A. P. Dempster, N. M. Laird, and D. B. Rubin. Max-
imum likelihood from incomplete data via the EM

algorithm. J. of the Royal Statistical Society, Series
B, 34:1–38, 1977.

D. Edwards and T. Havr´anek. A fast procedure for
model search in multidimensional contingency ta-
bles. Biometrika, 72(2):339–351, 1985.

N. Friedman. The Bayesian structural EM algorithm.
In G. F. Cooper and S. Moral, editors, Proc. of the
Conf. on Uncertainty in AI, pages 129–138, 1998.

S. Geman and D. Geman. Stochastic relaxation, Gibbs
distributions, and the Bayesian restoration of im-
ages. IEEE Trans. on Pattern Analysis and Machine
Intelligence, 6(6), 1984.

P. Giudici and R. Castelo. Improving Markov chain
Monte Carlo model search for data mining. Machine
Learning, 50(1):127–158, 2003.

P. Giudici and P. Green. Decomposable graphical
gaussian model determination. Biometrika, 86(4):
785–801, 1999.

T. Kocka and R. Castelo.

Improved learning of
Bayesian networks. In D. Koller and J. Breese, edi-
tors, Proc. of the Conf. on Uncertainty in AI, pages
269–276, 2001.

S. L. Lauritzen. The EM algorithm for graphical as-
sociation models with missing data. Computational
Statistics and Data Analysis, 19:191–201, 1995.

R. J. Little and D. B. Rubin. Statistical Analysis with

Missing Data. Wiley and Sons, 1987.

D. Madigan and J. York. Bayesian graphical models
for discrete data. Intl. Statistical Review, 63:215–
232, 1995.

G. J. McLachlan and T. Krishnan. The EM Algorithm

and Extensions. Wiley, 1997.

M. Ramoni and P. Sebastiani. Learning Bayesian net-
works from incomplete databases. In D. Geiger and
P. Shenoy, editors, Proc. of the Conf. on Uncertainty
in AI, pages 401–408, 1997.

M. Ramoni and P. Sebastiani. Robust learning with
missing data. Machine Learning, 45(2):147–170,
2001.

D. J. Spiegelhalter and S. L. Lauritzen. Sequential
updating of conditional probabilities on directed
graphical structures. Networks, 20:579–605, 1990.

M. Tanner and W. Wong. The calculation of posterior
distributions by data augmentation. J. of the Am.
Stat. Assoc., 82(398):528–540, 1987.

308On the Behavior of MDL Denoising

Teemu Roos
Helsinki Institute for Information Technology

Petri Myllym¨aki

Henry Tirri

Nokia Research Center

Univ. of Helsinki & Helsinki Univ. of Technology

P.O. Box 407 Nokia Group

P.O. Box 9800 FIN-02015 TKK, Finland

FIN-00045, Finland

Abstract

We consider wavelet denoising based on min-
imum description length (MDL) principle.
The derivation of an MDL denoising criterion
proposed by Rissanen involves a renormaliza-
tion whose eﬀect on the resulting method has
not been well understood so far. By inspect-
ing the behavior of the method we obtain a
characterization of its domain of applicabil-
ity: good performance in the low variance
regime but over-ﬁtting in the high variance
regime. We also describe unexpected behav-
ior in the theoretical situation where the ob-
served signal is pure noise. An interpreta-
tion for the renormalization is given which
explains both the empirical and theoretical
ﬁndings. For practitioners we point out two
technical pitfalls and ways to avoid them.
Further, we give guidelines for constructing
improved MDL denoising methods.

1 INTRODUCTION

Most natural signals such as audio and images are typ-
ically redundant in that the neighboring time-slots or
pixels are highly correlated. Wavelet representations
of such signals are very sparse, meaning that most of
the wavelet coeﬃcients are very small and the informa-
tion content is concentrated on only a small fraction of
the coeﬃcients (Mallat, 1989). This can be exploited
in data compression, pattern recognition, and denois-
ing, i.e., separating the informative part of a signal
from noise.
In statistics the denoising problem has
been analyzed in terms of statistical risk, i.e., the ex-

pected distortion under an assumed model where typ-
ically distortion is deﬁned as squared error and the
model consists of deterministic signal plus additive
Gaussian noise. Donoho & Johnstone (1994) prove
that certain thresholding methods are nearly minimax
optimal for a large class of signals. In the Bayesian ap-
proach a prior distribution is postulated for the signal
and the expected (Bayes) risk is minimized (Ruggeri
& Vidakovic, 1999). Both approaches require that pa-
rameters such as noise variance are known beforehand
or determined as a part of the process.

The minimum description length (MDL) philosophy
oﬀers an alternative view where the noise is deﬁned as
the incompressible part of the signal (Rissanen, 2000).
We analyze Rissanen’s MDL denoising method and
characterize its domain of applicability. We show that
the method performs well in the low variance regime
but fails in the high variance regime when compared to
a thresholding method proposed by Donoho and John-
stone. In particular, in the theoretical situation where
the noise completely dominates the signal, the MDL
denoising method retains a majority of the wavelet co-
eﬃcients even though in this case discarding all coef-
ﬁcients is the optimal solution in terms of both statis-
tical risk and what we intuitively understand as sepa-
rating information from noise.

We explain the behavior of the MDL method by show-
ing that it results not from the MDL principle itself but
from a renormalization technique used in deriving the
method. We also point out two technical pitfalls in
the implementation of MDL denoising that practition-
ers should keep in mind. Further, we give guidelines
for constructing MDL denoising methods that have a
wider domain of applicability than the current one and
list objectives for future research in this direction.

3092 MDL PRINCIPLE

We start by introducing some notation and brieﬂy re-
viewing some of the relevant parts of MDL theory.
A recent introduction to MDL is given by Gr¨unwald
(2005), see also Barron et al. (1998).

2.1 STOCHASTIC COMPLEXITY

Let yn be a sequence of observations. We deﬁne a
model class as a set of densities {f (yn ; θ) : θ} indexed
by a ﬁnite-dimensional parameter vector θ. The max-
imum likelihood estimator of the parameter vector is
denoted by ˆθ(yn). The normalized maximum likeli-
hood (NML) density for a model class parameterized
by parameter vector θ is deﬁned by

¯f (yn) =

f (yn ; ˆθ(yn))

C n

,

where C n is a normalizing constant:

C n = ZY

f (yn ; ˆθ(yn)) dyn.

(1)

(2)

Implicit in the notation is the range of integration Y
within which the data yn is restricted. A range other
than the full domain of yn is necessary in cases where
the integral is otherwise unbounded.

The diﬀerence between the ideal code-length (negative
logarithm) of the NML density and the unachievable
maximum likelihood code-length is given by the re-
gret which is easily seen to be constant for all data
sequences yn:

− ln ¯f (yn) − [− ln f (yn ; ˆθ(yn))] = ln C n.

The NML density is
Shtarkov’s minimax problem (Shtarkov, 1987):

the unique minimizer

in

min

q

yn − ln q(yn) − [− ln f (yn ; ˆθ(yn))] = ln C n,
max

and the following more general problem:

min

q

p

max

Ep − ln q(yn) − [− ln f (yn ; ˆθ(yn))] = ln C n,
where the expectation over yn is taken with respect
to the worst-case data generating density p. For any
density q other than the NML density, the maximum
(expected) regret is greater than ln C n. Further, the
NML is also the least favorable distribution in that is
the unique maximizer of the maximin problem with

the order of the min and max operators in the lat-
ter problem above exchanged. For these reasons the
NML code is said to be universal in that it gives the
shortest description of the data achievable with a given
model class, deserving to be deﬁned as the stochastic
complexity of the data for the model class. The MDL
principle advocates the choice of the model class for
which stochastic complexity is minimized.

2.2 PARAMETRIC COMPLEXITY

It is instructive to view NML as seeking a balance be-
tween ﬁt versus complexity. The numerator measures
how well the best model in the model class can rep-
resent the observed data while the denominator ‘pe-
nalizes’ too complex model classes. The logarithm
of the denominator, ln C n, is termed parametric com-
plexity of the model class. Currently one of the most
active areas of research within the MDL framework
is the problem of unbounded parametric complexity
which makes it impossible to deﬁne the NML density
for models such as geometric, Poisson, and Gaussian
families, see (Gr¨unwald, 2005).

For model classes with unbounded parametric com-
plexity, Rissanen (1996) proposes to use a two-part
scheme where the range of the data is ﬁrst encoded
using a code based on an universal code for integers
after which the data is encoded using NML taking ad-
vantage of the restricted range. Foster & Stine (2001,
2005) analyze similar schemes where the range of the
parameters is restricted instead that of the the data.
A weakness in such solutions is that they typically re-
sult in two-part codes that are not complete, i.e., the
corresponding density integrates to less than one.

Rissanen (2000) describes an elegant renormalization
scheme where the hyperparameters deﬁning the range
of the data are optimized and a second normalization
is performed such that the resulting code is complete.
This ‘renormalized’ NML can be used for model se-
lection in linear regression and denoising. We discuss
the renormalization and the resulting MDL denoising
criterion more thoroughly in Sec. 4.

3 WAVELET DENOISING

Wavelet denoising can be seen as a special case of lin-
ear regression with regressor selection. For a good
textbook on wavelets, see (Daubechies, 1992). An ex-

310tensive review of statistical uses of wavelets is given
by Abramovich et al. (2000).

corresponding maximum likelihood parameters in the
full model and one gets the parameter vector

3.1 WAVELET REGRESSION

This section closely follows Rissanen (2000). Let X
be an n× k matrix of regressor variables (independent
variables), and yn be a vector of n regression variables
(dependent variables).
In a linear regression model
the regression variables are dependent on the regressor
variables and a k × 1 parameter vector β through the
equation yn = Xβ + n, where n is a vector of n noise
terms that are modeled as independent Gaussian with
zero mean and variance σ2. This is equivalent to the
equation

√2πσ¶n

2σ2

expµ−kyn − Xβk2

¶ , (3)
f (yn ; β, σ) = µ 1
where k·k2 denotes the squared Euclidean norm. The
regressor matrix X is considered ﬁxed and given in all
of the following and therefore omitted in the notation.
We deﬁne the matrices Z = X 0X and Σ = n−1Z which
are assumed to be positive deﬁnite in order to guaran-
tee uniqueness of maximum likelihood estimates. The
maximum likelihood estimators of β and σ2 are inde-
pendent and given by

ˆβ(yn) = Z −1X 0yn,

ˆσ2(yn) =

1
nkyn − X ˆβ0(yn)k2.

(4)

(5)

Now, assume the vector yn can be considered a se-
ries, i.e., the data points are ordered in a meaningful
way. We can then obtain a regressor matrix X by var-
ious transformations of the index i of the yi variables.
Thus, we deﬁne for each j ≤ k, Xi,j = fj(i), where fj
are arbitrary basis functions. One both theoretically
and practically appealing way to deﬁne the functions
fj is to use a wavelet basis, see e.g., Daubechies (1992).
By letting the regressor matrix be square, i.e., k = n,
and taking as the basis functions fj(i) an appropriate
wavelet basis, we get an orthogonal regressor matrix
X, i.e., X has as its inverse the transpose X 0 and we
have Z = X −1X = I, where I is the identity matrix.

Instead of using all the basis vectors, we may also
choose a subset γ of them. This gives the recon-
γ = X ˆβγ(yn), and the diﬀerence to
structed version ˆyn
the original signal is left to be modeled as noise. Since
the basis is orthogonal, the maximum likelihood val-
ues of any subset of all the parameters are equal to the

ˆβγ(yn) = (δi(γ) ˆβi(yn))0,

where δi(γ) is equal to one if the index i is in the index
set γ of retained coeﬃcients and zero otherwise. The
maximum likelihood estimator of the noise variance
becomes

γ(yn) =
ˆσ2

=

1
nkX ˆβ0(yn) − X ˆβ0
1
nk ˆβ(yn) − ˆβγ(yn)k2,

γ(yn)k2

which is seen to be the sum of the discarded coeﬃ-
cients divided by n. We denote for convenience the
squared norm of the maximum likelihood coeﬃcient
vector corresponding to γ by Sγ:

Sγ = k ˆβγ(yn)k2 = Xi∈γ

β2
i .

The squared norm of the coeﬃcient in the full model
with k = n is denoted simply by S. From orthogonal-
ity it follows that S is equal to the squared norm of
the data kynk2.

3.2 THE DENOISING PROBLEM

The denoising problem is now to choose a subset γ
such that the retained coeﬃcients would give a good
reconstruction of the informative part of the signal
while the discarded coeﬃcients would contain as much
of the noise in the signal as possible, The sparseness
of wavelet representations, i.e., the fact that a large
fraction of the coeﬃcients are essentially zero in the
‘noise-free’ or informative part of the signal (see (Mal-
lat, 1989)) makes it plausible to recover the informa-
tive part by identifying and discarding the coeﬃcients
that are likely to contain pure noise.

(1991).

The idea of wavelet thresholding was proposed soon af-
ter Mallat’s paper independently by Donoho & John-
stone (1991) and Weaver et al.
In wavelet
thresholding a threshold value is ﬁrst determined and
the coeﬃcients whose absolute value is less than the
threshold are discarded. Using the maximum likeli-
hood estimates as the values of the retained coeﬃcients
is called hard thresholding while in soft thresholding
the retained coeﬃcients are also shrunk towards zero
in order to reduce the noise distorting the informative
coeﬃcients.

311In statistical wavelet denoising the denoising problem
is often formalized using the concept of statistical risk,
i.e., the expected distortion (usually squared error) of
the reconstructed signal when compared to a true sig-
nal. This requires an assumed model typically involv-
ing i.i.d. noise added to a true signal. In the statis-
tical approach the signal is considered deterministic
and the worst-case risk over a class of signals is mini-
mized while in the Bayesian approach (see, e.g., (Rug-
geri & Vidakovic, 1999; Chang et al. , 2000)) a prior
distribution on the true signal is postulated and the
expected (Bayes) risk is minimized. Donoho & John-
stone (1994) have derived a set of wavelet denoising
methods including the following hard threshold:

tDJ = σp2 log n,

(6)

where σ is the standard deviation of noise.

In order to apply the method in practice, one usu-
ally needs to estimate σ. Donoho & Johnstone sug-
gest using as an estimator the median of the coeﬃ-
cients on the ﬁnest level divided by .6745 which usu-
ally works well as long as the signal is contained mainly
in the low frequency coeﬃcients. There are also sev-
eral other, more reﬁned denoising methods suggested
by the mentioned authors and others but due to space
limitations and the fact that our real focus is in under-
standing the behavior of MDL based denoising, these
methods are not discussed in the current paper. Fodor
& Kamath (2003) present an empirical comparison
of diﬀerent wavelet denoising methods; see also Oja-
nen et al.
(2004) for a comparison of the Donoho-
Johnstone method and MDL denoising.

4 MDL DENOISING

The MDL principle oﬀers a diﬀerent approach to de-
noising where the objective is to separate information
and noise in the observed signal. Unlike in the statisti-
cal approach, information and noise are deﬁned as the
compressible and the incompressible part of the signal
respectively, thus depending on the model class used
for describing the signal.

4.1 MDL APPROACH TO DENOISING

One of the most characteristic features of the MDL ap-
proach to statistical modeling is that there is no need
to assume a hypothetical generating model whose ex-

istence would be very hard to verify. Any background
information regarding the phenomenon under study is
incorporated in the choice of the model class. The only
assumption is that at least one of the model classes un-
der consideration allows compression of the data which
is clearly much easier to accept than the assumption
that the assumed model is indeed an exact replica of
the true generating mechanism.

In denoising, MDL model selection is performed by
considering each subset of the coeﬃcients as a model
class and minimizing the stochastic complexity of the
data given the model class. Unfortunately, for wavelet
based models and more generally, for linear regres-
sion models, the normalizer in the NML density is un-
bounded and NML is not deﬁned unless the range of
the data is restricted. The problem can be solved by
resorting to universal models other than NML, such as
two-part or mixture models in deﬁning the stochastic
complexity. Hansen & Yu (2000) propose a combina-
tion of two-part and mixture codes for wavelet denois-
ing. Their method also includes an estimation step
similar to the one used by Donoho & Johnstone, and
is thus not completely faithful to the MDL philosophy.

4.2 RENORMALIZED NML

Rissanen (2000) solves the problem of unbounded
parametric complexity by two-fold normalization. The
data range is ﬁrst restricted such that the squared (Eu-
clidean) norm of the maximum likelihood values of the
wavelet coeﬃcients k ˆβγ(yn)k2 is always less than some
maximal value R and the maximum likelihood vari-
γ(yn) is greater than some minimal value σ2
ance ˆσ2
0.
We then obtain an NML density with limited support
for each pair (R, σ2
0). It is now possible to construct
a ‘renormalized’ or ‘meta’ NML density by taking the
obtained NML densities as a new model class1.

After the application of Stirling’s approximation to
gamma functions and ignoring constant terms it can be
shown that the code-length to be minimized becomes2

(n − k)

2

ln

S − Sγ
n − k

+

k
2

ln

Sγ
k

+

1
2

ln(k(n − k)).

(7)

1In fact even the renormalization requires the data
range to be restricted but it turns out that the ﬁnal range
doesn’t aﬀect the resulting criterion.

2Multiplying the code-length formula by two gives an
equivalent minimization problem. Note the last term that
was incorrect in some of the earlier publications.

312It can be shown that the criterion is always maximized
by choosing γ such that either the k largest or the k
smallest coeﬃcients are retained for some k. We con-
sider this an artefact of the renormalization performed
and assume in the what follows that the k largest coef-
ﬁcients are retained. We return to the issue in Sec. 5.3.

4.3 PRACTICAL ISSUES

We point out two issues of a rather technical nature
that nevertheless deserve to be noted by practitioners
since we have found them to result in very poor per-
formance in more than one case. First, in all wavelet
thresholding methods, it should be made sure that the
wavelet transform used is such that the coeﬃcients are
scaled properly, in other words, that the correspond-
ing basis is orthogonal. This is essential for all wavelet
thresholding methods. It is easy to check that the sum
of squares of the original data and the transformed co-
eﬃcients are always equal.

Secondly, since the criterion is derived for continuous
data and involves densities, problems may occur when
it is applied to low-precision or discrete, say integer,
data. If the data can be represented exactly by some
number k0 of coeﬃcients, the criterion becomes minus
inﬁnity for all k ≥ k0 because the ﬁrst term includes
a logarithm of zero. Also, for k almost as large as k0
the criterion takes a very small value and such a value
of k is often selected as the optimal one potentially re-
sulting in severe over-ﬁtting. This problem may either
be solved by using a lower bound for (S − Sγ)/(n − k)
corresponding to a lower bound on the variance. Al-
ternatively, once a sudden drop to minus inﬁnity in the
criterion is recognized it is possible to reject all values
of k that are near the point where the drop occurs.

5 BEHAVIOR OF MDL DENOISING

By inspecting the behavior of the MDL denoising cri-
terion as a function of noise variance, we are able to
give a rough characterization of its domain of applica-
bility. This makes way towards a more important goal,
the understanding of renormalized NML, and poten-
tial ways of generalizing and improving it.

5.1 EMPIRICAL OBSERVATIONS

Fig. 1 illustrates the behavior of the MDL denoising
method and the method by Donoho & Johnstone de-

σ = 10.0

σ = 47.5

y
s
i
o
n

e
n
o
t
s
n
h
o
J
-
o
h
o
n
o
D

L
D
M

Figure 1: Lena Denoised. Top left: Noisy image (σ =
10.0); middle left: Donoho-Johnstone (2.2 % retained,
std. error 8.1); bottom left: MDL (7.6 % retained, std. er-
ror 6.8); top right: Noisy image (σ = 47.5); middle right:
Donoho-Johnstone (0.3 % retained, std. error 17.3); bottom
right: MDL (46.9 % retained, std.error 44.9).

scribed in Sec. 3 with Daubechies N=4 wavelet basis.
The original image is distorted by Gaussian noise to
get a noisy signal. When there is little noise, the dif-
ference is small, MDL method performing better in
terms of standard error. However, when there is much
noise the methods produce very diﬀerent results. The
Donoho-Johnstone method retains only 0.3 percent of
the coeﬃcients while the MDL method retains 46.9
percent of them, the former giving a better result in
terms of standard error.

The eﬀect of the standard deviation of noise on the be-
havior of the two methods can be clearly seen in Fig. 2.
It can be seen that the MDL method outperforms the
Donoho-Johnstone method when the noise standard
deviation is less than 15. However, outside this range
the performance of the MDL method degrades linearly

313r
o
r
r
e
 
d
r
a
d
n
a
t
s

 30

 25

 20

 15

 10

 5

 0

MDL

D o n o h o - J o h n s t o n e

 0

 5

 10  15  20  25  30  35  40  45

noise standard deviation

Figure 2: Eﬀect of noise.

due to retaining too many coeﬃcients. The standard
error of the noise should be compared to the standard
deviation of the original signal which in this case was
46.6. Experiments with other natural images indicate
that the standard deviation of the signal determines
the scale but does not aﬀect the shape of the curves.
As a rough characterization of the domain of appli-
cability of the MDL method it can be said that the
noise standard deviation should be at most half of the
standard deviation of the signal.

5.2 THEORETICAL ANALYSIS

The degradation of performance of the MDL denoising
criterion is underlined when the noise variance is very
large. This can be demonstrated theoretically by con-
sidering what happens when the noise variance grows
without bound so that in the limit the signal is pure
Gaussian noise. Since the criterion is scale invariant we
may without loss of generality assume unit variance.
Essentially, we need to evaluate the asymptotics of Sk,
the squared sum of the k largest coeﬃcients in abso-
lute value. Let β2
in be the squared
coeﬃcients ordered in ascending order. We have

i2 ≤ ... ≤ β2

i1 ≤ β2

Sk =

n

Xj=n−k+1

β2

ij = Xβ2

i ≥t2

k

β2
i ,

where we assumed that the ﬁrst retained coeﬃcient
tk := βin−k+1 is unique. If we consider tk a ﬁxed pa-
rameter instead of a random variable, the terms in the
above sum are independent with expectation given by:

E[β2

i | βi ≥ tk] =

1

1 − Φ(tk) Z +∞

tk

2

x2e− x2
√2π

dx,

n=128

n=1024

k=78

 1

 32

 64
k

 96

 127

 1

 256

 512

k

k=625

 768

 1023

Figure 3: The renormalized NML denoising criterion with
pure Gaussian noise.

where the expectation is taken with respect to the
standard normal distribution whose distribution func-
tion is denoted by Φ. The integral is given by

Z x2e− x2
√2π

2

dx = −xe− x2
√2π

2

+ Φ(x),

and the expectation becomes

E[β2

i | βi ≥ tk] =

t2
k
2

tke−

√2π(1 − Φ(tk))

+ 1.

(8)

Now in order to contain a k/n fraction of Gaussian
random variates as n goes to inﬁnity, the limiting value
of the cut-point tk must be

lim
n→∞

tk = Φ−1µ1 −

k

2n¶ .

(Division of k by two comes from the fact that also
negative coeﬃcients with large absolute value are in-
cluded.) Plugging this into Eq. (8) in place of tk gives
the asymptotic behavior of the average Sk/k. Since
the expectation of all coeﬃcients under the unit vari-
ance Gaussian noise model is equal to one, the expec-
tation of (Sn − Sk)/(n − k), i.e., the expectation of
the n − k smallest squared coeﬃcients can be easily
obtained once the expectation of the k largest coeﬃ-
cients is known.

Fig. 3 shows the values of the renormalized NML de-
noising criterion with sample sizes n = 128 (on the
left), and n = 1024 (on the right), with 50 repetitions
in each case. Data is pure Gaussian noise with unit
variance. The theoretical minima for the two samples
sizes are k = 78 and k = 625 respectively. The asymp-
totic curve is plotted with a solid line. By evaluating
the criterion for large n it can be seen that the MDL
method tends to keep about 625/1024 ≈ 61 % of the
coeﬃcients. This is suboptimal in terms of both sta-
tistical risk and the natural meaning of information

314and noise in data. If all data is indeed pure noise the
method should indicate that there is no information in
the data at all.

5.3

INTERPRETATION

Let us now consider the interpretation of the renormal-
ized NML denoising criterion in order to understand
the above described behavior. The code-length func-
tion (7) is the negative logarithm of a corresponding
density of the following form (ignoring normalization
constants):

(S − Sγ)−(n−k)/2S−k/2

γ

= k ˆβγck−(n−k)k ˆβγk−k,

(9)

where γc denotes the complement of γ, i.e, the set of
n − k discarded coeﬃcients.
Incidentally, the form in Eq. (9) is equivalent to using
a zero-mean Gaussian density with optimized variance
for both the retained and the discarded coeﬃcients.
This can be seen as follows. Given a vector x of k
random variates, the maximal density achievable with
a zero-mean Gaussian density assuming the entries in
the vector are independent is given by

max

σ

(2πσ2)−k/2 expµ−kxk2

2σ2 ¶ = ¡2πek−1kxk2¢−k/2

(10)

which is seen to be proportional to kxk−k. Thus the
two factors in Eq. (9) correspond to maximized Gaus-
sian densities of the kind in (10). Fig. 4 gives an illus-
tration verifying that the threshold is at the intersec-
tion points of two Gaussian densities ﬁtted to the dis-
carded and the retained coeﬃcients respectively. The
latter density has very high variance because the em-
pirical distribution of the coeﬃcients has heavy tails.
The fact that both retained and discarded coeﬃcients
are encoded with a Gaussian density explains many
aspects of the behavior reported above.

It is quite easy to derive rough conditions on when
the criterion performs well. From orthogonality of the
wavelet transform it follows that each of the informa-
tive coeﬃcients is a sum of an information term and a
noise term. Assuming independent noise, the density
of the sum is given by the convolution of the densities
of the summands. For instance, if the original sig-
nal has Gaussian density, the convolution is Gaussian
as well with variance equal to the sum of the signal
variance σ2
N . As long as the

S and the noise variance σ2

 0.07
 0.06
 0.05
 0.04
 0.03
 0.02
 0.01
 0

discarded

retained

-50

-25

 0

 25

 50

Figure 4: Gaussian densities ﬁtted to noisy Lena (σ =
10.0). The empirical histogram is plotted with solid line.
Gaussian densities with variance adjusted for the discarded
(ˆσ = 6.0) and the retained (ˆσ = 153.7) coeﬃcients are
shown with dotted curves. Threshold is at ±15.4.

S + σ2

signal variance is large compared to the noise variance,
the variance of the informative coeﬃcients, σ2
N , is
signiﬁcantly larger than that of the noise coeﬃcients.
Consequently, the criterion based on Gaussian densi-
ties with diﬀerent variances is able to separate the in-
formative and non-informative coeﬃcients as long as
the noise variance is not too high.3
It is also easy
to understand that ﬁtting two Gaussian densities to a
single one gives nonsensical results which explains the
behavior in the pure noise scenario of Sec. 5.2.

It has been observed that wavelet coeﬃcients in nat-
ural
images tend to be well modeled by general-
ized Gaussian densities of the form K exp(−(|x|/α)β)
where K is a normalization constant (Mallat, 1989).
The typical values of β are near one which corresponds
to the Laplacian (double exponential) density. This
suggests that the density of the observed coeﬃcients
can be modeled by a convolution of the Laplace and
Gaussian densities. Ruggeri & Vidakovic (1999) con-
sider Bayes optimal hard thresholding in this model
when the scale parameters of both densities are known.
Chang et al.
(2000) estimate the scale parameters
from the observed signal. The construction of an NML
model based on Laplacian and generalized Gaussian
models with a proper treatment of the scale parame-
ters is an interesting future research topic.

3Similar reasoning also shows that while the criterion is
symmetric in the two sets of coeﬃcients, one should always
retain the k largest coeﬃcients instead of the k smallest
coeﬃcients.

3156 CONCLUSIONS

In its general form, the MDL principle form essentially
aims at separating meaningful information from noise,
and thus provides a very natural approach to denois-
ing as an alternative to the statistical and Bayesian
approaches. There are, however, some intricate issues
in applying MDL to the denoising problem related to
unbounded parametric complexity of Gaussian fami-
lies. We discussed a solution by Rissanen involving a
renormalization whose eﬀect has been unclear so far
and is of considerable interest not only in denoising
applications but in the MDL framework in general.

The reported empirical and theoretical ﬁndings sug-
gested a characterization of the domain of applica-
bility for Rissanen’s denoising method.
It was seen
that over-ﬁtting is likely in the high noise regime. For
practitioners, we pointed out two technical pitfalls and
ways to avoid them. We gave an interpretation of
the renormalization by showing that it results in a
code based on two Gaussian densities, one for the re-
tained wavelet coeﬃcients and one for the discarded
ones. Based on the interpretation we were able to ex-
plain both the empirical and the theoretical ﬁndings.
The interpretation also facilitates understanding of the
problem of unbounded parametric complexity in gen-
eral and suggests generalizations of the renormaliza-
tion procedure, potentially leading to improved MDL
methods for denoising as well as other applications.

Acknowledgments

We thank Jorma Rissanen, Peter Gr¨unwald, and Ur-
sula Gather for useful discussions. This work was
supported in part by the Academy of Finland un-
der projects Minos and Cepler, the Finnish Technol-
ogy Agency under project PMMA, and the IST Pro-
gramme of the European Community, under the PAS-
CAL Network of Excellence, IST-2002-506778. This
publication only reﬂects the authors’ views.

References

Abramovich, F., Bailey, T., & Sapatinas, T. 2000. Wavelet
analysis and its statistical applications. Journal of the
Royal Statistical Society, Series D, 49(1), 1–29.

Barron, A., Rissanen, J., & Yu, B. 1998. The minimum de-
scription length principle in coding and modeling. IEEE
Transactions on Information Theory, 44(6), 2743–2760.

Chang, G., Yu, B., & Vetterli, M. 2000. Adaptive wavelet
thresholding for image denoising and compression. IEEE
Transactions on Image Processing, 9(9), 1532–1546.

Daubechies, I. 1992. Ten Lectures on Wavelets. Society
for Industrial & Applied Mathematics (SIAM), Philadel-
phia, PA.

Donoho, D., & Johnstone, I. 1991. Minimax estimation via

wavelet shrinkage. Tech. rept., Stanford University.

Donoho, D., & Johnstone, I. 1994. Ideal spatial adaptation

via wavelet shrinkage. Biometrika, 81(3), 425–455.

Fodor, I.K., & Kamath, C. 2003. Denoising through
wavelet shrinkage: an empirical study. Journal of Elec-
tronic Imaging, 12(1), 151–160.

Foster, D.P., & Stine, R.A. 2001. The competitive com-
plexity ratio. Proceedings of the 2001 Conference on
Information Sciences and Systems, 1–6.

Foster, D.P., & Stine, R.A. 2005. The contribution of
parameters to stochastic complexity. To appear in:
Gr¨unwald, P., Myung, I.J., & Pitt, M. (eds), Advances
in Minimum Description Length: Theory and Applica-
tions, MIT Press, Cambridge, MA.

Gr¨unwald, P. 2005.

A Tutorial

introduction to the
minimum description length principle. To appear in:
Gr¨unwald, P., Myung, I.J., & Pitt, M. (eds), Advances
in Minimum Description Length: Theory and Applica-
tions, MIT Press, Cambridge, MA.

Hansen, M., & Yu, B. 2000. Wavelet thresholding via MDL
for natural images. IEEE Transactions on Information
Theory, 46(7), 1778–1788.

Mallat, S. 1989. A Theory for multiresolution signal de-
composition: the wavelet representation. IEEE Trans-
actions on Pattern Analysis and Machine Intelligence,
11(7), 674–693.

Ojanen, J., Miettinen, T., Heikkonen, J., & Rissanen, J.
2004. Robust denoising of electrophoresis and mass spec-
trometry signals with minimum description length prin-
ciple. FEBS Letters, 570(1–3), 107–113.

Rissanen, J. 1996. Fisher information and stochastic com-
IEEE Transactions on Information Theory,

plexity.
42(1), 40–47.

Rissanen, J. 2000. MDL denoising. IEEE Transactions on

Information Theory, 46(7), 2537–2543.

Ruggeri, F., & Vidakovic, B. 1999. A Bayesian decision
theoretic approach to the choice of thresholding param-
eter. Statistica Sinica, 9(1), 183–197.

Shtarkov, Yu M. 1987. Universal sequential coding of single
messages. Problems of Information Transmission, 23(3),
3–17.

Weaver, J.B., Yansun, X., Healy, D.M. Jr., & Cromwell,
L.D. 1991. Filtering noise from images with wavelet
transforms. Magnetic Resonance in Medicine, 21(2),
288–295.

316Focused Inference

R(cid:19)omer E. Rosalesy+ and Tommi S. Jaakkolay

yComputer Science and Arti(cid:12)cial Intelligence Lab., MIT. Cambridge, MA 02139

+Computer-Aided Diagnosis and Therapy, Siemens Medical Solutions. Malvern, PA 19355(cid:3)

Abstract

We develop a method similar to variable elim-
ination for computing approximate marginals
in graphical models. An underlying notion in
this method is that it is not always necessary
to compute marginals over all the variables in
the graph, but focus on a few variables of in-
terest. The Focused Inference (FI) algorithm
introduced reduces the original distribution
to a simpler one over the variables of interest.
This is done in an iterative manner where in
each step the operations are guided by (local)
optimality properties. We exemplify various
properties of the focused inference algorithm
and compare it with other methods. Numer-
ical simulation indicates that FI outperform
competing methods.

1

INTRODUCTION AND

RELATED WORK

Probabilistic models are useful in a wide variety of
(cid:12)elds. An e(cid:11)ective way to represent the structure
of a probability distribution is by means of a graph;
e.g., a graphical model, where variables and their de-
pendencies are associated to nodes and edges in the
graph. A crucial task in using such models is to com-
pute marginal distributions over single or groups of
random variables. This is referred to here as prob-
abilistic inference. However, the complexity of ex-
act inference scales exponentially with the tree-width
of the associated graphical model, and even (cid:12)nding
(cid:15)-approximations (i.e., within given error bounds) is
NP-hard [2]. Approximate methods can nevertheless
be indispensable in practice.

Approximate inference methods have relied on several
key ideas. For example, we can try to simplify the

(cid:3)Current address. This work was done while the (cid:12)rst author

was with MIT CSAIL

original model to the extent that it becomes tractable.
In some cases it is feasible to identify groups of nodes
that are nearly conditionally independent or con(cid:12)g-
urations that are highly improbable, and then mod-
ify the original graph appropriately to represent this
(cid:12)nding before running an exact algorithm (e.g., [9]).
Variational methods, on the other hand, typically look
for the best approximation within a restricted class
of distributions, for example, by minimizing the KL-
divergence D(qjjp) between the approximation q and
the original distribution p[7]. The quality of this ap-
proximation is tied to how expressive the restricted
class is. Other methods, such as Assumed Density
Filtering (ADF)[13](see also [14]), Expectation Prop-
agation (EP)[14] and sequential (cid:12)tting[5] de(cid:12)ne the
quality of approximation in terms of D(pjjq), preserv-
ing select statistics in the course of incorporating evi-
dence. Similarly, belief Propagation (BP)[16, 12] and
its generalizations[20, 19] seek locally (not globally)
consistent beliefs about the values of variables and
have been useful in various contexts.

Variational methods can generally provide a bound on
the likelihood but are typically symmetry breaking in
the sense that the optimized approximate marginals
are asymmetric in the absence of any evidence to this
e(cid:11)ect (cf. mode selection). Propagation algorithms
such as BP or EP avoid symmetry breaking due to
the di(cid:11)erent optimization criterion. They are exact
for trees, or hyper-trees in the case of generalized BP,
but, with the singular exception of [18], do not pro-
vide bounds, nor are necessarily guaranteed to con-
verge without additional assumptions.

The structure of the approximating distribution (e.g.,
[6, 14, 15]), the message propagation scheme (e.g.,
[19]), or the clusters in generalized BP can lead to im-
portant variability in accuracy; (cid:12)nding a good struc-
ture or clusters is an essential and still unresolved
problem.

In this paper we pay closer attention to the essential
operation for computing a subset of desired marginals,

317i.e., marginalizing out each of the remaining hidden
variables. The plain focused inference (FI) algorithm
is a simple iterative process that eliminates variables
step by step (or in parallel whenever possible) and
obtains an approximation of the select marginal dis-
tribution. We extend the the basic FI idea to a
distributed algorithm operating in a tree-like struc-
ture. Our method provides a formalism for performing
the necessary graph/distribution transformation oper-
ations to be exact on restricted graphs, and approx-
imate for others. While FI can be seen to generate
approximating distributions at each step, these distri-
butions do not have to be tractable.

2 DEFINITIONS - BACKGROUND

Let X = (X1; :::; XN ) be a random vector with Xi
taking values denoted xi, where xi 2 X . We let X
be the discrete space X = f0; 1; :::; M (cid:0) 1g; thus, X
takes values in the Cartesian product space X N . In
this paper we consider probability distributions p(x)
whose structure is represented by the undirected bi-
partite graph G = (fV; F g; E), with variable nodes V
such that X = fXiji 2 V g, factor nodes F , and edges
E (cid:18) f(i; (cid:11))ji 2 V; (cid:11) 2 F g. The factor graph [10] G
corresponds to the following family of distributions:

p(X = x) =

1
Zp Y

(cid:11)2F

 (cid:11)(x(cid:11)) Y

i2V

(cid:30)i(xi);

(1)

where   and (cid:30) are positive functions (potentials or fac-
tors), and X(cid:11) are all the random variables connected
to the factor node (cid:11); i.e., X(cid:11) = fXij(i; (cid:11)) 2 Eg. For
later convenience, we denote single node factors by
(cid:30). This graph representation is more explicit than
the standard undirected graphical model representa-
tion regarding the factorization of the probability dis-
tribution. In this paper we concentrate primarily on
the cases when p can be de(cid:12)ned by factor nodes with
degree at most two1. The neighborhood set of the vari-
able node i is de(cid:12)ned (cid:23)(i) = fjj(i; (cid:11)) 2 E; (j; (cid:11)) 2 Eg
(this includes the node i itself), while the neighbors
of the variable node i is the set (cid:23)(i)(cid:0) = (cid:23)(i) (cid:0) fig.
The factors associated to a variable node i are denoted
F (i), with F (i) = f(cid:11) 2 F j(i; (cid:11)) 2 Eg. Throughout
this paper, the short-hand p(x) will denote p(X = x).

3 FOCUSED INFERENCE

APPROXIMATION

Consider the basic marginalization operation. When
marginalizing the joint distribution p(x) with respect
to a single variable Xe, the fundamental computational

1Note this need not be the case for joint marginals of p

issues, for discrete representations, are the time com-
plexity of combining the relevant random variable con-
(cid:12)gurations and the space complexity of representing
the result. In general we have that with (cid:22)e = V (cid:0) feg,

X

xe

p(x) / h2(x(cid:22)e)X

xe

h1(x(cid:23)(e)) = h2(x(cid:22)e)f (x(cid:22)e):

(2)

Even if the graph corresponding to p is a tree, repre-
senting f (x(cid:22)e) without resorting to its functional form
may require O(M j(cid:23)(e)j(cid:0)1) space. Further computa-
tions (like marginalizing with respect to another vari-
able), referring to this result may also have exponential
time complexity.

This exact operation can been seen as a step in a
bucket elimination algorithm [3]. This is also the basic
operation that data structures like the clique-tree or
junction tree are designed to handle in exact inference
methods like variable elimination [17], and illustrates
why some elimination and induced triangulations are
much more e(cid:14)cient than others, even though all per-
form exact calculations.

There are instances when f turns out to accept simple
(e.g., product) decompositions. In this case it is possi-
ble to improve upon the above complexity bounds on
inference. However, it is not clear how to induce such
decompositions given a distribution p. The essence
of the focused inference algorithm explained in this
section lies in variable elimination and in generating a
succession of non-exact decompositions to compute op-
timal marginal approximations in the context of Eq. 2.
We will discuss an extension of the basic algorithm
later in the paper.

3.1 BASIC FI ALGORITHM

Let p(x) be the distribution of interest, with associated
factor graph G = (fV; F g; E), focused inference (FI) is
based on a new graph decomposition together with an
approximation that reduces the original distribution p
(and graph G) to a simpler one in an iterative manner,
with certain optimality properties at each step. We
can think of the essential process as focusing only on
a few target node(s) at a time, whose marginal distri-
butions (e.g., pairwise) are to be approximated. Each
iteration eliminates variable and factors, includes new
factors, and modi(cid:12)es the distribution appropriately to
keep the focused approximation accurate.

We start by formalizing FI for a single iteration and
when the target variables consist of a speci(cid:12)c pair of
nodes T , T (cid:26) V , and later generalize it to multiple
pairwise marginals.

The (cid:12)rst step of the iteration consists on choosing a
non-target node e 2 V (cid:0) T and rewriting the corre-

318sponding probability distribution as:

p(x) = ~p1(x(cid:23)(e))~p2(x(cid:22)e);

(3)

where the two new distributions are de(cid:12)ned according
to the following decomposition:

X1

Xe

12

1e

2e

X2

13

e3

X3

X2

24

e4

34

X1

1234

12

24

13

34

X3

X2

12

24

X1

14

13

34

X3

X4

(a)

X4

(b)

X4

(c)

~p1(x(cid:23)(e)) =

1

Z ~p1 Y

(cid:11)2F (e)

 (x(cid:11)) Y

i2(cid:23)(e)

(cid:30)i(xi)

(4)

~p2(x(cid:22)e) / Y

(cid:11) =2F (e)

 (x(cid:11)) Y

i =2(cid:23)(e)

(cid:30)i(xi):

(5)

Assuming each factor involves at most two variables,
~p1(x(cid:23)(e)) is always a tree-structured distribution and
thus computing exact marginals from ~p1 can be done
e(cid:14)ciently. ~p2(x(cid:22)e) remains generally intractable. The
decomposition is not unique (even up to constant)
since we are free to trade single node marginals be-
tween the components. Note that the decomposition
itself involves no approximations, only rewriting of the
original distribution.

(cid:23)(e)(cid:0) ) = Pxe

The exact node/edge removal operation (marginaliz-
~p1(x(cid:23)(e));
ing) consist on (cid:12)nding f (x
see Fig. 1(b). The above decomposition is helpful
since sensible approximations for the (cid:12)rst portion of
the full distribution (Eq. 4) are readily available. In
particular, in this paper we employ the speci(cid:12)c class
of approximations that optimize the KL-divergence
D(f (x
(cid:23)(e)(cid:0) ) and the ap-
proximating distribution q(x
(cid:23)(e)(cid:0) ) constrained to be a
tree-distribution. We denote this class of approximat-
ing distributions by Q.

(cid:23)(e)(cid:0) )) between f (x

(cid:23)(e)(cid:0) )jjq(x

Figure 1: One-step approximation by removal of Xe: (a)
original factor graph, (b) exact (marginalized) graph, and
(c) example FI approximation where appropriate factors
(in bold) have been created ( 14) and updated ( 12;  34)

where di denotes the degree of node i and GT =
(VT ; ET ) is a tree (q is in the family of distributions
Q). The optimal tree GT can be found e(cid:14)ciently.

In the third step of the algorithm we combine the pro-
jected approximation with the remaining variables to
get the approximation to marginalized p(x):

^p(x(cid:22)e) = q(x

(cid:23)(e)(cid:0) )~p2(x(cid:22)e):

(8)

This node/edge elimination and approximation iter-
ation is repeated until all but the focus set T is left
in the graph 2. The new distribution ^p(x(cid:22)e) is again
de(cid:12)ned in the form of Eq. 1. This involves rede(cid:12)ning
the previous potentials and incorporating new ones.
The following provides the resulting factor/potential
update equations 3. For each pair (i; j) 2 ET , poten-
tials can be modi(cid:12)ed or created:

 (cid:11)(x(cid:11))    (cid:11)(x(cid:11))

q(xi; xj)q(xi)(cid:0)(cid:26)i q(xj)(cid:0)(cid:26)j

 (cid:11)(x(cid:11))  

(cid:30)i(xi)(cid:30)j(xj)
q(xi; xj )q(xi)(cid:0)(cid:26)i q(xj)(cid:0)(cid:26)j

(cid:30)i(xi)(cid:30)j(xj)

(modify)

(9)

(create); (10)

In the second step of the FI iteration we solve:

q(x

(cid:23)(e)(cid:0) ) = arg min
q2Q

D(X

xe

~p1(x(cid:23)(e))jjq(x

(cid:23)(e)(cid:0) ):

(6)

This projection can be solved e(cid:14)ciently whenever Q
is restricted to trees.

This optimization is related to that used by ADF (and
thus EP); however in FI no (cid:12)xed, predetermined ref-
erence (e.g., tree-structured) distribution is set and at
each step the structure of the best local approximat-
ing distribution can be obtained dynamically. Also,
the projection operation may (automatically) intro-
duce factors that were not previously present. We are
not assuming a speci(cid:12)c choice of ADF terms. Also,
recall than in ADF the structure of the approximat-
ing distribution is predetermined (not found by ADF
itself).

One way to represent the solution to Eq. 6 is by the
following tree-structured factorization:

q(x(cid:23)(e)(cid:0) ) = Y

(i;j)2ET

q(xi; xj)= Y

i2VT

q(xi)di(cid:0)1;

(7)

where (cid:26)i = (di (cid:0) 1)=di and the potential is modi(cid:12)ed
whenever both (i; (cid:11)) and (j; (cid:11)) are in E (created other-
wise). The graphical operations for factor graph G are
variable node, factor, edge removal, and edge addition,
respectively:

V   V (cid:0) feg;

(i)
(iii) E   E (cid:0) f(e; (cid:11))j(cid:11) 2 F (e)g;
(iv) E   E [ f(i; (cid:11)); (j; (cid:11))j(i; j) 2 ET g

(ii) F   F (cid:0) F (e);

One iteration applied to a simple (cid:12)ve-variable factor
graph is shown in Fig. 1. The repetition of these steps
de(cid:12)nes an elimination ordering E = (e1; :::; eK) and
a series of approximating distributions fQkgk=1;:::;K
which characterize one focusing operation. While
these basic steps are (cid:12)xed, the global algorithm is more
(cid:13)exible; for example, in the choice of approximating
distributions, in the elimination ordering, etc. These
and other aspects will be further discussed next.

2Alternatively until a tractable substructure containing

the set T has been reached

3This is one succinct way to state the update equations
for multinomials, other equivalent forms can be also used.
This form does not require updating the potentials (cid:30)i

319y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
y
4 ALGORITHM ANALYSIS

Here we illustrate key properties of the algorithm and
provide additional details.

4.1 ALGORITHM COMPLEXITY AND

OPTIMALITY

Under the decomposition de(cid:12)ned in Eqs. 4-5, the min-
imization problem in Eq. 6 for a (cid:12)xed tree structure
has a known solution in O(M 3). The problem reduces
to (cid:12)nding the pairwise marginals of ~p1 along the tree
edges ET . Since ~p1 is always a tree (a star graph
centered at Xe) and each potential   is a function of
at most two random variables, any of these marginals
can be found in O(M 3). As for (cid:12)nding the best tree-
structured distribution family in Q, this result follows
directly from [1] applied to our decomposition.

Proposition 1 The focused inference algorithm of
Sec. 3 is exact for any decimatable distribution p (tree-
width two or, equivalently, when the maximal clique
size of the triangulated graph is three). Not all elimi-
nation orderings yield the exact result.

Proof The approximation is exact when all the steps
are exact. The steps are exact if each variable has at
most two neighbors when eliminated. Since the maxi-
mal clique size is three, this elimination constraint can
always be satis(cid:12)ed through some elimination ordering.

An analogous result may not hold for ADF (or EP)
with the same time complexity.

4.2 ELIMINATION ORDERING

For a graph G = (fV; F g; E) and for a set of nodes
F of interest, an elimination ordering is a sequence
of nodes E = (e1; ::::; eK) with ei 2 V (cid:0) F. In case
we measure the approximation accuracy in terms of
the KL-divergence, the focused inference method sug-
gests a seemingly natural elimination ordering E: at
each step, eliminate the (non-target) node that gives
the lowest KL divergence D(f (x(cid:23)(e)(cid:0) )jjq(x(cid:23)(e)(cid:0) )) be-
tween marginalized and approximating distribution at
each step. However, note that this gives a locally best
and, in general, not a globally best ordering. Finding
approximations to the best overall elimination order-
ing is a much harder problem due that the complexity
of the problem representation increases rapidly with
the number of elimination steps.

The focused inference algorithm is designed to con-
centrate on speci(cid:12)c marginals and thus, a particular
ordering is used to reduce the graph to those nodes
of interest. In the most general setting, the algorithm
has to be run again if other marginals are needed (or

partially run since common calculations or partial re-
sults could be handily stored). A reasonable question
is whether these marginals are consistent. The an-
swer is negative, in general. Speci(cid:12)cally, for a distri-
bution p(x) and two sets of focus (target) variables
fXa; Xbg and fXb; Xcg, the corresponding pairwise
and single marginals produced by the focused infer-
ence algorithm under di(cid:11)erent elimination orderings
E1 = (e11; :::; e1K1) and E2 = (e21; :::; e2K2) are con-
sistent (1)if p(x) is a decimatable distribution; since
the algorithm is exact, and (2)if the elimination or-
derings are the same except for the (cid:12)nal node: K1 =
K2 = N (cid:0) 2 and e1i = e2i for i < K; since after elim-
inating N (cid:0) 3 nodes, the remaining variables will be
Xa; Xb; Xc, and their joint distribution is decimatable.

If we do not require that the approximation be optimal
(at each step), the graph can be reduced to a tree very
quickly. Moreover, this can be done so that the pair-
wise distributions are tree consistent. However, clearly
this involves non-optimal (local) approximations.

4.3 CONSISTENCY OF SINGLE AND

PAIRWISE MARGINALS

Let us instead consider how to start from the poten-
tially inconsistent set of marginals found using the FI
algorithm and reach a consistent set of marginals. We
consider the following problem: given a set of pairwise
marginals found under di(cid:11)erent elimination orderings,
how can we obtain a set of consistent marginals with
respect to a tree graph GT 0 = (VT ; ET 0 ).

Our approach consist on using a maximum likelihood
criterion; speci(cid:12)cally, let M be the set of ordered pairs
(i; j) of marginals fq(xi; xj)g. Under this criterion, we
wish to solve the following optimization problem:

arg max
r2R

(cid:0) X

(i;j)2M

q(xi; xj ) log r(xi; xj);

(11)

for the set of distributions R with model structure
GT 0 . This problem is equivalent to the minimization
of Eq. 6, and thus can be solved in closed-form.

4.4 INCLUDING SINGLE NODE

POTENTIALS

The decomposition given by Eqs. 4- 5 is an instance
of a more general decomposition which generalizes the
way single node potentials are included as follows:

~p1(x(cid:23)(e)) / (cid:30)e(xe) Y

(cid:11)2F (e)

 (x(cid:11)) Y

i2(cid:23)(e)(cid:0)

(cid:30)i(xi)(cid:17)i

(12)

~p2(x(cid:22)e) / Y

(cid:11) =2F (e)

 (x(cid:11)) Y

i =2(cid:23)(e)

(cid:30)i(xi) Y

i2(cid:23)(e)(cid:0)

which subsumes the original one.

(cid:30)i(xi)(1(cid:0)(cid:17)i

(13)
;

)

320The extra degrees of freedom are given by the vari-
ables (cid:17) = f(cid:17)ig; i 2 (cid:23)(e)(cid:0), (cid:17)i 2 < (note that (cid:30)e(xe)
must be fully included during e’s elimination). This
extra (cid:13)exibility could be used to our advantage in
(cid:12)nding a better distribution when minimizing Eq. 6.
This is because single node potentials could be in-
cluded such as to obtain an approximating q distri-
bution giving smaller KL-divergence. However, one
must be cautious, since we can almost always de(cid:12)ne
(cid:17) to obtain an approximating distribution for which
the KL-divergence is almost zero. This can be done
by allowing almost all of p’s probability mass to fall in
appropriate variable states easily represented by dis-
tributions in Q. Yet, despite this momentary success,
the overall gain is not guaranteed to be larger since the
resulting ^p distribution might be di(cid:14)cult to approx-
imate in future steps. This may allow us to provide
more accurate overall approximations by appropriately
including the e(cid:11)ect of single node potentials. Taking
advantage of this generalization is an interesting prob-
lem that remain to be exploited.

4.5 FURTHER CONNECTIONS WITH

OTHER METHODS

As a way to further understand FI, we now discuss
other connections with related methods. Consider
a single inclusion of a pairwise term in ADF. The
marginals obtained by ADF for any (tractable) ap-
proximating distribution could also be obtained by FI.
This can be seen by noticing that FI can perform exact
marginalization in a cycle (like ADF) and the inclusion
of a pairwise term in ADF will at most generate a cy-
cle. It is signi(cid:12)cant that for this equivalence to hold,
FI needs to make locally suboptimal decisions and ig-
nore those edges not in the cycle, even if they can be
easily approximated during elimination. For simulta-
neous inclusion of multiple terms, ADF’s complexity
in general increases exponentially, FI’s complexity re-
mains as before, of course using an approximation.

Unlike ADF and EP, in FI there is no reference struc-
ture for the approximation made. Interestingly, inter-
mediate (joint) approximations built by FI may not be
tractable. Their structure can be chosen with locally
optimal guarantees. FI builds these approximations
dynamically, thus there are less choices to be made
by hand regarding the structure of the approximating
distribution. This is related to [5], in the sense that
di(cid:11)erent approximating structures are found at each
step; however, in [5] a (tractable) tree-structured joint
distribution is maintained at all times.

There exist certain resemblance between the FI algo-
rithm in Sec. 3.1 and the mini-buckets scheme [4] in
the sense that both methods repeatedly approximate
complex functions of multiple variables with products

In mini-buckets, the local ap-
of simpler functions.
proximations employ a non explicitly guided partition-
ing of variables to functions (a partitioning, to some
extent corresponds to the structure of a local approxi-
mating distribution in the FI method). In FI, contrary
to mini-buckets, the approximating distributions q, in-
cluding their structure, can be solved for, and are opti-
mal with respect to a de(cid:12)nite criterion, the appropriate
KL-divergence.

In mini-buckets the approximation relies on arithmetic
bounds on product of positive functions. In a criterion
derived from mini-buckets [11], this approximation is
given by the solution of a linear optimization problem
(thus more like FI). However, still the structure of the
approximating distribution is not part of the formula-
tion and also the optimization problem entails using
an exponential number of constraints.

5 DISTRIBUTED FOCUSED

INFERENCE

Let us say we are interested in the marginal distri-
bution for all of the variables Xi. In the worst case,
the basic FI algorithm needs to be re-run on the or-
der of N times to obtain all marginals of interest. Is
there a more e(cid:14)cient way to perform the necessary
computations? In this section we address the question
whether there exist a distributed (asynchronous) al-
gorithm equivalent or based on the same fundamental
ideas. For exact inference, there are distributed algo-
rithms to some extent related to variable elimination
(e.g., [17, 16, 12]). Asynchronous algorithms also ex-
ist for (cid:12)xed structure approximations (e.g., [13, 7, 14]).
However, note that in the FI approximation, the result
of eliminating one variable is not propagated symmet-
rically through the graph (neighbors), it depends on
the factorization chosen; the underlying factor graph is
dynamically modi(cid:12)ed, based on previous approxima-
tions to other parts of the graph; and di(cid:11)erent elimina-
tion orderings (optimal in some sense for a particular
focusing variable) are used for computing the di(cid:11)erent
marginals. Thus, it is not clear for example, what data
structure (cid:12)ts the underlying algorithm, what informa-
tion or quantities a node should transfer to another,
and if the overall algorithm allows for quantities to be
stored e(cid:14)ciently, e.g., locally.

It turns out that for a type of FI approximations, we
can build a distributed algorithm and answer these
questions.
In order to de(cid:12)ne the algorithm, a tree
structure similar to the clique-tree [12, 17] can be used
for the underlying computations. However, unlike the
above, in our case it is not necessary to (cid:12)nd the maxi-
mal cliques or use the concept of triangulation explic-
itly. This is important because (cid:12)nding maximal cliques

32114

47

X1

X4

X7

12

45

78

1

4

7

25

58

X2

X5

X8

23

56

89

2

5

8

36

69

X3

X6

X9

3

6

9

{6,8}
{6,8,9}
{6,9}
{9}

{2,4}
{1,2,4}
{1,2}
{1}

{6}

{}
{8}
{6,8}

{6,8}
{5,6,8}

{5,6,8}
{4,5,6,8}

{4,5,6}
{2,4,5,6}
{2,4,6}
{2,6}
{2,3,6}
{2,3}
{3}

{2,4}
{2}

{4,8,5}
{4,8}
{4,7,8}
{4,7}
{7}

{4,5,6}
{4,5}
{4}

{5,6}
{5}

Figure 2: Example factor graph and the tree induced by
the ordering E = (1; 3; 7; 9; 2; 4; 5; 6; 8)

Distributed Focused Inference Algorithm

1. Form OT and for each node A assign function:

~ A(xA) = Y

(cid:11)2F (A)

 (cid:11)(x(cid:11)) Y

i2A

(cid:30)i(xi);

(14)

F (A) : set of factors whose variables are in A

2. Pick any node in the tree as root node

3. Perform a bottom-up and top-down pass, send-
ing the following message between neighbor
nodes (random variable sets) A and B:

mB!A(xA) = }xBnA [ Y

C2(cid:23)(B)

mC!B(xB)
~ C\B(xC\B)

~ B(xB)]; (15)

is in NP-complete [8]. The following algorithm de(cid:12)nes
the necessary tree structure whose nodes, denoted Aj,
are subsets of the random variables in p:

where (cid:23) denotes neighborhood in the OT

4. Compute marginals for the nodes of interest:

Algorithm for building Order-induced Tree

Denote elimination ordering E = (e1; :::; en)

1. Assign a single variable to the initial tree nodes:

Aj = fXej g (j = 1; :::; N (cid:0) 1)

2. Iterate i = 1:::N

(a) Create new node C = Sj Aj for j s.t. Aj
(b) For each j found in (a)

does not have a parent and Xei 2 Aj

Let B = C (cid:0) Aj = fXblg and chain nodes:
(C) ! (CnfXb1g) ! ::: ! (CnB) ! (Aj)

(c) For all the (not eliminated) variables Xk

sharing a factor with Xei
i. Create new node C0 = C [ Xk and make

C0 a parent of C
ii. Rede(cid:12)ne C   C0

(d) Create new node C0 = C (cid:0) fXeig and make

C0 a parent of C

(e) Eliminate Xei

Since we do not need the concept of cliques, we simply
call it an Order-induced Tree (OT). Note that when
traversed bottom-up (to the root), this tree gives a
marginalization ordering that properly tracks the re-
sulting function arguments at the nodes in the order
given. As in the basic FI, the above steps resemble
bucket elimination [3].
In fact, at the graph level,
the OT algorithm performs the variable inclusion and
elimination operations in the same order as FI. An ex-
ample OT tree for a simple 3(cid:2)3 grid is shown in Fig. 2.
The distributed algorithm (shown next) uses the OT
as basic data structure for message passing.

p(xA) / Y

B2(cid:23)(A)

mB!A(xA)
~ B\A(xB\A)

~ A(xA)

(16)

(e.g., use the nodes A containing the single
variables of interest; some joint marginals can
be computed directly as well)

In the algorithm, the operator }, has a similar role
than the minimization in Eq. 6. In the case of FI we
have:

}xBnA[g]

4
= arg min
q2Q

D(

1
Zg X

xBnA

g(xB)jjq(xA));

(17)

which is the known projection operation in informa-
tion geometry (as before Q is the set of tree structure-
distributions). Since D is de(cid:12)ned on distributions, Zg
is the necessary normalization constant. We defer a
detailed analysis of the above algorithm and present
the basic results in the remaining of this section.

g(xB)

Theorem 2 The distributed algorithm computes the
exact marginals when the minimization operation is
4
=

replaced by exact summation, i.e., when }xBnA[g]
1
Zg PxBnA
Proof sketch It su(cid:14)ces to show that the new de(cid:12)ni-
tion of } is equivalent to solving for f in Eq. 2, and that
sequential application of step 3 with any root node is
equivalent to sequential application of Eq. 2 in a par-
ticular ordering.

From the above result, step 3 using Eq. 17 can be
seen as passing (approximate) distributions over vari-
ables in the target nodes.
Interestingly these distri-
butions may be intractable themselves. The basic FI

322y
y
y
y
y
y
y
y
y
y
y
y
f
f
f
f
f
f
f
f
f
100

10−2

10−4

10−6

10−8

l

)
e
a
c
s
 

g
o
l
(
 
r
o
r
r

E
e

 

t

l

u
o
s
b
A

10−10

0

0.35

Focused Inference

0.45

0.5

0.55

  attractive  < b  >  repulsive

100

10−2

10−4

10−6

10−8

l

)
e
a
c
s
 

g
o
l
(
 
r
o
r
r

E
e

 

t

l

u
o
s
b
A

0.65

1

(a)

10−10

0

0.35

Tree−Structured ADF

0.45

0.5

0.55

  attractive  < b  >  repulsive

100

10−2

10−4

10−6

10−8

l

)
e
a
c
s
 

g
o
l
(
 
r
o
r
r

E
e

 

t

l

u
o
s
b
A

0.65

1

(b)

10−10

0

0.35

Mean Field

Ha =0.09

Ha =0.29

Ha =0.47

Ha =0.72

Ha =0.97

0.65

1

(c)

0.45

  attractive  < b  >  repulsive

0.5

0.55

Figure 3: Numerical test results for grid networks with random single and pairwise potentials with various levels of
entropy bounds (H(cid:11),I(cid:12)). Note x-axis scale is given in terms of I(cid:12) and networks with maximally attractive and repulsive
potentials are at (cid:12) = 0 and (cid:12) = 1 respectively. Performance of: (a) FI, (b) ADF, and (c) MF

Absolute error (MF)−Absolute error(FI)

of node pairs are: maximum dependency is achieved
at (cid:12) = 0 (attractive) and (cid:12) = 1 (repulsive), and full
independency at (cid:12) = 1
2 .

Absolute error (T−ADF)−Absolute error(FI)

100

l

)
e
a
c
s
 

g
o
l
(
 

e
c
n
e
r
e

f
f
i

D

10−2

10−4

10−6

100

l

)
e
a
c
s
 

g
o
l
(
 

e
c
n
e
r
e

f
f
i

D

10−2

10−4

10−6

10−8

0

0.35

0.45

0.5

0.55

  attractive  < b  >  repulsive

0.65

1

10−8

0

0.35

0.45

0.5

  attractive  < b  >  repulsive

0.55

0.65

1

Figure 4: Absolute error di(cid:11)erences (see Fig. 3 for legend)

algorithm, focusing on a single marginal, is equiva-
lent to (1)choosing an OT with same ordering E and
(2)performing just one pass (to the root). However,
the marginals computed by running the basic FI algo-
rithm for multiple focusing sets are not necessarily the
same as those computed by the distributed algorithm.
This can be easily seen by observing that di(cid:11)erent ap-
proximations are made in each case. The distributed
algorithm is equivalent to multiple runs of FI where
every run respects the approximations induced by the
OT by means of its variable subsets and tree arrange-
ment. The approximation over the target variables
can vary in structure (i.e., we can still choose optimal
tree-structure distributions for message passing).

6 NUMERICAL EVALUATION

In order to test how FI performs for diverse types
of distributions, we constructed a number of bi-
nary 9 (cid:2) 9 grid networks by choosing its factors
 ij (xi; xj) = (cid:18)xixj according to di(cid:11)erent uniform pri-
ors. Speci(cid:12)cally, we use a hyper parameter (cid:12) to de-
(cid:12)ne the random variable b (cid:24) U( 1
2 ; 1 (cid:0) (cid:12)) and set
2 ; 1(cid:0)b
2 ; b
(cid:18) = ((cid:18)00; (cid:18)01; (cid:18)10; (cid:18)11) = ( b
2 ). When letting
0 < (cid:12) < 1
2 , attractive potentials with varying strength
are constructed. Similarly, by letting 1
2 < (cid:12) < 1 and
b (cid:24) U(1 (cid:0) (cid:12); 1
2 ) we de(cid:12)ne repulsive potentials. By
varying (cid:12) we control the (maximum allowed) mutual
information I(cid:12) describing how dependent the states

2 ; 1(cid:0)b

2 (cid:0) (cid:11); 1

2 + (cid:11)), for 0 < (cid:11) < 1

A second hyper parameter (cid:11) controls the distribution
of single node potentials. Let (cid:30)i(xi) = (cid:18)xi, we de-
(cid:12)ne a (cid:24) U( 1
2 and let
((cid:18)0; (cid:18)1) = (a; 1 (cid:0) a). Thus, (cid:11) controls the entropy in
the prior state of a single variable (associated to its
single node potential); when (cid:11) = 1
2 the minimum en-
tropy allowed, denoted H(cid:11), is 1 bit (full uncertainty),
and when (cid:11) = 0 it is 0 bits. In our experiments we
varied (cid:12) and (cid:11) to obtain probability distributions with
di(cid:11)erent properties regarding strength of dependences
and strength of value preference.

In all of the experiments, we used the basic FI algo-
rithm (no consistency was enforced). We chose the
node to be eliminated at each step simply by look-
ing at the number of neighbors of each node in the
intermediate graphs and picking those with less neigh-
bors (cid:12)rst, randomly when tied. For ADF, we chose the
structure of the approximating distribution by keeping
the most informative edges (maximizing the pairwise
mutual information) forming a spanning tree. This cri-
terion performed better than random edge selection.

Fig. 3(a) shows the accuracy of FI for probability
distributions sampled under di(cid:11)erent settings of the
hyper-parameters (cid:12) and (cid:11). Performance is measured
in terms of the average absolute di(cid:11)erence between ex-
act and approximate (single node) marginals. As ex-
pected the performance improves as the coupling be-
tween the nodes become weaker ((cid:12) ! 1
2 ) for all values
of (cid:11). We performed the same tests using ADF and the
variational Mean Field method. Fig. 3(b)(c) shows the
performance results from these methods. Like FI, ac-
curacy is higher at (cid:12) (cid:25) 1

2 for any (cid:11).

FI clearly outperforms ADF under all conditions
(Fig. 4-left). The ADF terms were the pairwise factors;
FI and ADF had equivalent computational complexity.

323Notably, the di(cid:11)erence in performance increased with
the strength of the dependences in the network and
also with the strength of the (cid:12)eld given by the single
node potentials. Focused inference also outperformed
Mean Field (MF) under all conditions (Fig. 4-right),
even in the case when the basic Mean Field assumption
is almost fully valid (when variables are almost inde-
pendent). As variable dependencies grew stronger, the
performance gap between FI and the competing meth-
ods became larger at increasing rates.

7 CONCLUSIONS

We introduced an approximate inference algorithm,
similar to variable elimination, that is based on tai-
loring the approximation to the subset of variables
of interest. We also developed a distributed message-
passing version of the algorithm, constructed around
a particular elimination ordering.

The basic decomposition step, followed by the projec-
tion, can be guaranteed to be optimal for decimatable
graphs and properly chosen elimination ordering. We
are not aware of similar results for ADF. In a more
general context, the advantage of the focused inference
algorithm lies primarily in the inclusion of dependen-
cies induced by marginalization but not represented in
the original graph. FI does not require setting a (cid:12)xed
reference distribution (e.g., a class of tractable approx-
imating distributions) for de(cid:12)ning the approximation.
The selection of dependencies to introduce is based
on optimizing the projection of each local marginal-
ization result down to a tree. The ability to maintain
such dependencies through approximate marginaliza-
tions may underlie the superior empirical results.

Acknowledgements

The authors gratefully acknowledge support from
DARPA IPTO program and British Aerospace Engi-
neering.

References

[1] C. Chow and C. Liu, Approximating discrete prob-
ability distributions with dependence trees, Trans.
Information Theory. 14 (1968).

[2] P. Dagum and M. Luby, Approximating proba-
bilistic inference in bayesian belief networks is
NP-hard, Arti(cid:12)cial Intelligence 60 (1993), no. 1,
141{153.

[3] R. Dechter, Bucket elimination: A unifying
framework for reasoning, Arti(cid:12)cial Intelligence
113 (1999), no. 1-2, 41{85.

[4] R. Dechter and I. Rish, Mini-buckets: A general
scheme for approximating inference, J. ACM 50
(2003), no. 2, 107{153.

[5] B. J. Frey, R. Patrascu, T. Jaakkola, and
J. Moran, Sequentially (cid:12)tting inclusive trees for
inference in noisy-or networks, Neural Info. Proc.
Systems, 2000.

[6] Z. Ghahramani and M. Jordan, Factorial hidden
markov models, Neural Info. Proc. Systems, 1997.
[7] M. Jordan, Z. Ghahramani, T.Jaakkola, and
L. Saul, An introduction to variational methods
for graphical models, Learning in Graphical Mod-
els, M. Jordan (ed.) (1998).

[8] R. M. Karp, Reducibility among combinatorial
problems, In R. E. Miller and J. W. Thatcher,
eds., Complexity of Computer Computations
(1972), 85{104.

[9] U. Kj(cid:26)rul(cid:11), Reduction of computational complex-
ity in Bayesian networks through removal of weak
dependencies, Proc. Uncert. in Artif. Intell., 1994.
[10] F. Kschischang and B. Frey, Iterative decoding
of compound codes by probability propagation in
graphical models, J. Sel. Areas in Comm. 16
(1998), 219{230.

[11] D. Larkin, Approximate decomposition: A method
for bounding and estimating probabilistic and de-
terministic queries, Proc. Uncert. in Artif. Intell.,
2003.

[12] S. L. Lauritzen and D. J. Spiegelhalter, Local
computations with probabilities on graphical struc-
tures and their application to expert systems, J.
Royal Stat. Society, B 50 (1988), no. 2, 157{223.
[13] P. Maybeck, Stochastic models estimation and

control, Academic Press, 1982.

[14] T. Minka, A family of algorithms for approximate

Bayesian inference, Ph.D. thesis, MIT, 2001.

[15] T. Minka and Y. Qi, Tree-structured approxi-
mations by expectation propagation, Neural Info.
Proc. Systems, 2003.

[16] J. Pearl, Probabilistic reasoning in intelligent sys-

tems, Morgan-Kaufman, 1988.

[17] G. Shafer and P. Shenoy, Probability propagation,

Ann. Math. Arti(cid:12)cial Intel. 2 (1990), 327{351.

[18] M. Wainwright, T. Jaakkola, and A. Willsky, A
new class of upper bounds on the log partition
function, Proc. Uncert. in Artif. Intell., 2002.

[19]

, Tree-based reparameterization framework
for analysis of sum-product and related algo-
rithms, Trans. Information Theory. 49-5 (2003).
[20] J. Yedidia, W. Freeman, and Y. Weiss, Gener-
alized belief propagation, Neural Info. Proc. Sys-
tems, 2000, pp. 689{695.

324Kernel Methods for Missing Variables

Alex J. Smola, S.V.N. Vishwanathan

Statistical Machine Learning Program
NICTA and ANU, Canberra, ACT, 0200

{Alex.Smola, SVN.Vishwanathan}@nicta.com.au

Thomas Hofmann

Department of Computer Science
Brown University, Providence, RI

th@cs.brown.edu

Abstract

We present methods for dealing with missing
variables in the context of Gaussian Processes
and Support Vector Machines. This solves an
important problem which has largely been ig-
nored by kernel methods: How to systemati-
cally deal with incomplete data? Our method
can also be applied to problems with partially
observed labels as well as to the transductive
setting where we view the labels as missing
data.
Our approach relies on casting kernel meth-
ods as an estimation problem in exponen-
tial families. Hence, estimation with miss-
ing variables becomes a problem of comput-
ing marginal distributions, and ﬁnding eﬃ-
cient optimization methods. To that extent
we propose an optimization scheme which ex-
tends the Concave Convex Procedure (CCP)
of Yuille and Rangarajan, and present a
simpliﬁed and intuitive proof of its conver-
gence. We show how our algorithm can be
specialized to various cases in order to eﬃ-
ciently solve the optimization problems that
arise. Encouraging preliminary experimen-
tal results on the USPS dataset are also pre-
sented.

1 Introduction

Kernel methods [12] have been remarkably success-
ful for standard classiﬁcation and regression problems.
However, they have also been found very eﬀective
in dealing with a variety of related learning prob-
lems such as sequence annotation, conditional ran-
dom ﬁelds, multi-instance learning, and novelty detec-
tion. Many algorithms for Gaussian Processes (GP)
and Support Vector Machines (SVM) bear witness of
this. One problem, however, has remained completely

untouched so far: How to deal with datasets which
exhibit missing variables?
In the following, we will develop a framework to deal
with such cases in a systematic fashion. Our analy-
sis is based on the observation that kernel methods
can be written as estimators in an exponential family.
More speciﬁcally, Gaussian Processes can be seen to be
minimizing the negative log-posterior under a normal
prior on the natural parameter of the exponential den-
sity, whereas Support Vector Machines maximize the
likelihood ratio. Based on this observation, we provide
a method for dealing with missing variables in such a
way that standard kernel methods arise as a special
case, whenever there are no missing variables.
To solve the optimization problems arising in this con-
text – a concave-convex objective function with both
convex and concave constraints – we extend the CCP
algorithm of [16] for ﬁnding local optima and give an
intuitive proof for its convergence.
The rest of the paper is organized as follows.
In
Section 2.1 we discuss exponential families in feature
space and in Sections 2.2 -2.4 we present methods to
deal with missing data. In Section 2.5 we show how
Gaussian Processes and Support Vector Machines can
be extended to deal with missing data. Section 3
is devoted to the discussion of the Constrained Con-
cave Convex Procedure (CCCP) and its application
to Gaussian Processes and Support Vector Machines.
We discuss some implementation tips in Section 4 and
present experimental results on the USPS dataset in
Section 5. An outlook and a discussion in Section 6
conclude the paper.

2 The Model for Incomplete Data

2.1 Exponential Families

We begin with a deﬁnition of exponential families: De-
note by X the domain of observations, and let φ(x)
with x ∈ X refer to a vector of suﬃcient statistics.

325Then, a member of the exponential family of densities
can be deﬁned in exponential normal form via
p(x; θ) = p0(x) exp (hφ(x), θi − g(θ)) ,

(1)

where

g(θ) = log

Z

X

p0(x) exp(hφ(x), θi) dx.

(2)

Here, p0(x) is a suitably chosen underlying measure,
θ is the natural parameter, g(θ) is the log-partition
function, often called the cumulant generating func-
tion, and h·,·i denotes a scalar product in an Eu-
clidean space, or more generally in a Reproducing Ker-
nel Hilbert Space (RKHS) H. Without loss of gener-
ality, and for ease of exposition, we will ignore the
underlying measure p0(x) for the rest of the paper.
Let Y denote the space of labels, and φ(x, y) be the
suﬃcient statistics of the joint distribution associated
with (x, y) ∈ X ×Y. For the purpose of classiﬁca-
tion we are mainly concerned with estimating condi-
tional probabilities. Therefore, we assume that given
the data, the labels are drawn from an exponential
family and, extend the exponential families framework
to conditional probabilities. Here we have

p(y|x; θ) = exp (hφ(x, y), θi − g(θ|x)) ,

(3)

(4)

and

g(θ|x) := log

Z

Y

exp(hφ(x, y), θi) dy.

In analogy to the above case, g(θ|x) is commonly re-
ferred to as the conditional log-partition function.
Both g(θ) and g(θ|x) are convex C∞ functions in θ
and they can be used to compute cumulants of the
distribution [6, 4], for instance:

∂θg(θ) = Ep(x;θ)[φ(x)],
θ g(θ) = Varp(x;θ)[φ(x)],
∂2
∂θg(θ|x) = Ep(x,y;θ)[φ(x, y)|x],
θ g(θ|x) = Varp(x,y;θ)[φ(x, y)|x].
∂2

2.2

Incomplete Training Data

In the following, we will deal with the problem of esti-
mating p(y|x; θ) or a related quantity based on a set of
observations (xi, yi) ∈ X ×Y with i = 1, . . . , m. More
speciﬁcally, we allow that some of the xi have been
observed only partially, that is, we may partition the
observations as xi = (xo
i represents the
i , xu
observed part and xu
is the unobserved part of the
i
data (see [3] for a detailed description of how miss-
ing data may arise and how it is typically treated in

i ), where xo

an Expectation Maximization (EM) context). Observe
that we allow for diﬀerent sets of missing variables for
diﬀerent data points.
The ﬁrst step is to extend (3) to partially observed
data. Clearly
p(xu, y|xo; θ) = exp (hφ(xo, xu, y), θi − g(θ|xo)) . (5)
Integration over the unobserved part of x, that is, xu,
and direct calculation yields
p(y|xo; θ) =

exp (hφ(xo, xu, y), θi − g(θ|xo)) dxu
(6)
with a suitable deﬁnition of g(θ|xo, y). In other words,
the conditional probability p(y|xo; θ) is now given by
the exponential of the diﬀerence of two conditional log-
partition functions. This poses two problems:

= exp(g(θ|xo, y) − g(θ|xo)) ,

Z

X u

• Computing the log-partition function is a non-
trivial problem [14].
In particular, the compu-
tation of g(θ|xo) and g(θ|xo, y) may pose addi-
tional diﬃculties. This is because the joint suﬃ-
cient statistics might lead to an intractable inte-
gral. However, in many real life applications the
data is discrete and only a small number of vari-
ables are missing. In these cases, one can either
resort to brute force computation or exploit the
algebraic structure of the integrand.

• The negative log-likelihood, − log(p(y|xo; θ)),
ceases to be a convex function. This means that
the optimization problems arising from estimation
with missing variables may involve many local op-
tima. In Section 3, we will present an optimiza-
tion method to deal with this problem by extend-
ing the CCP of [16] as well as a second method
based on the EM algorithm.

2.3

Incomplete Labels

Y u

Using ideas similar to those used for handling missing
training data we can also handle data with missing
labels. As before, we partition yi = (yo
i ) and inte-
grate out the unobserved part of the labels to yield
p(yo|x; θ) =

exp (hφ(x, yo, yu), θi − g(θ|x)) dyu

i , yu

Z

= exp(g(θ|x, yo) − g(θ|x)).

(7)
(7) can then be used to perform Maximum Likelihood
Estimation (MLE) or Maximum A Posteriori (MAP)
estimation. As before, the conditional probability
p(yo|x; θ) is given by the exponential of the diﬀerence
of two conditional log-partition functions. Note that
both types of missing data can also be combined in a
straightforward manner using the conditional density
p(yo|xo; θ).

3262.4 Transduction

Transduction can be viewed as an extreme case of in-
complete labels. Typically, we are given a set of ob-
servations with a few missing labels. The task is to
predict these missing labels. We now compute a prob-
ability distribution on the missing labels, given by
p(yu|x, yo; θ) = exp (hφ(x, yo, yu), θi − g(θ|x, yo)) .

In order to compute the above density we need to com-
pute

g(θ|x, yo) = log

exp(hφ(x, yo, yu), θi dyu.

(8)

Z

Y u

If the space of labels Y is large, and many labels are
missing, then computing the above integral is a non-
trivial task and we need to resort to Monte-Carlo sam-
pling methods or other similar high dimensional inte-
gration techniques in order to perform prediction.

2.5 Conditional Probabilities and Estimators

Our discussion so far has been very generic. In this
section, we focus on two particular kernel algorithms.
First, we show how Gaussian Processes can be viewed
as estimators in exponential families. Then, we dis-
cuss the well known Support Vector Machines in the
context of exponential families. Using our discussion
above, we also show how both these algorithms can
handle missing data in a natural way.

If the training
Gaussian Process Classiﬁcation:
data is assumed to be generated IID from an expo-
nential family distribution, the MLE problem for ex-
ponential families is to minimize

because θ is normally distributed with zero mean, and
Eθ[t(x, y)] = 0 and the covariance (kernel) matrix is
given by

k((x, y), (x0, y0)) = hφ(x, y), φ(x0, y0)i .

This argument is similar to the one used by [15] to es-
tablish a connection between Support Vector Machines
and Gaussian Processes.
As a special case we let Y = {±1} and con-
sider the choice φ(x, y) = yφ0(x). This gives us
k((x, y), (x0, y0)) = yiyj · k0(x, x0) where k0(x, x0) =
hφ0(x), φ0(x0)i.
Now using the normal prior, the MAP estimation
problem for exponential families is to minimize

−log p(θ|X, Y )=

=

− log p(yi|xi, θ)+

kθk2
2σ2
g(θ|xi)−hφ(xi, yi), θi +

(9)

kθk2
2σ2 .

mX
mX

i=1

i=1

Observe that
the MAP estimation problem (9)
is convex, and by the representer theorem [11],
the minimizer θ∗ can be found in the span of
{φ(xi, y) where y ∈ Y}. So far, this interpretation
of Gaussian Processes is consistent with the classical
viewpoint.
We now turn to the setting with incomplete input data
(the setting with missing labels is analogous and can
be handled similarly). Here, all we need to do is to
replace p(yi|xi, θ) by p(yi|xo
i , θ). Using (6) this leads
to the following problem:

− log p(yi|xi, θ)

minimize

[g(θ|xo

i ) − g(θ|xo

i , yi)] +

1
2σ2kθk2. (10)

mX

i=1

mX
mX

i=1

i=1

(cid:18)

− log p(θ|X, Y ) =

=

g(θ|xi) − hφ(xi, yi), θi .

Since we are considering an exponential family in fea-
ture space, the suﬃcient statistics are possibly inﬁnite
dimensional. To avoid over-ﬁtting the data we con-
sider a prior over the parameter θ.
One can show [1] that Gaussian Processes can be seen
as estimators, where the prior on the natural parame-
ter is normal, that is,

(cid:19)

.

p(θ) ∝ exp

− 1
2σ2kθk2

To see this, observe that under the above prior
t(x, y) := hφ(x, y), θi is a Gaussian Process. This is

Unlike (9), the above problem is no longer convex, and
we will need a more sophisticated method to solve it.
In Section 3 we show how the CCCP method can be
used to solve this optimization problem eﬃciently.
It is easy to check that g(θ|xo
i , yi), θi if
i = xi, that is, we recover the original Gaussian Pro-
xo
cess optimization problem whenever the set of obser-
vations is complete.

i , yi) = hφ(xo

Support Vector Classiﬁcation: Gaussian Pro-
cesses maximize the log-likelihood using a normal prior
on the parameters.
Instead of directly maximizing
the log-likelihood, one may want to maximize the log-
likelihood ratio between the correct label and the most
likely incorrect labeling [9]. This leads to the following

327cost function:

r(x, y; θ) := log

p(y|x; θ)

max˜y6=y p(˜y|x; θ)

= hφ(x, y), θi − max
˜y6=y

hφ(x, ˜y), θi .

(11)

(12)

In order to take the margin into account, we use

c(x, y; θ) := max(1 − r(xi, yi; θ), 0)

which is essentially a clipped version of r(x, y; θ).
To see the connection to binary Support Vector Ma-
chines, assume Y ∈ {±1} and φ(x, y) = y
2 φ0(x).
Then, r(x, y; θ) = yi hφ0(x), φ0(x0)i and c(x, y; θ) =
max(1 − yi hφ0(x), φ(x0)i , 0) which essentially recovers
the hinge loss. Therefore, our loss function is simply a
generalization of the hinge loss to multi-class Support
Vector Machines [9].
In fact, the MAP estimate in this case is found by
solving

argmin

θ

c(xi, yi; θ) +

1
2σ2kθk2.

(13)

To recover soft margin estimates, one simply needs to
introduce slack variables into the above equation.
The main diﬀerence between the Support Vector Ma-
chine and the Gaussian process optimization problem
is that, in the case of Support Vector Machines, the
cost function c(x, y; θ) does not depend on the log-
partition function. Instead, it is given by the diﬀerence
between scalar products.
An extension to missing variables is now straightfor-
ward: all we need to do is to replace the conditional
probability estimates in the fully observed case by their
counterparts for partially observed data. Using (6)
and (11) we have

r(x, y; θ) = g(θ|xo, y) − max
˜y6=y

g(θ|xo, ˜y).

Finally, we can introduce slack variables and extend
(13) into a constrained optimization problem for miss-
ing variables:

mX

i=1

minimize

1
2σ2kθk2 +

mX
ξi
i , yi) − max
˜y6=yi

i=1

s.t. g(θ|xo
ξi ≥ 0.

g(θ|xo

i , ˜y) ≥ 1 − ξi

(14a)

(14b)

(14c)

The diﬀerence between (14) and (13) is that now the
constraints, as speciﬁed by (14b), are non longer con-
vex. Therefore, the minimization is no longer a con-
vex problem, and we need, for instance, an iterative
scheme to enforce these constraints.

As before, if xo
have g(θ|xo
version of (13) which incorporates slack variables.

i = xi, that is, if no data is missing, we
i , yi), θi and (14) reduces to a

i , yi) = hφ(xo

3 Optimization

As stated in Section 2.5, the optimization problems
that arise when data is missing are no longer convex.
Hence, it is a non-trivial task to solve them. In the
case of Gaussian Processes one could invoke an EM
like algorithm to perform maximum likelihood estima-
m})
tion over the joint set of parameters (θ,{xu
directly. But, it is not clear how such an algorithm
can be extended to incorporate non-convex constraints
which arise in the case of Support Vector Machines
with missing variables.
Instead, we take a small detour: EM can also be
viewed as a consequence of the CCP [16]. This pro-
vides us with a strategy to use similar algorithms for
constrained problems by extending CCP to the Con-
strained CCP.

1 , . . . , xu

3.1 The Constrained Concave Convex

Procedure

Theorem 1 (Constrained CCP) Denote by fi, gj
real-valued convex and diﬀerentiable functions on a
vector space X for all i ∈ {0, . . . , n}, and let ci ∈ R
for i ∈ {1, . . . , n}. Then, Algorithm 1 converges to
a local minimum of the following optimization prob-
lem, provided that the linearization of the nonconvex
constraints in conjunction with the convex constraints
satisfy suitable constraint qualiﬁcations at the point of
convergence of the algorithm.

minimizef0(x) − g0(x)

(15a)
s.t. fi(x) − gi(x) ≤ ci for all 1 ≤ i ≤ n (15b)

In the following, we denote by Tn{f, x}(x0) the nth
order Taylor expansion of f at location x, that is,
T1{f, x}(x0) = f(x) + hx0 − x, ∂xf(x)i.

Algorithm 1 Constrained Concave Convex Procedure

Initialize x0 with a random value
repeat

ﬁnd xt+1 as the solution of the convex optimiza-
tion problem

minimizef0(x) − T1{g0, xt}(x)

s.t. fi(x) − T1{gi, xt}(x) ≤ ci ∀i

(16a)
(16b)

until convergence of xt

328fi(x) − T1{gi, xt}(x) ≥ fi(x) − gi(x).

Proof The key idea of the proof is that for any convex
function, the ﬁrst order Taylor expansion is a lower
bound, that is, gi(x) ≥ T1{gi, xt}(x) for all x, xt ∈ X .
Consequently for all x, xt ∈ X and 0 ≤ i ≤ n we have
(17)
By construction, equality holds at the point of expan-
sion x = xt. This means that for every xt, (16) is an
upper restriction of (15). In other words, every x fea-
sible in (16b) is also feasible in (15b). Moreover, the
objective function (16a) is an upper bound of (15a).
When x = xt, the values of (15) and (16) match. Con-
sequently, minimizing (16) leads to xt+1 with a lower
value of the objective function (15a). This is because
of two facts: Firstly, (16) presents an upper bound on
(15). Secondly, when replacing the expansion at xt by
the one at xt+1 again the objective function may only
decrease. To see this, observe that, by convexity we
have
f0(xt+1) − T1{g0, xt}(xt+1) ≥ f0(xt+1) − g0(xt+1),
but, by deﬁnition we have
f0(xt+1) − g0(xt+1) = f0(xt+1) − T1{g0, xt+1}(xt+1).
Next, we need to prove that if the xt converge, then we
actually arrived at a minimum or a saddlepoint of the
optimization problem. We show this by proving that
at stationarity a saddlepoint in the Lagrange function
corresponding to (15) is also a saddlepoint in the La-
grange function corresponding to (16) with the same
set of dual variables.
Now, assume that the above algorithm converges to x∗
and let α∗ be the dual variables of (16). By stationar-
ity, the convex restriction at x∗ satisﬁes the constraint
qualiﬁcations and the Lagrange function of (16) has a
saddle point in x∗, α∗.
However, by construction, the linearization is tight at
x∗, so α∗ also satisﬁes the Kuhn-Tucker conditions for
(15a) and the derivatives of the Lagrangian of (15a)
match those of their counterpart from (16a) at x∗. So
we showed that if the convex restriction has a saddle
point in the Lagrangian, so does the original problem.

This gives us a simple procedure to perform optimiza-
tion even in a constrained nonconvex problem: simply
linearize the constraints at every step and solve the
resulting convex problem.

Remark 2 (CCP) The CCP is a special case of the-
orem 1, where there are no constraints. In this case the
ﬁrst order conditions for the solution of (16a) amount
to ∂θf0(θ) − ∂θg0(θt) = 0. This is exactly what [16]
propose.

3.2 Application to GP Classiﬁcation

Recall that for Gaussian Process classiﬁcation with
missing variables the MAP-estimation problem (10)
becomes that of solving

[g(θ|xo

i ) − g(θ|xo

i , yi)] +

1
2σ2kθk2.

mX

minimize

i=1

We deﬁne

∂θg(θ|xo) = Ep(x,y;θ)[φ(x, y)|xo; θ] := E(θ, x, y),

and
∂θg(θ|xo, y) = Ep(x,y;θ)[φ(x, y)|xo, y; θ] := F (θ, x, y).

Using the above, and the ﬁrst-order optimality condi-
tions of Remark 2, the Gaussian Process optimization
problem can now be expressed as:
E(θ, xi, y) − F (θt, xi, yi) +

X

(18)

1
σ2 θ = 0.

i

Note that while the ﬁrst expectation depends on θ, the
second one is taken for a ﬁxed value θt, which is the
solution of the previous iteration of the optimization
problem. We can now specialize Algorithm 1 to this
case by iterating the above repeatedly with respect
to θ. To show that our algorithm is identical to the
EM algorithm, we show that an identical optimization
problem arises out of the EM algorithm.
Recall that in the expectation step of EM one computes
the value of the expected log-likelihood with respect to
the given set of parameters θt, that is, we compute

#

− log p(yi, xu

i |xo

i , θ) +

1
2σ2kθk2

. (19)

" mX

Ep(x,y;θt)

i=1

Observe that

Ep(x,y;θt) [g(θ|xo

(cid:20) 1
2σ2kθk2

i )] = g(θ|xo
i ),
(cid:21)

=

1
2σ2kθk2.

and

Ep(x,y;θt)

Using the linearity of expectation, the above observa-
tions, and (5) we can re-write (19) as

[g(θ|xo

i ) − hF (θt, xi, yi), θi] +

1
2σ2kθk2.

(20)

mX

i=1

In the maximization step of EM, one computes the
value of θ which maximizes the above expectation.
First order optimality conditions for (20) are found by

329taking derivatives with respect to θ and setting them
to 0. This is equivalent to solving

E(θ, xi, y) − F (θt, xi, yi) +

1
σ2 θ = 0,

X

i

which is exactly the same as (18). This is not sur-
prising, since the CCP is a generalization of the EM
algorithm [16]. Things are more interesting in the case
of Support Vector Machine classiﬁcation.

3.3 Application to SV Classiﬁcation

It is clear that (14) satisﬁes the conditions of Theo-
rem 1: simply deﬁne

1
2σ2kθk2 +
f0(θ, ξ) =
ξi
fi(θ, ξ) = 1 − ξi + max
g(θ|xo
˜y6=yi
g0(θ) = 0 and gi(θ) = g(θ|xo
We also set ci = 0 for all i and write

i=1

i , ˜y)

i , yi).

(21a)

(21b)

(21c)

mX

mX

T1{gi, θt}(θ) = gi(θt) + hθ − θt, F (θt, xi, yi)i .

If we deﬁne

di := 1 − ξi − gi(θt) + hθt, F (θt, xi, yi)i ,

then each iteration Algorithm 1 requires solving the
following optimization problem:

1
2σ2kθk2 +

min
s.t. hF (θt, xi, yi), θi − max
˜y6=yi

i=1

ξi

ξi ≥ 0.

g(θ|xo

i , ˜y) ≥ di

(22a)

(22b)

(22c)

Since this is a convex optimization problem, standard
Quadratic Programming (QP) packages can be used to
solve it. Basically, what happens is that the expected
value of Φ(x, y) with respect to the unknown part of
x is used for classiﬁcation. This is theoretical justiﬁ-
cation for the sometimes-used heuristic of estimating
the values of the missing parameters and subsequently
performing classiﬁcation based on them. The main
diﬀerence to this simple heuristic is that the margin of
classiﬁcation is deﬁned as the diﬀerence between pairs
of log-partition functions. This means that the condi-
tional expectations depend on the (xu, y) pair rather
than on xu alone.

4 Implementation

To make the above algorithms feasible in practice, sev-
eral technical problems need to be overcome:
it may

not be possible to compute the log-partition function
or its derivatives exactly. The solutions cease to be
sparse, as they are given by linear combinations of con-
ditional expectations. Sometimes, the dimensionality
of the space might be so large that high dimensional
integration techniques may need to be employed. In
this section we discuss a few ideas which can be used
to overcome the above problems.

It follows from the
The Representer Theorem:
generalized representer theorem [11] that the solution
θ∗ of both Support Vector Machine and Gaussian Pro-
cess classiﬁcation satisﬁes

θ∗ ∈ span{Φ(xo

i , xu

i , y) where xu

i , y are free} .

(23)

This means that the cardinality of the basis for θ is typ-
ically very large, sometimes even inﬁnite. This might
happen, for instance, when either the input space X
or the label space Y have large dimensionality. This is
clearly not desirable and we need an alternative. This
is given in the form of an incomplete Cholesky factor-
ization of the kernel matrix, either by sparse greedy
approximation [13] or by positive diagonal pivoting [2].
For practical purposes we used the latter based on the
kernel matrix arising from complete data pairs. The
advantage is that instead of conditional expectations of
Φ(x, y), which could be inﬁnite dimensional, we now
only need to compute conditional expectations over
kernel values, that is
hExu[Φ(x, y)|xo; θ], Φ(x0, y0)i = Exu[k((x, y), (x0, y0))|xo].

(24)

Likewise, second derivatives with respect to θ are given
by covariances over kernel values.
In other words, instead of allowing the solution to lie
in a possibly inﬁnite dimensional space we constraint
it to lie in a subspace spanned by the fully observed
variables. This can lead to signiﬁcant computational
advantages. Of course, the downside is that the so-
lution that we obtain might be sub-optimal since we
are enforcing our constraint satisfaction conditions on
only a subspace.

The log-partition function: The second issue, and
arguably a very thorny one, is that one needs to be
able to compute the value of the log-partition function
for both the conditional as well as the unconditional
densities. If suppose the number of missing variables
is very small, and furthermore, if they can take only
a small number of discrete values, then brute force
computation of the conditional log-partition function
is feasible.
In all other cases, we need to resort to methods for
numerical quadrature, such as those discussed in [8].

330The key diﬀerence to before is that now we will not
even be able to reach a local optimum exactly but only
up to the level of precision provided by the numerical
integration method. A simple approximation is to use
a Monte-Carlo estimate over the domain of missing
variables instead of an exact integral. In other words,
to compute

we use the approximation

Ep(x,y;θ)[k((x, y), (x0, y0))|xo],

P
xu∈X u k((x, y), (x0, y0))ehΦ(x,y),θi

P

xu∈X u ehΦ(x,y),θi

where xu is drawn uniformly from the domain of ob-
servations. We believe that the use of a more sophis-
ticated MCMC sampling technique will lead to better
performance.

Stochastic Gradient Descent Finally, instead of
performing a new Taylor expansion at every new step,
we may also perform stochastic gradient descent on
the objective function itself. This may be preferable
whenever the constrained optimization problem be-
comes highly nontrivial. Essentially, in this case we
only perform conditional expectations for the particu-
lar observation at hand. Standard considerations for
stochastic gradient descent methods apply [5].

5 Experiments

We use the well known US Postal Service (USPS)
dataset. It contains 9298 handwritten digits (7291 for
training and 2007 for testing), collected from mail en-
velopes in Buﬀalo [7]. Upto 25% of pixels (64 pixels
out of 256) from each data point in the training set
were randomly selected and their values were erased.
A Sparse Greedy matrix approximation using a maxi-
mum of 1000 basis functions was used to approximate
the kernel matrix. We use the Gaussian kernel

(cid:18)kx − x0k2

(cid:19)

2σ2

,

k(x, x0) = exp

and tune the σ parameter using cross validation. Reg-
ularization parameters previously reported in the lit-
erature [10] were used for all our experiments. To es-
timate the integrals we used a Monte-Carlo sampling
technique using 50 conﬁgurations of missing data gen-
erated uniformly at random. We then used a block
Jacobi method in conjunction with the CCCP algo-
rithm in order to train a multi-class Gaussian Process.
We obtained the best error rate of 5.8%. Contrast this
with the best error rate of around 4.0% reported for the
Gaussian kernel on the same dataset [10]. We noticed
that estimating the integrals by using many samples

decreases the error rate but takes signiﬁcantly longer
amounts of time to compute and converge.
In the second experiment, we replaced the missing val-
ues by their mean values from other observed data.
This is commonly known as mean imputation [3]. We
obtain the best error rate of 6.08% for this procedure.
As can be see the error rates achieved by our method
is marginally better than that obtained by mean im-
putation. This phenomenon was also observed by [3].
We believe that more sophisticated numerical integra-
tion techniques to estimate integrals will signiﬁcantly
improve the performance of our algorithm.

6 Discussion and Outlook

In this paper, we presented a principled method for
dealing with missing data using exponential families
in feature space. We outlined methods to deal with
missing training data as well as partially observed la-
bels. Transduction can be viewed as a special case of
our framework. We then showed how Gaussian Pro-
cesses and Support Vector Machines can be extended
to missing data by using our framework. In order to
solve the non-convex optimization problem that arises
we presented a generalization of the Convex Concave
Procedure to incorporate non-convex constraints. We
also discussed a simple proof of convergence for our
algorithm. Preliminary experimental results are en-
couraging.
Clearly, computation of the log-partition function is
the most expensive step in our algorithm. Faster ap-
proximation algorithms viz. Quasi Monte Carlo sam-
pling methods need to be explored for computing the
log-partition function. Extending our results to graph-
ical models and other similar density estimators re-
mains the focus of future research.

ICT Australia

Acknowledgments National
is
funded through the Australian Government’s Backing
Australia’s Ability initiative, in part through the Aus-
tralian Research Council. This work was supported
by grants of the ARC and sponsored by an NSF-ITR
grant, award number IIS-0312401.

References

[1] Y. Altun, T. Hofmann, and A.J. Smola. Expo-
nential families for conditional random ﬁelds. In
Uncertainty in Artiﬁcial Intelligence UAI, 2004.
[2] S. Fine and K. Scheinberg. Eﬃcient SVM train-
ing using low-rank kernel representations. Journal
of Machine Learning Research, 2:243 – 264, Dec
2001. http://www.jmlr.org.

331Inference in Graphical Models, pages 599 – 621.
MIT Press, 1999.

[16] A.L. Yuille and A. Rangarajan. The concave-
convex procedure. Neural Computation, 15:915
– 936, 2003.

[3] Z. Ghahramani and M. I. Jordan. Supervised
learning from incomplete data via an EM ap-
proach. In J. D. Cowan, G. Tesauro, and J. Al-
spector, editors, Advances in Neural Information
Processing Systems, volume 6, pages 120 – 127.
Morgan Kaufmann Publishers, Inc., 1994.

[4] R. E. Kass and P. W. Vos. Geomtrical Foun-
dations of Asymptotic Inference. Wiley series
in Probability and Statistics. Wiley Interscience,
1997.

[5] J. Kivinen, A.J. Smola, and R. C. Williamson.
Online learning with kernels. IEEE Transactions
on Signal Processing, 2003. To Appear.

[6] S. L. Lauritzen. Graphical Models. Oxford Uni-

versity Press, 1996.

[7] Y. LeCun, B. Boser, J. S. Denker, D. Hender-
son, R. E. Howard, W. Hubbard, and L. J. Jackel.
Backpropagation applied to handwritten zip code
recognition. Neural Computation, 1:541 – 551,
1989.

[8] W. H. Press, S. A. Teukolsky, W. T. Vetterhing,
and B. P. Flannery. Numerical Recipes in C. The
Art of Scientiﬁc Computation. Cambridge Uni-
versity Press, 1994.

[9] G. R¨atsch, S. Mika, and A.J. Smola. Adapting
codes and embeddings for polychotomies. In Neu-
ral Information Processing Systems, volume 15.
MIT Press, 2002.

[10] B. Sch¨olkopf. Support Vector Learning. R. Old-
enbourg Verlag, M¨unchen, 1997.
Doktorar-
beit, TU Berlin. Download: http://www.kernel-
machines.org.

[11] B. Sch¨olkopf, R. Herbrich, and A.J. Smola. A gen-
eralized representer theorem.
In Proceedings of
the Annual Conference on Computational Learn-
ing Theory, pages 416 – 426, 2001.

[12] B. Sch¨olkopf and A.J. Smola. Learning with Ker-

nels. MIT Press, 2002.

[13] A.J. Smola and B. Sch¨olkopf.

Sparse greedy
matrix approximation for machine learning.
In
P. Langley, editor, Proceedings of the Interna-
tional Conference on Machine Learning, pages
911 – 918, San Francisco, 2000. Morgan Kauf-
mann Publishers.

[14] M. J. Wainwright and M. I. Jordan. Graphical
models, exponential families, and variational in-
ference. Technical Report 649, UC Berkeley, De-
partment of Statistics, September 2003.

[15] C. K. I. Williams. Prediction with Gaussian pro-
cesses: From linear regression to linear prediction
and beyond. In M. I. Jordan, editor, Learning and

332Semiparametric Latent Factor Models

Yee Whye Teh

Computer Science Div.
University of California
Berkeley, CA 94720-1776
ywteh@eecs.berkeley.edu

Matthias Seeger

Computer Science Div.
University of California
Berkeley, CA 94720-1776
mseeger@eecs.berkeley.edu

Michael I. Jordan

Computer Science Div. and Dept. of Statistics

University of California
Berkeley, CA 94720-1776
jordan@eecs.berkeley.edu

Abstract

We propose a semiparametric model for regres-
sion problems involving multiple response vari-
ables. The model makes use of a set of Gaus-
sian processes that are linearly mixed to cap-
ture dependencies that may exist among the re-
sponse variables. We propose an efﬁcient ap-
proximate inference scheme for this semipara-
metric model whose complexity is linear in the
number of training data points. We present ex-
perimental results in the domain of multi-joint
robot arm dynamics.

1 Introduction

We are interested in supervised problems involving mul-
tiple responses that we would like to model as condition-
ally dependent. In statistical terminology, we would like to
“share statistical strength” between multiple response vari-
ables; in machine learning parlance this is often referred to
as “transfer of learning.” As we demonstrate empirically,
such sharing can be especially powerful if the data for the
responses is partially missing.

In this paper we focus on multivariate regression prob-
lems.1 Models related to the one proposed here are used
in geostatistics and spatial prediction under the name of
co-kriging [3], and an example from this domain helps to
give an idea of what we want to achieve with our tech-
nique. After an accidental uranium spill, a spatial map of
uranium concentration is sought covering a limited area.
We can take soil samples at locations of choice and mea-
sure their uranium content, and then use Gaussian process
regression or another spatial prediction technique to infer
a map. However, it is known that these carbon concentra-
tion and uranium concentration are often signiﬁcantly cor-
related, and carbon concentration is easier to measure, al-

1In Section 5 we indicate how our technique can be extended

to other settings such as multi-label classiﬁcation.

lowing for more dense measurements. Thus in co-kriging
the aim is to set up a joint spatial model for several re-
sponses with the aim of improving the prediction of one of
them. The model to be described in the current paper goes
beyond simple co-kriging methods in several ways. First,
rather than combining responses in a posthoc manner as
in co-kriging, our model uses latent random processes to
represent conditional dependencies between responses di-
rectly. The latent processes are ﬁtted using the data from
all responses and can be used to model chacteristics of the
dependencies beyond those based solely on marginal rela-
tionships. Second, the nature of the dependencies does not
have to be known in advance but is learned from training
data using empirical Bayesian techniques.

Another example of a motivating application arises in com-
puter vision, where it is of interest to estimate the pose of
a human ﬁgure from image data. In this case the response
variables are the joint angles of the human body [1]. It is
well known that human poses are highly constrained, and it
would be useful for a pose estimation algorithm to take into
account these strong dependencies among the joint angles.

Historically,
the problem of capturing commonalities
among multiple responses was one of the motivations be-
hind multi-layer neural networks—the “hidden units” of
a neural network were envisaged not only as nonlinear
transformations, but also as adaptive basis functions to be
“shared” in predicting multivariate responses. As neural
networks gave way to kernel machines for classiﬁcation
and regression, with comcomitant improvements in ﬂex-
ibility, analytical tractability and performance, this core
ability of neural networks was largely lost.

To elaborate on this point, note that there have been two
main paths from neural networks to kernel machines. The
ﬁrst path, due to [10], involved the observation that in a
particular limit the probability associated with (a Bayesian
interpretation of) a neural network approaches a Gaus-
sian process. For some purposes, it is arguably advan-
tageous to work directly with the Gaussian process via
its covariance function. However,
in this limit it also
turns out that the components of the response (the output

333vector) are independent—the ability to model couplings
among these components is lost. The second path to ker-
nel machines, via the optimization of margins [14], sim-
pliﬁed the problem of ﬁtting one-dimensional responses,
but largely neglected the problem of ﬁtting dependent mul-
tivariate responses. This problem has returned to the re-
search agenda via architectures such as the conditional ran-
dom ﬁeld which links response variables using the graphi-
cal model formalism [5, 13].

Our approach to modeling dependencies among response
variables heads in a direction that is more nonparametric
than the CRF. In the spirit of factor analysis, we view the
relationships among C components of a response vector y
as reﬂecting a linear (or generalized linear) mixing of P
underlying latent variables. These latent variables are in-
dexed by a covariate vector x, and thus we have a set of
indexed collections of variables; that is, a set of stochastic
processes. Speciﬁcally, we assume that each of the P vari-
ables is conditionally independently distributed according
to a Gaussian process, with x as the (common) index set.
The mean of the response y is then a (possibly nonlinear)
function of a linear combination of these conditionally in-
dependent Gaussian processes.

This model is a semiparametric model, as it combines
a nonparametric component (several Gaussian processes)
with a parametric component (the linear mixing). We re-
fer to the model as a semiparametric latent factor model
(SLFM). Note that factor analysis is a special case of the
SLFM, arising when x is a constant. Note also that Neal’s
limiting Gaussian process is a special case, arising when
P = 1. Finally, as we discuss in Section 2, when C = 1
and P > 1 the SLFM can be viewed as a Gaussian pro-
cess version of the multiple kernel learning architecture
proposed in [6].

As in the case of simpler Gaussian process models, a sig-
niﬁcant part of the challenge of working with the SLFM
is computational. This challenge can be largely met by
exploiting recent developments in the literature on ﬁtting
large-scale Gaussian process regression and classiﬁcation
models.
In particular, we make use of the informative
vector machine (IVM) framework for Gaussian processes
[8, 11]. In this framework, only a subset of “informative”
likelihood terms are included in the computation of the
posterior, yielding an training algorithm which scales lin-
early in the number of training data points. Moreover, the
Bayesian underpinnings of the IVM yields general methods
for setting free parameters (hyperparameters), an important
capability which is not always easily achieved within the
context of other kernel-based methodologies.

2 Semiparametric Latent Factor Models

In this section we give a description of our model for non-
parametric regression with multiple responses. We begin

with a short overview of Gaussian process (GP) regression
in the simpler setting of single responses.

A GP can be viewed as a prior over random real-valued
functions u : X 7! R, and is parametrized by a mean func-
tion (cid:22)((cid:1)) and a covariance kernel k((cid:1); (cid:1)). A random function
u((cid:1)) is said to be distributed according to a GP if for any
ﬁnite subset X = fx1; : : : ; xmg (cid:26) X of covariate vec-
tors the random vector u(X) = (u(x1); : : : ; u(xm))T 2
Rm is distributed according to a Gaussian with mean
((cid:22)(x1); : : : ; (cid:22)(xm))T and covariance K 2 Rm;m where
the i; jth entry is k(xi; xj). In our work we use GPs with
zero mean: (cid:22)(x) = 0 for all x 2 X . The covariance ker-
nel k((cid:1); (cid:1)) has to satisfy a symmetric positive-deﬁniteness
(SPD) property; that is, K should be SPD for every ﬁnite
subset X. Thus, a GP is simply a consistent way of as-
signing multivariate Gaussian distributions to u(X) for any
ﬁnite X.

GPs have traditionally been used for Bayesian classiﬁca-
tion and regression with a single response, where the prob-
lem is treated as that of estimating a random univariate
function from the covariate space to the response space.
Rather than assuming a parametric form for the random
function, the nonparametric Bayesian approach places a GP
prior over the space of all functions, and infers the posterior
over functions given the training data.

Returning to our multiple response setting, let X be the
covariate (input) space and let Y = RC be the response
(output) space. We are interested in predicting y =
(y1; : : : ; yC)T 2 Y from x 2 X ;
i.e., in estimating
P (yjx). We model the conditional distribution using la-
tent variables v 2 RC such that the components yc are
mutually independent and independent of x given v:

P (yjv; x) =

C

Y

c=1

P (ycjvc):

The conditional distribution of y given x is then:

P (yjx) = Z P (vjx)

C

Y

c=1

P (ycjvc) dv:

In this paper we focus on regression with Gaussian errors;
c ). We treat P (vjx) nonpara-
i.e., P (ycjvc) = N (ycjvc; (cid:27)2
metrically, in particular using GPs. We do this by introduc-
ing a further set of latent variables u 2 RP and letting v
be linearly related to u:

v = (cid:8)u;

(1)

with (cid:8) 2 RC;P . Finally we assume that the coordinates
of u have independent GP priors conditional on x; i.e.,
there are random functions up : X 7! R such that up =
up(x), and up((cid:1)) are distributed according to a GP with
zero mean and covariance kernel kp((cid:1); (cid:1)). This setup allows

334q p

c

x

Gaussian
processes

u

linear
mixing

v

y

likelihood

Figure 1: A semiparametric latent factor model.

for conditional dependencies among the coordinates of v
to be expressed via (cid:8) and the latent u variables.

The form assumed in Eq. 1 is in direct analogy with factor
analysis models. Note that the information learned from
each single response variable yc is reﬂected in the posterior
for the latent GPs u((cid:1)). Thus, there is sharing of statistical
strength across response variables.

We call the model a semiparametric latent factor model
(SLFM); the graphical model is shown in Figure 1. The pa-
rameters are the components of (cid:8) and the hyperparameters
(aka, the nuisance parameters) are the kernel parameters (cid:18)p
c associated with the Gaus-
and the variance parameters (cid:27)2
sian likelihoods P (ycjvc).

p=1 (cid:30)2

Note that each coordinate vc((cid:1)) of v((cid:1)) = (cid:8)u((cid:1)) is a priori
a GP with covariance kernel given by PP
c;pkp((cid:1); (cid:1)),
where (cid:30)c;p is the (c; p)th element of the matrix (cid:8). Hence
one interpretation of our model is that each response vari-
able is modeled as a Gaussian process with a kernel that
is an adaptive, conic combination of base kernels. In fact,
if we have C = 1 and P > 1, then this model can be
viewed as a Gaussian process version of the kernel learn-
ing proposed in [6]. However our model does not just ﬁt
the kernel, it actually makes use of the same latent Gaus-
sian processes for every response variable, allowing more
expressive sharing of information across the response vari-
ates. Also, in the case P < C which is our focus in the
current paper, it is more efﬁcient to represent u explicitly
than to integrate it out.

3 Inference

Given a model and training samples D = f(x1; y1); : : : ;
(xn; yn)g drawn i.i.d. from the model2, we perform
Bayesian inference for the latent variables and estimate the
parameters and the hyperparameters within an empirical
Bayes framework. We begin by introducing the relevant
latent variables.

Let ui;p = up(xi) and vi;c = vc(xi). We collect these
into vectors u = (ui;p)i;p and v = (vi;c)i;c where the dou-

2We allow incomplete observations of yi. That is, entries of
yi are allowed to be unobserved—thissimply involves dropping
likelihood terms corresponding to the unobserved entries.

ble indices are ﬂattened, with index i running over 1; : : : ; n
ﬁrst, e.g., u = (u1;1; u2;1; : : : ; un;1; : : : ; un;P )T . The vec-
tors u and v are again linearly related: v = ((cid:8) (cid:10) I)u,
where (cid:10) is the Kronecker product.
In the following we
will assume that P (cid:20) C and (cid:8) has full rank so the pseudo-
inverse (cid:8)y such that (cid:8)y(cid:8) = I exists and u = ((cid:8)y (cid:10) I)v.
The case P > C requires a different treatment and will be
presented in future work. The variable u is distributed a
priori according to a Gaussian with zero mean and block
diagonal covariance matrix K = diag(K (p))p, where the
pth block has i; jth entry given by K (p)
i;j = kp(xi; xj). The
covariance of v is thus ~K = ((cid:8) (cid:10) I)K ((cid:8)T (cid:10) I).

The posterior processes u((cid:1)) j D are Gaussian in the case of
Gaussian likelihoods P (ycjvc), and in principle we could
compute their mean and covariance functions explicitly.
However, this is prohibitively expensive for all but fairly
small values of n and C (the procedure scales as O(n3 C 3)
in general). We thus make use of the informative vector
machine (IVM) framework [8] which computes a sparse
approximation to the full Gaussian posterior P (vjD) by
means of greedy forward selection of an active subset of the
training sample using information-theoretic criteria. The
difference here is that P > 1 processes have to be rep-
resented along with their dependencies, and the empirical
Bayes maximization has to encompass a large number of
non-kernel parameters, namely the elements of (cid:8).

3.1 Forward selection

The active set I of size d consists of tuples (i; c) 2
f1; : : : ; ng (cid:2) f1; : : : ; Cg. The goal is to select I such that
the approximate posterior

Q(v) / P (v) Y

(i;c)2I

P (yi;cjvi;c)

(2)

is close to P (vjD). For given I, the posterior approxi-
mation Q is given by simply ignoring all observations not
in I. However, our method of selecting I depends on the
complete sample D, as is discussed in this section. The
idea is to greedily select the candidate (i; c) which changes
the posterior most if we were to include it (i.e., incorpo-
rate its likelihood term into Q). A good way of measuring
this change is the information gain studied in the setting of
active learning (or sequential design). If Qk(cid:0)1 denotes the
posterior approximation after k (cid:0) 1 inclusions, the criterion
is

(cid:1)inf o

i;c = D [Qi;c(v) k Qk(cid:0)1(v)]

= D [Qi;c(vi;c) k Qk(cid:0)1(vi;c)] ;

where Qi;c is the approximate posterior we obtain if the
term (i; c) is included at iteration k. At each iteration we
pick the (i; c) that maximizes (cid:1)inf o
. Since Qi;c(vi;c) /
P (yi;cjvi;c)Qk(cid:0)1(vi;c), we can compute (cid:1)inf o
in O(1) if

i;c

i;c

335F
s
the current marginal Qk(cid:0)1(vi;c) is known. The represen-
tation of Q described in Section 3.2 makes it possible to
maintain all these marginals at all times so that we can
score all (i; c) 62 I prior to each inclusion. After d it-
erations we have an active set (i1; c1); : : : ; (ik; ck) which
determines the approximate posterior in Eq. 2.

3.2 Representing the approximate posterior

The representation for the approximate posterior in Eq. 2
has to satisfy the following properties in order for it to be
useful: it should allow all marginals Q(vi;c) to be main-
tained explicitly at all times, which allows for forward se-
lection (see Section 3.1); it should have a small memory
footprint; and it can be efﬁciently updated when a new like-
lihood term is included. In this section we describe how
these properties are achieved.

Let (cid:5) = diag((cid:25)k)k be a diagonal matrix and b = (bk)k be
a vector which collects the parameters of the approximate
posterior, in the sense that

Q(v) / P (v) exp(cid:18)(cid:0)

(cid:5)vI + bT vI(cid:19) ;

vT
I

1
2

and bk = (cid:27)(cid:0)2
ck

In the case of regres-
where vI = (vi1;c1 ; : : : ; vid;cd)T .
yik;ck. Note that
sion we have (cid:25)k = (cid:27)(cid:0)2
ck
(cid:5) and b are ordered according to the order in which like-
lihood terms are included. To convert from this ordering to
the natural ordering of u and v, deﬁne a selection matrix
P 2 Rd;nC where P k;(ik;ck) = 1 for k = 1; : : : ; d, and
zeros elsewhere (note that the natural ordering in which we
ﬂatten i; c indices runs over i ﬁrst).

Given (cid:5) and P , the covariance of Qk(v) is

~A = ( ~K

y

+ P T (cid:5)P )y:

Given our assumption P (cid:20) C, we can represent the ap-
proximate posterior in terms of u to minimize memory and
time requirements. As u = ((cid:8)y (cid:10) I)v, the covariance of
Qk(u) is

A = ((cid:8)y (cid:10) I)( ~K

y

+ P T (cid:5)P )y((cid:8)yT (cid:10) I):

Using the Sherman-Morrison-Woodbury formula, we ob-
tain

A = K (cid:0) M M T ; M = K ((cid:8)T (cid:10) I)P T (cid:5)1=2L(cid:0)T ;
(3)

while the mean and variance of vi;c under Qk are

~hi;c = (cid:30)(c)hi;

~ai;c = (cid:30)(c)Ai(cid:30)(c)T ;

where hi and Ai are the mean and covariance of ui, ex-
tracted from entries of Eq. 4 and Eq. 3 respectively, and
(cid:30)(c) is the cth row of (cid:8). The forward selection can be car-
ried out once ~hi;c and ~ai;c are computed for every (i; c) not
already included in the active set.

Finally, the representation of Q(u) is given by L 2 Rd;d,
(cid:12) 2 Rd, M 2 RnP;d, and the mean hi 2 RP and co-
variance Ai 2 RP;P of ui, for i = 1; : : : ; n. Since the
rows of L, (cid:12), and M are already ordered by inclusion
iteration, they can be updated efﬁciently and stably by ap-
pending new rows or columns. If at iteration k we included
likelihood term (i; c), we compute

l = p1 + (cid:25)k~ai;c;
(cid:30)c;p(cid:25)1=2

k K(p)
i (cid:0) M (p)l
l

(cid:22)p =

l = (cid:25)1=2

k X

(cid:30)c;pM (i;p) T

bk (cid:0) lT (cid:12)
l

;

p
(cid:25)(cid:0)1=2
k

(cid:13) =

i

is subtracted from Ai.

where M (p) is a matrix whose rows are M (i;p). The new
row of L is (lT l), the new column of M (p) is (cid:22)p, and the
new entry of (cid:12) is (cid:13). Let (cid:22)i = ((cid:22)i;p)p. Then hi is updated
by adding (cid:13)(cid:22)i while (cid:22)i(cid:22)T
The memory requirement is dominated by M which is
O(nP d), while the P matrix-vector multiplications in-
volved in computing (cid:22)p dominate the update time com-
plexity, which is O(nP d). Computing the information gain
scores (cid:1)inf o
requires O(nCP 2) time which is in general
subdominant to O(nP d). Note that all costs are linear in
the number of training points n which is the dominant fac-
tor in many large applications.

i;c

3.3 Parameter and hyperparameter estimation

We have described an effective procedure to compute an
approximation to the posterior of the latent variables. Here
we outline empirical Bayes estimation of the parameters
and hyperparameters. Let (cid:11) denote a parameter or hy-
perparameter of interest, and let s denote the variational
parameters which deﬁne the approximate posterior—these
are the active set indicators, (cid:5) and b. Since we cannot
compute the marginal probability of y given x and (cid:11) ex-
actly, we optimize a variational lower bound instead:

where L is the lower triangular Cholesky factor of

log P (y j x; (cid:11)) (cid:21)

B = I + (cid:5)1=2P ~K P T (cid:5)1=2:

The mean of Qk(u) is obtained as

h = EQk [u] = M (cid:12); (cid:12) = L(cid:0)1(cid:5)(cid:0)1=2b

(4)

EQ[log P (y j u; (cid:11))] (cid:0) D[Q(u)kP (u j (cid:11))];

(5)

where Q(u) is the approximate posterior, given by Eq. 2.
We use a double loop iterative procedure, where in the in-
ner loop we optimize Eq. 5 with respect to (cid:11) using a quasi-
Newton method while keeping s ﬁxed, and in the outer

336loop we reselect a new s greedily as detailed above. No-
tice that Q((cid:1)) is dependent on both s and (cid:11). For purposes
of optimizing (cid:11) we propagate derivatives with respect to (cid:11)
through Q((cid:1)), but keep s ﬁxed. This differs from most other
variational methods that keep all of Q((cid:1)) ﬁxed when opti-
mizing (cid:11). Note that the overall optimization is not guar-
anteed to converge, since the s updates are not guaranteed
to increase the lower bound. In practice we ﬁnd the opti-
mization almost always increases and behaves well. The
criterion and gradient computation has the same complex-
ity as the conditional inference, but is much faster in prac-
tice because code for large matrix operations can be used.
The memory requirements are not increased signiﬁcantly,
because M can be overwritten. The derivation is rather
involved; it can be found in [12].

4 Experiments

In this section we present experimental results for the re-
gression task of modeling of the dynamics of a 3-D, four-
joint robot arm. The dataset is created using realistic simu-
lation code which provides a mapping from twelve covari-
ates (the angles, angular velocities and torques at each of
the four joints of the arm) to four responses (the angular
accelerations at the four joints).

We preprocessed the raw data by ﬁtting a linear regression
to the training set and replacing all responses by the cor-
responding residuals, then normalizing both covariate and
response variables to have mean zero and variance one.
This removal of the linear component of the regression
helps clarify the relative contributions made by the nonlin-
ear methods that are our focus. Finally the four responses
were linearly mixed using randomly sampled unit length
vectors to produce six response variables. Thus the dataset
is a mapping from twelve covariates to six responses, where
it is known that four latent variables are sufﬁcient to capture
the mapping.

The dataset sizes are n = 1000 for training and 500 points
for testing. We report mean squared error (MSE) and av-
erage marginal log probability (LOGP) in the experiments
below.3 To calibrate the numbers, note that linear regres-
sion would have an average MSE of 1 on this task.

We compare our model against a baseline method (INDEP)
in which each response variable is simply modeled inde-
pendently, i.e., taking P = C and (cid:8) = I. We use the
IVM technique for both models. For our model we use a
joint active set I of size d, while for the baseline we use
individual active sets of size d0 per response variate. It is
clear that for similar training set size and coverage by ac-
tive points, training for INDEP is signiﬁcantly faster than
for SLFM, and in this study we do not attempt to equalize
training times.

3LOGP is log Q(y(cid:3)jx(cid:3)) averaged over the test set.

In both models we use the squared-exponential covariance
function (SQEXP):

kp(x; x0) = (cid:23)p exp (cid:0)X

l

1
2(cid:18)2
p;l

jxl (cid:0) x0

lj2! ;

(6)

where (cid:18)p;l is the length scale for dimension l, and (cid:23)p > 0
sets the overall variance. For the SLFM, the same kernel is
used for all latent GPs and we set (cid:23)p = 1 since the variance
can already be represented by scaling the columns of (cid:8).
We allow different length scales for each input dimension
because we ﬁnd that this has a signiﬁcant impact on the
quality of prediction—if the length scale is constrained to
be the same for all covariate dimensions then less relevant
input dimensions tend to obscure the more relevant ones.
Note that this large set of hyperparameters is adjusted based
on the training set within our empirical Bayesian frame-
work; no validation set is needed.

The mean squared errors and log probabilities are shown in
Table 1 as a function of P as P is varied from 2 to 6. The
model performs best at P = 4, although similar accuracy
is achieved for P = 4; 5; 6. We do expect the performance
to degrade for even larger values of P but we have not in-
vestigated this. For the rest of this section we chose P = 4
since this is the smallest value supported by the data.

c n P

1
2
3
4
5
6

LOGP

2

0.2930
0.2840
0.3940
0.3630
0.3080
0.5560
-5.770

3

0.2340
0.2950
0.1570
0.2980
0.2830
0.3010
-4.571

4

0.1220
0.1780
0.1080
0.1270
0.1760
0.1180
-2.342

5

0.1190
0.1890
0.1060
0.1490
0.1840
0.1190
-2.516

6

0.1130
0.1880
0.1030
0.1410
0.1810
0.1100
-2.466

Table 1: The mean squared errors for each response variate
on the test set and the average log probability per training
point assigned by our model for varying P .

Next we compared the SLFM with P = 4 to the base-
line of independently modeled response variables. We used
a training set of size n = 1000 and active sets of size
d = 1000 and d0 = 180 (if all INDEP active sets are dis-
joint, their union has size 6 (cid:1) 180 = 1080). The results are
shown in Table 2. Note that the MS errors for our model
are smaller than for the baseline.

We also tested for the effects of varying the active set size
d; results are given in Table 3.

We see that the active set size d has a signiﬁcant effect on
prediction accuracy. The quadratic scaling in d can be ob-
served from the training times, except for the largest values
of d, where the O(d3) component in the gradient computa-
tion dominates the O(n P d2) component.

Since our method models dependencies among the re-
sponse variables, for every test point we have a joint predic-
tive distribution over the response variables y(cid:3) 2 RC. This

337SLFM INDEP
MSE
0.133
0.202
0.152
0.179
0.202
0.135

c MSE
0.122
1
0.178
2
0.108
3
0.127
4
0.176
5
0.118
6

SLFM INDEP
LOGP
LOGP
-0.110
0.018
-0.335
-0.244
-0.352
-0.025
-0.271
0.011
-0.340
-0.349
-0.046
0.053

Table 2: Comparing our model (SLFM) against the base-
line (INDEP) on the robot arm task, with C = 6; P = 4.
Rows correspond to response variables.

c n d

1
2
3
4
5
6

time

500
0.174
0.285
0.228
0.283
0.281
0.196
382

1000
0.122
0.178
0.108
0.127
0.176
0.118
1269

2000
0.096
0.107
0.072
0.082
0.100
0.090
5806

3000
0.067
0.094
0.062
0.068
0.090
0.066
16746

Table 3: MS test errors for each response as the active set
size d is varied.
time gives the complete training time in
seconds.

can be used to further improve the prediction of the model
for any speciﬁc component y(cid:3);c, if in addition to the co-
variates x(cid:3) we are also given a subset of the other response
variables y(cid:3);c0. In Table 4 we show the mean squared errors
attained for response c = 5, when we are also given other
responses. The errors are reduced signiﬁcantly, especially
for c0 = f2g, and further improve as we observe more re-
sponses; in particular when we observe c0 = f3; 4g. Note
that for the baseline method each response variable is mod-
eled independently and the predictive distribution over v(cid:3)
factorizes, hence knowledge of other responses cannot help
in predicting y(cid:3);c.

c0
f1g
f2g
f3g
f4g
f6g
f3; 4g

MSE
0.1770
0.0380
0.1490
0.1320
0.1740
0.112

LOGP
-0.2640
0.2450
-0.2760
-0.2940
-0.3440
-0.221

Table 4: Improved predictions of the model on response
variable c = 5 when the model is given other responses
y(cid:3);c0.

Finally we report an experiment that aimed at improv-
ing our understanding of how statistical strength is shared
across response variables. We again focus on predicting re-
sponse variate c = 5 in the task with 1000 training points.
However, instead of presenting all 1000 covariate/response
pairs simultaneously, we start by observing only response
variable c = 5, for a subset of l < 1000 points. Subse-

quently, we are given all 1000 covariate vectors and the cor-
responding responses for a subset c0 not including c = 5.
We ask whether this will improve our prediction of re-
sponse variable c = 5. Note that this setup is similar to
co-kriging scenarios mentioned in Section 1. Table 5 shows
the mean squared errors attained for various values of l and
for various subsets c0 of additional observed response vari-
ables. We see a large improvement of the mean squared
error for c0 = f1; 2g. Even for l = 50 the errors are al-
ready smaller than those in Table 2. This is because of
the strong dependencies between response variables c = 2
and c = 5 (as seen in Table 4). Note also that the case
c0 = f1; 2; 3; 4; 6g performed worse than c0 = f1; 2g,
though still yielding a marked improvement over no addi-
tional training set (c0 = ;). This occurs because the func-
tional that our method optimizes is a joint functional over
the response variables, and thus depends more strongly on
response variables with more training data. Performance
as assessed by this functional indeed improved for larger
c0. If our goal is to obtain good prediction for a particular
response variable, we can consider a different functional
which focuses on the response variable of interest.

l n c0

50
150
250

;

1.011
0.752
0.278

f1; 2g
0.111
0.111
0.105

f1; 2; 3; 4; 6g

0.202
0.198
0.183

Table 5: Mean squared error on test set for varying training
set sizes l and additional response variables c0.

5 Discussion

We have described a model for nonlinear regression in
problems involving multiple, linked response variables. In
a manner reminiscent of factor analysis in the parametric
setting, we model the response vector as (a function of) a
linear combination of a set of independent latent Gaussian
processes. This rather simple semiparametric approach to
sharing statistical strength has a number of virtues—most
notably its ﬂexible parametrization in terms of sets of co-
variance kernels and its computational tractability. We pre-
sented an efﬁcient approximate inference strategy based on
the IVM. While our primary focus has been prediction,
the inferential tools provided by the IVM also allow us to
compute posteriors over various components of the model,
in particular the latent factors and the parameters. Possi-
ble extensions of the model include placing an automatic
relevant determination (ARD) prior on the columns of the
mixing matrix (cid:8) and letting the model determine P auto-
matically. It is also of interest to consider ways in which
the mixing matrix might be dependent on the covariates as
well.

There are other ways of combining multiple Gaussian pro-
cesses. [9] and [7] present models in which the hyperpa-

338rameters of a set of Gaussian processes are endowed with a
common prior. This hierarchical model couples the Gaus-
sian processes as in the SLFM, but the amount of shar-
ing that it induces is rather limited, since it involves only
the hyperparameters of the Gaussian processes. In our ap-
proach the sharing involves entire processes and as such
can be much more expressive. Note also that although we
considered tasks involving a single regression problem with
multiple responses, the SLFM can readily accommodate
the setting in which there are multiple related tasks, each
with a single response and with a separate training set.

As we have noted, the semiparametric approach presented
here is an alternative to the parametric methodology of con-
ditional random ﬁelds (CRFs) that has recently been the
focus of attention in the machine learning and computer vi-
sion communities [5, 4]. When the response variables can
plausibly be linked in a simple structure, for example ac-
cording to a chain or a tree, the CRF approach would seem
to be preferable to the SLFM approach. On the other hand,
when the graph is not a chain, the potential intractability
of the partition function can be a signiﬁcant drawback of
the CRF approach. In vision problems, for example, one
would like to use a two-dimensional Markov random ﬁeld
for modeling dependencies, but this runs aground on the
problem of the partition function. In our approach, cou-
plings among variables arise by marginalizing over a latent
set of linearly mixed Gaussian processes, and this provides
an alternative, implicit approach to linking variables.
In
cases in which graphical models are intractable, this ap-
proach may provide the requisite tractability at a cost of
modeling ﬂexibility. Finally, note also that the SLFM ap-
proach is a kernel-based approach by deﬁnition; there is no
need to explicitly “kernelize” the SLFM.

Several methods for multiple responses in regression have
been proposed which involve posthoc combinations of the
outputs of the independent baseline method. An example
is the curds and whey method [2] for multiple linear re-
gression. It is important to stress that our approach is fun-
damentally different in that the latent u processes are ﬁt-
ted jointly using all data. These processes can represent
conditional dependencies directly, while the processes of
the baseline method only ever see marginal data for each
response. Posthoc combination schemes should be suc-
cessful if response dependencies are mainly unconditional
but may fail to represent dependencies which change with
x. An advantage of posthoc methods is that they can be
cheap computationally, having essentially the same scaling
as the independent baseline (which they use as a subrou-
tine). Whether a more ﬂexible technique such as ours with
a computational complexity closer to the baseline method
exists is an open question.

5.1 Applications to classiﬁcation

Our model can be extended to classiﬁcation problems
and to other problems involving non-Gaussian likelihoods
P (ycjvc). The basic idea is to again make use of GP-based
techniques such as the IVM that have been extended to GP-
based classiﬁcation in the single response variable case [8].
The non-Gaussian likelihoods are effectively replaced by
Gaussians whose parameters are determined by sequential
moment matching.

The extension to classiﬁcation is of particular interest in
the multiple response variable setting because it allows us
to address multi-label classiﬁcation problems in which the
class labels are not assumed to be mutually exclusive and
may exhibit interesting and useful interdependencies.

In a preliminary investigation of this extension we con-
sidered the toy example shown in Figure 2. We sampled
500 two-dimensional covariate vectors uniformly at ran-
dom from [(cid:0)1; 1]2 and labeled these vectors using eight bi-
nary response variables, one for each of the regions shown
in the top left panel of Figure 2. There was no label noise,
but 10% of the n = 500 training responses were missing at
random. We ﬁt this data with an SLFM suitably extended
to probit likelihoods, using P = 3 latent GPs, each with
a different SQEXP kernel (Eq. 6) and with a single length
scale parameter (i.e., (cid:18)p;l = (cid:18)p;l0).

−0.8

−0.6

−0.4

−0.2

0

0.2

0.4

0.6

0.8

1

−0.8

−0.6

−0.4

−0.2

0

0.2

0.4

0.6

0.8

1

−0.8

−0.6

−0.4

−0.2

0

0.2

0.4

0.6

0.8

1

−0.8

−0.6

−0.4

−0.2

0

0.2

0.4

0.6

0.8

1

−0.8

−0.6

−0.4

−0.2

0

0.2

0.4

0.6

0.8

1

−0.8

−0.6

−0.4

−0.2

0

0.2

0.4

0.6

0.8

1

−0.8

−0.6

−0.4

−0.2

0

0.2

0.4

0.6

0.8

1

−0.8

−0.6

−0.4

−0.2

0

0.2

0.4

0.6

0.8

1

Figure 2: Top left: the eight regions. Rest: posterior mean
function of the latent GPs. Light colors correspond to larger
values.

After training, the test set errors for the eight response
variables were 0:0345, 0:0261, 0:0133, 0:0296, 0:0602,
0:0176, 0:0494 and 0:0230. The remaining three panels
in Figure 2 show the approximate posterior mean functions

339sponses in multiple linear regression. J. Roy. Stat. Soc. B,
59(1):3–54, 1997.

[3] N. Cressie. Statistics for Spatial Data. John Wiley & Sons,

2nd edition, 1993.

[4] S. Kumar and M. Hebert. Discriminative random ﬁelds: A
discriminative framework for contextual interaction in clas-
siﬁcation. In Proceedings of IEEE International Conference
on Computer Vision, 2003.

[5] J. Lafferty, F. Pereira, and A. McCallum. Conditional ran-
dom ﬁelds: Probabilistic models for segmenting and label-
ing sequence data. In Proceedings of the International Con-
ference on Machine Learning, 2001.

[6] G. R. G. Lanckriet, N. Cristianini, P. Bartlett, L. El Ghaoui,
and M. I. Jordan. Learning the kernel matrix with semideﬁ-
nite programming. Journal of Machine Learning Research,
5:27–72, 2004.

[7] N. D. Lawrence and J. C. Platt. Learning to learn with the
informative vector machine. In Proceedings of the Interna-
tional Conference in Machine Learning, 2004.

[8] N. D. Lawrence, M. Seeger, and R. Herbrich. Fast sparse
Gaussian process methods: The informative vector machine.
In Advances in Neural Information Processing Systems 15,
pages 609–616, 2003.

[9] U. Menzefricke. Hierarchical modeling with Gaussian pro-
cesses. Communications in Statistics–Simulation and Com-
putation, 29(4):1089–1108, 2000.

[10] R. M. Neal. Priors for inﬁnite networks. Technical Report
CRG-TR-94-1, Department of Computer Science, Univer-
sity of Toronto, 1994.

[11] M. Seeger. Bayesian Gaussian Process Models: PAC-
Bayesian Generalisation Error Bounds and Sparse Approx-
imations. PhD thesis, University of Edinburgh, July 2003.
See www.cs.berkeley.edu/˜mseeger.

[12] M. Seeger, Y.-W. Teh, and M.
factor models.

parametric latent
Technical
University of California at Berkeley, 2004.
www.cs.berkeley.edu/˜mseeger.

I. Jordan.

Semi-
report,
See

[13] B. Taskar, C. Guestrin, and D. Koller. Max-margin Markov
In Advances in Neural Information Processing

networks.
Systems 16, 2004.

[14] V. N. Vapnik. Estimation of Dependences based on Empiri-

cal Data. Series in Statistics. Springer, 1st edition, 1982.

for the three latent GPs. Roughly speaking, one GP is used
for vertical discrimination, one for horizontal, and a third
for inside-vs-outside separation (although the ﬁrst two GPs
also distinguish inside-vs-outside separation to a lesser ex-
tent). Thus we see that the model has formed a combi-
natorial code in which it is able to classify eight response
variables using only three latent GPs.

5.2 Other issues

Computational
issues remain a serious concern if the
SFLM is to be scaled to larger problems. The main avenue
open for tackling larger datasets is to refrain from scoring
all remaining points for all later inclusions. In particular,
after a number of initial inclusions selected from all re-
maining points we can potentially narrow down the candi-
date set stepwise by excluding points with the worst current
scores. The empirical Bayes learning procedure then ap-
proximates the full likelihood by the likelihood restricted
to the ﬁnal candidate set (which always includes the ac-
tive set). For very large tasks, even more elaborate caching
strategies could be envisaged. A natural limit for the ac-
tive set size d is imposed by the O(d3) time and memory
scaling.

While we have focused on the case P < C in the current
paper, it is also of great interest to explore cases in which
P > C. In particular, in the P < C regime the variable
v 2 RC is constrained to lie in a P -dimensional subspace;
while the analogy to factor analysis suggests that this may
be a useful constraint in some problems, it also may im-
pose an overly narrow bottleneck on the regression map-
ping in other problems. There are several possible ways to
remove this constraint and consider versions of the SFLM
that operate in the P > C regime. One interesting vari-
ant involves replacing Eq. 1 by v = v(0) + (cid:8)u where
all components of (v(0)T ; uT )T are conditionally indepen-
dent and are given GP priors with different kernels. While
this setup can be viewed as simply a particular choice of
(cid:8) in a generic SFLM with P > C, the additional inde-
pendences in the model aid in the design of approximate
inference methods based on a variant of belief propagation.

Acknowledgments

This work has been supported by a grant from the Intel
Corporation, by a grant from Microsoft Research, and by
a grant from DARPA in support of the CALO program.

References
[1] A. Agarwal and B. Triggs. 3D human pose from silhouettes
by relevance vector regression. In Proceedings of the IEEE
International Conference on Computer vision and Pattern
Recognition, 2004.

[2] L. Breiman and J. Friedman. Predicting multivariate re-

340(cid:0)Æ(cid:1)(cid:2)(cid:3) (cid:6)(cid:8)(cid:9)(cid:2)(cid:3) (cid:10)	(cid:8)(cid:2) (cid:15) (cid:10)(cid:9)(cid:2)(cid:2)(cid:8)  (cid:6)(cid:8)	(cid:2)(cid:8) (cid:9)(cid:3) 

(cid:0) (cid:2)(cid:3)(cid:4)(cid:5)

(cid:1)(cid:2)(cid:6) (cid:8)(cid:9)(cid:9)(cid:10)(cid:2)(cid:11)

(cid:11)(cid:1)(cid:9)(cid:13)(cid:1)(cid:2)(cid:6)(cid:15)(cid:2)

(cid:8)(cid:3)(cid:4)(cid:3)(cid:5) (cid:5)(cid:5)(cid:13)
(cid:1)(cid:2)(cid:6) (cid:8)(cid:9)(cid:9)(cid:10)(cid:2)(cid:11)
(cid:9)(cid:9)(cid:16)(cid:13)(cid:1)(cid:2)(cid:6)(cid:15)(cid:2)

(cid:0)(cid:1)(cid:5)(cid:6)

(cid:17)(cid:9) (cid:1)(cid:18)	(cid:2)(cid:9) (cid:8)(cid:9)(cid:2)	(cid:1)(cid:20)(cid:9) (cid:21)(cid:22)(cid:9)(cid:1)(cid:10)  (cid:1)(cid:22)(cid:9)(cid:18)
(cid:18)(cid:9)  (cid:8)(cid:21) (cid:10)(cid:18) (cid:18)(cid:9)(cid:1)(cid:20)(cid:9) (cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6)
(cid:11)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) (cid:6) (cid:11)(cid:9) (cid:1)(cid:2) (cid:9)(cid:9)	(cid:18)(cid:10)(cid:10)  (cid:1)(cid:16)(cid:9)	
 (cid:1)(cid:11)(cid:18)(cid:15) (cid:17)(cid:9) (cid:18)(cid:9)(cid:10)(cid:9) (cid:11)(cid:29) (cid:9) (cid:2)(cid:10) 	(cid:9)
(cid:30)(cid:10)(cid:30)(cid:1) (cid:1)(cid:1)(cid:2) (cid:1)(cid:6)(cid:9)(cid:9)(cid:2)(cid:9) (cid:1) (cid:31)(cid:18)(cid:1)(cid:1)(cid:10)   (cid:10)		
(cid:1)(cid:10) (cid:31)  (cid:27)(cid:10)(cid:11)(cid:1)(cid:2)(cid:10)  (cid:18)(cid:9)  (cid:10) (cid:9)(cid:2)(cid:1)(cid:10)  (cid:2)(cid:10)(cid:9)
(cid:6) (cid:8)(cid:21)  (cid:2)	(cid:9) (cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:10)
(cid:31)  (cid:18)(cid:9) (cid:15) (cid:17)(cid:9) (cid:10)  (cid:18)(cid:9)(cid:10)(cid:9) (cid:11)(cid:10) (cid:11)(cid:1)
(cid:10)(cid:10)(cid:2)(cid:11) (cid:2)(cid:10) "(cid:1)(cid:9) (cid:18) (cid:1) (cid:9) (cid:10)(cid:18) (cid:9)#(cid:9)(cid:2)(cid:1)(cid:20)(cid:9) (cid:10) (cid:27)	
(cid:1)(cid:11) (cid:6) (cid:2)	(cid:1)(cid:27) (cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:18)	
(cid:9)  (cid:29)(cid:1)(cid:11) (cid:1)(cid:9)(cid:18) (cid:10)(cid:10)(cid:9)(cid:9) (cid:10)(cid:18) (cid:1)  	(cid:10)(cid:9) (cid:11)(cid:1)
(cid:10)(cid:10)(cid:2)(cid:11)  (cid:2)(cid:11)(cid:10)(cid:1)(cid:2) $(cid:8)$ (cid:18)(cid:9) (cid:15)

(cid:7)

(cid:11)	(cid:6)(cid:13)

%(cid:11)(cid:9) (cid:2)	(cid:10)(cid:1) (cid:6) (cid:10)(cid:10)(cid:9)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:27)(cid:1)(cid:20)(cid:9) (cid:1)(cid:2)	
 (cid:9)(cid:9) (cid:18)(cid:10)(cid:10) (cid:1) (cid:10) (cid:1)(cid:10) (cid:9) (cid:1)  (cid:9)(cid:10)(cid:1)(cid:27) (cid:11)(cid:9) (cid:10)(cid:10)	
(cid:9)(cid:9) (cid:6) (cid:10) (cid:10)(cid:1)(cid:1)(cid:2)(cid:10)  (cid:18)(cid:9)  (cid:29)(cid:1)(cid:11) (cid:1)(cid:1)(cid:27) (cid:18)(cid:10)(cid:10)(cid:15)  (cid:10)	
(cid:1)(cid:2)	 (cid:10) (cid:6) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:30)(cid:10)(cid:9)(cid:18) (cid:1)(cid:1)’(cid:10)(cid:1) (cid:9)(cid:11)(cid:18) 	(cid:2)(cid:11)
(cid:10) (cid:11)(cid:9) (cid:2)(	(cid:27)(cid:10)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:9)(cid:11)(cid:18) (cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:1) 	(cid:9)(cid:18)
 (cid:1)(cid:9)(cid:10)(cid:1)(cid:20)(cid:9) " (cid:10)(cid:18)(cid:10) (cid:11)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) (cid:6) (cid:11)(cid:9) (cid:18)(cid:9)  (cid:1)
(cid:18)(cid:9)  (cid:1)(cid:20)(cid:9) (cid:11)(cid:9) (cid:1)(cid:2) (cid:9)(cid:9)	(cid:18)(cid:10)(cid:10)  (cid:1)(cid:16)(cid:9) (cid:1)(cid:11)(cid:18) (cid:10)(cid:18)
(cid:1) (cid:11)(cid:1) (cid:29)(cid:10)" (cid:1)(cid:18)(cid:9)(cid:1)(cid:6)" (cid:11)(cid:9) (cid:21)   (cid:2)(cid:10)  (cid:10)(cid:22)(cid:1)(cid:10) (cid:6) (cid:11)(cid:9)
(cid:1)(cid:2) (cid:9)(cid:9)	(cid:18)(cid:10)(cid:10)  (cid:1)(cid:16)(cid:9) (cid:1)(cid:11)(cid:18)(cid:15)

 (cid:11)(cid:1) (cid:10)(cid:9) (cid:29)(cid:9) (cid:18)(cid:9)(cid:1)(cid:20)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:10)
(cid:30)(cid:10)(cid:18) (cid:2) (cid:10) (cid:6) (cid:27)(cid:10)(cid:11)(cid:1)(cid:2)(cid:10)  (cid:18)(cid:9)  (cid:2)(cid:10)  (cid:9)(cid:18) (cid:9)(cid:2)	(cid:1)(cid:20)(cid:9) (cid:9)(cid:22)	
(cid:9)(cid:1)(cid:10)  (cid:1)(cid:22)(cid:9)(cid:18) (cid:18)(cid:9)  (cid:8)(cid:21)(cid:15) (cid:8)(cid:21) (cid:27)(cid:9)(cid:9)(cid:10) 	
(cid:1)’(cid:9) (cid:11)(cid:9) (cid:29)(cid:9)  	(cid:16)(cid:29) (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)   (cid:10)	(cid:1)(cid:10) (cid:31)  (cid:18)(cid:1)(cid:9)(cid:2)(cid:9)(cid:18)
(cid:27)(cid:10)(cid:11)(cid:1)(cid:2)(cid:10)  (cid:18)(cid:9)  (cid:1)(cid:18)	(cid:2)(cid:9)(cid:18) (cid:30)" (cid:10)	(cid:1)’(cid:9) (cid:10)(cid:18) (cid:17)(cid:9)	
	(cid:11) *+,+(cid:15) (cid:17)(cid:11)(cid:1) (cid:9) (cid:8)(cid:21) (cid:11)(cid:10)(cid:20)(cid:9) (cid:18)(cid:9)  (cid:1)(cid:27) (cid:10)(cid:18)(cid:20)(cid:10)	
(cid:10)(cid:27)(cid:9) (cid:20)(cid:9) (cid:31)  (cid:18)(cid:9)  (cid:9)(cid:15)(cid:27)(cid:15) (cid:10)  (cid:29)(cid:1)(cid:27) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9)
 (cid:11)(cid:10)(cid:20)(cid:9) (cid:2)(cid:1)		 (cid:10)(cid:9) 	 (cid:1)(cid:10)" (cid:1)(cid:20)(cid:10)(cid:1)
(cid:6) (cid:1)(cid:18)	(cid:2)(cid:1)(cid:27) (cid:8)(cid:21) (cid:1) (cid:11)(cid:1) (cid:10)(cid:9) (cid:1) (cid:10) (cid:10)   
(cid:18)(cid:9)(cid:1)(cid:20)(cid:9) (cid:11)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:31)  (cid:18)(cid:9) (cid:15)

(cid:31)  (cid:18)(cid:9)  (cid:10)(cid:9) (cid:10) (cid:1)(cid:10) (cid:2) (cid:10) (cid:6) (cid:27)(cid:10)(cid:11)(cid:1)(cid:2)(cid:10)  (cid:18)	
(cid:9) (cid:15) %(cid:11)(cid:9)" (cid:27)(cid:9)(cid:9)(cid:10) (cid:1)’(cid:9) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:10)(cid:18)  (cid:10)	(cid:1)(cid:10) -(cid:10)"(cid:9)(cid:1)(cid:10)
(cid:9)(cid:29)(cid:16) (cid:10)(cid:18) (cid:1)(cid:10) " (cid:11)(cid:9)" (cid:11)(cid:10)(cid:20)(cid:9) (cid:9)Æ(cid:2)(cid:1)(cid:9) (cid:9)(cid:22)(cid:10)(cid:2)
(cid:30)(cid:10)(cid:30)(cid:1) (cid:1)(cid:1)(cid:2) (cid:1)(cid:6)(cid:9)(cid:9)(cid:2)(cid:9) (cid:10) (cid:27)(cid:1)(cid:11) (cid:6) (cid:2)	(cid:1)(cid:27) (cid:2)	
(cid:18)(cid:1)(cid:1)(cid:10)  (cid:10)(cid:27)(cid:1)(cid:10)  (cid:30)(cid:10)(cid:30)(cid:1) (cid:1)(cid:1)(cid:9) (cid:10)	(cid:1)’(cid:9) (cid:10)(cid:18) (cid:9)(cid:9)

/00*(cid:15) (cid:17)(cid:9) (cid:18)(cid:9)(cid:1)(cid:20)(cid:9) (cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:1) (cid:6) (cid:11)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) (cid:27)(cid:10)	
(cid:18)(cid:1)(cid:9) (cid:1) (cid:31)  (cid:18)(cid:9)  (cid:10)(cid:18) (cid:18)(cid:9)(cid:10)(cid:9) (cid:11)(cid:10) (cid:10)(cid:18)(cid:10)(cid:18)
(cid:30)(cid:10)(cid:30)(cid:1) (cid:1)(cid:1)(cid:2) (cid:1)(cid:6)(cid:9)(cid:9)(cid:2)(cid:9) (cid:9)(cid:2)(cid:11)(cid:1)	(cid:9) (cid:2)(cid:10) (cid:30)(cid:9) 	(cid:9)(cid:18)  (cid:9)Æ	
(cid:2)(cid:1)(cid:9) " (cid:2)	(cid:9) (cid:11)(cid:9)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9)(cid:15)

(cid:17)(cid:9) (cid:10)  (cid:18)(cid:9)(cid:10)(cid:9) (cid:11)(cid:10) 	 (cid:10)(cid:10)(cid:2)(cid:11) (cid:2)(cid:10) "(cid:1)(cid:9) (cid:18) (cid:1)	
 (cid:9) (cid:10)(cid:18) (cid:9)#(cid:9)(cid:2)(cid:1)(cid:20)(cid:9) (cid:10) (cid:27)(cid:1)(cid:11) (cid:6) (cid:2)	(cid:1)(cid:27) (cid:10)(cid:10)(cid:9)(cid:9)
(cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:27)(cid:10)(cid:11)(cid:1)(cid:2)(cid:10)  (cid:18)(cid:9)  (cid:29)(cid:1)(cid:11) (cid:1)(cid:9)(cid:18) (cid:10)(cid:10)(cid:9)(cid:9)(cid:15)
(cid:17)(cid:9) (cid:1)  	(cid:10)(cid:9) 	 (cid:10)(cid:10)(cid:2)(cid:11)  (cid:11)(cid:10)(cid:18) (cid:1)(cid:27) (cid:1)(cid:9)(cid:18) (cid:10)(cid:10)(cid:9)(cid:9)
 (cid:2)(cid:11)(cid:10)(cid:1)(cid:2) $(cid:8)$ (cid:18)(cid:9)  %(cid:11)(cid:1)(cid:9) (cid:0) (cid:2) (cid:4) /002(cid:15)
%(cid:11)(cid:9) (cid:2)(cid:11)(cid:10)(cid:1)(cid:2) $(cid:8)$ (cid:18)(cid:9)  (cid:1) (cid:6) (cid:10)(cid:1)(cid:2)	 (cid:10) (cid:1)(cid:9)(cid:9)
(cid:30)(cid:9)(cid:2)(cid:10)	(cid:9) (cid:1) (cid:1) (cid:10) (cid:1) (cid:9) (cid:10)(cid:18) 	(cid:9)(cid:6)	  (cid:18)(cid:9)  (cid:6) (cid:18)(cid:9) (cid:1)(cid:27)
(cid:1)(cid:9)	(cid:9)(cid:1)(cid:9) (cid:18)(cid:10)(cid:10)(cid:15)

(cid:9)(cid:20)(cid:1)	 (cid:10)(cid:9) (cid:11)(cid:10)(cid:20)(cid:9) (cid:18)(cid:9)(cid:1)(cid:20)(cid:9)(cid:18) (cid:10)(cid:10)(cid:9)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6)
(cid:27)(cid:10)(cid:11)(cid:1)(cid:2)(cid:10)  (cid:18)(cid:9) (cid:15) 4 (cid:1)(cid:10)(cid:2)(cid:9) %(cid:11)(cid:1)(cid:9) *++5 (cid:10)(cid:18)
-(cid:1)(cid:18)(cid:9) (cid:0) (cid:2) (cid:4) *++5 (cid:18)(cid:9)(cid:1)(cid:20)(cid:9) (cid:11)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6)
(cid:27)(cid:9)(cid:9)(cid:10)  (cid:2) (cid:10)(cid:9) (cid:6) (cid:27)(cid:10)(cid:11)(cid:1)(cid:2)(cid:10)  (cid:18)(cid:9) (cid:15)  (cid:10)(cid:18)(cid:18)(cid:1)(cid:1) (cid:30)(cid:11)
%(cid:11)(cid:1)(cid:9) *++5 (cid:10)(cid:18) -(cid:1)(cid:18)(cid:9) (cid:0) (cid:2) (cid:4) *++5 (cid:18)(cid:9)(cid:10)(cid:9)
(cid:11)(cid:10) (cid:6) (cid:27)(cid:10)(cid:11)(cid:1)(cid:2)(cid:10)  (cid:18)(cid:9)  (cid:29)(cid:1)(cid:11)  " (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9)
(cid:9) (cid:2)(cid:10) (cid:2)	(cid:9) (cid:11)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) 	(cid:1)(cid:27) (cid:9)(cid:22)(cid:10)(cid:2)
(cid:30)(cid:10)(cid:30)(cid:1) (cid:1)(cid:1)(cid:2) (cid:1)(cid:6)(cid:9)(cid:9)(cid:2)(cid:9)(cid:15) -(cid:1)(cid:18)(cid:9) (cid:0) (cid:2) (cid:4) *++5 (cid:10)  (cid:18)(cid:1)	
(cid:2)	 (cid:2)	(cid:10)(cid:1) (cid:6) (cid:11)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:18)(cid:9) 
(cid:11)(cid:10) (cid:11)(cid:10)(cid:20)(cid:9) (cid:2)(cid:1)		 (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9)(cid:15) 4 	(cid:2)(cid:11) (cid:18)(cid:9)  (cid:11)(cid:9)"
(cid:9)  (cid:2)(cid:11)(cid:10)(cid:1)(cid:2) (cid:1)	 (cid:10)(cid:1)  (cid:2)	(cid:9) (cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)	
(cid:9)6 (cid:11)(cid:9)" (cid:18)  (cid:9)(cid:20)(cid:9) (cid:29)(cid:1)(cid:11) (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)   (cid:10)	(cid:1)(cid:10) (cid:18)(cid:9) 
(cid:6) (cid:29)(cid:11)(cid:1)(cid:2)(cid:11) (cid:9)(cid:22)(cid:10)(cid:2) (cid:30)(cid:10)(cid:30)(cid:1) (cid:1)(cid:1)(cid:2) (cid:1)(cid:6)(cid:9)(cid:9)(cid:2)(cid:9) (cid:10) (cid:27)(cid:1)(cid:11) (cid:9)(cid:22)	
(cid:1)(cid:15) 	 (cid:9)	  (cid:9)(cid:22)(cid:9)(cid:18) (cid:11)(cid:1) (cid:29)(cid:16) (cid:30)" (cid:18)(cid:9)(cid:10)(cid:1)(cid:27)
(cid:9)(cid:2)(cid:1)(cid:9) " (cid:11)(cid:29) (cid:9) (cid:2)(cid:10) 	(cid:9) (cid:30)(cid:10)(cid:30)(cid:1) (cid:1)(cid:1)(cid:2) (cid:1)(cid:6)(cid:9)(cid:9)(cid:2)(cid:9) 
(cid:2)	(cid:9) (cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:31)  (cid:27)(cid:10)(cid:11)(cid:1)(cid:2)(cid:10)  (cid:18)(cid:9) (cid:15)

(cid:14) (cid:15)(cid:16)(cid:6)	(cid:13)(cid:17)(cid:16) (cid:16)(cid:18)(cid:16)(cid:13)(cid:5)  (cid:13)(cid:18)(cid:16)(cid:11) (cid:11)(cid:16) 

(cid:17)(cid:9) (cid:2)(cid:1)(cid:18)(cid:9) (cid:18)(cid:1)(cid:9)(cid:2)(cid:9)(cid:18) (cid:27)(cid:10)(cid:11)(cid:1)(cid:2)(cid:10)  (cid:18)(cid:9)  (cid:29)(cid:1)(cid:11) (cid:30)(cid:11) (cid:18)(cid:1)	
(cid:2)(cid:9)(cid:9) (cid:10)(cid:18) (cid:2)(cid:1)		 (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9)(cid:15) 4 (cid:10) (cid:18)(cid:1)(cid:9)(cid:2)(cid:9)(cid:18) (cid:27)(cid:10)(cid:11)	
(cid:1)(cid:2)(cid:10)  (cid:18)(cid:9)  (cid:11)(cid:9) 	(cid:2)	(cid:10)  (cid:9) (cid:10)(cid:1) (cid:30)(cid:9)(cid:29)(cid:9)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9)
(cid:0) 8 (cid:0)(cid:0)(cid:0)(cid:0)(cid:1)  (cid:10)(cid:9) (cid:9)(cid:9)(cid:9)(cid:9)(cid:18) (cid:30)" (cid:10) (cid:18)(cid:1)(cid:9)(cid:2)(cid:9)(cid:18) (cid:10)(cid:2)"(cid:2) (cid:1)(cid:2)
(cid:27)(cid:10)(cid:11) 9$  (cid:29)(cid:11)(cid:9)(cid:9) (cid:9)(cid:10)(cid:2)(cid:11) (cid:18)(cid:9) (cid:1) (cid:9)(cid:9)(cid:9) (cid:10) (cid:20)(cid:10)(cid:1)	
(cid:10)(cid:30) (cid:9) (cid:0)(cid:0) (cid:10)(cid:18) (cid:18)(cid:1)(cid:9)(cid:2)(cid:9)(cid:18) (cid:9)(cid:18)(cid:27)(cid:9) (cid:9)(cid:9)(cid:9) (cid:18)(cid:1)(cid:9)(cid:2) (cid:1):	(cid:9)(cid:2)(cid:9)
(cid:6) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:9)(cid:9)(cid:9)(cid:9)(cid:18) (cid:30)" (cid:10)(cid:9) (cid:18)(cid:9) (cid:0)(cid:3)(cid:0)(cid:15)
(cid:10)(cid:16)(cid:20) (cid:9)(cid:1)(cid:9) (cid:29)(cid:1)(cid:11) (cid:9)(cid:9)(cid:2)  (cid:11)(cid:9) (cid:27)(cid:10)(cid:11) (cid:1)(cid:1)(cid:20)(cid:9)(cid:1)
<(cid:9)(cid:9)(cid:18) (cid:10)(cid:18) (cid:31)(cid:10) (cid:1) *+,26 (cid:10)	(cid:1)’(cid:9) (cid:0) (cid:2) (cid:4) *++0 (cid:1) "
(cid:11)(cid:10) (cid:10)" (cid:18)(cid:1)(cid:1)(cid:30)	(cid:1) (cid:29)(cid:11)(cid:1)(cid:2)(cid:11) (cid:1) 	(cid:2)	(cid:10)  " (cid:18)(cid:9)=(cid:9)(cid:18) (cid:30)"
(cid:10) 	(cid:2)(cid:11) (cid:18)(cid:9)  (cid:2)(cid:10) (cid:30)(cid:9) (cid:9)(cid:9)(cid:9)(cid:9)(cid:18) (cid:30)"  (cid:2)(cid:10)  (cid:2)(cid:18)(cid:1)(cid:1)(cid:10) 

341(cid:18)(cid:1)(cid:1)(cid:30)	(cid:1) (cid:0)(cid:0)(cid:0)(cid:0)(cid:3)(cid:0)(cid:15)
%(cid:11)(cid:1)(cid:9) *++5 (cid:18)(cid:9)=(cid:9) (cid:10) (cid:2) (cid:10) (cid:6) (cid:18)(cid:1)(cid:9)(cid:2)(cid:9)(cid:18) (cid:27)(cid:10)(cid:11)(cid:1)(cid:2)(cid:10) 
(cid:18)(cid:9)  (cid:2)(cid:10)  (cid:9)(cid:18) (cid:9)(cid:2)	(cid:1)(cid:20)(cid:9) (cid:9)(cid:22)(cid:9)(cid:1)(cid:10)  (cid:18)(cid:9)  (cid:8)(cid:21) (cid:6)
(cid:29)(cid:11)(cid:1)(cid:2)(cid:11) (cid:11)(cid:9) (cid:6)(cid:2)	 (cid:1)  (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9)(cid:15) (cid:17)(cid:9) (cid:9)(cid:22)(cid:9)(cid:18)
(cid:11)(cid:1) (cid:18)(cid:9)=(cid:1)(cid:1)  (cid:1)(cid:22)(cid:9)(cid:18) (cid:18)(cid:9)  (cid:29)(cid:1)(cid:11) (cid:30)(cid:11) (cid:2)(cid:1)		
(cid:10)(cid:18) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9)(cid:15) (cid:17)(cid:9) (cid:2)(cid:10)   (cid:11)(cid:1) (cid:2) (cid:10) (cid:6) (cid:18)(cid:9)  (cid:6)
(cid:0)(cid:6)	(cid:9)(cid:10)(cid:0) (cid:0)(cid:11)(cid:0)(cid:9)(cid:2)  (cid:9)(cid:11)(cid:0)(cid:16) (cid:16)(cid:0)  (cid:8)(cid:21)(cid:15)

-(cid:11) (cid:8)(cid:21) (cid:10)(cid:18) (cid:8)(cid:21) (cid:18)(cid:9)  (cid:10)	(cid:9) (cid:17) (cid:18)(cid:2)  (cid:10)(cid:2)(cid:9)(cid:2)(cid:9)
(cid:9)(cid:16)(cid:0)(cid:0)(cid:16)(cid:0)(cid:6)(cid:0) (cid:6) (cid:11)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) (cid:1) (cid:11)(cid:9) (cid:18)(cid:9) (cid:15) %(cid:11)(cid:10)
(cid:1)

(cid:0)(cid:0)(cid:0)(cid:0)(cid:3)(cid:0)(cid:4) (cid:3)(cid:0)(cid:4)

*

(cid:0)(cid:0)(cid:3) 8 (cid:0)(cid:0)(cid:0)(cid:1)

(cid:3)(cid:0)(cid:4) (cid:0) (cid:5)

(cid:29)(cid:11)(cid:9)(cid:9)  8 (cid:0)(cid:0)(cid:1) (cid:0) (cid:10)(cid:18) (cid:3)(cid:0) (cid:2) (cid:0) (cid:2) (cid:9)(cid:9) " (cid:9)(cid:2)(cid:1)	
=(cid:9) (cid:11)(cid:9) (cid:9) (cid:10)(cid:1)(cid:11)(cid:1) (cid:30)(cid:9)(cid:29)(cid:9)(cid:9) (cid:11)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:0)(cid:0) (cid:10)(cid:18) (cid:1)
(cid:2)(cid:18)(cid:1)(cid:1)(cid:10)  (cid:9) (cid:6) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:0)(cid:3)(cid:0)(cid:15)
4 (cid:1)(cid:22)(cid:9)(cid:18) (cid:18)(cid:9)  (cid:11)(cid:9) (cid:2)(cid:18)(cid:1)(cid:1)(cid:1)(cid:27) (cid:9) (cid:6) (cid:18)(cid:1)(cid:1)	
(cid:30)	(cid:1)  (cid:11)(cid:9) (cid:1)(cid:27)(cid:11)	(cid:11)(cid:10)(cid:18) (cid:1)(cid:18)(cid:9) (cid:6) * (cid:10)" (cid:11)(cid:10)(cid:20)(cid:9)
(cid:30)(cid:11) (cid:2)(cid:1)		 (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:18)(cid:9)(cid:9)(cid:18) (cid:0) (cid:4)
(cid:3)(cid:0) (cid:10)(cid:18) (cid:18)(cid:1)	
(cid:2)(cid:9)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:18)(cid:9)(cid:9)(cid:18) (cid:0) (cid:5)
(cid:3)(cid:0)(cid:15) %(cid:11)(cid:10) (cid:1) (cid:0)(cid:3)(cid:0) 8
(cid:0) (cid:4)
(cid:3)(cid:0)(cid:15) (cid:17)(cid:11)(cid:9) (cid:11)(cid:9) (cid:2)(cid:18)(cid:1)(cid:1)(cid:1)(cid:27) (cid:9) (cid:2)(cid:10)(cid:1)
(cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:8)(cid:21) (cid:18)(cid:9)  (cid:29)(cid:1)   (cid:1) (cid:10)(cid:18)(cid:18)(cid:1)(cid:1) (cid:10)	
	(cid:9) (cid:2)(cid:9)(cid:2)   (cid:6)(cid:2)  (cid:10)(cid:2)(cid:9)(cid:2)(cid:9) (cid:9)(cid:16)(cid:0)(cid:0)(cid:16)(cid:0)(cid:6)(cid:0) (cid:30)(cid:9)(cid:29)(cid:9)(cid:9) (cid:10)	
(cid:10)(cid:9)(cid:9) (cid:1) (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)  (cid:18)(cid:1)(cid:1)(cid:30)	(cid:1) (cid:29)(cid:1)(cid:11) (cid:18)(cid:1)#(cid:9)(cid:9) (cid:20)(cid:10) 	
	(cid:9) (cid:6) (cid:11)(cid:9) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:2)(cid:18)(cid:1)(cid:1)(cid:1)(cid:27) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9)(cid:15) (cid:9) (cid:5)
(cid:0) (cid:18)(cid:9)	
(cid:9) (cid:11)(cid:9) (cid:9) (cid:6) (cid:10)   (cid:2)=(cid:27)	(cid:10)(cid:1) (cid:6) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:10)(cid:9)
(cid:6) (cid:1) (cid:10)(cid:18)  (cid:9) (cid:5)(cid:5)
(cid:0) (cid:18)(cid:9)(cid:9) (cid:10) (cid:10)(cid:1)(cid:2)	 (cid:10) (cid:2)=(cid:27)	(cid:10)	
(cid:1)(cid:15) -" (cid:10)(cid:1)(cid:10)   (cid:2)(cid:10)  (cid:10)(cid:10)(cid:9)(cid:9) (cid:1)(cid:18)(cid:9)(cid:9)(cid:18)(cid:9)(cid:2)(cid:9) (cid:0) 8
(cid:6)(cid:0)
(cid:1) (cid:2) (cid:9)(cid:9) " (cid:18)(cid:9)=(cid:9)
(cid:1)  (cid:10)(cid:18) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)
(cid:11)(cid:9)  (cid:6)(cid:2)  (cid:16)(cid:0)  (cid:0)(cid:0)(cid:0)(cid:0) (cid:4)
(cid:1) (cid:15) (cid:1)(cid:2)(cid:9) (cid:11)(cid:10) (cid:1)(cid:6)
(cid:11)(cid:9) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:9) (cid:6) (cid:10)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:1) (cid:9)" (cid:11)(cid:9) (cid:11)(cid:9)
 (cid:2)(cid:10)  (cid:18)(cid:9)  (cid:0)(cid:0)(cid:0)(cid:0) (cid:4)
(cid:1)  8 (cid:0)(cid:0)(cid:0)(cid:0)(cid:3)(cid:0)(cid:4) (cid:3)(cid:0)(cid:15)
 (cid:9)(cid:2)(cid:9) (cid:8)(cid:21) (cid:18)(cid:9)  (cid:29)(cid:1)(cid:11)  " (cid:2)(cid:1)		 (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9)
(cid:29)(cid:1)    " (cid:9)	(cid:1)(cid:9) (cid:27) (cid:30)(cid:10)  (cid:10)(cid:10)(cid:9)(cid:9) (cid:1)(cid:18)(cid:9)(cid:9)(cid:18)(cid:9)(cid:2)(cid:9)(cid:15) 	
(cid:1)(cid:2)(cid:9) (cid:10)  (cid:11)(cid:10) (cid:1)(cid:6) (cid:10)   (cid:1)(cid:20) (cid:20)(cid:9)(cid:18) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:10)(cid:9) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:11)(cid:9)
(cid:10)(cid:1)(cid:10)   (cid:2)(cid:10)  (cid:10)(cid:10)(cid:9)(cid:9) (cid:1)(cid:18)(cid:9)(cid:9)(cid:18)(cid:9)(cid:2)(cid:9) (cid:1) (cid:11)(cid:9) (cid:10)(cid:9) (cid:10)  	
(cid:2)(cid:10)  (cid:10)(cid:10)(cid:9)(cid:9) (cid:1)(cid:18)(cid:9)(cid:9)(cid:18)(cid:9)(cid:2)(cid:9) (cid:10) (cid:18)(cid:9)=(cid:9)(cid:18) (cid:6) (cid:11)(cid:9) (cid:8)(cid:21)
(cid:18)(cid:9) (cid:15)

(cid:1) (cid:2) (cid:0)(cid:1)(cid:6)(cid:0)
(cid:3)(cid:0)(cid:4) (cid:5)(cid:5)

(cid:3)(cid:0)(cid:4) (cid:5)(cid:5)

(cid:0) (cid:2) (cid:5)

(cid:0) (cid:4) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1) (cid:0)(cid:0)

(cid:1) (cid:0)(cid:1)(cid:6)(cid:0)

(cid:0) (cid:4) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

 (cid:1)(cid:20)(cid:9) (cid:27) (cid:30)(cid:10)  (cid:10)(cid:18) (cid:10)(cid:1)(cid:10)   (cid:2)(cid:10)  (cid:10)(cid:10)(cid:9)(cid:9) (cid:1)(cid:18)(cid:9)(cid:9)(cid:18)(cid:9)(cid:2)(cid:9)
(cid:11)(cid:9)  (cid:1)(cid:16)(cid:9) (cid:1)(cid:11)(cid:18) (cid:6) (cid:10) (cid:1)(cid:27) (cid:9) (cid:30)(cid:9)(cid:20)(cid:10)(cid:1) (cid:6)(cid:10)(cid:2) (cid:1)  (cid:6)(cid:2) 
 (cid:9)(cid:19)(cid:0) (cid:9)(cid:20)(cid:16) (cid:10) (cid:6)  (cid:29)

(cid:6)(cid:0)(cid:3) 8 (cid:0)(cid:0)(cid:0)(cid:1)

(cid:6)(cid:0)(cid:0)(cid:6)(cid:3)(cid:0)(cid:4) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1) (cid:7)

4 (cid:10) (cid:8)(cid:21) (cid:11)(cid:9)  (cid:2)(cid:10)  (cid:18)(cid:9)  (cid:11)(cid:10)(cid:20)(cid:9)  (cid:30)(cid:9) (cid:9)(cid:9)	
(cid:9)(cid:10)(cid:30) (cid:9) (cid:10) (cid:9)(cid:27)	 (cid:10) (cid:9)(cid:22)(cid:9)(cid:1)(cid:10)  (cid:18)(cid:9) (cid:15)  (cid:9)(cid:2)(cid:9) (cid:10)  (cid:2)(cid:10) 
 (cid:1)(cid:16)(cid:9) (cid:1)(cid:11)(cid:18) (cid:1) (cid:9)(cid:9)(cid:9)(cid:9)(cid:18) (cid:10)

(cid:6)(cid:0)(cid:0)(cid:6)(cid:3)(cid:0)(cid:4) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)
(cid:1) 

8 (cid:8)(cid:6)(cid:0) (cid:9)(cid:22) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1) (cid:6)(cid:0)(cid:2)   (cid:10)(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

/

(cid:1)  (cid:4)

(cid:29)(cid:11)(cid:9)(cid:9) (cid:8) (cid:1) (cid:11)(cid:9) (cid:2)(cid:10)"(cid:1)(cid:27) (cid:18)(cid:9)(cid:1)"  (cid:11)(cid:9) (cid:2)(cid:10)(cid:1)(cid:2)(cid:10)  (cid:10)(cid:1)	
(cid:1)(cid:2) (cid:10) (cid:11)(cid:9) (cid:10) (cid:1)’(cid:10)(cid:1) (cid:6)	(cid:2)(cid:1) (cid:10)(cid:18) (cid:2) (cid:18)(cid:9)(cid:9) (cid:10)	
(cid:9)(cid:15) (cid:1)(cid:2)(cid:9) (cid:11)(cid:10) (cid:8)  (cid:10) (cid:10)(cid:9) (cid:9)(cid:2)(cid:1)=(cid:2)  (cid:11)(cid:9) (cid:18)(cid:1)(cid:1)	
(cid:30)	(cid:1) (cid:29)(cid:11)(cid:9)(cid:9) (cid:29)(cid:9) (cid:2)(cid:18)(cid:1)(cid:1)  (cid:11)(cid:9) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:10)(cid:9)
(cid:3)(cid:0) 8 (cid:5)(cid:5)
(cid:6)(cid:5)
(cid:0) (cid:15)

$ (cid:18)(cid:9)(cid:2)(cid:1)(cid:30)(cid:9)(cid:18) (cid:10)(cid:30)(cid:20)(cid:9) (cid:10) (cid:18)(cid:9)  (cid:1) (cid:10) (cid:8)(cid:21) (cid:1)(cid:6) (cid:1) (cid:1) (cid:18)(cid:9)	
=(cid:9)(cid:18) (cid:1) (cid:9) (cid:6)  (cid:2)(cid:10)  (cid:18)(cid:9)  (cid:9)(cid:9)(cid:9)(cid:9)(cid:18) (cid:10) (cid:9)(cid:27)	 (cid:10)
(cid:9)(cid:22)(cid:9)(cid:1)(cid:10)  (cid:18)(cid:9)  (cid:10)(cid:18) (cid:11)(cid:9) (cid:2)  (cid:9)(cid:2)(cid:1) (cid:6)  (cid:2)(cid:10)  (cid:18)(cid:9) 
(cid:10)(cid:1)(cid:6)" (cid:27) (cid:30)(cid:10)  (cid:10)(cid:18) (cid:10)(cid:1)(cid:10)   (cid:2)(cid:10)  (cid:20)(cid:10)(cid:1)(cid:10)(cid:1) (cid:1)(cid:18)(cid:9)(cid:9)(cid:18)(cid:9)(cid:2)(cid:9)(cid:15)
(cid:10)(cid:9) (cid:1) <(cid:9)(cid:2)(cid:1) B (cid:29)(cid:9) (cid:29)(cid:1)   (cid:9)(cid:9) (cid:11)(cid:10) (cid:11)(cid:9) (cid:10)	(cid:1) (cid:6)
(cid:20)(cid:10)(cid:1)(cid:10)(cid:1) (cid:1)(cid:18)(cid:9)(cid:9)(cid:18)(cid:9)(cid:2)(cid:9) (cid:2)(cid:10) (cid:9)(cid:10)(cid:1) " (cid:30)(cid:9) (cid:9) (cid:10)(cid:22)(cid:9)(cid:18)  (cid:10)  (cid:29)
(cid:10)(cid:10)(cid:9)(cid:9)  (cid:30)(cid:9) (cid:1)(cid:9)(cid:18) (cid:10)(cid:2)  (cid:2)(cid:10)  (cid:18)(cid:9) (cid:15)

(cid:14)(cid:15)(cid:16) (cid:8)(cid:17)(cid:4)(cid:4)(cid:18)  (cid:20)(cid:18)	(cid:4)(cid:18) (cid:17)(cid:5) 

%(cid:11)(cid:9) (cid:8)(cid:21) (cid:10)(cid:9) (cid:10)(cid:1)(cid:2)	 (cid:10) " (cid:18)(cid:9)(cid:1)(cid:27)(cid:9)(cid:18)  (cid:27)(cid:9)(cid:9)(cid:10) (cid:1)’(cid:9)
(cid:11)(cid:9) (cid:2) (cid:10) (cid:6) (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)   (cid:10)	(cid:1)(cid:10) (cid:31)  (cid:18)(cid:9)  (cid:1)	
(cid:18)	(cid:2)(cid:9)(cid:18) (cid:30)" (cid:10)	(cid:1)’(cid:9) (cid:10)(cid:18) (cid:17)(cid:9)	(cid:11) *+,+(cid:15) %(cid:11)(cid:9) (cid:31) 
(cid:18)(cid:9)  (cid:10)(cid:9) (cid:6) (cid:10)(cid:1)(cid:2)	 (cid:10) (cid:1)(cid:9)(cid:9) (cid:30)(cid:9)(cid:2)(cid:10)	(cid:9) (cid:29)(cid:9) (cid:2)(cid:10) (cid:10)
(cid:29)(cid:9) (cid:18)(cid:9)(cid:10)(cid:9) (cid:30)(cid:9) (cid:29) 	(cid:9) (cid:11)(cid:9) (cid:9)(cid:22)(cid:10)(cid:2) (cid:1)(cid:6)(cid:9)(cid:9)(cid:2)(cid:9) (cid:2)(cid:11)(cid:9)(cid:9)
(cid:6) (cid:10)	(cid:1)’(cid:9) (cid:10)(cid:18) (cid:9)(cid:9) /00*  (cid:9)Æ(cid:2)(cid:1)(cid:9) " (cid:2)	(cid:9)
(cid:11)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:11)(cid:9)(cid:9) (cid:18)(cid:9) (cid:15)

$ (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)   (cid:10)	(cid:1)(cid:10) (cid:18)(cid:1)(cid:9)(cid:2)(cid:9)(cid:18) (cid:27)(cid:10)(cid:11)(cid:1)(cid:2)(cid:10)  (cid:18)(cid:9)  (cid:1) (cid:10)
(cid:27)(cid:10)(cid:11)(cid:1)(cid:2)(cid:10)  (cid:18)(cid:9)  (cid:1) (cid:29)(cid:11)(cid:1)(cid:2)(cid:11) (cid:1) (cid:11)(cid:9) (cid:27)(cid:10)(cid:11)(cid:1)(cid:2)(cid:10)  9$  	(cid:2)	
	(cid:9) (cid:11)(cid:10)  (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:29)(cid:1)(cid:11) (cid:10) (cid:2)(cid:1)		 (cid:10)(cid:9)
(cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:1)(cid:1) (cid:11)(cid:9)  (cid:2)(cid:10)  (cid:18)(cid:9)  (cid:6) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:10)(cid:9)
(cid:18)(cid:9)=(cid:9)(cid:18) (cid:30)" (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)  	 (cid:1)(cid:1)(cid:10)  (cid:18)(cid:1)(cid:1)(cid:30)	(cid:1) (cid:11)(cid:10)
(cid:2)(cid:10) (cid:30)(cid:9) (cid:9)(cid:9)(cid:9)(cid:9)(cid:18) (cid:1) (cid:11)(cid:9) 		(cid:10)  (cid:29)(cid:10)" (cid:20)(cid:1)(cid:10) (cid:2)(cid:18)(cid:1)(cid:1)(cid:10) 
(cid:30)(cid:10)(cid:30)(cid:1) (cid:1)" (cid:10)(cid:30) (cid:9) (cid:10)(cid:18) (cid:1)(cid:1)(cid:1) (cid:11)(cid:9)  (cid:2)(cid:10)  (cid:18)(cid:9)  (cid:6) (cid:2)(cid:1)	
		 (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:27)(cid:1)(cid:20)(cid:9) (cid:2)(cid:1)		 (cid:10)(cid:18) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:10)(cid:9)
(cid:10)(cid:9) (cid:18)(cid:9)=(cid:18) (cid:30)" (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)   (cid:10)	(cid:1)(cid:10) (cid:9)(cid:27)(cid:9)(cid:1) C (cid:9)
(cid:6) (cid:9)(cid:10)(cid:2)(cid:11) (cid:2)=(cid:27)	(cid:10)(cid:1) (cid:6) (cid:20)(cid:10) 	(cid:9) (cid:6) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:10)(cid:9)(cid:15)
 (cid:10)(cid:1)(cid:2)	 (cid:10)

(cid:0)(cid:0)(cid:0)(cid:0) (cid:4)

(cid:3)(cid:0)(cid:4) (cid:5)(cid:5)

(cid:0) (cid:4) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)
(cid:1) 

(cid:4)  (cid:3)(cid:11)(cid:5)(cid:5)

(cid:0)   (cid:12)(cid:5)(cid:5)

(cid:0) (cid:0) (cid:4)

(cid:3)(cid:0)(cid:4) (cid:13)(cid:5)(cid:5)

(cid:0) (cid:4) (cid:7)

(cid:17)(cid:9) (cid:11)(cid:10)(cid:20)(cid:9) (cid:11)(cid:9)(cid:9) (cid:9)(cid:11)(cid:10)’(cid:1)(cid:9)(cid:18) (cid:11)(cid:10) (cid:11)(cid:9) (cid:1)(cid:9)(cid:2)(cid:9) (cid:6) (cid:11)(cid:9) (cid:9)	
(cid:27)(cid:9)(cid:1) (cid:11) (cid:11)(cid:9)  (cid:1)(cid:9)(cid:10) (cid:9)(cid:27)(cid:9)(cid:1) (cid:2)(cid:9)Æ(cid:2)(cid:1)(cid:9) (cid:12) (cid:10)(cid:18) (cid:11)(cid:9)
(cid:20)(cid:10)(cid:1)(cid:10)(cid:2)(cid:9) (cid:13) (cid:10)   (cid:18)(cid:9)(cid:9)(cid:18)  (cid:11)(cid:9) (cid:10)(cid:1)(cid:2)	 (cid:10) (cid:2)=(cid:27)	(cid:10)(cid:1)
(cid:6) (cid:11)(cid:9) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:10)(cid:9) (cid:5)(cid:5)
(cid:0) (cid:15) % (cid:1) (cid:1)(cid:6)" (cid:11)(cid:9) (cid:10)(cid:1)
(cid:1) (cid:29)(cid:11)(cid:10) (cid:6)  (cid:29) (cid:29)(cid:9) (cid:29)(cid:1)   (cid:18) (cid:11)(cid:1) (cid:9)(cid:22) (cid:1)(cid:2)(cid:1) (cid:18)(cid:9)(cid:9)(cid:18)(cid:9)(cid:2)(cid:9)(cid:15)

(cid:10)(cid:9) (cid:1) <(cid:9)(cid:2)(cid:1) 2(cid:15)/ (cid:10)(cid:18) 2(cid:15)E (cid:29)(cid:9) (cid:29)(cid:1)   (cid:9)(cid:9) (cid:11)(cid:10)  (cid:2)(cid:10) 
(cid:2)(cid:18)(cid:1)(cid:1)(cid:10)  	 (cid:1)(cid:1)(cid:10)  (cid:10)(cid:18) 	(cid:18)(cid:9)(cid:27)(cid:9)(cid:9)(cid:10)(cid:9)  	
(cid:1)(cid:1)(cid:20)(cid:9)  (cid:2)(cid:10)  (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)   (cid:10)	(cid:1)(cid:10) (cid:18)(cid:1)(cid:1)(cid:30)	(cid:1) (cid:2)(cid:10) (cid:30)(cid:9)
(cid:9)(cid:9)(cid:9)(cid:9)(cid:18) (cid:10) (cid:9)(cid:22)(cid:9)(cid:1)(cid:10)  (cid:18)(cid:9) (cid:15) $ (cid:31)  (cid:18)(cid:9)  (cid:10)	
	(cid:1)(cid:27) (cid:27) (cid:30)(cid:10)  (cid:10)(cid:18) (cid:10)(cid:1)(cid:10)   (cid:2)(cid:10)  (cid:10)(cid:10)(cid:9)(cid:9) (cid:1)(cid:18)(cid:9)(cid:9)	
(cid:18)(cid:9)(cid:2)(cid:9) (cid:1) (cid:11)(cid:9)(cid:9)(cid:6)(cid:9) (cid:10) (cid:8)(cid:21)(cid:15)

(cid:22) (cid:23)(cid:24)(cid:16) (cid:13)(cid:6) (cid:16)(cid:16)	(cid:11)(cid:5)(cid:5) (cid:26)(cid:5)(cid:11)(cid:13)(cid:16)

(cid:17)(cid:9) (cid:2)(cid:1)(cid:18)(cid:9) (cid:10) (cid:9) (cid:6) (cid:1)(cid:2) (cid:9)(cid:9) (cid:30)(cid:9)(cid:20)(cid:10)(cid:1) (cid:10)(cid:18) (cid:10)	
	(cid:9) (cid:11)(cid:10) (cid:11)(cid:9) (cid:30)(cid:9)(cid:20)(cid:10)(cid:1) (cid:10)(cid:9) (cid:1)(cid:2) (cid:9)(cid:9) (cid:1) (cid:10) 	
(cid:1)(cid:6)(cid:10)(cid:1)(cid:20)(cid:9) (cid:29)(cid:10)" (cid:9)(cid:15)(cid:27)(cid:15) (cid:1)(cid:1)(cid:27) (cid:10) (cid:10)(cid:18)6  (cid:9) (cid:10) (cid:0)
(cid:2) (cid:4) *++B(cid:15) (cid:9) (cid:23) 8 (cid:14)(cid:3)(cid:4) (cid:14)(cid:4)(cid:4) (cid:7) (cid:7) (cid:7) (cid:4) (cid:14) (cid:18)(cid:9)(cid:9) (cid:10) (cid:10) (cid:9)
(cid:6) (cid:1)(cid:30) " (cid:1)(cid:2) (cid:9)(cid:9) (cid:30)(cid:9)(cid:20)(cid:10)(cid:1) (cid:29)(cid:11)(cid:1)(cid:2)(cid:11) (cid:10)(cid:9) 			
(cid:10)  " (cid:1)(cid:18)(cid:9)(cid:9)(cid:18)(cid:9)(cid:15)  (cid:1)(cid:20)(cid:9) (cid:11)(cid:9) 		(cid:10)  (cid:1)(cid:18)(cid:9)(cid:9)(cid:18)(cid:9)(cid:2)(cid:9) (cid:11)(cid:9)
 (cid:1)(cid:16)(cid:9) (cid:1)(cid:11)(cid:18) (cid:6)(cid:10)(cid:2)(cid:1)’(cid:9) (cid:10) (cid:10) (cid:18)	(cid:2) (cid:20)(cid:9)  (cid:1)(cid:16)(cid:9) (cid:1)(cid:11)(cid:18) (cid:6)
(cid:9)(cid:10)(cid:2)(cid:11) (cid:30)(cid:9)(cid:20)(cid:10)(cid:1)

(cid:23)(cid:0)(cid:3) 8

(cid:14) (cid:0)(cid:3)(cid:7)



(cid:0) (cid:5)(cid:3)

342%(cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:11)(cid:9) (cid:10) (cid:9)  (cid:27)	 (cid:1)(cid:16)(cid:9) (cid:1)(cid:11)(cid:18) (cid:2)(cid:10) (cid:11)(cid:9)(cid:9)	
(cid:6)(cid:9) (cid:30)(cid:9) (cid:30)(cid:10)(cid:1)(cid:9)(cid:18) (cid:30)" (cid:1) " (cid:10)(cid:18)(cid:18)(cid:1)(cid:27) (cid:11)(cid:9) (cid:1)(cid:18)(cid:1)(cid:20)(cid:1)(cid:18)	(cid:10)  (cid:27)(cid:10)	
(cid:18)(cid:1)(cid:9) (cid:6) (cid:9)(cid:10)(cid:2)(cid:11) (cid:30)(cid:9)(cid:20)(cid:10)(cid:1)(cid:15) %(cid:11)(cid:10) (cid:1)

(cid:29)(cid:11)(cid:9)(cid:9)

(cid:18) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)  8

(cid:15)(cid:10)(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)
(cid:1) 
(cid:15)(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)

(cid:15)  (cid:27) (cid:23)(cid:0)(cid:3)

(cid:15)(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)

8



(cid:5) (cid:5)(cid:3)

(cid:15)  (cid:27) (cid:14) (cid:0)(cid:3)

(cid:15)(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)

(cid:7)

E

(cid:17)(cid:9) (cid:29)(cid:1)   (cid:1) (cid:11)(cid:9) (cid:9)(cid:22) (cid:9)(cid:2)(cid:1) (cid:18)(cid:9)(cid:1)(cid:20)(cid:9) (cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:9)(cid:22)(cid:9)	
(cid:1) (cid:6) (cid:10) (cid:1)(cid:27) (cid:9) (cid:30)(cid:9)(cid:20)(cid:10)(cid:1) (cid:16)(cid:29)(cid:1)(cid:27) (cid:11)(cid:10) (cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)	
(cid:9) (cid:6) (cid:10) (cid:10) (cid:9) (cid:2)(cid:10) (cid:30)(cid:9) (cid:30)(cid:10)(cid:1)(cid:9)(cid:18) (cid:30)" (cid:1) " (cid:10)(cid:18)(cid:18)(cid:1)(cid:27) 	
(cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:9)(cid:10)(cid:2)(cid:11) (cid:30)(cid:9)(cid:20)(cid:10)(cid:1) (cid:10) (cid:1) E(cid:15)

(cid:27) (cid:28)(cid:13)(cid:26) (cid:16) (cid:1)(cid:16)(cid:17)(cid:5)(cid:13) (cid:26)(cid:5)(cid:11)(cid:13)(cid:16)

<	(cid:9) (cid:6) (cid:10) (cid:27)(cid:1)(cid:20)(cid:9) (cid:18)(cid:9)  (cid:11)(cid:10) (cid:10) (cid:2) (cid:9)(cid:9) (cid:30)(cid:9)(cid:20)(cid:10)	
(cid:1) (cid:6) (cid:1)  " (cid:30)(cid:9)(cid:20)(cid:9)(cid:18) (cid:1)(cid:18)(cid:1)(cid:9)(cid:2) " (cid:11)	(cid:27)(cid:11) (cid:11)(cid:9) (cid:9)(cid:6)	
 (cid:0)(cid:0) (cid:30)(cid:9)(cid:20)(cid:10)(cid:1) (cid:14)(cid:15) 9(cid:9)(cid:9) (cid:30)" (cid:6) (cid:14) (cid:11)(cid:9) (cid:9) (cid:6) 	
(cid:1)(cid:30) (cid:9) (cid:2) (cid:9)(cid:1) (cid:11)(cid:10) (cid:10)(cid:9) (cid:30)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:30)" (cid:10)	(cid:27)(cid:9)(cid:1)(cid:27)
(cid:11)(cid:9) (cid:1)(cid:2) (cid:9)(cid:9) (cid:30)(cid:9)(cid:20)(cid:10)(cid:1) (cid:14)(cid:15) %(cid:11)(cid:9)  (cid:1)(cid:16)(cid:9) (cid:1)(cid:11)(cid:18) (cid:6) (cid:11)(cid:9)
(cid:1)(cid:2) (cid:9)(cid:9) (cid:30)(cid:9)(cid:20)(cid:10)(cid:1) (cid:11)(cid:9) (cid:30)(cid:9)(cid:2)(cid:9)

(cid:6)(cid:0)(cid:3)(cid:16)(cid:6)

(cid:14)(cid:0)(cid:3) 8 (cid:6)(cid:9)(cid:0)(cid:3) (cid:10)
8 (cid:6)(cid:9)(cid:0)(cid:3) (cid:10) (cid:0)(cid:0)(cid:0)(cid:1)

(cid:6)(cid:0)(cid:0)(cid:6)(cid:3)(cid:0)(cid:4) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1) (cid:16)(cid:6)(cid:4) 2

(cid:29)(cid:11)(cid:9)(cid:9) (cid:16) (cid:1) (cid:10) (cid:27)(cid:9)(cid:9)(cid:10) (cid:1)’(cid:9)(cid:18) (cid:9)(cid:10)	(cid:9) (cid:29)(cid:11)(cid:1)(cid:2)(cid:11) (cid:6) (cid:10) (cid:31) 
(cid:18)(cid:9)  (cid:1) (cid:10) (cid:10)(cid:1)(cid:10)(cid:9) (cid:2)(cid:30)(cid:1)(cid:10)(cid:1) (cid:6) (cid:11)(cid:9) (cid:2)	(cid:1)(cid:27)
(cid:9)(cid:10)	(cid:9) (cid:6) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:10)(cid:18) (cid:11)(cid:9) (cid:9)(cid:30)(cid:9)	(cid:9) (cid:9)(cid:10)	
	(cid:9) (cid:6) (cid:2)(cid:1)		 (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9)(cid:15)

%(cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:11)(cid:9)  (cid:27)	 (cid:1)(cid:16)(cid:9) (cid:1)(cid:11)(cid:18) (cid:2)(cid:10) (cid:29) (cid:30)(cid:9) (cid:9)(cid:22)	
(cid:9)(cid:9)(cid:18) (cid:10)

(cid:15)  (cid:27) (cid:14)(cid:0)(cid:3)

(cid:15)(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)

8

8

*

(cid:14)(cid:0)(cid:3)

(cid:15)(cid:14)(cid:0)(cid:3)
(cid:15)(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)

*

(cid:14)(cid:0)(cid:3)(cid:6)(cid:9)(cid:0)(cid:3) (cid:10)

(cid:15)(cid:6)(cid:0)(cid:3)
(cid:15)(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)

(cid:16)(cid:6)(cid:4) B

(cid:29)(cid:11)(cid:9)(cid:9) (cid:11)(cid:9)  (cid:10) (cid:9)	(cid:10) (cid:1)" (cid:6)  (cid:29) (cid:6) 2 (cid:10)(cid:18) (cid:30)" 	(cid:1)(cid:27)
(cid:9)(cid:1)(cid:30)(cid:1)’ 	 (cid:9) (cid:6) (cid:1)(cid:9)(cid:2)(cid:11)(cid:10)(cid:27)(cid:1)(cid:27) (cid:11)(cid:9) (cid:18)(cid:9) (cid:6) (cid:18)(cid:1)#(cid:9)(cid:9)	
(cid:1)(cid:10)(cid:1) (cid:10)(cid:18) (cid:1)(cid:9)(cid:27)(cid:10)(cid:1)(cid:15)

(cid:29) (cid:2)(cid:1)(cid:18)(cid:9) (cid:11)(cid:9)  (cid:2)(cid:10)  (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:11)(cid:9) (cid:2) (cid:9)(cid:9) (cid:30)	
(cid:9)(cid:20)(cid:10)(cid:1) (cid:6)(cid:15) %(cid:11)(cid:9) (cid:2)(cid:11)(cid:10)(cid:1) 	 (cid:9) (cid:6) (cid:18)(cid:1)#(cid:9)(cid:9)(cid:1)(cid:10)(cid:1) (cid:1) (cid:1)(cid:9)

(cid:15)(cid:6)(cid:0)(cid:3)
(cid:15)(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)

8

(cid:6)(cid:0)(cid:3)

(cid:15)(cid:6)(cid:0)(cid:0)(cid:6)(cid:3)(cid:0)(cid:4) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)
(cid:1) 

(cid:6)(cid:0)(cid:0)(cid:6)(cid:3)(cid:0)(cid:4) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)
(cid:1) 

(cid:15)(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)

8 (cid:6)(cid:0)(cid:3)

(cid:15)  (cid:27) (cid:6)(cid:0)(cid:0)(cid:6)(cid:3)(cid:0)(cid:4) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)
(cid:1) 

(cid:15)(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)

(cid:7)

G

%(cid:11)	 (cid:30)" (cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:1)(cid:10)  (cid:9)(cid:9)(cid:9)(cid:10)(cid:1) (cid:1) / (cid:11)(cid:9)
 (cid:2)(cid:10)  (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:10) (cid:2) (cid:9)(cid:9) (cid:30)(cid:9)(cid:20)(cid:10)(cid:1) (cid:30)(cid:9)(cid:2)(cid:9)

(cid:15)(cid:6)(cid:0)(cid:3)
(cid:15)(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)

8 (cid:6)(cid:0)(cid:3) (cid:6)(cid:0)

(cid:1) (cid:6)(cid:5)

(cid:3)(cid:0) (cid:6)(cid:0)   (cid:18) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)
(cid:1)  (cid:4)

5

(cid:1) (cid:6)(cid:5)

(cid:10)(cid:18)  (cid:6)(cid:0)
(cid:6) (cid:6)(cid:5)

(cid:3)(cid:0) 8 (cid:5)(cid:5)

(cid:0) (cid:10)(cid:18) ’(cid:9) (cid:11)(cid:9)(cid:29)(cid:1)(cid:9)(cid:15)

(cid:3)(cid:0) (cid:1) (cid:11)(cid:9) (cid:1)(cid:18)(cid:1)(cid:2)(cid:10) (cid:6)	(cid:2)(cid:1) (cid:29)(cid:11)(cid:1)(cid:2)(cid:11) (cid:1) (cid:9)

 (cid:1) (cid:10) (cid:29)(cid:9)  	(cid:16)(cid:29) (cid:6)(cid:10)(cid:2) (cid:6) (cid:9)(cid:22)(cid:9)(cid:1)(cid:10)  (cid:18)(cid:9)  (cid:11)(cid:9)"
(cid:11)(cid:10) (cid:11)(cid:9) (cid:18)(cid:9)(cid:1)(cid:20)(cid:10)(cid:1)(cid:20)(cid:9) (cid:6) (cid:11)(cid:9) (cid:10) (cid:1)’(cid:1)(cid:27) (cid:6)	(cid:2)(cid:1) (cid:9)	(cid:10) 
(cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:2)(cid:9)(cid:18) (cid:20)(cid:10) 	(cid:9) (cid:6) (cid:11)(cid:9) (cid:2)(cid:10)(cid:1)(cid:2)(cid:10)  (cid:10)(cid:1)(cid:1)(cid:2) (cid:9)(cid:9) (cid:9)(cid:15)(cid:27)(cid:15)
<(cid:2)(cid:11)(cid:9)(cid:20)(cid:1)(cid:11) *++B(cid:15) %(cid:11)(cid:10) (cid:1)

(cid:18) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)  8 (cid:24)(cid:11)(cid:1)(cid:0)(cid:2)(cid:0)

(cid:1)

H(cid:0)(cid:0)I(cid:7)

(cid:17)(cid:9) (cid:29)(cid:1)    (cid:10)(cid:9) 	(cid:9) (cid:11)(cid:1) (cid:6)(cid:10)(cid:2) (cid:29)(cid:11)(cid:9) (cid:18)(cid:9)(cid:1)(cid:20)(cid:1)(cid:27) (cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9)
(cid:6) (cid:9)(cid:2)(cid:1)=(cid:2) (cid:18)(cid:1)(cid:1)(cid:30)	(cid:1)(cid:15)

(cid:29) (cid:30)" (cid:1)(cid:9)(cid:1)(cid:27) 5 (cid:1) B (cid:29)(cid:9) (cid:27)(cid:9) (cid:11)(cid:9) (cid:6)  (cid:29)(cid:1)(cid:27)
(cid:9)(cid:22)(cid:9)(cid:1) (cid:6) (cid:11)(cid:9)  (cid:2)(cid:10)  (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:11)(cid:9) (cid:1)(cid:2) (cid:9)(cid:9) (cid:30)	
(cid:9)(cid:20)(cid:10)(cid:1)

(cid:15)  (cid:27) (cid:14)(cid:0)(cid:3)

(cid:15)(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)

8 (cid:6)(cid:9)(cid:0)(cid:3) (cid:10)

(cid:6)(cid:0)(cid:3)
(cid:14)(cid:0)(cid:3)

 (cid:6)(cid:0)

(cid:1) (cid:6)(cid:5)

(cid:3)(cid:0)

4(cid:1)(cid:10)  " (cid:30)" (cid:10) "(cid:1)(cid:27) (cid:11)(cid:9) (cid:6)(cid:10)(cid:2) (cid:11)(cid:10)

 (cid:6)(cid:0)   (cid:18) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)  (cid:16)(cid:6)(cid:7)

(cid:6)(cid:0)(cid:14)(cid:4) (cid:3) 8 (cid:9)(cid:1)(cid:11)

(cid:10)(cid:1)(cid:11)
0

(cid:6) (cid:6) (cid:2) (cid:6) (cid:14) (cid:10)(cid:18) (cid:14)(cid:0)(cid:3) (cid:19) 0
(cid:11)(cid:9)(cid:29)(cid:1)(cid:9)(cid:15)

(cid:29)(cid:9) (cid:30)(cid:10)(cid:1) (cid:11)(cid:9) =(cid:10)  (cid:9)(cid:22)(cid:9)(cid:1) (cid:6) (cid:11)(cid:9)  (cid:2)(cid:10)  (cid:27)(cid:10)(cid:18)(cid:1)(cid:9)

(cid:15)  (cid:27) (cid:14)(cid:0)(cid:3)

(cid:15)(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)

(cid:1) (cid:6)(cid:5)

(cid:3)(cid:0)

8 (cid:6) (cid:6)(cid:0)(cid:4)(cid:3)(cid:0)(cid:0)(cid:14)(cid:4) (cid:3) (cid:6)(cid:0)
 (cid:6)(cid:0)   (cid:18) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)
8 (cid:6) (cid:6)(cid:0)(cid:4) (cid:6)(cid:4)
 (cid:6)(cid:0)   (cid:18) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:3)(cid:0)(cid:4) (cid:5)(cid:5)

(cid:0) (cid:0)(cid:14)(cid:4) (cid:3)

(cid:1)  (cid:16)(cid:6)(cid:0)(cid:4)(cid:3)(cid:0)
(cid:1)  (cid:16)(cid:6)(cid:0)(cid:4) (cid:6)(cid:4)

(cid:1) (cid:6)(cid:5)

(cid:3)(cid:0) 8 (cid:5)(cid:5)

(cid:3)(cid:0) (cid:1) (cid:9) (cid:6) (cid:6)(cid:5)

(cid:3)(cid:0) ,
(cid:29)(cid:11)(cid:9)(cid:9) (cid:11)(cid:9)  (cid:10) (cid:9)	(cid:10)(cid:1) (cid:6)  (cid:29) (cid:6) (cid:1)(cid:9)(cid:27)(cid:10)(cid:1)(cid:27) (cid:20)(cid:9)
(cid:10)   (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:10)(cid:9) (cid:10)(cid:18) (cid:9)(cid:22) (cid:1)(cid:1)(cid:27) (cid:11)(cid:9) (cid:6)(cid:10)(cid:2) (cid:11)(cid:10)
 (cid:6)(cid:0)
(cid:0) (cid:10)(cid:18) ’(cid:9) (cid:11)(cid:9)(cid:29)(cid:1)(cid:9)(cid:15)
%(cid:11)(cid:9) (cid:1)(cid:2) (cid:9)(cid:9)	(cid:18)(cid:10)(cid:10)  (cid:27)	 (cid:1)(cid:16)(cid:9) (cid:1)(cid:11)(cid:18) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:9)(cid:22)(cid:9)	
(cid:1) (cid:1) , (cid:10) " (cid:6) (cid:10)"  (cid:2)(cid:10)  (cid:9)(cid:22)(cid:9)(cid:1)(cid:10)  (cid:18)(cid:9) (cid:15)
%(cid:11)(cid:1) (cid:27)(cid:9)(cid:9)(cid:10) (cid:1)" (cid:10)(cid:16)(cid:9) (cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:1) (cid:10)(cid:9)(cid:10) (cid:9)(cid:29)(cid:11)(cid:10)
(cid:2) (cid:1)(cid:2)(cid:10)(cid:9)(cid:18)(cid:15)  (cid:29)(cid:9)(cid:20)(cid:9) (cid:10) (cid:29)(cid:9) (cid:29)(cid:1)   (cid:9)(cid:9) (cid:30)(cid:9) (cid:29) (cid:1) <(cid:9)(cid:2)	
(cid:1) 2(cid:15)/ (cid:10)(cid:18) 2(cid:15)E (cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:1)(cid:10)  (cid:18)(cid:9)  (cid:9)(cid:22)(cid:9)(cid:1)
 (cid:9)(cid:10)(cid:18)  (cid:1) (cid:9) (cid:9)(cid:22)(cid:9)(cid:1) (cid:6) (cid:11)(cid:9) (cid:9) (cid:9)(cid:2)(cid:1)=(cid:2)  (cid:2)(cid:10) 
(cid:2)(cid:18)(cid:1)(cid:1)(cid:10)  	 (cid:1)(cid:1)(cid:10)  (cid:10)(cid:18) (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)   (cid:10)	(cid:1)(cid:10) (cid:1)
(cid:11)(cid:9) (cid:31)  (cid:18)(cid:9) (cid:15)

(cid:25)(cid:15)(cid:16) (cid:26)(cid:5)	(cid:18)(cid:18)(cid:5)(cid:5)(cid:4)(cid:28)(cid:18)(cid:4)

%(cid:11)(cid:9)  (cid:2)(cid:10)  (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:10) (cid:9)(cid:27)	 (cid:10) (cid:9)(cid:22)(cid:9)(cid:1)(cid:10)  (cid:18)(cid:9)  (cid:18)(cid:1)	
(cid:1)(cid:30)	(cid:1) (cid:1) (cid:10) (cid:9)  (cid:11)(cid:9) (cid:29)(cid:10)" (cid:1) (cid:18)(cid:9)(cid:1)(cid:20)(cid:1)(cid:27) (cid:11)(cid:9)  (cid:2)(cid:10)  (cid:27)(cid:10)	
(cid:18)(cid:1)(cid:9) (cid:6) (cid:11)(cid:9) (cid:9)(cid:2)(cid:1)=(cid:2)  (cid:2)(cid:10)  (cid:18)(cid:1)(cid:1)(cid:30)	(cid:1) (cid:1) (cid:31)  (cid:18)	
(cid:9) (cid:15) 4 (cid:11)(cid:9)(cid:9) (cid:9)(cid:2)(cid:1)=(cid:2) (cid:18)(cid:1)(cid:1)(cid:30)	(cid:1) (cid:29)(cid:9) (cid:29)(cid:1)   (cid:11)(cid:29)(cid:9)(cid:20)(cid:9)

343(cid:2)(cid:1)(cid:18)(cid:9) (cid:9)(cid:2)(cid:1)=(cid:2) (cid:10)(cid:18)(cid:10)(cid:18) 	(cid:9)(cid:22)(cid:9)(cid:1)(cid:10)  (cid:10)(cid:10)(cid:9)	
(cid:9)(cid:1)’(cid:10)(cid:1) (cid:10) (cid:29)(cid:9) (cid:29)(cid:1)   (cid:9)(cid:9) (cid:1) (cid:11)(cid:9) 	(cid:30)(cid:9)(cid:2)(cid:1) (cid:30)(cid:9) (cid:29)(cid:15) %
(cid:30)(cid:10)(cid:1) (cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:29)(cid:1)(cid:11) (cid:9)(cid:9)(cid:2)  (cid:10) (cid:9)(cid:29) (cid:10)(cid:10)(cid:9)(cid:9)	
(cid:1)’(cid:10)(cid:1) (cid:20) (cid:29)(cid:9) (cid:10) " (cid:11)(cid:9) (cid:2)(cid:11)(cid:10)(cid:1) 	 (cid:9) (cid:10)(cid:18) 	 (cid:1) " (cid:11)(cid:9)
(cid:18)(cid:9)(cid:1)(cid:20)(cid:10)(cid:1)(cid:20)(cid:9) (cid:1) 5 (cid:30)" (cid:11)(cid:9) (cid:10)(cid:2)(cid:30)(cid:1)(cid:10) (cid:15)(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)
(cid:1) (cid:21)(cid:15)(cid:20)(cid:15) 9(cid:1)(cid:27)
 (cid:29)(cid:9) (cid:30)(cid:10)(cid:1)

(cid:15)(cid:6)(cid:0)(cid:20)

(cid:15)(cid:20)

8

(cid:15)(cid:6)(cid:0)(cid:3)
(cid:15)(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)

(cid:15)(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)

(cid:15)(cid:20)

8 (cid:6)(cid:0)(cid:3) (cid:6)(cid:0)

(cid:1) (cid:6)(cid:5)

(cid:3)(cid:0)

 (cid:6)(cid:0)   (cid:18) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)
(cid:1) 

(cid:15)(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)

(cid:15)(cid:20)

(cid:7)

(cid:9)(cid:6)(cid:1)(cid:27) (cid:11)(cid:9) (cid:10)(cid:9) (cid:9)(cid:10)(cid:1) (cid:11)(cid:10)  (cid:9)(cid:10)(cid:18) (cid:6) 5 
, (cid:1) (cid:1)(cid:20)(cid:1)(cid:10)  (cid:10)(cid:18) (cid:29)(cid:9) =(cid:10)  " (cid:30)(cid:10)(cid:1) (cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:1) (cid:6)
(cid:11)(cid:9)  (cid:2)(cid:10)  (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:11)(cid:9) (cid:1)(cid:2) (cid:9)(cid:9)	(cid:18)(cid:10)(cid:10)  (cid:27)	 (cid:1)(cid:16)(cid:9) (cid:1)(cid:11)(cid:18)
(cid:29)(cid:1)(cid:11) (cid:9)(cid:9)(cid:2)  (cid:11)(cid:9) (cid:9)	(cid:10)(cid:10)(cid:9)(cid:9)(cid:1)’(cid:10)(cid:1)

(cid:15)  (cid:27) (cid:14)(cid:0)(cid:20)

(cid:15)(cid:20)

8 (cid:6) (cid:6)(cid:0)(cid:4) (cid:6)(cid:4)

(cid:3)(cid:0)(cid:4) (cid:5)(cid:5)

(cid:0) (cid:0)(cid:14)(cid:4) (cid:3)

 (cid:6)(cid:0)   (cid:18) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)
(cid:1) 

(cid:15)(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)

(cid:15)(cid:20)

(cid:16)(cid:6)(cid:0)(cid:4) (cid:6)(cid:4)

(cid:3)(cid:0)(cid:7)+

(cid:25)(cid:15)(cid:14) (cid:8)(cid:17)(cid:4)(cid:4)(cid:18)  	 (cid:4)(cid:4)(cid:18)   (cid:29)(cid:18)  (cid:30)(cid:18)(cid:17)(cid:4)(cid:5)

(cid:9) 	 (cid:29) (cid:10)(cid:16)(cid:9) (cid:10)  (cid:16) (cid:10) (cid:11)(cid:9)  (cid:2)(cid:10)  (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:11)(cid:9) (cid:29)
(cid:9)(cid:2)(cid:1)=(cid:2) "(cid:9) (cid:6)  (cid:2)(cid:10)  (cid:18)(cid:1)(cid:1)(cid:30)	(cid:1) (cid:1) (cid:10) (cid:31)  (cid:18)(cid:9) (cid:15)
4(cid:1) (cid:2)(cid:1)(cid:18)(cid:9) (cid:10) (cid:6)(cid:16)(cid:9)(cid:9)(cid:2)  	 (cid:9)(cid:9)(cid:2)  (cid:18)(cid:1)(cid:1)(cid:30)	(cid:1)
(cid:6) (cid:0)(cid:0)(cid:0)(cid:5)(cid:5)
(cid:0) (cid:15) $ (cid:18)(cid:9)(cid:10)(cid:9)(cid:18) (cid:1) %(cid:11)(cid:1)(cid:9) *++5
(cid:29)(cid:9) (cid:2)(cid:10) (cid:30)(cid:10)(cid:1) (cid:10) (cid:9)(cid:22)(cid:9)(cid:1)(cid:10)  (cid:18)(cid:9)  (cid:9)(cid:9)(cid:9)(cid:10)(cid:1) (cid:6)
(cid:11)(cid:1) (cid:18)(cid:1)(cid:1)(cid:30)	(cid:1) (cid:10) (cid:6)  (cid:29)(cid:15) (cid:9) (cid:6) (cid:18)(cid:9)(cid:9) (cid:10) (cid:20)(cid:10) 	(cid:9) (cid:6)
(cid:9)(cid:6)(cid:9)(cid:9)(cid:2)(cid:9) (cid:6) (cid:11)(cid:9) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:0)(cid:0) (cid:10)(cid:18)  (cid:9)  8
*(cid:4) (cid:7) (cid:7) (cid:7) (cid:4) (cid:23) (cid:30)(cid:9) (cid:11)(cid:9) (cid:9)(cid:10)(cid:1)(cid:1)(cid:27) (cid:1)(cid:30) (cid:9) (cid:20)(cid:10) 	(cid:9) (cid:6) (cid:0)(cid:0)(cid:15)
(cid:6)
(cid:29)(cid:9) (cid:2)(cid:11)(cid:9) (cid:6) (cid:10) (cid:10)" (cid:20)(cid:10) 	(cid:9) (cid:6) (cid:29)(cid:11)(cid:1)(cid:2)(cid:11) (cid:6)(cid:0)(cid:5)(cid:5)
(cid:0)  (cid:19) 0 (cid:29)(cid:9)
(cid:2)(cid:10) (cid:9)(cid:9)(cid:9) (cid:11)(cid:9) (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)  	 (cid:1)(cid:1)(cid:10)  (cid:18)(cid:1)(cid:1)(cid:30)	(cid:1)
(cid:30)" (cid:10) (cid:9)(cid:22)(cid:9)(cid:1)(cid:10)  (cid:18)(cid:9)  (cid:29)(cid:1)(cid:11) (cid:30)(cid:10)(cid:30)(cid:1) (cid:1)(cid:1)(cid:9) (cid:6) (cid:11)(cid:9) (cid:6)
/ (cid:30)"  (cid:9)(cid:1)(cid:27)

(cid:0) (cid:21)(cid:6)(cid:0)(cid:5)(cid:5)
(cid:6) (cid:6)(cid:0) 8 
(cid:11)(cid:9)(cid:29)(cid:1)(cid:9)

0

(cid:3) 8  (cid:27)(cid:0)(cid:5)(cid:5)
(cid:6)(cid:0) 8(cid:10) *
(cid:1)  8  (cid:27)(cid:11)
(cid:12)* 

(cid:10)(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:8)(cid:6)(cid:0) 8 *

(cid:0) 
(cid:9)(cid:22)(cid:3) (cid:13)
(cid:14)

(cid:13)

(cid:5)(cid:5)(cid:3)

(cid:1)

(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:3)(cid:3)(cid:4) (cid:7) (cid:7) (cid:7) (cid:4) (cid:3)(cid:13)

8
(cid:29)(cid:11)(cid:9)(cid:9)
(cid:3)(cid:6)(cid:0)(cid:4) (cid:7) (cid:7) (cid:7) (cid:4) (cid:13)(cid:6)(cid:0)(cid:15)
%(cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:2)(cid:9)(cid:18) (cid:20)(cid:10) 	(cid:9) (cid:6) (cid:11)(cid:9) (cid:2)(cid:10)(cid:1)(cid:2)(cid:10)  (cid:10)(cid:1)(cid:1)(cid:2) (cid:1) (cid:11)(cid:9)
(cid:10)(cid:30)(cid:20)(cid:9) (cid:9)(cid:22)(cid:9)(cid:1)(cid:10)  (cid:18)(cid:9)  (cid:9)(cid:9)(cid:9)(cid:10)(cid:1) (cid:1)

(cid:6)(cid:0)

(cid:10)(cid:18)

8

(cid:18) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)  8 (cid:24)(cid:11)(cid:1)(cid:0)(cid:2)(cid:0)

(cid:1)

H(cid:0)(cid:0)I

(cid:6)(cid:0)(cid:6)(cid:0)(cid:0)(cid:6)(cid:3)(cid:0)(cid:4) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)
(cid:1) 

8 (cid:5)(cid:9)(cid:1)
8  (cid:3)(cid:4) (cid:7) (cid:7) (cid:7) (cid:4) (cid:13)

(cid:1) (cid:15)

(cid:0) (cid:4) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:29)(cid:11)(cid:9)(cid:9)  8 (cid:0)(cid:0) 8 (cid:0)(cid:5)(cid:5)
(cid:17)(cid:9) =(cid:10)  " (cid:30)(cid:10)(cid:1) (cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:1) (cid:6) (cid:11)(cid:9)  (cid:2)(cid:10)  (cid:27)(cid:10)(cid:18)(cid:1)(cid:9)
(cid:29)(cid:1)(cid:11) (cid:9)(cid:9)(cid:2)  (cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:1)(cid:10)  (cid:18)(cid:9)  (cid:10)(cid:10)(cid:9)(cid:9)(cid:1)’(cid:10)	
(cid:1) (cid:30)" (cid:1)(cid:9)(cid:1)(cid:27) (cid:11)(cid:9) (cid:10)(cid:30)(cid:20)(cid:9) (cid:9)(cid:22)(cid:9)(cid:1) (cid:6) (cid:6)(cid:0) (cid:10)(cid:18)
(cid:18) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)
(cid:1)  (cid:1) (cid:9)	(cid:10)(cid:1) ,(cid:15) %(cid:11)(cid:9) (cid:9) (cid:9)(cid:9) (cid:6) (cid:11)(cid:1) (cid:20)(cid:9)(cid:2)
(cid:10)(cid:9)

(cid:15)  (cid:27) (cid:14)(cid:0)(cid:3)

(cid:15)(cid:3)

8 (cid:6) (cid:6)(cid:0)(cid:4) (cid:5)(cid:5)

(cid:0) (cid:0)(cid:14)(cid:4) (cid:3)(cid:6)(cid:0)(cid:16)(cid:6)(cid:0)

(cid:0)(cid:0)(cid:14)(cid:4) (cid:3) (cid:16)(cid:6)(cid:0)

8 (cid:4) (cid:5)(cid:5)

 (cid:6) (cid:6)(cid:0)(cid:4) (cid:5)(cid:5)

(cid:0) (cid:0)(cid:14)(cid:4) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)
(cid:1) 
 (cid:5)(cid:5)

(cid:0) (cid:0)(cid:14)(cid:4) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1) (cid:0)(cid:5)(cid:5)

(cid:0) (cid:4) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1) (cid:7) *0

(cid:17)(cid:9) (cid:2)(cid:10) (cid:29) 	(cid:9) (cid:11)(cid:9) (cid:10)	(cid:1)’(cid:9) (cid:10)(cid:18) (cid:9)(cid:9) /00* 	
(cid:10)(cid:27)(cid:10)(cid:1) (cid:2)(cid:11)(cid:9)(cid:9) (cid:6) -(cid:10)"(cid:9)(cid:1)(cid:10) (cid:9)(cid:29)(cid:16) (cid:29)(cid:1)(cid:11) (cid:31)  (cid:18)(cid:1)(cid:1)	
(cid:30)	(cid:1)  (cid:9)Æ(cid:2)(cid:1)(cid:9) " (cid:2)	(cid:9) (cid:11)(cid:9) 	(cid:10)(cid:1)(cid:1)(cid:9) (cid:1) *0(cid:15)
%(cid:11)(cid:9) (cid:10)(cid:27)(cid:10)(cid:1) (cid:2)(cid:11)(cid:9)(cid:9) (cid:9)(cid:10)(cid:30) (cid:9) 	  (cid:9)Æ(cid:2)(cid:1)(cid:9) " (cid:2)	
	(cid:9) (cid:9)(cid:1) (cid:10)(cid:27)(cid:1)(cid:10)  (cid:18)(cid:1)(cid:1)(cid:30)	(cid:1) (cid:6) (cid:10)" (cid:6)(cid:10)(cid:1) "
(cid:0)(cid:0)(cid:4)(cid:3)(cid:0) (cid:27)(cid:1)(cid:20)(cid:9) (cid:9)(cid:20)(cid:1)(cid:18)(cid:9)(cid:2)(cid:9) (cid:14)(cid:15) %(cid:11)(cid:1) (cid:10)(cid:27)(cid:1)(cid:10)  (cid:18)(cid:1)(cid:1)(cid:30)		
(cid:1) (cid:1) (cid:9)(cid:9)(cid:9)(cid:9)(cid:18) (cid:10) (cid:11)(cid:9) (cid:18)	(cid:2) (cid:6) (cid:10) (cid:10)(cid:27)(cid:1)(cid:10)  (cid:18)(cid:1)(cid:1)	
(cid:30)	(cid:1) (cid:6) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:10)(cid:18) (cid:10) (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)   (cid:10)		
(cid:1)(cid:10) (cid:6) (cid:2)(cid:1)		 (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:27)(cid:1)(cid:20)(cid:9) (cid:11)(cid:9) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:20)(cid:10)(cid:1)	
(cid:10)(cid:30) (cid:9)(cid:15) %(cid:11)(cid:9) (cid:9)(cid:1) (cid:30)(cid:10)(cid:30)(cid:1) (cid:1)(cid:1)(cid:9) (cid:4) (cid:5)(cid:5)
(cid:0) (cid:0)(cid:14)(cid:4) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)
(cid:1) 
(cid:10)(cid:18) (cid:5)(cid:5)
(cid:1)  (cid:2)(cid:10) (cid:11)(cid:9)(cid:9)(cid:6)(cid:9) (cid:9)(cid:10)(cid:1) " (cid:30)(cid:9) (cid:9)(cid:22)(cid:10)(cid:2)(cid:9)(cid:18)
(cid:6) (cid:11)(cid:9) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:10)(cid:27)(cid:1)(cid:10)  (cid:18)(cid:1)(cid:1)(cid:30)	(cid:1) (cid:10)(cid:18) (cid:11)(cid:9)(cid:2)(cid:9)
(cid:10) (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)  	 (cid:1)(cid:1)(cid:10)   (cid:2)(cid:10)  (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:2)(cid:10) (cid:30)(cid:9) (cid:9)Æ	
(cid:2)(cid:1)(cid:9) " (cid:2)	(cid:9)(cid:18)(cid:15)

(cid:0) (cid:0)(cid:14)(cid:4) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

%(cid:11)(cid:9) (cid:10)	(cid:1)’(cid:9) (cid:10)(cid:18) (cid:9)(cid:9) /00* (cid:10)(cid:27)(cid:10)(cid:1) (cid:2)(cid:11)(cid:9)(cid:9)
	(cid:1) (cid:1)’(cid:9) (cid:11)(cid:9) (cid:10)(cid:18)(cid:1)(cid:1)(cid:10)  (cid:10)(cid:10)(cid:9)(cid:9)(cid:1)’(cid:10)(cid:1) (cid:6) (cid:11)(cid:9) (cid:2)	
(cid:18)(cid:1)(cid:1)(cid:10)  	 (cid:1)(cid:1)(cid:10)  (cid:18)(cid:1)(cid:1)(cid:30)	(cid:1)(cid:15) %(cid:11)(cid:1) (cid:9)(cid:9)(cid:9)(cid:10)(cid:1)
(cid:1) (cid:27)(cid:1)(cid:20)(cid:9) (cid:30)" (cid:11)(cid:9) (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)  (cid:30)(cid:10)(cid:30)(cid:1) (cid:1)(cid:1)(cid:9) (cid:6)(cid:4)    (cid:4) (cid:13)
(cid:29)(cid:11)(cid:9)(cid:9) (cid:6) 8 (cid:0)(cid:0) 8 (cid:6)(cid:0)(cid:5)(cid:5)
(cid:1)  (cid:10)(cid:18)  (cid:1) (cid:18)(cid:9)=(cid:9)(cid:18)
(cid:10) (cid:10)(cid:30)(cid:20)(cid:9)(cid:15)  (cid:9)(cid:2)(cid:9) (cid:10)(cid:6)(cid:9) (cid:29)(cid:9) 	(cid:18)(cid:10)(cid:9) (cid:11)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) (cid:6)
(cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:1)(cid:10)  (cid:18)(cid:9)  (cid:9)(cid:9)(cid:9)(cid:10)(cid:1) (cid:18)	(cid:1)(cid:27) (cid:11)(cid:9)  (cid:1)(cid:9)	
(cid:9)(cid:10)(cid:2)(cid:11) (cid:1) (cid:10) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:30)(cid:10)(cid:9)(cid:18) (cid:1)(cid:1)’(cid:10)(cid:1) (cid:9)(cid:11)(cid:18) (cid:29)(cid:9)
(cid:29)(cid:1)   (cid:9)(cid:9)(cid:18)  (cid:29)(cid:1)(cid:2)(cid:11) (cid:30)(cid:10)(cid:2)(cid:16) (cid:1) (cid:11)(cid:9) (cid:10)(cid:18)(cid:1)(cid:1)(cid:10)  (cid:9)(cid:9)(cid:9)	
(cid:10)(cid:1) C 	(cid:1)(cid:27) / C (cid:1) (cid:18)(cid:9)  	(cid:9) (cid:11)(cid:9) (cid:10)(cid:27)(cid:10)(cid:1)
(cid:2)(cid:11)(cid:9)(cid:9)  (cid:2)	(cid:9) (cid:11)(cid:9) (cid:9)(cid:22) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9)(cid:15)

(cid:0) (cid:4) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

<(cid:29)(cid:1)(cid:2)(cid:11)(cid:1)(cid:27) (cid:30)(cid:9)(cid:29)(cid:9)(cid:9) (cid:9)(cid:9)(cid:9)(cid:10)(cid:1) (cid:11)(cid:10) (cid:10) (cid:1) (cid:2)	
	(cid:10)(cid:1)(cid:10)  (cid:2)(cid:15)  (cid:11)(cid:9) (cid:11)(cid:9) (cid:11)(cid:10)(cid:18) (cid:9)(cid:6)(cid:1)(cid:27) (cid:11)(cid:9)
(cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:1)(cid:1)’(cid:10)(cid:1) (cid:6) (cid:10)(cid:10)(cid:9)(cid:9) (cid:1) (cid:11)(cid:9) (cid:9)(cid:22)(cid:9)	
(cid:1)(cid:10)  (cid:18)(cid:9)  (cid:9)(cid:9)(cid:9)(cid:10)(cid:1) (cid:11)(cid:10) (cid:11)(cid:9) (cid:30)(cid:9)(cid:9)= (cid:11)(cid:10) (cid:11)(cid:1) (cid:10)	
(cid:10)(cid:9)(cid:9)(cid:1)’(cid:10)(cid:1) (cid:10)	(cid:10)(cid:1)(cid:2)(cid:10)  " (cid:9)(cid:6)(cid:2)(cid:9) (cid:11)(cid:9) (cid:2)(cid:10)(cid:1)

 (cid:8) 0 (cid:10)(cid:18)   8 * (cid:29)(cid:11)(cid:1)(cid:2)(cid:11) (cid:1)  (cid:11)(cid:9) (cid:2)(cid:10)(cid:9) (cid:6) (cid:27)(cid:10)(cid:18)(cid:1)	

(cid:9) (cid:1)(cid:1)’(cid:10)(cid:1) 	(cid:1)(cid:27) (cid:11)(cid:9) (cid:10)(cid:18)(cid:1)(cid:1)(cid:10)  (cid:10)(cid:10)(cid:9)(cid:9)(cid:15)

(cid:17)(cid:9) (cid:2)(cid:1)(cid:18)(cid:9) (cid:9)(cid:22) (cid:11)(cid:9) (cid:10) (cid:9)(cid:10)(cid:1)(cid:20)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:11)(cid:9) (cid:10)	
(cid:18)(cid:1)(cid:1)(cid:10)  (cid:10)(cid:10)(cid:9)(cid:9) (cid:9)(cid:9)(cid:9)(cid:10)(cid:1)(cid:15)  (cid:18)(cid:9)  (cid:18)(cid:9)(cid:1)(cid:20)(cid:9)
(cid:11)(cid:1) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:29)(cid:9) = (cid:18)(cid:9)(cid:1)(cid:20)(cid:9) (cid:11)(cid:9) (cid:10)(cid:2)(cid:30)(cid:1)(cid:10) (cid:6) (cid:11)(cid:9) (cid:9)(cid:22)	

344(cid:9)(cid:1)(cid:10)  (cid:18)(cid:9)  (cid:9)(cid:9)(cid:9)(cid:10)(cid:1)  (cid:11)(cid:9) (cid:10)(cid:18)(cid:1)(cid:1)(cid:10)  (cid:30)	
(cid:10)(cid:30)(cid:1) (cid:1)" (cid:10)(cid:10)(cid:9)(cid:9)(cid:1)’(cid:10)(cid:1)

(cid:15)(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)

(cid:15)(cid:6)(cid:4)    (cid:4) (cid:13)

 *(cid:21)(cid:6)

*(cid:21)(cid:3)

 *(cid:21)(cid:6)

0

0
(cid:15)(cid:15)(cid:15)
(cid:7) (cid:7) (cid:7)

(cid:7) (cid:7) (cid:7)

0

0

*(cid:21)(cid:13)

8 (cid:16)
(cid:17)(cid:18)

(cid:7)

(cid:19)
(cid:20)(cid:21)

-" (cid:1)(cid:9)(cid:1) (cid:1) (cid:9)	(cid:10)(cid:1) + (cid:29)(cid:9) (cid:29) (cid:30)(cid:10)(cid:1) (cid:11)(cid:9)  (cid:2)(cid:10) 
(cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:29)(cid:1)(cid:11) (cid:9)(cid:9)(cid:2)  (cid:11)(cid:9) (cid:10)(cid:18)(cid:1)(cid:1)(cid:10)  (cid:9)(cid:9)(cid:9)(cid:10)(cid:1)(cid:15)
%(cid:11)(cid:9) (cid:15)  8 0(cid:4) (cid:7) (cid:7) (cid:7) (cid:4) (cid:23) (cid:9) (cid:9)(cid:9) (cid:1) (cid:11)(cid:1) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:1) (cid:27)(cid:1)(cid:20)(cid:9)
(cid:30)"

(cid:15)  (cid:27) (cid:14)(cid:0)(cid:3)

(cid:15)

8

(cid:4) (cid:5)(cid:5)
(cid:0)(cid:5)(cid:5)

(cid:0) (cid:0)(cid:14)(cid:4) (cid:3)
(cid:0) (cid:4) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)
(cid:1) 

  (cid:5)(cid:5)

(cid:0) (cid:0)(cid:14)(cid:4) (cid:3)(cid:7) **

(cid:1)(cid:2)(cid:9) (cid:11)(cid:10) (cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:1) (cid:6) (cid:11)(cid:1) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:18)(cid:1)#(cid:9)
 (cid:1)(cid:27)(cid:11) " (cid:6) (cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:9)(cid:22)(cid:9)(cid:1) (cid:1) -(cid:1)(cid:18)(cid:9) (cid:0) (cid:2) (cid:4)
*++5 H(cid:21)	(cid:10)(cid:1) 2I(cid:15)

-(cid:1)(cid:18)(cid:9) (cid:0) (cid:2) (cid:4)

*++5 (cid:9)	(cid:9) (cid:11)(cid:10) (cid:11)(cid:9) (cid:2)(cid:10)(cid:1)

  8 * (cid:1) (cid:10)(cid:1)=(cid:9)(cid:18) (cid:30)" 	(cid:1)(cid:27) (cid:10) (cid:10)(cid:18)(cid:10)(cid:18) (cid:9)(cid:11)(cid:18)

(cid:1) (cid:29)(cid:11)(cid:1)(cid:2)(cid:11) (cid:9) ((cid:9)(cid:2) (cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9)  (cid:11)(cid:9) 	(cid:6)(cid:10)(cid:2)(cid:9)
(cid:18)(cid:9)=(cid:9)(cid:18) (cid:30)" (cid:11)(cid:1) (cid:2)(cid:10)(cid:1)(cid:15) %(cid:11)(cid:1) (cid:9)(cid:11)(cid:18) (cid:2)(cid:10) (cid:30)(cid:9) 	(cid:9)(cid:18)
(cid:6) (cid:10) (cid:1)(cid:1)’(cid:10)(cid:1) (cid:9)(cid:11)(cid:18) (cid:30)(cid:10)(cid:9)(cid:18)  	 (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:1)
** (cid:10) (cid:29)(cid:9)  (cid:15) <(cid:1)   (cid:11)(cid:29)(cid:9)(cid:20)(cid:9) (cid:30)(cid:11) (cid:9)(cid:11)(cid:18) (cid:29)(cid:1)   (cid:11)(cid:10)(cid:20)(cid:9)
 (cid:9)	(cid:9) (cid:11)(cid:9) (cid:2)(cid:10)(cid:1) (cid:11)(cid:10)  (cid:8) 0 (cid:30)" (cid:1)(cid:9)(cid:2)(cid:1)(cid:27) (cid:11)(cid:9)
(cid:30)(cid:10)(cid:30)(cid:1) (cid:1)" (cid:10)(cid:10)(cid:9)(cid:9)(cid:1)’(cid:10)(cid:1) (cid:18)	(cid:1)(cid:27) (cid:10) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) 	(cid:18)(cid:10)(cid:9)
(cid:1)(cid:15)(cid:9)(cid:15) (cid:10)  (cid:1)(cid:9)	(cid:9)(cid:10)(cid:2)(cid:11)(cid:15)

(cid:25)(cid:15)(cid:31) (cid:8)(cid:17)(cid:4)(cid:4)(cid:18)  (cid:20)(cid:18)	(cid:4)(cid:18)  (cid:29)(cid:18)  (cid:30)(cid:18)(cid:17)(cid:4)(cid:5)

(cid:0)  (cid:6)(cid:4)

(cid:3)(cid:0)(cid:4) (cid:0) (cid:5)

(cid:3)(cid:0) (cid:10) (cid:29)(cid:9)   (cid:10) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:0) (cid:5)

(cid:9)(cid:22)  (cid:9) 	 (cid:2)(cid:1)(cid:18)(cid:9) (cid:10) (cid:6)(cid:16)(cid:9)(cid:9)(cid:2)  (cid:22)(cid:2)	(cid:9)(cid:2) (cid:31)   (cid:2)(cid:10) 
(cid:9)(cid:27)(cid:9)(cid:1) (cid:18)(cid:9)  (cid:6) (cid:11)(cid:9) (cid:2)(cid:1)		 (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:0)(cid:0) (cid:27)(cid:1)(cid:20)(cid:9)
(cid:11)(cid:9) (cid:10)(cid:9) (cid:0)(cid:3)(cid:0) 8 (cid:0) (cid:4)
(cid:3)(cid:0) (cid:29)(cid:11)(cid:9)(cid:9) (cid:11)(cid:9) (cid:2)	
(cid:18)(cid:1)(cid:1)(cid:1)(cid:27) (cid:10)(cid:9) (cid:9) (cid:10)" (cid:2)(cid:10)(cid:1) (cid:2)(cid:1)		 (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9)
(cid:0) (cid:4)
(cid:3)(cid:0)(cid:15) (cid:8)(cid:9)(cid:2)(cid:10)  
(cid:11)(cid:10) (cid:5)(cid:5)
(cid:0) (cid:18)(cid:9)(cid:9) (cid:10) (cid:10)(cid:1)(cid:2)	 (cid:10) (cid:2)=(cid:27)	(cid:10)(cid:1) (cid:6) (cid:20)(cid:10) 	(cid:9) (cid:6)
(cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:10)(cid:9) (cid:10)(cid:18)  (cid:9)(cid:10)(cid:9) (cid:10)(cid:1) (cid:29)(cid:9) (cid:29)(cid:1)   (cid:1) (cid:11)(cid:1)
(cid:9)(cid:2)(cid:1) 	(cid:9) (cid:24) (cid:1)(cid:9)(cid:10)(cid:18) (cid:6) (cid:5)(cid:4)
(cid:3)(cid:0)  (cid:18)(cid:9)(cid:9) (cid:10) (cid:10)	
(cid:1)(cid:2)	 (cid:10) (cid:2)=(cid:27)	(cid:10)(cid:1) (cid:6) (cid:20)(cid:10) 	(cid:9) (cid:6) (cid:2)(cid:1)		 (cid:10)(cid:9)(cid:15)
%(cid:11)(cid:9) (cid:31)  (cid:9)(cid:27)(cid:9)(cid:1) (cid:18)(cid:9)  (cid:18)(cid:9)=(cid:9) (cid:10) (cid:9) (cid:6)  (cid:1)(cid:9)(cid:10) (cid:9)(cid:27)(cid:9)	
(cid:1)  (cid:11)(cid:9) (cid:2)(cid:1)		 (cid:10)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) C (cid:10) (cid:9)(cid:27)(cid:9)(cid:1)
(cid:6) (cid:9)(cid:10)(cid:2)(cid:11) (cid:2)=(cid:27)	(cid:10)(cid:1) (cid:6) (cid:18)(cid:1)(cid:9)(cid:9) (cid:10)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9)(cid:15) <(cid:9)(cid:9)
(cid:10)	(cid:1)’(cid:9) (cid:10)(cid:18) (cid:17)(cid:9)	(cid:11) *+,+ (cid:6) (cid:9) (cid:18)(cid:9)(cid:10)(cid:1)   (cid:31) 
(cid:18)(cid:9) (cid:15) (cid:9) 	 (cid:29) (cid:2)(cid:1)(cid:18)(cid:9) (cid:10) (cid:10)(cid:1)(cid:2)	 (cid:10) (cid:18)(cid:1)(cid:1)(cid:30)	(cid:1)
(cid:6) (cid:0)(cid:0) (cid:27)(cid:1)(cid:20)(cid:9) (cid:11)(cid:9) (cid:20)(cid:10) 	(cid:9) (cid:24) (cid:6) (cid:2)(cid:1)		 (cid:10)(cid:9) (cid:10)(cid:18)
(cid:11)(cid:9) (cid:2)=(cid:27)	(cid:10)(cid:1) (cid:6) (cid:20)(cid:10) 	(cid:9) (cid:6) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:10)(cid:9) (cid:5)(cid:5)
(cid:0) (cid:15) %(cid:11)(cid:9)
(cid:18)(cid:1)(cid:1)(cid:30)	(cid:1) (cid:1) (cid:18)(cid:9)=(cid:9)(cid:18) (cid:30)" (cid:11)(cid:9) (cid:9)(cid:10) (cid:16) 8 (cid:11)  (cid:12)(cid:24)(cid:2) (cid:10)(cid:18)
(cid:20)(cid:10)(cid:1)(cid:10)(cid:2)(cid:9) (cid:13) (cid:29)(cid:11)(cid:9)(cid:9) (cid:11) (cid:10)(cid:18) (cid:12) (cid:10)(cid:9) (cid:9)(cid:9)(cid:2)(cid:1)(cid:20)(cid:9) " (cid:11)(cid:9) (cid:1)(cid:9)(cid:2)(cid:9)
(cid:10)(cid:18) (cid:11)(cid:9) (cid:2)(cid:9)Æ(cid:2)(cid:1)(cid:9) (cid:6) (cid:11)(cid:9) (cid:9)(cid:27)(cid:9)(cid:1)  (cid:2)(cid:1)		
(cid:10)(cid:9) (cid:10)(cid:18) (cid:2) (cid:18)(cid:9)(cid:9) (cid:10)(cid:9)(cid:15) (cid:8)(cid:9)(cid:1)(cid:2)(cid:1)(cid:27) (cid:10)(cid:9)	
(cid:1)  	(cid:18)(cid:9)(cid:27)(cid:9)(cid:9)(cid:10)(cid:9)  (cid:1)(cid:1)(cid:20)(cid:9)  (cid:10)	(cid:1)(cid:10) (cid:29)(cid:11)(cid:9)(cid:9)
(cid:13) (cid:19) 0 (cid:29)(cid:9) (cid:2)(cid:10) (cid:30)(cid:10)(cid:1) (cid:10) (cid:9)(cid:22)(cid:9)(cid:1)(cid:10)  (cid:18)(cid:9)  (cid:9)(cid:9)(cid:9)	
(cid:10)(cid:1) (cid:6) (cid:11)(cid:9) (cid:6) / (cid:10) (cid:6)  (cid:29)

(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1) 8 (cid:3)(cid:3)(cid:4) (cid:3)(cid:4) 8 (cid:22) (cid:16)

(cid:13)

(cid:4)  

*

/(cid:13)(cid:23)

(cid:4)  

*

/(cid:13)(cid:23)

(cid:13)

8 (cid:22) (cid:11)  (cid:12)(cid:24)(cid:2)
(cid:6)(cid:0) 8  (cid:6)(cid:0)(cid:4) (cid:6)(cid:4)
(cid:0)

(cid:1)  8  

 

(cid:3)(cid:4)
(cid:3)
2(cid:3)(cid:4)

*
/

(cid:10)(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

 (cid:27) /(cid:3)(cid:4)

8

(cid:16)(cid:4)
/(cid:13)



*
/

 (cid:27) (cid:13)

(cid:8)(cid:6)(cid:0) 8 /(cid:5) (cid:3)(cid:16)(cid:4)(cid:7)

(cid:1)(cid:2)(cid:9) (cid:11)(cid:10) (cid:11)(cid:9) (cid:9)(cid:1)(cid:2)(cid:1)  (cid:1)(cid:1)(cid:20)(cid:9)  (cid:10)	(cid:1)(cid:10) (cid:13) (cid:19)
0 (cid:9)	(cid:9) (cid:11)(cid:10) (cid:11)(cid:9) (cid:10)	(cid:10)  (cid:10)(cid:10)(cid:9)(cid:9) (cid:6) (cid:11)(cid:9) (cid:9)(cid:22)	
(cid:9)(cid:1)(cid:10)  (cid:9)(cid:9)(cid:9)(cid:10)(cid:1) (cid:10)(cid:9) (cid:18)(cid:9)=(cid:9)(cid:18)(cid:15)

%(cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:2)(cid:9)(cid:18) (cid:20)(cid:10) 	(cid:9) (cid:6) (cid:11)(cid:9) (cid:2)(cid:10)(cid:1)(cid:2)(cid:10)  (cid:10)(cid:1)(cid:1)(cid:2) (cid:1)

(cid:18) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)  8 (cid:24)(cid:11)(cid:1)(cid:0)(cid:2)(cid:0)

(cid:1)

H(cid:0)(cid:0)I

8 (cid:16)(cid:4) (cid:13)  (cid:16)(cid:4)

8  (cid:11)  (cid:12)(cid:24)(cid:2)(cid:4) (cid:13)  (cid:11)  (cid:12)(cid:24)(cid:2)(cid:4) (cid:7)

$(cid:27)(cid:10)(cid:1) (cid:29)(cid:9) (cid:2)(cid:10) 	(cid:9) (cid:11)(cid:9) (cid:10)	(cid:1)’(cid:9) (cid:10)(cid:18) (cid:9)(cid:9) /00*
(cid:10)(cid:27)(cid:10)(cid:1) (cid:2)(cid:11)(cid:9)(cid:9)  (cid:9)Æ(cid:2)(cid:1)(cid:9) " (cid:2)	(cid:9) (cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9)
(cid:6) (cid:11)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) (cid:6) (cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:1)(cid:10)  (cid:18)(cid:9) (cid:15) $ (cid:29)(cid:1)(cid:11)
(cid:11)(cid:9) (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)  	 (cid:1)(cid:1)(cid:10)  (cid:2)(cid:10)(cid:9) (cid:11)(cid:9) (cid:1)(cid:6)(cid:9)(cid:9)(cid:2)(cid:9) (cid:2)(cid:11)(cid:9)(cid:9)
	(cid:1) (cid:1)’(cid:9) (cid:10) (cid:10)(cid:10)(cid:9)(cid:9)(cid:1)’(cid:10)(cid:1) (cid:6) (cid:10) (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)   (cid:10)	(cid:1)(cid:10)
(cid:11)(cid:10) (cid:1) (cid:18)(cid:1)#(cid:9)(cid:9) (cid:6) 	 (cid:9)(cid:22)(cid:9)(cid:1)(cid:10)  (cid:18)(cid:9) (cid:15)  (cid:11)(cid:9)
(cid:2)(cid:10)(cid:9) (cid:6) (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)  	 (cid:1)(cid:1)(cid:10)  (cid:18)(cid:9)  (cid:29)(cid:9) (cid:2)(cid:10) (cid:9)(cid:10)(cid:1) "
(cid:29)(cid:1)(cid:2)(cid:11) (cid:30)(cid:9)(cid:29)(cid:9)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9)(cid:1)’(cid:10)(cid:1)(cid:15) %(cid:11)(cid:1) (cid:10)  (cid:29)(cid:9)(cid:18) 	 
	(cid:9) (cid:10) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:9)(cid:11)(cid:18) (cid:9)(cid:15)(cid:27)(cid:15) (cid:10)  (cid:1)(cid:9)	(cid:9)(cid:10)(cid:2)(cid:11)  	(cid:18)(cid:10)(cid:9)
(cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:1)(cid:10)  (cid:18)(cid:9)  (cid:10)(cid:10)(cid:9)(cid:9) (cid:10)(cid:18) (cid:11)(cid:9) (cid:2)(cid:20)(cid:9)
(cid:11)(cid:9) (cid:9)	 (cid:1)(cid:27) (cid:10)(cid:10)(cid:9)(cid:9)(cid:1)’(cid:10)(cid:1) (cid:30)(cid:10)(cid:2)(cid:16) (cid:1) (cid:11)(cid:9) (cid:10)(cid:27)(cid:10)	
(cid:1) (cid:2)(cid:11)(cid:9)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) (cid:1) (cid:18)(cid:9)  (cid:2)	(cid:9) (cid:11)(cid:9) (cid:9)(cid:22)
(cid:27)(cid:10)(cid:18)(cid:1)(cid:9)(cid:15)  (cid:29)(cid:9)(cid:20)(cid:9) (cid:1) (cid:11)(cid:9) (cid:2)(cid:10)(cid:9) (cid:6) (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)   (cid:10)	(cid:1)(cid:10)
(cid:18)(cid:9)  (cid:11)(cid:9) (cid:10)(cid:27)(cid:10)(cid:1) (cid:2)(cid:11)(cid:9)(cid:9) (cid:9)	(cid:1)(cid:9) (cid:11)(cid:9) (cid:10)(cid:10)(cid:9)	
(cid:9) (cid:11)(cid:4) (cid:12)(cid:4) (cid:13) (cid:10)(cid:18) (cid:11)(cid:9)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) (cid:2)(cid:10) (cid:30)(cid:9) (cid:30)(cid:10)(cid:1)(cid:9)(cid:18)
(cid:6) (cid:11)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) (cid:6) (cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:1)(cid:10)  (cid:18)(cid:9)  (cid:9)(cid:9)	
(cid:9)(cid:10)(cid:1)(cid:15) (cid:17)(cid:9) (cid:11)(cid:9)(cid:9)(cid:6)(cid:9) (cid:2)	(cid:9) (cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:11)(cid:9)(cid:9)
(cid:10)(cid:10)(cid:9)(cid:9) (cid:18)(cid:1)(cid:9)(cid:2) "(cid:15)
-" (cid:1)(cid:9)(cid:1)(cid:27) (cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:1) (cid:6) (cid:0)(cid:0) (cid:10)(cid:18) (cid:18) (cid:3)(cid:0)(cid:1)(cid:6)(cid:0)
(cid:11)(cid:9) (cid:9)	(cid:10)(cid:1) + (cid:10)(cid:18) (cid:30)" 	(cid:1)(cid:27) (cid:11)(cid:9) (cid:10)(cid:2)(cid:30)(cid:1)(cid:10)

(cid:1)  (cid:1)

(cid:15)(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)

(cid:15)(cid:11)(cid:4) (cid:12)(cid:4) (cid:13)

8(cid:24) (cid:3)

(cid:17)
0

(cid:3)

(cid:17)   (cid:4)(cid:18)(cid:3)(cid:1)
0

(cid:17)(cid:1)

(cid:3)

(cid:4)(cid:17)(cid:1)

(cid:25)

(cid:29)(cid:9) (cid:2)(cid:10) (cid:18)(cid:9)(cid:1)(cid:20)(cid:9) (cid:11)(cid:9) (cid:6)  (cid:29)(cid:1)(cid:27)  (cid:2)(cid:10)  (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:29)(cid:1)(cid:11) (cid:9)(cid:9)(cid:2)
 (cid:11)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9)(cid:1)’(cid:10)(cid:1) (cid:11)(cid:4) (cid:12)(cid:4) (cid:13)(cid:15) (cid:9) (cid:16) 8 (cid:11)(cid:12)(cid:24)(cid:2) (cid:11)(cid:9)

(cid:15)  (cid:27) (cid:14)(cid:0)(cid:3)
(cid:15)(cid:11)(cid:4) (cid:12)(cid:4) (cid:13)

8

(cid:15)  (cid:27) (cid:14)(cid:0)(cid:3)

(cid:15)(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)

(cid:15)(cid:3)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)

(cid:15)(cid:11)(cid:4) (cid:12)(cid:4) (cid:13)

8 (cid:6) (cid:6)(cid:0)(cid:4) (cid:24)(cid:4) (cid:5)(cid:5)

(cid:0) (cid:0)(cid:14)(cid:4) (cid:3)

(cid:9)(cid:1) (cid:19)

(cid:17)

(cid:9)(cid:1) (cid:19)(cid:3)

(cid:17)

(cid:9)(cid:1) (cid:19)(cid:1) (cid:17)

(cid:4)(cid:17)

(cid:16)
(cid:17)(cid:18)

(cid:16)(cid:6)(cid:0)(cid:4) (cid:24)

*/

(cid:2)

(cid:19)
(cid:20)(cid:21)

3458 (cid:5)(cid:5)

(cid:0) (cid:4) (cid:14)(cid:4) (cid:3)

(cid:9)(cid:1) (cid:19)

(cid:0) (cid:0)(cid:14)(cid:4) (cid:3)(cid:6) (cid:6)(cid:0)(cid:4) (cid:24)(cid:0)(cid:5)(cid:5)
(cid:19)
(cid:16)
(cid:20)(cid:21)
(cid:17)(cid:18)

(cid:9)(cid:1) (cid:19)(cid:1) (cid:17)

(cid:9)(cid:1) (cid:19)(cid:3)

(cid:4)(cid:17)

(cid:17)

(cid:17)

(cid:2)

(cid:16)(cid:6)(cid:0)(cid:4) (cid:24)

*E

(cid:29)(cid:11)(cid:9)(cid:9) (cid:6)(cid:0)(cid:4) (cid:24)(cid:0)(cid:5)(cid:5)
(cid:0) (cid:4) (cid:14)(cid:4) (cid:3) 8 0 (cid:6) (cid:20)(cid:10) 	(cid:9) (cid:6) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:10)	
(cid:9) (cid:5)(cid:5)
(cid:0)  (cid:2)(cid:1)(cid:9) (cid:29)(cid:1)(cid:11) (cid:11)(cid:9) (cid:1)(cid:2) (cid:9)(cid:9) (cid:30)(cid:9)(cid:20)(cid:10)	
(cid:1) (cid:14)(cid:15) %(cid:11)(cid:9) (cid:9) (cid:6) */  *E (cid:6)  (cid:29) (cid:30)" (cid:6)(cid:10)(cid:2)(cid:1)(cid:27)
(cid:6)(cid:0)(cid:4) (cid:24)(cid:4) (cid:5)(cid:5)
(cid:0) (cid:0)(cid:14)(cid:4) (cid:3) (cid:10)(cid:18)
(cid:11)(cid:9) 	  (cid:1)(cid:27) (cid:11)(cid:9) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:18)(cid:9)(cid:1)" 	 (cid:6) 	(cid:18)(cid:9) (cid:11)(cid:9)
(cid:1)(cid:9)(cid:27)(cid:10)(cid:1)(cid:15)

(cid:0) (cid:0)(cid:14)(cid:4) (cid:3) (cid:1) (cid:6)(cid:0)(cid:4) (cid:24)(cid:0)(cid:5)(cid:5)

(cid:0) (cid:4) (cid:14)(cid:4) (cid:3) (cid:10)(cid:18) (cid:5)(cid:5)

(cid:9) (cid:6)(cid:0)(cid:4) (cid:24) (cid:18)(cid:9)(cid:9) (cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:2)(cid:9)(cid:18) (cid:20)(cid:10) 	(cid:9) (cid:6) (cid:11)(cid:9) (cid:20)(cid:9)(cid:2)
(cid:0)(cid:0)(cid:4) (cid:0) (cid:4)
(cid:3)(cid:0) (cid:29)(cid:1)(cid:11) (cid:9)(cid:9)(cid:2)  (cid:11)(cid:9) (cid:9)(cid:1)  (cid:10)	(cid:1)(cid:10)
(cid:18)(cid:1)(cid:1)(cid:30)	(cid:1) (cid:6) (cid:0)(cid:0)(cid:4) (cid:0) (cid:4)

(cid:3)(cid:0) (cid:27)(cid:1)(cid:20)(cid:9) (cid:5)(cid:5)

(cid:0) %(cid:11)(cid:10) (cid:1)

(cid:6)(cid:0)(cid:4) (cid:24) 8 (cid:24)(cid:11)(cid:1)(cid:0)(cid:2)(cid:0)

(cid:1)

H(cid:0)(cid:0)(cid:4) (cid:0) (cid:4)

(cid:3)(cid:0)(cid:0)(cid:14)I

8 (cid:6) (cid:6)(cid:0)(cid:4) (cid:24)(cid:0)(cid:5)(cid:5)

(cid:0)(cid:4) (cid:14)(cid:4) (cid:3)(cid:6)(cid:0)(cid:4) (cid:24)(cid:16)(cid:6)(cid:0)(cid:4) (cid:24)(cid:7)

<(cid:1)(cid:1) (cid:10) "  (cid:9) (cid:6)(cid:0)(cid:4) (cid:24)(cid:2)(cid:6)(cid:0)(cid:4) (cid:24) (cid:18)(cid:9)(cid:9) (cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:2)(cid:9)(cid:18) (cid:20)(cid:10) 	(cid:9)

(cid:6) (cid:11)(cid:9) (cid:10)(cid:1)(cid:22) (cid:3)(cid:0)(cid:0)(cid:4) (cid:0) (cid:4)

H(cid:0)(cid:0)(cid:0) (cid:4)

(cid:3)(cid:0)(cid:2)(cid:0)(cid:0)(cid:4) (cid:0) (cid:4)

(cid:10)(cid:2)(cid:9) (cid:6)(cid:0)(cid:24) 8 (cid:24)(cid:11)(cid:1)(cid:0)(cid:2)(cid:0)
%(cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:1) (cid:6) (cid:11)(cid:9)  (cid:2)(cid:10)  (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:1) *E (cid:11)(cid:9) (cid:9)	
(cid:18)	(cid:2)(cid:9) 

(cid:3)(cid:0)(cid:0)(cid:14)I(cid:15)

(cid:1)

(cid:3)(cid:0)(cid:4)(cid:15) 4 (cid:1)	

(cid:15)  (cid:27) (cid:14)(cid:0)(cid:3)

(cid:15)(cid:11)

(cid:15)  (cid:27) (cid:14)(cid:0)(cid:3)

(cid:15)(cid:12)

(cid:15)  (cid:27) (cid:14)(cid:0)(cid:3)

(cid:15)(cid:13)

8 (cid:5)(cid:5)

(cid:0) (cid:0)(cid:14)(cid:4) (cid:3) (cid:6)(cid:0)   (cid:12)(cid:24)   (cid:11) (cid:21)(cid:13)

8 (cid:5)(cid:5)

8 (cid:5)(cid:5)

(cid:0) (cid:0)(cid:14)(cid:4) (cid:3) (cid:6)(cid:0)(cid:24)   (cid:11)(cid:24)   (cid:12)(cid:24)(cid:2)(cid:24) (cid:21)(cid:13)
(cid:0) (cid:0)(cid:14)(cid:4) (cid:3) (cid:6)(cid:0)(cid:6)(cid:0)   /(cid:11)(cid:6)(cid:0)   /(cid:12)(cid:6)(cid:0)(cid:24)(cid:2)
(cid:12)(cid:24)(cid:2)(cid:24)(cid:12)(cid:2)  /(cid:11)(cid:12)(cid:24)(cid:2)  (cid:11)(cid:4)   (cid:13) (cid:21)/(cid:13)(cid:4)(cid:7)

*2

(cid:17)(cid:9) (cid:2)(cid:10) (cid:29) 	(cid:9) (cid:11)(cid:9) (cid:10)	(cid:1)’(cid:9) (cid:10)(cid:18) (cid:9)(cid:9) /00*
(cid:10)(cid:27)(cid:10)(cid:1) (cid:2)(cid:11)(cid:9)(cid:9) (cid:10)(cid:18) (cid:11)(cid:1) (cid:1)(cid:9) (cid:9)Æ(cid:2)(cid:1)(cid:9) " (cid:2)	(cid:9)
(cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:31)  (cid:9)(cid:27)(cid:9)(cid:1) (cid:18)(cid:9) (cid:15) (cid:8)(cid:9)(cid:2)(cid:10)   (cid:11)(cid:10)
(cid:11)(cid:9) (cid:10)(cid:27)(cid:10)(cid:1) (cid:2)(cid:11)(cid:9)(cid:9) (cid:10)  (cid:29) 	  (cid:9)Æ(cid:2)(cid:1)(cid:9) " (cid:2)	
	(cid:9) (cid:9)(cid:1) (cid:10)(cid:27)(cid:1)(cid:10)  (cid:18)(cid:1)(cid:1)(cid:30)	(cid:1) (cid:6) (cid:10)" (cid:6)(cid:10)	
(cid:1) " (cid:0)(cid:0)(cid:4)(cid:3)(cid:0) (cid:29)(cid:11)(cid:9)(cid:9) (cid:11)(cid:1) (cid:18)(cid:1)(cid:1)(cid:30)	(cid:1) (cid:1) (cid:9)(cid:9)(cid:9)(cid:9)(cid:18)
(cid:10) (cid:11)(cid:9) (cid:18)	(cid:2) (cid:6) (cid:11)(cid:9) (cid:10)(cid:27)(cid:1)(cid:10)  (cid:18)(cid:1)(cid:1)(cid:30)	(cid:1) (cid:6) (cid:18)(cid:1)	
(cid:2)(cid:9)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:0) (cid:5)
(cid:3)(cid:0) (cid:10)(cid:18) (cid:11)(cid:9) (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)   (cid:10)		
(cid:1)(cid:10) (cid:0)(cid:0)(cid:4) (cid:0) (cid:4)
(cid:3)(cid:0)(cid:0)(cid:0) (cid:5)
(cid:3)(cid:0)(cid:15)  (cid:1)(cid:20)(cid:9) (cid:10) (cid:10)(cid:1)(cid:2)	 (cid:10) (cid:2)=(cid:27)		
(cid:10)(cid:1) (cid:6) (cid:11)(cid:9) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:5)(cid:5)
(cid:0)  (cid:11)(cid:9) (cid:9)(cid:10) (cid:20)(cid:9)(cid:2) (cid:16)
(cid:10)(cid:18) (cid:2)(cid:20)(cid:10)(cid:1)(cid:10)(cid:2)(cid:9) (cid:10)(cid:1)(cid:22)  (cid:6) (cid:11)(cid:1) (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)   (cid:10)	(cid:1)(cid:10)
(cid:9)	(cid:10) 

(cid:16) 8 (cid:6)(cid:0)(cid:4) (cid:24)
 8 (cid:6)(cid:0)(cid:4) (cid:24)(cid:2)(cid:6)(cid:0)(cid:4) (cid:24)   (cid:16)(cid:2)(cid:16)(cid:7)

%(cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:2)(cid:9)(cid:18) (cid:10)(cid:1)(cid:1)(cid:2)  (cid:11)(cid:9) (cid:1)(cid:27)(cid:11)	(cid:11)(cid:10)(cid:18) (cid:1)(cid:18)(cid:9) (cid:6) *2
(cid:2)(cid:10) (cid:11)(cid:9)(cid:9)(cid:6)(cid:9) (cid:9)(cid:10)(cid:1) " (cid:30)(cid:9) (cid:9)(cid:22)(cid:10)(cid:2)(cid:9)(cid:18) (cid:6) (cid:11)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9)(cid:1)	
’(cid:10)(cid:1) (cid:6) (cid:11)(cid:9) (cid:10)(cid:27)(cid:1)(cid:10)  (cid:18)(cid:1)(cid:1)(cid:30)	(cid:1) (cid:10)(cid:18) (cid:11)(cid:9)(cid:2)(cid:9) (cid:11)(cid:9) (cid:27)(cid:10)	
(cid:18)(cid:1)(cid:9) (cid:6) (cid:10) (cid:31)  (cid:9)(cid:27)(cid:9)(cid:1) (cid:2)(cid:10) (cid:30)(cid:9) (cid:9)Æ(cid:2)(cid:1)(cid:9) " (cid:2)	(cid:9)(cid:18)(cid:15)

(cid:29) (cid:5)(cid:5)(cid:16)(cid:16) (cid:31)(cid:13)(cid:26)

%"(cid:1)(cid:27) (cid:6) (cid:10)(cid:10)(cid:9)(cid:9) (cid:1) (cid:10) (cid:9)(cid:9)(cid:1)(cid:10)  (cid:6)(cid:9)(cid:10)	(cid:9) (cid:6) (cid:9)
"(cid:9) (cid:6) (cid:18)(cid:9)  (cid:1)(cid:2) 	(cid:18)(cid:1)(cid:27) (cid:6) (cid:9)(cid:22)(cid:10) (cid:9) (cid:18)(cid:9)  (cid:6)
(cid:2)(cid:11)(cid:10)(cid:1)(cid:2) (cid:9)(cid:10)  (cid:2)(cid:9)(cid:9) (cid:10)(cid:18) (cid:9)(cid:18)(cid:1)(cid:27)(cid:9)(cid:9) (cid:10)(cid:10) "(cid:1)(cid:15)
(cid:17)(cid:9) (cid:2)(cid:1)(cid:18)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) "(cid:1)(cid:27) (cid:11)(cid:10) (cid:9) (cid:10)(cid:22)(cid:9) (cid:11)(cid:9) (cid:27) (cid:30)(cid:10) 
(cid:20)(cid:10)(cid:1)(cid:10)(cid:1) (cid:1)(cid:18)(cid:9)(cid:9)(cid:18)(cid:9)(cid:2)(cid:9) (cid:1) * (cid:30)" (cid:10)	(cid:1)(cid:27) (cid:11)(cid:10) (cid:11)(cid:9)
(cid:10)(cid:10)(cid:9)(cid:9)(cid:1)’(cid:10)(cid:1) (cid:6) (cid:11)(cid:9) (cid:9) (cid:10)(cid:1)(cid:11)(cid:1) (cid:30)(cid:9)(cid:29)(cid:9)(cid:9) (cid:11)(cid:9) (cid:20)(cid:10)(cid:1)	
(cid:10)(cid:30) (cid:9) (cid:0)(cid:0) (cid:10)(cid:18) (cid:1) (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)  (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:0)(cid:3)(cid:0) (cid:1) (cid:11)(cid:9) (cid:10)(cid:9)
(cid:10)(cid:2) (cid:10) (cid:9) (cid:6) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9)(cid:15) (cid:9) K(cid:1) (cid:9) (cid:25) (cid:18)(cid:9)(cid:9) (cid:10) 	(cid:2)(cid:11) (cid:9)
(cid:6) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:10)(cid:18)  (cid:9) K(cid:25) (cid:18)(cid:9)(cid:9) (cid:10)   (cid:6) 	(cid:2)(cid:11) (cid:9)(cid:15) (cid:17)(cid:9)
(cid:29)(cid:1)    (cid:9) (cid:3)(cid:8)(cid:0) (cid:18)(cid:9)(cid:9) (cid:11)(cid:9) (cid:1)(cid:9)(cid:18) (cid:10)(cid:10)(cid:9)(cid:9)(cid:1)’(cid:10)(cid:1) (cid:10)(cid:2) (cid:10)  
(cid:1) (cid:2) K(cid:1)(cid:15)  (cid:11)(cid:1) (cid:2)(cid:10)(cid:9) (cid:11)(cid:9) (cid:18)(cid:9)  (cid:6)(cid:10)(cid:2)(cid:1)’(cid:9) (cid:10)

(cid:0)(cid:0)(cid:3) 8 (cid:0)(cid:0)(cid:0)(cid:1)

(cid:0)(cid:0)(cid:0)(cid:0)(cid:3)(cid:0)(cid:4) (cid:3)(cid:8)(cid:0)

*B

(cid:29)(cid:11)(cid:9)(cid:9)  8 (cid:8)(cid:0)(cid:0) (cid:8)(cid:1) (cid:8)(cid:0)(cid:15) (cid:17)(cid:9) (cid:2)(cid:10)   (cid:11)(cid:1) "(cid:9) (cid:6) "(cid:1)(cid:27) (cid:6)
(cid:17) (cid:18)(cid:2)  (cid:2)(cid:2)(cid:0)(cid:0) (cid:23)(cid:9)(cid:17)(cid:15)   (cid:30)(cid:10)  (cid:10)(cid:10)(cid:9)(cid:9) "(cid:1)(cid:27) (cid:1) (cid:6)
(cid:2)	(cid:9)  " (cid:1)(cid:30) (cid:9) (cid:30)(cid:9)(cid:29)(cid:9)(cid:9) (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)  (cid:18)(cid:9)  (cid:11)(cid:10)
(cid:10)(cid:9) (cid:1)(cid:1) (cid:10)(cid:15) %(cid:11)(cid:10) (cid:1) (cid:6) (cid:10)   (cid:0)(cid:0) (cid:29)(cid:11)(cid:9)(cid:9) (cid:1) (cid:2) K(cid:1) (cid:11)(cid:9)
	(cid:30)(cid:9) (cid:6) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:10)(cid:18) (cid:2)(cid:1)		 (cid:2)(cid:18)(cid:1)(cid:1)(cid:1)(cid:27) (cid:10)	
(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) 	 (cid:30)(cid:9) (cid:11)(cid:9) (cid:10)(cid:9) (cid:10)(cid:18) (cid:11)(cid:9) (cid:9) (cid:6) (cid:1)(cid:30) (cid:9)
(cid:10)(cid:9) (cid:2)=(cid:27)	(cid:10)(cid:1) (cid:6) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:10)(cid:9) 	 (cid:30)(cid:9) (cid:11)(cid:9)
(cid:10)(cid:9)(cid:15) (cid:17)(cid:9) (cid:29)(cid:1)    (cid:9) (cid:5)(cid:5)
(cid:8)(cid:0) (cid:18)(cid:9)(cid:9) (cid:10) (cid:10)(cid:1)(cid:2)	 (cid:10) (cid:2)=(cid:27)	(cid:10)(cid:1)
(cid:6) (cid:10)(cid:9) (cid:6) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:10)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9)(cid:15) %(cid:11)(cid:1) (cid:2)=(cid:27)	(cid:10)	
(cid:1) (cid:29)(cid:1)   (cid:30)(cid:9) (cid:11)(cid:9) (cid:10)(cid:9) (cid:10)(cid:2) (cid:10)   (cid:1) (cid:2) K(cid:1)(cid:15)

(cid:17)(cid:9) (cid:10)(cid:9) (cid:29) (cid:9)(cid:9)(cid:16)(cid:1)(cid:27) (cid:11)(cid:9) (cid:1)(cid:2) (cid:9)(cid:9)	(cid:18)(cid:10)(cid:10)  (cid:27)	 (cid:1)(cid:16)(cid:9) (cid:1)(cid:11)(cid:18)
(cid:29)(cid:1)(cid:11) (cid:9)(cid:9)(cid:2)  (cid:11)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9)(cid:1)’(cid:10)(cid:1) (cid:3)(cid:8)(cid:0)(cid:1)(cid:6)(cid:0)
(cid:15) <(cid:1)(cid:1) (cid:10) 
G (cid:10)(cid:18) 5 (cid:29)(cid:9) 	(cid:9) (cid:11)(cid:9) (cid:2)(cid:11)(cid:10)(cid:1) 	 (cid:9) (cid:10)(cid:18) (cid:9)(cid:22)(cid:9)(cid:1)(cid:10) 
(cid:18)(cid:9)  (cid:9)(cid:9)(cid:9)(cid:10)(cid:1)  = (cid:2)	(cid:9) (cid:11)(cid:9)  (cid:2)(cid:10)  (cid:27)(cid:10)(cid:18)(cid:1)	
(cid:9) (cid:6) (cid:10) (cid:2) (cid:9)(cid:9) (cid:30)(cid:9)(cid:20)(cid:10)(cid:1)

(cid:2)(cid:1)

(cid:15)(cid:6)(cid:0)(cid:3)(cid:8)(cid:0)
(cid:15)(cid:3)(cid:8)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:2)(cid:1)

8 (cid:5)(cid:0)(cid:0)(cid:8)(cid:0)
8 (cid:5)(cid:0)(cid:0)(cid:8)(cid:0)

(cid:6)(cid:0)(cid:3)

(cid:15)  (cid:27) (cid:6)(cid:0)(cid:0)(cid:6)(cid:3)(cid:0)(cid:4) (cid:3)(cid:8)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:2)(cid:1)



(cid:15)(cid:3)(cid:8)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:2)(cid:1)

(cid:6)(cid:0)(cid:3) (cid:6)(cid:0)

(cid:2)(cid:1) (cid:6)(cid:3)(cid:0)(cid:3)(cid:6)(cid:0)   (cid:18) (cid:3)(cid:8)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:2)(cid:1)

(cid:4) (cid:7)

(cid:17)(cid:9) (cid:11)(cid:9) (cid:30)(cid:10)(cid:1) (cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:1) (cid:6) (cid:11)(cid:9)  (cid:2)(cid:10)  (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6)
(cid:11)(cid:9) (cid:1)(cid:2) (cid:9)(cid:9) (cid:18)(cid:10)(cid:10)  (cid:27)	 (cid:1)(cid:16)(cid:9) (cid:1)(cid:11)(cid:18) (cid:30)" (cid:11)(cid:9) (cid:10)(cid:9) (cid:9)
(cid:29)(cid:11)(cid:1)(cid:2)(cid:11)  (cid:9)(cid:10)(cid:18)  , (cid:10)(cid:18) +(cid:15)  (cid:9)(cid:2)(cid:9)

(cid:15)  (cid:27) (cid:14)(cid:0)(cid:20)

(cid:15)(cid:20)

8(cid:5)(cid:0)(cid:0)(cid:8)(cid:0)(cid:6) (cid:6)(cid:0)(cid:4) (cid:6)(cid:4)

(cid:3)(cid:0)(cid:4) (cid:5)(cid:8)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:2)(cid:1)



(cid:15)(cid:3)(cid:8)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:2)(cid:1)

(cid:15)(cid:20)

(cid:0)(cid:14)(cid:4) (cid:3)(cid:3)(cid:6)(cid:0)   (cid:18) (cid:3)(cid:8)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:2)(cid:1)

(cid:4)

(cid:16)(cid:6)(cid:0)(cid:4) (cid:6)(cid:4)

(cid:3)(cid:0)(cid:7)

*G

(cid:20)(cid:11)(cid:2)(cid:1)(cid:0)(cid:2)(cid:0)

(cid:2)(cid:1)

(cid:20)(cid:21) 8 * (cid:27)(cid:1)(cid:20)(cid:9) 	 (cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:1) (cid:6) (cid:11)(cid:9) (cid:27)(cid:10)	
<(cid:9)(cid:1)(cid:27)
(cid:18)(cid:1)(cid:9) (cid:29)(cid:1)(cid:11) (cid:9)(cid:9)(cid:2)  (cid:11)(cid:9) (cid:10)	(cid:10)  (cid:10)(cid:10)(cid:9)(cid:9) (cid:1) (cid:11)(cid:9)
(cid:9)(cid:22)(cid:9)(cid:1)(cid:10)  (cid:18)(cid:9)  (cid:9)(cid:9)(cid:9)(cid:10)(cid:1)(cid:15)

(cid:1)(cid:2)(cid:9) (cid:11)(cid:10) (cid:11)(cid:9)  " (cid:18)(cid:1)#(cid:9)(cid:9)(cid:2)(cid:9) (cid:30)(cid:9)(cid:29)(cid:9)(cid:9) + (cid:10)(cid:18) *G
(cid:1) (cid:11)(cid:10) (cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:1) *G (cid:10)(cid:18)(cid:18) (cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:2)	
	(cid:9)(cid:18) (cid:10) (cid:9)(cid:10)(cid:2)(cid:11) (cid:1) (cid:2) K(cid:1)(cid:15)
 (cid:11)(cid:9) (cid:29)(cid:18) (cid:29)(cid:1)(cid:11) (cid:27) (cid:30)(cid:10) 

346(cid:10)(cid:10)(cid:9)(cid:9) "(cid:1)(cid:27) (cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:11)(cid:9) (cid:1)(cid:2) (cid:9)(cid:9)	(cid:18)(cid:10)(cid:10)
 (cid:27)	 (cid:1)(cid:16)(cid:9) (cid:1)(cid:11)(cid:18) (cid:2)(cid:10) (cid:30)(cid:9) (cid:2)	(cid:9)(cid:18) (cid:30)" (cid:2)(cid:9)(cid:9)(cid:18)(cid:1)(cid:27) (cid:10) (cid:1)(cid:6) (cid:10)	
(cid:10)(cid:9)(cid:9) (cid:29)(cid:9)(cid:9)  (cid:1)(cid:9)(cid:18) (cid:10)(cid:18) (cid:11)(cid:9) (cid:10)(cid:18)(cid:18) 	 (cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9)
(cid:29)(cid:11)(cid:1)(cid:2)(cid:11) (cid:10)(cid:9) (cid:9) (cid:10)(cid:9)(cid:18) (cid:30)" "(cid:1)(cid:27)(cid:15) %(cid:11)(cid:10) (cid:1)

(cid:27) (cid:4)  0(cid:4) (cid:29) (cid:29)(cid:1)(cid:11) (cid:27) 		(cid:10)  " (cid:1)(cid:18)(cid:9)(cid:9)(cid:18)(cid:9) (cid:6) (cid:10)  
(cid:15) %(cid:11)(cid:9) (cid:18)(cid:9)  (cid:11)(cid:9)(cid:9)(cid:6)(cid:9) (cid:1)(cid:20) (cid:20)(cid:9) (cid:11)(cid:9) (cid:6)(cid:9)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9)
(cid:11) (cid:28)(cid:3)(cid:4) (cid:7) (cid:7) (cid:7) (cid:4) (cid:28) (cid:12)(cid:3)(cid:4) (cid:7) (cid:7) (cid:7) (cid:4) (cid:12) (cid:10)(cid:18) (cid:29)(cid:15) %(cid:11)(cid:9)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9)
(cid:10)(cid:9) (cid:1)(cid:9)(cid:18) (cid:10)(cid:2) (cid:1)(cid:9) (cid:9)(cid:15)

(cid:15)  (cid:27) (cid:14)(cid:0)(cid:20)

(cid:15)(cid:20)

8 (cid:5)(cid:0)(cid:0)(cid:8)(cid:0)

(cid:15)  (cid:27) (cid:14)(cid:0)(cid:20)(cid:0)(cid:1)(cid:6)(cid:0)
(cid:1) 

(cid:15)(cid:20)(cid:0)(cid:1)(cid:6)(cid:0)

(cid:1)

*5

(cid:29)(cid:11)(cid:9)(cid:9) (cid:20)(cid:0)(cid:1)(cid:6)(cid:0)
(cid:9)(cid:1)’(cid:10)(cid:1) (cid:6) (cid:11)(cid:9)  (cid:2)(cid:10)  (cid:18)(cid:9)  (cid:29)(cid:1)(cid:11) (cid:20)(cid:0)(cid:1)(cid:6)(cid:0)
(cid:1) (cid:2) K(cid:1)(cid:15)

(cid:1) (cid:18)(cid:9)(cid:9) (cid:11)(cid:9) (cid:10)(cid:1)=(cid:2)(cid:1)(cid:10)  	(cid:1)(cid:9)(cid:18) (cid:10)(cid:10)(cid:9)	
(cid:1) 8 (cid:20) (cid:6) (cid:10)  

4 (cid:1) (cid:1)(cid:2)(cid:1)" (cid:29)(cid:9) (cid:29)(cid:1)    " (cid:2)(cid:1)(cid:18)(cid:9) (cid:27) (cid:30)(cid:10)  (cid:10)(cid:10)(cid:9)	
(cid:9) "(cid:1)(cid:27) (cid:10) (cid:18)(cid:9)(cid:2)(cid:1)(cid:30)(cid:9) (cid:10)(cid:30)(cid:20)(cid:9)(cid:15) (cid:9) (cid:11)(cid:1)(cid:1)(cid:2)(cid:10)(cid:9)(cid:18) "(cid:1)(cid:27)
(cid:2)(cid:11)(cid:9)(cid:9) (cid:10)(cid:9) (cid:6) (cid:2)	(cid:9) (cid:1)(cid:30) (cid:9)(cid:15)

 (cid:15)(cid:16) !(cid:29)(cid:3)(cid:18)(cid:4)(cid:29) "(cid:26)" (cid:17)(cid:5) 

%(cid:11)(cid:9) (cid:2)(cid:11)(cid:10)(cid:1)(cid:2) $(cid:8)$ (cid:13)$(cid:8)$ (cid:18)(cid:9)  (cid:6) %(cid:11)(cid:1)(cid:9)
(cid:0) (cid:2) (cid:4) /002 (cid:1) (cid:10) (cid:1)  	(cid:10)(cid:1)(cid:20)(cid:9) (cid:9)(cid:22)(cid:10) (cid:9) (cid:6) (cid:10) (cid:2)(cid:11)(cid:10)(cid:1)(cid:2)
(cid:9)(cid:10)  (cid:2)(cid:9) (cid:29)(cid:11)(cid:9)(cid:9) "(cid:1)(cid:27) (cid:6) (cid:10)(cid:10)(cid:9)(cid:9)  (cid:10)" (cid:10)
(cid:1)(cid:10)  (cid:9)(cid:15) (cid:13)$(cid:8)$ (cid:18)(cid:9)  (cid:10)(cid:9) (cid:2) (cid:9) " (cid:9) (cid:10)(cid:9)(cid:18)
 (cid:11)(cid:9) (cid:2) (cid:10)(cid:1)(cid:2) (cid:10)	(cid:9)(cid:27)(cid:9)(cid:1)(cid:20)(cid:9) (cid:20)(cid:1)(cid:27) (cid:10)(cid:20)(cid:9)(cid:10)(cid:27)(cid:9) $(cid:8)$
(cid:1)(cid:9)	(cid:9)(cid:1)(cid:9) (cid:18)(cid:9)  (cid:9)(cid:9) (cid:9)(cid:15)(cid:27)(cid:15) -(cid:22) (cid:9)(cid:16)(cid:1) (cid:10)(cid:18) (cid:8)(cid:9)(cid:1)	
(cid:9)  *++2  $ (cid:9)" *+5+(cid:15) $ (cid:18)(cid:9)(cid:10)(cid:9)(cid:18) (cid:1) %(cid:11)(cid:1)(cid:9)	
 (cid:0) (cid:2) (cid:4) /002 (cid:30)(cid:11) (cid:11)(cid:9) $(cid:8)$ (cid:10)(cid:18) (cid:13)$(cid:8)$ (cid:18)	
(cid:9)  (cid:10)(cid:9) (cid:10)	(cid:10)  " (cid:9)(cid:9)(cid:9)(cid:9)(cid:18) (cid:10) (cid:27)(cid:10)(cid:11)(cid:1)(cid:2)(cid:10)  (cid:18)(cid:9)  (cid:29)(cid:1)(cid:11)
 " (cid:2)(cid:1)		 (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9)(cid:15) %(cid:11)(cid:9) (cid:13)$(cid:8)$ (cid:18)(cid:9)  (cid:18)(cid:1)#(cid:9)
(cid:6) (cid:11)(cid:9) $(cid:8)$ (cid:18)(cid:9)  (cid:30)" (cid:9) (cid:10)(cid:2)(cid:1)(cid:27) (cid:11)(cid:9) (cid:18)(cid:9)(cid:9)(cid:1)(cid:1)	
(cid:1)(cid:2) (cid:2)(cid:9) (cid:6) (cid:10) $(cid:8)$ (cid:18)(cid:9)  (cid:29)(cid:1)(cid:11) (cid:10)  (cid:10)	(cid:1)(cid:10)
(cid:18)(cid:1)(cid:1)(cid:30)	(cid:1) (cid:11)(cid:10)(cid:20)(cid:1)(cid:27) (cid:10) (cid:10)   (cid:20)(cid:10)(cid:1)(cid:10)(cid:2)(cid:9) (cid:10) (cid:29)(cid:9) (cid:29)(cid:1)   (cid:9)(cid:9) (cid:30)(cid:9)	
 (cid:29)(cid:15) %(cid:11)(cid:1) (cid:20)(cid:10)(cid:1)(cid:10)(cid:1) (cid:10)  (cid:29) 	  (cid:11) (cid:11)(cid:9) (cid:1)(cid:9) (cid:9)(cid:1)(cid:9)
(cid:18)(cid:9)  (cid:1) (cid:10) (cid:2)  (cid:9)(cid:18) (cid:29)(cid:10)"(cid:15)

$ (cid:13)$(cid:8)$ (cid:1)(cid:9)	(cid:9)(cid:1)(cid:9) (cid:18)(cid:9)  (cid:1) (cid:18)(cid:9)=(cid:9)(cid:18) (cid:10) (cid:6) 	
 (cid:29)(cid:15) (cid:17)(cid:9) (cid:18)(cid:9)(cid:9) (cid:10) (cid:9)(cid:10)  (cid:9)	(cid:9)(cid:2)(cid:9) (cid:6) (cid:2)(cid:1)		
(cid:30)(cid:9)(cid:20)(cid:10)(cid:1) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:30)" (cid:26) 8 (cid:26)(cid:3)(cid:4) (cid:26)(cid:4)(cid:4) (cid:7) (cid:7) (cid:7) (cid:4) (cid:26)(cid:22) (cid:15) %(cid:1)(cid:9)	
(cid:9)(cid:1)(cid:9) (cid:18)(cid:10)(cid:10) (cid:1) (cid:10) (cid:9)	(cid:9)(cid:2)(cid:9) (cid:6) (cid:20)(cid:10) 	(cid:9) (cid:6) (cid:11)(cid:9)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9)
C (cid:9) (cid:6) (cid:29)(cid:11)(cid:1)(cid:2)(cid:11) (cid:10)" (cid:30)(cid:9) (cid:1)(cid:1)(cid:27)(cid:15) %(cid:11)(cid:9) (cid:18)(cid:9)  (cid:10)	
(cid:2)(cid:1)(cid:10)(cid:9) (cid:10)  (cid:10)(cid:9) L(cid:29)(cid:11)(cid:1)(cid:9) (cid:1)(cid:9)M (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:29)(cid:1)(cid:11) (cid:9)(cid:10)(cid:2)(cid:11) (cid:30)	
(cid:9)(cid:20)(cid:10)(cid:30) (cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9)(cid:15) %(cid:11)(cid:9)(cid:9)  (cid:10)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:10)(cid:9) (cid:18)(cid:9)(cid:9)(cid:18)
(cid:27) 8 (cid:27)(cid:3)(cid:4) (cid:27)(cid:4)(cid:4) (cid:7) (cid:7) (cid:7) (cid:4) (cid:27)(cid:22) (cid:15)
%(cid:11)(cid:9) (cid:13)$(cid:8)$ (cid:18)(cid:9)  (cid:1) (cid:29) (cid:18)(cid:9)=(cid:9)(cid:18) (cid:30)" (cid:11)(cid:9) (cid:2)(cid:18)(cid:1)(cid:1)(cid:10) 
 (cid:10)	(cid:1)(cid:10) (cid:18)(cid:1)(cid:1)(cid:30)	(cid:1)

(cid:26)(cid:0)(cid:26) (cid:4) (cid:7) (cid:7) (cid:7) (cid:4) (cid:26) (cid:3)(cid:4) (cid:27) (cid:4) (cid:7) (cid:7) (cid:7) (cid:4) (cid:27) (cid:4)  (cid:16)(cid:4) (cid:13)*,

(cid:29)(cid:11)(cid:9)(cid:9) (cid:11)(cid:9) (cid:6)	(cid:2)(cid:1)(cid:10)  (cid:9)(cid:22)(cid:9)(cid:1) (cid:6) (cid:11)(cid:9) (cid:9)(cid:10) (cid:16) (cid:10)(cid:18)
(cid:11)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:2)(cid:9) (cid:13) (cid:10)(cid:9) (cid:11)(cid:10)(cid:9)(cid:18) (cid:10)(cid:2) (cid:11)(cid:9) (cid:30)(cid:9)(cid:20)(cid:10)(cid:1) (cid:20)(cid:10)(cid:1)	
(cid:10)(cid:30) (cid:9)(cid:15) %(cid:11)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:2)(cid:9) (cid:1) =(cid:22)(cid:9)(cid:18) (cid:10) (cid:10) (cid:27)(cid:1)(cid:20)(cid:9) (cid:10)   (cid:20)(cid:10) 	(cid:9) 
(cid:30)(cid:9) (cid:9)(cid:2)(cid:1)=(cid:9)(cid:18) (cid:30)" (cid:11)(cid:9) 	(cid:9)(cid:15) %(cid:11)(cid:9) (cid:9)(cid:10) (cid:1) (cid:9) (cid:10)(cid:9)(cid:18)  (cid:11)(cid:9)
(cid:2)(cid:18)(cid:1)(cid:1)(cid:10)  (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:10) (cid:6)  (cid:29)





(cid:12)(cid:24)(cid:27) (cid:24) 

(cid:28)(cid:25)(cid:26) (cid:25)

*+

(cid:5)(cid:24)(cid:5)(cid:6)

(cid:16) 8 (cid:11) 

(cid:5)(cid:25)(cid:5)(cid:3)
(cid:29)(cid:11)(cid:9)(cid:9) (cid:11) (cid:1) (cid:11)(cid:9) (cid:1)(cid:9)(cid:2)(cid:9) (cid:6) (cid:11)(cid:9) (cid:9)(cid:27)(cid:9)(cid:1)
(cid:1) (cid:11)(cid:9) (cid:10)	(cid:9)(cid:27)(cid:9)(cid:1)(cid:20)(cid:9) $(cid:8) (cid:10) 

(cid:25)(cid:5)(cid:3) (cid:28)(cid:25)(cid:26) (cid:25)
(cid:24)(cid:5)(cid:6) (cid:12)(cid:24)(cid:27) (cid:24) (cid:1) (cid:11)(cid:9)
(cid:20)(cid:1)(cid:27) (cid:10)(cid:20)(cid:9)(cid:10)(cid:27)(cid:9) $ (cid:10) (cid:29)(cid:1)(cid:11) (cid:12)(cid:6) =(cid:22)(cid:9)(cid:18) (cid:10) * (cid:10)(cid:18)

4 (cid:11)(cid:9) (cid:10)(cid:30)(cid:20)(cid:9) (cid:18)(cid:9)(cid:2)(cid:1)(cid:1) (cid:9) (cid:10)" (cid:9)(cid:10) (cid:1)’(cid:9) (cid:11)(cid:10) (cid:10)
$(cid:8)$ (cid:18)(cid:9)  (cid:1) (cid:11)(cid:9)  (cid:1)(cid:1) (cid:6) (cid:10) (cid:13)$(cid:8)$ (cid:18)(cid:9)  (cid:10)
(cid:13) (cid:10) 0(cid:15) (cid:9)(cid:1)(cid:27) (cid:13) (cid:10) 0 (cid:29)(cid:1)   (cid:1) (cid:9)#(cid:9)(cid:2) (cid:9) (cid:10)(cid:2)(cid:9) (cid:11)(cid:9) (cid:2)(cid:18)(cid:1)	
(cid:1)(cid:10)   (cid:10)	(cid:1)(cid:10) (cid:18)(cid:1)(cid:1)(cid:30)	(cid:1) (cid:1) *, (cid:30)" (cid:10) (cid:18)(cid:9)(cid:9)(cid:1)(cid:1)(cid:1)(cid:2)
(cid:9) (cid:10)(cid:1) (cid:29)(cid:11)(cid:9)(cid:9) (cid:26) (cid:9)	(cid:10)  (cid:11)(cid:9) (cid:1)(cid:27)(cid:11)	(cid:11)(cid:10)(cid:18) (cid:1)(cid:18)(cid:9) (cid:6) *+(cid:15)
(cid:17)(cid:9) (cid:10)(cid:9) (cid:1)(cid:9)(cid:9)(cid:9)(cid:18) (cid:1) (cid:2)	(cid:1)(cid:27) (cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:11)(cid:9)
(cid:6)(cid:16)(cid:9)(cid:9)(cid:2)   (cid:17)	 (cid:9)(cid:19)(cid:0) (cid:9)(cid:20)(cid:16) (cid:16)(cid:0)  (cid:29)(cid:11)(cid:9)(cid:9) (cid:29)(cid:9) (cid:2)(cid:18)(cid:1)(cid:1) 
(cid:11)(cid:9) = (cid:30) 8 (cid:24)(cid:6)(cid:4)  (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9)(cid:15) (cid:8)(cid:9) (cid:10)(cid:1) (cid:30)(cid:9)(cid:29)(cid:9)(cid:9)
(cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:6)  (cid:11) (cid:30) (cid:2)(cid:10) (cid:11)(cid:9)(cid:9)(cid:6)(cid:9) (cid:30)(cid:9) (cid:1)(cid:27)(cid:9)(cid:18)(cid:15) %(cid:11)(cid:9)
(cid:27)(cid:10)(cid:11)(cid:1)(cid:2)(cid:10)  (cid:9)(cid:9)(cid:9)(cid:10)(cid:1) (cid:6) (cid:10) (cid:13)$(cid:8)$// (cid:18)(cid:9)  (cid:1)
(cid:11)(cid:29) (cid:1) 4(cid:1)(cid:27)	(cid:9) *(cid:15)  (cid:11)	 (cid:18) (cid:30)(cid:9) (cid:9)(cid:18) (cid:11)(cid:10) (cid:1)(cid:6) (cid:29)(cid:9) (cid:10)(cid:1)	
=(cid:2)(cid:1)(cid:10)  " (cid:9)(cid:22)(cid:9)(cid:18) (cid:11)(cid:9) (cid:1)(cid:9) (cid:9)(cid:1)(cid:9) (cid:30)(cid:10)(cid:2)(cid:16) (cid:1) (cid:1)(cid:9) (cid:6) (cid:8) 		
(cid:30)(cid:9)(cid:20)(cid:9)(cid:18) (cid:1)(cid:9) (cid:9) (cid:11)(cid:1) (cid:18)(cid:9)  (cid:9)(cid:9)(cid:9) (cid:29)(cid:11)(cid:10) (cid:1)
(cid:16)(cid:29) (cid:1) (cid:11)(cid:9)  (cid:1)(cid:9)(cid:10)	(cid:9) (cid:10) (cid:11)(cid:9) (cid:0)(cid:11)(cid:2)(cid:6)  (cid:9)(cid:19)(cid:0) (cid:9)(cid:20)(cid:16) (cid:16)(cid:0) (cid:15)
%(cid:11)(cid:9)(cid:9) (cid:10)(cid:9) (cid:10) (cid:9)(cid:10)(cid:1)(cid:20)(cid:9) (cid:9)(cid:11)(cid:18) (cid:6) (cid:18)(cid:9)(cid:10) (cid:1)(cid:27) (cid:29)(cid:1)(cid:11) (cid:11)(cid:9) (cid:30)(cid:9)	
(cid:27)(cid:1)(cid:1)(cid:27) (cid:6) (cid:10) (cid:1)(cid:9) (cid:9)(cid:1)(cid:9) (cid:9)(cid:9) (cid:9)(cid:15)(cid:27)(cid:15) -(cid:22) (cid:9)(cid:16)(cid:1) (cid:10)(cid:18)
(cid:8)(cid:9)(cid:1)(cid:9)  *++2(cid:15)

E1

Y1

E2

Y2

E3

Y3

E4

Y4

E5

Y5

4(cid:1)(cid:27)	(cid:9) *N  (cid:10)(cid:11)(cid:1)(cid:2)(cid:10)  (cid:9)(cid:9)(cid:9)(cid:10)(cid:1) (cid:6) (cid:13)$(cid:8)$//
(cid:1)(cid:9)	(cid:9)(cid:1)(cid:9) (cid:18)(cid:9)  (cid:29)(cid:1)(cid:11) =(cid:20)(cid:9) (cid:30)(cid:9)(cid:20)(cid:10)(cid:1)(cid:15)

(cid:9) 	 = (cid:2)(cid:1)(cid:18)(cid:9) (cid:11)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:2)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) (cid:29)
(cid:29)(cid:11)(cid:1)(cid:2)(cid:11) (cid:1) (cid:1)(cid:9)(cid:18) (cid:10)(cid:2) (cid:10)   (cid:11)(cid:9) L(cid:29)(cid:11)(cid:1)(cid:9) (cid:1)(cid:9)M (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9)
(cid:27)(cid:26)(cid:4) (cid:27)(cid:26)(cid:3)(cid:4) (cid:7) (cid:7) (cid:7) (cid:4) (cid:27)(cid:22) (cid:15) (cid:17)(cid:9) (cid:1)(cid:9)(cid:18)  	(cid:9) *5  (cid:2)	(cid:9)
(cid:11)(cid:9) (cid:10)(cid:1)(cid:10)  (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:11)(cid:1) (cid:10)(cid:10)(cid:9)(cid:9) (cid:10)(cid:18) (cid:29)(cid:1)   (cid:11)(cid:9)(cid:9)	
(cid:6)(cid:9) = (cid:18)(cid:9)(cid:1)(cid:20)(cid:9) (cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:1) (cid:6) (cid:10) (cid:10)(cid:1)(cid:10)  (cid:27)(cid:10)(cid:18)(cid:1)(cid:9)
	(cid:18)(cid:9) (cid:11)(cid:9) (cid:10)	(cid:1) (cid:11)(cid:10) (cid:11)(cid:9) (cid:29) (cid:10)(cid:10)(cid:9)(cid:9) (cid:6) (cid:11)(cid:9)(cid:9)
(cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:10)(cid:9)  (cid:1)(cid:9)(cid:18)(cid:15) (cid:1)(cid:2)(cid:9) (cid:11)(cid:10) (cid:29) (cid:29)(cid:1)   (cid:1) (cid:11)(cid:1) (cid:2)(cid:10)(cid:9)
(cid:10)(cid:16)(cid:9) (cid:11)(cid:9)  (cid:10)(cid:2)(cid:9) (cid:6) (cid:11)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:2)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) (cid:13) (cid:1) (cid:10)   (cid:6) (cid:11)(cid:9)
(cid:6)	 (cid:10) (cid:1) <(cid:9)(cid:2)(cid:1) 2(cid:15)E(cid:15) $  (cid:9)(cid:2)(cid:10)   (cid:11)(cid:10) (cid:11)(cid:9) L(cid:29)(cid:11)(cid:1)(cid:9)
(cid:1)(cid:9)M (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9) (cid:18)  (cid:11)(cid:10)(cid:20)(cid:9) (cid:10)" (cid:10)(cid:9) (cid:29)(cid:11)(cid:1)(cid:2)(cid:11) (cid:9)(cid:10)
(cid:11)(cid:10) (cid:11)(cid:9)(cid:9) (cid:10)(cid:9)  (cid:9)(cid:27)(cid:9)(cid:1) (cid:2)(cid:9)Æ(cid:2)(cid:1)(cid:9) (cid:10)(cid:18) (cid:11)(cid:9)(cid:2)(cid:9) 
(cid:10)(cid:1)(cid:10)  (cid:18)(cid:9)(cid:1)(cid:20)(cid:10)(cid:1)(cid:20)(cid:9) (cid:29)(cid:1)(cid:11) (cid:9)(cid:9)(cid:2)  (cid:12)(cid:15) -(cid:9)(cid:2)(cid:10)	(cid:9) (cid:11)(cid:9)  (cid:10)		
(cid:1)(cid:10) (cid:18)(cid:1)(cid:1)(cid:30)	(cid:1) (cid:1) (cid:9)(cid:1)(cid:2)(cid:9)(cid:18)  (cid:11)(cid:10)(cid:20)(cid:9) (cid:10) (cid:9)(cid:10) (cid:6) ’(cid:9)
(cid:29)(cid:9) (cid:1)(cid:20)(cid:16)(cid:9) (cid:11)(cid:9) (cid:2)(cid:11)(cid:10)(cid:1)		 (cid:9) (cid:2)(cid:9) (cid:9) (cid:10)(cid:18) 	 (cid:1) " (cid:11)(cid:9)
(cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:9)(cid:22)(cid:9)(cid:1) (cid:1) *2 (cid:30)" (cid:11)(cid:9) (cid:10)(cid:2)(cid:30)(cid:1)(cid:10) H0 *I(cid:2) (cid:27)(cid:1)(cid:27)
(cid:6) (cid:11)(cid:9) (cid:11)(cid:4) (cid:29) (cid:10)(cid:10)(cid:9)(cid:9)(cid:1)’(cid:10)(cid:1)  (cid:10) (cid:10)(cid:10)(cid:9)(cid:9)(cid:1)’(cid:10)(cid:1)
(cid:29)(cid:11)(cid:9)(cid:9) (cid:29) (cid:1) (cid:11)(cid:9)  " (cid:10)(cid:10)(cid:9)(cid:9)(cid:15) (cid:1)(cid:2)(cid:9) (cid:11)(cid:10) (cid:30)(cid:9)(cid:2)(cid:10)	(cid:9)
(cid:11)(cid:9) (cid:10)(cid:2)(cid:30)(cid:1)(cid:10) (cid:1) (cid:2)(cid:10) (cid:29)(cid:1)(cid:11) (cid:9)(cid:9)(cid:2)  (cid:11)(cid:9) (cid:1)(cid:9)(cid:27)(cid:10) 
(cid:1) *E (cid:11)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:2)(cid:10) (cid:30)(cid:9) (cid:2)	(cid:9)(cid:18) (cid:30)"
(cid:1) " 	 (cid:1) "(cid:1)(cid:27) (cid:11)(cid:9) (cid:10)(cid:2)(cid:30)(cid:1)(cid:10) (cid:10)(cid:18) (cid:9)	(cid:10)(cid:1) *2(cid:15) $
(cid:9)(cid:22)(cid:9)(cid:2)(cid:9)(cid:18) (cid:29)(cid:9) (cid:30)(cid:10)(cid:1) (cid:10) (cid:10)(cid:1)(cid:10)  (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:11)(cid:9) 	(cid:1)(cid:9)(cid:18)
(cid:20)(cid:10)(cid:1)(cid:10)(cid:2)(cid:9) (cid:6) (cid:27) (cid:11)(cid:10) (cid:9)	(cid:10)  (cid:11)(cid:9) (cid:10)(cid:1)(cid:10)  (cid:18)(cid:9)(cid:1)(cid:20)(cid:10)(cid:1)(cid:20)(cid:9) (cid:6)
(cid:11)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:2)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) (cid:1) *2 C (cid:30)	 (cid:1) (cid:1)  	(cid:1)(cid:9) (cid:10)
(cid:2) (cid:1)(cid:2)(cid:10)(cid:9)(cid:18) (cid:30)(cid:9)(cid:2)(cid:10)	(cid:9) (cid:11) 8 0 (cid:10)(cid:18) (cid:27) (cid:11)(cid:10)  (cid:10)(cid:9)(cid:15) 4(cid:1)	
(cid:10)  " (cid:30)" 	(cid:1)(cid:27) *5 (cid:29)(cid:9) (cid:10)(cid:1)(cid:20)(cid:9) (cid:10) (cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:1) (cid:6) (cid:11)(cid:9)

347(cid:10)(cid:1)(cid:10)  (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:29)(cid:1)(cid:11) (cid:9)(cid:9)(cid:2)  (cid:11)(cid:9) (cid:1)(cid:9)(cid:18) (cid:29) (cid:10)(cid:10)(cid:9)(cid:9)

(cid:15)  (cid:27) (cid:14)(cid:0)(cid:3)

(cid:15)(cid:29)

8

(cid:22)

(cid:5)(cid:5)(cid:26)(cid:3)

!!   (cid:29)

/(cid:29)(cid:4)

(cid:7)

/0

 (cid:10) (cid:1)(cid:1) (cid:10) (cid:6)(cid:10)(cid:11)(cid:1) (cid:29)(cid:9) (cid:2)(cid:10) (cid:18)(cid:9)(cid:1)(cid:20)(cid:9) (cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6)
(cid:11)(cid:9) (cid:6)(cid:9)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) (cid:11) (cid:28)(cid:3)(cid:4) (cid:7) (cid:7) (cid:7) (cid:4) (cid:28) (cid:10)(cid:18) (cid:12)(cid:3)(cid:4) (cid:7) (cid:7) (cid:7) (cid:4) (cid:12)
(cid:10)(cid:2)(cid:1)(cid:10)(cid:9)(cid:18) (cid:29)(cid:1)(cid:11) (cid:11)(cid:9) (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)   (cid:10)	(cid:1)(cid:10) (cid:18)(cid:1)(cid:1)(cid:30)	(cid:1)
(cid:6) (cid:11)(cid:9) (cid:30)(cid:9)(cid:20)(cid:10)(cid:1) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9)(cid:15) $ (cid:10)(cid:30)(cid:20)(cid:9) (cid:29)(cid:9) (cid:10) "
(cid:11)(cid:9) (cid:2)(cid:11)(cid:10)(cid:1) 	 (cid:9)  (cid:10)(cid:2)(cid:11)(cid:1)(cid:9)(cid:20)(cid:9) (cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:11)(cid:9) (cid:6)(cid:9)(cid:9)
(cid:10)(cid:10)(cid:9)(cid:9)(cid:15) (cid:9) " 8 (cid:26) (cid:4) (cid:7) (cid:7) (cid:7) (cid:4) (cid:26) (cid:3)(cid:4) (cid:27) (cid:4) (cid:7) (cid:7) (cid:7) (cid:4) (cid:27)
(cid:18)(cid:9)(cid:9) (cid:10)   (cid:11)(cid:9) (cid:10)(cid:9) (cid:6) (cid:11)(cid:9) (cid:30)(cid:9)(cid:20)(cid:10)(cid:1) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9)
(cid:26) (cid:10)(cid:18)  (cid:9) # 8 "  (cid:27) (cid:18)(cid:9)(cid:9) (cid:11)(cid:9) (cid:10)(cid:9) (cid:9)(cid:22)(cid:2)(cid:9)
(cid:6) (cid:11)(cid:9) (cid:10)(cid:9) (cid:27) (cid:10)(cid:2)(cid:1)(cid:10)(cid:9)(cid:18) (cid:29)(cid:1)(cid:11) (cid:11)(cid:9) =(cid:22)(cid:9)(cid:18) (cid:9)(cid:27)(cid:9)	
(cid:1) (cid:2)(cid:9)Æ(cid:2)(cid:1)(cid:9) (cid:12)(cid:6)(cid:15) (cid:17)(cid:9) (cid:18)(cid:9)(cid:9) (cid:10)   (cid:6) (cid:11)(cid:9) (cid:9)(cid:27)(cid:9)(cid:1)
(cid:2)(cid:9)Æ(cid:2)(cid:1)(cid:9) (cid:30)" (cid:12) 8 (cid:28)(cid:3)(cid:4) (cid:7) (cid:7) (cid:7) (cid:4) (cid:28)(cid:4) (cid:12)(cid:6)(cid:4) (cid:12)(cid:3)(cid:4) (cid:7) (cid:7) (cid:7) (cid:4) (cid:12) (cid:10)(cid:18)  (cid:9)
(cid:12)(cid:27) 8 (cid:28)(cid:3)(cid:4) (cid:7) (cid:7) (cid:7) (cid:4) (cid:28)(cid:4) (cid:12)(cid:3)(cid:4) (cid:7) (cid:7) (cid:7) (cid:4) (cid:12) (cid:18)(cid:9)(cid:9) (cid:11)(cid:9) (cid:6)(cid:9)(cid:9) (cid:9)(cid:27)(cid:9)	
(cid:1) (cid:2)(cid:9)Æ(cid:2)(cid:1)(cid:9)(cid:15) %(cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:1) (cid:6) (cid:11)(cid:9) (cid:10)(cid:1)(cid:10)  (cid:27)(cid:10)(cid:18)(cid:1)	
(cid:9) (cid:6) (cid:11)(cid:9) (cid:1)(cid:9)(cid:18) (cid:11) (cid:10)(cid:18) (cid:12)(cid:27) (cid:10)(cid:10)(cid:9)(cid:9) (cid:29) (cid:30)(cid:9)(cid:2)(cid:9)

(cid:15)  (cid:27) (cid:14)(cid:0)(cid:3)

(cid:15)(cid:11)(cid:4) (cid:12)(cid:27) 

8

(cid:22)

(cid:5)(cid:5)(cid:26)(cid:3)(cid:26) (cid:6)   (cid:12)(cid:24)   (cid:11) (cid:21)(cid:13)
(cid:3)(cid:6)$   (cid:11)$   (cid:12)(cid:27)$(cid:2)

$(cid:4) (cid:21)(cid:13) (cid:27)(cid:2)

(cid:7)

  !(cid:13)(cid:6)	(cid:13) (cid:5)(cid:11) "	(cid:24)(cid:16) #$

 (cid:11)(cid:1) (cid:10)(cid:9) (cid:29)(cid:9) (cid:18)(cid:9)(cid:1)(cid:20)(cid:9)(cid:18) (cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:9)(cid:2)	(cid:1)(cid:20)(cid:9) (cid:9)(cid:22)	
(cid:9)(cid:1)(cid:10)  (cid:1)(cid:22)(cid:9)(cid:18) (cid:18)(cid:9)  (cid:10) (cid:2) (cid:10) (cid:6) (cid:30)(cid:10)(cid:30)(cid:1) (cid:1)(cid:1)(cid:2) (cid:18)	
(cid:9)  (cid:29)(cid:1)(cid:11) (cid:30)(cid:11) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:10)(cid:18) (cid:2)(cid:1)		 (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9)(cid:15) (cid:17)(cid:9)
(cid:18)(cid:9)(cid:10)(cid:9)(cid:18) (cid:11)(cid:10) (cid:1)(cid:1)(cid:20)(cid:9) (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)   (cid:10)	(cid:1)(cid:10) (cid:18)	
(cid:9)  (cid:10)(cid:9) (cid:10) (cid:9)(cid:2)(cid:1)=(cid:2) 	(cid:30)(cid:2) (cid:10) (cid:6) (cid:11)(cid:9) (cid:8)(cid:21) (cid:10)(cid:18) (cid:11)(cid:10)
(cid:9) (cid:2)(cid:10) 	(cid:9) (cid:30)(cid:10)(cid:30)(cid:1) (cid:1)(cid:1)(cid:2) (cid:1)(cid:6)(cid:9)(cid:9)(cid:2)(cid:9)  (cid:2)	(cid:9) (cid:11)(cid:9) (cid:10)	
(cid:10)(cid:9)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:11)(cid:9) (cid:1)(cid:2) (cid:9)(cid:9)	(cid:18)(cid:10)(cid:10)  (cid:1)(cid:16)(cid:9) (cid:1)(cid:11)(cid:18) (cid:6)
(cid:11)(cid:9)(cid:9) (cid:18)(cid:9) (cid:15) $ (cid:18)(cid:9)(cid:2)(cid:1)(cid:9)(cid:18) (cid:10)(cid:30)(cid:20)(cid:9) (cid:9) (cid:2)(cid:10) 	(cid:9) (cid:11)(cid:1) (cid:27)(cid:10)	
(cid:18)(cid:1)(cid:9)  (cid:10)(cid:18)(cid:10) (cid:11)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) (cid:1) (cid:18)(cid:9)  (cid:1)(cid:20)(cid:9) (cid:11)(cid:9)
(cid:1)(cid:2) (cid:9)(cid:9)	(cid:18)(cid:10)(cid:10)  (cid:1)(cid:16)(cid:9) (cid:1)(cid:11)(cid:18) (cid:10)(cid:18) (cid:1)(cid:18)(cid:9)(cid:1)(cid:6)" (cid:11)(cid:9) (cid:21) 
 (cid:2)(cid:10)  (cid:10)(cid:22)(cid:1)(cid:10) (cid:6) (cid:11)(cid:9)  (cid:1)(cid:16)(cid:9) (cid:1)(cid:11)(cid:18)(cid:15)
 (cid:1) (cid:9)(cid:10)"  (cid:9)(cid:22)(cid:9)(cid:18)
(cid:11)(cid:1) (cid:10)(cid:10) "(cid:1)  (cid:30)(cid:10)(cid:1) (cid:1)(cid:1) (cid:10) (cid:9)	  (cid:6) $ (cid:9)(cid:1)	
(cid:10)(cid:1) (cid:30)" (cid:18)(cid:1)#(cid:9)(cid:9)(cid:1)(cid:10)(cid:1)(cid:27) (cid:10) (cid:1) (cid:29)(cid:1)(cid:11) (cid:9)(cid:9)(cid:2)  (cid:11)(cid:9)
(cid:10)(cid:10)(cid:9)(cid:9) (cid:6) (cid:1)(cid:9)(cid:9)(cid:15)

$ (cid:9)(cid:10)(cid:1)(cid:20)(cid:9) (cid:9)(cid:11)(cid:18) (cid:6)  (cid:9)(cid:10)(cid:1)(cid:27) (cid:10)(cid:10)(cid:9)(cid:9) (cid:11)(cid:10) (cid:18)
 (cid:18)(cid:1)(cid:9)(cid:2) " (cid:2)	(cid:9) (cid:11)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:9)(cid:22)(cid:1)(cid:15) 4
(cid:1)(cid:10)(cid:2)(cid:9) (cid:11)(cid:9) (cid:21) (cid:10) (cid:27)(cid:1)(cid:11) (cid:1) (cid:10) (cid:27)(cid:9)(cid:9)(cid:10)  (cid:9)(cid:11)(cid:18) (cid:6)
(cid:1)(cid:20)(cid:1)(cid:27) (cid:10)(cid:10)(cid:9)(cid:9) (cid:6) (cid:10) (cid:10)(cid:1)(cid:1)(cid:2)(cid:10)  (cid:18)(cid:9)  (cid:27)(cid:1)(cid:20)(cid:9) (cid:1)	
(cid:2) (cid:9)(cid:9) (cid:18)(cid:10)(cid:10)(cid:15)
 (cid:11)(cid:9) (cid:2)(cid:9)(cid:22) (cid:6) (cid:27)(cid:10)(cid:11)(cid:1)(cid:2)(cid:10)  (cid:18)(cid:9) 
(cid:11)(cid:9) (cid:21)	(cid:9) (cid:6) (cid:11)(cid:9) (cid:21) (cid:10) (cid:27)(cid:1)(cid:11) (cid:1) (cid:10)(cid:2)(cid:2) (cid:1)(cid:11)(cid:9)(cid:18) (cid:20)(cid:1)(cid:10)
(cid:30)(cid:10)(cid:30)(cid:1) (cid:1)(cid:1)(cid:2) (cid:1)(cid:6)(cid:9)(cid:9)(cid:2)(cid:9) (cid:1) (cid:11)(cid:9) (cid:27)(cid:10)(cid:11)(cid:1)(cid:2)(cid:10)  (cid:18)(cid:9)  (cid:9)(cid:9) (cid:9)(cid:15)(cid:27)(cid:15)
(cid:10)	(cid:1)’(cid:9) *++B (cid:6) (cid:10) (cid:9)(cid:10)(cid:9) (cid:6) (cid:11)(cid:9) (cid:21) (cid:10) (cid:27)(cid:1)(cid:11)
(cid:6) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:27)(cid:10)(cid:11)(cid:1)(cid:2)(cid:10)  (cid:18)(cid:9) (cid:15)
 (cid:11)	 (cid:18) (cid:30)(cid:9) (cid:9)(cid:18)
(cid:11)(cid:29)(cid:9)(cid:20)(cid:9) (cid:11)(cid:10) (cid:1) (cid:10)" (cid:1)	(cid:10)(cid:1) (cid:9) (cid:2)(cid:10) (cid:1)(cid:20)(cid:9) (cid:11)(cid:9)
(cid:9)(cid:9)(cid:18) (cid:6) (cid:2)(cid:20)(cid:9)(cid:27)(cid:9)(cid:2)(cid:9) (cid:6) (cid:11)(cid:9) (cid:21) (cid:10) (cid:27)(cid:1)(cid:11) (cid:11)	(cid:27)(cid:11) (cid:11)(cid:9)
	(cid:9) (cid:6) (cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:9)(cid:9) (cid:9)(cid:15)(cid:27)(cid:15) %(cid:11)(cid:1)(cid:9) *++B(cid:15) $  (cid:1)
(cid:9) (cid:1)	(cid:10)(cid:1) (cid:11)(cid:9) (cid:21) (cid:10) (cid:27)(cid:1)(cid:11) (cid:2)(cid:10) (cid:30)(cid:9) (cid:10) (cid:1)(cid:9)(cid:18)
 (cid:1)(cid:20)(cid:9) (cid:11)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) (cid:6) (cid:11)(cid:9) (cid:18)(cid:9) (cid:15)  	(cid:2)(cid:11) (cid:1)		
(cid:10)(cid:1) (cid:10) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:9)(cid:11)(cid:18) (cid:2)(cid:10) (cid:6)(cid:9) (cid:30)(cid:9) 	(cid:9)(cid:18) (cid:1)(cid:9)(cid:10)(cid:18)(cid:15)

 (cid:1) (cid:1)(cid:10)  (cid:9) (cid:11)(cid:10) (cid:31)  (cid:18)(cid:9)  (cid:11)(cid:10) (cid:1)(cid:20) (cid:20)(cid:9)
 (cid:2)(cid:10)  (cid:18)(cid:9)(cid:27)(cid:9)(cid:9)(cid:10)(cid:9) (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)   (cid:10)	(cid:1)(cid:10) (cid:18)(cid:9)  (cid:2)(cid:10)
(cid:30)(cid:9) (cid:9)(cid:22)(cid:9)(cid:9)(cid:18) (cid:10) (cid:8)(cid:21)(cid:15) %(cid:11)(cid:9) (cid:9)	(cid:1)(cid:9)(cid:9) (cid:6) 	
(cid:18)(cid:9)(cid:27)(cid:9)(cid:9)(cid:10)(cid:9) (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)   (cid:10)	(cid:1)(cid:10) (cid:29)(cid:11)(cid:9)(cid:9) (cid:11)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:2)(cid:9)
(cid:13) (cid:19) 0 (cid:2)(cid:10) (cid:30)(cid:9) (cid:9)(cid:9) (cid:30)" (cid:9)(cid:22)(cid:10)(cid:1)(cid:1)(cid:27) (cid:11)(cid:9) (cid:9)(cid:22)(cid:9)(cid:1)(cid:10)  (cid:10)	
(cid:10)(cid:9)(cid:9)(cid:1)’(cid:10)(cid:1) (cid:6) (cid:11)(cid:9) (cid:2)(cid:18)(cid:1)(cid:1)(cid:10)   (cid:10)	(cid:1)(cid:10)  (cid:2)(cid:10)  (cid:18)(cid:9) 
(cid:1) <(cid:9)(cid:2)(cid:1) 2(cid:15)E(cid:15) O(cid:6)	(cid:10)(cid:9) " (cid:9) (cid:10)(cid:18)(cid:10)(cid:18) (cid:18)(cid:9) 
(cid:2)(cid:10) (cid:11)(cid:9)(cid:9)(cid:6)(cid:9)  (cid:30)(cid:9) (cid:10)	(cid:10)  " (cid:9)(cid:22)(cid:9)(cid:9)(cid:18) (cid:10) (cid:8)(cid:21)(cid:15)
4 (cid:1)(cid:10)(cid:2)(cid:9) (cid:11)(cid:9) $(cid:8)$ (cid:10) (cid:2)(cid:11)(cid:10)(cid:1)(cid:2) $(cid:8)$ (cid:18)(cid:9) 
(cid:1) (cid:29)(cid:11)(cid:1)(cid:2)(cid:11) (cid:11)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:2)(cid:9) (cid:13) (cid:1) ’(cid:9) (cid:2)(cid:10) (cid:30)(cid:9) (cid:9)(cid:9)(cid:9)(cid:9)(cid:18)
(cid:10) (cid:10) (cid:31)  (cid:18)(cid:9) (cid:15)  (cid:1) (cid:10) (cid:9) 	(cid:9)(cid:1) (cid:10)  (cid:29)(cid:11)(cid:9)(cid:11)(cid:9)
  (cid:30)(cid:10)(cid:30)(cid:1) (cid:1)(cid:1)(cid:2) (cid:1)(cid:6)(cid:9)(cid:9)(cid:2)(cid:9) (cid:2)(cid:10) (cid:30)(cid:9) 	(cid:9)(cid:18)  (cid:9)Æ(cid:2)(cid:1)(cid:9) "
(cid:2)	(cid:9) (cid:11)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) 	(cid:1)(cid:1)(cid:20)(cid:9) (cid:31)  (cid:18)(cid:9) (cid:15)

4(cid:1)(cid:10)  " (cid:11)(cid:9) (cid:2) (cid:10) (cid:6) (cid:8)(cid:21) (cid:11)(cid:10) (cid:11)(cid:9) (cid:10)(cid:18)(cid:20)(cid:10)(cid:10)(cid:27)(cid:9) (cid:20)(cid:9)
(cid:31)  (cid:18)(cid:9)  (cid:6) (cid:10)  (cid:29)(cid:1)(cid:27) (cid:18)(cid:1)(cid:2)(cid:9)(cid:9) (cid:20)(cid:10)(cid:1)(cid:10)(cid:30) (cid:9)  (cid:11)(cid:10)(cid:20)(cid:9) (cid:2)	
(cid:1)		 (cid:10)(cid:9)(cid:15)  (cid:1)(cid:20)(cid:9) (cid:11)(cid:1) (cid:10)(cid:18)(cid:20)(cid:10)(cid:10)(cid:27)(cid:9) (cid:1) (cid:29)	 (cid:18) (cid:30)(cid:9)
(cid:29)(cid:11)(cid:29)(cid:11)(cid:1) (cid:9)  (cid:1)(cid:20)(cid:9)(cid:1)(cid:27)(cid:10)(cid:9) (cid:9)Æ(cid:2)(cid:1)(cid:9) (cid:9)(cid:11)(cid:18) (cid:6) (cid:2)	
	(cid:1)(cid:27) (cid:11)(cid:9) (cid:10)(cid:10)(cid:9)(cid:9) (cid:27)(cid:10)(cid:18)(cid:1)(cid:9) (cid:6) (cid:8)(cid:21) (cid:1)(cid:15)(cid:9)(cid:15) (cid:11)(cid:9)
	(cid:10)(cid:1)" (cid:1) (cid:9)	(cid:10)(cid:1) ,(cid:15)

(cid:15)(cid:16)"(cid:16)(cid:16)(cid:6)(cid:16)

(cid:9) (cid:13)(cid:14) (cid:16)(cid:17) (cid:18)(cid:17) (cid:3)(cid:19)(cid:20)(cid:19)(cid:17) (cid:9) (cid:21) (cid:22)(cid:25)(cid:27) (cid:29) (cid:27)(cid:13) (cid:13)(cid:30)(cid:21)(cid:31)  (cid:25) (cid:13) (cid:25)(cid:27)! (cid:29) (cid:21)
(cid:25)(cid:30)(cid:13)! (cid:21)	(cid:13)(cid:22)(cid:13)(cid:25)#(cid:13)	#(cid:25)(cid:22) (cid:21)#(cid:13)(cid:21)(cid:22)(cid:13) (cid:31)(cid:13)(cid:17) (cid:0)(cid:1)(cid:4)(cid:1)(cid:7)(cid:8) (cid:9)(cid:9)
&(cid:19)’(&(cid:17)

)(cid:25)!(cid:13) (cid:17)   (cid:13) ,(cid:17) -	(cid:13)   .(cid:17) (cid:17)  (cid:21)(cid:21)0(cid:21)1(cid:21) (cid:17) (cid:3)(cid:19)(cid:19)(cid:20)(cid:17)
(cid:9)!(cid:21)(cid:25)#(cid:13) 2(cid:21)2(cid:25) (cid:25)(cid:25)(cid:31) (cid:13)1  1(cid:25)(cid:27) (cid:27)(cid:25)!!(cid:13) #(cid:21)(cid:25)(cid:21)2 (cid:13)(cid:17) (cid:8)(cid:11)(cid:12)(cid:1)(cid:4)
(cid:4)(cid:8)(cid:1)(cid:15) (cid:16)(cid:17) (cid:4)(cid:3)3’(cid:4)44(cid:17)

)(cid:30) 5(cid:17) 6(cid:17) (cid:17) (cid:13) (cid:25) 5(cid:17) (cid:17)  -(cid:13)(cid:25)(cid:13)  5(cid:17) (cid:16)(cid:17) (cid:3)(cid:19)(cid:19)4(cid:17) (cid:18)(cid:1)(cid:4) (cid:4)(cid:1)(cid:4)

(cid:8)(cid:8) (cid:21)(cid:1)(cid:17) (cid:13)1 (cid:13)(cid:13)(cid:14): (cid:13)(cid:25)(cid:31)(cid:13)  (cid:21)  (cid:17)

5(cid:13) (cid:21) (cid:9)(cid:17) (cid:16)(cid:21) (cid:25) (cid:17) )(cid:17) .(cid:13)  (cid:17) .(cid:17)  -	2(cid:25) ,(cid:17) )(cid:17) (cid:3)(cid:19)(cid:19)&(cid:17)

(cid:0)(cid:8)(cid:21)(cid:4)(cid:1)(cid:8) (cid:22)(cid:8)(cid:8) (cid:8)(cid:8) (cid:21)(cid:1)(cid:17) !: (cid:16)(cid:27)(cid:21)(cid:21) (cid:21)!  (cid:21)  (cid:17)

(cid:25)(cid:25)#(cid:13)(cid:25)  (cid:17) .(cid:13)(cid:13)! =(cid:17) (cid:17)  (cid:16)(cid:21) (cid:25) (cid:17) )(cid:17) (cid:3)(cid:19)>4(cid:17) -(cid:13)(cid:31)	(cid:25)#(cid:13) (cid:31)(cid:21)	(cid:21) 
!(cid:13) (cid:17) 	(cid:8)  (cid:25) (cid:12)(cid:4) (cid:26)	(cid:8) (cid:1)(cid:8) (cid:8)(cid:12)(cid:4)(cid:8)(cid:1)(cid:11)(cid:8)  (cid:27)(cid:11)(cid:1)(cid:4)(cid:21) (cid:28)(cid:9)
3(cid:6)’&(cid:4)(cid:17)

(cid:21)	(cid:25)0(cid:13) .(cid:17) (cid:17) (cid:3)(cid:19)(cid:19)&(cid:17) =(cid:27)(cid:13) 6 (cid:21) (cid:22)(cid:25)(cid:27) (cid:29) (cid:22)(cid:21)(cid:27)(cid:25)(cid:31)(cid:21)  (cid:21)(cid:31)(cid:25)(cid:21)(cid:25)
!(cid:13)  1(cid:25)(cid:27) (cid:25)(cid:25)(cid:22) !(cid:21)(cid:21)(cid:17) (cid:29)	(cid:8)(cid:1)(cid:8)  (cid:27)(cid:8)(cid:1)(cid:1)(cid:11)   (cid:8)(cid:8)
(cid:26)(cid:8) (cid:21)(cid:1) !(cid:17) (cid:3)(cid:19)(cid:3)’(cid:4)(cid:6)(cid:3)(cid:17)

(cid:21)	(cid:25)0(cid:13) .(cid:17) (cid:17) ,(cid:21)1(cid:25)! (cid:9)(cid:17) (cid:17) (cid:21)(cid:13) )(cid:17) (cid:17)  (cid:13)(cid:25)(cid:13)  (cid:17)	5(cid:17)
(cid:3)(cid:19)(cid:19)(cid:6)(cid:17) !(cid:13)(cid:13)!(cid:13)(cid:31)(cid:13) (cid:13)(cid:25)(cid:13) (cid:29) !(cid:25)(cid:13)(cid:31)(cid:13)! (cid:21) # @(cid:13) !(cid:17) (cid:4)	
$(cid:7) (cid:16)% 4(cid:19)(cid:3)’&(cid:6)&(cid:17)

(cid:21)	(cid:25)0(cid:13) .(cid:17) (cid:17)  (cid:13)(cid:13) (cid:18)(cid:17) (cid:4)(cid:6)(cid:6)(cid:3)(cid:17) .(cid:21)2 (cid:13)  (cid:31)(cid:21)  (cid:31)	(cid:21)(cid:25) 1(cid:25)(cid:27)
(cid:31)!(cid:25)(cid:25)(cid:21)  (cid:22)(cid:21)	(cid:25)(cid:21) !(cid:25)(cid:25)2	(cid:25)(cid:17) (cid:27)(cid:8)(cid:1)(cid:1)(cid:11) (cid:8)(cid:22) (cid:29)	(cid:1)(cid:15)
!! (cid:3)(cid:19)(cid:3)’(cid:4)(cid:6)3(cid:17)

(cid:21)	(cid:25)0(cid:13) .(cid:17) (cid:17)  A(cid:13)	(cid:27) (cid:17) (cid:3)(cid:19)>(cid:19)(cid:17) 5(cid:21)(cid:27)(cid:25)(cid:31)(cid:21)  !(cid:13)  (cid:29) (cid:21)	
(cid:31)(cid:25)(cid:21)(cid:25) 2(cid:13)1(cid:13)(cid:13) #(cid:21)(cid:25)(cid:21)2 (cid:13) (cid:13) (cid:29) 1(cid:27)(cid:25)(cid:31)(cid:27) (cid:21)(cid:13) 	(cid:21) (cid:25)(cid:21)(cid:25)#(cid:13) (cid:21)!
(cid:13) 	(cid:21)(cid:25)(cid:21)(cid:25)#(cid:13)(cid:17) (cid:18)(cid:12)(cid:4) (cid:26)(cid:8)  (cid:25) (cid:27)(cid:8)(cid:1)(cid:1)(cid:11) !& 3(cid:3)’&(cid:20)(cid:17)

.(cid:31)(cid:27)(cid:13)#(cid:25)(cid:27) (cid:17) (cid:17) (cid:3)(cid:19)(cid:19)&(cid:17) (cid:18)(cid:12)(cid:4)(cid:21) (cid:25) (cid:8)(cid:1)(cid:1)(cid:11)(cid:17) (cid:13)1 C : .(cid:25)(cid:22)(cid:13)	

D(cid:13) (cid:21)(cid:22)(cid:17)

=(cid:27)(cid:25)(cid:13) )(cid:17) (cid:3)(cid:19)(cid:19)&(cid:17) (cid:9)(cid:31)(cid:31)(cid:13) (cid:13)(cid:21)(cid:13)! 	(cid:21)(cid:25)@(cid:31)(cid:21)(cid:25) (cid:29) )(cid:21)(cid:14)(cid:13)(cid:25)(cid:21) (cid:13)	
1  1(cid:25)(cid:27) (cid:25)(cid:31) (cid:13)(cid:13) !(cid:21)(cid:21)(cid:17) (cid:11)(cid:4)(cid:4)(cid:22)(cid:1)(cid:15) (cid:25) ((cid:1) (cid:4)(cid:8)(cid:1)(cid:8) 
(cid:29)(cid:25)(cid:4)(cid:4)(cid:11)(cid:4)  $ (cid:4)(cid:22)(cid:15)(cid:4)  (cid:1)(cid:11)+(cid:4)(cid:21) (cid:8)(cid:22)  (cid:8)(cid:8) (cid:1)(cid:1)(cid:15) (cid:17) 3(cid:6)(’
3(cid:3)(cid:3)(cid:17) (cid:9)(cid:9)(cid:9) (cid:13)(cid:17)

=(cid:27)(cid:25)(cid:13) )(cid:17) (cid:3)(cid:19)(cid:19)(cid:20)(cid:17) .(cid:31)(cid:13) (cid:21)! (cid:25)(cid:29)(cid:21)(cid:25) (cid:29) (cid:13)(cid:31)	(cid:25)#(cid:13) (cid:13)(cid:30)(cid:13)	
(cid:25)(cid:21)  !(cid:13)  1(cid:25)(cid:27) (cid:25)(cid:31) (cid:13)(cid:13) !(cid:21)(cid:21)(cid:17) (cid:11)(cid:4)(cid:4)(cid:22)(cid:1)(cid:15) (cid:25) (cid:12)(cid:4) (cid:18)(cid:12)(cid:1)(cid:4)(cid:4)(cid:12)
(cid:29)(cid:25)(cid:4)(cid:4)(cid:11)(cid:4)  ,(cid:11)(cid:4)(cid:8)(cid:1)(cid:21) (cid:1) (cid:26)(cid:1)-(cid:11)(cid:1)(cid:8)  (cid:4)  (cid:1)(cid:15)(cid:4)(cid:11)(cid:4) (cid:17) 4&3’
4(3(cid:17) (cid:22)(cid:21) (cid:21)	(cid:29)(cid:21) 	2 (cid:25)(cid:27)(cid:13)(cid:17)

=(cid:27)(cid:25)(cid:13) )(cid:17) (cid:16)(cid:27)(cid:25)(cid:31) (cid:13)(cid:25)(cid:22) ,(cid:17) (cid:17)  (cid:13)(cid:31) (cid:13)(cid:21) ,(cid:17)  (cid:13)(cid:13)  (cid:16)(cid:17) (cid:4)(cid:6)(cid:6)4(cid:17)
(cid:9)-(cid:9) (cid:25)(cid:13)	(cid:13)(cid:25)(cid:13) !(cid:13) (cid:25)(cid:22) 1(cid:25)(cid:27) (cid:22)(cid:21)(cid:27)(cid:25)(cid:31)(cid:21)  !(cid:13) (cid:17) (cid:11)(cid:4)(cid:4)(cid:22)(cid:1)(cid:15)
(cid:25) (cid:12)(cid:4) (cid:18)$(cid:4)(cid:1)(cid:4)(cid:12) (cid:29)(cid:25)(cid:4)(cid:4)(cid:11)(cid:4)  ,(cid:11)(cid:4)(cid:8)(cid:1)(cid:21) (cid:1) (cid:26)(cid:1)-(cid:11)(cid:1)(cid:8)  (cid:4) 	
 (cid:1)(cid:15)(cid:4)(cid:11)(cid:4) (cid:17) &&(cid:4)’&((cid:6)(cid:17) (cid:9)E(cid:9) (cid:13)(cid:17)

348Very Large SVM Training using Core Vector Machines

Ivor W. Tsang

James T. Kwok

Department of Computer Science

The Hong Kong University of Science and Technology

Pak-Ming Cheung

Clear Water Bay

Hong Kong

Abstract

Standard SVM training has O(m3) time and
O(m2) space complexities, where m is the train-
ing set size.
In this paper, we scale up kernel
methods by exploiting the “approximateness” in
practical SVM implementations. We formulate
many kernel methods as equivalent minimum en-
closing ball problems in computational geome-
try, and then obtain provably approximately opti-
mal solutions efﬁciently with the use of core-sets.
Our proposed Core Vector Machine (CVM) al-
gorithm has a time complexity that is linear in m
and a space complexity that is independent of m.
Experiments on large toy and real-world data sets
demonstrate that the CVM is much faster and can
handle much larger data sets than existing scale-
up methods. In particular, on our PC with only
512M RAM, the CVM with Gaussian kernel can
process the checkerboard data set with 1 million
points in less than 13 seconds.

1 Introduction

In recent years, there has been a lot of interest on using
kernels in various machine learning problems, with the sup-
port vector machines (SVM) being the most prominent ex-
ample. Many of these kernel methods are formulated as
quadratic programming (QP) problems. Denote the number
of training patterns by m. The training time complexity of
QP is O(m3) and its space complexity is at least quadratic.
Hence, a major stumbling block is in scaling up these QP’s
to large data sets, such as those commonly encountered in
data mining applications.

To reduce the time and space complexities, a popular tech-
nique is to obtain low-rank approximations on the kernel
matrix, by using the Nystr¨om method (Williams & Seeger,
2001), greedy approximation (Smola & Sch¨olkopf, 2000)
or matrix decompositions (Fine & Scheinberg, 2001).

However, on very large data sets, the resulting rank of the
kernel matrix may still be too high to be handled efﬁciently.

Another approach to scale up kernel methods is by chunk-
ing or more sophisticated decomposition methods. How-
ever, chunking needs to optimize the entire set of non-zero
Lagrange multipliers that have been identiﬁed, and the re-
sultant kernel matrix may still be too large to ﬁt into mem-
ory. Osuna et al. (1997) suggested optimizing only a ﬁxed-
size subset of the training data (working set) each time,
while the variables corresponding to the other patterns are
frozen. Going to the extreme, the sequential minimal opti-
mization (SMO) algorithm (Platt, 1999) breaks a large QP
into a series of smallest possible QPs, each involving only
two variables. In the context of classiﬁcation, Mangasar-
ian and Musicant (2001) proposed the Lagrangian SVM
(LSVM) that avoids the QP (or LP) altogether.
Instead,
the solution is obtained by a fast iterative scheme. How-
ever, for nonlinear kernels (which is the focus in this pa-
per), it still requires the inversion of an m× m matrix. Fur-
ther speed-up is possible by employing the reduced SVM
(RSVM) (Lee & Mangasarian, 2001), which uses a rectan-
gular subset of the kernel matrix. However, this may lead
to performance degradation (Lin & Lin, 2003).

In practice, state-of-the-art SVM implementations typically
have a training time complexity that scales between O(m)
and O(m2.3) (Platt, 1999). This can be further driven down
to O(m) with the use of a parallel mixture (Collobert et al.,
2002). However, these are only empirical observations and
not theoretical guarantees. For reliable scaling behavior to
very large data sets, our goal is to develop an algorithm that
can be proved (using tools in analysis of algorithms) to be
asymptotically efﬁcient in both time and space.

Moreover, practical SVM implementations, as in many nu-
merical routines, only approximate the optimal solution by
an iterative strategy. Typically, the stopping criterion uti-
lizes either the precision of the Lagrange multipliers (e.g.,
(Joachims, 1999; Platt, 1999)) or the duality gap (e.g.,
(Smola & Sch¨olkopf, 2004)). However, while approxi-
mation algorithms (with provable performance guarantees)
have been extensively used in tackling computationally dif-

349ﬁcult problems like NP-complete problems (Garey & John-
son, 1979), such “approximateness” has never been ex-
ploited in the design of SVM implementations.

In this paper, we ﬁrst transform the SVM optimization
problem (with a possibly nonlinear kernel) to the minimum
enclosing ball (MEB) problem in computational geometry.
The MEB problem computes the ball of minimum radius
enclosing a given set of points (or, more generally, balls).
Traditional algorithms for ﬁnding exact MEBs do not scale
well with the dimensionality d of the points. Consequently,
recent attention has shifted to the development of approxi-
mation algorithms. Lately, a breakthrough was obtained by
B˘adoiu and Clarkson (2002), who showed that an (1 + ǫ)-
approximation of the MEB can be efﬁciently obtained us-
ing core-sets. Generally speaking, in an optimization prob-
lem, a core-set is a subset of the input points, such that
we can get a good approximation (with an approximation
ratio1 speciﬁed by a user-deﬁned ǫ parameter) to the orig-
inal input by solving the optimization problem directly on
the core-set. Moreover, a surprising property of (B˘adoiu &
Clarkson, 2002) is that the size of its core-set is indepen-
dent of both d and the size of the point set.

Inspired from this core-set-based approximate MEB al-
gorithm, we will develop an approximation algorithm for
SVM training that has an approximation ratio of (1 + ǫ)2.
Its time complexity is linear in m while its space complex-
ity is independent of m. The rest of this paper is organized
as follows. Section 2 gives a short introduction on the MEB
problem and its approximation algorithm. The connection
between kernel methods and the MEB problem is given in
Section 3. Section 4 then describes our proposed Core Vec-
tor Machine (CVM) algorithm. Experimental results are
presented in Section 5, and the last section gives some con-
cluding remarks.

2 MEB in Computational Geometry

Given a set of points S = {x1, . . . , xm}, where each xi ∈
Rd, the minimum enclosing ball of S (denoted MEB(S))
is the smallest ball that contains all the points in S. The
MEB problem has found applications in diverse areas such
as computer graphics (e.g., collision detection, visibility
culling), machine learning (e.g., similarity search) and fa-
cility locations problems.

C∗ , C∗

C ” ≤ ρ(n).

1Let C be the cost (or value of the objective function) of
the solution returned by an approximate algorithm, and C ∗ be
the cost of the optimal solution. Then, the approximate algo-
rithm has an approximation ratio ρ(n) for an input size n if
max “ C
Intuitively, this measures how bad
the approximate solution is compared with the optimal solution.
A large (small) approximation ratio means the solution is much
worse than (more or less the same as) the optimal solution. Ob-
serve that ρ(n) is always ≥ 1. If the ratio does not depend on
n, we may just write ρ and call the algorithm an ρ-approximation
algorithm.

R

ε
R

the tth iteration,

Here, we will focus on approximate MEB algorithms based
on core-sets. Let B(c, R) be the ball with center c and
radius R. Given ǫ > 0, a ball B(c, (1 + ǫ)R) is an (1 +
ǫ)-approximation of MEB(S) if R ≤ rMEB(S) and S ⊂
B(c, (1 + ǫ)R). A subset X ⊆ S is a core-set of S if an
expansion by a factor (1 + ǫ) of its MEB contains S, i.e.,
S ⊂ B(c, (1 + ǫ)r), where B(c, r) = MEB(X) (Figure 1).
To obtain such an (1 + ǫ)-
approximation, B˘adoiu and
Clarkson (2002) proposed
a simple iterative scheme:
At
the
current estimate B(ct, rt)
is expanded incrementally
by including the furthest
point outside the (1 + ǫ)-
ball B(ct, (1 + ǫ)rt). This
is repeated until all
the
points in S are covered by
B(ct, (1 + ǫ)rt). Despite
its simplicity, B˘adoiu and
Clarkson (2002) showed
that the number of itera-
tions, and hence the size of
the ﬁnal core-set, depends
only on ǫ but not on d or m.
This independence of d is important on applying this algo-
rithm to kernel methods (Section 3) as the kernel-induced
feature space can be inﬁnite-dimensional. As for the inde-
pendence on m, it allows both the time and space complex-
ities of our algorithm to grow slowly, as will be shown in
Section 4.3.

Figure 1: The inner cir-
cle is the MEB of the set
of squares and its (1 + ǫ)
expansion (the outer cir-
cle) covers all the points.
The set of squares is thus a
core-set.

3 MEB Problems and Kernel Methods

Obviously, the MEB is equivalent to the hard-margin sup-
port vector data description (SVDD) (Tax & Duin, 1999),
which will be brieﬂy reviewed in Section 3.1. The MEB
problem can also be used for ﬁnding the radius compo-
nent of the radius-margin bound (Chapelle et al., 2002).
Thus, as pointed out by Kumar et al.
(2003), the MEB
problem is useful in support vector clustering and SVM
parameter tuning. However, we will show in Section 3.2
that other kernel-related problems, including the training
of soft-margin one-class and two-class L2-SVMs, can also
be viewed as MEB problems.

3.1 Hard-Margin SVDD
Given a kernel k with the associated feature map ϕ, let the
MEB in the kernel-induced feature space be B(c, R). The
primal problem in the hard-margin SVDD is

min R2

: kc − ϕ(xi)k2 ≤ R2,

i = 1, . . . , m.

(1)

The corresponding dual is
′diag(K) − α

max α

′Kα : 0 ≤ α, α

′1 = 1,

(2)

350where α = [αi, . . . , αm]′ are the Lagrange multipli-
ers, 0 = [0, . . . , 0]′, 1 = [1, . . . , 1]′ and Km×m =
[k(xi, xj)] = [ϕ(xi)′ϕ(xj )] is the kernel matrix. As is
well-known, this is a QP problem. The primal variables
can be recovered from the optimal α as

mX

p

c =

αiϕ(xi), R =

i=1

α′diag(K) − α′Kα.

(3)

3.2 Viewing Kernel Methods as MEB Problems

In this paper, we consider the situation where

k(x, x) = κ,

(4)

a constant2. This will be the case when either (1) the
isotropic kernel k(x, y) = K(kx−yk) (e.g., Gaussian ker-
nel); or (2) the dot product kernel k(x, y) = K(x′y) (e.g.,
polynomial kernel) with normalized inputs; or (3) any nor-
malized kernel k(x, y) =
is used. Using
the condition α′1 = 1 in (2), we have α′diag(K) = κ.
Dropping this constant term from the dual objective in (2),
we obtain a simpler optimization problem:

√K(x,x)√K(y,y)

K(x,y)

max−α

′Kα : 0 ≤ α, α

′1 = 1.

(5)

Conversely, when the kernel k satisﬁes (4), QP’s of the
form (5) can always be regarded as a MEB problem (1).
Note that (2) and (5) yield the same set of α’s, Moreover,
let d∗
2 denote the optimal dual objectives in (2) and
(5) respectively, then, obviously,

1 and d∗

d∗
1 = d∗

2 + κ.

(6)

In the following, we will show that when (4) is satisﬁed,
the duals in a number of kernel methods can be rewrit-
ten in the form of (5). While the 1-norm error has been
commonly used for the SVM, our main focus will be on
the 2-norm error.
In theory, this could be less robust in
the presence of outliers. However, experimentally, its gen-
eralization performance is often comparable to that of the
L1-SVM (e.g., (Lee & Mangasarian, 2001; Mangasarian &
Musicant, 2001). Besides, the 2-norm error is more advan-
tageous here because a soft-margin L2-SVM can be trans-
formed to a hard-margin one. While the 2-norm error has
been used in classiﬁcation (Section 3.2.2), we will also ex-
tend its use for novelty detection (Section 3.2.1).

3.2.1 One-Class L2-SVM
i=1 where zi only has
Given a set of unlabeled patterns {zi}m
the input part xi, the one-class L2-SVM separates the out-

2In this case, it can be shown that the hard (soft) margin SVDD
yields identical solution as the hard (soft) margin one-class SVM
(Sch¨olkopf et al., 2001). Moreover, the weight w in the one-class
SVM solution is equal to the center c in the SVDD solution.

liers from the normal data by solving the primal problem:

mX

w,ρ,ξi kwk2 − 2ρ + C
min

i=1

ξ2
i

: w′ϕ(xi) ≥ ρ − ξi,

where w′ϕ(x) = ρ is the desired hyperplane and C is a
user-deﬁned parameter. Note that constraints ξi ≥ 0 are
not needed for the L2-SVM. The corresponding dual is

(cid:18)
K +

′

(cid:19)
I

1
C

α : 0 ≤ α, α

′1 = 1

max−α
= max−α

C ].

′1 = 1,

′ ˜Kα : 0 ≤ α, α

(7)
where I is the m×m identity matrix and ˜K = [˜k(zi, zj)] =
[k(xi, xj) + δij
It is thus of the form in (5). Since
k(x, x) = κ, ˜k(z, z) = κ + 1
C ≡ ˜κ is also a constant. This
one-class SVM thus corresponds to the MEB problem (1),
in which ϕ is replaced by the nonlinear map ˜ϕ satisfying
˜ϕ(zi)′ ˜ϕ(zj) = ˜k(zi, zj). From the Karush-Kuhn-Tucker
i=1 αiϕ(xi) and
(KKT) conditions, we can recover w =
ξi = αi
C from any support vector
xi.

C , and ρ = w′ϕ(xi) + αi

P

m

3.2.2 Two-Class L2-SVM
Given a training set {zi = (xi, yi)}m
the primal of the two-class L2-SVM is

i=1 with yi ∈ {−1, 1},

mX

minw,b,ρ,ξi

s.t.

kwk2 + b2 − 2ρ + C
yi(w′ϕ(xi) + b) ≥ ρ − ξi.

i=1

ξ2
i

(8)

The corresponding dual is

′

(cid:18)
K ⊙ yy′ + yy′ +
′ ˜Kα : 0 ≤ α, α

0≤α −α
max
= max−α

(9)
where ⊙ denotes the Hadamard product, y = [y1, . . . , ym]′
and ˜K = [˜k(zi, zj )] with

′1 = 1,

(cid:19)
I

1
C

α : α

′1 = 1

˜k(zi, zj ) = yiyjk(xi, xj) + yiyj +

δij
C

,

(10)

involving both input and label information. Again, this is of
the form in (5), with ˜k(z, z) = κ + 1 + 1
C ≡ ˜κ, a constant.
Again, we can recover

mX

mX

w =

αiyiϕ(xi),

b =

αiyi,

ξi =

i=1

i=1

αi
C

,

(11)

from the optimal α and ρ = yi(w′ϕ(xi) + b) + αi
C from
any support vector zi. Note that all the support vectors
of this L2-SVM, including those deﬁning the margin and
those that are misclassiﬁed, now reside on the surface of the
ball in the feature space induced by ˜k. A similar relation-
ship connecting one-class classiﬁcation and binary classiﬁ-
cation is also described in (Sch¨olkopf et al., 2001).

3514 Core Vector Machine (CVM)
After formulating the kernel method as a MEB problem,
we obtain a transformed kernel ˜k, together with the associ-
ated feature space ˜F, mapping ˜ϕ and constant ˜κ = ˜k(z, z).
To solve this kernel-induced MEB problem, we adopt the
approximation algorithm3 described in the proof of Theo-
rem 2.2 in (B˘adoiu & Clarkson, 2002). As mentioned in
Section 2, the idea is to incrementally expand the ball by
including the point furthest away from the current center.
In the following, we denote the core-set, the ball’s center
and radius at the tth iteration by St, ct and Rt respectively.
Also, the center and radius of a ball B are denoted by cB
and rB. Given an ǫ > 0, the CVM then works as follows:

1. Initialize S0, c0 and R0.
2. Terminate if there is no ˜ϕ(z) (where z is a training
point) falling outside the (1+ǫ)-ball B(ct, (1+ǫ)Rt).

3. Find z such that ˜ϕ(z) is furthest away from ct. Set

St+1 = St ∪ {z}.

4. Find the new MEB(St+1) from (5) and set ct+1 =

cMEB(St+1) and Rt+1 = rMEB(St+1) using (3).

5. Increment t by 1 and go back to step 2.

In the sequel, points that are added to the core-set will be
called core vectors. Details of each of the above steps will
be described in Section 4.1. Despite its simplicity, CVM
has an approximation guarantee (Section 4.2) and also
provably small time and space complexities (Section 4.3).

4.1 Detailed Procedure
4.1.1 Initialization

B˘adoiu and Clarkson (2002) simply used an arbitrary point
z ∈ S to initialize S0 = {z}. However, a good initial-
ization may lead to fewer updates and so we follow the
scheme in (Kumar et al., 2003). We start with an arbi-
trary point z ∈ S and ﬁnd za ∈ S that is furthest away
from z in the feature space ˜F. Then, we ﬁnd another
point zb ∈ S that is furthest away from za in ˜F. The ini-
tial core-set is then set to be S0 = {za, zb}. Obviously,
MEB(S0) (in ˜F) has center c0 = 1
2 ( ˜ϕ(za) + ˜ϕ(zb)) On
using (3), we thus have αa = αb = 1
2 and all the other
αi’s are zero. The initial radius is R0 = 1
2k ˜ϕ(za) −
q
˜ϕ(zb)k = 1
k ˜ϕ(za)k2 + k ˜ϕ(zb)k2 − 2 ˜ϕ(za)′ ˜ϕ(zb) =

2˜κ − 2˜k(za, zb).

1
2
In a classiﬁcation problem, one may further require za and
zb to come from different classes. On using (10), R0 then
becomes 1
+ 2k(xa, xb). As κ and C are
2
constants, choosing the pair (xa, xb) that maximizes R0 is
then equivalent to choosing the closest pair belonging to

(cid:0)
κ + 2 + 1
C

q
2

p

(cid:1)

2

opposing classes, which is also the heuristic used in initial-
izing the SimpleSVM (Vishwanathan et al., 2003).

4.1.2 Distance Computations
Steps 2 and 3 involve computing kct − ˜ϕ(zℓ)k for zℓ ∈ S.
Now,
kct − ˜ϕ(zℓ)k2
(12)
αi˜k(zi, zℓ) + ˜k(zℓ, zℓ),
= X

αiαj ˜k(zi, zj) − 2 X

zi ,zj ∈St

zi∈St

on using (3). Hence, computations are based on kernel
evaluations instead of the explicit ˜ϕ(zi)’s, which may be
inﬁnite-dimensional. Note that, in contrast, existing MEB
algorithms only consider ﬁnite-dimensional spaces.

However, in the feature space, ct cannot be obtained as
an explicit point but rather as a convex combination of
(at most) |St| ˜ϕ(zi)’s. Computing (12) for all m training
points takes O(|St|2 + m|St|) = O(m|St|) time at the tth
iteration. This becomes very expensive when m is large.
Here, we use the probabilistic speedup method in (Smola
& Sch¨olkopf, 2000). The idea is to randomly sample a suf-
ﬁciently large subset S ′ from S, and then take the point in
S ′ that is furthest away from ct as the approximate furthest
point over S. As shown in (Smola & Sch¨olkopf, 2000),
by using a small random sample of, say, size 59, the fur-
thest point obtained from S ′ is with probability 0.95 among
Instead of
the furthest 5% of points from the whole S.
taking O(m|St|) time, this randomized method only takes
O(|St|2 + |St|) = O(|St|2) time, which is much faster as
|St| ≪ m. This trick can also be used in initialization.
4.1.3 Adding the Furthest Point
Points outside MEB(St) have zero αi’s (Section 4.1.1) and
so violate the KKT conditions of the dual problem. As in
(Osuna et al., 1997), one can simply add any such violating
point to St. Our step 3, however, takes a greedy approach
by including the point furthest away from the current cen-
ter. In the classiﬁcation case4 (Section 3.2.2), we have

arg

max

zℓ /∈B(ct,(1+ǫ)Rt)kct − ˜ϕ(zℓ)k2
= arg

X

min

zℓ /∈B(ct,(1+ǫ)Rt)

= arg

min

zℓ /∈B(ct,(1+ǫ)Rt)

αiyiyℓ(k(xi, xℓ) + 1)

zi∈St
yℓ(w′ϕ(xℓ) + b),

(13)

on using (10), (11) and (12). Hence, (13) chooses the worst
violating pattern corresponding to the constraint (8). Also,
as the dual objective in (9) has gradient −2 ˜Kα, so for a
pattern ℓ currently outside the ball

( ˜Kα)ℓ =

mX

αi

i=1

(cid:18)
yiyℓk(xi, xℓ) + yiyℓ +

(cid:19)

δiℓ
C

= yℓ(w′ϕ(xℓ) + b),

3A similar algorithm is also described in (Kumar et al., 2003).

4The case for one-class classiﬁcation (Section 3.2.1) is similar.

352on using (10), (11) and αℓ = 0. Thus, the pattern chosen
in (13) also makes the most progress towards maximizing
the dual objective. This subset selection heuristic has been
commonly used by various decomposition algorithms (e.g.,
(Chang & Lin, 2004; Joachims, 1999; Platt, 1999)).

4.1.4 Finding the MEB

At each iteration of step 4, we ﬁnd the MEB by using the
QP formulation in Section 3.2. As the size |St| of the
core-set is much smaller than m in practice (Section 5),
the computational complexity of each QP sub-problem is
much lower than solving the whole QP. Besides, as only
one core vector is added at each iteration, efﬁcient rank-one
update procedures (Cauwenberghs & Poggio, 2001; Vish-
wanathan et al., 2003) can also be used. The cost then be-
comes quadratic rather than cubic. In the current imple-
mentation (Section 5), we use SMO. As only one point is
added each time, the new QP is just a slight perturbation of
the original. Hence, by using the MEB solution obtained
from the previous iteration as starting point (warm start),
SMO can often converge in a small number of iterations.

4.2 Convergence to (Approximate) Optimality

First, consider ǫ = 0. The proof in (B˘adoiu & Clarkson,
2002) does not apply as it requires ǫ > 0. Nevertheless, as
the number of core vectors increases by one at each itera-
tion and the training set size is ﬁnite, so CVM must termi-
nate in a ﬁnite number (say, τ) of iterations, With ǫ = 0,
MEB(Sτ ) is an enclosing ball for all the points on termina-
tion. Because Sτ is a subset of the whole training set and
the MEB of a subset cannot be larger than the MEB of the
whole set. Hence, MEB(Sτ ) must also be the exact MEB
of the whole ( ˜ϕ-transformed) training set. In other words,
when ǫ = 0, CVM outputs the exact solution of the kernel
problem.

a parameter similar to our ǫ is required at termination. For
example, in SMO and SVMlight (Joachims, 1999), train-
ing stops when the KKT conditions are fulﬁlled within ǫ.
Experience with these softwares indicate that near-optimal
solutions are often good enough in practical applications.
Moreover, it can also be shown that when the CVM ter-
minates, all the points satisfy loose KKT conditions as in
SMO and SVMlight.

4.3 Time and Space Complexities

Existing decomposition algorithms cannot guarantee the
number of iterations and consequently the overall time
complexity (Chang & Lin, 2004). In this Section, we show
how this can be obtained for CVM. In the following, we as-
sume that a plain QP implementation, which takes O(m3)
time and O(m2) space for m patterns, is used for the MEB
sub-problem in Section 4.1.4. Moreover, we assume that
each kernel evaluation takes constant time.

As proved in (B˘adoiu & Clarkson, 2002), CVM converges
in at most 2/ǫ iterations. In other words, the total number
of iterations, and consequently the size of the ﬁnal core-set,
are of τ = O(1/ǫ). In practice, it has often been observed
that the size of the core-set is much smaller than this worst-
case theoretical upper bound (Kumar et al., 2003). This
will also be corroborated by our experiments in Section 5.

Consider ﬁrst the case where probabilistic speedup is not
used in Section 4.1.2. As only one core vector is added at
each iteration, |St| = t + 2. Initialization takes O(m) time
while distance computations in steps 2 and 3 take O((t +
2)2 + tm) = O(t2 + tm) time. Finding the MEB in step 4
takes O((t + 2)3) = O(t3) time, and the other operations
take constant time. Hence, the tth iteration takes O(tm +
t3) time, and the overall time for τ = O(1/ǫ) iterations is

τX

O(tm + t3) = O(τ 2m + τ 4) = O

(cid:18)

(cid:19)

,

m
ǫ2 +

1
ǫ4

Now, consider ǫ > 0. Assume that the algorithm terminates
at the τth iteration, then

t=1

which is linear in m for a ﬁxed ǫ.

Rτ ≤ rMEB(S) ≤ (1 + ǫ)Rτ

(14)

by deﬁnition. Recall that the optimal primal objective p∗
of the kernel problem in Section 3.2.1 (or 3.2.2) is equal to
2 in (7) (or (9)), which in turn
the optimal dual objective d∗
MEB(S) in (2)
is related to the optimal dual objective d∗
by (6). Together with (14), we can then bound p∗ as

1 = r2

(cid:16)

R2
τ ≤ p∗ + ˜κ ≤ (1 + ǫ)2R2
τ .
R2
p∗+˜κ , p∗+˜κ
τ

(cid:17)

Hence, max
≤ (1 + ǫ)2 and thus CVM is
an (1 + ǫ)2-approximation algorithm. This also holds with
high probability when probabilistic speedup is used.

R2
τ

(15)

As for space5, since only the core vectors are involved
in the QP, the space complexity for the tth iteration is
O(|St|2). As τ = O(1/ǫ), the space complexity for the
whole procedure is O(1/ǫ2), which is independent of m
for a ﬁxed ǫ.

On the other hand, when probabilistic speedup is used, ini-
tialization only takes O(1) time while distance computa-
tions in steps 2 and 3 take O((t + 2)2) = O(t2) time. Time
for the other operations remains the same. Hence, tth iter-
ation takes O(t3) time and the whole procedure takes

τX

O(t3) = O(τ 4) = O

t=1

(cid:18)

(cid:19)

1
ǫ4

.

As mentioned in Section 1, practical SVM implementa-
tions also output approximated solutions only. Typically,

5As the patterns may be stored out of core, we ignore the

O(m) space required for storing the m patterns.

353For a ﬁxed ǫ, it is thus constant, independent of m. The
space complexity, which depends only on the number of
iterations τ, is still O(1/ǫ2).

If more efﬁcient QP solvers were used in the MEB sub-
problem of Section 4.1.4, both the time and space complex-
ities can be further improved. For example, with SMO, the
space complexity for the tth iteration is reduced to O(|St|)
and that for the whole procedure driven down to O(1/ǫ).

Note that when ǫ decreases, the CVM solution becomes
closer to the exact optimal solution, but at the expense of
higher time and space complexities. Such a tradeoff be-
tween efﬁciency and approximation quality is typical of all
approximation schemes. Morever, be cautioned that the O-
notation is used for studying the asymptotic efﬁciency of
algorithms. As we are interested on handling very large
data sets, an algorithm that is asymptotically more efﬁ-
cient (in time and space) will be the best choice. However,
on smaller problems, this may be outperformed by algo-
rithms that are not as efﬁcient asymptotically. These will
be demonstrated experimentally in Section 5.

5 Experiments
In this Section, we implement the two-class L2-SVM in
Section 3.2.2 and illustrate the scaling behavior of CVM (in
C++) on both toy and real-world data sets. For comparison,
we also run the following SVM implementations6:

1. L2-SVM: LIBSVM implementation (in C++);

2. L2-SVM: LSVM implementation (in MATLAB), with
low-rank approximation (Fine & Scheinberg, 2001) of
the kernel matrix added;

3. L2-SVM: RSVM (Lee & Mangasarian, 2001) imple-
mentation (in MATLAB). The RSVM addresses the
scale-up issue by solving a smaller optimization prob-
lem that involves a random ¯m × m rectangular subset
of the kernel matrix. Here, ¯m is set to 10% of m;

4. L1-SVM: LIBSVM implementation (in C++);

5. L1-SVM: SimpleSVM (Vishwanathan et al., 2003)

implementation (in MATLAB).

Parameters are used in their default settings unless other-
wise speciﬁed. All experiments are performed on a 3.2GHz
Pentium–4 machine with 512M RAM, running Windows
XP. Since our focus is on nonlinear kernels, we use the

6Our CVM implementation can be downloaded from
http://www.cs.ust.hk/∼jamesk/cvm.zip.
LIBSVM can be
downloaded from http://www.csie.ntu.edu.tw/∼cjlin/libsvm/;
LSVM from http://www.cs.wisc.edu/dmi/lsvm;
and Sim-
pleSVM from http://asi.insa-rouen.fr/∼gloosli/. Moreover, we
followed http://www.csie.ntu.edu.tw/∼cjlin/libsvm/faq.html in
adapting the LIBSVM package for L2-SVM.

P

m

Gaussian kernel k(x, y) = exp(−kx − yk2/β), with
β = 1
m2

i,j=1 kxi − xjk2.

Our CVM implementation is adapted from LIBSVM, and
uses SMO for each QP sub-problem in Section 4.1.4. As in
LIBSVM, our CVM also uses caching (with the same cache
size as in the other LIBSVM implementations above) and
stores all training patterns in main memory. For simplicity,
shrinking is not used in our current CVM implementation.
Moreover, we employ probabilistic speedup (Section 4.1.2)
and set ǫ = 10−6 in all the experiments. As in other de-
composition methods, the use of a very stringent stopping
criterion is not necessary in practice. Preliminary studies
show that ǫ = 10−6 is acceptable for most tasks. Using an
even smaller ǫ does not show improved generalization per-
formance, but may increase the training time unnecessarily.

5.1 Checkerboard Data
We ﬁrst experiment on the 4 × 4 checkerboard data used
by Lee and Mangasarian (2001) for evaluating large-scale
SVM implementations. We use training sets with a maxi-
mum of 1 million points and 2000 independent points for
testing. Of course, this problem does not need so many
points for training, but it is convenient for illustrating the
scaling properties. Experimentally, L2-SVM with low rank
approximation does not yield satisfactory performance on
this data set, and so its result is not reported here. RSVM,
on the other hand, has to keep a rectangular kernel matrix
of size ¯m × m and cannot be run on our machine when m
exceeds 10K. Similarly, the SimpleSVM has to store the
kernel matrix of the active set, and runs into storage prob-
lem when m exceeds 30K.

As can be seen from Figure 2, CVM is as accurate as the
others. Besides, it is much faster7 and produces far fewer
support vectors (which implies faster testing) on large data
sets. In particular, one million patterns can be processed in
under 13s. On the other hand, for relatively small training
sets, with less than 10K patterns, LIBSVM is faster. This,
however, is to be expected as LIBSVM uses more sophis-
ticated heuristics and so will be more efﬁcient on small-to-
medium sized data sets. Figure 2(b) also shows the core-set
size, which can be seen to be small and its curve basically
overlaps with that of the CVM. Thus, almost all the core
vectors are useful support vectors. Moreover, it also con-
ﬁrms our theoretical ﬁndings that both time and space are
constant w.r.t. the training set size, when it is large enough.

5.2 Forest Cover Type Data8
This data set has been used for large scale SVM training
by Collobert et al.
(2002). Following (Collobert et al.,

7As some implementations are in MATLAB, so not all the
CPU time measurements can be directly compared. However, it
is still useful to note the constant scaling exhibited by the CVM
and its speed advantage over other C++ implementations, when
the data set is large.

8http://kdd.ics.uci.edu/databases/covertype/covertype.html

354106

105

104

103

102

101

100

)
s
d
n
o
c
e
s
 
n
i
(
 
e
m

i
t
 

U
P
C

10−1

1K

3K

10K

L2−SVM (CVM)
L2−SVM (LIBSVM)
L2−SVM (RSVM)
L1−SVM (LIBSVM)
L1−SVM (SimpleSVM)

105

’

s
V
S

 
f

o

 
r
e
b
m
u
n

104

103

1M

102

1K

3K

10K

L2−SVM (CVM)
L2−SVM (LIBSVM)
L2−SVM (RSVM)
L1−SVM (LIBSVM)
L1−SVM (SimpleSVM)

L2−SVM (CVM)
core−set size
L2−SVM (LIBSVM)
L2−SVM (RSVM)
L1−SVM (LIBSVM)
L1−SVM (SimpleSVM)

40

35

30

25

20

15

10

5

)

 

%
n
i
(
 
e

t

a
r
 
r
o
r
r
e

1M

0
1K

3K

10K

30K

size of training set

100K

300K

1M

30K

100K

300K
size of training set

30K

100K

300K
size of training set

(a) CPU time.

Figure 2: Results on the checkerboard data set (Except for the CVM, all the other implementations have to terminate
early because of not enough memory and / or the training time is too long). Note that the CPU time, number of support
vectors, and size of the training set are in log scale.

(b) number of SV’s.

(c) testing error.

2002), we aim at separating class 2 from the other classes.
1% − 90% of the whole data set (with a maximum of
522,911 patterns) are used for training while the remaining
are used for testing. We set β = 10000 for the Gaussian
kernel. Preliminary studies show that the number of sup-
port vectors is over ten thousands. Consequently, RSVM
and SimpleSVM cannot be run on our machine. Similarly,
for low rank approximation, preliminary studies show that
over thousands of basis vectors are required for a good ap-
proximation. Therefore, only the two LIBSVM implemen-
tations will be compared with the CVM here.

Figure 3 shows that CVM is, again, as accurate as the oth-
ers. Note that when the training set is small, more training
patterns bring in additional information useful for classi-
ﬁcation and so the number of core vectors increases with
training set size. However, after processing around 100K
patterns, both the time and space requirements of CVM be-
gin to exhibit a constant scaling with the training set size.
With hindsight, one might simply sample 100K training
patterns and hope to obtain comparable results9. However,
for satisfactory classiﬁcation performance, different prob-
lems require samples of different sizes and CVM has the
important advantage that the required sample size does not
have to be pre-speciﬁed. Without such prior knowledge,
random sampling gives poor testing results, as has been
demonstrated in (Lee & Mangasarian, 2001).

5.3 Relatively Small Data Sets: UCI Adult Data10
Following (Platt, 1999), we use training sets with up to
32,562 patterns. As can be seen in Figure 4, CVM is
still among the most accurate methods. However, as this
data set is relatively small, more training patterns do carry
more classiﬁcation information. Hence, as discussed in
Section 5.2, the number of iterations, the core set size
and consequently the CPU time all increase with the num-

ber of training patterns. From another perspective, recall
that the worst case core-set size is 2/ǫ, independent of
m (Section 4.3). For the value of ǫ = 10−6 used here,
2/ǫ = 2 × 106. Although we have seen that the actual size
of the core-set is often much smaller than this worst case
value, however, when m ≪ 2/ǫ, the number of core vec-
tors can still be dependent on m. Moreover, as has been ob-
served in Section 5.1, the CVM is slower than the more so-
phisticated LIBSVM on processing these smaller data sets.

6 Conclusion

In this paper, we exploit the “approximateness” in SVM
implementations. We formulate kernel methods as equiv-
alent MEB problems, and then obtain provably approxi-
mately optimal solutions efﬁciently with the use of core-
sets. The proposed CVM procedure is simple, and does not
require sophisticated heuristics as in other decomposition
methods. Moreover, despite its simplicity, CVM has small
asymptotic time and space complexities. In particular, for
a ﬁxed ǫ, its asymptotic time complexity is linear in the
training set size m while its space complexity is indepen-
dent of m. When probabilistic speedup is used, it even has
constant asymptotic time and space complexities for a ﬁxed
ǫ, independent of the training set size m. Experimentally,
on large data sets, it is much faster and produce far fewer
support vectors (and thus faster testing) than existing meth-
ods. On the other hand, on relatively small data sets where
m ≪ 2/ǫ, SMO can be faster. CVM can also be used for
other kernel methods such as support vector regression, and
details will be reported elsewhere.

References

B˘adoiu, M., & Clarkson, K. (2002). Optimal core-sets for balls.

DIMACS Workshop on Computational Geometry.

9In fact, we tried both LIBSVM implementations on a random
sample of 100K training patterns, but their testing accuracies are
inferior to that of CVM.

10http://research.microsoft.com/users/jplatt/smo.html

Cauwenberghs, G., & Poggio, T. (2001). Incremental and decre-
mental support vector machine learning. Advances in Neural
Information Processing Systems 13. Cambridge, MA: MIT
Press.

355106

105

104

103

102

)
s
d
n
o
c
e
s
 

n
i
(
 
e
m

i
t
 

U
P
C

101
0

1

2

3

4

5

size of training set

L2−SVM (CVM)
L2−SVM (LIBSVM)
L1−SVM (LIBSVM)

106

’

s
V
S

 
f

o

 
r
e
b
m
u
n

105

104

L2−SVM (CVM)
core−set size
L2−SVM (LIBSVM)
L1−SVM (LIBSVM)

6

7

103
0

8
x 105

1

2

3

size of training set

4

5

6
x 105

25

20

)

 

%
n
i
(
 

e

t

a
r
 
r
o
r
r
e

15

10

5

0
0

L2−SVM (CVM)
L2−SVM (LIBSVM)
L1−SVM (LIBSVM)

1

2

3

size of training set

4

5

6
x 105

(a) CPU time.

(b) number of SV’s.

(c) testing error.

Figure 3: Results on the forest cover type data set. Note that the y-axes in Figures 3(a) and 3(b) are in log scale.

105

104

103

102

101

100

)
s
d
n
o
c
e
s
 
n
i
(
 
e
m

i
t
 

U
P
C

L2−SVM (CVM)
L2−SVM (LIBSVM)
L2−SVM (low rank)
L2−SVM (RSVM)
L1−SVM (LIBSVM)
L1−SVM (SimpleSVM)

105

104

103

’

s
V
S

 
f

o

 
r
e
b
m
u
n

L2−SVM (CVM)
core−set size
L2−SVM (LIBSVM)
L2−SVM (low rank)
L2−SVM (RSVM)
L1−SVM (LIBSVM)
L1−SVM (SimpleSVM)

L2−SVM (CVM)
L2−SVM (LIBSVM)
L2−SVM (low rank)
L2−SVM (RSVM)
L1−SVM (LIBSVM)
L1−SVM (SimpleSVM)

20

19

18

17

16

15

)

 

%
n
i
(
 

e

t

a
r
 
r
o
r
r
e

10−1

1000

3000

6000 10000

30000
size of training set

102
1000

3000

6000 10000

30000
size of training set

14
1000

3000

6000 10000

size of training set

30000

(a) CPU time.

(b) number of SV’s.

(c) testing error.

Figure 4: Results on the UCI adult data set (The other implementations have to terminate early because of not enough
memory and/or training time is too long). Note that the CPU time, number of SV’s and size of training set are in log scale.

Chang, C.-C., & Lin, C.-J.

LIBSVM: a li-
brary for support vector machines. Software available at
http://www.csie.ntu.edu.tw/˜cjlin/libsvm.

(2004).

Chapelle, O., Vapnik, V., Bousquet, O., & Mukherjee, S. (2002).
Choosing multiple parameters for support vector machines.
Machine Learning, 46, 131–159.

Collobert, R., Bengio, S., & Bengio, Y. (2002). A parallel mixture
of SVMs for very large scale problems. Neural Computation,
14, 1105–1114.

Fine, S., & Scheinberg, K. (2001). Efﬁcient SVM training using
low-rank kernel representation. Journal of Machine Learning
Research, 2, 243–264.

Garey, M., & Johnson, D. (1979). Computers and intractability:

A guide to the theory of NP-completeness. W.H. Freeman.

Joachims, T. (1999). Making large-scale support vector machine
learning practical. In B. Sch¨olkopf, C. Burges and A. Smola
(Eds.), Advances in kernel methods – Support vector learning,
169–184. Cambridge, MA: MIT Press.

Kumar, P., Mitchell, J., & Yildirim, A. (2003). Approximate min-
imum enclosing balls in high dimensions using core-sets. ACM
Journal of Experimental Algorithmics, 8.

Mangasarian, O., & Musicant, D. (2001). Lagrangian support
vector machines. Journal of Machine Learning Research, 1,
161–177.

Osuna, E., Freund, R., & Girosi, F. (1997). Training support vec-
tor machines: an application to face detection. Proceedings of
Computer Vision and Pattern Recognition (pp. 130–136). San
Juan, Puerto Rico.

Platt, J. (1999). Fast training of support vector machines using
sequential minimal optimization. In B. Sch¨olkopf, C. Burges
and A. Smola (Eds.), Advances in kernel methods – support
vector learning, 185–208. Cambridge, MA: MIT Press.

Sch¨olkopf, B., Platt, J., Shawe-Taylor, J., Smola, A., &
Williamson, R. (2001). Estimating the support of a high-
dimensional distribution. Neural Computation, 13, 1443–1471.

Smola, A., & Sch¨olkopf, B. (2000). Sparse greedy matrix approx-
imation for machine learning. Proceedings of the Seventeenth
International Conference on Machine Learning (pp. 911–918).
Standord, CA, USA.

Smola, A., & Sch¨olkopf, B. (2004). A tutorial on support vector

regression. Statistics and Computing, 14, 199–222.

Tax, D., & Duin, R. (1999). Support vector domain description.

Pattern Recognition Letters, 20, 1191–1199.

Lee, Y.-J., & Mangasarian, O. (2001). RSVM: Reduced support
vector machines. Proceeding of the First SIAM International
Conference on Data Mining.

Vishwanathan, S., Smola, A., & Murty, M. (2003). SimpleSVM.
Proceedings of the Twentieth International Conference on Ma-
chine Learning (pp. 760–767). Washington, D.C., USA.

Lin, K.-M., & Lin, C.-J. (2003). A study on reduced support
vector machines. IEEE Transactions on Neural Networks, 14,
1449–1459.

Williams, C., & Seeger, M. (2001). Using the Nystr¨om method
to speed up kernel machines. Advances in Neural Information
Processing Systems 13. Cambridge, MA: MIT Press.

356Streaming Feature Selection using IIC

Lyle H. Ungar and Jing Zhou

Computer and Information Science

Dean P. Foster and Bob A. Stine

Statistics Department

University of Pennsylvania, Philadelphia, PA 19104

University of Pennsylvania, Philadelphia, PA 19104

ungar, jingzhou@seas.upenn.edu

foster, stine@wharton.upenn.edu

Abstract

In Streaming Feature Selection (SFS), new fea-
tures are sequentially considered for addition to
a predictive model. When the space of poten-
tial features is large, SFS offers many advantages
over methods in which all features are assumed to
be known in advance. Features can be generated
dynamically, focusing the search for new features
on promising subspaces, and overﬁtting can be
controlled by dynamically adjusting the thresh-
old for adding features to the model. We present
a new, adaptive complexity penalty, the Informa-
tion Investing Criterion (IIC), which uses an ef-
ﬁcient coding of features added, and not added,
to the model to dynamically adjust the threshold
on the entropy reduction required for adding a
new feature. Streaming Feature Selection with
IIC gives strong guarantees against overﬁtting. In
contrast, standard penalty methods such as BIC
or RIC always drastically over- or under-ﬁt in the
limit of inﬁnite numbers of non-predictive fea-
tures. Empirical results show that SFS is compet-
itive with much more compute-intensive feature
selection methods.

1 Introduction

In many problems, one has a ﬁxed set of observations from
which a vast, or even inﬁnite stream of features can be
generated to build predictive models. The large number
of potentially predictive features may come from trans-
formations of, and interactions between, a smaller initial
set of features. For example, most commercial statistical
software offers the ability to do stepwise regression using
all feature interactions (e.g., products of pairs of features,
or all products containing three variables). Pairwise in-
teractions are important and, along with data transforma-
tions, can rapidly create large data sets. For example in
a bankruptcy prediction problem described below, consid-

ering interactions between the 365 original features led to
a set of over 67,000 potential features, of which about 40
proved signiﬁcant.

The features may also come from more complex feature
generation algorithms. For example, Statistical Relational
Learning (SRL) methods often generate tens or hundreds
of thousands of potentially predictive features. SRL and
related methods “crawl” through a database or other rela-
tional structure and generate features by building increas-
ingly complex compound relations [1] . For example, when
building a model to predict the journal in which an article
will be published, potentially predictive features include
the words in the target article itself, the words in the articles
cited by the target article, the words in articles that cite arti-
cles written by the authors of the target article, and so forth.
Traversing such relational structures can easily generates
millions of features, since there are many words, authors,
and journals. Current modeling techniques, however, are
ill equipped to deal with problems of learning from, say, a
million potential features for each of a hundred thousand
observations. A hundred billion numbers do not ﬁt easily
into memory on most contemporary computers. More im-
portantly, CPU is fast relative to memory, and being more
so.

When building models from potentially enormous sets of
features, it is desirable to interleave the process of feature
generation with that of feature testing in order to avoid even
generating features which are less likely to be useful. One
may want to only consider interaction terms in a regression
if at least one of the component terms has proven predic-
tive. One may want to only search farther in those branches
of a reﬁnement graph in inductive logic programming (ILP)
which contain terms that have proven predictive – as is, in-
deed, done in ILP. Building predictive models from such
large, complex data sets requires careful control to avoid
over-ﬁtting, particularly when there are many more fea-
tures than observations. Standard statistical and machine
learning methods such as SVMs, maximum entropy meth-
ods and neural networks generally assume that all features
(“predictors”) are known in advance. They then use regu-

357larization or features selection to avoid overﬁtting.

This paper focuses on penalty-based feature selection
methods for problems in which a small number of predic-
tive features are to be selected from a large set of potential
features. We will compare, in the context of streaming fea-
ture selection, the widely used BIC penalty method with
RIC, a more recent penalty method, and with the new In-
formation Investing Criterion (IIC), which this paper intro-
duces.

2 log(n), i.e.

BIC can be understood in an information theoretic sense
as consisting of a code (specifying the parameters in the
model) and the compressed data (describing the errors in
the predictions made by the model). Each zero parameter
(feature not included in the model) is coded with one bit,
and each non-zero parameter is coded with 1 + 1
2 log(n)
bits, where n is the number of observations used. (All logs
are base 2.) Recalling that the log likelihood of the data
given a model gives the number of bits to code the model
error, leads to the BIC criterion for feature selection: ac-
cept a new feature xi only if the change in log likelihood
from adding the feature is greater than 1
if
log(P (Y | ˆYi))− log(P (Y | ˆY−i)) > 1
2 log(n). BIC is equiv-
alent to a Minimum Description Length (MDL)[2] criterion
if the number of features considered, p is much less than the
number of observations, n. Howver, BIC is not a valid code
for p (cid:29) n.
The Risk Inﬂation Criterion (RIC) [3, 4] gives another,
much more stringent criterion for feature selection, which
controls the minimax risk. RIC chooses a set of features
from the potential feature pool so that the loss of the re-
sulting model is within a factor of log(p) of the loss of the
best such model. In essence, RIC behaves like a Bonferroni
rule, in which a threshold for feature inclusion is selected
so that the set of all features will only have a small chance
of containing a “false” feature. This is highly conservative,
and does often not produce optimal out of sample predic-
tion accuracies.

The Information Investing Criterion (IIC) introduced in this
paper is an alternative MDL-style coding which, unlike
BIC and RIC, is adaptive. Information investing does not
require knowing the number of potential predictors in ad-
vance, yet still has provable bounds on overﬁtting. IIC’s
performance is never much worse than BIC or RIC, and for
the types of problems we are interested in, where there are
far more potential features than observations, it often gives
vastly superior performance.

The assumptions behind penalty methods such as BIC and
RIC are not met when a ﬁxed number of features are to be
selected from an arbitrarily large set of potentially predic-
tive features. Inclusion rules such as AIC and BIC, which
are not a function of p, the number of possible features to
be considered for inclusion in the model, inevitably over-
ﬁt as p becomes large. When presented with a continuous

sequence of features that are random noise, any selection
procedure that generates false positives at a ﬁxed rate, such
as AIC or BIC, will select inﬁnitely many of these random
features as predictors. Inclusion rules such as RIC (Bon-
ferroni) which are a function of p under-ﬁt as p becomes
large. Any such method that reduces the chance of includ-
ing each feature based on the total number of features, p,
to be considered will end up not adding any features in the
limit as p → ∞.
The solution to this dilemma is to sequentially consider a
stream of features for model inclusion and use a method
which incrementally adjusts the criterion for including new
features in the model depending on the history of addi-
tion (or non-addition) of features seen so far. We argue
for Streaming Feature Selection (SFS), where as each ad-
ditional feature is observed, it is tested for inclusion in the
model and then either included or discarded. Streaming
feature selection offers many advantages over the tradi-
tional approach of stepwise selection from a ﬁxed set of
features. In stepwise regression, all features are considered
for addition to the model, the best one is selected, and then
all remaining features considered, etc. At every iteration,
almost all features are tested for addition to the model. This
requires having a ﬁnite set of features speciﬁed in advance,
and requires looking at each feature many times. Step-
wise feature selection is widely used with penalty methods
such as AIC and BIC, but we will show below that stream-
ing feature selection often gives competitive performance,
while allowing much greater ﬂexibility in dynamically con-
trolling feature generation. Using streams of features has
other beneﬁts. Since most features will not be included in
the models, they can be discarded soon after generation,
thus reducing data storage requirement and allowing the
solution of larger problems than can be tackled using stan-
dard machine learning algorithms such as support vector
machines (SVMs) or neural networks which assume that
all potentially predictive features are known a priori.

2 Streaming feature selection

The goal of streaming feature selection is to pick useful
predictors from an offered sequence of features. For a ﬁxed
set of observations, new features (predictors) are consid-
ered sequentially, and the decision to include or discard
each feature is made at the time it is provided. SFS can be
used with a variety of different machine learning methods;
all it requires from the machine learner is that it take fea-
tures sequentially and produce an estimate of the change
in entropy (log-likelihood) in the model. A wide range
of classical statistical methods can be used off-the-shelf,
such as linear or logistic regression, or extensions such as
generalized linear methods and estimating equations. SFS
works particularly well with modeling methods than can ef-
ﬁciently add additional features and with adaptive penalty
methods such as IIC.

358Initialize

Do f orever

i = 1, wealth = w0 bits, model = {}
x ← get new f eature()
 ← wealth/2i
bits saved ← entropy reduction(x, , model)
if (bits saved > w∆)

wealth ← wealth + w∆
add f eature(x, model) // add x to the model

else

wealth ← wealth − 

i ← i + 1

Figure 1: Information-investing algorithm

SFS dynamically adjusts the threshold, w∆, on the entropy
reduction needed for a new variable to enter the model.1
The threshold, w∆, is adjusted using the wealth, wi, which
represents the number of bits currently available for over-
ﬁtting. Wealth starts at an initial value w0 specifying the
number of bits by which one is willing to risk increasing
the description length. It is increased by w∆ each time a
variable (feature) is added to the model, since the variable
is guaranteed to save at least w∆ bits, and decreased by 
each time a variable is not added to the model,reﬂecting (as
described below) the cost of coding the fact that the feature
was not added.

The algorithm is given in Figure 1.  speciﬁes how many
bits are available to code a variable. The bits saved by
adding a feature to the model is the net entropy reduction
from adding x to the model: the reduction in the model er-
ror minus the cost of coding the coefﬁcient, β, associated
with x and the cost of indicating that the variable is to be
added to the model. Different codings can be used for the
coefﬁcients, for example 1
2 log(n) bits (or, for a very ap-
proximate coding 3 bits) to code each nonzero coefﬁcient,
and e.g. -log() bits to code that x is to be added to the
model. (Since  is the number of bits available to code a
spurious feature, the probability of the next feature being
“useful.” is 1 − e− = 1 − (1 −  + O(2)) ≈ , and
the cost in bits of coding that that the feature is useful is
roughly -log() bits.) If β, the coefﬁcient of x, has an as-
sociated t-statistic, then adding x to the model reduces the
entropy of the model by 1
2 t2log(e). (The log(e) converts
the t2 to bits.)

If the feature x reduces entropy sufﬁciently to be worth
adding to the model, then the wealth is incremented by a
ﬁxed amount, w∆.
If the feature x is not added to the

1A very similar SFS algorithm, which we call α-investing,
can be written that dynamically adjusts the criterion for adding a
new feature to a model based on the p-value of the feature under
consideration.

model, the wealth is decreased by the cost of coding the
variable’s absence, which by an argument similar for that
used above is − log(1 − ), which, for small , is approxi-
mately .

2.1 Guarantees against overﬁtting

One sense in which SFS is guaranteed not to over-ﬁt, is
that on average, the sum of the total description length plus
the wealth will never increase. Since the wealth is strictly
positive, this guarantees that the total description length can
never increase by more than the current wealth. Since when
a feature is added to the model we increase the wealth less
than the description length decreases, the description length
plus wealth tends to decrease, providing on average better
models.

SFS also provides another, much more subtle, guarantee
against overﬁtting. For the case of “hard” problems, where
the coefﬁcients to be estimated are just barely distinguish-
able above the noise, the cost of adding a “false” feature is
comparable to the beneﬁt of adding a true features. This
is a property of using a so-called testimator. A testimator
tests for signiﬁcance and then estimates by the usual esti-
mator if it is signiﬁcant, and estimates by zero otherwise.
If a variable has a true coefﬁcient of zero, then when it is
falsely included, it will be biased by about tαSE, where tα
is the critical value used for testing signiﬁcance, and SE
is the standard error of the coefﬁcient. On the other hand,
the hardest to detect coefﬁcients will have a coefﬁcient of
about tαSE. Hence leaving them out will bias their esti-
mated value by about the same amount, namely tαSE. We
can thus get optimal test error by adding as many features
as possible while not exceeding a speciﬁed ratio of false to
true features added to the model.2

SFS using the IIC coding (described below) allows us, for
any valid coding, to bound in expectation the ratio of in-
correct features added to correct features added, and thus
to minimize the expected test error by adding as many fea-
tures as possible subject to controlling that ratio.

Theorem
Let Mi be the number of correct variables included in the
model, let Ni be the number of spurious variables (those
with true coefﬁcient zero) included and wi be the wealth,
all at iteration i, and let w∆ < 1/4 be a user selected value.
Then if the algorithm in Figure 1 is modiﬁed so that it never
bids more than 1/2 it will have the property that:

E(Ni) < 4w∆E(Mi) + 4w0.

2This is very similar to controlling the False Discovery Rate
(FDR) [5], the number of features incorrectly included in the
model divided by the total number of features included in the
model, which has become popular in recent years. In the regime
that we are working, correctly adding a feature always reduces
both the FDR and the out-of-sample error, and incorrectly adding
a feature always increases both FDR and error.

359Proof Sketch
The proof relies on the fact that Si ≡ Ni − 4w∆Mi +
4wi is a super-martingale, namely at each time period the
conditional expectation of Si − Si−1 is negative. We will
show that Si is a super-martingale by considering the cases
when the variable is or is not in the true model and is or is
not added to the estimated model.

βi = 0

βi 6= 0

use zero ∆Mi = 0, ∆Ni = 0 ∆Mi = 0, ∆Ni = 0
add variable ∆Mi = 0, ∆Ni = 1 ∆Mi = 1, ∆Ni = 0
We can write the change in Si as:

∆Si ≡ Si − Si−1

= ∆Ni − 4w∆∆Mi + 4∆wi

If βi 6= 0, then ∆Ni = 0. Thus,

∆Si = −i(1 − ∆Mi) ≤ 0,

where i is the amount bid at time i. On the other hand, if
βi = 0, then ∆Mi = 0. So,

∆Si = ∆Ni + 4∆wi

= ∆Ni + 4w∆∆Ni − 4i(1 − ∆Ni)
= ∆Ni(1 + 4w∆ + i) − 4i.
By bounds
from information theory, we see that
E(∆Ni) ≤ i. Also by assumption, 4w∆ ≤ 1 and
i ≤ 1/2. Hence E(∆Si) ≤ 4i − 4i = 0. Thus, Si
is a super-martingale.
Using the weaker fact that for super-martingales: E(Si) ≤
E(Si−1), we see that E(Si) ≤ S0. But since we start out
with Ni = 0, and Mi = 0, S0 = 4w0. Since wi > 0 by
construction, we see that E(Ni − 4w∆Mi) < 4w0.
When w∆ = 1
4 , this reduces to E(Ni) < E(Mi) + 4w0.
The expected number of spurious variables added is thus no
more than 4w0 greater than the expected number of correct
variables added.

As described above, if we add as many features as possible
subject to meeting such a constraint on spurious to true fea-
tures added, we will minimize the expected test error. The
selection of i as wi/2i gives the slowest possible decrease
in wealth such that all wealth is used; i.e., so that as many
features as possible are included in the model without sys-
tematically over-ﬁtting. More formally:

Theorem
Computing i as wi/2i gives the slowest possible decrease
in wealth such that limi→∞ wi = 0.
Proof Sketch
Deﬁne δi = i/wi to be the fraction of wealth invested
at time i.
If no features are added to the model, wealth
at time i is wi = Πi(1 − δi). If we pass to the limit to

generate w∞, we have w∞ = Πi(1− δi) = eP log(1−δi) =
e− P δi+O(δ2

i ). Thus, w∞ = 0 iff P δi is inﬁnite.

Thus if we let δi go to zero faster than 1/i, say i−1−γ where
γ > 0 then w∞ > 0 and we have wealth that we never use.

2.2 IIC and its coding scheme

A key question is what coding scheme to use in determin-
ing the entropy reduction. We describe here an “optimal”
coding scheme which leads to the information investing al-
gorithm described in Figure 1. Our goal is to ﬁnd a (legit-
imate) coding scheme which, given a “bid,” , specifying
how many bits are available to code a variable, will guar-
antee the highest probability of adding the variable to the
model. The key idea is that log(probability) and bits are
equivalent. This equivalence allows us to think in terms
of distributions and thus to compute codes which handle
fractions of a bit. We show in this section that given any
actual distribution ˜fβ of the coefﬁcients, we can produce a
coding corresponding to a modiﬁed distribution fβ which
uniformly dominates the coding implied by ˜fβ.
Assume, for simplicity, that we increase the wealth by one
bit when a variable xi with coefﬁcient βi is added. Thus,
when xi is added log(p(xi is a “true” variable) / p(xi is a
“false” variable)) > 1 bit; i.e. the log-likelihood decreases
by more than one bit. Let fβi be the distribution implied by
the coding scheme for tβi if we add xi and f0(tβi ) be the
normal distribution (the null model in which xi should not
be added). The coding saves enough bits to justify adding
a variable whenever fβi(tβi ) ≥ 2 ∗ f0(tβi ). This happens
with probability αi ≡ p0({tβi : fβi(tβi) ≥ 2 ∗ f0(tβi)})
under the null (αi is thus the area under the tails of the null
distribution.)
There is no reason to have fβi(tβi ) (cid:29) 2 ∗ f0(tβi ) in the
tails, since this would “waste” probability or bits. Hence
the optimal coding corresponds to fβ(tβi ) = 2 ∗ f0(tβi )
for all the variables that are likely to be added. Using all of
the remaining probability mass (or equivalently, making the
coding “Kraft tight”) dictates the coding for the case when
the variable is not likely to be added. The most efﬁcient
coding to use is thus:

(cid:26) fβ(tβi) = 2f0(tβi )
fβ(tβi) = 1−2∗αi
1−αi

if |tβi| > tαi

f0(tβi ) otherwise

and the corresponding cost in bits is:

log(fβ(tβi )/f0(tβi )) = log(2) = 1 bit
log(fβ(tβi )/f0(tβi ) =
log( 1−2αi
1−αi



Figure 2 shows the distribution fβ(t(βi)), with the proba-
bility mass transfered away from the center, where features
are not added, out to the tails, where features are added.

if |tβi| > tαi
otherwise

) ≈ −αi bits

360than the stepwise selection procedure. RIC gives perfor-
mance superior to SFS in this particular case (q = 10) but
it fails badly when its assumptions (q small) are violated, as
shown in Table 2. Stepwise regression using RIC does bet-
ter here than the streaming version. However, using stan-
dard code from R, the stepwise regression was much slower
than the streaming regression, to the point where running
stepwise regression on data sets with tens of thousands of
features was not possible.

features
error

25.5
9.57

BIC RIC SFS
61.5
89.3
6.24
7.60

Table 2. RIC underﬁts for q (cid:29) 1. Same
parameters as Table 1 (streaming) except n =
1,000, q = 100 features in data and σ2 = 15.

One might
hope that
adding
more
spurious
features to
the end of
a
feature
stream
would not
severely harm an algorithm’s performance. However, BIC,
since its penalty is not a function of p, will add even more
spurious variables (if BIC haven’t already added a feature
for every observation!). RIC (or Bonferroni) puts a harsher
penalty as p gets large, adding fewer and fewer features.
As Table 3 shows, SFS is clearly the superior method when
the true features occur early in the feature stream. SFS
continues to occasionally add features to the model, which
would be good if there were predictive features later in the
stream, but does not lead to much overﬁtting when there
are no such features.

Figure 2: Optimal distribution fβ

streaming

stepwise

features
error
features
error

BIC RIC SFS
39.3
5.4
3.21
3.16
199
3.89

7.1
2.88
11.1
2.40

–
–

Table 1. BIC overﬁts for p (cid:29) n. Average number of
features selected and out-of-sample error. n = 200 observa-
tions, p = 1,000 features, q = 10 true features in model Syn-
thetic data: x ∼ N (0, 1) y: linear in x with noise σ2 = 5. A
perfect model would give test error of 2.236, the error of the
null model is 3.873. The results are an average over 20 runs,
and reported errors have an uncertainty of around 0.02.

The above equations been derived assuming that 1 bit is
added to the wealth. It can be generalized to add w∆ bits to
the wealth each time a variable is added to the model. Then,
when a variable is added to the model the probability of it
being “true” should be 2w∆ times that of it being “false”,
and all of the 2’s in the above equations are replaced with
2w∆.

3 Experimental Results

To further illustrate the method, we evaluate SFS on a syn-
thetic data set for which the correct answers are known and
on a larger, real data set of bankruptcy prediction. The base
synthetic data set contains 200 observations each of 1,000
features, of which 10 are predictive. We generate the fea-
tures independently from a normal distribution, N (0, 1),
with the true model being the sum of the ten predictors plus
noise, N (0, 5). The artiﬁcially simple structure of the data
allows us to easily see which feature selection methods are
adding spurious variables or failing to ﬁnd variables that
should be in the model.

The results are presented in Table 1. As expected, BIC
overﬁts, although less badly when streaming is used rather

It is often the case that large numbers of features are
generated, with the best ones tending to be earlier in
the sequence. Such feature streams are generated when
one searches over interactions and transformations, as in
the bankruptcy example presented below. Similar feature
streams arise when one computes features at many length
scales, as for face or object recognition in machine vi-
sion. Another example is Structural Relational Learning
(SRL), where potential features are generated by searching
the space of logic queries or relational database queries.

We have used the CiteSeer data set, which contains about
500,000 papers, 100,000 “constants” (words, authors, and
journals), and around ten different relations (including au-
thor, venue, cites, has-word, institution, download) to pre-
dict which journal a given paper will be published in, or
which papers it will cite. Predictions using CiteSeer beneﬁt
from the generation of rich sets of features, and depending
on the exact task, SFS gives out-of-sample errors compara-
ble to, or several percentage points below those from non-
adaptive techniques [6]. Learning in SRL methods such as
Structural Generalized Linear Regression (SGLR) [6] ben-
eﬁt from efﬁcient integration of feature generation and se-
lection; as each feature is tested for possible inclusion in
the model, the results are fed back to the feature genera-

361p

features
BIC false pos.

error

features
RIC false pos.

error

features
false pos.

error

SFS

1,000
39.3
29.5
3.21
7.1
0.1
2.88
5.4
0.3
3.16

10,000
199
189
4.45
3.8
0.5
3.49
5.4
0.5
3.30

100k
199
189
4.45
1.2
0.1
3.77
5.7
0.8
3.29

1M
199
189
4.45
0.9
0.2
3.91
5.7
0.8
3.29

Table 3. Effect of adding spurious features Same pa-
rameters as Table 1 except that additional spurious features
have been added after the ﬁrst 1,000 features. “false pos.”
indicates the average number of features incorrectly added.
(average over 10 runs)

tor, which can then use this information to determine which
further features to generate. Since generating the features
from these databases takes CPU days, avoiding generating
features is important both for computational as well as for
statistical efﬁciency methods.

We also tested a slight modiﬁcation of SFS on a problem of
predicting personal bankruptcies[7]. The data set is highly
un-balanced, containing 2,244 bankruptcy events and hun-
dreds of thousands of non-bankruptcy observations. The
real world loss function for predicting bankruptcy is quite
asymmetric: the cost of predicting a bankruptcy when none
occurs is much higher than the cost of failing to predict a
bankruptcy when one does occur. We call the ratio of these
two costs ρ.

We compared Streaming Feature Selection against boosted
C4.5, doing 5-fold cross-validation, where each pass of the
cross-validation uses 100,000 non-bankruptcies and about
one ﬁfth of the bankruptcies. SFS was run once, and then
the out-of-sample costs were estimated for each cost ratio,
ρ using the predicted probability of bankruptcy. C4.5 was
run separately for each value of ρ.

ρ
C.45 cost
SFS cost

199
132
61

99
76
41

19
18.6
15.3

6
7.2
6.9

4

5.09
5.02

1

1.45
1.54

Table 4. Loss as a function of the loss ratio, ρ, for

boosted C4.5 and for SFS

Table 4 shows that for low cost ratios, the two methods
give very similar results, but at higher cost ratios, SFS gives
around half the loss of C4.5. Using AIC, one would expect
over 1,000 variables to be falsely included in the model,
based on the fact that an f-statistic-based penalty of 2 cor-
responds to a t-statistic of √2 which is a wildly generous

threshold when considering 67,000 features. BIC also mas-
sively overﬁts, although less severely.

4 Alternate feature selection methods

Recent developments in statistical variable selection take
into account the size of the feature space, but only allow
for ﬁnite, ﬁxed feature spaces, and do not support sequen-
tial (or streaming) feature selection. The risk inﬂation crite-
rion (RIC) produces a model that possesses a type of com-
petitive predictive optimality [4, 3]. RIC chooses a set of
features from the potential feature pool so that the loss of
the resulting model is within a factor of log(p) of the loss
of the best such model.
In essence, RIC behaves like a
Bonferroni rule [3]. Each time a predictor is considered,
there is a chance that it will enter the model even if it is
merely noise.
In other words, the tested null hypothesis
is that the proposed feature does not improve the predic-
tion of the model. Doing a formal test generates a p-value
for this null hypothesis. Suppose we only add this predic-
tor if its p-value is less than αj when we consider the jth
predictor. Then the Bonferroni rule keeps the chance of
adding even one extraneous predictor to less than, say, 0.05

by constrainingP αj ≤ 0.05.

Bonferroni methods like RIC are conservative, limiting the
ability of a model to add factors that improve its predic-
tive accuracy. The connection of RIC to α-spending rules
leads to a more powerful alternative. An α-spending rule
is a multiple comparison procedure that bounds its cumula-
tive type 1 error rate at a small level, say 5%. For example,
suppose one has to test the p hypotheses H1, H2, . . . , Hp.
If we test the ﬁrst using level α∆, the second using level

α2 and so forth with Pj αj = 0.05, then we have only a

5% chance of falsely rejecting one of the p hypotheses. If
we associate each hypothesis with the claim that a predictor
adds to value to a regression, then we are back in the situa-
tion of a Bonferroni rule for variable selection. Bonferroni
methods and RIC simply ﬁx αj = α/p for each test.

Alternative multiple comparison procedures control a dif-
ferent property. Rather than control the cumulative α (also
known as the family wide error rate), these control the so-
called false discovery rate [5]. Control of the false dis-
covery rate at 5% implies that at most 5% of the rejected
hypotheses are false positives. In variable selection, this
implies that of the included predictors, at most 5% de-
grade the accuracy of the model. The Benjamini-Hochberg
method for controlling the false discovery rate suggests the
α-spending method for keeping the false discovery rate be-
low α: Order the p-values of the independents tests of
H1, H2, . . . , Hp so that p1 ≤ p2 ≤ ··· pp. Now ﬁnd the
largest p-value for which pk ≤ α/(p − k) and reject all Hi
for i ≤ k. Thus, if the smallest p-value p1 ≤ α/p, it is
rejected. Rather than compare the second largest p-value to
the RIC/Bonferroni threshold α/p, reject H2 if p2 ≤ 2α/p.

362There have been many papers that looked at procedures of
this sort for use in variable selection from an FDR perspec-
tive [8], an empirical Bayesian perspective [9, 10], an infor-
mation theoretical perspective [11] or simply a data mining
perspective [7]. But all of these require knowing the en-
tire list of possible variables ahead of time. Further, most
of them assume that the variables are orthogonal and hence
tacitly assume that p < n.

We are currently exploring a way of doing SFS that uses
what we call α-investing instead of IIC. In SFS using IIC,
we keep track of the number of bits saved and use these
bits to invest in future variables. Whereas in α-investing
the medium of exchange is the accumulation of α that has
yet to be spent. When a signiﬁcant variable is found, the
α-spending account goes up, but when a variable is found
to be insigniﬁcant, the account decreases. Though the α-
investing rule sounds like it might be close to Benjamini-
Hochberg’s FDR procedure described above, it turns out to
be fairly different. In particular, the Benjamini-Hochberg
method fails as p gets large; it is a batch-oriented proce-
dure. But the α-investing shares with IIC the property of
not needing to know p ahead of time and hence being able
to handle a potentially inﬁnite stream of predictors.

5 Summary

A variety of machine learning algorithms have been devel-
oped for online learning where observations are sequen-
tially added. Algorithms such as SFS which are online in
the features being used are much less common. For some
problems, all predictors are known in advance, and a large
fraction of them are predictive. In such cases, regulariza-
tion or smoothing methods work well and streaming fea-
ture selection does not make sense. For other problems,
selecting a small number of features gives a much stronger
model than trying to smooth across all potential features.
(See [12, 13] for a range of feature selection problems and
approaches.) For example, in predicting what journal an
article will be published in, we ﬁnd that roughly 10-20 of
the 80,000 features we examine are selected [14]. For the
problems in citation prediction and bankruptcy prediction
that we have looked at, generating potential features (e.g.
by querying a database or by computing transformations or
combinations of the raw features) takes orders of magni-
tude more time than the machine learning done by stream-
ing feature selection. Thus, the ﬂexibility that SFS provides
to dynamically decide which features to generate and add
to the feature stream provides potentially large savings in
computation.

Streaming feature selection can be done using any penalty
method such as AIC, BIC or RIC, but is functions best
when using a method such as IIC which adapts the penalty
as a function of what features have been seen and added at
each point. The widely used BIC criterion is only valid in

the limit as the number of observations n goes to inﬁnity
while the number of features p remains small. The more
modern RIC assumes that n and p are large but that the
number of true variables in the model is close to one. Un-
like BIC and RIC, IIC works for all values of p and n, and
for any q (cid:28) p. The results presented in this paper are for
“hard” problems, in which the coefﬁcients are close to the
limit of being detectable above the noise. For easy prob-
lems, where the signal to noise ratio is high, all methods
tend to work reasonably well. For problems which have a
mix of easy and hard coefﬁcients, the SFS algorithm can
be modiﬁed to make multiple passes, ﬁrst “investing” a rel-
atively small number of bits to ﬁnd the easy features, and
then using the algorithm as described above to ﬁnd the hard
features.

Key to the guarantee that IIC works for widely varying val-
ues of n, p and q is the use of an adaptive penalty to control
the ratio of correct (“true”) to incorrect (“false”) features by
using an information theoretic coding to adjust the thresh-
old on the entropy reduction necessary for adding a variable
to the model. Streaming Feature Selection with IIC is ex-
tremely easily to implement on top of any algorithm which
incrementally considers features for addition and calculates
their entropy reduction or p-value. For linear and logistic
regression, we have found that SFS can easily handle mil-
lions of features.

References

[1] S. Dzeroski and N. Lavrac. Relational Data Mining.

Springer-Verlag, 2001.

[2] Jorma Rissanen. Hypothesis selection and testing by
the mdl principle. The Computer Journal, 42:260–
269, 1999.

[3] D. P. Foster and E. I. George. The risk inﬂation cri-
terion for multiple regression. Annals of Statistics,
22:1947–1975, 1994.

[4] D. L. Donoho and I. M. Johnstone. Ideal spatial adap-
tation by wavelet shrinkage. Biometrika, 81:425–455,
1994.

[5] Y. Benjamini and Y. Hochberg. Controlling the false
discovery rate: a practical and powerful approach to
multiple testing. Journal of the Royal Statistical So-
ciety, Series B(57):289–300, 1995.

[6] A. Popescul and L. H. Ungar. Cluster-based concept
invention for statistical relational learning. In Proc.
Conference Knowledge Discovery and Data Mining
(KDD-2004), 2004.

[7] D. P. Foster and R. A. Stine. Variable selection
in data mining: Building a predictive model for
bankruptcy. Journal of the American Statistical As-
sociation (JASA), 2004. 303-313.

363[8] Felix Abramovich, Y. Benjamini, D. Donoho, and Ian
Johnstone. Adapting to unknown sparsity by control-
ling the false discovery rate. Technical Report 2000–
19, Dept. of Statistics, Stanford University, Stanford,
CA, 2000.

[9] E. I. George and D. P. Foster. Calibration and empiri-
cal bayes variable selection. Biometrika, 87:731–747,
2000.

[10] I. M. Johnstone and B. W. Silverman. Needles and
straw in haystacks: Empirical bayes estimates of pos-
sibly sparse sequences. Annals of Statistics, 32:1594–
1649, 2004.

[11] D. P. Foster and R. A. Stine. Adaptive variable se-
lection competes with Bayes experts. Submitted for
publication, 2004.

[12] In JMLR Special Issue on Variable Selection. Journal

of Machine Learning Research (JMLR), 2003.

[13] In NIPS 2003 workshop on feature extraction, 2003.

[14] A. Popescul and L. H. Ungar. Structural logistic
In KDD Workshop on

regression for link analysis.
Multi-Relational Data Mining, 2003.

364Defensive Forecasting

Vladimir Vovk∗
vovk@cs.rhul.ac.uk

http://vovk.net

Akimichi Takemura†

takemura@stat.t.u-tokyo.ac.jp

http://www.e.u-tokyo.ac.jp/~takemura

Glenn Shafer‡∗

gshafer@andromeda.rutgers.edu

http://glennshafer.com

Abstract

We consider how to make probability fore-
casts of binary labels. Our main mathemati-
cal result is that for any continuous gambling
strategy used for detecting disagreement be-
tween the forecasts and the actual
labels,
there exists a forecasting strategy whose fore-
casts are ideal as far as this gambling strat-
egy is concerned. A forecasting strategy ob-
tained in this way from a gambling strategy
demonstrating a strong law of large numbers
is simpliﬁed and studied empirically.

1 INTRODUCTION

Probability forecasting can be thought of as a game
between two players, Forecaster and Reality:

FOR n = 1, 2, . . . :

Reality announces xn ∈ X.
Forecaster announces pn ∈ [0, 1].
Reality announces yn ∈ {0, 1}.

On each round, Forecaster predicts Reality’s move yn
chosen from the label space, always taken to be {0, 1}
in this paper. His move, the probability forecast pn,
can be interpreted as the probability he attaches to
the event yn = 1. To help Forecaster, Reality presents
him with an object xn at the beginning of the round;
xn are chosen from an object space X.
Forecaster’s goal is to produce pn that agree with the
observed yn. Various results of probability theory,
∗Computer Learning Research Centre, Department of
Computer Science, Royal Holloway, University of London,
Egham, Surrey TW20 0EX, England.
†Department of Mathematical Informatics, Graduate
School of Information Science and Technology, University
of Tokyo, 7-3-1 Hongo, Bunkyo-ku, Tokyo 113-0033, Japan.
‡Rutgers Business School—Newark and New Bruns-

wick, 180 University Avenue, Newark, NJ 07102, USA.

in particular limit theorems (such as the weak and
strong laws of large numbers, the law of the iterated
logarithm, and the central limit theorem) and large-
deviation inequalities (such as Hoeﬀding’s inequality),
describe diﬀerent aspects of agreement between pn and
yn. For example, according to the strong law of large
numbers, we expect that

n(cid:88)

i=1

lim
n→∞

1
n

(yi − pi) = 0.

(1)

Such results will be called laws of probability and the
existing body of laws of probability will be called clas-
sical probability theory.
In §2, following [12], we formalize Forecaster’s goal by
adding a third player, Skeptic, who is allowed to gam-
ble at the odds given by Forecaster’s probabilities. We
state a result from [14] and [12] suggesting that Skep-
tic’s gambling strategies can be used as tests of agree-
ment between pn and yn and that all tests of agree-
ment between pn and yn can be expressed as Skeptic’s
gambling strategies. Therefore, the forecasting proto-
col with Skeptic provides an alternative way of stating
laws of probability.
As demonstrated in [12], many standard proof tech-
niques developed in classical probability theory can be
translated into continuous strategies for Skeptic. In §3
we show that for any continuous strategy S for Skep-
tic there exists a strategy F for Forecaster such that S
does not detect any disagreement between the yn and
the pn produced by F. This result is a “meta-theorem”
that allows one to move from laws of probability to
forecasting algorithms: as soon as a law of probability
is expressed as a continuous strategy for Skeptic, we
have a forecasting algorithm that guarantees that this
law will hold; there are no assumptions about Reality,
who may play adversarially.
Our meta-theorem is of any interest only if one can ﬁnd
suﬃciently interesting laws of probability (expressed as
gambling strategies) that can serve as its input. In §4

365we apply it to the important properties of unbiased-
ness in the large and small of the forecasts pn ((1) is an
asymptotic version of the former). The resulting fore-
casting strategy is automatically unbiased, no matter
what data x1, y1, x2, y2, . . . is observed.
In §5 we simplify the algorithm obtained in §4 and
demonstrate its performance on some artiﬁcially gen-
erated data sets.

2 THE GAMBLING FRAMEWORK

FOR TESTING PROBABILITY
FORECASTS

Skeptic is allowed to bet at the odds deﬁned by Fore-
caster’s probabilities, and he refutes the probabilities if
he multiplies his capital manyfold. This is formalized
as a perfect-information game in which Skeptic plays
against a team composed of Forecaster and Reality:

Binary Forecasting Game I
Players: Reality, Forecaster, Skeptic
Protocol:
K0 := 1.
FOR n = 1, 2, . . . :

Reality announces xn ∈ X.
Forecaster announces pn ∈ [0, 1].
Skeptic announces sn ∈ R.
Reality announces yn ∈ {0, 1}.
Kn := Kn−1 + sn(yn − pn).

Restriction on Skeptic: Skeptic must choose the sn
so that his capital is always nonnegative (Kn ≥ 0 for
all n) no matter how the other players move.

This is a perfect-information protocol; the players
move in the order indicated, and each player sees the
other player’s moves as they are made.
It speciﬁes
both an initial value for Skeptic’s capital (K0 = 1)
and a lower bound on its subsequent values (Kn ≥ 0).
Our interpretation, which will be called the testing in-
terpretation, of Binary Forecasting Game I is that Kn
measures the degree to which Skeptic has shown Fore-
caster to do a bad job of predicting yi, i = 1, . . . , n.

2.1 VALIDITY AND UNIVERSALITY OF

THE TESTING INTERPRETATION

As explained in [12], the testing interpretation is valid
and universal in an important sense. Let us assume,
for simplicity, that objects are absent (formally, that
|X| = 1).
In the case where Forecaster starts from
a probability measure P on {0, 1}∞ and obtains his
forecasts pn ∈ [0, 1] as conditional probabilities under

P that yn = 1 given y1, . . . , yn−1, we have a standard
way of testing P and, therefore, pn: choose an event
A ⊆ {0, 1}∞ (the critical region) with a small P (A)
and reject P if A happens. The testing interpretation
satisﬁes the following two properties:

Validity Suppose Skeptic’s strategy is measurable
and pn are obtained from P ; Kn then form a
nonnegative martingale w.r. to P . According to
Doob’s inequality [14, 3], for any positive con-
stant C, supn Kn ≥ C with P -probability at most
1/C. (If Forecaster is doing a bad job according
to the testing interpretation, he is also doing a
bad job from the standard point of view.)

Universality According to Ville’s theorem ([12],
§8.5),
for any positive constant  and any
event A ⊆ {0, 1}∞ such that P (A) < , Skep-
tic has a measurable strategy that ensures
lim inf n→∞ Kn > 1/ whenever A happens, pro-
vided pn are computed from P . (If Forecaster is
doing a bad job according to the standard point
of view, he is also doing a bad job according to
the testing interpretation.) In the case P (A) = 0,
Skeptic actually has a measurable strategy that
ensures limn→∞ Kn = ∞ on A.

The universality of the gambling scenario of Binary
Forecasting Game I is its most important advantage
over von Mises’s gambling scenario based on subse-
quence selection; it was discovered by Ville [14].

2.2 CONTINUITY OF GAMBLING

STRATEGIES

In [12] we constructed Skeptic’s strategies that made
him rich when the statement of any of several key laws
of probability theory was violated. The constructions
were explicit and lead to continuous gambling strate-
gies. We conjecture that every natural result of clas-
sical probability theory leads to a continuous strategy
for Skeptic.

3 DEFEATING SKEPTIC

In this section we prove the main (albeit very simple)
mathematical result of this paper: for any continuous
strategy for Skeptic there exists a strategy for Fore-
caster that does not allow Skeptic’s capital to grow,
regardless of what Reality is doing. Actually, our re-
sult will be even stronger: we will have Skeptic an-
nounce his strategy for each round before Forecaster’s
move on that round rather than making him announce
his full strategy at the beginning of the game, and we
will drop the restriction on Skeptic. Therefore, we con-

366using the strategy sn = s

n(cid:89)

i=1

Kn =

n := Kn−1. Indeed, since
(1 + (yi − pi)),

on the paths where Kn is bounded we have

(1 + (yi − pi)) ≤ C,

n(cid:89)
n(cid:88)

i=1

i=1

n(cid:88)



i=1



ln(1 + (yi − pi)) ≤ ln C,

n(cid:88)

(yi − pi) − 2

(yi − pi)2 ≤ ln C,

(yi − pi) ≤ ln C + 2n,

i=1

n(cid:88)
n(cid:88)
(yi − pi) ≤ ln C
n

i=1
1
n

+ 

i=1

sup
n

Kn < ∞ =⇒ lim sup
n→∞

1
n

(yi − pi) ≤ 

(2)

lim sup
n→∞

1
n

(yi − pi) ≤ .

(4)

sider the following perfect-information game that pits
Forecaster against the two other players:

Binary Forecasting Game II
Players: Reality, Forecaster, Skeptic
Protocol:
K0 := 1.
FOR n = 1, 2, . . . :

Reality announces xn ∈ X.
Skeptic announces continuous Sn : [0, 1] → R.
Forecaster announces pn ∈ [0, 1].
Reality announces yn ∈ {0, 1}.
Kn := Kn−1 + Sn(pn)(yn − pn).

Theorem 1 Forecaster has a strategy in Binary Fore-
casting Game II that ensures K0 ≥ K1 ≥ K2 ≥ ··· .

Proof Forecaster can use the following strategy to en-
sure K0 ≥ K1 ≥ ··· :

• if the function Sn(p) takes the value 0, choose pn

so that Sn(pn) = 0;

• if Sn is always positive, take pn := 1;
• if Sn is always negative, take pn := 0.

4 EXAMPLES OF GAMBLING

STRATEGIES

In this section we discuss strategies for Forecaster
obtained by Theorem 1 from diﬀerent strategies for
Skeptic; the former will be called defensive forecasting
strategies. There are many results of classical proba-
bility theory that we could use, but we will concen-
trate on the simple strategy described in [12], p. 69,
for proving the strong law of large numbers.
If Sn(p) = Sn does not depend on p, the strategy from
the proof of Theorem 1 makes Forecaster choose

0

pn :=

1
0 or 1

if Sn < 0
if Sn > 0
if Sn = 0.

The basic procedure described in [12] (p. 69) is as fol-
lows. Let  ∈ (0, 0.5] be a small number (expressing
our tolerance to violations of the strong law of large
numbers). In Binary Forecasting Game I, Skeptic can
ensure that

n(cid:88)

i=1

n(cid:88)
n(cid:88)

i=1

1
n

1
n
n + s−

i=1

n(cid:88)

i=1

(we have used the fact that ln(1 + t) ≥ t − t2 when
|t| ≤ 0.5). If Skeptic wants to ensure

Kn < ∞ =⇒ − ≤ lim inf
n→∞

sup
n

(yi − pi)

≤ lim sup
n→∞

(yi − pi) ≤ ,

he can use the strategy sn := (s
wants to ensure

n )/2, and if he

Kn < ∞ =⇒ lim
n→∞

sup
n

1
n

(yi − pi) = 0,

(3)

n + s−

he can use a convex mixture of (s
n )/2 over a se-
quence of  converging to zero. There are also standard
ways of strengthening (3) to
n→∞ Kn < ∞ =⇒ lim
lim inf
n→∞

(yi − pi) = 0;

n(cid:88)

1
n

i=1

for details, see [12].
In the rest of this section we will draw on the excellent
survey [2]. We will see how Forecaster defeats increas-
ingly sophisticated strategies for Skeptic.

4.1 UNBIASEDNESS IN THE LARGE

Following Murphy and Epstein [7], we say that Fore-
caster is unbiased in the large if (1) holds. Let us ﬁrst
consider the one-sided relaxed version of this property

n(cid:88)

i=1

367The strategy for Skeptic described above, Sn(p) :=
Kn, leads to Forecaster always choosing pn := 1; (4)
is then satisﬁed in a trivial way.
Forecaster’s strategy corresponding to the two-sided
version

n(cid:88)

−  ≤ lim inf
n→∞

1
n

(yi − pi)

i=1

≤ lim sup
n→∞

1
n

n(cid:88)

i=1

(yi − pi) ≤ 

(5)

is not much more reasonable. Indeed, it can be repre-
sented as follows. The initial capital 1 is split evenly
between two accounts, and Skeptic gambles with the
two accounts separately. If at the outset of round n the
capital on the ﬁrst account is K1
n−1 and the capital on
the second account is K2
n−1
with the ﬁrst account and s2
n−1 with the sec-
ond account; his total move is

n−1, Skeptic plays s1

n := −K2

n := K1

(cid:33)

(1 + (pi − yi))

.

Sn(p) := K1

(cid:195)

n−1(cid:89)

i=1

n−1

n−1 − K2

(1 + (yi − pi)) − n−1(cid:89)
n−1(cid:88)

i=1

Therefore, Forecaster’s move is pn := 1 if

ln(1 + (yi − pi)) >

ln(1 + (pi − yi)),

i=1

n−1(cid:88)

i=1

ln(1 + (pi − yi)),

ln(1 + (yi − pi)) <

and pn can be chosen arbitrarily in the case of equal-
ity. The limiting form of this strategy as  → 0 is:
Forecaster’s move is pn := 1 if

= 

n−1(cid:88)

i=1

n−1(cid:88)

i=1

pn := 0 if

pn := 0 if

and pn can be chosen arbitrarily in the case of equality.
We can see that unbiasedness in the large does not
lead to interesting forecasts: Forecaster fulﬁls his task
too well. In the one-sided case (4), he always chooses
pn := 1 making

n(cid:88)

(6)

as small as possible.
 → 0, he manages to guarantee that

In the two-sided case (5) with

(cid:175)(cid:175)(cid:175)(cid:175)(cid:175) n(cid:88)

i=1

(cid:175)(cid:175)(cid:175)(cid:175)(cid:175) ≤ 1.

(yi − pi)

(cid:80)
(cid:80)

(cid:80)

His goals are achieved with categorical forecasts, pn ∈
{0, 1}.
In the rest of this section we consider the more inter-
esting case where Sn(p) depends on p.

4.2 UNBIASEDNESS IN THE SMALL

We now consider a subtler requirement that forecasts
should satisfy, which we introduce informally. We say
that the forecasts pn are unbiased in the small (or reli-
able, or valid, or well calibrated) if, for any p∗ ∈ [0, 1],

i=1,...,n:pi≈p∗ yi
i=1,...,n:pi≈p∗ 1

≈ p∗

(7)

i=1,...,n:pi≈p∗ 1 is not too small.

provided
Let us ﬁrst consider just one value for p∗. Instead of
the “crisp” point p∗ we will consider a “fuzzy point” I :
[0, 1] → [0, 1] such that I(p∗) = 1 and I(p) = 0 for all p
outside a small neighborhood of p∗. A standard choice
would be something like I := I[p−,p+], where [p−, p+] is
a short interval containing p and I[p−,p+] is its indicator
function, but we will want I to be continuous (it can,
however, be arbitrarily close to I[p−,p+]).
The strategy for Skeptic ensuring (2) can be modiﬁed
as follows. Let  ∈ (0, 0.5] be again a small num-
ber. Now we consider the strategy Sn(p) = S,I
n (p) :=
I(p)Kn−1. Since
Kn =

(1 + I(pi)(yi − pi)),

n(cid:89)

on the paths where Kn is bounded we have

i=1

(1 + I(pi)(yi − pi)) ≤ C,

ln(1 + I(pi)(yi − pi)) ≤ ln C,

n(cid:88)

n(cid:88)

I(pi)(yi − pi) − 2

I 2(pi)(yi − pi)2 ≤ ln C,

i=1

I(pi)(yi − pi) − 2

I(pi) ≤ ln C

i=1

i=1

(the last step involves replacing I 2(pi) with I(pi); the
loss of precision is not great if I is close to I[p−,p+]),

n(cid:88)



n(cid:88)

n(cid:88)

n(cid:89)
n(cid:88)

i=1

i=1

n−1(cid:88)
n−1(cid:88)

i=1

i=1

(yi − pi) > 0,

(yi − pi) < 0,

n(cid:88)

i=1



(yi − pi)



I(pi)(yi − pi) ≤ ln C + 2

I(pi),

i=1

i=1

i=1

368(cid:80)n
(cid:80)n
i=1 I(pi)(yi − pi)

i=1 I(pi)

(cid:80)n

ln C
i=1 I(pi)

≤



+ .

The last inequality shows that the mean of yi for pi
close to p∗ is close to p∗ provided we have observed suf-
ﬁciently many such pi; its interpretation is especially
simple when I is close to I[p−,p+].
n (p) and
In general, we may consider a mixture of S,I
S−,I
(p) for diﬀerent values of  and for diﬀerent I cov-
ering all p∗ ∈ [0, 1]. If we make sure that the mixture
is continuous (which is always the case for continuous
I and ﬁnitely many  and I), Theorem 1 provides us
with forecasts that are unbiased in the small.

n

4.3 USING THE OBJECTS

Unbiasedness, even in the small, is only a necessary but
far from suﬃcient condition for good forecasts: for ex-
ample, a forecaster who ignores the objects xn can be
perfectly calibrated, no matter how much useful infor-
mation xn contain. (Cf. the discussion of resolution in
[2]; we prefer not to use the term “resolution”, which
is too closely connected with the very special way of
probability forecasting based on sorting and labeling.)
It is easy to make the algorithm of the previous sub-
section take the objects into account: we can allow the
test functions I to depend not only on p but also on
the current object xn; Sn(p) then becomes a mixture
of

n (p) := I(p, xn)
S,I

(1 + I(pi, xi)(yi − pi))

i=1

and S−,I

n

(p) (deﬁned analogously) over  and I.

4.4 RELATION TO A STANDARD

COUNTER-EXAMPLE

Suppose, for simplicity, that objects are absent (|X| =
1). The standard construction from Dawid [1] showing
that no forecasting strategy produces forecasts pn that
are unbiased in the small for all sequences is as follows.
Deﬁne an inﬁnite sequence y1, y2, . . . recursively by

(cid:40)

n−1(cid:89)

where pn is the forecast produced by the forecasting
strategy after seeing y1, . . . , yn−1. For the forecasts
pn < 0.5 we always have yn = 1 and for the forecasts
pn ≥ 0.5 we always have yn = 0; obviously, we do not
have unbiasedness in the small.
Let us see what Dawid’s construction gives when ap-
plied to the defensive forecasting strategy constructed
(p), as described
from the mixture of S,I

n (p) and S−,I

n

above, over diﬀerent  and diﬀerent I; we will assume
not only that the test functions I cover all [0, 1] but
also that each point p ∈ [0, 1] is covered by arbitrar-
ily narrow (concentrated in a small neighborhood of
p) test functions.
It is clear that we will inevitably
have pn → 0.5 if pn are produced by the defensive
forecasting strategy and yn are produced by Dawid’s
construction. On the other hand, since all test func-
tions I are continuous and so cannot sharply distin-
guish between the cases pn < 0.5 and pn ≥ 0.5, we do
not have any contradiction: neither the test functions
nor any observer who can only measure the pn with a
ﬁnite precision can detect the lack of unbiasedness in
the small.
In this paper we are only interested in unbiasedness
in the small when the test functions I are required
to be continuous. Dawid’s construction shows that
unbiasedness in the small is impossible to achieve if I
are allowed to be indicator functions of intervals (such
as [0, 0.5) and [0.5, 1]). To achieve unbiasedness in the
small in this stronger sense, randomization appears
necessary (see, e.g., [18]). It is interesting that already
a little bit of randomization suﬃces, as explained in
[5].

5 SIMPLIFIED ALGORITHM
Let us assume ﬁrst that objects are absent, |X| = 1.
It was observed empirically that the performance of
defensive forecasting strategies with a ﬁxed  does not
depend on  much (provided it is not too large; e.g., in
the above calculations we assumed  ≤ 0.5). This sug-
gests letting  → 0 (in particular, we will assume that
 (cid:191) n−2). As the test functions I we will take Gaus-
sian bells Ij with standard deviation σ > 0 located
densely and uniformly in the interval [0, 1]. Letting ≈
stand for approximate equality and using the short-
hand

(cid:80)
± f(±) := f(+) + f(−), we obtain:
(cid:88)

(cid:88)

(±)Ij(p)

(1 ± Ij(pi)(yi − pi))

Sn(p) =

n−1(cid:89)
(cid:195)
n−1(cid:88)
(cid:195)

i=1

i=1

(cid:195)
(cid:195)

i=1

n−1(cid:88)
n−1(cid:88)
n−1(cid:88)

i=1

i=1

(±)Ij(p) exp

±

Ij(pi)(yi − pi)

(±)Ij(p)

1 ± 

Ij(pi)(yi − pi)

(±)Ij(p)

±

Ij(pi)(yi − pi)

yn :=

1
0

if pn < 0.5
otherwise,

=

(±)Ij(p) exp

ln(1 ± Ij(pi)(yi − pi))

j

±

j

±

(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)
(cid:88)

≈

≈

±

±

j

j

=

±

j

(cid:33)

(cid:33)
(cid:33)
(cid:33)

369n−1(cid:88)

i=1

Ij(pi)(yi − pi)

∝

Ij(p)

(cid:88)
n−1(cid:88)

j

=

i=1

K(p, pi)(yi − pi),

(8)

(cid:88)
(cid:182)

j

where K(p, pi) is the Mercer kernel

K(p, pi) :=

Ij(p)Ij(pi).

(cid:90) 1

0

This Mercer kernel can be approximated by

exp

1√
2πσ

(cid:181)
(cid:181)
−(t − pi)2
−(t − p)2
(cid:182)
(cid:181)
2σ2
2σ2
−(t − p)2 + (t − pi)2
(cid:182)
(cid:181)
−(t − p)2 + (t − pi)2

exp

2σ2

dt.

dt

exp

2σ2

1√
2πσ

∝

≈

exp

(cid:90) 1
(cid:90) ∞

0

−∞

(cid:182)

dt

Figure 1: The First 1000 Probabilities Output by the
K29 (σ = 0.01) and Laplace Forecasting Strategies on
a Randomly Generated Bit Sequence

As a function of p, the last expression is proportional
to the density of the sum of two Gaussian random
variables of variance σ2; therefore, it is proportional
to

(cid:182)

(cid:181)
−(p − pi)2
4σ2

.

exp

To get an idea of the properties of this forecasting
strategy, which we call the K29 strategy (or algo-
rithm), we run it and the Laplace forecasting strategy
(pn := (k + 1)/(n + 1), where k is the number of 1s
observed so far) on a randomly generated bit sequence
of length 1000 (with the probability of 1 equal to 0.5).
A zero point pn of Sn was found using the simple bi-
section procedure (see, e.g., [9], §§9.2–9.4, for more so-
phisticated methods): (a) start with the interval [0, 1];
(b) let p be the mid-point of the current interval; (c)
if Sn(p) > 0, remove the left half of the current in-
terval; otherwise, remove its right half; (d) go to (b).
We did 10 iterations, after which the mid-point of the
remaining interval was output as pn. Notice that the
values Sn(0) and Sn(1) did not have to be tested. Our
program was written in MATLAB, Version 7, and the
initial state of the random number generator was set
to 0.
Figure 1 shows that the probabilities output by the
K29 (σ = 0.01) and Laplace forecasting strategies are
almost indistinguishable. To see that these two fore-
casting strategies can behave very diﬀerently, we com-
plemented the 1000 bits generated as described above
with 1000 0s followed by 1000 1s. The result is shown
in Figure 2. The K29 strategy detects that the proba-
bility p of 1 changes after the 1000th round, and fairly
quickly moves down. When the probability changes

again after the 2000th round, K29 starts moving to-
ward p = 1, but interestingly, hesitates around the line
p = 0.5, as if expecting the process to reverse to the
original probability of 1.
The Mercer kernel

(cid:182)

(cid:181)
−(p − pi)2
4σ2

K(p, pi) = exp

n−1(cid:88)

used in these experiments is known in machine learning
as the Gaussian kernel (in the usual parameterization
4σ2 is replaced by 2σ2 or c); however, many other
Mercer kernels also give reasonable results.
If we start from test functions I depending on the ob-
ject, instead of (8) we will arrive at the expression

Sn(p) =

K((p, xn), (pi, xi))(yi − pi),

(9)

i=1

where K is a Mercer kernel on the squared product
([0, 1]× X)2. There are standard ways of constructing
such Mercer kernels from Mercer kernels on [0, 1]2 and
X2 (see, e.g., the description of tensor products and
direct sums in [13, 11]). For Sn to be continuous, we
have to require that K be forecast-continuous in the
following sense: for all x ∈ X and all (p(cid:48), x(cid:48)) ∈ [0, 1] ×
X, K((p, x), (p(cid:48), x(cid:48))) is continuous as a function of p.
The overall procedure can be summarized as follows.

K29 Algorithm
Parameter: forecast-continuous Mercer kernel K on
([0, 1] × X)2
FOR n = 1, 2, . . . :
Read xn ∈ X.

0100200300400500600700800900100000.10.20.30.40.50.60.70.80.91K29 forecasting strategyLaplace forecasting strategy370law of large numbers used in this paper was extracted
from Ville’s [14] martingale proof of the law of the
iterated logarithm (upper half).
The theory of probability forecasting was a topic of in-
tensive research in meteorology in the 1960s and 1970s;
this research is summarized in [2]. Machine learning is
still mainly concerned with categorical prediction, but
the situation appears to be changing. Probability fore-
casting using Bayesian networks is a mature ﬁeld; the
literature devoted to probability forecasting using de-
cision trees and to calibrating other algorithms is also
fairly rich. So far, however, the ﬁeld of probability
forecasting has been developing without any explicit
connections with classical probability theory.
Defensive forecasting is indirectly related, in a sense
dual, to prediction with expert advice (reviewed in
[15], §4) and its special case, Bayesian prediction. In
prediction with expert advice one starts with a given
loss function and tries to make predictions that lead
to a small loss as measured by that loss function. In
defensive forecasting, one starts with a law of proba-
bility and then makes predictions such that this law
of probability is satisﬁed. So the choice of the law
of probability when designing the forecasting strategy
plays a role analogous to the choice of the loss function
in prediction with expert advice.
In prediction with expert advice one combines a pool of
potentially promising forecasting strategies to obtain
a forecasting strategy that performs not much worse
than the best strategies in the pool. In defensive fore-
casting one combines strategies for Skeptic (such as
the strategies corresponding to diﬀerent test functions
I and diﬀerent ± in §4) to obtain one strategy achiev-
ing an interesting goal (such as unbiasedness in the
small); a strategy for Forecaster is then obtained us-
ing Theorem 1. The possibility of mixing strategies
for Skeptic is as fundamental in defensive forecasting
as the possibility of mixing strategies for Forecaster in
prediction with expert advice.
This paper continues the work started by Foster and
Vohra [4] and later developed in, e.g., [6, 10, 18] (the
last paper replaces the von Mises–style framework of
the previous papers with a martingale framework, as
in this paper). The approach of this paper is similar to
that of the recent paper [5], which also considers de-
terministic forecasting strategies and continuous test
functions for unbiasedness in the small.
The main diﬀerence of this paper’s approach from the
bulk of work in learning theory is that we do not make
any assumptions about Reality’s strategy.
The following directions of further research appear to
us most important:

Figure 2: The Probabilities Output by the K29 (σ =
0.01) and Laplace Forecasting Strategies on a Ran-
domly Generated Sequence of 1000 Bits Followed by
1000 0s and 1000 1s

Deﬁne Sn(p) as per (9).
Output any root p of Sn(p) = 0 as pn;
if there are no roots, pn := (1 + sign(Sn))/2.
Read yn ∈ {0, 1}.

Computer experiments reported in [16] show that the
K29 algorithm performs well on a standard benchmark
data set. For a theoretical discussion of the K29 algo-
rithm, see [19] (Appendix) and [17].

6 RELATED WORK AND

DIRECTIONS OF FURTHER
RESEARCH

This paper’s methods connect two areas that have
been developing independently so far: probability fore-
casting and classical probability theory.
It appears
that, when properly developed, these methods can
beneﬁt both areas:

• the powerful machinery of classical probability

theory can be used for probability forecasting;

• practical problems of probability forecasting may

suggest new laws of probability.

Classical probability theory started from Bernoulli’s
weak law of large numbers (1713) and is the subject
of countless monographs and textbooks. The original
statements of most of its results were for independent
random variables, but they were later extended to the
martingale framework; the latter was reduced to its
game-theoretic core in [12]. The proof of the strong

05001000150020002500300000.10.20.30.40.50.60.70.80.91K29 forecasting strategyLaplace forecasting strategy371• extending Theorem 1 to other forecasting proto-
cols (such as multi-label classiﬁcation) and design-
ing eﬃcient algorithms for ﬁnding the correspond-
ing pn;

• exploring forecasting strategies corresponding to:
(a) Hoeﬀding’s inequality, (b) the central limit
theorem, (c) the law of the iterated logarithm (all
we did in this paper was to slightly extend the
strong law of large numbers and then use it for
probability forecasting).

Acknowledgments

We are grateful to the participants of the PAS-
CAL workshop “Notions of complexity:
information-
theoretic, computational and statistical approaches”
(October 2004, EURANDOM) who commented on
this work and to the anonymous referees for use-
ful suggestions. This work was partially supported
by BBSRC (grant 111/BIO14428), EPSRC (grant
GR/R46670/01), MRC (grant S505/65), Royal So-
ciety, and, especially, the Superrobust Computation
Project (Graduate School of Information Science and
Technology, University of Tokyo).

References

[1] A. Philip Dawid. Self-calibrating priors do not
exist: Comment. Journal of the American Sta-
tistical Association, 80:340–341, 1985. This is a
contribution to the discussion in [8].

[2] A. Philip Dawid. Probability forecasting.

In
Samuel Kotz, Norman L. Johnson, and Camp-
bell B. Read, editors, Encyclopedia of Statistical
Sciences, volume 7, pages 210–218. Wiley, New
York, 1986.

[3] Joseph L. Doob. Stochastic Processes. Wiley, New

York, 1953.

[4] Dean P. Foster and Rakesh V. Vohra. Asymptotic

calibration. Biometrika, 85:379–390, 1998.

[5] Sham M. Kakade and Dean P. Foster. Determin-
istic calibration and Nash equilibrium.
In John
Shawe-Taylor and Yoram Singer, editors, Pro-
ceedings of the Seventeenth Annual Conference on
Learning Theory, volume 3120 of Lecture Notes in
Computer Science, pages 33–48, Heidelberg, 2004.
Springer.

[6] Ehud Lehrer. Any inspection is manipulable. Eco-

nometrica, 69:1333–1347, 2001.

[7] Allan H. Murphy and Edward S. Epstein. Veriﬁ-
cation of probabilistic predictions: a brief review.
Journal of Applied Meteorology, 6:748–755, 1967.

[8] David Oakes. Self-calibrating priors do not exist
(with discussion). Journal of the American Sta-
tistical Association, 80:339–342, 1985.

[9] William H. Press, Brian P. Flannery, Saul A.
Teukolsky, and William T. Vetterling. Numer-
ical Recipes in C. Cambridge University Press,
Cambridge, second edition, 1992.

[10] Alvaro Sandroni, Rann Smorodinsky,

and
Rakesh V. Vohra. Calibration with many check-
ing rules. Mathematics of Operations Research,
28:141–153, 2003.

[11] Bernhard Sch¨olkopf and Alexander J. Smola.
Learning with Kernels. MIT Press, Cambridge,
MA, 2002.

[12] Glenn Shafer and Vladimir Vovk. Probability and
Finance: It’s Only a Game! Wiley, New York,
2001.

[13] Vladimir N. Vapnik. Statistical Learning Theory.

Wiley, New York, 1998.

[14] Jean Ville. Etude critique de la notion de collectif.

Gauthier-Villars, Paris, 1939.

[15] Vladimir Vovk. Competitive on-line statistics. In-
ternational Statistical Review, 69:213–248, 2001.

[16] Vladimir Vovk. Defensive forecasting for a bench-
mark data set, The Game-Theoretic Probability
and Finance project, http://probabilityandfi
nance.com, Working Paper #9, September 2004.

[17] Vladimir Vovk. Non-asymptotic calibration
and resolution, The Game-Theoretic Probability
and Finance project, http://probabilityandfi
nance.com, Working Paper #11, November 2004.

[18] Vladimir Vovk and Glenn Shafer. Good ran-
domized sequential probability forecasting is al-
ways possible, The Game-Theoretic Probability
and Finance project, http://probabilityandfi
nance.com, Working Paper #7, June 2003 (re-
vised September 2004).

[19] Vladimir

Defensive

Vovk, Akimichi Takemura,

and
Glenn Shafer.
forecasting, The
Game-Theoretic Probability and Finance project,
http://probabilityandfinance.com, Working
Paper #8, September 2004. This is a fuller version
of the current paper, with an appendix added.

372Inadequacy of interval estimates corresponding to variational

Bayesian approximations

Bo Wang

Department of Statistics
University of Glasgow

Glasgow G12 8QQ

Scotland, U.K.

D. M. Titterington
Department of Statistics
University of Glasgow

Glasgow G12 8QQ

Scotland, U.K.

Abstract

In this paper we investigate the properties
of the covariance matrices associated with
variational Bayesian approximations, based
on data from mixture models, and com-
pare them with the true covariance matri-
ces, corresponding to Fisher information ma-
trices.
It is shown that the covariance ma-
trices from the variational Bayes approxima-
tions are normally ‘too small’ compared with
those for the maximum likelihood estimator,
so that resulting interval estimates for the pa-
rameters will be unrealistically narrow, espe-
cially if the components of the mixture model
are not well separated.

1 INTRODUCTION

A standard paradigm for learning about the param-
eters of latent variable models from data is that of
maximum likelihood. However, maximum likelihood
is well known for its tendency to overﬁt the data. On
the other hand, the Bayesian framework averages over
all possible settings of the model parameters. As a re-
sult Bayesian inference does not suﬀer from overﬁtting,
and, moreover, prior knowledge can be incorporated
naturally. Unfortunately, for most models of interest
involving missing data a full Bayesian analysis requires
the computation of the posterior distribution for a col-
lection of unknown quantities, including parameters
and latent variables, which often leads to intractable
calculations because complicated multiple integrations
are involved. The use of Markov chain Monte Carlo
methods for numerical integration helps to side-step
this problem, but this is clearly quite expensive, in
terms of time and storage. Moreover MCMC algo-
rithms can still exhibit conceptual and technical dif-
ﬁculties, for example in the assessment of the conver-
gence of the chain to its stationary distribution.

Recently, a deterministic approximate approach to
the intractable Bayesian learning problem, the vari-
ational Bayesian approximation, has been introduced
in the machine learning community, and is widely
recognised to be eﬀective and promising in a variety
of models, such as hidden Markov models (MacKay
(1997)), graphical models (Attias (1999, 2000)), mix-
ture models (Humphreys and Titterington (2000);
Penny and Roberts (2000)), mixtures of factor anal-
ysers (Ghahramani and Beal (2000)) and state space
models (Ghahramani and Beal (2001); Beal (2003)).
A general formulation of the variational approach is
described in Jordan (2004). The variational Bayes
approach facilitates analytical calculation of approxi-
mate posterior distributions over the hidden variables,
parameters and structures. They are computed via
an iterative algorithm that is closely related to the
Expectation-Maximisation (EM) algorithm and so its
convergence is guaranteed. Empirically, variational
Bayesian approximations have often been shown to
perform well in earlier contributions, but it has also
been noticed that this approach may underestimate
the spread of the posterior distributions for some par-
ticular examples (Humphreys and Titterington (2000);
Consonni and Marin (2004)), so its validity has still to
be assessed properly: exact theoretical analysis of the
quality of the method needs to be studied.
Some initial investigations have been implemented by
the authors in Wang and Titterington (2003) and
Wang and Titterington (2004b).
It was shown the-
oretically that the iterative algorithm for obtaining
the variational Bayes approximation for the param-
eters of Gaussian mixture models converges locally
to the maximum likelihood estimator at the rate of
O(1/n) in the large sample limit. Later in Wang and
Titterington (2004a) we proved local convergence of
variational approximation algorithms for more general
models, namely exponential family models with miss-
ing values, and showed that the variational posterior
distribution for the parameters is asymptotically nor-
mal with the same mean but a diﬀerent covariance ma-

3732 THE MIXTURE MODEL AND

q(Θ)(Θ) = q(π)

trix compared with those for the maximum likelihood
estimator.
Since the maximum likelihood estimators and poste-
rior distributions are also asymptotically normal (see
for instance Walker (1969), Chen (1985) and Ghosal
et al. (1995)), an interesting problem is how these
two limiting normal distributions can be compared.
From the early results on local convergence of vari-
ational approximations, one can note that they have
the same mean (i.e. the true value). However, their
covariance matrices do not appear to be equal. In the
context of Gaussian mixture models, in this paper we
study the covariance matrices associated with varia-
tional Bayesian approximations, which dictate the per-
formance of variational Bayes approximations for in-
terval estimates, and compare them with the true co-
variance matrices, as given in terms of Fisher informa-
tion matrices. We show that the covariance matrices
from the variational Bayes approximation are normally
‘too small’ compared with those for the MLE, so that
resulting interval estimates for the parameters will be
too narrow, especially if the components of the mix-
ture model are not well separated. Some numerical
examples illustrate the theoretical analysis.

THE VARIATIONAL
APPROXIMATION

m(cid:88)

We consider a model in which we have a mixture of
m multivariate Gaussian densities p1, p2, . . . , pm with
mean vectors µ1, . . . , µm and precision (inverse covari-
ance) matrices Γ1, . . . , Γm, respectively. Thus the den-
sity of an observation is given by

s=1

p(yi|Θ) =

ps(yi|Θ)p(si = s|Θ),

(1)
where yi ∈ IRd denotes the ith observed data vector,
and si indicates the hidden component that generated
it. The components are labelled by s = 1, 2, . . . , m,
and component s has mixing coeﬃcient πs = p(si =
s|Θ), for any i and s = 1, 2, . . . , m − 1. Consequently
πm (cid:44) p(si = m|Θ) = 1 −(cid:80)m−1
s=1 πs. We write the
 µ1
 , Γ =

 , µ =

 π1

parameters collectively as

 ,



vec(Γm)

...
µm

vec(Γ1)

π =

(cid:48)
, Γ

(cid:48)
, µ

)(cid:48). Here vec(A) is deﬁned as the

and Θ = (π
stacked columns of A.
We use conjugate priors on the parameters Θ. The
mixing coeﬃcients π follow a symmetric Dirichlet dis-
tribution D(λ0). The precisions are independently

...
πm−1
(cid:48)

...

Wishart, with Γs ∼ W(ν0, Φ0). The means condi-
tioned on the precisions are independently Gaussian,
with µs|Γs ∼ N (ρ0, β0Γs), where β0Γs is the inverse
covariance matrix of the Gaussian distribution.
The joint density of Θ, S and Y is

p(Θ, S, Y ) = p(π)

p(µs|Γs)p(Γs)

πsipsi(yi).

m(cid:89)

s=1

n(cid:89)

i=1

In the variational Bayes approach, we use an approxi-
mating density q(S, Θ) for p(S, Θ|Y ), which factorises
as

q(S, Θ) = q(S)(S)q(Θ)(Θ),

(2)
and such that the factors are chosen to maximise the
negative free energy

q(S, Θ) log p(Θ, S, Y )

q(S, Θ) dΘ.

(3)

(cid:90) (cid:88){S}

As a result of the form of p(Θ, S, Y ), it follows im-
mediately that the optimal q(S)(S) and q(Θ)(Θ) must
factorise as

q(S)(S) =

n(cid:89)
m(cid:89)

i=1

s=1

q(S)
i

(si),

q(µs|Γs)q(Γs).

As in Attias (1999, 2000), Ghahramani and Beal
(2000), Humphreys and Titterington (2000) and
Penny and Roberts (2000), the remaining details of
the variational posteriors can be obtained by the fol-
lowing iterative procedure.
In turn, we perform the
following two stages.
(i) Optimise q(Θ)(Θ) for ﬁxed {q(S)
(si), i = 1, . . . , n}.
Since conjugate priors are used, these variational
posteriors are functionally identical to the priors,
with diﬀerent hyperparameter values:
the mixing
coeﬃcients π are jointly Dirichlet, with q(π) =
D(π : λ1, . . . , λm); the precisions are independently
Wishart, with q(Γs) = W(Γs : νs, Φs); and the means
conditioned on the precisions are independently Gaus-
sian, with q(µs|Γs) = N (µs : ρs, βsΓs). Here D(π :
λ1, . . . , λm), W(Γs : νs, Φs) and N (µs : ρs, βsΓs) de-
note the relevant density functions. The hyperparam-
eters are updated as follows:

i

n(cid:88)

λs =

ris + λ0,

ρs =(cid:16) n(cid:88)
n(cid:88)

βs =

i=1

i=1

i=1

risyi + β0ρ0(cid:17)(cid:46)(cid:16) n(cid:88)
n(cid:88)

ris + β0,

νs =

i=1

i=1

ris + β0(cid:17),

ris + ν0,

(4)

(5)

(6)

374and

+(cid:104)(
n(cid:88)

i=1

n(cid:88)

Φs = Φ0 +

ris(yi − ¯µs)(yi − ¯µs)(cid:48)
ris)β0(¯µs − ρ0)(¯µs − ρ0)(cid:48)(cid:105)(cid:46)(cid:16) n(cid:88)

i=1

ris + β0(cid:17),

i=1

(7)

where

ris = q(S)

i

(si = s),

¯µs =(cid:16) n(cid:88)

risyi(cid:17)(cid:46)(cid:16) n(cid:88)

ris(cid:17).
(si), si = 1, . . . , m, i = 1, . . . , n} for

i=1

i=1

(ii) Optimise {q(S)
ﬁxed q(Θ)(Θ). For s = 1, . . . , m, this results in

i

−d/(2βs) (cid:44) γis,

ris = q(S)

(si = s)

i

where

−(yi−ρs)

∝ ˜πs˜Γ1/2
s e

(cid:48) ¯Γs(yi−ρs)/2 · e
˜πs = exp{(cid:90) q(π) log πsdπ},
˜Γs = exp{(cid:90) q(Γs) log |Γs|dΓs},
¯Γs =νsΦ−1
s .
If we let γi = (cid:80)m

s=1 γis,

i = 1, . . . , n, then ris =

γis/γi.
This iterative procedure can be initialised by taking,
for each i and s,
ris ∝ λ0(ν0Φ0)1/2e

ν0Φ0(yi−ρ0)/2 · e

−d/(2β0).

−(yi−ρ0)

(cid:48)

∗, µ
∗, µ

∗
∗ and Γ
∗
∗ and Γ

where the maps M1, M2 and M3 represent the itera-
tive procedure in (i) (ii).
In Wang and Titterington (2004b), the following con-
vergence property of the variational Bayes estimates
deﬁned by (8) has been proved.
Lemma 1. With probability 1 as n approaches inﬁn-
ity, π(k), µ(k) and Γ(k) converge locally to the true
values π
; that is, they converge to the
true values whenever the starting values are suﬃciently
near to π
Remark 1. For general mixture models, because the
negative free energy (3) may be multi-modal, the vari-
ational Bayes algorithm may converge to diﬀerent lim-
its if diﬀerent starting values (or hyperparameters) are
chosen. Therefore only local convergence was proved.
Denote by ⊗ the Kronecker product. By (4)-(7) and
the convergence property given by Lemma 1, one can
easily obtain that, as n tends to inﬁnity, nCov(π) →

.

 (cid:44) Λ,



∗
1)

π

1(1 − π
∗
−π

∗
sπ

...

∗
k

π

−π

∗
sπ

∗
k

m−1(1 − π
∗
∗
m−1)
s )−1 ⊗ (Φ(k)
s )−1
∗−1
(Γ∗
s

s

s

s

s

(Φ(k)

= 2ν(k)

nCov(Γs) = 2nν(k)
⊗ Φ(k)

(Φ(k)
s )−1 → 2π
IE(µs) =(cid:90) µsq(k)(µs)dµs
=(cid:90) µsq(k)(µs|Γs)q(k)(Γs)dΓsdµs = ρ(k)

⊗ Γ∗
s),

s ,

3 THE CONVERGENCE OF

VARIATIONAL BAYES
APPROXIMATIONS AND
ASSOCIATED COVARIANCE
MATRICES

Suppose that the true value of the parameter Θ is Θ∗.
At the kth iteration of the iterative procedure (i) (ii),
we deﬁne the variational Bayesian estimates π(k), µ(k)
and Γ(k) of the parameters π, µ and Γ as their varia-
tional posterior means corresponding to the distribu-
tions q(π), q(µs|Γs) and q(Γs) at the current iteration,
thus the iterative procedure (i) (ii) suggests the follow-
ing algorithm: starting with some initial values π(0),
µ(0) and Γ(0), the variational Bayesian estimates are
computed recursively by

π(k+1)
s
µ(k+1)
Γ(k+1)

s

s

= M1(π(k), µ(k), Γ(k)),
= M2(π(k), µ(k), Γ(k)),
= M3(π(k), µ(k), Γ(k)),

(8a)
(8b)
(8c)

q(k)(µs)dµs

q(k)(µs|Γs)q(k)(Γs)dΓsdµs

and it follows that

nCov(µs) = n(cid:90) (µs − ρ(k)
s )(µs − ρ(k)
s )(cid:48)
= n(cid:90) (µs − ρ(k)
s )(µs − ρ(k)
s )(cid:48)
= n(cid:90) (β(k)
s )−1q(k)(Γs)dΓs

s Γ(k)
)−1(ν(k)

s

= n(β(k)

s

− m − 1)−1Φ(k)
s and Γtτ

s

→ π

s Γ∗−1
∗−1

s

.

Moreover, letting µj
µs and Γs, respectively, we have

s denote any elements of

nCov(µj

s

=n(cid:90) [µj
=n(cid:90) [µj

s, Γtτ
s )
− IE(µj

s)][Γtτ

s

− IE(Γtτ
s )]

· q(k)(µs)q(k)(Γs)dµj

sdΓtτ
− IE(Γtτ
s )]
· q(k)(µs|Γs)(q(k)(Γs))2dµj

− ρ(k),j

][Γtτ
s

s

s

s

sdΓtτ

s = 0,

375After a straightforward calculation we obtain
s = 1, . . . , m − 1,

= αs − αm,

and the other covariances between π, µ and Γ are zero,
by assumption (2).
Deﬁne

Ω = diag(π

s Γ∗−1
∗−1

s

), Σ = diag(2π

∗−1
s

(Γ∗

s

⊗ Γ∗

s)).

Then the covariance matrix of Θ associated with the
variational posterior distributions is such that

nCov(Θ) →Λ 0 0

0 Ω 0
0 0 Σ

 (cid:44) Ψ.

Let

(9)

∂L
∂πs
∂L
∂µs

= πsαsΓsδs,

s = 1, . . . , m,

=

1
2 πsαsσs,

s = 1, . . . , m.

∂L

∂vec(Γs)



Q =

α1 − αm

αm−1 − αm
π1α1Γ1δ1

πmαmΓmδm

1
2 π1α1σ1

1
2 πmαmσm

...

...

...



.

4 COMPARISON OF

VARIATIONAL COVARIANCE
MATRICES WITH FISHER
INFORMATION MATRICES

In this section we ﬁrst give an explicit expression for
the Fisher information matrix associated with our mix-
ture model, and then compare it with the covariance
matrix associated with variational Bayes approxima-
tions, which is crucial for the performance of interval
estimates based on variational Bayes approximations.
In the sequel, we denote by y any random vector dis-
tributed according to the probability density of the
form (1). Thus the Fisher information matrix per ob-
servation is given by

I(Θ) =(cid:90)

[∇ log p(y|Θ)][∇ log p(y|Θ)](cid:48)

p(y|Θ)dy.
(10)

IRd

The Fisher information matrix plays an important role
in determining the asymptotic distribution of maxi-
mum likelihood estimators. Under quite mild condi-
tions, Redner and Walker (1984) stated the following
property of asymptotic normality for the maximum
likelihood estimator for mixture models.
Theorem 1. Let ˜Θn be the strongly consistent MLE
n( ˜Θn − Θ∗) is asymptoti-
of the parameter Θ. Then
cally normally distributed with mean zero and covari-
ance matrix I(Θ∗)−1.
Let L(Θ) = log p(y|Θ) and, for s = 1, . . . , m, let

√

αs = ps(y|Θ)
p(y|Θ) ,
σs = vec[Γ−1

s

δs = y − µs,

− (y − µs)(y − µs)(cid:48)].

One should bear in mind the dependencies of αs, δs
and σs on Θ or its components, which are omitted for
the sake of clarity.

Then the Fisher information matrix (10) can be rewrit-
ten as

(cid:48)
QQ

p(y|Θ)dy = IE[QQ
(cid:48)].

(11)

I(Θ) =(cid:90)

IRd

1, then

s=1 ηs =

The following lemma is a corollary of Schwarz’s in-
equality, which has been used in Peters and Walker
(1978).

Lemma 2. If ηs ≥ 0 for s = 1,··· , m and(cid:80)m

ξsηs|2 ≤ m(cid:88)

| m(cid:88)
for any {ξs}s=1,··· ,m.
Moreover, after a tedious calculation the following
equalities can be veriﬁed.
Lemma 3. At the true value Θ∗, we have that, for
s = 1, . . . , m,

ξ2
s ηs

s=1

s=1

IE(αs) = 1,
IE(αsσs) = 0,

IE(αsσsσ

IE(αsδs) = 0,
(cid:48)
IE(αsδsσ
s) = 0,
⊗ Γ∗
s)−1.

s) = 2(Γ∗
(cid:48)

s

(12a)
(12b)
(12c)

Now we state the main result of this section.
Theorem 2. If Ψ is deﬁned as in (9), then the Fisher
information matrix satisﬁes

I(Θ∗)−1 ≥ Ψ,

(13)
by which it is meant that I(Θ∗)−1 − Ψ is nonnegative
deﬁnite.

376Proof. Obviously, Ψ is positive deﬁnite, and thus it is
suﬃcient to show that
Θ(cid:48)
for any

I(Θ∗)Θ ≤ Θ(cid:48)Ψ−1Θ = u

(cid:48)Ω−1v+W

(cid:48)Λ−1u+v

Σ−1W

(cid:48)

Θ = u

v
W

 =



u1
...
um−1
v1
...
vm
...

vec(W1)

vec(Wm)



,

where us, vs and Ws are elements of the vector spaces
IR, IRd and the set of all real, symmetric d×d matrices,
respectively, for each s.
In fact, by (11) one has that
(cid:48))Θ

Θ(cid:48)

(cid:48)

π

π

+

s=1

s=1

s=1

1
2 π

s=1
∗

∗
s αsδ

∗
s αsσ

∗−1
s + δ

m(cid:88)
svec(Ws)(cid:27)2
sΓ∗
(cid:48)

I(Θ∗)Θ = Θ(cid:48)IE(QQ
=IE(cid:26) m−1(cid:88)
(αs − αm)us +
m(cid:88)
=IE(cid:26) m(cid:88)
s αs(cid:104)usπ
where we have deﬁned um = −(cid:80)m−1
Noting that (cid:80)m
≤IE(cid:26) m(cid:88)
s αs(cid:104)usπ
IE(cid:26)u2
m(cid:88)

∗−1
s αs + π

Θ(cid:48)IE(QQ

∗−1
s + δ

(cid:48))Θ
∗

∗
s αs[δ

we have

svs +

svs +

(cid:48)
sΓ∗

sΓ∗
(cid:48)

svs]2

s=1 π

sπ

s=1

=

π

s=1

(cid:48)
sΓ∗
svs

svec(Ws)(cid:105)(cid:27)2

(cid:48)

,

1
2 σ

svec(Ws)(cid:105)2(cid:27)

(cid:48)

1
2 σ

s=1 us.

∗
s αs = 1 and applying Lemma 2,

=

+

1
4 π
+ usαsσ

sπ

m(cid:88)
IE(cid:8)u2
IE(cid:26)1
m(cid:88)

s=1

+

∗
s αs[σ
(cid:48)
svec(Ws) + π

svsσ

∗
s αsδ

sΓ∗
(cid:48)
(cid:48)
svec(Ws)]2 + 2usαsδ
svec(Ws)(cid:27)
svs
(cid:48)
svs]2(cid:27)
sΓ∗
(cid:48)

sΓ∗
(cid:48)
IE(cid:26)π
m(cid:88)
∗
s αs[δ
svec(Ws)]2(cid:27)

∗−1

s αs(cid:9) +

∗
s αs[σ

s=1

(cid:48)

s=1

4 π
(cid:44)I1 + I2 + I3,
where the last equality holds since the cross terms av-
erage to zero, by (12).

Clearly, one has

I1 =

m(cid:88)

IE(cid:8)αsu2
Note that um = −(cid:80)m−1

s=1

sπ

s=1 us and
∗−1
m

∗−1
1 + π

π

∗−1

s (cid:9) =

m(cid:88)

s=1

∗−1
s

.

u2
sπ

∗−1
m

π

Λ−1 =

...

∗−1
m

π

∗−1
m−1 + π
from which it can be easily checked that u
By (12),

π

∗−1
m
(cid:48)Λ−1u = I1.

 ,



(cid:48)
sπ
v

sΓ∗
∗

svs = v

(cid:48)Ω−1v.

svs]2(cid:27) =
sΓ∗
(cid:48)

m(cid:88)
svec(Ws)(cid:3)2(cid:27)

s=1

(cid:48)

∗

s αs(cid:2)σ
s αs(cid:104)tr{[Γ∗−1

s

IE(cid:26)π

m(cid:88)

s=1

∗
s αs[δ

I2 =

Finally,

I3 =

=

s=1

4 π
∗

IE(cid:26)1
m(cid:88)
IE(cid:26)1
m(cid:88)
m(cid:88)
· IE(cid:26)αs(cid:104)(tr{Γ∗−1

4 π
∗
s

1
4 π

s=1

s=1

=

s)(y − µ
− (y − µ
∗
∗

s)(cid:48)]Ws}(cid:105)2(cid:27)

− 2tr{Γ∗−1

Ws})2
s)(y − µ
s Ws})2 + (tr{(y − µ
s)(cid:48)
∗
∗
Ws}(cid:105)(cid:27)
s Ws}tr{(y − µ
s)(y − µ
s)(cid:48)
∗
∗
s(cid:26)IE(cid:104)αs(tr{(y − µ
Ws})2(cid:105)
s)(y − µ
s)(cid:48)
∗
∗
s Ws})2(cid:27).

− (tr{Γ∗−1

∗

1
4 π

m(cid:88)

s=1

=

By expanding the matrices into expressions involving
their components and noting (12c), one can check that

Therefore,

I3 =

s

IE(cid:104)αs(tr{(y − µ
=2tr(cid:8)(WsΓ∗−1
m(cid:88)
m(cid:88)

Ws})2(cid:105)
s)(y − µ
s)(cid:48)
∗
∗
)2(cid:9) + (tr{Γ∗−1
s Ws})2.
s Ws(cid:9)
str(cid:8)WsΓ∗−2
⊗ Γ∗
∗
s[vec(Ws)](cid:48)(Γ∗

s=1

s

=

∗

1
2 π
1
2 π
Σ−1W .

s=1
(cid:48)
= W

s)−1vec(Ws)

The proof is complete.

377Table 1: The Fisher information (FI) matrices and the
inverse of the variational covariance (IVC) matrices
corresponding to Figure 1. Each cell contains a 2 × 2
matrix.

(1)

(2)

(3)

(4)

5.83 2.50

2.47 1.29

6.08 3.77

0.00 0.00

2.50 5.83
5.83 2.50

1.29 0.91
5.83 3.33

3.77 5.50
6.67 3.33

0.00 11.11
4.50 2.50

2.50 5.83

3.33 6.67

3.33 5.83

2.50 12.50

FI

IVC

By Lemma 2 the equality in (13) holds if and only if the
mixture model (1) has only one component. In other
cases, there must exist overlapping.
If the compo-
nents are well separated or have smaller overlaps, the
mixture distribution can be regarded approximately
as multinomial. In this case, for a given observation
yi, there exists one ps(yi) which is far larger than the
others, and therefore the inverse of Fisher information
matrix is close to the covariance matrix of the varia-
tional posterior distribution. Theorem 2 shows that if
overlapping exists between the components of a mix-
ture model then the covariance matrix from the vari-
ational Bayes approximation is ‘too small’ compared
with that for the MLE, so that resulting interval esti-
mates for the parameters will be too narrow.

5 NUMERICAL EXPERIMENTS

In this section we demonstrate our results with some
simple mixtures of normal densities.
First we consider mixtures of three known univariate
normal densities p1(·), p2(·) and p3(·) with means µ1,
µ2 and µ3; all have unit variance. The mixing coef-
ﬁcients are π1, π2 and 1 − π1 − π2, respectively. For
diﬀerent values of these parameters, we compute the
corresponding Fisher information matrices and the co-
variance matrices of the variational posteriors. The
mixture densities of some typical cases are plotted in
Figure 1, and the corresponding Fisher information
matrices and the inverses of variational covariance ma-
trices are described in Table 1. Obviously, if the com-
ponents in the mixture models are widely separated,
these two matrices are very similar, whereas, if the
components are nearly identical, they are very diﬀer-
ent. The latter behaviour is reﬂected particularly by
the case (4) in Figure 1, where p1(·) and p1(·) are com-
pletely identical.
Next we consider a more general mixture model of two
unknown normal densities. Their means, precisions
and mixing coeﬃcients are µ1, Γ1, π and µ2, Γ2, 1− π,

Figure 1: Some typical mixture densities based on dif-
ferent values of the parameters.

respectively. We compute the Fisher information ma-
trices and the covariance matrices of the variational
posteriors by using two sets of values of the param-
eters, namely, (π, µ1, Γ1, µ2, Γ2) = (0.1, 1, 1, 0, 1) and
(0.5, 6, 1, 0, 1). There is large overlap between the two
components for the ﬁrst set of the parameters while
they are well separated for the second. For the ﬁrst
∗, is
set, the Fisher information matrix, denoted by I
0.7456 −0.0363 −0.2612
0.0606 −0.0134 −0.0539
0.0774
0.7723
0.0198
0.0167
0.0774
0.3646

1.1542
0.1505
0.1505
0.0259
0.7456
0.0606
−0.0363 −0.0134
−0.2612 −0.0539

0.0167
0.0152
0.0198





and the inverse of the variational covariance matrix is
Ψ−1 = diag(11.1111, 0.1000, 0.9000, 0.0500, 0.4500).
Evaluated at a couple of arbitrary vectors Θ =
(0.8, 4, 3, 2, 1)(cid:48) and (1, 1, 1, 1, 1)(cid:48), for illustrative pur-
poses, Θ(cid:48)
∗Θ (Θ(cid:48)Ψ−1Θ) are equal to 14.0885 and
3.7435 (17.4611 and 12.6111), respectively. For the
second set, the Fisher information matrix I

∗ is

I





0.0122

0.0170 −0.0170
0.0122
0.0133
0.0157
0.2308

0.0125
3.9834
0.0125
0.4905 −0.0091 −0.0133
0.0125
0.0125 −0.0091
0.4905 −0.0122
0.0170 −0.0133 −0.0122
0.2308
−0.0170
0.0133
0.0157
and the inverse of the variational covariance matrix is
Ψ−1 = diag(4.0000, 0.5000, 0.5000, 0.2500, 0.2500).
Evaluated at the same vectors Θ, Θ(cid:48)
∗Θ (Θ(cid:48)Ψ−1Θ)
are equal to 15.7931 and 5.4889 (16.3100 and 5.5000),
respectively.

I

−10−5051000.050.10.150.2(1) pi1=0.3,pi2=0.3,mu1=−8,mu2=0,mu3=8−2−10120.050.10.150.20.250.3(2) pi1=0.4,pi2=0.3,mu1=−1,mu2=0,mu3=1−5051000.050.10.150.2(3) pi1=0.3,pi2=0.4,mu1=−2.5,mu2=0,mu3=8−5051000.10.20.30.4(4) pi1=0.5,pi2=0.1,mu1=8,mu2=0,mu3=8378(8), the variational variance Λ, the maximum likeli-
∗), and
hood estimate ˜π and the Fisher information I(π
these are used to form approximate 95% conﬁdence in-

tervals given by ˆπ±1.96(cid:112)Λ/n and ˜π±1.96/(cid:112)nI(π∗).

For µ2 = 3.0, a total of 100 samples are generated and
the resulting 100 conﬁdence intervals are computed.
It turns out that 91 out of these 100 intervals do in-
clude the true value if the variational approximation is
used, and 92 by the MLE method. Both proportions
are close to the nominal conﬁdence coeﬃcient of 0.95.
For µ2 = 1.0, the same number of conﬁdence inter-
vals are generated. Among these 100 intervals, only
68 of those based on the variational approximation in-
clude the true value, while this number is 92 from the
MLE. In this case the resulting interval estimates are
obviously too narrow.
Since the variational approaches provide good approx-
imations for point estimates but poor approximations
for interval estimates, a question of interest is whether
or not the performance can be improved if we substi-
tute the variational covariance matrix by the inverse
of Fisher information for interval estimates. Theoreti-
cally, by this approach the resulting intervals would be
very close to those obtained by MLE when the sam-
ple size is large, since the variational Bayes estimator
converges to the maximum likelihood estimator. In or-
der to verify this point, we use the same independent
random samples as in the previous numerical exam-
ples to generate approximate 95% conﬁdence interval

given by ˆπ ± 1.96/(cid:112)nI(π∗). For µ2 = 3.0, 93 out of

100 intervals include the true value, whereas 96 inter-
vals contain the true value if µ2 is 1.0. It turns out
that the approach of substituting the variational co-
variance matrix in the inverse of Fisher information
does reﬁne the interval estimates.

6 CONCLUSION

Exact theoretical analysis of the quality of variational
Bayes approximations is an important issue. Hav-
ing proved the properties of local convergence and
asymptotic normality in Wang and Titterington (2003,
2004b,a), in this paper we examined the covariance
matrices associated with variational Bayesian approx-
imations and the resulting performance of variational
Bayes approximations for interval estimates, by com-
paring them with the true covariances, given in terms
of Fisher information matrices. It has been shown that
the covariance matrices corresponding to the varia-
tional Bayes approximation are normally ‘too small’
compared with those for the MLE, so that resulting
interval estimates for the parameters will be too nar-
row if the components of the mixture model are not
well separated. Finally the theoretical analysis was re-
inforced by some numerical examples, which also sug-

Figure 2: The inverses of the variances associated with
the variational Bayes approximation and Fisher infor-
mation for diﬀerent mixing coeﬃcients. The solid lines
denote Fisher information and the dashed horizontal
lines indicate the inverses of the variances for the vari-
ational Bayes approximation.

To clarify the dependence of the diﬀerences between
the inverses of the variational covariance and Fisher
information matrices on the overlaps between the com-
ponents, now we use a mixture model of two known
normal densities with means µ1 and µ2 with unit vari-
ance. The mixing coeﬃcients are π and 1 − π, respec-
tively. The parameter π is given a Beta prior distri-
bution Beta(1, 1); i.e. π ∼ Un(0, 1). To compare the
variance associated with the variational Bayes approx-
imate with Fisher information, we ﬁx one component
to have mean zero and compute the inverse of the vari-
ance and Fisher information with the other component
having varying mean µ1. The results are plotted in
Figure 2 for diﬀerent mixing coeﬃcients π. The in-
verses of the variances associated with the variational
Bayes approximation do not vary with the changes of
µ1, whereas the Fisher informations do. And the dif-
ferences between them become larger as µ1 is closer to
zero, the mean of the ﬁrst component.
We investigate the performance of interval estimates
based on the variational approximation using two em-
pirical experiments. We ﬁx the mixing coeﬃcient at
∗ = 0.65 and one component to have mean zero and
π
unit variance within a mixture model of two normal
densities. Independent random samples, each of size
n = 50, are selected from the mixture model with the
mean of the other component equal to µ2 = 3.0 and
1.0, and with unit variance. For each sample we cal-
culate the variational Bayesian estimate ˆπ as given by

−10−50510−20020406080100120Mixing coefficient pi=0.01mu1−10−50510−2024681012Mixing coefficient pi=0.1mu1−10−50510−1012345Mixing coefficient pi=0.3mu1−10−50510−1012345Mixing coefficient pi=0.5mu1379In Bethlehem, J. G. and van der Heijden, P. G. M.,
editors, COMPSTAT2000, pages 331–336. Physica-
Verlag, Heidelberg.

Jordan, M. I. (2004). Graphical models. Statistical

Science, 19(1):140–155.

MacKay, D. J. C. (1997). Ensemble learning for hid-
den Markov models. Technical report, Cavendish
Laboratory, University of Cambridge.

Penny, W. D. and Roberts, S. J. (2000). Variational
Bayes for 1-dimensional mixture models. Technical
Report PARG-2000-01, Oxford University.

Peters, B. C. and Walker, H. F. (1978). An itera-
tive procedure for obtaining maximum-likelihood es-
timates of the parameters for a mixture of normal
distributions. SIAM J. Appl. Math., 35:362–378.

Redner, R. A. and Walker, H. F. (1984). Mixture den-
sities, maximum likelihood and the EM algorithm.
SIAM Review, 26:195–239.

Walker, A. M. (1969). On the asymptotic behaviour of
posterior distributions. J. R. Statist. Soc. B, 31:80–
88.

Wang, B. and Titterington, D. M. (2003). Local con-
vergence of variational Bayes estimators for mix-
ing coeﬃcients. Technical Report 03-4, University
of Glasgow. http://www.stats.gla.ac.uk/Research/-
TechRep2003/03-4.pdf.

Wang, B. and Titterington, D. M. (2004a). Con-
vergence and asymptotic normality of variational
Bayesian approximations for exponential
family
models with missing values. In Chickering, M. and
Halpern, J., editors, Proceedings of the twentieth
conference on Uncertainty in Artiﬁcial Intelligence,
pages 577–584, Banﬀ, Canada. AUAI Press.

Wang, B. and Titterington, D. M. (2004b). Conver-
gence properties of a general algorithm for calcu-
lating variational Bayesian estimates for a normal
mixture model. Technical Report 04-3, University
of Glasgow. http://www.stats.gla.ac.uk/Research/-
TechRep2004/04 3.pdf.

gested an idea leading to the reﬁnement of variational
Bayes approximations for interval estimates by substi-
tuting the variational covariance by the ‘usual’ true
covariance - the inverse of Fisher information. The ar-
guments in the paper can be extended to non-Gaussian
mixture models, such as mixtures of exponential fam-
ily distributions, without any technical diﬃculty.

Acknowledgement

This work was supported by a grant from the UK Sci-
ence and Engineering Research Council. This work
was also supported in part by the IST Programme of
the European Community, under the PASCAL Net-
work of Excellence, IST-2002-506778. This publica-
tion only reﬂects the authors’ views.

References
Attias, H. (1999).

Inferring parameters and struc-
ture of latent variable models by variational Bayes.
In Prade, H. and Laskey, K., editors, Proc. 15th
Conference on Uncertainty in Artiﬁcial Intelligence,
pages 21–30, Stockholm, Sweden. Morgan Kauf-
mann Publishers.

Attias, H. (2000). A variational Bayesian framework
for graphical models.
In Solla, S., Leen, T., and
Muller, K.-R., editors, Advances in Neural Infor-
mation Processing Systems 12, pages 209–215. MIT
Press, Cambridge, MA.

Beal, M. J. (2003). Variational Algorithms for Approx-
imate Bayesian Inference. PhD thesis, University
College London.

Chen, C.-F. (1985). On asymptotic normality of lim-
iting density functions with Bayesian implications.
J. R. Statist. Soc. B, 47:540–546.

Consonni, G. and Marin, J.-M. (2004). A note on
variational approximate bayesian inference for la-
tent variable models. Preprint.

Ghahramani, Z. and Beal, M. J. (2000). Variational
inference for Bayesian mixtures of factor analysers.
In Solla, S., Leen, T., and Muller, K.-R., editors,
Advances in Neural Information Processing Systems
12, pages 449–455. MIT Press, Cambridge, MA.

Ghahramani, Z. and Beal, M. J. (2001). Propaga-
tion algorithms for variational Bayesian learning.
In Leen, T., Dietterich, T., and Tresp, V., editors,
Advances in Neural Information Processing Systems
13, pages 507–513. MIT Press, Cambridge, MA.

Ghosal, S., Ghosh, J. K., and Samanta, T. (1995). On
convergence of posterior distributions. The Annals
of Statistics, 23(6):2145–2152.

Humphreys, K. and Titterington, D. M. (2000). Ap-
proximate Bayesian inference for simple mixtures.

380Nonlinear Dimensionality Reduction by Semideﬁnite

Programming and Kernel Matrix Factorization

Kilian Q. Weinberger, Benjamin D. Packer, and Lawrence K. Saul∗

Department of Computer and Information Science

University of Pennsylvania, Philadelphia, PA 19104-6389

{kilianw,lsaul,bpacker}@seas.upenn.edu

Abstract

We describe an algorithm for nonlinear di-
mensionality reduction based on semideﬁnite
programming and kernel matrix factoriza-
tion. The algorithm learns a kernel matrix
for high dimensional data that lies on or near
a low dimensional manifold. In earlier work,
the kernel matrix was learned by maximizing
the variance in feature space while preserv-
ing the distances and angles between near-
est neighbors.
In this paper, adapting re-
cent ideas from semi-supervised learning on
graphs, we show that the full kernel matrix
can be very well approximated by a product
of smaller matrices. Representing the ker-
nel matrix in this way, we can reformulate
the semideﬁnite program in terms of a much
smaller submatrix of inner products between
randomly chosen landmarks. The new frame-
work leads to order-of-magnitude reductions
in computation time and makes it possible
to study much larger problems in manifold
learning.

1 Introduction

A large family of graph-based algorithms has recently
emerged for analyzing high dimensional data that
lies or or near a low dimensional manifold [2, 5, 8,
13, 19, 21, 25]. These algorithms derive low dimen-
sional embeddings from the top or bottom eigenvec-
tors of specially constructed matrices. Either directly
or indirectly, these matrices can be related to ker-
nel matrices of inner products in a nonlinear feature
space [9, 15, 22, 23]. These algorithms can thus be
viewed as kernel methods with feature spaces that “un-
fold” the manifold from which the data was sampled.

∗This work was supported by NSF Award 0238323.

In recent work [21, 22], we introduced Semideﬁnite
Embedding (SDE), an algorithm for manifold learning
based on semideﬁnite programming [20]. SDE learns
a kernel matrix by maximizing the variance in fea-
ture space while preserving the distances and angles
between nearest neighbors. It has several interesting
properties: the main optimization is convex and guar-
anteed to preserve certain aspects of the local geome-
try; the method always yields a semipositive deﬁnite
kernel matrix; the eigenspectrum of the kernel matrix
provides an estimate of the underlying manifold’s di-
mensionality; also, the method does not rely on esti-
mating geodesic distances between faraway points on
the manifold. This particular combination of advan-
tages appears unique to SDE.
The main disadvantage of SDE, relative to other al-
gorithms for manifold learning, is the time required
to solve large problems in semideﬁnite programming.
Earlier work in SDE was limited to data sets with
n≈2000 examples, and problems of that size typically
required several hours of computation on a mid-range
desktop computer.
In this paper, we describe a new framework that has
allowed us to reproduce our original results in a small
fraction of this time, as well as to study much larger
problems in manifold learning. We start by showing
that for well-sampled manifolds, the entire kernel ma-
trix can be very accurately reconstructed from a much
smaller submatrix of inner products between randomly
chosen landmarks. In particular, letting K denote the
full n×n kernel matrix, we can write:

K ≈ QLQT ,

(1)
where L is the m×m submatrix of inner products be-
tween landmarks (with m(cid:28) n) and Q is an n×m linear
transformation derived from solving a sparse set of lin-
ear equations. The factorization in eq. (1) enables us
to reformulate the semideﬁnite program in terms of the
much smaller matrix L, yielding order-of-magnitude
reductions in computation time.

381The framework in this paper has several interesting
connections to previous work in manifold learning
and kernel methods. Landmark methods were orig-
inally developed to accelerate the multidimensional
scaling procedure in Isomap [7]; they were subse-
quently applied to the fast embedding of sparse sim-
ilarity graphs [11]. Intuitively, the methods in these
papers are based on the idea of triangulation—that is,
locating points in a low dimensional space based on
their distances to a small set of landmarks. This idea
can also be viewed as an application of the Nystr¨om
method [24, 12], which is a particular way of extrapo-
lating a full kernel matrix from one of its sub-blocks.
It is worth emphasizing that the use of landmarks in
this paper is not based on this same intuition. SDE
does not directly estimate geodesic distances between
faraway inputs on the manifold, as in Isomap. As op-
posed to the Nystr¨om method, our approach is better
described as an adaptation of recent ideas for semi-
supervised learning on graphs [1, 16, 18, 26, 27]. Our
approach is somewhat novel in that we use these ideas
not for transductive inference, but for computational
savings in a purely unsupervised setting. To manage
the many constraints that appear in our semideﬁnite
programming problems, we have also adapted certain
ideas from the large-scale training of support vector
machines [6].
The paper is organized as follows. In section 2, we re-
view our earlier work on manifold learning by semideﬁ-
nite programming. In section 3, we investigate the ker-
nel matrix factorization in eq. (1), deriving the linear
transformation that reconstructs other examples from
landmarks, and showing how it simpliﬁes the semidef-
inite program for manifold learning. Section 4 gives
experimental results on data sets of images and text.
Finally, we conclude in section 5.

2 Semideﬁnite Embedding

We brieﬂy review the algorithm for SDE; more de-
tails are given in previous work [21, 22]. As in-
put, the algorithm takes high dimensional vectors
{~x1, ~x2, . . . , ~xn}; as output,
it produces low dimen-
sional vectors {~y1, ~y2, . . . , ~yn}. The inputs ~xi ∈ RD are
assumed to lie on or near a manifold that can be em-
bedded in d dimensions, where typically d (cid:28) D. The
goal of the algorithm is to estimate the dimensional-
ity d and to output a faithful embedding that reveals
the structure of the manifold.
The main idea behind SDE has been aptly described
as “maximum variance unfolding” [17]. The algorithm
attempts to maximize the variance of its embedding,
subject to the constraint that distances and angles
between nearby inputs are preserved. The resulting

transformation from inputs to outputs thus looks lo-
cally like a rotation plus translation—that is, it rep-
resents an isometry. To picture such a transformation
from D =3 to d=2 dimensions, one can imagine a ﬂag
being unfurled by pulling on its four corners.
The ﬁrst step of the algorithm is to compute the k-
nearest neighbors of each input. A neighborhood-
indicator matrix is deﬁned as ηij =1 if and only if the
inputs ~xi and ~xj are k-nearest neighbors or if there ex-
ists another input of which both are k-nearest neigh-
bors; otherwise ηij = 0. The constraints to preserve
distances and angles between k-nearest neighbors can
then be written as:

||~yi − ~yj||2 = ||~xi − ~xj||2 ,

(2)

for all (i, j) such that ηij = 1. To eliminate a transla-
tional degree of freedom in the embedding, the outputs
are also constrained to be centered on the origin:

~yi = ~0.

(3)

X

i

var(~y) =X

Finally, the algorithm attempts to “unfold” the inputs
by maximizing the variance

||~yi||2

(4)

i

while preserving local distances and angles, as in
eq. (2). Maximizing the variance of the embedding
turns out to be a useful surrogate for minimizing its di-
mensionality (which is computationally less tractable).
The above optimization can be formulated as an
instance of semideﬁnite programming [20].
Let
Kij = ~yi · ~yj denote the Gram (or kernel) matrix of the
outputs. As shown in earlier work [21, 22], eqs. (2–4)
can be written entirely in terms of the elements of this
matrix. We can then learn the kernel matrix K by
solving the following semideﬁnite program.

Maximize trace(K) subject to:
1) K (cid:23) 0.
2) ΣijKij = 0.
3) For all (i, j) such that ηij =1,
Kii − 2Kij + Kjj = ||~xi − ~xj||2.

√

As in kernel PCA [15], the embedding is derived from
the eigenvalues and eigenvectors of the kernel matrix;
λαuαi,
in particular, the algorithm outputs yαi =
where λα and uα are the top d eigenvalues and eigen-
vectors. The dimensionality of the embedding, d,
is suggested by the number of appreciably non-zero
eigenvalues.
In sum, the algorithm has three steps: (i) computing
k-nearest neighbors; (ii) computing the kernel matrix;

382and (iii) computing its top eigenvectors. The compu-
tation time is typically dominated by the semideﬁnite
program to learn the kernel matrix. In earlier work,
this step limited us to problems with n≈ 2000 exam-
ples and k ≤ 5 nearest neighbors; moreover, problems
of this size typically required several hours of compu-
tation on a mid-range desktop computer.

3 Kernel Matrix Factorization

In practice, SDE scales poorly to large data sets
because it must solve a semideﬁnite program over
n × n matrices, where n is the number of examples.
(Note that the computation time is prohibitive de-
spite polynomial-time guarantees1 of convergence for
semideﬁnite programming.) In this section, we show
that for well-sampled manifolds, the kernel matrix
K can be approximately factored as the product of
smaller matrices. We then use this representation to
derive much simpler semideﬁnite programs for the op-
timization in the previous section.

3.1 Sketch of algorithm

We begin by sketching the basic argument behind the
factorization in eq. (1). The argument has three steps.
First, we derive a linear transformation for approxi-
mately reconstructing the entire data set of high di-
mensional inputs {~xi}n
i=1 from m randomly chosen in-
puts designated as landmarks. In particular, denoting
these landmarks by {~µα}m
α=1, the reconstructed inputs
{ˆxi}n

i=1 are given by the linear transformation:

Qiα~µα.

(5)

α

The linear transformation Q is derived from a sparse
weighted graph in which each node represents an input
and the weights are used to propagate the positions of
the m landmarks to the remaining n−m nodes. The
situation is analogous to semi-supervised learning on
large graphs [1, 16, 18, 26, 27], where nodes represent
labeled or unlabeled examples and transductive infer-
ences are made by diﬀusion through the graph. In our
setting, the landmarks correspond to labeled exam-
ples, the reconstructed inputs to unlabeled examples,
and the vectors ~µα to the actual labels.
Next, we show that the same linear transformation
can be used to reconstruct the unfolded data set—that
is, after the mapping from inputs {~xi}n
i=1 to outputs

1For the examples in this paper, we used the SDP solver
CSDP v4.9 [4] with time complexity of O(n3 +c3) per it-
eration for sparse problems with n×n target matrices and
c constraints. It seems, however, that large constant factors
can also be associated with these complexity estimates.

ˆxi =X

ˆyi =X

{~yi}n
marks by {~‘α}m
{ˆyi}n

In particular, denoting the unfolded land-
α=1 and the reconstructed outputs by

i=1.
i=1, we argue that ~yi ≈ ˆyi, where:

Qiα

~‘α.

(6)

α

The connection between eqs. (5–6) will follow from
the particular construction of the weighted graph that
yields the linear transformation Q. This weighted
graph is derived by appealing to the symmetries of
linear reconstruction coeﬃcients; it is based on a simi-
lar intuition as the algorithm for manifold learning by
locally linear embedding (LLE) [13, 14].
Finally, the kernel matrix factorization in eq. (1) fol-
lows if we make the approximation

Kij = ~yi · ~yj ≈ ˆyi · ˆyj.

(7)

In particular, substituting eq. (6) into eq. (7) gives
the approximate factorization K ≈ QLQT , where
Lαβ = ~‘α · ~‘β is the submatrix of inner products be-
tween (unfolded) landmark positions.

3.2 Reconstructing from landmarks

To derive the linear transformation Q in eqs. (5–6),
we assume the high dimensional inputs {~xi}n
i=1 are
well sampled from a low dimensional manifold. In the
neighborhood of any point, this manifold can be locally
approximated by a linear subspace. Thus, to a good
approximation, we can hope to reconstruct each input
by a weighted sum of its r-nearest neighbors for some
small r. (The value of r is analogous but not necessar-
ily equal to the value of k used to deﬁne neighborhoods
in the previous section.) Reconstruction weights can
be found by minimizing the error function:

E(W ) =X

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)~xi −X
subject to the constraint thatP

i

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)2

Wij~xj

j

,

(8)

j Wij = 1 for all j, and
where Wij = 0 if ~xj is not an r-nearest neighbor of ~xi.
The sum constraint on the rows of W ensures that the
reconstruction weights are invariant to the choice of
the origin in the input space. A small regularizer for
weight decay can also be added to this error function
if it does not already have a unique global minimum.
Without loss of generality, we now identify the ﬁrst m
inputs {~x1, ~x2, . . . , ~xm} as landmarks {~µ1, ~µ2, . . . , ~µm}
and ask the following question: is it possible to recon-
struct (at least approximately) the remaining inputs
given just the landmarks ~µα and the weights Wij? For
suﬃciently large m, a unique reconstruction can be ob-
tained by minimizing eq. (8) with respect to {~xi}i>m.

383To this end, we rewrite the reconstruction error as a
function of the inputs, in the form:

Φij ~xi·~xj,

(9)

E(X) =X

ij

where Φ = (In − W )T (In − W ) and In is the n × n
identity matrix. It is useful to partition the matrix Φ
into blocks distinguishing the m landmarks from the
other (unknown) inputs:

mz }| {
(cid:18) Φ‘‘

Φu‘

n−mz }| {

Φ‘u
Φuu

(cid:19)

Φ =

(10)

In terms of this matrix, the solution with minimum
reconstruction error is given by the linear transforma-
tion in eq. (5), where:

(cid:18)

(cid:19)

Q =

Im

(Φuu)−1Φul

.

(11)

An example of this minimum error reconstruction is
shown in Fig. 1. The ﬁrst two panels show n = 10000
inputs sampled from a Swiss roll and their approxi-
mate reconstructions from eq. (5) and eq. (11) using
r =12 nearest neighbors and m=40 landmarks.
Intuitively, we can imagine the matrix Φij in eq. (9)
as deﬁning a sparse weighted graph connecting nearby
inputs. The linear transformation reconstructing in-
puts from landmarks is then analogous to the manner
in which many semi-supervised algorithms on graphs
propagate information from labeled to unlabeled ex-
amples.
To justify eq. (6), we now imagine that the data set
has been unfolded in a way that preserves distances
and angles between nearby inputs. As noted in previ-
ous work [13, 14], the weights Wij that minimize the
reconstruction error in eq. (8) are invariant to trans-
lations and rotations of each input and its r-nearest
neighbors. Thus, roughly speaking, if the unfolding
looks locally like a rotation plus translation, then the
same weights Wij that reconstruct the inputs ~xi from
their neighbors should also reconstruct the outputs ~yi
from theirs. This line of reasoning yields eq. (6). It
also suggests that if we could somehow learn to faith-
fully embed just the landmarks in a lower dimensional
space, the remainder of the inputs could be unfolded
by a simple matrix multiplication.

3.3 Embedding the landmarks

It is straightforward to reformulate the semideﬁnite
program (SDP) for the kernel matrix Kij = ~yi · ~yj
in section 2 in terms of
smaller matrix
Lαβ = ~‘α · ~‘β. In particular, appealing to the factor-
ization K ≈ QLQT , we consider the following SDP:

the

Maximize trace(QLQT ) subject to:
1) L (cid:23) 0.
2) Σij(QLQT )ij = 0.
3) For all (i, j) such that ηij =1,
(QLQT )ii−2(QLQT )ij +(QLQT )jj ≤ ||~xi − ~xj||2.

This optimization is nearly but not quite identical to
the previous SDP up to the substitution K ≈ QLQT .
The only diﬀerence is that we have changed the equal-
ity constraints in eq. (2) to inequalities. The SDP in
section 2 is guaranteed to be feasible since all the con-
straints are satisﬁed by taking Kij = ~xi · ~xj (assuming
the inputs are centered on the origin). Because the
matrix factorization in eq. (1) is only approximate,
however, here we must relax the distance constraints
to preserve feasibility. Changing the equalities to in-
equalities is the simplest possible relaxation; the trivial
solution Lαβ =0 then provides a guarantee of feasibil-
ity.
In practice, this relaxation does not appear to
change the solutions of the SDP in a signiﬁcant way;
the variance maximization inherent to the objective
function tends to saturate the pairwise distance con-
straints, even if they are not enforced as strict equali-
ties.
To summarize, the overall procedure for unfolding the
inputs ~xi based on the kernel matrix factorization
in eq. (1) is as follows:
(i) compute reconstruction
weights Wij that minimize the error function in eq. (8);
(ii) choose landmarks and compute the linear trans-
formation Q in eq. (11); (iii) solve the SDP for the
landmark kernel matrix L; (iv) derive a low dimen-
sional embedding for the landmarks ~‘α from the eigen-
vectors and eigenvalues of L; and (v) reconstruct the
outputs ~yi from eq. (6). The free parameters of the al-
gorithm are the number of nearest neighbors r used
to derive locally linear reconstructions, the number
of nearest neighbors k used to generate distance con-
straints in the SDP, and the number of landmarks m
(which also constrains the rank of the kernel matrix).
In what follows, we will refer to this algorithm as land-
mark SDE, or simply ‘SDE.
‘SDE can be much faster than SDE because its main
optimization is performed over m× m matrices, where
m (cid:28) n. The computation time in semideﬁnite pro-
gramming, however, depends not only on the matrix
size, but also on the number of constraints. An ap-
parent diﬃculty is that SDE and ‘SDE have the same
number of constraints; moreover, the constraints in
the latter are not sparse, so that a naive implementa-
tion of ‘SDE can actually be much slower than SDE.
This diﬃculty is surmounted in practice by solving the
semideﬁnite program for ‘SDE while only explicitly
monitoring a small fraction of the original constraints.
To start, we feed an initial subset of constraints to

384word
one
may
men
iraq
drugs
january
germany
recession
california
republican
government

four nearest neighbors
two, three, four, six
won’t, cannot, would, will
passengers, soldiers, oﬃcers, lawmakers
states, israel, china, noriega
computers, missiles, equipment, programs
july, october, august, march
canada, africa, arabia, marks
environment, yen, season, afternoon
minnesota, arizona, ﬂorida, georgia
democratic, strong, conservative, phone
pentagon, airline, army, bush

Table 1: Selected words and their four nearest neigh-
bors (in order of increasing distance) after nonlinear
dimensionality reduction by ‘SDE. The d = 5 dimen-
sional embedding of D = 60000 dimensional bigram
distributions was computed by ‘SDE in 35 minutes
(with n=2000, k =4, r =12, and m=30).

had to be explicitly enforced by the SDP solver to ﬁnd
a feasible solution. Interestingly, similarly faithful em-
beddings were obtained in shorter times using as few
as m=10 landmarks, though the input reconstructions
in these cases were of considerably worse quality. Also
worth mentioning is that adding low variance Gaus-
sian noise to the inputs had no signiﬁcant impact on
the algorithm’s performance.
The second data set was created from the n = 2000
most common words in the ARPA North American
Business News corpus. Each of these words was repre-
sented by its discrete probability distribution over the
D = 60000 words that could possibly follow it. The
distributions were estimated from a maximum likeli-
hood bigram model. The embedding of these high di-
mensional distributions was performed by ‘SDE (with
k = 4, r = 12, and m = 30) in about 35 minutes; the
variance of the embedding, as revealed by the eigen-
value spectrum of the landmark kernel matrix, was es-
sentially conﬁned to d = 5 dimensions. Table 1 shows
a selection of words and their four nearest neighbors
in the low dimensional embedding. Despite the mas-
sive dimensionality reduction from D =60000 to d=5,
many semantically meaningful neighborhoods are seen
to be preserved.
The third experiment was performed on n=400 color
images of a teapot viewed from diﬀerent angles in the
plane. Each vectorized image had a dimensionality of
D =23028, resulting from 3 bytes of color information
for each of 76× 101 pixels.
In previous work [22] it
was shown that SDE represents the angular mode of
variability in this data set by an almost perfect cir-
cle. Fig. 2 compares embeddings from ‘SDE (k = 4,
r = 12, m = 20) with normal SDE (k = 4) and LLE
(r = 12). The eigenvalue spectrum of ‘SDE is very

Figure 1:
(1) n = 10000 inputs sampled from a
Swiss roll; (2) linear reconstruction from r = 12 near-
est neighbors and m = 40 landmarks (denoted by
black x’s); (3) embedding from ‘SDE, with distance
and angle constraints to k =4 nearest neighbors, com-
puted in 16 minutes.

the SDP solver, consisting only of the semideﬁnite-
ness constraint, the centering constraint, and the dis-
tance constraints between landmarks and their near-
est neighbors.
If a solution is then found that vio-
lates some of the unmonitored constraints, these are
added to the problem, which is solved again. The
process is repeated until all the constraints are sat-
isﬁed. Note that this incremental scheme is made pos-
sible by the relaxation of the distance constraints from
equalities to inequalities. As in the large-scale train-
ing of support vector machines [6], it seems that many
of the constraints in ‘SDE are redundant, and simple
heuristics to prune these constraints can yield order-
of-magnitude speedups. (Note, however, that the cen-
tering and semideﬁniteness constraints in ‘SDE are al-
ways enforced.)

4 Experimental Results

Experiments were performed in MATLAB to evaluate
the performance of ‘SDE on various data sets. The
SDPs were solved with the CSDP (v4.9) optimization
toolbox [4]. Of particular concern was the speed and
accuracy of ‘SDE relative to earlier implementations
of SDE.
The ﬁrst data set, shown in the top left panel of Fig. 1,
consisted of n=10000 inputs sampled from a three di-
mensional “Swiss roll”. The other panels of Fig. 1
show the input reconstruction from m=40 landmarks
and r = 12 nearest neighbors, as well as the embed-
dingobtained in ‘SDE by constraining distances and
angles to k = 4 nearest neighbors. The computation
took 16 minutes on a mid-range desktop computer.
Table 2 shows that only 1205 out of 43182 constraints

385Figure 3: Top: Error rate of ﬁve-nearest-neighbors
classiﬁcation on the test set of USPS handwritten dig-
its. The error rate is plotted against the dimensional-
ity of embeddings from PCA and ‘SDE (with k = 4,
r =12, m=10). It can be seen that ‘SDE preserves the
neighborhood structure of the digits fairly well with
only a few dimensions. Bottom: Normalized eigen-
value spectra from ‘SDE and PCA. The latter reveals
many more dimensions with appreciable variance.

similar to that of SDE, revealing that the variance of
the embedding is concentrated in two dimensions. The
results from ‘SDE do not exactly reproduce the re-
sults from SDE on this data set, but the diﬀerence
becomes smaller with increasing number of landmarks
(at the expense of more computation time). Actu-
ally, as shown in Fig. 4, ‘SDE (which took 79 seconds)
is slower than SDE on this particular data set. The
increase in computation time has two simple explana-
tions that seem peculiar to this data set. First, this
data set is rather small, and ‘SDE incurs some over-
head in its setup that is only negligible for large data
sets. Second, this data set of images has a particular
cyclic structure that is easily “broken” if the moni-
tored constraints are not sampled evenly. Thus, this
particular data set is not well-suited to the incremen-
tal scheme for adding unenforced constraints in ‘SDE;
a large number of SDP reruns are required, resulting
in a longer overall computation time than SDE. (See
Table 2.)
The ﬁnal experiment was performed on the entire data
set of n=9298 USPS handwritten digits [10]. The in-
puts were 16×16 pixel grayscale images of the scanned
digits. Table 2 shows that only 690 out of 61735 in-
equality constraints needed to be explicitly monitored
by the SDP solver for ‘SDE to ﬁnd a feasible solution.
This made it possible to obtain an embedding in 40
minutes (with k = 4, r = 12, m = 10), whereas earlier
implementations of SDE could not handle problems

Figure 4: Relative speedup of ‘SDE versus SDE on
data sets with diﬀerent numbers of examples (n) and
landmarks (m). Speedups of two orders of magnitude
are observed on larger data sets. On small data sets,
however, SDE can be faster than ‘SDE.

of this size. To evaluate the embeddings from ‘SDE,
we compared their nearest neighbor classiﬁcation error
rates to those of PCA. The top plot in Fig. 3 shows the
classiﬁcation error rate (using ﬁve nearest neighbors
in the training images to classify test images) versus
the dimensionality of the embeddings from ‘SDE and
PCA. The error rate from ‘SDE drops very rapidly
with dimensionality, nearly matching the error rate on
the actual images with only d=3 dimensions. By con-
trast, PCA requires d=12 dimensions to overtake the
performace of ‘SDE. The bar plot at the bottom of
Fig. 3 shows the normalized eigenvalue spectra from
both ‘SDE and PCA. From this plot, it is clear that
‘SDE concentrates the variance of its embedding in
many fewer dimensions than PCA.
When does ‘SDE outperform SDE? Figure 4 shows the
speedup of ‘SDE versus SDE on several data sets. Not
surprisingly, the relative speedup grows in proportion
with the size of the data set. Small data sets (with
n < 500) can generally be unfolded faster by SDE,
while larger data sets (with 500 < n < 2000) can be
unfolded up to 400 times faster by ‘SDE. For even
larger data sets, only ‘SDE remains a viable option.

5 Conclusion

In this paper, we have developed a much faster algo-
rithm for manifold learning by semideﬁnite program-
ming. There are many aspects of the algorithm that
we are still investigating, including the interplay be-
tween the number and placement of landmarks, the
deﬁnition of local neighborhoods, and the quality of

386Figure 2: Comparison of embeddings from SDE, LLE and ‘SDE for n = 400 color images of a rotating teapot.
The vectorized images had dimension D =23028. LLE (with r =12) and ‘SDE (with k =4, r =12, m=20) yield
similar but slightly more irregular results than SDE (with k =4). The normalized eigenspectra in SDE and ‘SDE
(i.e., the eigenspectra divided by the trace of their kernel matrices) reveal that the variances of their embeddings
are concentrated in two dimensions; the eigenspectrum from LLE does not reveal this sort of information.

data set
teapots
bigrams

USPS digits
Swiss roll

n
400
2000
9298
10000

m constraints monitored
20
30
10
20

1599
11170
61735
43182

565
1396
690
1205

time (secs)

79
2103
2420
968

Table 2: Total number of constraints versus number of constraints explicitly monitored by the SDP solver for
‘SDE on several data sets. The numbers of inputs (n) and landmarks (m) are also shown, along with computation
times. The speedup of ‘SDE is largely derived from omitting redundant constraints.

the resulting reconstructions and embeddings. Nev-
ertheless, our initial results are promising and show
that manifold learning by semideﬁnite programming
can scale to much larger data sets than we originally
imagined in earlier work [21, 22].
Beyond the practical applications of ‘SDE, the frame-
work in this paper is interesting in the way it com-
bines ideas from several diﬀerent lines of recent work.
‘SDE is based on the same appeals to symmetry at
the heart of LLE [13, 14] and SDE [21, 22]. The
linear reconstructions that yield the factorization of
the kernel matrix in eq. (1) are also reminiscent of
semi-supervised algorithms for propagating labeled in-
formation through large graphs of unlabeled exam-
ples [1, 16, 18, 26, 27]. Finally, though based on a
somewhat diﬀerent intuition, the computational gains
of ‘SDE are similar to those obtained by landmark
methods for Isomap [7].
While we have applied ‘SDE (in minutes) to data
sets with as many as n = 10000 examples, there ex-
ist many larger data sets for which the algorithm re-
mains impractical. Further insights are therefore re-
quired. In related work, we have developed a simple
out-of-sample extension for SDE, analogous to similar

extensions for other spectral methods [3]. Algorithmic
advances may also emerge from the dual formulation of
“maximum variance unfolding” [17], which is related
to the problem of computing fastest mixing Markov
chains on graphs. We are hopeful that a combination
of complementary approaches will lead to even faster
and more powerful algorithms for manifold learning by
semideﬁnite programming.

Acknowledgments

We are grateful to Ali Jadbabaie (University of Penn-
sylvania) for several discussions about semideﬁnite
programming and to the anonymous reviewers for
many useful comments.

References

[1] M. Belkin, I. Matveeva, and P. Niyogi. Regulariza-
tion and semi-supervised learning on large graphs. In
Proceedings of the Seventeenth Annual Conference on
Computational Learning Theory (COLT 2004), pages
624–638, Banﬀ, Canada, 2004.

[2] M. Belkin and P. Niyogi. Laplacian eigenmaps for di-
mensionality reduction and data representation. Neu-
ral Computation, 15(6):1373–1396, 2003.

387[3] Y. Bengio, J-F. Paiement, and P. Vincent. Out-of-
sample extensions for LLE, Isomap, MDS, eigenmaps,
and spectral clustering. In S. Thrun, L. K. Saul, and
B. Sch¨olkopf, editors, Advances in Neural Information
Processing Systems 16, Cambridge, MA, 2004. MIT
Press.

[4] B. Borchers. CSDP, a C library for semideﬁnite
programming. Optimization Methods and Software
11(1):613-623, 1999.

[5] M. Brand. Charting a manifold.

In S. Becker,
S. Thrun, and K. Obermayer, editors, Advances in
Neural Information Processing Systems 15, pages 985–
992, Cambridge, MA, 2003. MIT Press.

[6] N. Cristianini and J. Shawe-Taylor. An Introduction
to Support Vector Machines. Cambridge University
Press, Cambridge, UK, 2000.

[7] V. de Silva and J. B. Tenenbaum. Global versus lo-
cal methods in nonlinear dimensionality reduction. In
S. Becker, S. Thrun, and K. Obermayer, editors, Ad-
vances in Neural Information Processing Systems 15,
pages 721–728, Cambridge, MA, 2003. MIT Press.

[8] D. L. Donoho and C. E. Grimes. Hessian eigen-
locally linear embedding techniques for high-
maps:
dimensional data.
the National
Academy of Arts and Sciences, 100:5591–5596, 2003.

Proceedings of

[9] J. Ham, D. D. Lee, S. Mika, and B. Sch¨olkopf. A kernel
view of the dimensionality reduction of manifolds. In
Proceedings of the Twenty First International Confer-
ence on Machine Learning (ICML-04), pages 369–376,
Banﬀ, Canada, 2004.

[10] J. J. Hull. A database for handwritten text recognition
research. IEEE Transaction on Pattern Analysis and
Machine Intelligence, 16(5):550–554, May 1994.

[17] J. Sun, S. Boyd, L. Xiao, and P. Diaconis. The fastest
mixing Markov process on a graph and a connection
to a maximum variance unfolding problem. SIAM Re-
view, submitted.

[18] M. Szummer and T. Jaakkola. Partially labeled clas-
siﬁcation with Markov random walks.
In T. G. Di-
etterich, S. Becker, and Z. Ghahramani, editors, Ad-
vances in Neural Information Processing Systems 14,
Cambridge, MA, 2002. MIT Press.

[19] J. B. Tenenbaum, V. de Silva, and J. C. Langford. A
global geometric framework for nonlinear dimension-
ality reduction. Science, 290:2319–2323, 2000.

[20] L. Vandenberghe and S. P. Boyd. Semideﬁnite pro-

gramming. SIAM Review, 38(1):49–95, March 1996.

[21] K. Q. Weinberger and L. K. Saul. Unsupervised
learning of image manifolds by semideﬁnite program-
ming.
In Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition (CVPR-
04), volume 2, pages 988–995, Washington D.C., 2004.

[22] K. Q. Weinberger, F. Sha, and L. K. Saul. Learning
a kernel matrix for nonlinear dimensionality reduc-
tion. In Proceedings of the Twenty First International
Conference on Machine Learning (ICML-04), pages
839–846, Banﬀ, Canada, 2004.

[23] C. K. I. Williams. On a connection between kernel
PCA and metric multidimensional scaling. In T. K.
Leen, T. G. Dietterich, and V. Tresp, editors, Ad-
vances in Neural Information Processing Systems 13,
pages 675–681, Cambridge, MA, 2001. MIT Press.

[24] Christopher K. I. Williams and Matthias Seeger. Us-
ing the Nystr¨om method to speed up kernel machines.
In T. Leen, T. Dietterich, and V. Tresp, editors, Neu-
ral Information Processing Systems 13, pages 682–
688, Cambridge, MA, 2001. MIT Press.

[11] J. C. Platt. Fast embedding of sparse similarity
graphs. In S. Thrun, L. K. Saul, and B. Sch¨olkopf,
editors, Advances in Neural Information Processing
Systems 16, Cambridge, MA, 2004. MIT Press.

[25] Z. Zhang and H. Zha. Principal manifolds and non-
linear dimensionality reduction by local tangent space
alignment. SIAM Journal of Scientiﬁc Computing, in
press.

[26] D. Zhou, O. Bousquet, T. N. Lai, J. Weston, and
B. Sch¨olkopf. Learning with local and global consis-
tency. In S. Thrun, L. K. Saul, and B. Sch¨olkopf, edi-
tors, Advances in Neural Information Processing Sys-
tems 16, pages 321–328, Cambridge, MA, 2004. MIT
Press.

[27] X. Zhu, Z. Ghahramani, and J. Laﬀerty.

Semi-
supervised learning using Gaussian ﬁelds and har-
monic functions. In Proceedings of the Twentieth In-
ternational Conference on Machine Learning (ICML
2003), pages 912–919, Washington D.C., 2003.

[12] J. C. Platt. FastMap, MetricMap, and landmark MDS
are all nystr¨om algorithms. In Proceedings of the Tenth
International Workshop on Artiﬁcial Intelligence and
Statistics, Barbados, WI, January 2005.

[13] S. T. Roweis and L. K. Saul. Nonlinear dimension-
ality reduction by locally linear embedding. Science,
290:2323–2326, 2000.

[14] L. K. Saul and S. T. Roweis. Think globally, ﬁt lo-
cally: unsupervised learning of low dimensional man-
ifolds. Journal of Machine Learning Research, 4:119–
155, 2003.

[15] B. Sch¨olkopf, A. J. Smola, and K.-R. M¨uller. Nonlin-
ear component analysis as a kernel eigenvalue prob-
lem. Neural Computation, 10:1299–1319, 1998.

[16] A. J. Smola and R. Kondor. Kernels and regulariza-
tion on graphs. In Proceedings of the Sixteenth An-
nual Conference on Computational Learning Theory
and Kernel Workshop, Washington D.C., 2003.

388An Expectation Maximization Algorithm for Inferring Offset-Normal Shape

Distributions

Max Welling

School of Information and Computer Science

University of California Irvine
Irvine CA 92697-3425 USA

welling@ics.uci.edu

Abstract

The statistical theory of shape plays a promi-
nent role in applications such as object recogni-
tion and medical imaging. An important para-
meterized family of probability densities deﬁned
on the locations of landmark-points is given by
the offset-normal shape distributions introduced
in [7]. In this paper we present an EM algorithm
for learning the parameters of the offset-normal
shape distribution from shape data. To improve
model ﬂexibility we also provide an EM algo-
rithm to learn mixtures of offset-normal distribu-
tions. To deal with missing landmarks (e.g. due
to occlusions), we extend the algorithm to train
on incomplete data-sets. The algorithm is tested
on a number of real-world data sets and on some
artiﬁcially generated data. Experimentally, this
seems to be the ﬁrst algorithm for which estima-
tion of the full covariance matrix causes no difﬁ-
culties. In all experiments the estimated distrib-
ution provided an excellent approximation to the
true offset-normal shape distribution.

1 INTRODUCTION

The statistical analysis of shape has important applications
in ﬁelds as diverse as biology, anatomy, genetics, medicine,
archeology, geology, geography, agriculture, image analy-
sis, computer vision, pattern recognition and chemistry (see
e.g. [9]). As an important example, we can represent an ob-
ject (e.g. a face, skull, etc.) as a collection of landmarks at
certain positions (in ﬁgure space). To compare objects it
is then useful to discard differences in location, orientation
and scale. (i.e. their pose). The remaining degrees of free-
dom are called the shape of an object. For a meaningful
comparison of objects by their shape we need the tools of
“statistical shape analysis”. For instance, we may want to
know whether two objects are signiﬁcantly different (using
a hypothesis test), or we may be interested in classifying or

clustering objects by their shape. The statistical analysis of
shape has a long history dating back to the late seventies
[15, 10, 11, 12, 1, 2, 3, 4].

The work that we will present here is based on a more re-
cent development in statistical shape analysis, namely the
introduction of the offset-normal distribution [14, 7, 8, 9].
Offset-normal probability densities describe the distribu-
tion of shapes as represented by collections of landmark
points in two dimensions. The assumption is that the land-
marks in ﬁgure space are normally distributed. Pose is re-
moved by mapping two landmarks to ﬁxed positions (e.g.
(0, 0) and (1, 0)), while the remaining landmarks represent
the shape information. Perhaps surprisingly, this distribu-
tion over the remaining landmarks can be expressed in an-
alytic form [7]. However, a reliable method to infer the
distribution parameters from shape data in the most gen-
eral case (full covariance matrix), is not available. The fact
that certain singular normal distributions map to the same
offset-normal shape distribution has obstructed the formu-
lation of estimation procedures for general covariance ma-
trices.

In this paper we will derive EM update rules for unre-
stricted parameters of the offset-normal shape distribution,
i.e. a mean vector and a full covariance matrix. As it turns
out, both E- and M-step can be computed analytically, pro-
viding an efﬁcient update scheme. In pattern recognition, it
may happen that landmarks are occluded. To deal with this
difﬁculty which is often encountered in practical problems
we extend the EM procedure to learn from incomplete data.
For cases where the data are not well approximated by an
offset-normal shape distribution, we provide EM-learning
rules for mixtures of offset-normal shape distributions. We
conclude with experiments on some real world data-sets.

2 THE OFFSET-NORMAL SHAPE

DISTRIBUTION

In order to be self contained, we explain and re-derive the
offset-normal shape distribution in this section. Some re-
sults in later sections will follow a similar derivation.

389Let an object in two dimensions be represented by the
positions {xi, yi} of p landmarks. Let x be distributed
according to a 2p dimensional normal distribution, x ∼
N2p[ν, Ω].
We will ﬁrst remove translational content by applying the
following transformation,

x = [x1, ..., xp, y1, ..., yp]T → Lx

(cid:183)

with

L =

I − 1eT
1 + e1eT
0

1

0
I − 1eT
1 + e1eT

1

and integrate out the ﬁrst landmark. In this equation I and
0 are the p × p dimensional identity and zero matrices re-
spectively, 1 is a p×1 dimensional vector of ones and e1 is
the p×1 dimensional vector [1, 0, ..., 0]T . This transforma-
tion shifts all landmarks, except the ﬁrst one, by an amount
x1, y1. Notice that if we had also shifted the ﬁrst landmark,
it would be ﬁxed at the location (0, 0), producing a singu-
lar probability distribution. Since the above transformation
is linear, the coordinates Lx are also normally distributed
with mean µ = Lν and covariance Σ = LΩLT . Integrat-
ing out x1, y1 for a normal distribution is simply accom-
plished by deleting the corresponding entries in the mean
and covariance. The remaining coordinates are denoted by
p]T and have dimension 2p − 2.
x∗ = [x∗
Next, we remove rotation and scale content by following a
similar procedure. First, we transform x∗ as follows,

2, ..., x∗

2, ..., y∗

p, y∗

This transformation would have moved the second land-
mark to the location (1, 0), not allowing any spread and
generating a singular pdf. Therefore, we will leave the sec-
ond landmark untouched, while treating all the other ones
as if the second landmark were moved to the reference po-
sition (1, 0). Finally, to remove information on orientation
and scale we need to integrate out the second landmark,
which we will do in the following.

We will simplify notation for the second landmark by writ-
ing x∗
2 = h, while u = [u3, ...up, v3, ..., vp]T . In the coor-
dinates {h, u} the pdf is given by,

P (h, u) =

1
√
(2π)p−1

det Σ

exp[−1

2 G]| det J|,

with,

G = (Wh − µ)T Σ−1(Wh − µ),

det J = (h2

x + h2

y)p−2,

(4)

(5)
(6)

u2 = x∗
2,

v2 = y∗
2,

ui =

vi =

(x∗
i x∗
2 + y∗
x∗
2 + y∗
2 − x∗
(y∗
i x∗
x∗
2 + y∗

2

2

2

2

2

i y2)

2

i y2)

i = 3, ..., p

i = 3, ..., p (3)

(z2

x + z2

y)p−2 =

(cid:183)

where J is the Jacobian of the transformation (3) and

WT =

1
u3
0 −v3

···
up
··· −vp

0
v3
1 u3

···
···

vp
up

The integration over h is facilitated by rewriting G as,

G = (h − ξ)T Γ−1(h − ξ) + g

with

(cid:184)

(1)

(2)

Γ−1 = WT Σ−1W
ξ = ΓWT Σ−1µ
g = µT Σ−1µ − ξT Γ−1ξ

(cid:184)

.

(7)

(8)

(9)
(10)
(11)

(cid:114)

(cid:90)

We can simplify (4) further by transforming to the eigen-
basis of Γ,

Γ = RDRT ,
ζ = RT ξ

z = RT h.

(12)

Noticing that the determinant of the Jacobian is invariant
with respect to rotations, this gives,

2 g ×

1

(2π)p−2

det Γ
det Σ e− 1
P (z, u) =
× Nzx[ζx, σx] Nzy[ζy, σy] (z2
(cid:112)
x + z2

(cid:112)

σx =

Dxx

σy =

Dyy

y)p−2

(13)

(14)

where

Finally, we use the binomial expansion to rewrite the Jaco-
bian as,

(cid:182)

(cid:181)

p−2(cid:88)

i=0

p − 2

i

x z2p−4−2i
z2i

y

.

(15)

(cid:90)
(cid:114)

We are now ready to perform the integrations over h, re-
quired for the deﬁnition of the offset-normal shape distrib-
ution,

PS(u) =

dh p(h, u) =

dz p(z, u) =

2 g ×

(cid:182)
det Γ
det Σ e− 1
p − 2

i

1

(cid:181)

(2π)p−2

× p−2(cid:88)

i=0

where,

(16)

|ζy, σy]

E[z2i

x |ζx, σx] E[z2p−4−2i

y

(cid:33)k

(cid:195)√

2σ
2i

Hk( iµ√
2σ

),

(17)

E[zk|µ, σ] =

denotes a Gaussian expectation and Hk denotes the Her-
mite polynomial of order k. Equation (17) is the offset-
normal shape distribution [7], which is invariant with re-
spect to translations, rotations and scalings of the data. It is

390expressed in terms of the parameters µ and Σ which are not
invariant with respect to orientation and scale changes (the
translations were taken out in going from ν → µ, Ω → Σ).
It follows that the parameter set must be redundant, i.e. ori-
entation and scale transformations of the parameters map
to the same offset-normal shape distribution. Technically,
this implies that the offset-normal shape distribution is de-
scribed by an equivalence class of parameters. Therefore,
when we mention in the rest of this paper that some ran-
dom variable is distributed according to an offset-normal
shape distribution with parameters µ and Σ, we refer to
the equivalence class of all µ and Σ that map to the same
offset-normal shape distribution. Sometimes it will be use-
ful to remove this ambiguity by deﬁning a canonical para-
meter set,

µc = Kµ = [1, µ3x, ..., µpx, 0, µ3y, ..., µpy]T ,
Σc = KΣKT ,

(18)

where the mean of the second landmark has been mapped
to (1, 0). More study is required to see for which offset-
normal shape distributions the above transformation re-
moves all redundancies and which have a still larger set of
invariant transformations. It is important to notice the dif-
ference with the non-linear mapping (3). In contrast, (18)
is a linear transform, depending on µ2. In [7] it is observed
that also some singular normal pdfs or even non-normal
pdfs may map to the same offset-normal shape distribution,
enlarging further the redundancy. In this paper we will not
concern us with those.

Transformation Properties: We will now state two im-
portant properties of the offset-normal shape distribution,
which will help us derive the learning algorithm in the sub-
sequent sections.
Lemma 1 Let x = [x1, ..., xp, y1, ..., yp]T be a ran-
dom variable distributed according to a normal dis-
tribution with parameters ν and Ω, and let u =
[u3, ..., up, v3, ..., vp]T be the corresponding shape random
variable, distributed according to the offset-normal shape
distribution with parameters

p−1,

p, y(cid:48)

1, ..., y(cid:48)

µ = Lp−1ν,

Σ = Lp−1ΩLT

(19)
where Lp−1 is the matrix deﬁned in (2) with the 1st
and (p + 1)st row deleted. The random variable x(cid:48) =
[x(cid:48)
1, ..., x(cid:48)
p]T = G x, where G is a matrix of di-
mension 2p × 2p, will be distributed according to a 2p di-
mensional normal distribution with parameters ν(cid:48) = Gν
and Ω(cid:48) = GΩGT . The corresponding shape random vari-
ables u(cid:48) = [u(cid:48)
p]T will be distributed ac-
cording to an offset-normal shape distribution with para-
meters,
µ(cid:48) = Lp−1Gν,
The proof of this lemma is straightforward and relies on
some well known properties of normal pdfs [5]. It is ac-
tually not necessary to assume that G is a square matrix.

Σ(cid:48) = Lp−1GΩGT LT

3, ..., u(cid:48)

3, ..., v(cid:48)

p, v(cid:48)

p−1.

(20)

In general G can be of size 2g × 2p, where 2 < g ≤ p.
This is useful if we want to integrate out variables from the
offset-normal shape distribution [5].

x(cid:48)

π(p), y(cid:48)

Deﬁne the pair of baseline variables to be the ones which
are mapped to (0, 0) and (1, 0). By choosing G to be a
permutation matrix we can transform the offset-normal
shape distribution between any pair of baseline variables
in terms of the ﬁgure space parameters ν and Ω. But does
this still hold if we only have access to the parameters of
the offset-normal shape distribution (i.e.
the parameters
µ and Σ)? The following lemma answers this in the
afﬁrmative:
Let x = [x1, ..., xp, y1, ..., yp]T be a
Lemma 2
random variable distributed according to a nor-
mal distribution with parameters ν and Ω, and let
u = [u3, ..., up, v3, ..., vp]T be the corresponding shape
random variable, distributed according to the offset-
normal shape distribution with parameters µ and Σ.
=
Furthermore,
[x(cid:48)
π(1), ..., x(cid:48)
π(p)]T = Px be a per-
mutation of x, which is distributed according to a
normal distribution with parameters ν(cid:48) = P ν and
Ω(cid:48) = P Ω PT . Then,
the shape random variables
u(cid:48) = [u(cid:48)
π(p), v(cid:48)
π(p)]T are distributed
according to an offset-normal shape distribution with
parameters,
µ(cid:48) = Bµ,
B = Lp−1PE,
(21)
Here E is the 2p × 2p − 2 dimensional matrix, E =

let
π(1), ..., y(cid:48)

Σ(cid:48) = BΣBT

 . This matrix has the effect of inserting ze-


i.e. µ →
···
0
... Σxy
···
0
... Σyy

···
0
... Σxx
···
0
... Σyx

y ]T and, Σ →

ros at the position of the ﬁrst landmark,

 0

π(3), ..., u(cid:48)

π(3), ..., v(cid:48)

···
0
···
I



x , 0, µT

[0, µT

I
0
0

Proof of Lemma 2 To prove this it we need to show that
the following two transformations are equivalent:

Lp−1P = BLp−1

.= Lp−1PELp−1

(22)

We will multiply left and right with the identity as follows,
ET E = I

ET ELp−1P = ET ELp−1PELp−1

(23)
Next, we notice that we can rewrite the combination ELp−1
as,

ELp−1 = I − 1eT

(24)
i.e. it is the 2p × 2p dimensional matrix which translates
the ﬁrst landmark to the origin. Using this in eqn. 23 we
ﬁnd,

1

(cid:162)(cid:161)

(cid:162)

P − 1eT

1 P

P − 1eT

1 P

I − 1eT

1

(25)

ET(cid:161)

(cid:162)

= ET(cid:161)

3911 1eT

1 = 1eT

1 = 1eT

Writing this out and noting that P1eT
1 and
1eT
1 , we verify that the left hand side is in-
deed identical to the right hand side, which then proves the
lemma. (cid:164)
The relevance of this lemma is that we can compute
the offset-normal shape distribution for an arbitrary pair
of baseline landmarks from the offset-normal shape-
parameters of a given pair of baseline landmarks. This will
allow us to estimate the parameters of the shape distribu-
tion, even if the data are presented in different reference
frames; a situation which may occur if one of the baseline
landmarks is occluded.

In the case where we only interchange the second land-
mark with higher labelled landmarks, leaving the ﬁrst land-
mark in place, the lemma slightly simpliﬁes. In that case,
PE = EPp−1, where Pp−1 is 2p−2×2p−2 dimensional
permutation matrix. Therefore, using, Lp−1E = I, we may
write instead of (21),

µ(cid:48) = Pp−1µ,

Σ(cid:48) = Pp−1ΣPT

p−1,

(26)

3 EM LEARNING ALGORITHM

Our main objective is to ﬁnd parameters µ and Σ (or µc
and Σc) that maximize the log-likelihood of the offset-
normal shape distribution given a data-set {un}
n =
1...N. The log-likelihood is given by,

L(µ, Σ) =

1
N

log PS(un|µ, Σ).

(27)

N(cid:88)

n=1

(cid:90)

N(cid:88)

Although the analytic form of the offset-normal shape
distribution is quite complicated,
the joint distribution
P (h, u) is much simpler. Unfortunately, h is not observed
and may be considered a hidden variable for that reason.
This makes this estimation problem a school example of
the expectation maximization (EM) algorithm. In the EM
framework one iteratively optimizes the following family
of objective functions (depending on the iteration k),

1
N

n=1

Q(k|k − 1) =

dh Pk−1(h|un) log Pk(h, un),
(28)
where Q(k|k − 1) depends on the parameters µk and Σk
at iteration k, given the parameters µk−1 and Σk−1 at iter-
ation k − 1. Maximization of the log-likelihood is obtained
by alternating an M-step where Q is maximized with re-
spect to the parameters µk and Σk, and an E-step where
the posterior distribution p(h|un) is determined, given the
new parameters calculated in the previous M-step.

M-step:
In the M-step we need to maximize
(cid:104)log P (h, un)(cid:105)n with respect to µk and Σk. Here (cid:104).(cid:105)n de-
notes a posterior average, (cid:104)f(h)(cid:105)n =
dh P (h|un)f(h).

(cid:82)

The derivatives are given by,

N(cid:88)

n=1

∂
∂µk
∂

Q(k|k − 1) =

1
N
Q(k|k − 1) =

k (Wn(cid:104)h(cid:105)n − µk)
Σ−1

(29)

(30)

(Σk − Wn(cid:104)hhT(cid:105)nWT

n + 2Wn(cid:104)h(cid:105)nµT

k − µkµT
k )

N(cid:88)

∂Σ−1
1
2

k
1
N

n=1

resulting in the following simple update rules:

N(cid:88)
N(cid:88)

n=1

n=1

µk =

Σk =

1
N

1
N

Wn(cid:104)h(cid:105)n

Wn(cid:104)hhT(cid:105)nWT

n − µkµT

k

(31)

(32)

After every M-step we also map the parameters µ and Σ
to the canonical parameters µc and Σc, deﬁned in (18),
to avoid drifting. Because the offset-normal shape distri-
bution is invariant with respect to this transformation, the
log-likelihood will not change either.

E-step:
In the E-step we need to calculate the mean
(cid:104)h(cid:105)n and covariance (cid:104)hhT(cid:105)n of the posterior distribution
P (h|un). Using Bayes rule it is easily found that,

P (h|un) = P (h, un)
PS(un) ,

(33)

where PS(un) is simply the offset-normal shape distribu-
tion evaluated at un. Calculation of the sufﬁcient statistics
thus involves the following integrals,

(cid:104)h(cid:105)n =
(cid:104)hhT(cid:105)n =

1

PS(un)

1

PS(un)

dh h P (h, un)

(34)

dh hhT P (h, un)

(35)

(cid:90)
(cid:90)

These integrals can be solved following the same strategy
as the one used to calculate the offset-normal shape dis-
tribution in section 2. Again, we will transform to the z
coordinates deﬁned in (12) and notice that,

(cid:104)h(cid:105)n = Rn(cid:104)z(cid:105)n,

(cid:104)hhT(cid:105)n = Rn(cid:104)zzT(cid:105)nRT
n .

(36)
(37)

Using the binomial expansion (15) and the result (17) we
can calculate the following posterior averages,

(cid:181)
(cid:80)p−2
(cid:80)p−2

i=0

j=0

(cid:182)

(cid:182)

p − 2

(cid:181)

i
p − 2

j

(cid:104)za
xzb

y(cid:105)n =

En[z2i+a

x

y

] En[z2p−4−2i+b
x ] En[z2p−4−2j

]

y

]

En[z2j

(38)

392(38)

=
Using
(1, 0), (0, 1), (2, 0), (1, 1), (0, 2)} allows us to perform the
E-step.

pairs

the

for

{(a, b)

Initialization: To initialize the parameters we use the
approximation described in [7].
If the variances of
the landmarks are small compared to the mean length
of the baseline,
then the offset-normal shape distribu-
tion becomes similar to a normal distribution with mean
λ = [µc3x, ..., µcpx, µc3y, ..., µcpy]T and covariance Λ =
FΣcFT , where µc and Σc are are the canonical parameters
and F is the 2p − 4 × 2p − 2 dimensional matrix,

 λ1

...

F =

I

γ1
...

λ2p−4 0 γ2p−4



0

I

γ = [µ3y, ..., µpy,−µ3x, ...,−µpx]T

(39)

(cid:80)N

(cid:80)N
To initialize our algorithm we therefore calculate the
sample mean and covariance of the shape data, λ =
n=1(un − λ)(un − λ)T .
1
N
The initial values of the mean µ and Σ are then given by,

n=1 un and Λ = 1
N−1

µ = [1, λx, 0, λy]
Σ = F+ΛFT
+,

F+ = FT (FFT )−1

(40)
(41)

where F+ is the pseudo-inverse of F.

4 MIXTURE DISTRIBUTIONS

In practice it might happen that the data in ﬁgure-space are
not well described by a normal distribution. In that case,
we may approximate it by a mixture of Gaussians. The
corresponding distribution in shape-space turns out to be a
mixture of offset-normal shape distributions according to
the following lemma [5]
Lemma 3 Under a multivariate normal mixture model for
the ﬁgure-space coordinates,

PMoG(x) =

N2p[x|µa, Σa] πa,

(42)

the joint probability distribution function of the shape vec-
tor u is a mixture of offset-normal shape distributions,

PMoS(u) =

PS[u|µa, Σa] πa

(43)

The proof is simple if one realizes that every mixture com-
ponent is mapped to an offset-normal shape distribution,
which are then combined using the a priori probabilities
πa. To ﬁnd update rules for the parameters πa, µa and Σa
we start with the log-likelihood,

M(cid:88)

a=1

M(cid:88)

a=1

(cid:90)

We will consider the labels a and the variables h hidden.
The function to be iteratively maximized is therefore given
by,
Q(k|k − 1) =
1
N

dh Pk−1(a, h|un) log{Pk(h, un|a) πa

(45)
k} =

(cid:90)

N(cid:88)
N(cid:88)

n=1

M(cid:88)
M(cid:88)

a=1

a=1

n=1

Pk−1(a|un)

1
dh Pk−1(h|un, a) ×
N
k},
× {log Pk(un, h|a) + log πa
where we used, P (h, a|u) = P (a|u) P (h|u, a). The M-
step involves again maximizing this expression at every it-
eration with respect to πa
k. Taking derivatives
with respect to these variables and equating them to zero
we ﬁnd,

k and Σa

k, µa

n=1

1
N

Pk−1(a|un),

N(cid:88)
(cid:80)N
(cid:80)N
n=1 Pk−1(a|un) Wn(cid:104)h(cid:105)a
(cid:80)N
,
m=1 Pk−1(a|um)
(cid:80)N
n=1 Pk−1(a|un) Wn(cid:104)hhT(cid:105)a
m=1 Pk−1(a|um)
(cid:90)

n

(cid:104)f(h)(cid:105)a

n =

dh P (h|un, a)f(h).

nWT
n

(46)

(47)

− µa

kµaT
k ,

(48)

(49)

k =
πa

µa

k =

Σa

k =

where we have deﬁned,

(cid:80)N

k is weighted by a factor

These update rules are very similar to (31) and (32). In the
mixture case however, the inﬂuence of every data point on
k and Σa
µa
which
expresses the probability that mixture component P (un|a)
is responsible for the generation of datum un.
The E-step involves the calculation of P (a|un), (cid:104)h(cid:105)a
(cid:104)hhT(cid:105)a

n. P (a|un) is simply given by,

Pk−1(a|un)
m=1 Pk−1(a|um)

n and

P (a|un) =

(cid:80)M
PS(un|a) πa
b=1 PS(un|b) πb

,

(50)

n and (cid:104)hhT(cid:105)a

where PS(un|a) is an offset-normal shape distribution with
parameters µa and Σa. According to (49), the calculation
of (cid:104)h(cid:105)a
n is identical to those described in sec-
tion 3, where we use parameters µa and Σa for µ and Σ.
We thus see that the learning rules for a mixture of offset-
normal shape distributions are straightforward generaliza-
tions of the one component learning rules.

5 INCOMPLETE DATA

N(cid:88)

M(cid:88)

L =

1
N

log

n=1

a=1

PS(un|a; µa, Σa) πa.

(44)

In practice, it may happen that landmarks are occluded and
only incomplete data are provided. First, we will assume

393that the missing information does not concern the baseline
points (i.e. landmarks 1 and 2). This will be generalized to
arbitrary missing landmarks later in this section.

Assume that we have N, possibly incomplete samples,
{un}, n = 1...N. For every sample we deﬁne an index
m denoting the missing dimensions, and an index o denot-
ing the observed dimensions. We will always assume that
both the x and the y component of a landmark are missing,
implying that m and o are necessarily even dimensional.
n]T (the dependence of m and o
We thus have un = [um
on n is omitted for notational convenience). The question
we want to answer is; Can we use the information of in-
complete data-vectors in the estimation of the parameters
of the offset-normal shape distribution ? To answer this,
we ﬁrst write the log-likelihood,

n , uo

L(µ, Σ) =

1
N

log PS(uo

n|µ, Σ),

(51)

N(cid:88)

n=1

which now only depends on the observed data. This im-
plies that we may treat the missing dimensions as hid-
den variables, alongside the variable x∗
2. Thus, for every
n, we have a different set of hidden variables, denoted
by hn = [x∗
In fact, it turns out to be more
convenient to represent the unobserved landmarks in ﬁg-
ure space, so that the set of missing variables becomes
n ]. The auxiliary functions Q(k|k − 1)
hn = [x∗
N(cid:88)
in terms of the above variables are given by,

2,n, x∗m

n ].
2,n, um

(cid:90)

dh Pk−1(h|uo

n) log Pk(h, uo

n).

Q(k|k − 1) =

1
N

n=1

(52)
The formula for P (h, uo) is very similar to (4) with 2 im-
portant differences. Firstly, since more variables are de-
ﬁned in ﬁgure space, the Jacobian of the transformation is
slightly different,

| det J| = (x∗

2 + y∗

2)p−2−q,

2

(53)
where q denotes the number of missing landmarks (which
may be different for each data case n). Assuming for a mo-
ment that the missing dimensions have the lowest indices
(i.e. m = 3, 4, . . .), we deﬁne,

2

1
0

WT =

0
0

...

...

0
1

0
0

0
0

0
0

···
···

uq+1
0

···
···

up
0

··· −vq+1
···
0

··· −vp
···
0

···
···

···
···

vq+1
0

uq+1
0

···
···

···
···

···
···

···
···

0
0

0
0

(54)

0
0

0
1



0
0

...

1
0

...

vp
0

...
up
0

...

(cid:90)

To generalize this to arbitrary missing dimensions we sim-
ply need to permute the columns of WT .

The M-step of the EM algorithm proceeds exactly as ex-
plained in section (3), where averages are now taken w.r.t.
the posterior distribution P (h|uo
n). Evaluating these av-
erages, which is part of the E-step, proceeds analogously
as in section (3). Using equations (34) and (35) we note
that the difﬁcult part of that calculation is computing the
following expectations,

1+h2

dh f(h)P (h, uo) = C E[f(h) (h2

q+1)2−p+q| ξ, Γ],
(55)
where E[. | ξ, Γ] denotes taking the average over a mul-
tivariate normal pdf with mean ξ and covariance Γ and
f(h) = h or f(h) = hhT . Unfortunately, the transfor-
mation in eqn. (12) will not leave the Jacobian invariant,
since

1 + h2
h2

q+1 = hT Ωh

(56)
is not invariant with respect to h → z = RT h. However,
if we transform,

1 + eq+1eT

Ω = e1eT

q+1

Γ = RDRT .= FFT
ζ = = F−1ξ = UD− 1
z = F−1h

2 RT ξ

(57)
then the normal distribution transforms to, Nh[ξ, Γ] →
Nz[ζ, I] while we can still choose the orthonormal matrix
U such that the Jacobian remains as simple as possible,

hT Ωh = zT FT ΩFz = zT Λz

(58)

The matrix Λ can be chosen diagonal by using the follow-
ing eigenvalue decomposition, FT ΩF = VHVT which is
always possible because FT ΩF is a symmetric rank-2 ma-
trix. Thus, by choosing Λ = H and U = VT we obtain
the desired result. We now need to expand the Jacobian in
a binomial series expansion and use eqns. (34) and (35) to
arrive at an expression for the desired averages similar to
eqn. (38).

Alternatively, a good approximation can be obtained by
sampling from the normal distribution N [h | ξ, Γ] and sub-
sequent calculation of the sample average.

Missing Baseline Landmarks: Next, we treat the case
where one or both of the baseline landmarks is missing
from the data. For such a data case, the locations of the
other landmarks should be represented in a different ref-
erence frame, i.e. using a different (observed) baseline
pair. In that frame, the situation reduces to the case treated
above. It remains to be understood how to incorporate data
in different reference frames in the estimation process. We
will ﬁrst choose one, arbitrary, baseline pair and invoke
lemma 2 (section 2) to write the distribution in any other

394frame as,

PS(u(cid:48)| µ(cid:48), Σ(cid:48)) = PS(u(cid:48)|Bµ, BΣBT ),

(59)

where B = Lp−1PE and Lp−1, P and E are deﬁned in
section 2. Since every data point may be deﬁned in a dif-
ferent reference frame, B depends on n. Taking derivatives
with respect to µ and Σ in the M-step then generates the
following update rules,

n Wn(cid:104)h(cid:105)n
B−1

(60)

n Wn(cid:104)hhT(cid:105)nWT
B−1

n B−T

n − µkµT
k ,

N(cid:88)
N(cid:88)

n=1

µk =

Σk =

1
N

1
N

n=1

(61)
where Wn and (cid:104).(cid:105)n are deﬁned in their own reference
frame.

In the E-step we compute the posterior mean and covari-
ance as usual, using parameters µ(cid:48)
n =
BnΣBT

n = Bnµ and Σ(cid:48)

n for data case n.

6 EXPERIMENTS

To test the algorithm on real world data, we downloaded
5 data-sets from the web 1. Some data-sets contain data
directly in shape space, while others have data in ﬁgure
space, which we converted to shape space by mapping two
landmarks to locations (0, 0) and (1, 0) respectively. Be-
fore transforming to shape space we extracted the sample
mean and covariance to establish ‘ground truth’, since these
are the parameters which describe the offset-normal shape
distribution. Note however that many different normal dis-
tributions map to the same offset-normal shape distribution,
so that comparing the parameters directly is not very mean-
ingful.

Figure 1 shows the results when the sample mean and
covariance were available in ﬁgure space. The data-sets
used in Figure 1 are “Brizalina”, ‘Globorotalia’ (described
in [4]) and ‘Mouse vertebrae’ (Small group) (described
in [9]). Figure 2 shows the results on the datasets ‘Go-
rilla skulls’ (female) (described in [9]) and ‘Rat calvar-
ial growth’ (studied in [4]). These data-sets are deﬁned
in shape space, which implies that we have no access to
ground truth. Finally, in ﬁgure 3, we present an example
where we artiﬁcially generated 100 samples from a ‘chal-
lenging’ offset-normal shape distribution.

The algorithm usually converges within 20 iterations. No-
tice however, that for every data-point a SVD needs to

1The data-sets can be found at:

http://www.amsta.leeds.ac.uk/˜iand/Shape-S/datasets.html
http://life.bio.sunysb.edu/morph/index.html

Figure 1: Estimation of offset-normal shape distributions for the
following data-sets provided in ﬁgure space (from top to bottom):
“Brizalina”, “Globorotalia” and “Mouse vertebrae (small group)”.
The ﬁrst column depicts the data overlaid with the offset-normal
distributions estimated in shape space, while the second column
shows the offset-normal distributions estimated in ﬁgure space.

be computed, resulting in unfavorable scaling behavior for
large amounts of data.

We have encountered no problems in the estimation of the
full covariance matrix, as described in [7], [9]. Also, few
data are needed to ﬁnd a reliable estimate of the distribution
(around 20).

7 DISCUSSION

In this paper we have shown how to infer the parameters
of a full covariance offset-normal shape distribution using
the expectation maximization algorithm. In addition, we
have addressed to important issues which open the door
to practical applications. Firstly, the data may not be well
described by an offset-normal shape distribution and sec-
ondly, the data may be incomplete, e.g. due to occlusion.
The ﬁrst problem was addressed by providing a learning

−0.500.511.52−1.5−1−0.500.5Data and estimated DM density in shape space−0.500.511.52−1.5−1−0.500.5Multivariate DM density in shape space00.20.40.60.811.21.4−1.4−1.2−1−0.8−0.6−0.4−0.200.2Data and estimated DM density in shape space00.20.40.60.811.21.4−1.4−1.2−1−0.8−0.6−0.4−0.200.2Multivariate DM density in shape space00.20.40.60.811.21.4−0.4−0.200.20.40.60.8Data and estimated DM density in shape space00.20.40.60.811.21.4−0.4−0.200.20.40.60.8Multivariate DM density in shape space395ACKNOWLEDGEMENTS

We thank CNSE and the sloan foundation for ﬁnancial sup-
port. We are also grateful for discussions with Pietro Per-
ona, Mike Burl and Markus Weber.

References

[1] F.L. Bookstein. Lecture Notes on Biomathematics, Vol. 24.

Springer Verlag, 1978.

[2] F.L. Bookstein. A statistical method for biological shape

comparison. J. Theor. Biol., 107:475–520, 1984.

[3] F.L. Bookstein. Size and shape spaces for landmark data in

two dimensions. Statistical Science, 1(2):181–242, 1986.

[4] F.L. Bookstein. Morphometric tools for landmark data.

Cambridge University Press, 1991.

[5] M.C. Burl. Recognition of visual object classes. PhD thesis,
Department of Electrical Engineering, California Institute of
Technology, Pasadena, CA, 1997.

[6] M.C. Burl, T.K. Leung, and P. Perona. “Face Localization
via Shape Statistics”. In Int Workshop on Automatic Face
and Gesture Recognition, 1995.

[7] I.L. Dryden and K.V. Mardia. General shape distributions in
a plane. Advanced Applied Probability, 23:259–276, 1991.

[8] I.L. Dryden and K.V. Mardia. Size and shape analysis of

landmark data. Biometrika, 79:57–68, 1992.

[9] I.L. Dryden and K.V. Mardia. Statistical shape analysis.

Wiley, 1998.

[10] D.G. Kendall. The diffusion of shape. Advances Applied

Probability, 9:428–430, 1977.

[11] D.G. Kendall. Shape manifolds, procrustean metrics, and
complex projective spaces. Bull. London Math Soc., 16:81–
121, 1984.

[12] D.G. Kendall. A survey of the statistical theory of shape.

Statistical Science, 4(2):87–120, 1989.

[13] T.K. leung, M.C. Burl, and P. Perona. Probabilistic afﬁne
invariants for recognition. In Proceedings of the Conference
on Computer Vision and Pattern Recognition, 1998.

[14] K.V. Mardia and I.L. Dryden. Shape distributions for land-

mark data. Adv. Appl. Prob., 21:742–755, 1989.

[15] H. Ziezold. On expected ﬁgures and a strong law of large
numbers for random elements in quasi-metric spaces.
In
Trans. 7th Praque Conf. Information Theory, Statistical De-
cision Functions, Random Processses and of the 1974 Eu-
ropean Meeting of Statisticians, volume A, pages 591–602,
Prague, 2000.

Figure 2: Estimation of offset-normal shape distributions for the
following data-sets provided in shape space (left to right): “Go-
rilla Skulls (female)” and “Rat calvarial growth” (small group).
These data-sets are only provided in shape-space, so no ﬁgure
space estimates are available.

Figure 3: As in ﬁgure 1 with artiﬁcially generated data.

algorithm for mixtures of offset-normal shape distributions
which improves model ﬂexibility. The second issue was
addressed by showing how to incorporate incomplete data
into the estimation process.

We think the presented learning algorithms could ﬁnd im-
portant applications in the ﬁeld of object (class) and pattern
recognition. In [6] a face recognition system was proposed
where the geometry of certain feature detectors (e.g. eye-
corner, nose) was described by the offset-normal shape dis-
tribution. This model also accounts for uncertainties in the
labelling and the positions of the landmarks. The parame-
ters of that model were determined in ﬁgure space. This
was possible only because the data were acquired under
carefully controlled circumstances. In more realistic situ-
ations, we want to learn the model using (possibly incom-
plete) shape data, which is precisely the topic of the present
paper.

An important generalization of the offset-normal shape dis-
tribution is the afﬁne invariant shape distribution proposed
in [13]. There, a third landmark is mapped to a ﬁxed posi-
tion (e.g. (x, y) = (0, 1)), rendering the resulting distribu-
tion invariant with respect to afﬁne transformations. The
presented EM algorithm is easily extended to cover that
case as well, which will be described in a future publica-
tion.

−2−101234567−3.5−3−2.5−2−1.5−1−0.500.5Data and estimated DM density in shape space−1−0.500.511.5200.511.5Data and estimated DM density in shape space−1.5−1−0.500.51−1.5−1−0.500.511.5Data and estimated DM density in shape space−1.5−1−0.500.51−1.5−1−0.500.511.5Multivariate DM density in shape space396Learning in Markov Random Fields with Contrastive Free Energies

Max Welling

School of Information and Computer Science

University of California Irvine
Irvine CA 92697-3425 USA

welling@ics.uci.edu

Charles Sutton

Department of Computer Science

University of Massachusetts

Amherst, MA 01002

casutton@cs.umass.edu

Abstract

Learning Markov random ﬁeld (MRF) models is
notoriously hard due to the presence of a global
normalization factor. In this paper we present a
new framework for learning MRF models based
on the contrastive free energy (CF) objective
function. In this scheme the parameters are up-
dated in an attempt to match the average sta-
tistics of the data distribution and a distribution
which is (partially or approximately) “relaxed” to
the equilibrium distribution. We show that max-
imum likelihood, mean ﬁeld, contrastive diver-
gence and pseudo-likelihood objectives can be
understood in this paradigm. Moreover, we pro-
pose and study a new learning algorithm: the “k-
step Kikuchi/Bethe approximation”. This algo-
rithm is then tested on a conditional random ﬁeld
model with “skip-chain” edges to model long
range interactions in text data. It is demonstrated
that with no loss in accuracy, the training time
is brought down on average from 19 hours (BP
based learning) to 83 minutes, an order of mag-
nitude improvement.

1 INTRODUCTION: LEARNING MRFs

In the context of machine learning two classes of graphical
model have been extensively studied: the directed graph-
ical model or Bayesian network (BN) and the undirected
graphical model or Markov random ﬁeld (MRF). While
both models have been applied successfully in a num-
ber of domains, it is fair to say that learning in BNs has
reached a more advanced level of sophistication than learn-
ing in MRFs. For instance, hidden variable models can
be efﬁciently tackled with the variational EM algorithm1,
Bayesian inference is often feasible with conjugate pri-
ors and greedy structure learning algorithms have met with

1Fully observed BNs are trivial and only depend on counts.

some success as well. In contrast, even for a fully observed
MRF model, evaluating the gradient of the log-likelihood
is typically intractable. The problem can be traced back
to the presence of a global normalization term which de-
pends on the parameters and which translates into an often
intractable inference problem when we compute its gra-
dient2. Clearly, introducing unobserved random variables
only aggravates this problem, while Bayesian approaches
to infer posterior distributions over parameters or structures
seem completely absent in the literature, apart from one pa-
per [9]. Because MRF models arise in many applications,
including spatial statistics, computer vision, and natural-
language processing, we feel that it is important to improve
this state of affairs.

We claim that learning MRFs is so difﬁcult because the
inference problem induced by the global normalizer is of
a different nature and often harder than the problem of
computing the posterior distribution of the hidden variables
given the observed variables needed for learning BNs. The
reason is that in the latter case we enter evidence to the
model and we may have reasonable hope that the posterior
is peaked around a single solution. However, for MRFs we
need to infer the distribution when all variables are uncon-
strained implying that the distribution we are trying to infer
is likely to have many modes. Even though much progress
has been in the ﬁeld of approximate inference, no method
can satisfactorily deal with a large number of modes for
which the location is unknown.

To approximate the required averages over the uncon-
strained (model) distribution we could for instance run a
MCMC sampler or use the mean ﬁeld approximation [10].
While the ﬁrst method is relatively slow (we need to sam-
ple for every iteration of gradient descent), the estimated
statistics can also get swamped by the sampling variance3.

2In case the structure of the graph is such we can identify a
junction tree with small tree-width, then inference can be per-
formed tractably and we can compute exact learning rules.

3Of course, one can reduce the variance by using more sam-
ples, but note that this only improves as 1/N where N is the num-
ber of samples.

397The mean ﬁeld approximation is not plagued by variance,
but unlike the MCMC sampler it has to tolerate a certain
bias in its estimates. However, both problems suffer from a
much more severe problem, namely that they will only ap-
proximate one mode of the distribution. One could argue
that a “good sampler” should mix between modes, but in
the absence of any information about the location of these
modes, this is an unrealistic hope, certainly in high dimen-
sions.

There is one piece of information which typically remains
unexploited, namely the fact that data points are expected
to be located close to a mode (or at least this is what we
like to achieve during learning). Hence, one idea to deal
with the above mentioned “many modes” problem, is to run
multiple MCMC chains, each one initialized at a different
data-point. With this method, we are at least certain that
all the modes close to data points are explored by samples.
This will have the effect that learning is likely to get the
local shape of each local mode correct. Still, there are (at
least) two drawbacks: 1) the modes do not communicate,
i.e. we have no mixing between modes and 2) accidental
modes which are created because of the particular parame-
terization of the model remain undetected by samples im-
plying there is no force to remove them from the model.
The ﬁrst problem has the undesirable effect that although
the shape of each mode may be a good ﬁt, the relative vol-
ume (or free energy) of the modes may not be properly esti-
mated. This was studied in [7] and mode-jumping MCMC
procedures were proposed to improve the communication
between modes. Since there is no information about the
location of the spurious modes (mentioned under 2), we
predict it will be extremely hard to deal with the second
problem.

Running Markov chains to convergence at every data case
at every iteration of learning is clearly a costly business.
Fortunately, it turns out that we can greatly improve our ef-
ﬁciency by running these Markov chains for only a few (say
k) steps4. It turns out that if one uses these pseudo-samples,
or rather “k-step reconstructions” of the data, we approxi-
mately minimize the so-called ”contrastive divergence” ob-
jective function [5]. Apart from a very signiﬁcant increase
in efﬁciency, we also decrease the variance of our estimates
at the expense of an increased bias.

The aim of the current paper is to combine deterministic,
variational approximations with the ideas of contrastive di-
vergence. This idea is analogous to the introduction of
mean ﬁeld learning in MRFs in [10]. A mean ﬁeld based
approach to contrastive divergence was presented in [17].
In the current work we extend these ideas to general vari-
ational approximations. In particular we study the Bethe
approximation, which in combination with the convergent
“belief optimization” algorithm to minimize the Bethe free

4It is essential that the chains are started at the data-cases.

energy results in a novel algorithm to train Markov ran-
dom ﬁelds with loopy structure. This algorithm is tested on
a conditional random ﬁeld model with long range interac-
tions (the so called “skip-chain” CRFs [11]) to label tokens
in email messages. We demonstrate that we can speed up
learning tenfold at no cost to the test-performance of the
trained model.

2 MAXIMUM LIKELIHOOD LEARNING

An intuitive way to restate the maximum likelihood ob-
jective is as a minimization problem of the following
Kullback-Leibler divergence between the data distribution
P0(y) and the model distribution Pλ(y),

λM L = arg min
λ

KL [P0(y)||Pλ(y)]

(1)

We will consider the general case here, where apart from
the observed variables, y, the model may also contain
a number of unobserved variables h.
Introducing the
joint distribution Pλ(y, h) and the distribution P0(y, h) =
Pλ(h|y)P0(y) = Pλ(h, y)P0(y)/Pλ(y) with Pλ(y) =
h Pλ(y, h), we can rewrite the KL divergence as a dif-

(cid:80)

ference between two free energies,

KL[P0(y)||Pλ(y)] = KL[P0(y, h)||Pλ(y, h)]
= F0 − F∞ .= CF∞ ≥ 0

(2)

where F0 denotes the free energy of the distribution
P0(y, h), while F∞ = − log(Z) denotes the free energy
of the “random system” governed by Pλ. The subscript ∞
indicates that we have to run a Markov chain inﬁnitely long
to reach equilibrium. For every data-case we can therefore
identify two random systems; one system with free energy
F0 has a data case clamped to the observed random vari-
ables while the hidden variables are free to ﬂuctuate. In
the “free system” (with free energy F∞) all random vari-
ables (y, h) are unconstrained. The energy of the system,
E(y, h), is deﬁned through the Boltzman distribution,

P (y, h) =

exp [−E(y, h)] .

1
Z

(3)

Although our discussion is more general, we will restrict
ourselves from now on to exponential family distributions
deﬁned through the following energy function,

(cid:88)

(cid:88)

E(y, h) = −

λiβfiβ(yβ, hβ).

(4)

β

i

In analogy to physical systems, we can decompose the free
energy in an average energy term and a entropy term,

F0 = E[E]0 − H0

F∞ = E[E]∞ − H∞ (5)
where E[·]0 denotes averaging with respect to the joint
P0(y, h) and E[·]∞ denotes averaging with respect to the
equilibrium distribution Pλ(v, h).

398Learning can now be understood as follows: for each data
case we ﬁrst compute the free energy F0 of the system with
the datum clamped to the observed units (this involves in-
ference over the hidden units). Then we set the constraints
on the observed variables free and let the system relax into
a new distribution Pλ(y, h) with lower free energy F∞.
If in this process the expected sufﬁcient statistics E[fiβ]
change we have an imperfect model and we change the
parameters λiβ in such a way that the expected sufﬁcient
statistics are better preserved in the next iteration,

∂CF∞
∂λiβ

= −E[fiβ(yβ, hβ)]P0 + E[fiβ(yβ, hβ)]Pλ

(6)

Note that this does not mean that the statistics for each data
point must cancel with the equilibrium statistics; this prop-
erty must only hold when averaged over all data cases.

3 APPROXIMATE ML-LEARNING

In the previous section, we wrote the likelihood function
as a difference of two free energies, one of which was in-
tractable to compute in general. In this section, we replace
those free energies with approximate free energies, in a way
conceptually similar to the mean ﬁeld approximation intro-
duced in [10]. The idea is to replace the objective in Eqn.2
with

0 − F APP∞

.= CFAPP∞ ≥ 0

KL[Q0(y, h)||Pλ(y, h)] − KL[Q∞(y, h)||Pλ(y, h)]
= F APP
(7)
where we deﬁne Q0(y, h) = Q(h|y)P0(y) and where
both Q0(h|y) and Q(y, h) are approximate, variational
distributions such as fully factorized mean ﬁeld distribu-
tions or tree structured distributions. Typically they de-
pend on a number of variational parameters that need to
be computed by separately minimizing the respective KL-
divergence terms in Eqn.7. The most important simpliﬁca-
tion that is achieved by minimizing CFAPP is the fact that
the log-partition function term, log Z, cancels between the
two terms in Eqn.7.

An important constraint that must be satisﬁed by any con-
trastive free energy is that F0 ≥ F∞ or equivalently
CF ≥ 0. The reason is that we like to change the un-
constrained system with F∞ so that on average it is similar
to the constrained system with F0. This would ensure that
if we sample from Pλ the samples would be similar to the
data-cases. Since both systems have the same energy func-
tion, but an unconstrained system has more entropy its free
energy should be lower as well (see Eqn.5). Moreover, the
cost function F0 − F∞ wouldn’t be lower bounded if F∞
was allowed to become arbitrarily large.

As an example, let’s choose the mean ﬁeld approximation
for Q0(h|y) and Q∞(h, y) in Eqn.7 above,
Q0(h|y) =
Q∞(y, h) =

qi(hi|y)

rj(zj) (8)

(cid:89)

(cid:89)

i

j

(cid:80)

(cid:80)

zj

hi

q(hi|y) = 1 ∀i and

with z = {y, h} and where both q and r are variational pa-
r(zj) =
rameters satisfying
1 ∀j. They are computed by minimizing their respective
KL-divergence terms in Eqn.7. It is now easy to see that
F∞ is smaller than F0, simply because it has more degrees
of freedom to minimize over (in F0 the variables y are con-
strained). It is convenient to imagine a process where we
minimize F∞ in two phases, ﬁrst we clamp y to a data-case
and minimize over h, then we set the y variables free and
continue the minimization over (y, h) jointly5. Once we
have found the variational parameters (q, r), we can update
the parameters using the following gradient,

∂CFAPP∞
∂λiβ

= −E[fiβ(yβ, hβ)]Q0 + E[fiβ(yβ, hβ)]Q∞ (9)

We only need to have access to (approximate) marginal
distributions pβ(yβ, hβ) in order to compute the expecta-
tions in Eqn.9. Hence, we are allowed to consider gen-
eral approximate free energies F0, F∞ as functions of local
marginal distributions only, as long as we can assert that
F0 ≥ F∞. An important example of this is the family of
Kikuchi free energies F KIK({qα}), where the approximate
marginals need not be consistent with a global distribution
Q. In other words, there may not exist a global distribution
Q such that its marginals over clusters of nodes are given
by the qα which minimize F KIK.
The contrastive Kikuchi free energy can be expressed as a
sum over constrained local KL-divergences as follows,

CFKIK∞

.= F KIK

0 − F KIK∞ =

cαKL[p0(yα)qα(hα|yα)||pα(yα, hα)] −
cαKL[rα(yα, hα)||pα(yα, hα)]

(10)

(cid:88)
(cid:88)

α

α

(cid:81)

(cid:88)

zα\zβ

β⊂α Ψβ(xβ), and where the set of
where pα(zα) = 1
clusters {α} consists of a number of overlapping large clus-
Zα
ters which cover the graph such that any interaction Ψβ
ﬁts in one of these clusters. By p0(yα) we mean the mar-
ginal data distribution over the variables6 y in cluster α.
Since this distribution is ﬁxed, we only minimize over the
qα variables in the ﬁrst term. The counting numbers cα
make sure that every variable and interaction is effectively
counted once. Unlike the mean ﬁeld approximation, the
marginals are overlapping and are required to satisfy cer-
tain “marginalization constraints” on the intersections,

rα(zα) = rβ(zβ)

(11)

and similarly for q. We refer to [19] for more details.

5In fact, the mean ﬁeld equations, when run sequentially (one

variable at a time), are a form of coordinate descent.

6Note that if we write (yα, hα) we mean all the variables y

and h which reside in cluster α.

399In the following we will be working with clusters consist-
ing of edges and nodes only, called the “Bethe approxima-
tion”, but we like to emphasize that the formalism is easily
adapted to general Kikuchi approximations, or in fact re-
gion graph approximations [19]. The counting numbers in
this case are given by,

cedge = 1,

cnode = 1 − #neighbors

(12)

The approximate learning procedure is again similar to
what we have seen before: ﬁrst we compute the varia-
tional parameters (qα, rα) by minimizing the respective
KL-divergence terms, and subsequently we update the pa-
rameters using the following gradients,

∂CFBETHE∞

∂λiβ

= −E[fiβ(yβ, hβ)]qαp0 + E[fiβ(yβ, hβ)]rα
(13)

0

and F BETHE∞

where we need that β ⊆ α.
When the free energies F BETHE
are convex in
the variational parameters (q, r), we can use a class of al-
gorithms under the name (generalized) belief propagation
to minimize the Bethe free energies (or KL-divergences) in
Eqn.10. However, the Bethe free energy is only convex un-
der very special circumstances, e.g. when the graph has at
most one loop. In general it is littered with local minima
and for reasons explained before it does not deserve rec-
ommendation to run BP and end up in some random local
minimum.
Instead, we would like to initialize our mini-
mization procedures on the data-cases. However, it is not
clear how to efﬁciently ﬁnd a set of messages that will pro-
duce a prescribed set of marginals, implying that we have
little control over our initialization. Fortunately, algorithms
have been developed that do not rely on messages but di-
rectly minimize the Bethe free energy as a function of the
marginals [14, 20, 4]. In general, these algorithms itera-
tively construct a convex upper bound on the Bethe free
energy and minimize those under the constraints of mar-
ginal consistency. Unfortunately, every constrained bound
optimization step is a slow iterative algorithm with linear
converge in general. Hence, if we use such an algorithm at
every step of learning for every data-case we end up with
a computationally very inefﬁcient learning algorithm. For
binary random variables with pairwise interactions the sit-
uation is considerably better, since it was shown in [18]
that the constraints can be solved analytically, leaving only
the node marginals as free variational parameters. Hence, a
truly efﬁcient learning procedure is currently only available
for this case, but we are conﬁdent that efﬁcient minimiza-
tion algorithms for the more general case will be developed
in the near future.

4 APPROXIMATE CONTRASTIVE FREE

ENERGIES

We will now introduce a second approximation that is
based on the ideas behind contrastive divergence and com-
bine them with the variational approximations described in
the previous section. This will have the effect of making the
learning algorithm computationally much more efﬁcient.

Recall our interpretation of learning using a contrastive free
energy. First we compute the free energy F0 at the data-
case under consideration and compute the necessary sufﬁ-
cient statistics. Then we relax the constraints on the vari-
ables which were clamped to the value of the data-case and
let the system reach equilibrium where we compute the val-
ues of the sufﬁcient statistics again. The system is relaxed
by “hitting” the data distribution P0 with a transition kernel
that has Pλ as its invariant distribution,

P1(h, y) =

K(h, y|h(cid:48), y(cid:48))P0(h(cid:48), y(cid:48))

(cid:88)

h(cid:48),y(cid:48)

Pλ = (K)∞P0

(14)

(15)

In practice we replace P0 by the empirical distribution and
achieve the relaxation by running MCMC sampling proce-
dures initialized at the data cases.

The underlying idea of contrastive divergence is that we
don’t actually have to wait until the system has reached
equilibrium, since there is much valuable information in
the ﬁrst few steps of this relaxation process (i.e. after a few
steps of the MCMC samplers). If the population of samples
have a systematic tendency to move away from the data,
we can immediately correct this tendency by changing the
parameters such that the probability becomes larger at the
location of the data and the probability becomes smaller at
the location of the samples obtained after a brief MCMC
run,

∂CFCD
k
∂λiβ

= −E[fiβ(yβ, hβ)]P0 + E[fiβ(yβ, hβ)]Pk

(16)

Following these gradients downhill approximately mini-
mizes the following contrastive divergence objective,

KL[P0(y, h)||Pλ(y, h)] − KL[Pk(y, h)||Pλ(y, h)]
= F0 − Fk
(17)

.= CFk ≥ 0

The derivative of this objective w.r.t. λiβ contains a term
∂Fk/∂λiβ in addition to the terms in Eqn.16. However, it
is usually small and rarely in conﬂict with the other terms
in the gradient and as result it can be safely ignored [5].

Clearly, learning with contrastive divergence results in a
vast improvement in efﬁciency. Moreover, because for each
data-case there is a nearby sample we reduce the variance in
the estimates of the sufﬁcient statistic in Eqn.16 (compared
to a MCMC sampler at equilibrium) but at the same time

400we may have introduced bias in our estimates. However,
it is not hard to show that for an inﬁnite number of data-
cases and a model that is ﬂexible enough to contain the
true model, it must be true that there is a ﬁxed point at
the correct parameter value, i.e. the ﬁrst and second term
in Eqn.20 will cancel. We refer to [5, 15, 21] for further
details on contrastive divergence learning.

one. The various methods differed in the way we allowed
the relaxation of the free energy to take place. We have
introduced approximate relaxations using variational dis-
tributions and partial relaxations where we don’t relax all
the way to equilibrium. We will now see that the pseudo-
likelihood estimator can also be interpreted in this frame-
work (see also [6]).

It is now a small step to argue for a procedure that combines
the variational approximation of the previous section with
the ideas of contrastive divergence. Instead of relaxing the
free energy using sampling we will relax it by applying a
minimization procedure over the variational distributions Q
initialized at Q0 or over the marginals rα(zα), initialized
at p0(yα)qα(hα|yα). Thus, we deﬁne the approximate “k-
step” contrastive free energy as,

KL[Q0(y, h)||Pλ(y, h)] − KL[Qk(y, h)||Pλ(y, h)]
= F APP
(18)

0 − F APP

k ≥ 0

.= CFAPP

k

k

where F APP
is a function of the variational distribution Qk.
Alternatively, in case of the Kikuchi approximation, we use
Eqn.10 and replace the local marginals rα(zα) with their
k-step counterparts obtained after k steps of minimization
on the Kikuchi free energy. Because of its deﬁnition the
“k-step” contrastive free energy must be positive which, as
discussed earlier, is an important constraint for the proce-
dure to work. Taking derivatives w.r.t.
to the parameters
{λiβ} we ﬁnd,
∂CFAPP
k
∂λiβ

= ∂F APP
∂λiβ

− ∂F APP
∂λiβ

− ∂F APP
∂Qk

∂Qk
∂λiβ

(19)

k

k

0

where the last term appears because we didn’t minimize the
free energy and hence ∂Fk/∂Qk (cid:54)= 0 (unlike ∂F0/∂Q0 =
0 and ∂F∞/∂Q∞ = 0). This term is difﬁcult to com-
pute, since we don’t have explicit expressions for Qk in
terms of λi. Again, it is small and rarely in conﬂict with
the other terms in the gradient so it can be safely ignored
(see [17] for experimental evidence of this fact in the case
of MF). Hence, ignoring the last term and simplifying the
other terms we arrive at the gradient,

∂CFAPP

k
∂λiβ

= −E[fiβ(yβ, hβ)]Q0 + E[fiβ(yβ, hβ)]Qk (20)

Of course, when we use the Kikuchi approximation we re-
place the global distributions Q0 and Qk in Eqn.20 by local
marginals qαp0 and rα,k as in Eqn.13.

5 RELATION TO PSEUDO-LIKELIHOOD

We have seen that learning in MRFs can be interpreted
as minimizing the difference between two free energies,
one with the data clamped on the observed variables, the
other one with all the variables unconstrained. Importantly,
the latter free energy must always be lower than the ﬁrst

In [1], the pseudo-likelihood (PL) was introduced to learn
MRF models tractably. For a fully observed7 MRF the PL
is given by,

N(cid:89)

K(cid:89)

n=1

k=1

PL =

1
KN

p(ˆyk,n|ˆy−k,n)

(21)

where y−k denotes all variables except variable yk, K is
the number of variables and N the number of data-cases.
This objective is far more tractable than the ML criterion
because it only depends on one dimensional normalization
constants Zk|−k. Moreover it was shown that asymptoti-
cally this estimator is consistent [3] (but less efﬁcient in the
statistical sense than the MLE). We can rewrite minus the
log of this objective as a difference of two free energies,
KL[P0||

fiβ(yβ)]P0 +

(cid:88)

(cid:88)

(cid:89)

log Zk|−k

1
K

Pk|−k] = E[
0 − F PL∞ = CFPL ≥ 0

k

iβ

= F PL

k

(22)

where we identify the ﬁrst term as the average energy and
the second as the average one dimensional conditional par-
tition functions. Since the data have no entropy, the ﬁrst
term is the free energy of the data F0. The second term
can be interpreted as a partially unconstrained free energy,
where only one variable is relaxed at a time, conditioned on
all the others and where the ﬁnal result is averaged. Hence,
like our partial relaxations, the PL-relaxation stays close to
the data distribution since at all times we condition on all
but one of the variables. The relaxed distribution for one
data-case is given by the following mixture,

pλ(yk,n|ˆy−k,n)

K(cid:88)

k=1

(cid:89)

j\k



δ(yj,n − ˆyj,n)

P PL
λ (yn) =

1
K

(23)
which has to be compared with Pλ (maximum likelihood),
Pk (k-step contrastive divergence), Q∞ (variational) and
Qk (k-step variational). It is now straightforward to derive
the following gradients,

∂CFPL
∂λiβ
= − 1
N

n=1

= −E[fiβ(yβ)]P0 + E[fiβ(yβ)]P PL
N(cid:88)

(cid:88)

(fiβ(ˆyβ,n) +

E[fiβ(yk, ˆyβ\k)]pk|−k)

(24)

1
|β|

k⊂β

7The following considerations are easily generalized to in-
clude hidden variables, but for simplicity we have chosen to il-
lustrate our point using observed variables only.

401where |β| denotes the number of nodes in the cluster β.
In light of our interpretation of learning in MRFs, it is not
hard to generalize the PL estimator to a generalized PL es-
timator where we allow the relaxation of larger, possibly
overlapping clusters of nodes conditioned on the remaining
nodes in the graph. We leave the study of these generalized
PL estimators as future work.

As mentioned above, it has been shown that the PL esti-
mator is asymptotically consistent, but is less efﬁcient than
the ML estimator. It would be interesting to see if the argu-
ments in the PL-consistency proofs can be adapted to cover
the estimators studied in this paper.

6 CONDITIONAL RANDOM FIELDS

A conditional random ﬁeld (CRF) [8] is a MRF that is
trained to maximize the conditional log-likelihood of la-
bels, y, given input variables x,

λM L = arg min
λ

KL [P0(y|x)||Pλ(y|x)]

(25)

That is, the variables that appear in the data are partitioned
into input nodes x, which will be observed at test time,
and output nodes y, which we will be asked to predict at
test time. In practice, discriminatively-trained models often
have advantages over generatively-trained models, includ-
ing the ability to include many interdependent variables in
x without needing to learn their distribution.

All of our previous considerations apply to the condi-
tional case as well. However, it should be noted that
for generatively-trained models the free energy F∞ must
be computed with all the variables free to ﬂuctuate.
In
contrast, for discriminatively-trained models the free en-
ergy F∞ has the data-case xn clamped to the input nodes.
Hence, the learning rule aims to match the average sufﬁ-
cient statistics of the random system with 1) both x and y
clamped at the nodes (F0) and 2) the random system with
only x clamped at the nodes (F∞). This has the impor-
tant consequence that the relaxed distributions Pλ(y|xn)
are different for every data-case, while the relaxed distrib-
utions for generatively-trained models Pλ(y) are the same
for all data-cases and it would in principle sufﬁce to run a
single MCMC procedure per learning iteration 8.

7 EXPERIMENTS

In this section, we evaluate the CFk estimators presented in
this paper on CRFs. The state of the art for training loopy
CRFs in practice is penalized maximum-likelihood train-
ing with the expected sufﬁcient statistics computed by BP

8Note that we need to visit all modes with this Markov chain,
so in practice it may be better to run multiple Markov chains ini-
tialized at various data-cases.

Method

F1 (2-clique) F1 (4-clique)

5

15

10

CFBETHE
CFBETHE
CFBETHE
CFBETHE
500
CFMF
10
MLMF
MLBP

70.08

68.35

61.80

63.44

57.91

60.98

68.19

74.94

75.23

76.51

75.86

55.91

65.31

78.71

Table 1: F1 performance measure for various training
methods on the 2-clique and 4-clique models.

[12, 13]. This has two difﬁculties: (a) If the model distri-
bution has multiple modes BP may converge to different
solutions depending on its initialization (or fail to converge
altogether), and (b) it requires running BP to convergence
at each step of gradient ascent on the log-likelihood, which
will be very expensive. Therefore, if nothing else, we can
still hope to achieve improved training time by using the
k-step CF estimators introduced in this paper. For the ex-
periments in this paper, we will use fully-observed training
data, leaving partially observed data to future work.

Our data set is a collection of 485 e-mail messages an-
nouncing seminars at Carnegie Mellon University. The
messages are annotated with the seminar’s starting time,
ending time, location, and speaker. This data set is due
to Dayne Freitag [2], and has been used in much previous
work. For reasons discussed in section 4, we consider here
the binary problem of whether a word is a speaker name.

Often the speaker is listed multiple times in the same mes-
sage. For example, the speaker’s name might be included
both near the beginning and later on, in a sentence like “If
you would like to meet with Professor Smith. . . ” It can be
useful to ﬁnd both such mentions, because different infor-
mation can be in the surrounding context of each mention:
for example, the ﬁrst mention might be near an institution
afﬁliation, while the second mentions that Smith is a pro-
fessor.

To solve this problem, we wish to exploit that when the
same word appears multiple times in the same message, it
tends to have the same label. In a CRF, we can represent
this by adding edges between output nodes (yi, yj) when
the words xi and xj are identical and capitalized. Thus,
the conditional distribution p(y|x) has different graphical
structure for different input conﬁgurations x. We use input
nodes describing word identity, part-of-speech tags, cap-
italization, and membership in domain-speciﬁc lexicons;
these are described in more detail elsewhere [11].

We compare training time and test performance of four dif-

402k

ferent contrastive free energies: MLMF, which corresponds
to maximum-likelihood training with mean-ﬁeld free en-
ergy; MLBP, which corresponds to maximum likelihood
training with the Bethe free energy; and ﬁnally, CFMF
and
k
CFBETHE
, which correspond to k-step contrastive diver-
gence with the mean-ﬁeld and Bethe approximations, re-
spectively. We compute the contrastive free energy as fol-
lows. For MLBP, we use the TRP schedule for belief prop-
agation [16], with messages initialized to 1. For MLMF,
we use damped ﬁxed point equations with damping factor
α = 0.1 and uniform initialization. For CFMF
k , however,
we observed that iterating ﬁxed-point equations for k steps
might not decrease the free energy if they are improperly
damped. Hence we have used separate damping factors for
each data-case, α(i), which are adapted to keep CF positive
during learning.
To compute CFBETHE
, we use belief optimization; that is,
we take k gradient steps on the Bethe free energy, elimi-
nating the constraints by solving for the pairwise marginals
and using the sigmoid parameterization described in [18].
The step-size for the gradient updates is determined by line
search. For k-step contrastive divergence, it is essential that
the optimization required to compute F BETHE
is initialized
at the data cases. However, at the empirical distribution
the derivative of the Bethe entropy is inﬁnite. To avoid
this problem we smooth the 0/1 empirical distribution by
˜pSOFT(xj) = |˜p0/1(xj) − |. In these experiments we use
 = 10−4.
We report performance with the F1 measure on a per-token
basis, that is:

k

k

F1 = (2P R)/(P + R)

(26)

with P = # correct tokens / # tokens extracted and R =
# correct tokens / # true tokens. We use (cid:96)2 regularization with
regularization parameter δ = 10. All results are averaged
over 5-fold cross validation.

First, we consider a 2-clique model where all cliques are ei-
ther linear chain edges (yi, yi+1), skip edges (yi, yj), and
input edges (yi, xi)9. The parameters are tied over all in-
stances of each clique type. For example, each linear chain
edge (yi, yi+1) has the same weight wLC. This sort of pa-
rameter tying is necessary in a conditional model because
until we observe the input x, we do not know how many
output nodes there will be or what connections they will
have.

Table 1 compares the testing performance of the differ-
ent training methods on the 2-clique model (ﬁrst column).
First, we note that both in CF and ML training, the Bethe
approximation results in better accuracy than the mean-
ﬁeld approximation. This is as expected because the skip-

9To make the exposition simpler, we describe the models as if
the only input variables xi are the words at time i. In reality, each
xi is a vector of the observational tests described in [11].

chain model contains few short loops which is a graphical
structure for which the Bethe approximation is more appro-
priate than the MF approximation. Second, with the Bethe
free energy, using CFBETHE
training results in comparable
accuracy to ML training. This has great practical signiﬁ-
cance, because while the CFBETHE
training used an average
of 83 minutes to train, the ML training using belief propa-
gation used over 19 hours, which is an order of magnitude
improvement.

5

5

Although the belief optimization algorithm has been de-
veloped for binary MRFs with pairwise interactions (a.k.a.
Boltzmann machines), the CRF is free to contain arbi-
trary cliques with at most two output nodes, since the dis-
tribution p(y|x) then still contains pairwise interactions
only. To evaluate the practical advantages of such mod-
els, we also evaluate a skip chain model with higher-order
cliques. In the 4-clique model, we add input nodes into the
linear-chain and skip-chain cliques, so that we now have
“linear-chain” cliques (yi, yi+1, xi) and “skip” cliques
(yi, yj, xi, xj) in addition to the input edges (yi, xi).
In Figure 1, we show the performance of CFBETHE
model
on the 4-clique model as a function of k (second column).
For all values of k, the higher-order model performs better
than the 2-clique model. Between the best 2-clique model
and the best higher-order clique model, all 5 folds show
improvement; averaging over the folds, the relative reduc-
tion in error is 20% (the F1 rises from 70 to 76). For an
unknown reason, the 2-clique model trained with CFBETHE
hits a bad local maximum, but we do not see this behav-
ior with a richer set of features.
In the 4-clique model,
ML training with BP does somewhat better than the best
CFBETHE
model, but there is substantial variance among
the different training sets. None of the differences between
MLBP and CFBETHE
for the 4-clique model are statistically
signiﬁcant (McNemar’s test with p > 0.1). For the 2-clique
model, on the other hand, CFBETHE
training is signiﬁcantly
5
better than MLBP (p < 0.001).

15

k

k

k

In summary, the experiments demonstrate two main points:
that a k-step CF energy performs comparably to ML with
vastly lower training time, and that belief optimization,
which was developed for Boltzmann machines, is still ef-
fective for training models with certain higher-order cliques
in a conditional setting.

8 CONCLUSION

In this paper we have offered a new view of parameter
learning in MRF models as a minimization of contrastive
free energies. We have seen that many objectives for
MRF learning, including the likelihood function, the mean
ﬁeld learning objective, the contrastive divergence and the
pseudo-likelihood can be written as a positive difference
between two free energies. During learning we ﬁrst infer
the (posterior) distribution of the hidden variables given a

403clamped data-vector, then we relax this system (exactly, ap-
proximately or partially) by un-constraining the observed
random variables. Finally we update the parameters by
computing the difference of the average sufﬁcient statistics.
Not only is this unifying framework conceptually interest-
ing, it also naturally suggests hybrid schemes where distri-
butions are relaxed partially and approximately. In particu-
lar, we have studied a new learning algorithm based on the
contrastive Kikuchi/Bethe free energy and its accompany-
ing minimization algorithm, “belief optimization”.

We feel that the view presented here is a rich breeding
ground for new approximate learning algorithms. In future
studies we hope to characterize the estimators proposed
here by their asymptotic properties such as consistency and
statistical efﬁciency.

Acknowledgments

This work was supported in part by the Center for Intelli-
gent Information Retrieval and in part by The Central In-
telligence Agency, the National Security Agency and Na-
tional Science Foundation under NSF grant #IIS-0326249.
Any opinions, ﬁndings and conclusions or recommenda-
tions expressed in this material are the author(s) and do not
necessarily reﬂect those of the sponsor. Max Welling likes
to thank G. Hinton, Y.W. Teh and S. Osindero for numerous
discussions on the topic.

References

[1] J. Besag. Efﬁciency of pseudo-likelihood estimation for

simple Gaussian ﬁelds. Biometrika, 64:616–618, 1977.

[2] Dayne Freitag. Machine Learning for Information Extrac-
tion in Informal Domains. PhD thesis, Carnegie Mellon
University, 1998.

[3] B. Gidas. Consistency of maximum likelihood and pseudo-
likelihood estimators for Gibbs distributions. In W. Fleming
and eds. P.L. Lions, editors, Stochastic Differential Systems,
Stochastic Control Theory and Applications. New York:
Springer, 1988.

[4] T. Heskes. Stable ﬁxed points of loopy belief propaga-
tion are minima of the Bethe free energy. In Advances in
Neural Information Processing Systems, volume 15, Van-
couver, CA, 2003.

[5] G.E. Hinton. Training products of experts by minimiz-
ing contrastive divergence. Neural Computation, 14:1771–
1800, 2002.

[6] G.E. Hinton, K. Osindero, M. Welling, and Y.W. Teh. Unsu-
pervised discovery of non-linear structure using contrastive
backpropagation, 2004. in prepration.

[7] G.E. Hinton, M. Welling, and A. Mnih. Wormholes improve
contrastive divergence. In Advances in Neural Information
Processing Systems, volume 16, 2004.

[8] John Lafferty, Andrew McCallum, and Fernando Pereira.
Conditional random ﬁelds: Probabilistic models for seg-
menting and labeling sequence data. In Proc. 18th Interna-
tional Conf. on Machine Learning, pages 282–289. Morgan
Kaufmann, San Francisco, CA, 2001.

[9] I. Murray and Z. Ghahramani. Bayesian learning in undi-
rected graphical models: approximate MCMC algorithms.
In Proceedings of the 14th Annual Conference on Uncer-
tainty in Artiﬁcial Intelligence (UAI-04), San Francisco, CA,
2004. Morgan Kaufmann Publishers.

[10] C. Peterson and J. Anderson. A mean ﬁeld theory learning
algorithm for neural networks. Complex Systems, 1:995–
1019, 1987.

[11] Charles Sutton and Andrew McCallum. Collective segmen-
tation and labeling of distant entities in information extrac-
tion. Technical Report TR # 04-49, University of Massa-
chusetts, July 2004. Presented at ICML Workshop on Sta-
tistical Relational Learning and Its Connections to Other
Fields.

[12] Charles Sutton, Khashayar Rohanimanesh, and Andrew Mc-
Callum. Dynamic conditional random ﬁelds: Factorized
probabilistic models for labeling and segmenting sequence
data. In Proceedings of the Twenty-First International Con-
ference on Machine Learning (ICML-2004), 2004.

[13] Ben Taskar, Pieter Abbeel, and Daphne Koller. Discrim-
inative probabilistic models for relational data.
In Eigh-
teenth Conference on Uncertainty in Artiﬁcial Intelligence
(UAI02), 2002.

[14] Y.W. Teh and M. Welling. The uniﬁed propagation and scal-
ing algorithm. In Advances in Neural Information Process-
ing Systems, 2002.

[15] Y.W. Teh, M. Welling, S. Osindero, and G.E. Hinton.
Energy-based models for sparse overcomplete representa-
tions. Journal of Machine Learning Research - Special Issue
on ICA, 4:1235–1260, 2003.

[16] M.J. Wainwright, T. Jaakkola, and A.S. Willsky. Tree-based
reparameterization for approximate estimation on loopy
graphs.
In Advances Neural Information Processing Sys-
tems, volume 14, vancouver, Canada, 2001.

[17] M. Welling and G.E. Hinton. A new learning algorithm
for mean ﬁeld Boltzmann machines.
In Proceedings of
the International Conference on Artiﬁcial Neural Networks,
Madrid, Spain, 2001.

[18] M. Welling and Y.W. Teh. Belief optimization for binary
networks: a stable alternative to loopy belief propagation. In
Proceedings of the Conference on Uncertainty in Artiﬁcial
Intelligence, pages 554–561, Seattle, USA, 2001.

[19] J.S. Yedidia, W. Freeman, and Y. Weiss. Constructing free
energy approximations and generalized belief propagation
algorithms. Technical report, MERL, 2002. Technical Re-
port TR-2002-35.

[20] A.L. Yuille. CCCP algorithms to minimize the Bethe and
Kikuchi free energies: Convergent alternatives to belief
propagation. Neural Computation, 14(7):1691–1722, 2002.

[21] A.L. Yuille. A comment on contrastive divergence. Tech-
nical report, Department Statistics and Psychology UCLA,
2004. Technical Report.

404Robust Higher Order Statistics

Max Welling

School of Information and Computer Science

University of California Irvine
Irvine CA 92697-3425 USA

welling@ics.uci.edu

Abstract

Sample estimates of moments and cumulants are
known to be unstable in the presence of outliers.
This problem is especially severe for higher order
statistics, like kurtosis, which are used in algo-
rithms for independent components analysis and
projection pursuit. In this paper we propose ro-
bust generalizations of moments and cumulants
that are more insensitive to outliers but at the
same time retain many of their desirable proper-
ties. We show how they can be combined into se-
ries expansions to provide estimates of probabil-
ity density functions. This in turn is directly rel-
evant for the design of new robust algorithms for
ICA. We study the improved statistical properties
such as B-robustness, bias and variance while in
experiments we demonstrate their improved be-
havior.

1 INTRODUCTION

Moments and cumulants are widely used in scientiﬁc dis-
ciplines that deal with data, random variables or stochas-
tic processes. They are well known tools that can be used
to quantify certain statistical properties of the probability
distribution like location (ﬁrst moment) and scale (second
moment). Their deﬁnition is given by,

µn = E[xn]

(1)
where E[·] denotes the average over the probability distri-
bution p(x). In practise we have a set of samples from the
probability distribution and compute sample estimates of
these moments. However, for higher order moments these
estimates become increasingly dominated by outliers, by
which we will mean the samples which are far away from
the mean. Especially for heavy tailed distributions this im-
plies that these estimates have high variance and are gener-
ally unsuitable to measure properties of the distribution.

An undesirable property of moments is the fact that lower
order moments can have a dominating inﬂuence on the
value of higher order moments. For instance, when the
mean is large it will have a dominating effect on the sec-
ond order moment,

E[x2] = E[x]2 + E[x − E[x]]2

(2)

The second term which measures the variation around the
mean, i.e. the variance, is a much more suitable statistic for
scale than the second order moment. This process of sub-
tracting lower order information can be continued to higher
order statistics. The resulting estimators are called central-
ized moments or cumulants. Well known higher order cu-
mulants are skewness (third order) measuring asymmetry
and kurtosis (fourth order) measuring ”peakiness” of the
probability distribution . Explicit relations between cumu-
lants and moments are given in appendix A (set µ0 = 1
for the classical case). Since cumulants are functions of
moments up to the same order, they also suffer from high
sensitivity to outliers.

Many statistical methods and techniques use moments and
cumulants because of their convenient properties. For in-
stance they follow easy transformation rules under afﬁne
transformations. Examples in the machine learning liter-
ature are certain algorithms for independent components
analysis [3, 2, 1]. A well known downside of these algo-
rithm is their sensitivity to outliers in the data. Thus, there
is a need to deﬁne robust cumulants which are relatively in-
sensitive to outliers but retain most of the convenient prop-
erties that moments and cumulants enjoy. This will be the
topic of this paper.

2 MOMENTS AND CUMULANTS

A formal deﬁnition of the relation between moments and
cumulants to all orders can be given in terms the character-
istic function (or moment generating function) of a proba-
bility distribution,

Ψ(t) = E[eixt] =

1
n! µn(it)n

(3)

∞(cid:88)

n=0

405where the last expression follows by Taylor expanding the
exponential. The cumulants can now be deﬁned by

on an extensive body of literature [5][6] to compute robust
estimates of location and scale.

1
n! κn(it)n = ln Ψ(t)

(4)

As will become apparent in the following, a convenient
choice for the robust moments is given by the following
expression,

∞(cid:88)

n=0

where we expand the right hand side in powers of (it) and
match terms at all orders.

The generalization of the above to the multivariate case is
straightforward. Moments are deﬁned as expectations of
monomials,

µi1,...,im = E[xi1....xim]

(5)

and the cumulants are again deﬁned through the character-
istic function (see Eq.7), where in addition to the univariate
cumulants we now also have cross-cumulants.

From the deﬁnition of the cumulants in terms of the mo-
ments we can derive a number of interesting properties,
which we will state below. It will be our objective to con-
serve most of these properties when we deﬁne the robust
cumulants.

Lemma 1 The following properties are true for cumu-
lants:

I. For a Gaussian density, all cumulants higher than sec-

ond order vanish.

II. For

independent
cumulants vanish.

(cid:184)

(cid:183)

Deﬁnition 1 The robust moments are given by:

µ(α)
i1...in

= E

(αxi1) . . . (αxin) φ(αx)
φ(x)

α ≥ 1 (6)

where φ(x) is the multivariate standard normal density.

is

=
The decaying factor
2(α2 − 1)xT x), where d is the dimension of the
αd exp(− 1
space. In the limit α → 1 we obtain the usual deﬁnition of
moments.

thus given by φ(αx)
φ(x)

In order to preserve most of the desirable properties that
cumulants obey, we will use the same deﬁnition to relate
moments to cumulants as in the classical case,

Deﬁnition 2 The robust cumulants are deﬁned by:

∞(cid:88)
M(cid:88)
∞(cid:88)

n=0

ln(

. . .

M(cid:88)

M(cid:88)

. . .

i1=1

in=1

1
n! κ(α)
M(cid:88)

(iti1) . . . (itin) =

i1...in

1
m! µ(α)

j1...jm

(itj1) . . . (itjm))

(7)

The right hand side can again be deﬁned as the logarithm
of the moment generating function for robust moments,

(cid:183)

(cid:184)

Ψ(α)(t) = E

exp(iαxT t) φ(αx)
φ(x)

(8)

The explicit relation between robust moments and cumu-
lants up to fourth order is given in appendix A.

With the above deﬁnitions we can now state some impor-
tant properties for the robust cumulants. Since we assume
zero-mean and unit-variance we cannot expect the cumu-
lants to be invariant with respect to translation and scal-
ings. However, we will prove that the following properties
are still valid,

Theorem 1 The following properties are true for robust
cumulants:

I. For a standard Gaussian density, all robust cumulants

higher than second order vanish.

II. For independent random variables, robust cross-

cumulants vanish.

III. All robust cumulants transform multi-linearly with re-

spect to rotations.

random variables,

all

cross-

m=0

j1=1

jm=1

III. All cumulants transform multi-linearly with respect to

afﬁne transformations.

IV. All cumulants higher than ﬁrst order are invariant

with respect to translations.

The proofs of these statements can for instance be found in
[9] and are very similar to the proofs for the robust cumu-
lants which we will present in the next section.

3 ROBUST MOMENTS AND

CUMULANTS

In this section we will deﬁne robust moments and cumu-
lants by introducing an isotropic decay factor which down-
weights outliers. With this decay factor we will have intro-
duced a preferred location and scale. We therefore make
the following important assumption: The probability den-
sity function has zero-mean and unit-variance (or covari-
ance equal to the identity in the multivariate case). This
can always be achieved by a linear transformation of the
random variables. Analogously, data will need to be cen-
tered and sphered. One may worry that these preprocessing
steps are non-robust operations. Fortunately, we can rely

406Proof: I: For a standard Gaussian we can compute the mo-
ment generating function analytically giving Ψ(α)(t) =
− 1
2 tT t, implying that κ(α)
i1i2 = δi1i2 and all other cumu-
lants vanish.
II: We note that if the variables {xi} are independent,
Ψ(α)(t) factorizes into a product of expectations which the
logarithm turns into a sum, each term only depending on
one ti. Since cross cumulants on the left hand side of Eq.7
are precisely those terms which contain distinct ti, they
must be zero.
III: From Eq.6 we see that since the decay factor is
isotropic, robust moments still transform multi-linearly
with respect to rotations. If we rotate both the moments
and t in the right-hand side of Eq.7, it remains invariant.
To ensure that the left-hand side of Eq.7 remains invari-
ant we infer that the robust cumulants must also transform
multi-linearly with respect to rotations,

κ(α)
i1...in

→ Oi1j1 . . . Oinjnκ(α)
This concludes the proof. (cid:163)

j1...jn

, OOT = OT O = I
(9)

4 ROBUST GRAM-CHARLIER AND

EDGEWORTH EXPANSIONS

Assuming we have computed robust cumulants (or equiv-
alently robust moments) up to a given order, can we com-
bine them to provide us with an estimate of the probability
density function? For the classical case it is long known
that the Gram-Charlier and Edgeworth expansions are two
possibilities [8]. In this section we will show that these ex-
pansions can be generalized to the robust case as well. To
keep things simple, we will discuss the univariate case here.
Multivariate generalizations are relatively straightforward.

Both robust Gram-Charlier and Edgeworth expansions will
be deﬁned as series expansions in the scaled Hermite poly-
nomials Hn(αx).

∞(cid:88)
(cid:90) ∞

n=0
1
n!

−∞

p(x) =

n =
c(α)

(cid:90) ∞

−∞

given by the following theorem1,

Theorem 2 The series expansion of a density p(x) in terms
of its robust cumulants is given by

(cid:80)∞

p(x) = φ(x)

n=0

φ(αx) e(
˜κ(α)
n = κ(α)

n! ˜κ(α)
1
n − δn,2

with

n (−1)n dn

d(αx)n )φ(αx)

(13)

(14)

Proof: see appendix B.

To ﬁnd an explicit expression up to a certain order in the
robust cumulants, one expands the exponential and uses
(−1)n dn
dxn φ(x) = Hn(x)φ(x) to convert derivatives into
Hermite polynomials.

n

Analogous to the classical literature we will talk about a
Gram-Charlier expansion when we expand in c(α)
and an
Edgeworth expansion when we expand in κ(α)
n . Their only
difference is therefore in their convention to break the se-
ries off after a ﬁnite number of terms.
When α = 1 the Hermite expansions discussed in this sec-
tion will be normalized, even when only a ﬁnite number of
terms is taken into account. This holds since H0 = 1 and
c0 = 1/N
n 1 = 1, while all higher order polynomials
are orthogonal to “1”. When generalizing to robust cumu-
lants this however no longer holds true. To correct this we
will add an extra term to the expansion,

(cid:80)

n Hn(αx) + ψ(x)}φ(x),
c(α)

(15)

pR(x) = { R(cid:88)

n=0

ψ(x) = (1 − R(cid:88)

n=0

− R(cid:88)

n=0

The correction factor can be computed by a Gram-Schmidt
procedure resulting in,

n!anc(α)

n )( φ(x)
φ(αx)

anHn(αx)).

n!

(α2 − 1) n

(16)
with an = (n−1)!!
2 δn,2k for k ∈ {0, 1, 2, 3, ...}
and (n−1)!! denotes the double factorial of (n−1) deﬁned
by 1 · 3 · 5...(n − 1). The correction factor is thus orthog-
onal to all Hermite polynomials Hn(αx) with n = 1..R
under the new measure dνα. We can also show that pR(x)
always integrates to 1 and that when α → 1 the correction
term will reduce to ψ(x) → cR+KHR+K(x) with K = 1
when R is odd and K = 2 when R is even. Finally we
2 − α2) the
note that since

−∞ φ2(x)/φ(αx)dx = 1/(α

(cid:82) ∞

√

n Hn(αx)φ(x) with
c(α)

p(x)Hn(αx)φ−1(x) dνα

(10)

(11)

where we have deﬁned the measure dνα = φ(αx) dx and
used the following generalized orthogonality relation,

Hn(αx)Hm(αx) dνα = n! δnm

(12)

1The equivalent result in the multivariate case is,

When c(α)
we see that the decay factor φ(αx)
robust against outliers.

n is estimated by averaging over samples (Eq.25),
φ(x) will again render them

We may also express the above series expansion directly in
terms of the robust cumulants. The explicit expression is

p(x) =

(cid:80)∞

n=0

(
e

with

φ(x)
φ(αx)

(cid:80)M

i1=1...

×
(cid:80)M
i1i2 − δi1i2

1
n! ˜κ

in=1

˜κ(α)
i1i2 = κ(α)

(α)
i1 ...in

(−1)n

d

d(αx)i1

...

d

d(αx)in

)

φ(αx)

407Theorem 3 The estimates ˆc(α)

n [pR] are B-robust for α > 1.

Proof: It is straightforward to compute the inﬂuence func-
tion deﬁned in Eq.17,

IF (x) =

1

n! Hn(αx) φ(αx)

φ(x)

− c(α)

n

(18)

(a)

(b)

(cid:163)

Since for α > 1 this IF is ﬁnite everywhere, the result
follows.
Since cumulants are simple functions of the c(α)
n up to the
same order, we conclude that cumulants are also B-robust.
It is important to notice that in the classical case (α = 1) the
theorem does not hold, conﬁrming that classical cumulants
are not robust. Analogously one can show that the sensitiv-
ity to shifting data-points is also bounded for α > 1.

(c)

(d)

Figure 1: (a)-Bias as a function of α2 for a generalized Laplacian
with a = 1.5 (super-Gaussian). (b)-Asymptotic variance (solid
line) and inverse Fisher information (dashed line) as a function of
α2 for a = 1.5. (c)-(d) Similar plots for a = 4 (sub-Gaussian)

correction is only normalizable for α2 < 2, which is what
we will assume in the following.

5 CONSISTENCY, ROBUSTNESS, BIAS

AND VARIANCE

In this section we will examine the robustness, bias and
efﬁciency of our generalized expansion. Many deﬁnitions
in this section are taken from [5]. Our analysis will assume
that the data arrive centered and sphered, which allows us
to focus on the analysis of the higher order statistics. For
a thorough study of the robustness properties of ﬁrst and
second order statistics see [5].
First we mention that the estimators ˆc(α)
n [pR] for the trun-
cated series expansion (Eq.15) are Fisher consistent. This
can be shown by replacing p(x) in Eq.11 with pR(x) and
using orthogonality between ψ(x) and the Hermite polyno-
mials Hn(αx) n = 1..R w.r.t. the measure dνα.
To prove B-robustness we need to deﬁne and calculate the
inﬂuence function IF for the estimators ˆc(α)
n . Intuitively,
the inﬂuence function measures the sensitivity of the esti-
mators to adding one more observation at location x,

IF (x) = lim
t→0

n [(1 − t)pR + tδx] − c(α)
c(α)

n [pR]

t

.

(17)

An estimator is called B-robust if its inﬂuence function is
ﬁnite everywhere. We will now state the following result.

We now turn to the analysis of bias and variance. It is well
known that the point-wise mean square error can be decom-
posed into a bias and a variance term,

(cid:105)

(cid:104)
(cid:105)
R (x)) = E
R (x) − pR(x))2
(p(N )

(cid:104)

MSEx(p(N )

E

R (x) − p(x))2
(p(N )
=
+ (pR(x) − p(x))2

(19)

where p(N )
R is the estimate of pR using a sample of size N.
The expectation E is taken over an inﬁnite number of those
samples. Clearly, the ﬁrst term represents the variance and
the second the bias which is independent of N. The vari-
ance term (V ) may be rewritten in terms of the inﬂuence
function,

R(cid:88)

n,m=0

V =

1
N

(cid:90) ∞

−∞

(cid:183)

Σ(c(α)

n , c(α)

m )Hn(αx)Hm(αx)φ2(x) (20)

Σ(c(α)

n , c(α)

m ) =

p(x)IF (x, c(α)

n )IF (x, c(α)

m )dx (21)

So the variance decreases as 1/N with sample size while
the data independent part is completely determined by
the asymptotic covariance matrix Σ which is expressed in
terms of the inﬂuence function.

Finally, by deﬁning the Fisher information as,

(cid:90) ∞

=

J(c(α)

n , c(α)

m ) = E

p(x)

∂c(α)
Hn(αx)Hm(αx)φ(x)2

n

1

∂

pR(x)

1

∂

p(x)

∂c(α)
m

−∞

p(x)

dx

(cid:184)

pR(x)

p

(22)

the well
Σ(c(α)
n , c(α)

known

Cramer-Rao

m ) ≥ J−1(c(α)

n , c(α)

m ).

bound

follows:

In ﬁgure 1 we plot the bias and the total variation (trace
of the covariance) as a function of α2 for a super-Gaussian
and a sub-Gaussian density (generalized Laplace density
p ∝ exp(−b|x|a) with unit variance and a = 1.5 and a = 4
respectively) . The trace of the inverse Fisher information

11.21.41.61.821.522.533.544.55x 10−4          Bias for exponential density (a=1.5)α2bias11.21.41.61.8211.21.41.61.822.22.4Asymptotic variance & inverse Fisher information (a=1.5)α2trace(Σ) & trace(J−1)11.21.41.61.820.511.522.53x 10−4          Bias for exponential density (a=4)α2bias11.21.41.61.820.911.11.21.31.41.5Asymptotic variance & inverse Fisher information (a=4)α2trace(Σ) & trace(J−1)408was also plotted (dashed line). The model included 10 or-
ders in the expansion n = 0, ..., 9 plus the normalization
term ψ(x). All quantities were computed using numerical
integration. We conclude that both bias and efﬁciency im-
prove when α moves away from the classical case α = 1.

6 INDEPENDENT COMPONENTS

ANALYSIS

Although robust moments and cumulants can potentially
ﬁnd applications in a broad range of scientiﬁc disciplines,
we will illustrate their usefulness by showing how they can
be employed to improve algorithms for independent com-
ponents analysis (ICA). The objective in ICA is to ﬁnd a
new basis for which the data distribution factorizes into a
product of independent one-dimensional marginal distrib-
utions. To achieve this, one ﬁrst removes ﬁrst and sec-
ond order statistics from the data by shifting the sample
mean to the origin and sphering the sample covariance to
be the identity matrix. These operations render the data de-
correlated but higher order dependencies may still remain.
It can be shown [2] that if an independent basis exists, it
must be a rotation away from the basis in which the data is
de-correlated, i.e. xica = Oxdecor where O is a rotation.
One approach to ﬁnd O is to propose a contrast function
that, when maximized, returns a basis onto which the data
distribution is a product of independent marginal distribu-
tions. Various contrast functions have been proposed, e.g.
the neg-entropy [4] and the mutual information [1]. All
contrast functions share the property that they depend on
the marginal distributions which need to be estimated from
the data. Naturally, the Edgeworth expansion [4, 3] and the
Gram-Charlier expansion [1] have been proposed for this
purpose. This turns these contrast functions into functions
of moments or cumulants. However, to obtain reliable esti-
mates one needs to include cumulants of up to fourth order.
It has been observed frequently that in the presence of out-
liers these cumulants often become unreliable (e.g. [7]).

We propose to use the robust Edgeworth and Gram-
Charlier expansions discussed in this paper instead of the
classical ones. As we will show in the experiments below,
it is safe to include robust cumulants to very high order in
these expansions (we have gone up to order 20), which at a
moderate computational cost will have a signiﬁcant impact
on the accuracy of our estimates of the marginal distrib-
utions. We note that the derivation of the contrast func-
tion in e.g. [4] crucially depends on properties I,II and III
from theorem 1. This makes our robust cumulants the ideal
candidates to replace the classical ones. Instead of going
through this derivation we will argue for a novel contrast
function that represents a slight generalization of the one
proposed in [4],

R(cid:88)

M(cid:88)

n=1

i=1

I(O) =

Figure 2: Histogram of sound-data (5000 samples).

ii = κ(α)

i...i only differ from the usual κ(α)

i...i in second or-
ii − 1. These cumulants are deﬁned on the
i = OT ei.

where ˜κ(α)
der, ˜κ(α)
rotated axis e(cid:48)
We will now state a number of properties that show the
validity of I(O) as a contrast function for ICA,

Theorem 4 The following properties are true for I(O):

i. I(O) is maximal if the probability distribution on the
corresponding axis factors into an independent prod-
uct of marginal distributions.

ii. I(O) is minimal (i.e. 0) if the marginal distributions

on the corresponding axis are Gaussian.

(cid:88)

Proof: To prove (i) we note that the following expression
is scalar (i.e. invariant) w.r.t. rotations2,

(˜κ(α)

i1...in

)2 = constant

∀n

(24)

i1...in

We now note that this expression can be split into two
terms: a sum over the “diagonal terms” where i1 =
i2 = . . . = in and a sum over all the remaining cross-
cumulant terms. When all directions are independent all
cross-cumulants must vanish by property II of theorem 1.
This minimizes the second term (since it’s non-negative).
Hence, by the fact the sum of these terms is constant, the
ﬁrst term, which equals I(O), must be maximal for inde-
pendent directions.
To prove (ii) we invoke property I of theorem 1 that
for Gaussian random variables all cumulants ˜κ must
vanish. (cid:163)
By the above theorem we see that I(O) simultaneously
searches for independent directions and non-Gaussian di-
rections. Observe however, that for practical reasons we
have ignored cumulants of order higher than R. Hence,
there will certainly be more than one distribution which

wn(˜κ(α)

i...i)2

wn ≥ 0,

(23)

2For vectors this reduces to the statement that an inner product
is scalar. To prove the general case we use OT O = I for every
index separately.

−10−50510050100150200250300350400450Histogram of sound dataxnumber of samples in bin409(a)

(c)

(b)

(a)

(b)

(d)

(c)

(d)

Figure 3: (a)-Expansion coefﬁcients for classical Gram-Charlier
expansion (α = 1). (b)-Density estimate for α = 1 after four
orders. The negative tails signal the onset of a diverging series.
(c)-Decreasing expansion coefﬁcients for α = 1.8. (f)-Density
estimate after 10 orders for α = 1.8.

maximizes I(O) (for instance distributions which only dif-
fer in the statistics of order higher than R). Good objective
functions are discriminative in the sense that there are only
few (relevant) densities that maximize it. We can inﬂuence
the ability of I(O) to discriminate by changing the weight-
ing factors wn. Doing this allows for a more directed search
towards predeﬁned qualities, e.g. a search for high kurtosis
directions would imply a large w4.
A straightforward strategy to maximize I(O) is gradient
ascent while at every iteration projecting the solution back
onto the manifold of rotations (e.g. see [10]). A more ef-
ﬁcient technique which exploits the tensorial property of
cumulants (i.e. property III of theorem 1) was proposed in
[3]. This technique, called Jacobi-optimization, iteratively
solves two dimensional sub-problems analytically.

7 EXPERIMENTS
The following set of experiments focus on density es-
timates based on the Gram-Charlier expansion (Eq.10)
where we replace Eq.11 with a sample estimate,

N(cid:88)

A=1

ˆc(α)
n =

1
N

1
n!

φ(αxA)
φ(xA) Hn(αxA)

(25)

The reason we focus on this task is that we can demonstrate
robustness by showing that low order robust statistics are
always dominant over higher order robust statistics, even

Figure 4: Top row: Generalized Laplace distributions with (a)
a = 1, (b) a = 4. Bottom row: Mixture of Gaussians with (c)
µ = 0.3, c = 3, d = 0 and (d) µ = 0.5, c = 3, d = 2.

for heavy tailed distributions. Yet at the same time they
carry the relevant information of the probability density, i.e.
they combine into an accurate estimate of it. This exercise
is also relevant for cumulant based algorithms for indepen-
dent components analysis because they rely on the fact that
the Gram-Charlier or Edgeworth expansions describe the
source distributions well.

Sound Data
We downloaded recordings from music CD’s 3 and ex-
tracted 5000 samples from it. The histogram is shown in
ﬁgure 2. Due to the presence of outliers we expect the clas-
sical expansion to break down. This can be observed from
ﬁgure (3a) where the coefﬁcients increase with the order of
the expansion. In ﬁgure (3b) we see that the density esti-
mate has become negative in the tails after 4 orders, which
is an indication that the series has become unstable. In ﬁg-
ures (3c,d) we see that for the robust expansion at α = 1.8
the coefﬁcients decrease with order and the estimate of the
density is very accurate after 10 orders.

Synthetic Data
In this experiment we sampled 5000 data-points from two
generalized Laplace densities p ∝ exp(−b|x|a) (ﬁgures
4a,b) and from two mixtures of two Gaussians parameter-
ized as
pmog(x) = µaφ(ax + b) + c(1 − µ)φ(cx + d) (ﬁgures
4c,d). These include super-Gaussian distributions (ﬁgures

3http://sweat.cs.unm.edu/bap/demos.html

012345678910−1000100200300400500600700expansion coefficient numbervalue of expansion coefficientExpansion coefficients for sound data (α=1)−10−50510−0.200.20.40.60.81xp(x)Estimated pdf for sound data (α=1)012345678910−0.4−0.200.20.40.60.811.2expansion coefficient numbervalue of expansion coefficientExpansion coefficients for sound data (α=1.8)−10−5051000.10.20.30.40.5xp(x)Estimated pdf for sound data (α=1.8)−50500.10.20.30.40.50.60.70.8Exponential density (a=1)xp(x)−50500.050.10.150.20.250.30.35Exponential density (a=4)xp(x)−50500.10.20.30.40.50.60.70.80.91Mixture of Gaussians (µ=0.3, c=3, d=0)xp(x)−50500.10.20.30.40.50.60.7Mixture of Gaussians (µ=0.5, c=3, d=2)xp(x)410(a)

(b)

(a)

(b)

Figure 6: L2-distance as a function of the order of the expansion
for (a) α2 = 1 and (b) α2 = 1.9 for the generalized Laplace PDF
with a = 1.

translations was lost and the
cumulants invariance w.r.t.
class of transformations under which they transform multi-
linearly was reduced from afﬁne to orthogonal (i.e. rota-
tions). However, all other cumulant properties were con-
veniently preserved. We argue that by ﬁrst centering and
sphering the data (using robust techniques described in the
literature [5]), multi-linearity w.r.t. orthogonal transforma-
tions is all we need, which could make the trade-off with
improved robustness properties worthwhile.

There is two well-known limitations of cumulants that one
needs to be aware of. Firstly, they are less useful as statis-
tics characterizing the PDF if the mass is located far away
from the mean. Secondly, the number of cumulants grows
exponentially fast with the dimensionality of the problem.
With these reservations in mind, many interesting problems
remain, even in high dimensions, that are well described by
cumulants of low dimensional marginal distributions, as the
ICA example has illustrated.

The sensitivity to outliers can be tuned with the parameter
α2 ∈ [1, 2). Our experiments have shown that if one in-
cludes many orders in the expansion, optimal performance
was obtained when α2 was close to (but smaller than) 2.
Although unmistakeably some information is ignored by
weighting down the impact of outliers, the experiments in-
dicated that the relevant information to estimate the PDF
was mostly preserved. In future experiments we hope to
show that this phenomenon is also reﬂected in improved
performance of ICA algorithms based on robust cumulants.

A ROBUST MOMENTS AND

CUMULANTS TO 4’TH ORDER

This appendix contains the deﬁnition of the cumulants in
terms of the moments and vice versa for general α. We
have not denoted α explicitely in the following for nota-

(c)

(d)

Figure 5: Top row: total L2 distance between true and estimated
densities as function of α2 for generalized Laplace density with
(a) a = 1, (b) a = 4. Bottom row: same as top row for the
mixture of Gaussians distributions with (c) µ = 0.3, c = 3, d = 0
and (d) µ = 0.5, c = 3. The corresponding densities are shown
in ﬁgure 4. Dashed line indicates the best estimate over all orders.

4a,c), a sub-Gaussian density (ﬁgures 4b) and an asymmet-
ric density (ﬁgures 4d). We plot the total L2 distance be-
tween the estimate and the true density as we vary α (ﬁg-
ures 5a,b,c,d). Shown is the best estimate over all orders or-
ders (dashed line) and the ﬁnal estimate after 20 orders. In
both cases it is observed that the best estimates are obtained
around α2 ≈ 2 (but recall that α2 < 2, see section 4. We
also plot the L2 distance between true and estimated den-
sity as a function of the order of the expansion for α2 = 1
and α2 = 1.9 (a = 1) in ﬁgures (6a,b). Clearly, the robust
expansion converges while the classical expansion is un-
stable. Finally, in ﬁgure 7 we compare the best estimated
PDFs for the general Laplace density at a = 1 with α2 = 1
(a) and α2 = 1.9 (b).

The general conclusion from these experiments is that in
all cases (super- or sub-Gaussian PDF, symmetric or asym-
metric PDF) we ﬁnd that the quality (in L2-norm) of the
estimated densities improves considerably when we use the
robust series expansion with a setting of α2 close to (but
smaller than) 2. This effect is more pronounced for super-
Gaussian densities than for sub-Gaussian densities.

8 DISCUSSION

In this paper we have proposed robust alternatives to higher
order moments and cumulants. In order to arrive at robust

11.21.41.61.8200.0020.0040.0060.0080.010.012α2L2−distance between pdf and estimateQuality of fit for exponential density (a=1)11.21.41.61.821.522.5x 10−4α2L2−distance between pdf and estimate          Quality of fit for exponential density (a=4)11.21.41.61.8200.010.020.030.040.05α2L2−distance between pdf and estimateQuality of fit for mixture of Gaussians (µ=0.3, c=3, d=0)11.21.41.61.82123456x 10−3α2L2−distance between pdf and estimate              Quality of fit for mix. of Gauss. (µ=0.5, c=3, d=2)0510152000.010.020.030.040.050.060.070.08order of expansionL2−distance between pdf and estimateL2 distance for exponential density (a=1, α=1)0510152000.0050.010.0150.020.0250.03order of expansionL2−distance between pdf and estimateL2 distance for exponential density (a=1, α=1.9)411generating function of p(x). We can ﬁnd an expression for
p(x) if we invert the Fourier transform,

p(x) = αφ(x)
φ(αx)

1
2π

e−iαxtΨ(α)(t) dt.

(28)

Next, we use the relation between the cumulants and the
moments (Eq.7) to write,

(cid:90) ∞

−∞

(cid:90) ∞

(cid:80)∞

e−iαxt e

n=0

n! κ(α)
1

n (it)n

dt.

−∞
(29)
n − δn,2 we can separate a factor

p(x) = αφ(x)
φ(αx)

1
2π

n = κ(α)

By deﬁning ˜κ(α)
φ(t) (Gaussian) inside the integral,
p(x) = αφ(x)
φ(αx)

(cid:90) ∞

e−iαxt e

1√
2π

−∞

(cid:80)∞

Finally, we will need the result

n=0

n! ˜κ(α)
1

n (it)n

φ(t) dt.

√

2π
α

(−1)n

dn

d(αx)n φ(αx).

(30)

(31)

(a)

(b)

Figure 7: Best estimates for the generalized Laplace density at
a = 1. In (a) we plot the best classical estimate which is found
after four orders of Hermite polynomials are taken into account
(i.e. H0(x), ..., H4(x)). For higher orders, the series becomes
unstable and the calculation of the expansion coefﬁcients is too
sensitive to sample ﬂuctuations. The best estimate from the robust
expansion is depicted in (b). In that case the best estimate is found
when all orders are taken into account, i.e. 20.

tional convenience.

F−1[(it)nφ(t)] =

)3

κ1 = µ1
µ0
− 3 µ1µ2
+ 2( µ1
µ2
µ0
0
)2 − 4 µ1µ3
− 3( µ2
µ2
µ0
0
µ1
µ0

= κ1

κ2 = µ2
µ0

− ( µ1
µ0

)2

)4

− 6( µ1
µ0

+ 12 µ2
1µ2
µ3
0
µ2
= κ2 + κ2
1
µ0

= κ3 + 3κ2κ1 + κ3
1

= κ4 + 4κ3κ1 + 3κ2

2 + 6κ2κ2

1 + κ4

1

κ0 = ln µ0
κ3 = µ3
µ0
κ4 = µ4
µ0
µ0 = eκ0
µ3
µ0
µ4
µ0

B PROOF OF THEOREM 2

(cid:90) ∞

−∞

The characteristic function or moment generating function
of a PDF is deﬁned by:

Ψ(t) =

eixtp(x) dx =

1
n! µn(it)n = F[p(x)]

(26)
where the last term follows from Taylor expanding the ex-
ponential and F denotes the Fourier transform. For arbi-
trary α we have,

∞(cid:88)

n=0

(cid:90) ∞

−∞

∞(cid:88)

n=0

=

Ψ(α)(t) =

eiαxtp(x) φ(αx)

φ(x) dx

1

n! µ(α)n(it)ndx = F[p(x) φ(αx)

αφ(x)

].

(27)

Where in the last equality the deﬁnition of the generalized
moments (Eq.6) was used. Ψ(α) is the (robust) moment

If we expand the exponential containing the cumulants in a
Taylor series, and do the inverse Fourier transform on every
term separately, after which we combine the terms again in
an exponential, we ﬁnd the desired result (Eq.14).

References

[1] S. Amari, A. Cichocki, and H.H. Yang. A new algorithm
for blind signal separation. Advances in Neural Information
Processing Systems, 8:757–763, 1996.

[2] A.J. Bell and T.J. Sejnowski. The independent components
of natural scenes are edge ﬁlters. Vision Research, 37:3327–
3338, 1997.

[3] J.F. Cardoso. High-order constrast for independent compo-

nent analysis. Neural Computation, 11:157–192, 1999.

[4] P. Comon. Independent component analysis, a new concept?

Signal Processing, 36:287–314, 1994.

[5] F.R. Hampel, E.M. Ronchetti, P.J. Rousseuw, and W.A. Sta-

hel. Robust statistics. Wiley, 1986.

[6] P.J. Huber. Robust statistics. Wiley, 1981.

[7] A. Hyv¨arinen. New approximations of differential entropy
for independent component analysis and projection pursuit.
In Advances in Neural Information Processing Systems, vol-
ume 10, pages 273–279, 1998.

[8] M.G. Kendall and A. Stuart. The advanced theory of statis-

tics Vol. 1. Grifﬁn, 1963.

[9] P. McCullagh. Tensor Methods in Statistics. Chapman and

Hall, 1987.

[10] M. Welling and M. Weber. A constrained EM algorithm
for independent component analysis. Neural Computation,
13:677–689, 2001.

−10−5051000.10.20.30.40.50.60.70.8xp(x)Best estimate for exponential density (a=1,α=1)−10−5051000.10.20.30.40.50.60.70.8xp(x)Best estimate for exponential density (a=1,α=1.9)412Online (and Ofﬂine) on an Even Tighter Budget

Jason Weston

NEC Laboratories

America,
Princeton,
NJ, USA

Antoine Bordes
NEC Laboratories

America,
Princeton,
NJ, USA

Leon Bottou

NEC Laboratories

America,
Princeton,
NJ, USA

jasonw@nec-labs.com

antoine@nec-labs.com

leonb@nec-labs.com

Abstract

We develop a fast online kernel algorithm for
classiﬁcation which can be viewed as an im-
provement over the one suggested by (Crammer,
Kandola and Singer, 2004), titled ”Online Clas-
siﬁcaton on a Budget”.
In that previous work,
the authors introduced an on-the-ﬂy compression
of the number of examples used in the prediction
function using the size of the margin as a qual-
ity measure. Although displaying impressive re-
sults on relatively noise-free data we show how
their algorithm is susceptible in noisy problems.
Utilizing a new quality measure for an included
example, namely the error induced on a selected
subset of the training data, we gain improved
compression rates and insensitivity to noise over
the existing approach. Our method is also ex-
tendable to the batch training mode case.

1 Introduction

Rosenblatt’s Perceptron (Rosenblatt, 1957) efﬁciently con-
structs a hyperplane separating labeled examples (x i, yi) ∈
n × {−1, +1}. Memory requirements are minimal be-
(cid:1)
cause the Perceptron is an online algorithm: each iteration
considers a single example and updates a candidate hyper-
plane accordingly. Yet it globally converges to a separating
hyperplane if such a hyperplane exists.

The Perceptron returns an arbitrary separating hyperplane
regardless of the minimal distance, or margin, between the
hyperplane and the examples.
In contrast, the General-
ized Portrait algorithm (Vapnik and Lerner, 1963) explictly
seeks an hyperplane with maximal margins.

All the above methods produce a hyperplane whose normal
vector is expressed as a linear combination of examples.
Both training and recognition can be carried out with the
only knowledge of the dot products x(cid:1)
ixj between exam-
ples. Support Vector Machines (Boser, Guyon and Vapnik,

1992) produce maximum margin non-linear separating hy-
persurfaces by simply replacing the dot products by a Mer-
cer kernel K(xi, xj).

Neither the Generalized Portrait nor the Support Vector
Machines (SVM) are online algorithms. A set of training
examples must be gathered (and stored in memory) prior
to running the algorithm. Several authors have proposed
online Perceptron variants that feature both the margin and
kernel properties. Example of such algorithms include the
Relaxed Online Maximum Margin Algorithm (ROMMA)
(Li and Long, 2002), the Approximate Maximal Margin
Classiﬁcation Algorithms (ALMA) (Gentile, 2001), and
the Margin Infused Relaxed Algorihm (MIRA) (Crammer
and Singer, 2003).
The computational requirements1 of kernel algorithms are
closely related to the sparsity of the linear combination
deﬁning the separating hyper-surface. Each iteration of
most Perceptron variants considers a single example and
decides whether to insert it into the linear combination. The
Budget Perceptron (Crammer, Kandola and Singer, 2004)
achieves greater sparsity by also trying to remove some of
the examples already present in the linear combination.

This discussion only applies to the case where all examples
can be separated by a hyperplane or a hypersurface, that
is to say in the absence of noise. Support Vector Machines
use Soft Margins (Cortes and Vapnik, 1995) to handle noisy
examples at the expense of sparsity. Even in the case where
the training examples can be separated, using Soft Margins
often improves the test error. Noisy data sharply degrades
the performance of all the Perceptron variants discussed
above.

We propose a variant of the Perceptron algorithm that ad-
dresses this problem by removing examples from the lin-
ear combination on the basis of a direct measurement of
the training error in the spirit of Kernel Matching Pursuit
(KMP) (Vincent and Bengio, 2000). We show that this al-
gorithm has good performance on both noisy and non-noisy
data.

1and sometimes the generalization properties

4132 Learning on a Budget

Figure 1 shows the Budget Perceptron algorithm (Cram-
mer, Kandola and Singer, 2004). Like Rosenblatt’s Per-
ceptron, this algorithm ensures that the hyperplane normal
wt can always be expressed as a linear combination of the
examples in set Ct:

wt = (cid:1)
i∈Ct

αixi.

(1)

Whereas Rosenblatt’s Perceptron updates the hyperplane
normal wt whenever the current example (x t, yt) is mis-
classiﬁed, the Budget Perceptron updates the normal when-
ever the margin is smaller than a predeﬁned parameter
β > 0, that is to say whenever yt(xt · wt) < β.
Choosing a large β ensures that the hyperplane will eventu-
ally become close to the maximal margin hyperplane. This
also increases the likelihood that an arbitrary example will
become part of the expansion (1) and make the ﬁnal solu-
tion less sparse.

The Budget Perceptron addresses this problem with a re-
moval process. Whenever the number of expansion exam-
ples exceeds a predeﬁned threshold p, the removal process
excludes one example from the expansion. More speciﬁ-
cally, the removal process (steps 1a–1c, ﬁgure 1) simulates
the removal of each example and eventually selects the ex-
ample i that, when removed, remains recognized with the
largest margin:

i = arg max

j∈Ct

{yj(wt−1 − αjyjxj) · xj}

The justiﬁcation for such a strategy is that the Perceptron
algorithm only adds examples to the cache when they are
errors. Early on in the training, examples may be added
because the decision rule learnt thus far is relatively inac-
curate, however later on these examples may be well classi-
ﬁed as the direction of the hyperplane has changed consid-
erably. The standard Perceptron algorithm does not have
any removal procedure.

Several variants of this algorithms can be derived by chang-
ing the update formula (ﬁgure 2) or by replacing the dot
products by suitable kernel functions. The maximum size
of the expansion can be ﬁxed or variable (Crammer, Kan-
dola and Singer, 2004). Essentially, to adapt to the vari-
able case one removes all examples that violate y j(wt−1 −
αjyjxj)·xj < β on each iteration. For simplicity however,
in the remainder of the paper we will present algorithms in
the simplest linear setup with Perceptron update and ﬁxed
sized cache, and leave such variants to the reader.

Experimental results (Crammer, Kandola and Singer, 2004)
demonstrate that
the Budget Perceptron performs ex-
tremely well on relatively noiseless problems. However, it
degrades quickly on noisy problems. Suppose for instance

Input: Margin β > 0, Cache Limit p.
Initialize: Set ∀t αt = 0, w0 = 0, C0 = ∅
Loop: For t = 1, . . . , T

n, yt = ±1.

– Get a new instance xt ∈ (cid:1)
– Predict ˆyt = sign(yt(xt · wt−1))
– If yt(xt · wt−1) ≤ β update:

1. If |Ct| = p remove one example:

{yj (wt−1 − αjyj xj) · xj}

j∈Ct

a Find i = arg max
b Update wt−1 ← wt−1 − αiyixi.
c Remove Ct−1 ← Ct−1 \ {i}.

2. Insert Ct ← Ct−1 ∪ {t}.
3. Set αt = 1.
4. Compute wt ← wt−1 + αtytxt.

Output: H(x) = sign(wT · x).

Figure 1: The Budget Perceptron algorithm (Crammer,
Kandola and Singer, 2004).

that we randomly ﬂip the labels of a small proportion η of
both the training and test examples. The misclassiﬁcation
rate of the best hyperplane is at least η. Such misclassi-
ﬁed examples accumulate into the Budget Perceptron ex-
pansion because only examples which are classiﬁed well
are removed. Mislabeled examples reverse the direction of
the normal wt, and poor performance follows.

Complexity Assuming we use an RBF kernel, the inser-
tion step requires O(pn) operations where p is the cache
size and n is the input dimensionality. The deletion step
requires O(p) operations, assuming all kernel calculations
are cached. Note that the latter cost is only incurred for
margin errors when the cache is full.

Perceptron (Rosenblatt, 1957)

αt = 1

MIRA (Crammer and Singer, 2003)

αt = min„1, max „0,

−yi(w · xi)

xi · xi

««

No-Bias-SVM (Kecman, Vogt and Huang, 2003) β = 1

αt = min„C, max„0, 1 − yi(w · xi)

xi · xi

««

Figure 2: Update Rules for Various Algorithms. These
can be used to replace step 3 in ﬁgure 1 or 3.

4143 Learning on a Tighter Budget

The Budget Perceptron removal process simulates the re-
moval of each example and eventually selects the exam-
ple that remains recognized with the largest margin. This
margin can be viewed as an indirect estimate of the impact
of the removal on the overall performance of the hyper-
plane. Thus, to improve the Budget algorithm we propose
to replace this indirect estimate by a direct evaluation of the
misclassiﬁcation rate. We term this algorithm the Tighter
Budget Perceptron. The idea is simply to replace the mea-
sure of margin

i = arg max

j∈Ct

{yj(wt−1 − αjyjxj) · xj}

(2)

with the overall error rate on all currently seen examples:

i = arg min
j∈Ct

{ t
(cid:1)

k=1

L(yk, sign((wt−1 − αjyjxj) · xk)}.

Intuitively, if an example is well classiﬁed (has a large mar-
gin) then not only will it be correctly classiﬁed when it is
removed as in equation (2) but also all other examples will
still be well classiﬁed as well. On the other hand, if an ex-
ample is an outlier then its contribution to the expansion of
w is likely to classify points incorrectly. Therefore when
removing an example from the cache one is likely to either
remove noise points or well-classiﬁed points ﬁrst. Apart
from when the kernel matrix has very low rank we do in-
deed observe this behaviour, e.g. in ﬁgure 8.

Compared to the original Budget Perceptron, this removal
rule is more expensive to compute, now it requires O(t(p +
n)) operations (see section 2). Therefore in section 3.2 we
discuss ways of approximating this computation whilst still
retaining its desirable properties. First, however we dis-
cuss the relationship between this algorithm and existing
approaches.

3.1 Relation to Other Algorithms

Kernel Matching Pursuit The idea of kernel matching
pursuit (KMP) (Vincent and Bengio, 2000) is to build a
predictor w = (cid:2)i αixi greedily by adding one example at
a time, until a pre-chosen cache size p is found. The ex-
ample to add is chosen by searching for the example which
gives the largest decrease in error rate, usually in terms of
squared loss, but other choices of loss function are possible.
While this procedure is for batch learning, and not online
learning, clearly this criteria for addition is the same as our
criteria for deletion.

There are various variants of KMP, two of them called
basic- and backﬁtting- are described in ﬁgure 4. Basic
adapts only a single αi in the insertion step, whereas back-
ﬁtting adjusts all αi of previously chosen points. The latter

Input: Margin β > 0, Cache Limit p.
Initialize: Set ∀t αt = 0, w0 = 0, C0 = ∅.
Loop: For t = 1, . . . , T

n, yt = ±1.

– Get a new instance xt ∈ (cid:1)
– Predict ˆyt = sign(yt(xt · wt−1)).
– Get a new label yt.
– If yt(xt · wt−1) ≤ β update:

1. If |Ct| = p remove one example:

L(yk, sign((wt−1 − αj yjxj) ·

t
k=1

a Find i = arg minj∈Ct
{
(cid:2)
xk)}.
b Update wt−1 ← wt−1 − αiyixi
c Remove Ct−1 ← Ct−1 \ {i}.

2. Insert Ct ← Ct−1 ∪ {t}.
3. Set αt = 1.
4. Compute wt ← wt−1 + αtytxt.

Output: H(x) = sign(wT · x).

Figure 3: The Tighter Budget Perceptron algorithm.

can be computed efﬁciently if the kernel matrix can be ﬁt
into memory (the algorithm is given in (Vincent and Ben-
gio, 2000)), but is expensive for large datasets. The basic
algorithm, on the other hand does not perform well for clas-
siﬁcation, as shown in ﬁgure 8.

Note that we could adapt our algorithm’s addition step to
also be based on training error. However, using the Percep-
tron rule, an example is only added to the cache if it is an
error, making it more efﬁcient to compute. Note that vari-
ants of KMP have also been introduced that incorporate a
deletion as well as an insertion step (Nair, Choudhury and
Keane, 2002).

Condense and Multi-edit Condense and multi-edit (De-
vijver and Kittler, 1982) are editing algorithms to ”spar-
sify” k-NN. Condense removes examples that are far from
the decision boundary. The Perceptron and the SVM al-
ready have their own ”condense” step as such points typi-
cally have αi = 0. The Budget Perceptron is an attempt to
make the condense step of the Perceptron more aggressive.
Multi-edit attempts to remove all the examples that are on
the wrong side of the Bayes decision boundary. One is
then left with learning a decision rule with non-overlapping
classes with the same Bayes decision boundary as before,
but with Bayes risk equal to zero. Note that neither the Per-
ceptron nor the SVM (with soft margin) perform this step 2,
and all incorrectly classiﬁed examples become support vec-

2An algorithm designed to combine the multi-edit step into

SVMs is developed in (Bakır, Bottou and Weston, 2004).

415Input: Cache Limit p.
Initialize: Set ∀t αt = 0, w0 = 0, C0 = ∅.
Loop: For t = 1, . . . , p

(yj − (wt + αxj ) · xi)2.

– Choose (k, α) =
X

arg min
α, j=1...m

m

i=1

– Insert Ct ← Ct−1 ∪ {t}.
– Basic-KMP:
Set wt ← wt−1 + αxk.
Backﬁtting-KMP:
Set wt ← (cid:1)
i∈Ct

m

αixi where {αi} =

arg min

 yj − X
i∈Ct
Output: H(x) = sign(wT · x).

X

{αi}

j=1

αixi · xj)!2

Figure 4: The Basic and Backﬁtting Kernel Matching Pur-
suit (KMP) Algorithms (Vincent and Bengio, 2000).

tors with αi > 0. Combining condense and multi-edit to-
gether one only tries to keep the correctly classiﬁed exam-
ples close to the decision boundary. The Tighter Budget
Perceptron is also an approximate way of trying to achieve
these two goals, as previously discussed.

Regularization One could also view the Tighter Budget
Perceptron as an approximation of minimizing a regular-
ized objective of the form

1

m (cid:1) L(yi, f(xi)) + γ||α||0.

where operator || · ||0 is deﬁned as counting the number
of nonzero coefﬁcients. That is to say, the ﬁxed sized
cache chosen acts a regularizer to reduce the capacity of the
set of functions implementable by the Perceptron rule, the
goal of which is to minimize the classiﬁcation loss. This
means that for noisy problems, with a reduced cache size
one should see improved generalization error compared to
a standard Perceptron using the Tighter Budget Perceptron,
and we indeed ﬁnd experimentally that this is the case.

3.2 Making the per-time-step complexity bounded by

a constant independent of t

An important requirement of online algorithms is that their
per-time-step complexity should be bounded by a constant
independent of t (t being the time-step index), for it is as-
sumed that samples arrive at a constant rate. The algorithm
in ﬁgure 3 grows linearly in the time, t, because of the com-
putation in step 1(a), that is when we choose the example

Input: Qt−1, xt, s
– Qt ← Qt−1 ∪ xt.
– If |Qt| > q

1. i = arg maxi∈Qt−1 si
2. Qt ← Qt \ xi

Output: Qt

Figure 5: Algorithm for maintaining a ﬁxed cache size q
of relevant examples for estimating the training error. The
idea is to maintain a count si of the number of times the
prediction changes label for example i. One then retains
the examples which change labels most often.

in the cache to delete which results in the minimal loss over
all t observations:
{ t
(cid:1)

L(yk, sign((wt−1 − αjyjxj) · xk)}.

i = arg min
j∈Ct

k=1

(Note that this extra computational expense is only invoked
when xt is a margin error, which if the problem has a low
error rate, is only on a small fraction of the iterations.) Nev-
ertheless, it is possible to consider approximations to this
equation to make the algorithm independent of t.

We could simply reduce the measure of loss to only the
ﬁxed p examples in the cache:

{ (cid:1)
k∈Ct

i = arg min
j∈Ct

L(yk, sign((wt−1 − αjyjxj) · xk)}.
(3)
While this is faster to compute, it may be suboptimal as we
wish to have an estimator of the loss that is as unbiased as
possible, and the points that are selected in the cache are a
biased sample. However, they do have the advantage that
many of them may be close to the decision surface.

A more unbiased sample could be chosen simply by pick-
ing a ﬁxed number of randomly chosen examples, say q
examples, where we choose q in advance. We deﬁne this
subset as Qt, where |Qt| = min(q, t) which is taken from
the t available examples until the cache is ﬁlled. Then we
compute:

i = arg min
j∈Ct

{ (cid:1)
k∈Qt

L(yk, sign((wt−1 − αjyjxj) · xk)}.
(4)

The problem with this strategy is that many of these exam-
ples may be either very easy to classify or always misla-
beled (noise) so this could be wastful.

We therefore suggest a secondary caching scheme to
choose the q examples with which we estimate the error.
We wish to keep the examples that are most likely to change

416label as these are most likely to give us information about
the performance of the classiﬁer.
If an example is well
classiﬁed it will not change label easily when the classi-
ﬁer changes slightly. Likewise, if an example is an outlier
it will be consisently incorrectly classiﬁed. In fact the num-
ber of examples that are relevant in this context should be
relatively small. We therefore keep a count s i of the num-
ber of times example xi has changed label, divided by the
amount of time it has been in the cache. If this value is
small then we can consider removing this point from the
secondary cache. When we receive a new observation at x t
at time t we thus perform the update given in ﬁgure 5 in the
case that xt is a margin error.

Complexity The last variant of the Tighter Budget Per-
ceptron has a deletion step cost of O(pq + qn) operations,
where p is the cache size, q is the secondary cache size, and
n is the input dimensionality. This should be compared to
O(p) for the Budget Perceptron, where clearly the deletion
step is still less expensive.

In the case of relatively noise free problems with a reason-
able cache size p, the deletion step occurs infrequently: by
the time the cache becomes full, the perceptron performs
well enough to make margin errors rare. The insertion step
then dominates the computational cost. In the case of noisy
problems, the cheaper deletion step of the Budget Percep-
tron performs too poorly to be considered a valid alterna-
tive. Moreover, as we shall see experimentally, the Tighter
Budget Perceptron can achieve the same test error as the
Budget Perceptron for smaller cache size p.

4 Experiments

4.1 2D Experiments - Online mode

Figure 6 shows a 2D classiﬁcation problem of 1000 points
from two classes separated by a very small margin. We
show the decision rule found after one epoch of Percep-
tron, Budget Perceptron and Tighter Budget Perceptron
training, using a linear kernel. Both Budget Perceptrons
variants produce sparser solutions than the Perceptron, al-
though the Budget Perceptron provides slightly less accu-
rate solutions, even for larger cache sizes. Figure 7 shows a
similar dataset, but with overlapping classes. The Percep-
tron algorithm will fail to converge with multiple epochs in
this case. After one epoch a decision rule is obtained with a
relatively large number of SVs. Most examples which are
3
on the wrong side of the Bayes decision rule are SVs.
The Budget Perceptron fails to alleviate this problem. Al-
though one can reduce the cache size to force more sparsity,
the decision rule obtained is highly inaccurate. This is due
to noise points which are far from the decision boundary

3Note that support vector machines, not shown, also suffer
from a similar deﬁciency in terms of sparsity - all incorrectly clas-
siﬁed examples are SVs.

Perceptron (16 SVs)

Tighter Budget Ptron (5 SVs)

Budget Perceptron (5 SVs)

Budget Perceptron (10 SVs)

Figure 6: Separable Toy Data in Online Mode. The Bud-
get Perceptron of (Crammer, Kandola and Singer, 2004)
and our Tighter Budget Perceptron provide sparser solu-
tions than the Perceptron algorithm, however the Budget
Perceptron seems sometimes to provide slightly worse so-
lutions.

being the last vectors to be removed from the cache, as can
be seen in the example with a cache size of 50.

4.2 2D Experiments - Batch mode

Figure 8 shows a 2D binary classiﬁcation problem with the
decision surface found by the Tighter Budget Perceptron,
Budget Perceptron, Perceptron, SVM, and two ﬂavors of
KMP when using the same Gaussian kernel. For the on-
line algorithms we ran multiple epochs over the dataset
until convergence. This example gives a simple demon-
stration of how the Budget and Tighter Budget Perceptrons
can achieve a greater level of sparsity than the Perceptron,
whilst choosing examples that are close to the margin, in
constrast to the KMP algorithm.

Where possible in the ﬁxed cache algorithms, we ﬁxed the
cache sizes to 10 SVs (examples highlighted with squares),
as a trained SVM uses this number. The Perceptron is not
as sparse as SVM, and uses 19 SVs. However both the
Budget Perceptron and the Tighter Budget Perceptron still
separate the data with 10 SVs. The Perceptron required 14
epochs to converge, the Tighter Budget Perceptron required
22, the Budget Perceptron required 26 (however, we had to
decrease the width of the Gaussian kernel for the last algo-
rithm as it did not converge for larger widths). Backﬁtting-
KMP provides as good sparsity as SVM. Basic-KMP does
not give zero error even after 400 iterations, and by this
time has used 37 SVs (it cycles around the same SVs many
times). Note that all the algorithms except KMP choose

417Perceptron (103 SVs)

Tighter Budget Ptron (5 SVs)

Perceptron (19 SVs)

Tighter Budget Ptron (10 SVs)

Budget Perceptron (5 SVs)

Budget Perceptron (50 SVs)

Budget Perceptron (10 SVs)

basic-KMP (37 SVs)

Figure 7: Noisy Toy Data in Online Mode. The Percep-
tron and Budget Perceptron (independent of cache size)
fail when problems contain noise, as demonstrated by a
simple 2D problem with Gaussian noise in one dimension.
The Tighter Budget Perceptron, however, ﬁnds a separation
very close to the Bayes rule.

SVs close to the margin.

4.3 Benchmark Datasets

We conducted experiments on three well-known datasets:
the US Postal Service (USPS) Database, Waveform and
Banana4. A summary of the datasets is given in Table 1.
For all three cases (USPS,Waveform,Banana) we chose an
RBF kernel, the width values were taken from (Vapnik,
1998) and (R¨atsch, Onoda and M¨uller, 2001), and are cho-
sen to be optimal for SVMs, the latter two by cross vali-
dation. We used the same widths for all other algorithms,
despite that these may be suboptimal in these cases. For
USPS we considered the two class problem of separating
digit zero from the rest. We also constructed a second ex-
periment by corrupting USPS with label noise. We ran-
domly ﬂipped the labels of 10% of the data in the training
set to observe the performance effects on the algorithms
tested (for SVMs, we report the test error with the optimal
value of C chosen on the test set, in this case, C = 10).

We tested the Tighter Budget Perceptron, Budget Percep-
tron and Perceptron in an online setting by only allowing
one pass through the training data. Obviously this puts
these algorithms at a disadvantage compared to batch al-
gorithms such as SVMs which can look at training points
multiple times. Nevertheless, we compare with SVMs as

4USPS is available at ftp://ftp.kyb.tuebingen.
mpg.de/pub/bs/data. Waveform and Banana are available
at http://mlg.anu.edu.au/˜raetsch/data/.

backﬁtting-KMP (10 SVs)

SVM (10 SVs)

Figure 8: Nonlinear Toy Data in Batch Mode. We com-
pare various algorithms on a simple nonlinear dataset fol-
lowing (Vincent and Bengio, 2000). See the text for more
explanation.

our gold standard measure of performance. The results are
given in ﬁgures 9-12. In all cases for the Perceptron vari-
ants we use β = 0 and for the Tighter Budget Perceptron
we employ the algorithm given in ﬁgure 3 without the com-
putational efﬁciency techniques given in section 3.2. We
show the test error against different ﬁxed cache sizes p re-
sulting in p support vectors. We report averages over 5 runs
for USPS and 10 runs for Waveform and Banana. The er-
ror bars indicate the maximum and minimum values over
all runs.

The results show the Tighter Budget Perceptron yielding
similar test error performance to the SVM but with consid-
erably less SVs. The Budget Perceptron fares less well with

Inputs Train Test
Name
2000
USPS
256
1000
Waveform 21
Banana
2
1300

7329
4000
4000

σ
128
3.16
0.7

C
1000
1
316

Table 1: Datasets used in the experiments. The hyper-
parameters are for an SVM with RBF kernel, taken from
(Vapnik, 1998) and (R¨atsch, Onoda and M¨uller, 2001).

418Budget Perceptron
Tighter Budget Perceptron
Tighter Budget Pton (10 epochs)
SVM
Perceptron
Perceptron (10 epochs)

50

100

SVs

150

200

250

Figure 9: USPS Digit 0 vs Rest.

Budget Perceptron
Tighter Budget Perceptron
SVM
Perceptron
Perceptron (10 epochs)

r
o
r
r

E

 
t
s
e
T

0.08

0.07

0.06

0.05

0.04

0.03

0.02

0.01

0
0

r
o
r
r

E

 
t
s
e
T

0.08

0.07

0.06

0.05

0.04

0.03

0.02

0.01

0
7

20

55

148
SVs

403

1097

2981

Figure 10: USPS Digit 0 vs Rest + 10% noise.

the test error degrading considerably faster for decreasing
cache size compared to the Tighter Budget Perceptron, par-
ticularly on the noisy problems. Note that if the cache
size is large enough both the Budget and Tighter Budget
Perceptrons converge to the Perceptron solution, hence the
two curves meet at their furthest point. However, while the
test error immediately degrades for the Budget Perceptron,
for the Tighter Budget Perceptron the test error in fact im-
proves over the Perceptron test error in both the noisy prob-
lems. This should be expected as the standard Perceptron
cannot deal with overlapping classes.

In ﬁgure 9 we also show the Tighter Budget Perceptron
with (up to) 10 epochs on USPS (typically the algorithm
converges before 10 epochs). The performance is similar to
only 1 epoch for small cache sizes. For larger cache sizes,
clearly the maximum cache size converges to the same per-
formance of a Perceptron with 10 epochs, which in this
case gives slightly better performance than any cache size
possible with 1 epoch.

4.4 Faster Error Computation

In this section we explore the error evaluation cache strate-
gies described previously in section 3.2. We compared the
following strategies to evaluate error rates: (i) using all

Budget Perceptron
Tighter Budget Perceptron
SVM
Perceptron
Perceptron (10 epochs)

200

400

SVs

600

800

1000

Figure 11: Waveform Dataset.

Budget Perceptron
Tighter Budget Perceptron
SVM
Perceptron
Perceptron (10 epochs)

0.3

0.25

0.2

0.15

r
o
r
r

E

 
t
s
e
T

0.1

0.05

0.5

0.45

0.4

0.35

0.3

0.25

0.2

0.15

0.1

r
o
r
r

E

 
t
s
e
T

200

400

SVs

600

800

Figure 12: Banana Dataset.

points so far seen, (ii) using only the support vectors in the
cache, i.e. equation (3), (iii) using a random cache of size
q, i.e. equation (4), and (iv) using a cache of size q of the
examples that ﬂip label most often, i.e. ﬁgure 5.

Figure 13 compares these methods on the USPS dataset for
ﬁxed cache size of support vectors p = 35 and p = 85. The
results are averaged over 40 runs (the error bars show the
standard error).
We compare different amounts of evaluation vectors q. The
results show that considerable computational speedup can
be gained by any of the methods compared to keeping all
training vectors. Keeping a cache of examples that change
label most often performs better than a random cache for
small cache sizes. Using the support vectors themselves
also performs better than the random strategy for the same
cache size. This makes sense as support vectors them-
selves are likely to be examples that can change label easily,
making it similar to the cache of examples that most often
change label. Nevertheless, it can be worthwhile to have a
small number of support vectors for fast evaluation, but a
larger set of error evaluation vectors when an error is en-
countered. We suggest to choose q and p such that a cache
of the qp kernel calculations ﬁts in memory at all times.

419Random Cache
Most flipped in Cache
Only SVs in cache

Part of this work was funded by NSF grant CCR-0325463.

2000

4000

6000

Error−Evaluation Cache Size (Q)

Random Cache
Most flipped in Cache
Only SVs in cache

2000

4000

6000

Error−Evaluation Cache Size (Q)

0.04

0.03

r
o
r
r

E

 
t
s
e
T

0.02

0.01

7

0.04

0.03

r
o
r
r

E

 
t
s
e
T

0.02

0.01

7

2981
Error−Evaluation Cache Size (Q)

403

55

2981
Error−Evaluation Cache Size (Q)

403

55

0.04

0.03

r
o
r
r

E

 
t
s
e
T

0.02

0.01

0

0.04

0.03

r
o
r
r

E

 
t
s
e
T

0.02

0.01

0

Figure 13: Error Rates for Different Error Measure
Cache Strategies on USPS, digit zero versus the rest.
The number of SVs is ﬁxed to 35 in the top row, and 85
in the bottom row, the left-hand plots are log plots of the
right-hand ones. The different strategies change the num-
ber of points used to evaluate the error rate for the SV cache
deletion process.

5 Summary

We have introduced a sparse online algorithm that is a vari-
ant of the Perceptron.
It attempts to deal with some of
the computational issues of using kernel algorithms in an
online setting by restricting the number of SVs one can
use. It also allows methods such as the Perceptron to deal
with overlapping classes and noise. It can be considered
as an improvement over the Budget Perceptron of (Cram-
mer, Kandola and Singer, 2004) because it is empirically
sparser than that method for the same error rate, and can
handles noisy problems while that method cannot. Our
method tends to keep only points that are close to the mar-
gin and that lie on the correct side of the Bayes decision
rule. This occurs because other examples are less useful
for describing a decision rule with low error rate, which is
the quality measure we use for inclusion in to the cache.

However, the cost of this is that quality measure used
to evaluate training points is more expensive to compute
than for the Budget Perceptron (and in this sense the
name ”Tighter Budget Perceptron” is slightly misleading).
However, we believe there exist various approximations to
speed up this method whilst retaining its useful properties.
We explored some strategies in this vein by introducing a
small secondary cache of evaluation vectors with positive
results. Future work should investigate further ways to im-
prove on this, some ﬁrst suggestions being to only look at
a subset of points to remove on each iteration, or to remove
the worst n points every n iterations.

Acknowledgements

References

Bakır, G., Bottou, L., and Weston, J. (2004). Breaking SVM
Complexity with Cross-Training. In Advances in Neural In-
formation Processing Systems 17 (NIPS 2004). MIT Press,
Cambridge, MA. to appear.

Boser, B. E., Guyon, I. M., and Vapnik, V. (1992). A Training Al-
gorithm for Optimal Margin Classiﬁers. In Haussler, D., ed-
itor, Proceedings of the 5th Annual ACM Workshop on Com-
putational Learning Theory, pages 144–152, Pittsburgh, PA.
ACM Press.

Cortes, C. and Vapnik, V. (1995). Support Vector Networks. Ma-

chine Learning, 20:273–297.

Crammer, K., Kandola, J., and Singer, Y. (2004). Online Classi-
ﬁcation on a Budget. In Thrun, S., Saul, L., and Sch¨olkopf,
B., editors, Advances in Neural Information Processing Sys-
tems 16. MIT Press, Cambridge, MA.

Crammer, K. and Singer, Y. (2003). Ultraconservative Online
Algorithms for Multiclass Problems. Journal of Machine
Learning Research, 3:951–991.

Devijver, P. and Kittler, J. (1982). Pattern Recogniton, A statisti-

cal approach. Prentice Hall, Englewood Cliffs.

Gentile, C. (2001). A New Approximate Maximal Margin Classi-
ﬁcation Algorithm. Journal of Machine Learning Research,
2:213–242.

Kecman, V., Vogt, M., and Huang, T. (2003). On the Equality
of Kernel AdaTron and Sequential Minimal Optimization in
Classiﬁcation and Regression Tasks and Alike Algorithms
for Kernel Machines.
In Proceedings of European Sym-
posium on Artiﬁcial Neural Networks, ESANN’2003, pages
215–222, Evere, Belgium. D-side Publications.

Li, Y. and Long, P. (2002). The Relaxed Online Maximum Mar-

gin Algorithm. Machine Learning, 46:361–387.

Nair, P. B., Choudhury, A., and Keane, A. J. (2002). Some Greedy
Learning Algorithms for Sparse Regression and Classiﬁca-
tion with Mercer Kernels. Journal of Machine Learning Re-
search, 3:781–801.

R¨atsch, G., Onoda, T., and M¨uller, K.-R. (2001). Soft Margins
for AdaBoost. Machine Learning, 42(3):287–320. Also:
NeuroCOLT Technical Report 1998-021.

Rosenblatt, F. (1957). The Perceptron: A perceiving and rec-
ognizing automaton. Technical Report 85-460-1, Project
PARA, Cornell Aeronautical Lab.

Vapnik, V. and Lerner, A. (1963). Pattern Recognition using Gen-
eralized Portrait Method. Automation and Remote Control,
24:774–780.

Vapnik, V. N. (1998). Statistical Learning Theory. Wiley, New

York.

Vincent, P. and Bengio, Y. (2000). Kernel Matching Pur-
suit. Technical Report 1179, D´epartement d’Informatique
et Recherche Op´erationnelle, Universit´e de Montr´eal. Pre-
sented at Snowbird’00.

420 	


 	
"!##$	%'&(		*)
"+	%-,.	)/
"103245!


687:9;67=<?>@<BAC7=D$EGF
HJIKI*LNM1OQPJRTSVUNPW1XNY[ZQ\]^_Y[`bacI1Y

dbef\gV\/X

h\\/]_`Kh]iS?Sj`k\/lnmo\YoXpnqVLnrQsQpVsutwv$LnI	Y

dbef\gQ\XxL@y{zn\*I1\`kzn\/]km|OjXNPN^

}~i}=B"inw"=TG~oN~oN

VJnT

SVX

`kYoSVXSV¥OV]kRNY¨`i]iOV]ka©UnX@PJY[]i\
SVX?ZV\¯

XOjYoX?]kYogVzB`\"`OVm: oL1pj¡Q¡QpV¢O£Xn\gV\/Xn\]Ojm
moOQ^k^Sj¥*UnlNl@\/]RTSVUNXNPn^SVX¦`kzn\£m[SQg§lNOV]_`iY¨`iY[SQX
¥UnX
OVm
`k\GPgQ]iOVlnznY
efSJPJ\m|^fzNOQ^RT\\/XªPJ\ZQ\moSVlT\/P« y{znY|^fR@SQUnXNP¬Yo^
SVXN^_`k]iU
SVeuRNY[XNOj`kYoSVXN^
`i\/PR?a­`iOV®BYoXng
`iOjRNm[\PJY|^b`i]kYoRnUJ`iY[SQXN^ y{zn\°\¯Jl@\/]kYoef\XJ±
SV¥*`k]O
`Ojm1]i\/^kUnm[`i^flnUnRNm[Y|^_zN\/P^_S£¥=OV]
\XB`i]iOj`k\/^#SQX
SVeuRNY[XNOj`kYoSVXN^²Sj¥«`i]k\/\"±³^b`i]kU
`kUn]i\/PfPJY|^_`k]iY[RnUn`kYoSVXN^
mo\/OQPJY[XNg´`iSO
SQX?ZV\"¯JY[µN\/P3¶w\"`kzN\°¥]i\\£\XN\]igVaVL
zY|^·efY[XNY[efYo¸\/P¹RBa3`kzN\§`k]i\\±º]i\w\YogVzB`i\/P
znY
RT\moY[\¥²ln]iSVlNOVgQOj`kYoSVXOjmogVSV]iY[`kzne K»KXn\Sj¥`kzn\u¥=OC±
ZQSV]OjRnmo\ln]iSVlT\]k`kYo\/^SV¥T`iznY|^
moOQ^k^SV¥xOjlnln]iS¼¯JY[eOj±
`iY[SQXN^wYo^½`kz@OC`{Y[X
SQeflnm[\¯JY¨`baSV¥x`kzn\
]k\GOV^kY[XNg5`kzn\
OVlnln]iS¼¯?YoeOC`iY[SQX·Yo^¾gQUNOj]OjXB`i\\/P·`kSYoX
]i\/OQ^_\`kzn\
®°SV¥w`iznY|^ugQUNOj]OjXB`k\/\fYo^XnSj±
ln]i\
Yo^kYoSVXx ·y{zn\moO
`iSV]iY[SQUN^fY[Xª^_`iOVXNPnOj]P¬gV\XN\]OjmoY[¸/\/P¬R@\/m[Yo\"¥5ln]iSVlJ±
OVgQOC`iY[SQXx £\YoX
]i\/OQ^_\f`izn\
SVeflnmo\"¯JY[`ba°SV¥`kzn\
OVlnln]iS¼¯?YoeOC`iY[XngPJY|^_`k]iY[RnUn`kYoSVXN^¿RBa	`iOV®BYoXng
SVeRnY¨±
XNOj`kYoSVXN^$SV¥jdbUnX
SVX?ZV\¯?±
`kYoSVX`k]i\\/^/L¼m[\GOVPJYoXngK`kS¾O
zYo^wefY[XNY[efYo¸\/P
Y[µN\/PÀ¾Yo®BU
R?a*]i\w\YogVzB`k\GPugQ\Xn\/]iOVm[Yo¸\GP*RT\moY[\¥TlN]kSQlNOjgBOC`kYoSVX¿ 
tÁ¯?lT\]iYoe#\/XB`iOjm?]i\/^kUnm[`i^$¥SV]
^kY[XNggQ]kY|Pn^OV^w\momnOV^
¥SQ]x¥Unmom[a
^kY[Xng	e#SJPJ\/mo^ÂOj]i\Áln]i\/^k\XB`k\GP
Yom[moUN^_`k]OC`iY[XngOVPJZCOVXQ`OjgQ\/^	OVXNPÃPnYo^iOVPJZCOVXQ`OjgQ\/^1SV¥
`izn\·]i\w\YogVzB`kYoXngÄef\"`iznSJPY[XÅOVlnln]iS¼¯?YoeOC`i\YoXJ±
¥\/]k\/X

znYT¥]k\/\K\/Xn\]igVaQLBzNY

SVXnXn\

`i\/P

\Q 

ÇQÈÊÉÃËÌ´ÍÅÎÐÏ£ÉÃÇnÌ´È

gV]OjlnzNY

OjmÁefSJPJ\m|^#^_U

z¬OV^u¶{O¼aQ\/^kYoOVX£XN\"`_±
]iSVR@OjRnYom[Y|^_`kY
wSV]i®?^OjXNPªÒ·OV]k®QSCZ´]OjXNPnSVeÓµ@\m|Pn^OV]k\Ãl@SCw\]k¥Unm1`iS?SVm|^
¥SV]mo\/OV]kXnYoXngÐOjXNP4]k\GOV^kSVXnYoXng3Y[X PJSVeOVY[XN^£Y[`kzÔUnX
\]k±
`iOVY[XB`baQ W	XJ¥SV]k`kUNXNOC`i\moaVL?\"¯nO
`OjRnmo\	YoX
\KYo^wYoXQ`i]iO
SQeflnm[\¯£gQ]iOVlnzN^/ y{zn\]i\"¥SQ]k\OVlnln]iS¼¯JY[eOC`i\fY[XJ¥\/]_±
m|Oj]igV\VL
\V Õ1XOjlnlN]kS¼¯JYoefOj±
\X
`kYoSVX£ef\"`iznSJP·`izNOC`*]i\
z°Oj`_`i\XB`kYoSVX£Yo^
moSBSQl?aRT\moYo\"¥@lN]kSQlNOjgBOC`kYoSVXc:¶
\GOj]im:L?q/ÖQ×V×B¢ ¿Õ	m¨`iznSVUngQz
SQX?ZV\]igV\QLKY[`·Sj¥±
`kzN\´OjmogVSQ]kY[`kzneYo^XNSj`·gVU@Oj]OjXB`k\/\/P¦`kS

`wYoXJ¥\/]k\/X
\ef\"`iznSJPn^ÁOj]i\{Sj¥gV]i\/Oj`$Yoefl@SQ]_`OjX

\/Y[ZQ\/P·eU
¢w

\XB`kmoa]k\

¤¤

SVX?ZQ\]igV\X

moUN^_`k\/]_±³^_Yo¸\5YoXÃh¾¶

`k\/XgVYoZV\/^{^kUn]iln]kY|^kY[XngQm[aO
Un]OC`k\]i\/^kUnm¨`^5=ÒUN]klnz?ac\`	Ojmº [L
q/ÖQÖVÖB¢ 
XØÁ\/PnYoPJY|O\"`Ojmº [LVpV¡V¡NqG¢L¼Y[`$z@OV^ÂR@\/\Xf^_znSCX*`kzNOj`
µn¯J\/PlTSVYoXB`i^5SV¥m[S?SVl?aÃ¶
OV]k\cO
`kU@Ojmom[a·\¯?`k]i\eOSj¥{`kzN\
SQXN^kYoPJ\/]k\GP·OV^O`b½SV±
¶w\"`izn\u¥]i\\#\XN\]igVaVLznY
OjX°R@\
`¥]i\\£\Xn\/]kgQa¬SV¥*`kzN\
XnSJPJ\OjlnlN]kS¼¯JYoefOj`kYoSVXSj¥u`kzn\£\"¯nO
^ka?^_`k\/e $¶wa
SVX@^_Y|PJ\]iYoXng`kzn\	À¾Yo®?U
znYJ¥]i\\\/Xn\]igVaQLjznY
Y|^wOVXOVlnln]iS¼¯JY[eOC`i\¥]i\\¾\Xn\/]kgQafRNOV^k\/PSVXm|Oj]igV\/]
m[U@^b`i\]^
\/P£gV\/Xn\]OjmoY[¸/\/P°R@\/m[Yo\"¥ln]iSVln±
Sj¥{XnSJPJ\G^LÂ`kzn\e#SQ]k\OQPJZCOjX
¢fOjmogVSQ]kY[`kzneÙzNOV^fRT\\/XÅPJ\]iYoZV\/PÐØÁ\/PJY|PJY|O
OjgBOC`iY[SQXÊºh¾¶
OjX°R@\#Z?Y[\/½\GP·OV^OjXÃY[XJ±
\"`5Ojmº oL«pV¡V¡NqG¢ y{znY|^OVm[gQSV]iY¨`izne
`k\/]klTSVm|OC`iY[SQX¬RT\"`bw\\/X¬moS?SVl?a§¶
`iY[SQX´`i]k\/\
OjXNP´`kzn\fdbUNX
OjmogVSQ]kY[`kzNe=ÚÂOjUn]iY¨`i¸\/XOVXNP·H?lnYo\gQ\mozNOjm[`k\/]/L«qGÖV×Q×nÛnÜQ\XN^k\XxL
OVXNP`kzN\OjlNln]kS¼¯JY[±
q/ÖQÖVrB¢ 1y{zn\*]i\m|OC`iY[SQXR@\`b½\/\X´ºh5¢b¶
znYC¥]i\\\/Xn\]igVYo\/^xe#SV`kYoZCOC`k\GP5^_\/ZV\/]iOVmC]k\±
eOC`i\²¶w\"`kzN\¼ÝCÀ¾Yo®?U
zn\/]i^`iSPJ\G^_YogVXPJSVUnRNm[\±ºmoS?SVlOVm[gQSV]iY¨`izne^¥SV]w\"¯JlnmoY
^k\/Oj]
Y[`
zNY{¥]k\/\\Xn\/]kgQa§Y¨`iz
efY[XNY[efYo¸/OC`iY[SQXSj¥`kzn\·¶w\"`izn\¼ÝjÀ¾Y[®?U
OgVU@Oj]OjXB`k\/\/P
OVm|¢5SVlJ`iY[eUneÞ:y¿\/z
\`kSÃOÄ=m[S
OjX@P£\mom[YoXng@L@pj¡Q¡QpJÛBØÁUnYomom[\QL@pj¡Q¡QpJÛJß	\/^k®V\/^{\`	Ojmº [LNpV¡V¡QàQ¢ 
Sj¥`i\XYoe#lN]kSCZQ\/^w`kzN\
acSj¥`izn\uOjlNln]kS¼¯JYoeOC`kYoSVX¿ wW	XJ¥SV]k`kUnX@OC`k\/m[aQLn`iznYo^	Yo^
SVUnXB`k\/]u\¯JOVeflnm[\Yo^u`kzN\
SVXNXn\
^kY[XngefSJPJ\mY[`kz£lNOVY[]*OVXNP`i]kYolnmo\"`uOjln±
®LÁpj¡Q¡QpV¢" ·tÁZQ\X
`iY[SQX5^b`i]k\/Xngj`izxLG`kzn\²`k]iY[lnmo\"`$Ojlnln]iS¼¯?±
zuwSV]^_\²`kzNOVXu`izn\{lNOjYo]OjlnlN]kS¼¯JYoefOj`kYoSVXx ÂÕ
Ojln±
OjXNXnSj`{R@\
SQe#l@Oj]iY[Xngu`kzn\/Y[]
znY¥]i\\f\XJ±

]k\GOV^kY[Xng#`izn\
Un]O
¤/¤
XnSV`gVU@Oj]OjXB`k\/\/P« ·ÕXnSj`iSV]iY[SQUN^
¥Unmom[a
ln]iS¼¯JY[eOC`iY[SQXN^c:À5OjlnlT\X´OVXNPªYo\gV\/]kYoX
Y[`kz*efSJPJ\]OC`i\Y[XB`i\]O
YoefOj`kYoSVXYo^eU
]i\m|OC`k\GPln]kSQRnmo\e¦Y|^«`izNOC`«`izn\²áBUNOVm[Y[`ba	SV¥JPnY¨â\]i\XB`$h¾¶
ln]iS¼¯JY[eOC`iY[SQXN^
À¾Yo®BU
\]igVacPnSB\G^XnSV`{YoeflnmoaO#R@\`_`i\]	OVlnln]iS¼¯?YoeOC`iY[SQXx 
Õ­ef\"`kzNS?Pu`kz@OC`Yo^
LCRnUn`Pn\]iY[ZQ\/P
SVX?ZQ\"¯JY¨µ@\/P´¥]k\/\
YoXÅO
\XN\]igVaOVlnln]iS¼¯JY[eOC`iY[SQXOjYoXB]iYogVzB`Á\"`{Ojmº [LJpj¡Q¡QpJÛV£OVY[XJ±
]iY[gQzQ`\"`Ojmº [L¾pj¡Q¡VànÛOjYoXB]iYogVzB`OVXNP¦ÜQSV]PnOjX¿LKpj¡Q¡VàQ¢" 
y{znY|^·OjlNln]kS¼¯JYoeOC`kYoSVXÊY|^·PJ\]iYoZV\/P3`iSªln]kSCZ?Y|PJ\ÄOjXÐUnlnlT\]
RTSVUnXNP£SV¥½`izn\m[SQglNOj]k`kY[`kYoSVX°¥UnX
`kYoSVXx y{zN\lNOj]Ojef\"`i\]^
Sj¥{`izn\c\"¯nO
`uefSJPJ\mwOj]i\]k\/ln]i\/^k\XB`k\GP°OQ^5`kzN\O¼ZV\/]iOVgV\#Sj¥
SVX?ZQ\"¯JY¨`baÃSj¥
lNOV]iOVe#\`k\/]i^¾SV¥½`i]iO
`kzN\*m[SQgflNOj]k`kY[`kYoSVX¥UnX
`kYoSVXxL@Y¨`1Y|^UnlNl@\/]_±R@SQUnXNPJ\GPR?ac`kzN\
O¼ZV\/]iOVgV\¾Sj¥`izn\umoSVgcl@Oj]k`kY[`kYoSVX¥UnX
`OjRnmo\
efSJPJ\m|^ Äy{zn\SVlJ`iY[efYo¸/Oj`kYoSVX´SV¥`kznY|^#UnlnlT\]fRTSVUnXNP§`kzn\/X

znY¥]k\/\\Xn\/]kgQaZCOjmoUn\/^/ cÕ m[SCw\]5À¾Yo®?U

SVeflnmo\"`i\moa¬PJY[â\]i\XB`{O¼a´Y|^f`kzn\

`iOVRnmo\e#SJPJ\/mo^/ ¶½aÃ`kzn\

m[SB^_\/m[a¾]i\m|OC`i\/P5`iS:h5¢b¶

`kYoSVXN^KSj¥`izn\*`i]iO

SVeflNOV]k\GPR?a

`k\/P

421
¤
¤
¤
¤
¤
¤
¤
¤
¤
¤
¤
¤
¤
¤
¤
¤
¤
¤
¤
¤
¤
¤
¤
¤
¤
¤
¤
¤

¤
¤

¤
Æ
Ñ
¤
¤
¤
¤
¤
¤
¤
¤
¤
¤
¤
¤
¤
Ñ
Ñ
¤

Ñ
¤
¤
z
¤
¤
¤
¤
¤
¤
z
¤
¤
Ñ
¤
Ñ
¤
Ñ
¤
¤
¤
¤
¤
¤
¤

X
¤
¤
Ñ
O
¤
¤
¤
¤

¤
¤
¤
Ñ
¤
¤
¤
¤
¤
¤
Ñ
¤
¤
¤
¤
¤
¤
¤
¤
¤
ðnæ½îfëVä[ù#õ"êQùQéiçkäoýnôJéiä[êQù5êjønéiðnä|è¿ìNëVì@æ/çÂä|èëjù*æíJì@æ/çkäoîfæùBéiëV÷

ôNèkä[ùNãÄékçiä[ìN÷[æéiècîôNè_éýTæ·îfêVçiæÃëVõ/õ"ônçëCéiæä[ùøçiææ·æ/ùnæçiãVú

æùNæçiãVú¬ëVìnìnçiê¼íJä[îëCéiä[êQù¬êVø*ëjùÅëjçiýnä[ékçëjçiú´ÿJä|èkõçkæékæìnçiêVýnö

üä[ékðÅäoùNõ"çiæ/ëQè_äoùnã§õêVîfìn÷oæ"íJä¨ébú­÷oæ/ëVÿNèékê§ékäoãVðBékæ/çëjìNìnçkê¼íJä[ö

êVùN÷[úä[ù?åQêV÷oåVæ/ÿëVìnìnçiê¼íJä[îëCéiä[êQùNè{üä[ékð·éiçkæ/æ/è/û@÷oæ/ëQÿJäoùnãékêë
ðnæêQìJékäoîfä[þ/æ/ÿÄì@è_æ/ôNÿJêjöîëjçiãVäoùNëj÷|è

ãVäoåVæçiäoèkæ1éiêfë#ëjìNìnçkê¼íJäoîëCékæKï½æékðnæCñCò¾äoó?ôNõðnä[öº÷oä[óQæ1øçiæææùJö
æçiãVúQû1äoù¦üðnä|õðÅéiðnæ£õ÷[ô@èbéiæçý@æ/÷[äoæ"ø=èëVçkæ°ìNëjçëjîfæ"éiæçèéiê
ðNæ*ëVÿJåCëjùBéëjãVæ¾êVø$éiðnä|è	ëjìNìnçkêBëVõðäoè1ékðNëjé
ékäoåVæ/÷[úÃæ/ëVèkúékêîfä[ùNä[îfäoþæVû$ëjùNÿÃä¨é*ä|èãVôNëVçiëVùBékææGÿéiêðNë¼åQæ

ýTæ*êVìJéiä[îfäoþæGÿ 
ékðNäoè*ëVìnìnçiê¼íJä[îëCéiæ*øçiææfæùNæçiãVú·ä|è5õ"êQùBåQæ"í Jêä[é*ä|è¾çkæ/÷oëjö
êVùN÷[úªë­è_äoùnãV÷oæÃîfäoùnäoîuônî 1ùNêjékðNæçëVÿJåCëjùBéëjãVæÃêjø*éiðnäoè
îfæ"éiðnêJÿ´ä|è*éiðNëCécëÃùnæ/è_ékæGÿ¬èkæ	Bônæ/ùNõ"æêjøKëVìnìnçiê¼í?äoîëCéiä[êQùNè
îëCéiä[êQùNèêjø$ékðNæ¾øçkæ/æ5æùnæ/çkãQú
 ?ê@ûJøêVçæínëjîfìn÷oæVûnäoù·ë#øôn÷o÷[ú
õ"êQùnùnæGõékæGÿbèkäoùnãfî#êJÿJæ/÷:û?éiðnæ*õ"êQù?åVæ"íJäNæ/ÿëjìnìNçkê¼íJäoîfëjékäoêVù
ékð@ëjùcüä[ékðcô@è_äoùnãuì@ëjäoçiè	 KùNæ1îë¼úæí?ìTæ/õ"é=êVçwðnêVìTæékðNëjé
ékðNæä[ùNõçkæGëVèkæêVøwìNçkæGõ"ä|è_äoêVù°ä[ù£øçiæææùNæçiãVúä|è5çkæNæ/õ"ékæGÿÃäoù
ëjùªäoùNõçkæGëVèkæ·êjø5ìnçiæ/õäoèkä[êQùªêjø*êVékðnæ/çBôNëjùBéiä¨éiä[æGèû1èkôNõð¦ëQè
ùnêJÿJæ1îëVçkãQä[ùNëV÷oè	 ÁíJì@æ/çkäoîfæùBéiëV÷JçkæGè_ôn÷[éiè²ìnônýn÷oä|è_ðnæGÿè_êVö:ø=ëVç
õ"êQù?åVæ"íJäNæ/ÿÄïwæékðnæøçkæ/ææùNæçiãVúVûüðnä|õð§ä|èuêQìJékäoîfä[þ/æ/ÿÄý?ú
ékçiææöºçiæüwæäoãVðBéiæ/ÿ£ï 
äoùéiðnæ/èkæ5ëjìnìNçkê¼íJäoîfëjékäoêVùNè{ëVçkæ¾ìNëVä[çköºîëVçkãQä[ùNëV÷oè	 
è_ékôNÿJúêjøõ"êVù?åQæ"íJä@æ/ÿëVìnìnçiê¼íJä[îëCéiä[êQùNèwüä¨éiðä[ùNõçkæGëVèkä[ùNãV÷oú
õ"êQîfìn÷[æícõ"÷oôNèbéiæçè $ä[çè_é/ûBü½æKçkæ/åBäoæü­éiðnæõêVù?åVæíJäNæGÿøçkæ/æ
ëjýNä[÷oä¨ébú§ÿnäoè_ékçiä[ýNôJékäoêVùNè! £ëVä[ù?üçiä[ãQðQé#æ"écëj÷" oû#%$&$&#(') £ëVä[ùJö
üçiä[ãQðQé*æéëj÷" oû#
$
$&*&û$ëjùNÿ£éiðnæcôNèkæcêVøõêVù?åVæí°õ"êQîuýnäoùNëjö
ékäoêVù@è5êjø+bônùNõ"ékäoêVùJöºékçiææGè5÷oæ/ëVÿnä[ùnãéiêÃõ"êQùBåQæ"íJäNæ/ÿ£ò¾ä[ó?ôNõðNä
øçiææ§æ/ùnæçiãVúQû*ëVèêQôJék÷oä[ùNæ/ÿæGëjçi÷[äoæçäoù,- ëjäoù?üçkäoãVðBéÃëVùNÿ
êVçÿnëjùxû/#%$
$&*&0 1 °æ¦ìnçkæGè_æ/ùBé§çkæ/ü½æ/ä[ãQðQéiæ/ÿ32¾ï45ä" 
æ& [û
2¾ï4wéiêcîfä[ùnäoîfä[þ/æ*éiðnæuõ"êQù?åVæ"íJäNæ/ÿøçiææ*æ/ùnæçiãVú& 
îfæ/èièkëVãVæö:øçiææ72¾ï4§ëj÷oãVêQçkä[ékðNî4ìnçiæ/èkæùBékæGÿ#ä[ù8:91æGè_óQæ/èÁëVùNÿ
ê?æ"éiæçGû<#%$
$&*&0 = £æ#õêVùNèkä|ÿJæçbè_äoùnããVçiäoÿNèKëVùNÿøôn÷o÷[ú°õ"êVùnö
ùnæGõékæGÿ>bèkä[ùNã	îfêJÿJæ÷|èxøêQçÂüðNäoõðü½æwõ"êVù@èbéiçkôNõ"éÂùnæGèbéiæ/ÿõ"êVùnö
åVæíJäNæGÿªìNëVä[çëjùNÿ3õ"÷oôNè_ékæçëjìNìnçkê¼íJäoîëCékäoêVù@ècêjø5éiðnæ°øçkæ/æ
æùNæçiãVúëjùNÿÄêVø{ékðnæõ"÷oôNè_ékæçîëjçiãVäoùNëj÷|è 
ëj÷oãVêQçkä[ékðNîfè?:91æ/èkóVæGè{æ"é	ëV÷: oû@#%$&$
*&0 
B/CEDGFIHKJMLONGBQPSR?TUDWVXH8YZH8Y[L]\
^`_
\aFbH8Y[L]\cDG\dN

ðNæ/èkæëjìNìnçkê¼íJä[ö
îëCéiä[êQùNè{ëjçiæ	æ"íJìTæçiä[îfæ/ùQéëj÷o÷[úõêVîfìNëjçiæ/ÿcüä¨éiðæ/ëQõðêVékðnæ/ç
ëjù@ÿ§üä[ékð§éiðnæõ"êQçkçiæ/èkì@êQùNÿJäoùnãÃè_éiëVùNÿnëjçÿ§ïwæ"éiðnæ¼ñjò¾ä[ó?ôNõðNä
ëjìNìnçkê¼íJäoîëCékäoêVù@è@êQìJékäoîfä[þ/æ/ÿ¾üä[ékð*õêVù?åVæ/çkãQæùBéÿnêVônýn÷oæ÷oêBêQì

VeBBfBQ\gB/VGhei
 £æ°õ"êQùNèkäoÿJæ/çë§ÿnäoè_ékçiä[ýNôJékäoêVùªêCåQæçÿJä|èiõ"çiæ"ékæÃå¼ëVçkä|ëjýN÷[æGèSj
üä[ékðì@êVékæ/ùQéiäoëV÷<k=!jlû

ðnäoè
äoèÃëªèbéiçiëVä[ãQðQékøêVçiüwëVçiÿÅãVæùNæçëj÷oä[þGëCékäoêVùÊêjø#ékðNæ

ëj÷oãVêQçkä[ékðNî

-jl)n5o

æí?ì-k=!jlqsr

ðnæ5ùnêQçkîëV÷[äoþ/ëjékäoêVùõêVùNè_éiëVùBé/û

!ksndt	u æ"íJì<-k-jlq

:#&

snax8t

÷|ëjìnìnäoùnãõ"÷oôNè_ékæ/çì@êVékæùBéiäoëV÷oè/û

ékðNæÿJä|è_ékçiä[ýnônékäoêVù
ëCéä[éièîfäoùnäoîuônîäoè

ékðnæè_éiëjékæ{åVæGõékêQççkæGèbéiçkä|õéiæ/ÿ
ðnæõ"÷oôNèbéiæçè	ëVùNÿì@êVékæ/ùQéiäoëV÷oè

çiæ"éiônçkù@è
ðnæåCëj÷oônæ	êVø«ékðnæKøçiææ	æ/ùnæçiãVú

ä|èó?ùnêCüùëVè$ékðNæ1ìNëjçkékä[ékäoêVù#øônù@õékäoêVùl NêVç÷|ëCéiæçÁçiæ"øæ/çkæ/ùNõ"æQû
üwæ½ëj÷|èkê	ÿJæ0@ùnæÁéiðnæ²åCëjçiä|ëCékäoêVù@ëj÷jøçiææ½æùnæ/çkãQúKêVøJékðnæwè_úJè_ékæ/îû
!*Z
lw
-jlJ÷[êQã{w
-jl0|
äoùnäoî#äoþäoùnãékðnæøçkæ/æuæ/ùnæçiãVúüä¨éið·çiæ/èkì@æGõé	éiê,w

-jlyk-jlz{t
 
äoù~
-
snx÷oêVã
<!
</8>	`M>=
êCü3ü½æ5õêVùNèkäoÿnæç1ÿJä|èbéiçkäoýnôJéiä[êQùNèêCåQæç{è_æéièêVøÂùnêJÿJæGèû[jXn
-|	rr	r|q[û1ëVùNÿ­ì@êVékæùBéiäoëV÷oèféiðNëCéø=ëVõéiêVçiä[þ/æä[ùBékêÄêCåQæçkö
k=!jl)ndtk
:&
üä[ékð`g
|	rr	r|q QûQëjùNÿj
ékêcékðnæuékðnæå¼ëVçkä|ëjýN÷[æGèä[ùX 
ëjçiæùnêVé²ônùnä¡Bônæ÷oú#ÿnæ0NùnæGÿ nêQç²äoùNèbéëjùNõæVû?õ"÷oôNè_ékæçèÁõ/ëjùýTæ
&¦
îfæçiãVæGÿÃäoùBékêýnäoãVãQæç5õ"÷oôNè_ékæçè>£¢
¢)n¤X¥X£¢Áüä[ékðbk
zIk
 snêQç{õêVù?åVæ/ùnäoæùNõæVû?ü½æ5ëQèkèkônîfæ	éiðNëCé1õ÷[ôNè_ékæ/çiè§
ëjçiæùnêjé1õ"êQùBéiëjäoùnæGÿcäoùæGëVõðêVékðnæ/ç	 
ý?úcîfæçiãVäoùnãè_ôNýTõ÷[ôNè_ékæ/çiè{üä[ékðéiðnæäoç	èkônì@æ/çièkæ"éè 
³ùãVæ/ùnæçëj÷{éiðnæÃÿJä|èbéiçkäoýnôJéiä[êQù
-jlfüäo÷[÷	ý@æ·äoùBékçëVõ"éiëjýN÷[æ& 
1ùæ"ínõ"æ/ìJékäoêVùä|èøêQçkîfæ/ÿ#ý?ú#î#êJÿJæ/÷oè²ä[ùüðnäoõðféiðnæ=ì@êBèkèkä[ö
ýn÷oúîfæ/çkãQæ/ÿ@õ÷[ô@èbéiæçè1õëVùý@æ*êQçkãBëjùnäoþæGÿäoùBékêë+bônùNõéiä[êQù
ékçiææ¾üä[ékðèkîfëV÷[÷¿îfëjíJä[îëj÷xõ÷[ô@èbéiæç1èkä[þ/æ
 
¨+bônùNõ"ékäoêVùÊékçiææG:©¿ëjôNçkä[ékþ/æùëjùNÿª?ìnäoæãQæ÷oðNëj÷[ékæ/ç/û
o«
¬
¬
äoèëÄð?úBìTæçköºékçiææêjø*õ"÷oôNè_ékæ/çièS¯®¤°MêQç
ëVõ"ékôNëV÷[÷oú²±ëuøêQçkæGèbéêVøÂð?ú?ì@æ/ç_öºékçiææGè³"ûJüðnäoõððNëQèwékðnæ5ìnçiêVìnö
æçkékäoæ/è°éiðNëCéøêVçÄëVùBúì@ëjäoç°êVøõ"÷oôNè_ékæ/çièbëjù@ÿ´£¢üä¨éið
ùnêQùnæîfìJébú°êCåVæçi÷|ëjì88µ8¢"±S
õ"÷oôNè_ékæ/çékçiææékð@ëCéõêVùnùnæGõéèS¹ëjù@ÿe£¢	ëVùNÿª:#&U1÷o÷1ékðNæ
õ"÷oôNè_ékæ/çiè)¶cä[ùféiðnæ1ìNëjékðcõêVùnùnæGõéiä[ùnãÃëjù@ÿ`¢@è_ðnêQôn÷|ÿõ"êVùnö
éiëVä[ù*ékðnæ/ä[ç$ä[ùBéiæçè_æGõékäoêVùl±<)µ)£¢e¶çiônùnùnäoùnã	äoùBékæ/çièkæ/õ"ékäoêVù
ìnçiêVìTæçkébú[ 
ðnæ*÷oä[ùnóJè	ý@æébü½æ/æù·ëVÿ+_ëVõ"æ/ùBéKõ"÷oôNè_ékæçèäoùékðNæ
ð?ú?ì@æ/ç_öºékçiææ*ëVçkæ*÷|ëjýTæ÷oæ/ÿ·üä¨éiðÃè_æ/ìNëjçëCéiêVçè 
êjø«ékðNæKëVÿ+_ëVõ"æ/ùBé½õ"÷oôNè_ékæçè	 
êjø«éiðnæ	äoùBékæ/çièkæ/õ"ékäoêVùNès·n¸¹µ>
ðnæù?ônîuýTæç#êjøéiä[îfæ/èéiðNëCéëÃèkônýõ"÷oôNèbéiæç`·ëjìNì@æGëjçèuäoù
ékðNæ5ðBú?ìTæçkö:éiçkæ/æKä|è§<º 
­ìnçiêVýNëVýnä[÷oä|èbéiäoõ²î#êJÿJæ/÷Jä[ùüðnä|õðuéiðnæwõ÷[ô@èbéiæçè_æé)°dna) 
õëVùý@æ*êQçkãBëjùnäoþæGÿëQè1ë+bônùNõ"ékäoêVùékçiææQûNõëVùý@æ5ø=ëQõéiêVçiä[þ/æ/ÿ
äoùQéiê£ëÃìnçiê?ÿnôNõéfêjø	ìNçkêQýNëjýnäo÷oä¨éiä[æGèuêQù§ékðNæõ÷[ä¡Bônæ/è`°ëVùNÿ
èkæìNëVçiëjékêVçè4»{û
(½%¾
½%¿
-jl)n
øêVçËÊ®I° ëjù@ÿ

üðnæ/çkæ½ü½æwÿJæ0NùNæ/ÿ¹È8ng°U¥4»{ûVëjù@ÿ5ékðNæwõêVônùBékäoùnãKùBôNîuýTæçè

ÆÅ³Ç
!j
½%Ä
øêVçËÊb®b»4 

-j

ÀSÁ,Â
nx§

ðnæ/çkæä|è5ëìNëCéiðä[ù£ékðNæ

ðnä|èõëVùýTæ5ëVõðnäoæåQæ/ÿ

ðnæ/úõêVùNèkä|èbéè

ðnæ.øçkæ/æ

æùNèkæùxû

o«
«
­

-j

-j

422


.
6

;

A
^
m
p

o


p
v
m
u
w
m
u
w
m
m
}
m
m
o

v

m
p
r




o


¦
n
k


¦

m
'
.
o




¢

m
¼
m


¼
º
m
º

Ã
m
Ã

­

É
Ã
n
o
É
Ã
Ã

úÆû

ã
ä/å

ÌÍ@ÌÎ³Ï
ÐSÑÒ
ÍÓÔÌÌÕÖ@ÎÆÌ×Æ×ÆÌ	ØÒ
×
ÜqÛ`Ú-æ
Ù`Ú!Û>ÜsÝÞbß
Ú!æ
à[á%â
ãë
Üìîí
Û`Ú!æ
ÜïÚ"ð
Ü
Û`Ú-æ
èZá%ésê
Üö4÷ø3ùªú³û
ÜXôõÛ`Ú-æ
Ú-æ
ÐeØ[Ì0ò@Í[óîÍ[Ï
ÌXüUóÍ@óüUóîý	Òþ
ú>úÆí8Û
ú³ì
úÆû
Ð~ÓÔÌÎÆÌ
Í 
ÌÍ@óÌ	Í
Ñ	Ò%ÍÓÌÑ
ÎÆÌ×qÖÌ	Ñ
Íÿ§ó
ÎÆþ
ú>ú³íXúÆû
ú³û
ü
Ì	ØOÒ
×¹ÒXüóîÍ[óîüUóýÒ
ÍOÿ§ó
Î³Ì	×ÆÖÔÌÑ
ÌóîÍ@Ø(Ì0þ
Ü	
Ú!æ
@×
×
@Í@Ø(ÌÎ>Ñ
ÖÌÍ@Ø(Ì	Í
ÌÎ?ü`Ò%Î³Ï
óîÍ@Ò
Í@×
Ò%óîÍ
÷
`÷
ú§úÆû
ú§í
ú³û
úÆû
 
Ì	Î
Í@×Æóî×
ÌÐÒ
ÎÆÌ?Ñ
Ì	Í
ÌóîÎ
Ò%ÖÔ×
 !#"$ %'&()
*+,&-.&-/ 0%!213&-45
98
úÆû
úÛ`Ú!ælÜ
ÿÌ>Ò&×Æ×7[üUÌ
ó¡×7óîÍ
Ò%Ó
Î³Ò&Ñ
Ú-å4Ü	
úÆû
ú³í
ìîí
úÆû
[Í@Ø
Ï9:
@Ö[ÖÔÌ	Îqþ
ÌÏ
ó¡×
óî×7×ÆÌ	Ñ
Û*=?>A@Ú!ælÜö
ú>í
Ú-ú
§ÿÌ
Î³óÓ<
Ò; 
Ì`ÒX×ÆÌ
Ò
Ñ
Í@×
Ø[óî×
Ò%Ó
ûZúEDsÚFÜHGJI
=?>C@Ú-ælÜ0ö
í
ú
úÆû
×B
Ò
Í@ØeÒ~ÿÌóîÏ
Ì	Í
ÿ§ó
óîÒ
DsÚFÜ7ÝML
ö
ú³û3K
ûXí
úÆû
Î³óÓ4
×7@Ñ
ÿ§ó
ÌØ(ó¡×
Í@×
Ì	Ò&Ñ
í
ú
úÆû
úúÆû
ì4å
ûZú
úÆû
Ì	Ø{×N@ü
óîÒ
Î³óîÏ
óîÍ@Ò
Ì	Í
ó¡×
Ì/ÿÌ	óÏ
=P>Q@
í%ú
×OB
ó¡Ò
Ì	Í
=?>C@
DsÚFÜ
ÚRZÜ
Ú-ælÜ)ÝGå=Ú-ælÜ
Ú-å4Ü
ú³û
ìîí
ìîí
ÍJS[Í@Ñ
ó¡×![Ö[ÖÌÎ
Ï9:
ÌÍ
ÏÖ@Ò
Î
[Í@Ø[Ì	Ø/ÓÐ
=?>Q@
DsÚFÜ
ÚUZÜ
Ú"ß
Ú-å4Ü1Ý
ìîí
ìí
ÏT:
Ï9:
=?>Q@
ÚNLWIZÜ
DsÚFÜìí
Ï9:
X4û
ìú
úÆû
Ú-å4Üö
×Y-Î
Í 
ÌÕó
ó¡×Î³Ì	×7
Ï9:
ó¡Ñ
Ìs×ÆÌüUóþ
í
ìîìîí
ú§ú³û
úÆû
ó[ &Ì
ÌZ!Ò&Ñ
Í@ØØ[ÌÎ³ó[ Ò
ÿ7×9-Î
Ì>×qÌÑ
\Y]
Ú-åÜ
ÝGÛ`Ú!æ`_N^ÜsÞIÛ`Ú!ælÜ
Û`ÚS^£Ü
åÚS^Ü
åÚ-ælÜ
ÚNLfL
ÞIÛ`Ú^ÜqÜ
ÞbÛ`Ú-ælÜÆÜ0Údc
Û`ÚbZÜ0Údc
Ý¸ß
a7e
ó? 
Ì>×ÆÌüUóþ
ó¡×4Ö
×qó
Ø(Ìò@Í[ó
gAhi
jlkEmnHoprqlkEmsutvwnxjZyzv{mn|m~}

nkyzvWmn'yzprp
Û*=?>Q@ú³í
7í
úÆû
Ò
Ì
ÓÔÌE@Í@Ñ
@×
ÿÌ
ÎÆÌ	Ì	×ÿ§ó
ÌÎ
ÚdF¹ÜÚ
úúÆû
ìì
û`úÆû
×7@Ñ
×
Ô×
ÌÎ4×qóîýÌóî××ÆüUÒ
×ÆÌ
Ì?ü`ÒÕ(óîüUÒ
=?>Q@
úÆíQÚRZÜ
`
ûÔÜ
í%ú
[Ï
@×
×OB
ÌÍ
Ò%Í@Ø/Ñ
ÌÍ
ó¡Ò
ÌÎ§Ö
ÑÑ
Ø(óîÍ[Ï
úÆû
í
ú
û[í
ó¡×-Ð
Ì	×ÆÌÖ
ÌÍ
óîÒ
×§×
Ø/×ÆÒ
=?>Q@
DsÚdFÜ
ÚNL{&Ü
ÜsÝGåÚ-ælÜ
Ú-æ
=?>@
áf

ìîí

úÆû

Ü¡ 
SÚ-ælÜ
Î³Ì	×ÆÖÌ	Ñ

6[í
úÆû
ÿÌ/Ò
×³×N@üÌ
Í 
Ì	Í[óîÌÍ@ÑÌ
ÌÎEgó¡×Ò
Ô×
ÎÑ
ÌÒ
Ñ
ÚFÜö
úì
ú4í
ú³û
ú4úÆû
£Ò
@×
üUÌüÓÔÌ	Î
Ì	Ò&×
Ì	Î4×ÆÌ
Í[Ì?Ñ
Ò
Í@Ø
í
ú
ìîì
úÆû
úÆû
úÆû
@×
Ì	Î³×gÒ
ÎÆÌ`Í
Ì	Î³×
@×
Ò
Í
×Æü`Ò
Ì	Î
ÌÑ
Üw X4û
îö
M
[Í@Ñ
Î³ÌÌ×
ó¡×`ÑÒ
ÍOÓÌ
óÌW 
Ì	ØÓÐüUÌÎ³Ï
óîÍ[Ï
×
Ñ
@×
Ò
Ñ
ÌÎ
Xíí
úÆû
úÆû
ìí
Ì@Ö[ÖÔÌ	ÎsÓ
[Í@Ø
ÍS[Í@Ñþ
óîüUóý	Ì
ÏÖÔÒ%Î
=P>A@
úÆû
úúÆí/ú³û
í
ú
@×
×*B
Î³Ì	×ÆÖÔÌÑ
ÌSÑ
Íbÿ§ó
ÌÎ¹Ö
ÌÍ
óîÒ
DsÚF¹Ü	&ö
ú4úÆû
ÌzÒ%Ï
Î
Î7@Ñ
ò[Õ(Ì	Ø
ÿÌ>Ñ
ÍÔ×
Ò%Í@Ï
ó¡Ò%Í
=?>A@
=?>A@
._¹ÜÝ
DsÚFÜ(ìí
Ï9:
B
=?>Q@
ÚNLW£ZÜ
DsÚFÜ
ã`Ú-ælÜ
Ú-æ
å=Ú-ælÜsÞ
=?>@
áf
ìú
Ø/@Ñ0ÌØ¤lÒ%Ï&Î³Ò
Í[Ï
Ì~ü
Ì	ÎÆÌbÿÌIóîÍ
óÌ	Î³×
óîÖ
ÚL;
Üw+¥
úUú³í
ú³û
ó[¦Ì	ÎÆÌ	Í
Î³Ò
óÍ
ÌXÑ
Íeÿ§ó
ÍÔ×
óîÒ
=?>Q@
Ü0ö
Ú-æ
@×ÆóÍ[Ï
=?>Q@
ìîí
Ï9:
=?>A@
ÚNL§Ü
Ú!æ
ÝEÛ
=P>A@
Ú!æ
ÚFÜ0ö
Î
Ø@×9
ÐóÌ
=?>Q@
ÚNL{«&Ü
SÚ-ælÜ)ôª`Ú-æ
ÜsÝ
Ú-æ
ãf¨Æã©
ö¬`Ú!ælÜ
úÆì
ú³û
ÐY¯dÿ§ó
Ö@×ÆÌ@Ø
Ò®­
Ö@Ö@Ò%Î³ÌÍ
óî×
Ö[Î
Ó@Ò%Ó@ó
úÆû
úÆû
ÌQ[Í@Ñ
Ö@×qÌW@Ø
@×
×W¯
þ"ü`Ò%Î³Ï
óîÍ@Ò
Î³ÌÌ×
Ì	Î³×
ÌÑ
ì£úÆíúÆû
ú³û
úÆû
Ì	×ÆÌr[Í@Ñþ
@×
Ò%Î³Ì¹ÌW°±@Ò
Ì`Ñ
Ì	Î=ü`Ò%Î³Ï
óîÍ@Ò
CX4û
ìîì[úÆû
úÆû
úÆû
B
óÌ×
óîÍ
óîü`Ò
óî×óîüUÖ
ÎÆÌ	Ì	×
ú³û
Ì¹Ø(ó[¦Ì	ÎÆÌ	Í
@×
[Í@Ñ
Î³ÌÌ×7Ò%Î³Ì
Ó@Ò
Ó[ó
Ì	Î7Ö[Î
óîÌ	×
ú§í
ú³û
 
Ì	Î
Í@×Æóî×
Ì	Í
ÌóîÎ
Ò%ÖÔ×
=?>
=?>Q@
ÚNLW´ZÜ
ÜsÝ)`Ú-æ
Ü)ÝEÛ
Ú-æ
Ú-æ
²..³
±².±³
²..³
ÚdF
Uø
ÚFÜ
Ü	
Ì	Î³×~
?Ñ
Ò%ÍÔØ 
@×
ÎÒ%ÍÐ]Ö@Ò
óÎ
=P>A@
=?>Q@
Ü	Q¶
ìí
Ù`Ú
ú³û
ÌÎ³Ìw
ÎÆü
Ï9:
Ò&×lüUóîÍ
=?>A@
úËú³û
ú7ú³û
ì<ú³íSúÆû
úÆû
Ò%Î³ÌÌW°±@Ò
Ìz!Ò
Ñ
óîÍ[Ï
óîü`Ò
`Ú-æ
ÚL{&Ü
Üö
Ò%Í@Ø·Ô×qóîÍ[Ï
Ö@×ÆÌ@Ø
üUÒ
ÎÆÏ&óÍÔÒ
ÿÌÑ	Ò%ÍOÒ&Ø[Ø
ìîìúÆû
ÌZ-ÎÆÌ	ÌÌ	Í[ÌÎ³Ï
óîÌ	×
Ò
[Ö
=?>Q@
ÜN`Ú!æ
DsÚdF¹Ü
Ü¸ÜsÝº¹³Þ8ß
`Ú-æ
Ú-æ
`Ú!æ
DsÚFÜ
`Ú-æ
=?>@
èZá%é
úÆû
óÍ@ÏÍ[üÓÔÌ	Î³×
@Í
Ø/@Ñ0óîÍ[Ï
Ì>Ñ
DsÚdFÜ
Ýgß
=?>@
á%é
ÚS¼
ÜÝ!
`ÚS¼
óîÍ[Ï
Ò%ÍÔØ`ÿ§ÎÆó
Ò
×óîÍ@Ø(ÌÖÌÍÔØ(ÌÍ
úÆû
Í &Ì0Õ(óòÔÌ	Ø¾½?ó[@Ñ
Ì/Ñ
ü`Ò%Î³Ï
óîÍ@Ò
×?ÿÌ
Ò%óîÍ

ÚNL
ð
Ü
ÚNLWRZÜ
Ö@×qÌW@Ø
ó¿-ÎÆÌ	Ì`ÌÍ(þ

Üìîí

423ß
à
à
à
Ü
ç
ß
è
ß
è
Ï
è
ñ
Û
è
è
è
ú
ó
í
í
í
ì
Ò
ú
ú
ó
í
ú
Ñ
ì
ú
ì
Û
è
è
í
ú
Î
ú
Ò
í
ú
Í
í
ì

6
Î
í
ü
Í
í
ÿ
í
Í
ö
Ò
ú
ú
ì
Ì
Í
ú
ó
í
Í
í
Ò
ì
Ó
í
8
û

Î
ú
ì
Ì
Ü
ú
ú
ó
í
Ö
ú
ì

í
Î

í

ú
ú
ó
í
ö
>
û
Ò
Ì
í
ì
Ö
ú
í

Ö
ú
ì
ß
>
B
Ì
ú
ó
ú
ó
í
ú
ó
í
Í
Ó
í
>
B
Ü
V
ß
>
Ú
B
Ü
í
ü
Ñ
í
ú
Ð
í

ÿ
û
û

í
ü
í
ú
ö
:
\
\
a
a
ã
Ü
í
ú
ú
Ì

ÿ
ú
ú
ó
í
Í
ú
Ñ
ì
ú
ú
Ò
ì
Ñ
ì
ú
í
ì
ú
ú
ì

í
Î
ú
ì

ì
ú
ß
>
ß

B


í
ö
Ò
ú
û
Ñ
ì
ú
í
ì
ú
ú

Ò
Ì
Ñ
ì
ú
ì
ú
í

Ì
ú
ó
í
Í
ú
Ú
ó

Ì
Ý

û
í
ì
ú

Ö
ú
í
í

Ì
ú
ó
ú
ó
í
ú
ó
í
ì
ú
ú
ì



í
Î
í
ú

Ú
ß
>
Ú
B
Ü
ç
ß


ß
>
ß

B


¢
ÿ
û
ú
Î
í
ì

í
Î
í
ú
ú
×
ú
ú
ó
í
B


\
Ú
B
Ü
\
B


Ü

Ü
ì
í
ø

Û

ß

Ü

Ð
í
þ
í
ì
ó
ú
­
í
ì
í
Í
ì
ú
í

ú
ó
í
Í
ú
Ò
ú
ì
ú
ì
×
í

ú
ó
í
Í
ú
ì
Ò
ú
Ì
í
Ö
ú
ì

Ò
Ì
Ñ
ì
ú
í
ì
ó
ú
í

ú
ú
ó
í
Í
ú
Ñ
í
ú
Í
í
ì

Û
³
@
Ü

í
í
ì
ú
ø


µ
í
ì
Ò
ú
Ì
Ì
Ú
B
Ü

Û
è
×
þ
Ò
Ì
í
Ö
ú
ì

Û
è

Ì
í
þ
ì
×
è
í
ß
>
Ù
Ú

è
à
å
à
à
à
Ü
ç
ß
>
ß
ê
è
è
Ï
è
Ü
 
¢
8
Í
ú
Î
í
í
ú
»
è
>
ß
è
³
ê
è
³
c
è
è
³
ú
è
è
è
Ü
ú
í
þ
ì
í
Ó
ú
í
û
äÓé±æ

äå
äå
ÍWÔ

äÓé/ê;æ
ädéfý.æ
Ý?Þ
æTÏ.Î
Ý[Þ

ÀÂÁdÃÅÄÅÆÇSÈ{ÉQÊ®Ë~Ì,ÍWÎÎ7ÏfÐfÍwÑÓÒSÔÍÍrÕÖZ×TØÚÙ
âzèäSåè{æTÏfÎ
Ïà
ÍâzãäåAãÅæTÏ
Û{Ü9Ý?Þ4Ý[ß7Ý
Ý[á
Þ<ç
Ý?Þ
Æì±í¿ìî/È
ëÜ
ÍÔ¸ÎôõCÄ
ÍÔòñà[óÅÎ
Ä<ÆÂî<ÁÁ
Ý[Þ<Þ
ïfÜ
æTÏfÎ
äSø
æ¿ùºâZúWû¡ü
ó<÷
Íâ
äSø
ôõCÄ
ÍÔ¸Î 
ÄÅÆÂî4ÁdÁQÿ.ó
ÍWÔOñwà?ó<Î
þÜ
ùºâZúû¡ü
ó4÷
Íâ
äå
äå
fÜ
ì	Cõ
Ä<Æ
Ü
ÄÅÆ
ì	Qõ

fÜ
ñÍ
ÍWÔ7Ð.Í
YÈWÇdÁCñÿ
fÜ
Þ	
âèäøÅèWæ
Æ âzãäåAãÅæTÏ
Æì±È
Þ<ç
ÛÜ
ÍÔÐ
æ7â
äå
%&('
 "!$#
äNê/±æ
æà?ÿfÐTâ
äå
#+*,#
%-(.
Ô¸Ï
Íñwÿ
Í54
ÿfó4à
Ý?Þ.ßòß
Þ<ç
Ý?á
Ý[Þ<Ý
ç32
*76
01
Í;:Ñ
ñwÿ
ÍÔà?Ïf÷<ÎWÙ98
ÏÔÍòñwÿ
Þ	
ÞEß
Þ.ß
ÍÒÏfñ
ÒSÔÿ4
xñÿ
ÒSÿ.à[à?ÿ
Ôó<ñ

ßòß
Ý[ß
ßÝ
Í{Î
ÍWÔ7Ð
ÒSÔ7ÍWÍ~Í
Í:3ñÿ4
ÎÏ,ñÿ
ÿÒOÍ:4Ïfñ
Þ	
ß7Ý
2<Ý[Þ
01
ÏÔÍñwÿ
Í;:Ù
Þ<
ÀGFIHJLKNMOH;FIPNF5P
P3H
Q3RTS
B,Q
=>@?
ACBED
BEAXWCY
ACBEBVB
ÏàÓÙ`_òéaa4ê]bdcOÍ{ÎÑ
Ï5Í
Í$Z
ÒSÔ7ÍWÍ,Í
ÍWÔ7Ð])ä^
ó<ñ
ç/ÝPç/Ý
Ý\[
ÏfàTÒSÿfÔ4
ÏfÎ
Í{Î*Í
ÏàÓÙ`_Téea]afý.æ
ÍxÎ7Ï4*ÍÒSó
ÏfÎ
ß7Ý
Ý?Þ
Íñÿfó
äêf/.æwÙg8
ÍWÔ7Í
ói4
ÍÔ¸ÎÙgj
ñwÍ
Þ±ß7Ý?Þ
ç/Ý`h
Ý?Þ5ß
ÿÒ
ÏÎ7Í
ÏfÔ
ÍÎ
ÍWÔ7Ð]_
ó<ñ
ÍkZ
ÒSÔÍÍ*Í
Ð÷Åÿ
Ý[Þ±ßÝ
ßÝ[Þ
Ý\[
ÍÔñà[ó<Î
ÿfó
ÍWÔÎ_
÷
ñWÏà?à`~ñÿ
ÍZñà[óÅÎ
ÍÔ¸Îl 
Ý?Þ
ÝPç/Ý?Þ
Ý[ß
ÍÂÿ.Ô
Ïàm4Eÿ
ÍWà?ÎäS÷
ÿ.ÎÎ
à\¾ÏÒ
ÍÔn4EÍÔÐ
Ð±æwÙT8
ÿÒ
Ý?Þ
Ý?Þ
Ý\2
ÍÔQñwà?ó<Î
ÍÔ¸ÎôTÏÔÍÚÒSÿfÔ4EÍ
ÐOÏfà[à
ÍÔ¸ÎNÍ{ñ
ÎYÿÒ
ço2
[Ý[Þ
Ý[Þ±ß
ß7Ý
Ý?Þ4Þ
óq4
ÍWÔÎ9ÒSÿ.à[à?ÿ
Ízñÿfó
ÍÔòñà[ó<Î
Íÿfó
ÒSÔÿ4
ÍWÔÎWÙp8
Þ±ß7Ý?Þ
*lu
*<t
ó<Î`ÒSÿ.Ôr4ó4à?Ï .è
ÍOÔ7Í{ñwó4Ô¸Î
ÍTÌ,ÿ±Í
!(s
Ý`
24Ý
.ã
ê~ÒSÿ.Ô*Ïfà[à9ÿfó
ÍÔ*ñwà?ó<Î
ÍÔ¸ÎWÙg8
ÍÎ
ÏÔ
ó<ñ
Ý`[
Þ<ç
ÒSÔÍÍZÍ
ÍWÔ7Ð]
ÍWÍ
Ízñÿ
Í:YÙ
çÞ
ßTß
Þ	
Hx
P3F
BEv
BoA
BovwW(B
ACB
=>\=
ÀoF5HJLK
U{z
BoD
ÒSÔÍÍ3Í
ó4Í
ÍZ
ÍWÍ
àPÏÔ
Í5Î
ó<ñ
Ý\[
Þ)ß
ÎEñwÿ
Ïà?Ðfÿ.Ô
ÍxÖZ×9Ø
ÍÔÐ·Ï
Í;:
ÍÔ¸Î
ç~
Ý`}
Þ<
Þ<ç·Ý[ß
Ý[ß
ÒSÔ7ÍWÍ~Í
ÎzÍ{ÏfÎ
ÍÔÐ
à\¾ÐfÍ
ÒSÿfÔn4
Í(Z
ó<ñ
Ý[Þ4Ý
Ý`[
Ý[áWÝ[Þ
ÐfÍ
ÍÔ¸Ïà
ÍÒr÷4Ôÿf÷ÅÏÐ.Ï
Íà
ÍÔ¸Ïà
ÿ3Ô7Í
ç~2
Ý[á
ß7Ý
ç·ß
Ý?á
ÍÔÐ.ÙcòÍÔÍ
ÒSÔÍÍZÍ
æ¿ÒSÿ.Ô
äÕÖZ×TØ
ó<ñ
Í;:
Ízñwÿ
Ý`[
Ý`}
Þ	
ÒSÿfÔ4ÿfÒÚÕÖZ×TØÚÙqj
ÍzÏk4EÍWÎÎ7ÏfÐfÍÑdÒSÔÍÍ
ÏfÎ7Í
ÍWÎñwÔ
Ý`2
ßòÝ
Íg4EÍ{Î7ÎÏÐ.ÍwÑÓÒSÔ7ÍWÍÖZ×TØ
÷<Ô7Í{ÎNÍ
äcòÍWÎ
ÍWÎHÏ
Þ)ß
çªÝ[Þ
Þ.ß
Þ<ç
ÿÍ
ÍÔf_òéea]afý.æ7æ	Ù8
ÍÔÍ
ñÍ
Íÿ
à\
ç/Ý`h
Ïà?à?ÿ
.ãg
êZÒSÿfÔ
Íÿfó
ÍÔOñwà?ó<Î
ÍWÔÎWÙ
ÍÔ¸Î
ÍÔCñwà?ó<Î
ÿfó
ÿ 
äæ
ÍÔ¸Î$3m
ñà[óÅÎ
ç/Ý\±ÝPç
Ý?Þ±ß
ñwÿ
ñà[óÅÎ
ÍÔ¸Î  
Í~ÿfÔ
Ïà4Eÿ
Íà_QÏ
Ý[ß
Ý[Þ
ÝPç/Ý[Þ
Ý?Þ
Þ<ç
Ý[Þ¾ß

ÍÔ¸Î
ÍÔZñwà?ó<Î
ÙE8
ÍÏ÷4Ñ
ÍWÔÎrÿÒ 
ñà[ó<Î
ÏÔÍzÎNó
Ý[Þ4Þ
01
ÍÔ÷4ÔÍ
äSà?ÿ±ÿ±ÎNÍWà`4æ
ÒSÔÍÍ9Í
4Ï
ÍWÔ7Ð]äê/±æAñWÏ
÷4Ôÿ+:
Ý?Þ±ß
Íª÷<ÎNÍWó
ÿfÑ
Ô7ÍWÍwÑ¡à
ÍªÒSÔ7ÍWÍwÑ¡Í
ÍWÔ7Ð]uÿfÒxÏó
ÏfÎ
ß7Ý
Ý\[
÷4Ôÿ
Þi
ßÝ
Ý\2
ç/Ý
Ý[ß
24Ý
äSå
æ
âEäåAæ
äÓéea±æ

æ
äSø

ÍÔ
ÍÔHñwà?ó<Î
ÿfó
ÍÔxÏ
Ïà
ÏfÔ
Í¾Î
Þ<ç
Ý[Þ4Þ
Ý?áÝ?Þ
Ý[Þ4Ý[ß7Ý
ßT2
ÏàPÎ
4ÏÔÐ
Ý?Þ
ãäåAãÅæ
äÓé/ê;æ
âèäåèWæ2ê
æ!Ï
æpÍ:÷Qä
âzãAäSåAã
Þ<ç
ÏÔÐfÍ
Ïfà
ÿfÔ
âäåAæ
ÎA÷4Ôÿf÷
Î7ÿ
Ý`2
ßAç4Ý
ß7Ý
ß9
ß7Ý
äSå
æNæ
äÓéfé.æ
â~äSåAæÍ;:/÷Aä
ÿ.ó
ÍWÔ¿Ï
ÍWÔ
ñwà?ó<Î
ÍÔ
ÍTÔÍ÷
ÍWÏ
à`ó4÷
Í:
Ý?Þ4Þ
ÞÅç
Ð.Í
ÒSÿfÔ4Ï
Ô7ÍÑ¡ÏfÔ7Ô¸Ï
÷<Î7Íó
ÿÑ 4EÏfÔ7Ð
ÏàPÎ
ßÝ
Ý?Þ+ß
Ý?Þ
Ý[Þ
ó<Ïfà[à\
Í4N4ó
ñÿ
ÿ~4Ï
ÍWÔX4ÏÔÐ
ñwà?ó<Î
ÏàPÎ
Þ±ß
Ý?Þ
ÍÔó4à?Í*ÒSÿfÔ
Íó4÷
Ùk8
à[Í
Ð¾äÓéféfæ
ÎÏ
ÍÍW÷
ßÝ
Ý[Þ
01
ÍÔOñà[óÅÎ
ÍÔ¸Îô
Ý?Þ4Þ
úWû¡ü
äÓéý±æ
âèäåèWæ
äSåè;æp!âè.äSåèWæ¢¡
r¤
n¥
¤
Ý[ß
&]ª¬«
äSå
æ¨§©
äSå
ÞÅç
Íó4÷
ÍÔó4à[Í
ÒSÿ.Ô
Íÿ.ó
ÍWÔOñwà?ó<Î
ÍÔ¸Î 
úû¡ü
äå
úWû¡ü
äÓéæ
æ!âãäSåAã
äSåAã
äå
ÏàÕÖZ×TØ
Ïà?Ðfÿ.Ô
ÎÎNóq4k4ÏÔ
à?ÐfÿfÑ
}ÅÞ
Ý[ß
Ý?á
ç#Ý?Þ"­
ê.Ù
ñWÏ
ÍÔf_Céea]afý±æ
ÿÍ
ÍWÎzÏ
äcOÍ{Î
Ïà?ÿfÐ
Þ~2
Ý[ß
Þ<ç
Ý[ß
:/Í
÷Åÿ
ÎCÿfÒ
à?Ðfÿ.Ô
4ê
ÎCÏ
Í;:
Ô7Í4óq4
Þß
Ý[Þ±ß
ß}
Ý[ß
4óq4~æAÿfÒ
Í9ñÿ
ñÍ9ÏE4
Í:
ÒSÔ7ÍWÍ
ó<ñ
äÏ
Ý[Þ<Ý
Þ	
Ý®}
Ý\[
Þ<ç
ñÿ
ÿfó4ÔEÎ
ÍxÏfà[Ð.ÿfÔ
Î_
ÍÔÐfÙ¯j
ÍWÔ7Ð.Í
4ó<à?Ï
ß7Ý
Þ	
Ï4*÷
ÿ.ó
ÐÅÙ8Aÿ~ÿ.ó4Ô
à?Í
Ð.Í_
ÍWÔ_
Ý[ß
ßrç
Ý[Þ
[Þ
_OÏ
Ðfó<ÏfÔÏ
Ù°j¡Ò
ÍWÍ
Ïe4E÷
ÍÔ4|ñWÏ
ÍÍ
Ý?Þ
Þ±2
Þ±ß
ÍWÎzÏ
óÅñwÍ
à?ÏfÔ
Í~ÿ
ä²cOÍ{Î
ÿÍ
ÍÔf_
Ô7ÿ
Ý?Þ.ß
Þ<ç
Ý?Þ
éea]afý±æ	Ù
Ädµ·À¢Â
´µ·¶°¸º¹¼»]¸"½¾¸¿¶°ÀwÁ¯ÂTÃºÄV»<¸
ÃÅÂ¼½°¶°Æ5ÇÈÃÉ½±Ã±ÇÈÊ¼Ë"Ä
Ôó<ñ
ÍOñÿ
ó4ÔÍ_
Ô7ó<ñ
ÿ4
ÏZÐfÔ¸Ï÷
ÿ.Ô
ÔÏ
ß7Ý
Þ<ç
1n0
ÿÒ
ÒSÿ.Ô
ÏÔ
Î`Î
Ô¸Ï
ÍWÔ7Ð]
ÒSÔ7ÍWÍTÍ
_{Ð
ÍZ
ó<ñ
Ý\
Þzß
Ý\[
ñÍÿÒ
ÍÂñÿfó
Í~ÔÍWÏ.ÎNÿ
Íñwà?ó<Î
ÍÔ¸ÎÙT8
ÞÝ
Þ±ß
ßß
à`¾ÒSÔÿ4
ÏÔ
ÔÏ
ÍÔ¸Î*ÒSÿfà?à[ÿ
ÒSÿfÔ
óq4
ÍÌxÿÍÑ
Ý?Þ
Í;:
ó<Î*ÒSÿfÔ4ó<à?Ï<Ùj
Íxñwÿ]4*÷<ó
ñWÏfÎ7Í_
Íxñwÿ
ÏÑ
Þ	
24Ý
Ý®}
Þ5ß
ÿÒ
ÍEñwÿ.ó
ÍWÔÎ
ÐfÍ
óq4
ÍÔ¸Ïà?à`T4óÅñ
4EÿfÔÍ
ß7Ý
Þ±ß7Ý?Þ

424ð
ß
ö
Ü
ç
Ï
ß
è
è
è
è
ð
ß
ß
ç
Ï
ß
ã
ã
æ
ã
ã
ð
ð
Þ

ã
#
ã
ã
ã
ã
æ
)
*
â
*
*
*
*
æ
Ý
ñ
1
Î
1
4
Í
ç
ó
ß
1
Þ
Î
ß
1
Ï
ß
ß
1
Í
â
Î
Þ
Î
Ý
Î
ß
Í
ÿ
1
Í
Ý
Ô
ÿ

1
Í
0
Î
2
Þ
Î
ß
ÿ
Þ
ß
1
1
Ï
ß

Ý
Ï
ÿ
Þ
ß
Þ
Ý
Ý
ñ
1
H
U
K
8
1
1
Ý
Þ
Í
ß
[
ß
1
ß
1
Þ
ñ
ÿ
Þ
1
Í
Þ
Ý
Î
1
Ð
Þ
2
Þ
ß
1
1
Ý
Þ
ß
1
ß
Î
ß
ß
ß
ß
Ý
ñ
Ð
0
1
ß
1
ß
ß
1
Ý
Ð
ç
ß
1
Í
ß

ß
Ï
ÿ
Þ
ß
1
ß
ß
1
Ð
Þ
2
0
ß
1

ê
è
.
0
Ý
ß
1

ß
ß
1
ß
Ï
ç
Z
1
Ý
Þ
Þ
ÿ
ÿ
2
M
B
H
W
K
À
D
y
H
B
A
J
z
À
W
|
ß
ÿ
ß
1
Ý
4
Ý
Ý
ß

2
Í
ß
0
1
1
Ý
Þ
Ñ
Í
Ý
ÿ
Þ
_
ß
1
1
4
4
Ð
ß
1
1
Ý
Þ
Ý
Ý
Þ
Ñ
Í
0
Í
Ý
Ð
1
ß
Í
ç
Þ
Í
Ý
ÿ
Þ
ß
1
Í
ç
Z
1
Ý
Þ
0
Í
ç
Î
2
ç
ÿ
1
Í
[

ß
1
Þ
Þ
Ý
Î
ß
1
Ï
ß
0
Í
Þ
ÿ
0
0

ß
1
ß
ß

Í
Í
ß
1
Í
ß
ß
ß
6
ñ
Ð
0
1
ß
1
Ý
Ð
ç

ß
6
ô
Ý
ñ
1
2
ß
1
Ý
ß
Í
Þ
Þ
2
Í
ß
Í
ç
ß
1
Þ
Þ
ñ
ÿ
Þ
ß
ç
2
Ï
à

Î
ß
Ô
ó
ÿ
_

ã
â
ã
ã
&

è
â
è
è

ß

Ð
ß
1
Í
ß
ß
'
.
ã
ß
1
Ï
Ý
ÿ
Þ
ß
ÿ
ß
1
Í
ß
Î
ß
Ô
ó
ÿ
Þ
_

#
ã
'
ã

ß
0
ß
Í
ç
ç
Ï
ß
Í
ß
1
Í
ß
ß
ç
ß
1
Ï
ß
Þ
ÿ
Þ
1
Í
ß
ß
[
Í
ß
1
ß
Þ
Î
Ý
Î
ß
Í
Ý
[
Î
}
Í
ç
1
ç
Ï
ß
ß
1
Í
ß
Ý
Î
â
è

£
¡
£

£
¡

0
1
¦
è

#
ã
t
è
.
ã
Ï
¥
â
è
è
ã
t
è
â
ã
è
æ

£

8
1
ç
Ï
ß
ß
1
ß
ß
Ý
Î
â
ã
æ
â
è
è
æ
â
ã
è
æ

8
1
Í
1
4
Ý
Í
Ô
Ý
ß
1
4
j
Þ
Ï
Þ
0
1
[

ß
Í
Î
1
ÿ
0
1
Ï
ç
­
1
Ý
Þ
ß
1
Í
Þ
ß
1
Í
ç
Z
1
Ý
Í
Þ
Þ
Ý
ÿ
Þ
ß
1
Ý
ß
1
4
ç
0
1
ÿ
0
ç
1
ÿ
0
Í

ß
1
Ý
Î
Ý
Î
Þ
ÿ
ß
ç
Þ
ç
Í
ç
ç
Ð
ß
Í
ç
ç
Î
Ý
4
Ý
ß
ÿ
ß
1
Þ
Í
[

ß
³
Ì
Ý
ß
1
Ï
Î
ß
ß
ß
1
Þ
Î
ß
ÿ
Þ
ß
1
1
Ý
Þ
Ý
ß
Ý
Ð
1
ß
0
ç
Í
1
Í
ñ
1
ÿ
Ý
ß
1
ß
1
Î
ß
1
Ï
1
Ñ
Ð
Þ
2
0
Î
ß
Ý
Ð
1
ß
0
ç
ß
1
1
Í
ç
ß
1
ß
ÿ
Þ
ß
1
Ð
Þ
2
Ý
Î
Þ
1
ÍÑÓ;Ï

ÍÑÐÒÏ

ÍÎfÏ
ÔÕ`Ö]×qØÙLÚÛÝÜÙ;ÞÑßfÛÞ×qà\àÖ]ØrÕ@á(âäã+åqã æÕ®ßç3èéÙØrÕ\êÒáÒÕ@ë ìéê]×qíiáqîØrï
ë;ê]íiáÒÕ`ßrÕ\êíiðñóòôÕ\áqáqà`Ù]Û(ðrèiîeíiíqÕ`íiÖ$ßØrÙÙñóõöÕ`Ö]ç]ßfÛ(ëê÷ÙØrÕ\íqÖ
×qíië;ßrÕ\êí(ßrØÙÙ]ñ
áÒÕ`ùXë;×qà`ßºúû¯îeÕ\í	æØrÕ\Öç<ßpÙßÝîeàñ`üÒýeþ]þ]ý]ÿñ ÒÕ`íiëÙöælÙdîeØÙÕ`í<ßÙØ
ÙðßrÙfá(Õ`íTßçqÙ èéÙØÞê]ØLîíië;ÙGêeÞíqÙfð
ßÙá3ë;ê]í	÷ÙÒÕiÙáCë;à\×iðßrÙØ
îeèièqØrê	ÒÕ
LîßrÕ\êíéðüÝæÕ®ßçqê×ÒßCçiî+÷	Õ`íqÖî¯Ö]ÙíqÙØîàöîeà\Öê]ØrÕ`ßrç
ÞêØpëêkèq×ÒßÕ`íiÖIë;ê×ií]ßÕ`íiÖoí	×nìéÙØðüeælÙØrÙfð
ßØrÕ@ëßmê×iØðrÙà`Þißê
îeèièqØrê	ÒÕ
LîßrÕ\êíéðêÞkêÒáÒÙà@ðæÕ®ßç
ØÙÖ]×qà@îeØÖØîeèqçiðü+íiîkÙà`ï
è7ÙØÕ\ê	áqÕ\ëdìéê]×qíiáqîØrïLë;ê]íiáÒÕ`ßrÕ\êíiðÝîeíiá
îeí
ðÕ\íqÖ5Ö]ØrÕ@ákæÕ`ßrç
ðrÕ\íqÖ
Þ×qà\à`ï(ë;ê]íqíqÙë;ßrÙfá
êÒáÒÙà²ñ
í~úû¯îeÕ\í	æØrÕ\Öç<ßÙ;ßdîà²ñ\üiýeþ]þ]ýÿ;üqîkë;êí	÷]Ù
ë;ê5ìqÕ\íiîeßrÕ\êí(êeÞ
îeà\àpðrèiîeíqíiÕ`íqÖ(ßØrÙÙðoÕ`ígßçqÙLÖØîeèqç¼Õ\ðoßî]Ùí
à\Ùî]áÒÕ\íqÖ
ßê3î
ë;ê]í	÷ÙÒÕiÙáÝÙßrçqÙoÞØÙÙoÙíqÙØrÖ]ïmñíCßrçqÕ@ðîeèqèiØrê	ÒÕ
kî
ßrÕ\êínßrçiÙlê]×ÒßrÙØëà`×éð
ßÙØðîØrÙÝßrçiÙlèéîeÕ\Øð9êeÞë;êíiíqÙë;ßrÙá5íqêÒáÒÙð
Õ\í$ßçqÙ
ðÕ\íqÖ
êÒáÒÙà²ñíÅúûgîÕ`í	æØÕ`Ö]ç<ßoÙß îà²ñ\ü9ýþþ]ý]ÿü7ßrçiÙ
áÒÕ@ð
ßØrÕ\ìq×ÒßÕ`ê]í pú"!5ÿXÕ\ðXêèÒßÕkÕ
#Ùá±î]ðLælÙà\à²ñ%$öÙØrÙôælÙ&
pú"!
ÿßê5ì7ÙE×qíiÕ®Þê]ØTñ'öíiáqÙØÝßrçqÕ@ððÕ
kèqà`Õ`Þï	Õ`íiÖnë;ê]íiáÒÕ`ßrÕ\êí
îeíéáLî<Õ\íqÖL×iðrÙ êeÞßrçiÙ5ðï(kÙ;ßØrÕ\ÙðÕ\íTßrçqÙ)
êÒáÒÙà\ðßrçiîeß
ælÙdë;ê]íiðÕ@áÒÙØü]æÝÙöëîeíXë;ê]íiðßrØ×iëßÝëêí	÷Ù*ÒÕ+iÙfá,GÕ	×iëçqÕqÞØrÙÙ
ÙíiÙØÖÕ\Ùð-
èiØrê÷	Õ@áÒÙoðßrØÕ@ëßrà\ïLßÕ`Ö]ç]ßÙØì7ê×qíéáqð
ßrçéîßöæÕ\à`à
úý8]ÿ
kÕ\í/102kÕ`í34.205kÕ`í3476
ðÕ\íqÖGkêÒáÒÙàÒßçiîßpælÙöë;ê]íiðrÕ\áÒÙØmÕ\ðîGÖØÕ\ánêeÞýIHJ
FçqÙ-iØðß7
ýIH±íiê	áqÙðnæÕ®ßç·è7ÙØÕ`êÒáÒÕ@ëXì7ê×qíéáqîeØïgëêíiáqÕ®ßÕ`ê]íiðCúßrê]Ør×iðÿñ
Kî]ëçCíiê	áqÙIÕ\ðdë;êíiíqÙë;ßrÙáCßêkÞê×qØöíiÙÕ\Öç	ìéê]ØðñpûgÙ5áÒÙíqêeßÙ
Ú<úî]ÿrÿñ
ßrçiÕ\ðÖ]ØîèqçCî]ðâMLN
LNgúðrÙÙ ÔÕ\Öiñ
ûgÙEë;ê]íiðrÕ\áÒÙØèiîÕ`ØlîeèqèiØrê	ÒÕ
kîeßrÕ\êíiðîeíiáXýOJLýGë;à\×iðßrÙØîeè
èqØê	ÒÕLîßÕ`ê]íiðñPF9ê¼æØÕ`ßrÙTáÒêæíQ4.üpæÝÙ(çiî+÷]ÙXßrê¯ë;êR
èq×ÒßÙ3ßrçiÙ¼ë;ê]×qí<ßrÕ\íqÖ~í	×5ì7ÙØðSTiñ¬Ôqê]ØXßrçiÕ\ð
æÝÙ$áqØî+æ
ßÙØð$îíiá¬ð×iì7ëà`×iðßrÙØð
ë;à\×ið
×iíiëßÕ`ê]í¬ßrØÙÙæÕ`ßrç
ØîeíiáÒê
UúV!5ÿñ
ðrÕ\íqÖà\Ù;ßêí
ÔqêØ·Ùîëç
ï	èéÙ±êÞTëà`×éð
ßÙØfüLíiîkÙà\ï
úÑß
ï	è7ÙRWúÚfÿÿ;üäèiîeÕ\ØkúÑß
ï	èéÙRWmú²ý]ÿÿü
îíiá¼ýXJ$ý
ßÙØLúÑß
ï	è7Ù
ëà`×éð
WmúZY<ÿrÿüælÙXë;êkèq×qßrÙLßçqÙ
ëê×qí<ßÕ`íqÖ$í<×[5ì7ÙØð
ðr×
êÞßrçqÙ
îíiá·áqÕ`÷	Õ@áÒÙ(ßrçqÙTØÙðr×qà®ßkì	ï~ßrçiÙ
ú"]ÿX^`_
ï	èéÙnWmúZ]
ÿlêeÞmë;à\×ið
ÿlÕ\íCßçqÙIê]ØrÕ\ÖÕ
ßrêßîà
í	×5ì7ÙØ3Hpú"]
ßÙØðêeÞß
íiîà7Ö]Øîèqç
ü<ßrçqÙfðÙGîeØÙ/HpúÚfÿ7^ YH
ñíXßçqÙGâ
Ö]Øîèqç
Hpú²ý]ÿO^qpH
ü9îíiárHpúZY<ÿO^qYH
ñFçiÙ
ØÙðr×qà`ßrÕ\íqÖ3ë;ê]×qí<ßrÕ\íqÖ
í	×5ì7ÙØÞêØlë;à\×ið
ÿü<æçqÕ@ëç
úZ]
ÿtIHpúZ]
ÿ7^
ï	è7Ù3]Õ\ðsSeúZ]
ßÙØðpêÞ7ß
ëîíôì7Ùnðr×qìiðßrÕ`ßr×ÒßÙáôÕ\íóúÚvu<ÿÞêØdßrçqÙSwTx
ðEæÕ®ßçyW¯êeÞmß
ï	è7Ù
]ñ

b?cedgfihTkjl
m
LoN

<>=?<@BACAD<*E

94:";

TRa

LN

.

pH

.

L~

YH

L~

L~

L~

Ls~

L~
YH

ÍÑÓ;Ï
ÍÑÐ	Ï
ÍÎ+Ï
ÍZz<Ï
ÙÞÑßÛÞ×qà\à`ïTë;ê]íqíqÙfëßrÙfá{|eñpò3Õ@áqáÒà\ÙÛðrèiîíqíqÕ\íqÖ
ÔÕ`Ö]×qØÙ ýqÛpÜ
×qíiëßÕ`ê]í(ßrØÙÙðñ
ßrØÙÙ]ñpõÕ\Öç<ßÛß
ælêkëê÷ÙØrÕ\íqÖ
ßrØÙÙXú²ðÙÙIÔÕ`Öéñ
 ÞæÝÙIëêíiðrÕ\áqÙØöîkðèéîeíqíqÕ\íqÖ
Ú]úìéÿÿ;üqæÝÙnéíiá
ý]ÿñdðînØÙðr×qà®ßælÙ
úýÿ7^}YH
Úoîíiá
Úfÿ7^
úZYH
iíiáCÞê]Ø3¼ßrçqÙIëê×qí<ßÕ`íqÖkí	×nìéÙØð
ýH
úý<ÿ
Ú+ÿ7^
Seú
îíiá
Seúýÿ7^
ýIH
îèqèqØê]î]ëç¼ælÙCëêíiðßrØ×iëß
Ôqê]Ø5ê]×qØnëà`×iðßrÙØ
îôðÙßnêÞ
×qíiëw
ßrÕ\êíIßrØÙÙðîðäÞê]à`à\êæöðÛßî]Ù7Hkíqêíê÷]ÙØà\îèqèqÕ\íqÖçqêØÕ#êí<ßîà
ßÙØðîeíiákë;ê]íqíqÙfëßßrçqÙfðÙ÷]ÙØrßrÕ
ï	è7ÙY ë;à\×ið
Úß
ðßrØÕ`èiðêÞýH
ëîà`à\ïIì	ïGH
ÚîáqáqÕ®ßÕ`ê]íiîeà<ß
ï	èéÙ*Y ëà`×iðßrÙØðú²ðÙÙÔ9Õ\ÖiñÒÚ<úëfÿÿñ
 	çqÕ`ÞÑßrÕ\íqÖ
îíiá(ØrêßîeßrÕ\íqÖkßrçqÕ@ðèqØêÒë;ÙfáÒ×qØÙ à`ÙfîáqðßêXîkçqêkê
ú²ýÿ7^
ÖÙíqÙê]×ið
ðrÙ;ßfñûgÙ7iíiá
úZY<ÿ7^ºýIH
Ú]ü
ú²ýH
ýÿ;ü
×iíiëßÕ`ê]í5ßØrÙÙðßrçiÙ
úÚfÿ7^°þqñ 	êiüeæÕ`ßrçnßrçiÕ\ðpëçiêÕ@ë;ÙlêeÞ
îeíéá
îØrÙ
ë;ê]×qí<ßrÕ\íqÖkí	×5ì7ÙØðlÞêØ3
ýH
ýH
îíiá
Seú²ý]ÿ7^
úýÿ
Seú"Y<ÿ7^
ýIH
ðèéîeíqíqÕ\íqÖ(ßrØÙÙfð îeíiágØÙðßrØÕ\ë;ß
ÖêTìiî]ë3ßrê(ßrçiÙ
 ÞæÝÙLíqêæ
ßrçiÙkðrèiîíqíqÕ\íqÖXßØrÙÙðEßrêCßrçqê<ðÙ5ßrçiîeßIîeØÙnë;ê]í<ßîeÕ\íqÙfá3Õ`í¼ßrçiÙ
úæçqÕ@ëçCÕ@ðlßrçqÙIëîðrÙ
×qíië;ßrÕ\êí(ßrØÙÙfðîðë;ê]íiðßrØ×iëßÙá
îìéê÷]Ù
ßrçiîeßßrçiÙöØrÙfð×ià®ßÕ`íqÖnë;ê×ií]ßÕ`íiÖ í<×[
Õ\íXÔ9Õ\ÖiñéÚ]úìéÿÿ;ü<ælÙiíéá
ì7ÙØð îeØÙnßçqÙXðîkÙLîðGÕ\íÈúý<ÿñLÔqØêOßçqÕ@ð æÝÙLëêíiëà`×iáqÙ
ßrçéîßßrçiÙIîeèqèqØê	ÒÕLîeßrÕ\êíiðlîeØÙGíqÙðßrÙfá(îíiágú²ý8]ÿÝçqêà@áqðñ
ûgÙóáÒÙíqêeßÙ~ßrçqÙÞ×qà`à\ï¬ë;ê]íqíqÙë;ßrÙfá%
ðÕ\íqÖ}kêÒáÒÙànæÕ®ßçH
íqêÒáÒÙfð
úðrÙÙôÔÕ`Öéñlýiúî]ÿrÿñûgÙ$ë;ê]íiðÕ@áÒÙØXèiîeÕ\Ø
îíiá
îð{
í	×nìéÙØð¼îeØÙ
ßrØÕ\èqà`ÙßgîèqèqØê		Õ
LîßÕ`ê]íiðñFçiÙóë;ê]×qí<ßrÕ\íqÖ
íqÙÙáÒÙfá·Þê]ØXðÕ\íqÖ]à`ÙßrêíéðôúÑß
ï	èéÙ&Wmú²ý]ÿÿü
ï	è7Ù&WúÚfÿÿ;üèiîeÕ\Øð3úß
ï	è7ÙRWúV]ÿÿ;ñíôßçqÙkÖØîeèqçr{
îeíéá3ßrØÕ\èqà`ÙßðkúÑß
Ú+ÿ3^Hmü
ü?Hpú
ÚfÿúZH
Hpú²ý]ÿ7^ Hpú"H
ÚfÿoteýqüqîeíiáHpú"<ÿ7^ Hpú"H
ý]ÿtIiñ
ßrØÙÙXú²ðÙÙIÔÕ`Öéñéýqúìéÿÿ;üqæÝÙnéíiá
 ÞæÝÙIëêíiðrÕ\áqÙØöîkðèéîeíqíqÕ\íqÖ
ýÿ;ñFçqÙôØÙðr×qà`ßrÕ\íqÖ
Ú¼îeíiá
úýÿ^H
úÚfÿ^
ú"H
ë;ê]×qí<ßrÕ\íqÖkí	×5ì7ÙØðlÞêØ34gîØrÙ
úýp<ÿ
SeúÚfÿ7^
îeíiá
Seú²ý]ÿ7^
Ôqê]Ø$ßçqÙóßrØÕ`èqà\Ù;ß¯îeèqèiØrê	ÒÕ
kîeßrÕ\êí¬ælÙóëêíiðrÕ\áqÙØ
×qíiëßÕ`ê]í
çéî+÷Ùôë;à\×iðßrÙØðLêÞGßrçqØÙÙôíiê	áqÙðüöîeíiá±ðrÙèiîØî
ßrØÙÙfðLßçiîß
áiÿrÿñ(ÔqêØnð×iëçgß
æÝêTíqêÒáÒÙfðXúðrÙÙXÔÕ\Öiñýiúëü
ßrê]ØðGêÞß
ï	è7ÙLêeÞ
×qíië;ßrÕ\êí3ßØrÙÙðælÙGiíéá
ú"<ÿs^H
]ÿü
úýÿ^
úZH
ýÒü

CX@@nOE<v=?<*@BAXEO

94:

425ø
î
ü
ü
å
î
ø
ß
\
\
T
å
L
ü
L
L
\
ø
\
\
ú
~
L
~
Ú
L
~
L
~
Ú
L
ø
~
~
\
\
~
\
ø
Ú
L
~
Ú
L
ø
N
N
~
~
~
\
~
\
~
~
ý
H
~
H
~
ý
H
ø
ø
\
~
\
~
~
¡"¼k£7¤

) M¡i¢	£7¤}¥[¦§(¨ª©«¬[[n­Z¨®¯4°±&²³[«s´*¨µk²¶
·ªkµ[¸)¹«*®º
¡ÀÁk£
´³ºÃ[[¶[·Q²o®«v«r¶º´¨²¶
«vÄ¶%rÅiµ[´²¶
¨²®o«*«¦
³«v®«*­Z¨®o«r²o³«ÇÃ[Ã®¨	ÈÉ¶
¸I²¶
¨º®«Ê·¶
Ä[«vºg²«v%[
¡VÀË£³¨Ì
ºv¦

¡VÀ£7¤

¾¿
¾¿

[

¾¿

¼£
¢>£

À¡

¢>£

³«&Ã®o«¬ÈqàoÛnáâ¡Z¶¦

ÎsÏÐÒÑ}Ó)ÔyÕrÏÉÖQ×Î
«Ã[ÃÌÙÊ¡VÚ/£¡ÛG£iÜ-Ý}²o¨X²o³«)Þiº¶[·X¸¨(«*ÌºªÉ«>º´*®¶
¹«v¶

²³[«Ã®«vß(¶¨µ[ººg«>´w²o¶¨?¦
«ãà·«v«*®Ìä
¶
å*«v[á£wãO¶
¸RÃ[Ì¶
«vº²³[«Pµºg«P¨­R¨µÉ²o«*®ä´*Ìµ[ºg²«v®oºÌ
®·«*®²³[
²i©s¨[ã[¸R«vÌÙæ²o³«yÀçÇÀ­Z¨®)²o³«&·®o¶
ºRÊ²³[«²o®¶
ÃÌ
«²oº
­Z¨®²³«­ZµÌ
Ì
ÙP´*¨«>´w²o«vr¸R¨ÉÉ«vÌ
ºv¦
³[«Ã®«*¬ÈÄàoÚ3áÊ¡Z¶¦
«¦ã
àg®o«*©s«*¶
·³k²o«vák£wã¶
¸ÃÌ¶
«vº²³[«ªµ[º«3¨­´¨µ[²o¶[·(µ¸)¹«*®º
»wè
­Z®o¨¸²o³«y´¨kß«ÈÉ¶¬[«vQ­Z®«v«&«*«v®·ÙÇºÉ«>º´*®¶
¹«>5¶5²³[«
Ã®o«*ß(¶
¨µ[ºº«v´²¶
¨%®o²³«v®&²³[é²³«Qºg²o[®o¨«>º¨¹ä
²o¶[«v¹(Ù²³«êy¨k«v¹¶
µ[º®o«*ÌI²¶
¨¦7ë¨®3Ú)¡VÛG£iÜ-Ýâ©s«nµ[ºg«>
²³[«ÚÛnÜ-Ý1Ì·¨®o¶+²o³¸`º«vºo´®o¶¹«vQ«v®oÌ
¶«v®)¶
Ç²³[¶
ºRÃ[ä
Ã«*®>¦ë¨®y¡VÛG£gÜsÝì©s«µ[º«v2²³[«BÉ¨µ[¹Ì«*äÌ
¨(¨ÃâÌ
·¨®¶²³¸
É«>º´*®¶
¹«>¶
Ê¡"í/«vºî«vº-«*²/Ì¦ã[À¥¥¼£w¦
ï?ð"ñ
òOóôGòOõö*÷òªøùsúûüòªùGýoþô
«3´¨ºg¶É«*®o«vÞiº¶·n·®¶ºÿ  [ÿº©«vÌÌº²³[«
­ZµÌ
ÌÙ&´¨«>´w²«>&¸¨(«*Ìº	G[
¦
³«ßI®o¶
¹Ì
«vº¶

²³[«R¸¨ÉÉ«vÌ
ºn®o«)¹[¶[®Ù
s¤¢¦
«´³¨(¨º«O¡	£/¤
*>£©¶²³
/²o³«kµ[¸)¹«*®R¨­
'(!$#)%
 "!$#&%
³[«G«È(²«v®[Ì¬[«*Ìº3®«O·«v«*®I²o«v
«v¶·³k¹¨®ºs¨­¨ÉÉ«,+¦
´v´¨®oÉ¶
·-#
¥[¢>£¡Z¶
R¹¨²o³)²iÙ(Ã«-¨­·®oÃ³[º£?[
¡"¥21¥23
(.0/
£4­Z¨®
²³[«-²¨®oµ[º[
´¨µÃÌ
¶[·º´v´¨®oÉ¶
·ª²¨54
¡V¥187
-.6/
£wã?©¶²³0=²³«(µ¸)¹«*®G¨­¨ÉÉ«>ºn¶r²³[«
¡"¥21
9.:/
·®Ã[³?ã3­Z¨®²o³«P­ZµÌÌ
ÙÄ´*¨«>´w²o«v}¸¨ÉÉ«vÌV¦
«Ê´¨[ºg¶É«v®
Ë1oÀ1oË 1v¢v¥E¦
¥3eÀ 1o¥3eË 1¥23BË 1v¢C1*¢D3
«*¶
·³k²ºo´*Ì¶
·kº?>¤A@
¶+²o³
«v´³Bºo´*Ì
¶
·[ã©«R·«v«*®I²o«vyËX¸R¨ÉÉ«vÌ
ºv¦Gë¨®ª«>´³y¸¨ÉÉ«*Ì
®o«vÌ
¶
åvI²o¶¨y©s«R®Pºg¶
¸)µ[Ì
²¶
¨[ºO©¶²³æÚ3Ü-Ý
ã?Ü-Ý
ÚÛnÜ-Ý
¦ÞÌÌ®µº*ãk©«O´¨¸RÃ[µÉ²«>²³«ª«È´²¸¶[¶¸Ì
ÛnÜ-Ý
­Z®o«*«B«v«*®o·Ùâ¯GFIHKJ&LM¤
Ì
¨·ONã²³[«r«*ÈÉ´w²«vÉ·«BÃ®o¨¹[ä
¹¶
Ì¶²¶
«vºQP¡
²³«ÃÃ®o¨	ÈÉ¶¸²¶
·­Z®«v««*[«*®o·Ùr¯(JRRTS

U'H
´v´¨®oÉ¶
·%²o¨
Ã[ºg«vµ[É¨ä
¡i¢>Á£ã&[ì²o³«éÃÃ®o¨	ÈÉ¶¸I²o¶[·
¸®o·¶
[Ìºs¨²³«G«>É·«>ºWV¡	£¦
ï?ðYX
Þn¬[·µ®«7¼3©«ÃÌ
¨²²«>O­Z¨®?²o³«­Z¨µ®?¸¨ÉÉ«*ÌºM²o³«7¸IÈÉ¶
¸)µ¸
¹ºg¨ÌµÉ²o«GÉ«*ß(¶I²¶
¨æ¡"ê[Z\n£-¨­
V¡
¡V¼¥k£
¸È
d)egfih
²³[«G®«vÌ
²¶
ß«O«*®o®¨®s¶
­Z®«v«n«*«v®·Ù
UH¿
¯kFHTJ&L'M

«vÉ·«nÃ®¨¹[¹[¶Ì
¶+²o¶«>º


õònüþûùRü

ê]Z\é¤

¸IÈ
a`&bCc
'_

FHTJ&L'M

P¡

¡V¼¢	£

JRRTS

£ã



reweighted

0.6

0.4

0.2

D
A
M

0.6

0.4

0.2

D
A
M

conventional

0

0

0.5

1

1.5

0
−10

0

10

20

ë¶·µ®o«lm§É´vI²g²o«*®ÃÌ
¨²¨­OÃ«v®g­Z¨®¸[´«¶âê]Z\
­Zµ[´²¶
¨r¨­®«vÌ
²¶
ß««v®®o¨®
ã3¡ZÌ
«­
²¶
¨º¡"Ú3Ü-Ýì[5ÚÛnÜ-Ý
Ã®o¨	ÈÉ¶¸I²o¶¨[ºn¡"Ü-Ýâ[ÛnÜ-Ý

ºR
­Z¨®ª®o«*©s«*¶
·³k²o«v&ÃÃ[®¨	ÈÉ¶
¸ä
²££[5´¨(ß«*k²o¶¨[ÌÃä
ã?¡Z®o¶
·³k²££w¦



¦[¡

¦Þ

ãkÛnÜ-Ý£

²o³«*¶
®n®«v©«v¶·³k²«v´*¨µk²o«*®oÃ[®²oº¡"Ú3Ü-Ý
[q

é²³«Q¹[º¨Ì
µÉ²«ÊßIÌ
µ«>º¨­R²³«>ºg«Q®«vÌ
²¶
ß«Ê«*®o®o¨®º
Ý7Ì
¨²²«>G®o«²³«¸«vºGºi²[®oG«*ß(¶
²¶
¨[º¨­(²³[«vº«
µ[k²o¶+²o¶«>ººs­Zµ[´²¶
¨&¨­
¶
²o«*®´²¶
¨&ºi²o®«v·²o³>7¦
[Xÿ
ã¶¹¨²³²³[«´¨(ß«*k²¶
¨[Ì
²³«n·®o¶º-ÿ
  
p 
Ã[Ã®¨	ÈÉ¶
¸I²¶
¨º¡"Ü-Ý
ã7ÛnÜ-Ý£º¶Q²³«&®o«*©s«*¶
·³k²«>ÇÃä
Ã®o¨	ÈÉ¶¸I²o¶¨[º¡"Ú/ÜsÝ
ÚÛnÜ-Ý£wãv¶´®o«vº¶
·3´Ì
µ[ºg²«*®º¶åv«7´¨ä
º¶
ºg²«v²oÌÙÊ¶
¸Ã®o¨Iß«vº²³«&®o«vºµÌ²)mÛnÜ-Ý1¨µÉ²oÃ«v®g­Z¨®¸ºÜ-Ý
qÚÛnÜ-Ý¨µ²Ã«*®­Z¨®o¸ºQÚ3Ü-Ý
¶+²o¶¨?ãX©s«}ºg«v«
²³I²²o³«ª´*¨(ß«vk²¶
¨[ÌÃÃ®o¨	ÈÉ¶¸²¶
¨[º3¡VÜ-Ý
¨µÉ²gä
Ã«*®­Z¨®o¸
Ú-ÛnÜ-Ýs£
¹¨²³&¶
²³«ê]Z-\
ã[²³«)®«*ä
¶²³&²³[«G­ZµÌ
ÌÙ&´¨«v´²«>¸¨ÉÉ«vÌ
º-
«*®o«*k²nÃ¶´w²µ[®«R­Z¨®O²o³«´¨ä
ºµÌ+²ºGºg³[¨I©´*¨¸ÃÌ
«²«vÌÙrÉ¶gr
ß«vk²¶
¨[Ì(ÃÃ®o¨	ÈÉ¶¸I²o¶¨[º)mÛnÜsÝrÃ«*®­Z¨®o¸º¨ÌÙ)©«vÌÌ(­Z¨®
º¸ÌÌs>¦Þ­O>2¶ºn¨­s¨®É«*®O¨«ã?¨®nÌ®o·«v®vã²³[«ÛnÜ-Ý%Ãä
Ã®o¨	ÈÉ¶¸I²o¶¨´*¨Ì
Ì
Ã[ºg«>º[RÜ-ÝP¨µÉ²oÃ«v®g­Z¨®¸º7ÛnÜ-Ý
³[«
Ì®o·«G«*®o®o¨®¹[®oº¶
rÛnÜ-Ýâ­Z¨®W>utq¢®o«Éµ«G²o¨²³«)­"´²
²³I²s­Z¨®ºg¨¸«/¸¨ÉÉ«*ÌM®o«vÌ¶
åv²¶
¨[ºsÛnÜsÝ2Ã«*®­Z¨®o¸R«>ß«v®Ù
©s«*Ì
ÌVã-[Q­Z¨®¨²³«v®oºRß«*®oÙÇ¹[£w¦
Q²o³«¨²o³«*®³[Mã
[É¶[·â´*¨¸ÃÌ
«ÈÉ¶²iÙ}¶é²o³«Ê®«v©«v¶·³k²«vÃÃ[®¨	ÈÉ¶
¸²¶
¨
Ì
©-	Ù(º¶
¸Ã®o¨Iß«vº²³«r®«>ºgµÌ²)mæÚÛnÜ-Ýì¶
ºÌ
©s	ÙÉº¹«²²«*®
²³rÚ/ÜsÝ
³«R¶¸Ã®o¨Iß«v¸«*k²ª¶ºO®«v¸®îI¹ÌÙ&´¨[ºg²ok²>ã
Ì
¸¨ºg²¶[«*Ã«*[É«vk²3¨­G>ã[[¶
[É«*Ã«*É«*k²3¨­©³«²o³«*®
²³[«ÃÃ®o¨	ÈÉ¶¸²¶
¨¶º-·¨(¨É¨®¹[M¦
¨)¶
kß«vºg²¶
·²«3²o³«O®«vÌ
²¶
¨X¹«²i©s«*«v
Xê]Z\%¨­?²³[«
²i©s¨É¶vr«v®«vk²O´Ìºoº«vº3¨­ÃÃ[®¨	ÈÉ¶
¸²¶
¨[ºvã[©s«)Ã¨(¨Ì
«vyÌÌ
²³[«)ºg¶
¸)µ[Ì
²¶
¨&®«>ºgµ[Ì+²º¡Z¶¦
«¦¨­ÌÌ?²³«®oµ[º­Z¨®²o³«n­Z¨µ®
¸¨ÉÉ«*Ìº©¶²³ÌÌÉ²o³«/º«²²¶
·º¨­>4£
¶
²o¨n²i©¨G·®¨µÃ[º)m?¨[«
­Z¨®/²³«)®«v©«v¶·³²o«v&Ã[Ã®¨	ÈÉ¶
¸I²¶
¨ºG¡"Ú3Ü-Ý}[&Ú-ÛnÜ-Ýs£
X¨[«/­Z¨®²o³«G´¨kß«*k²¶
¨ÌÃÃ®o¨	ÈÉ¶¸I²o¶¨[º/¡VÜ-Ý2[
ÛnÜ-Ý£¦Þ¬·µ®o«lX©s«)¸É«ºo´*²g²«v®/ÃÌ
¨²º/¨­7«v´³Ã¨(¨Ì
¹(ÙÃ[Ì¨²g²¶
·)²³«/ê[Z\éß«v®oºµ[º
­Z¨®«v´³º¶¸µÌI²¶
¨®oµ?¦
Þy²o³«vº«RÃÌ¨²oºª©«Rºg«v«)²o³[I²ª²³«®o«*ÌI²o¶¨¹«*²i©«v«*
[
ê]Z-\
¶
ºs¸µ[´³ºg²®o¨[·«*®s¶
²o³«O²³«n®o«*©s«*¶
·³k²«>Ã[Ã®¨	ÈÉ¶ä
¸I²o¶¨[ºs²³[&¶²³[«´¨(ß«*k²¶
¨[ÌÃÃ®o¨	ÈÉ¶¸I²o¶¨[ºv¦
©«¶(ß«vºg²¶
·I²o«vP²o³««wr«>´w²¨­3¶
[´®o«vºg¶
·
ëµ[®g²o³«*®o¸¨®o«ã
²³[«´Ì
µ[ºg²«*®ºg¶
å*«¶
Ê«v´³r¨­s²o³«ÃÃ®o¨	È(¶
¸I²o¶¨r´Ìºoº«vºv¦
ë¨®ª«>´³y¸¨ÉÉ«vÌ4®o«vÌ¶
åv²¶
¨?ã©«´¨¸Ã[®o«v²o³««v®®o¨®º
­Z¨®G²o³«XÃ[¶®RÃÃ[®¨	ÈÉ¶
¸²¶
¨[ºnÜ-Ý[ÊÚ3Ü-Ý
Êê]Z\

426»
½
¾
¡
»
¿
¾
¡
Â
Æ
Í
Ø
Æ
Æ
Ø
Æ
Ø

¾
¾
¾
Æ

4
7
;
<
Ø
Ø
ã
¿
^
£
¿
£
h
1
j
¤
¯
¯
1
e
e
j
h
j
h
¦
n
o
ã
ã
ã
j
¦
Ø

Æ
o
¦
Æ
Æ
j
j
j
j
0.6

D
A
M

0.3

0

100

D
A
M

10−3

10−6

0.3

0.2

0.1

0

100

10−5

 
|
 

 e
|

10−10

T6x6

100

101

100

101

100

101

0.6

D
A
M

0.3

0

100

D
A
M

10−3

10−6

0.3

0.2

0.1

0

100

10−5

 
|
 

 e
|

10−10

K9

100

101

T8x8

100

101

0.6

D
A
M

0.3

0

100

D
A
M

10−2

100

101

100

101

10

5

0

K12

100

101

100

101

0.6

D
A
M

0.3

0

100

D
A
M

10−2

10−4

10

5

0

100

101

100

101

100

101

100

 
|
 

 e
|

10−3

10−6

100

 
|
 

 e
|

10−3

10−6

100

101

100

101

100

101

100

101

x(yvzD{|~}?2OC{52O|~Cv}wIWa9|~yvzD)'})a{v~D|8k5zC|~yyva
5 
¡¢DQ  }))£}w|~yv  yY¤?¥D{2C|a¦
¤*D2 yvayC2§©¨?¥ªW})a{g§ªC|5««p¬$'¤W})a{g§QC|5­	®¯I{v¦°¤*C2})¤*a})±5²}wyg~i³[  })§©¬:'2ª})a{v~QD|
­´µ8¬sx(yv|§O|~p,(¶[p· yv9C¸C¥2aC{ a}" }w¹²yYpayC¯'¶]º-"»D|O} zC}"£|~C¥2C¥yvyvay})G¼G'½¾¿À })¤*D2	|~p,
¶]ºª²yvvDzª~¤wCv}D¬
Áy|~|~p,s}wYp~yv¹D},}w|~|aD|Oy|a})},}w})|azD¦ÃÂO¡ÄÅGÆÇaÇTÈ
ÉÊË¯ÅGÌIÊKÆ&ÍÎKaÏ8ÅkÌÊTÆ&Í'Î»yy})C|Wa¤)8}C¬»x2C{|aaq|~p,ÐC¥2aC{ a}?¹p8{})
8O|a})8ay¹C}ª}w|~|aD|~5Ñ
ÂpÑyÒCzq~¤w8}C¬Q})a{v~?8|~}Q£vC~})ÒC|,Ó?ÔÕÄ{v»vy}*kWÔÕ'D2})2*GÓ?ÔÕÄCa ÖT 8aa})
8[ÔÕÄ 8aa}2©¬9×-v¦
{2££})|,£28|a~"C»}w|~|aD|a¥8|§W8|~}Q|~
D|?¹yYa{28s¤*Y8|~yvK¦C¬	'ØG8|~zC}Q}w|~|aD|a¥8|§yvu­
82Ò­´µ
8|~}?yv
Ó?ÔÕÙ|a}{2g§~*¬
yva0~}¤wv{2a})|ªC££|~·²y9p~yvDÒy0a2}~85}Ã8£2£|a· yvÖ
9p~yvz5¤*YC~) Ó?ÔÕÙ8ÃÓ?ÔÕ±|~})a£}¤©~yv¹D}w¦C¬sÁ},a¤)paÖ
a})|s£8~(yÚzC{|~}Û"¤wv}8|~v¦,ap0apsyvªa2}O|~}wO}wyzC~})
8£2£|a· y9payC	¤wDa~}-£}w|aC|~982¤w}yvaC|azD}w|O¤*{2KÖ
a})|~kyv5£|~p¹C}yÜ8C5  }w|a}8yvÝp~yvD2w¬x2C|ka}O8££|~·²Ö
y58ayCÒyv[Å5¸~yY-y5£|~p¹C}w5})D-y-a2}wC|~}*~y¤)8v¦qzD{28|aÖ
8~}w})¬Á2}Üyv5£|~p¹C})5}wWyv
¥8~]Â-C2
¶]º-ÞyYa{|aÖ
£|~yayzC¦9¤*CK§8)¬(ßT	~}-¤wC²¹C})D~yvD288££2|a· y58ayC
¤*YC~)C~}y5£|ap¹D}w5}w¤wv}8|~v¦5 })£})2OC5~}-|~}wzDyv5}D¬
ßTqa2}})D¦|a})zCy5}	'a5CvÐÂa98G¶]º-"*Y8|~zC})|W¤*{2KÖ
a})|~ªyQ£2|ap¹D})a}|a}{2g§w¬ußT°a}28|§0|~}wzDyv5}Ò'C|azD}
ÂDY8|~zC}-¶]º?©²y2¤*|~})Dyz¤wv{2a})|OayÝw}9¦5C¤*a{2Cv¦Q
2C|aq¬ªx2{|aa})|a5C|~}C¸~}w|~}58|~}ª}w· ¤w}w£ ~yvD2)-aC5}*~yv5})
ÔÕiyv5£|~p¹C}{2£D
Ó?ÔÕi}w¹D}wyv~},})D¦9|~}wzDyv5}C¬

x(yv yv2zD¤w¤*{2|~8a}ªC££|~· yv9p~yvD2WC»zC|§8£2y¤)8GQ  })
a{2¤§ÜCGÔO¦D})ayC?}*KOC|~ê y(¤*|~{2¤wyCCyv a})yv|Ð8££2vyY¤w8ayC
aY8|~zC}~¤wCv}ª£|aD¥}w9yYa¥}Q|a}8yvÝ)})¬,Ó"}w2}w|§8yvÝ)})
¥}wyv}w"£|~C£8zD8ayC$Ó?ÔÕªyQpC2¦²Q¤*D2ay })|a}±D
C2}»82a}O5DG£p})|{²8£2£|a· y9payC,5}wa )¬(Á2}
5}*~ yYë2}w· yv¥},yqa}Üa}w2a}"a28Wa2}w|~}"yYWQ~|~D }wCì
y¯¤wC5£{ §payC8s¤*DQ£2v}w·²yvK¦]8[¤*{2a})|ÖTyÝw}D¬íWC|aÖ
a{22p~}w¦C8y2¤*|~})Dyza}¤*{2a})|îyÝw} ²})(CÐzD{28|§8~}w}
aqy5£|ap¹D}ªD¤w¤*{2|~D¤*¦CC2¯DQ}way5})"}w¹D}wÒ}*a})|ayC|§p~}
|~})a{g§w¬qxD|Ü~y|a}CaC¯}8|~}9yva})|a}K~})¯y68va}w|~28Ö
ay¹C}C££|~·²y9p~}5}*~ Ð~2pïCð£|ap¹²yY }-zD{28|§8~}w}
8yv5£|~p¹C})Q})ª'8"})DK?yv[a}ª|~}w}Q}w})|azD¦ *¬,Ô}yY }
a2}?¤wC²¹C}w· ygÚ2}5|~}w}"}w})|azD¦	8££|~DD¤§y¤§ya{ yv}
y~yY£28£}w|2C8~}w|5}*~ a28W£|ap¹²yY }"ayYzD{28|aÖ

áãâ ä-å¯æçääâ è±é

427b
b
b
b
b
b
b
b
b
e
b
e
b
e
b
e
b
b
b
b
®
à
100

)

P
B
R

(

10−2

10−4

10−4

reweighted

reweighted

conventional

)

(

P
B
R
D
A
M

10−1

10−2

100

|
 
)

P
B

(

 e
|

10−5

conventional

100

)

(

P
B
D
A
M

10−2

10−4

10−2

e (RGBP) 

100

10−2

10−1
MAD(RGBP)

10−10

10−10

10−5
| e (GBP) |

100

10−4

10−2
MAD(GBP)

100

T"?"$¿rF³"ÀTÀÁ£®vÂ2Ã0Â/ÄÅÆmÇÈ?ÉMÄÃÊÆÂOÄÆ]ËvÌÍÎÏ(ÃÊÌ'ÂVÂÎÄÐ=ÆÅÑ'Ï(

X?K"$)?/]Ö_§DM²TM(§/«K)Öj ¡¡ T£;×¤3Ø"K§Ù©(M3©(§D¤
°MÝ

«¹?"¨^";ªI¤a©(¹/.«"Ú?©(MaØT3(§N3©(§¤T¨^M©(¹?¤)¬h^Ûc¯Ü.½
C'²T"vÞ?³mßm´Þ ¡)

Ô'Ú?(§Ù©(¸""UàK/pà)/§"²TMD¹/Ù©(MmáSF³mÀâTâ£Ô$¤«m'=«M¤T¨^/Ú¦
©'©(§¤T?c¼Y§Ù©(¹R?(¤C?§©(§"¤TA²'/¹?§D«"U©(Ú/«©(Ú?("c/
©(¹/"§Ùv'//§«m3©(§D¤[©(¤S¥?K©7º©("¨^Z0¼Y§Ù©(¹J?§«"Ú?§¤TK£
ãäåYÆÍTÌTæ½/ÄÌÄÃ0Ï(ÄÃÊÉ(ÌTæ$½KÆmÉMÃÎÄÍ^½KÎÅÃÎÏË7Kß'¡ç³3ßèm´  'Þ

é[Ú?(?¹ºTÕUÖp"§"êS)'CT¤'/'$?é2¬/³"ÀTÀTÀT£$Ô$¤¤Tº
K"§Mª;(¤TC'²3©(§D¤PªI¤Y'/?(¤m¥§¨]'©(v§?ª0("/«"çac]"¨¦
/§Ù(§«m$©(ÚC)ºU¬hu­®v¯
Õ;m3(Ê??³"ÀTâTâT£FÜ.ÅÆì(ÌìMÃ0æ
ÃDíÎÂ?ÄaÏ(Í'Ïî
Ä+ÎïSÏMð7ÛXÎÄÐ=ÆÅ(Ñ'ÏBÆñ7Ü7æÌÈ)Ï(ÃÊì"æDÎv¯ÂmñmÎÅÎÂKÉÎUé[¤'(²'[XÚªI¦
¨]?[ÕFÚ/?D§¹?M("C¬+/«T

Ã0Ï(ÄÃÊÉcåvÎÌÏÆÂ?Ã0Â)íÃ0ÂW¯Â?Ä+ÎMæ0æ

//²"cÞTÁè"´Þèß)

°ë

"¹KêS'CJÖVMD§/²é2F ¡T¡T T£.¹?*Ú?/§ÙòCmA(¤TC'²3©(§D¤
C/²"vÀß¢m´)ÀÁT¡

/P«m'D§?²P'²T¤(§Ù©(¹?¨JF¬hRÛv¯Ü.½

ü8û% '&vô$(~öwõ

²T'©(§¤TJªI¤c??(¤m¥§D¨]3©(B§?ªIM("/«MZ§DP¹º?(§DP»."ºM§N'
/M©+¼.¤'("a¬+R®v¯½;¾®¾;½

öwö)ÿRô

ÒZÓ.ÔVÕU(""

ER *üCÿ$(~õaô 3aòüCÿ$.aü

ñ(òvóDôõ~ö÷ øúùÐöwõaûüCõ~ý9þ8ÿ wöþCÿ
	Þü8û2þ8òõ&þõ~ü²òý9þ~òvüDÿOù! Döwõ"ô#ö)õûüDõaý9þ8ÿ$ *ö
þ)õaü òý9þaòüCÿ$*+,ù.-
þ8ÿ/~öwö9ò01ö2(~õaô 3aôõ§þ)&sý5öþ8ÿ542ö'&0+6	]ñ7,þ)2õaü òý5þ)
aòüCÿ8ãòvö)óCöwõ~òÿ "9;:=<)>?>>?3-A@B1öA *üCÿC Dö3 òD4ö[ûõaö)öQö)ÿöwõ~óE
þ)õaüþ "1F:1üGö Cö)õ:1þaö' Döwõ§þ)&kþö)þ)&òÿóÃþ þCÿ/~þ8óDö-
HWÿ&vòI9CöJ6K	]ñL12öwüCõME:þ&N&=1öQöóCö-òÿO1öP~þCõaóDö3 òIaõ~òN
ôK~òvüDÿÃÿö)ö
öS *ü Cö)õaöTU-.@B1òIÿü
&öwý
üCÿ&NEV *òõM wôýW Döwÿ/MX1öPõ~ü
òvÿ56K	]ñiü8ûYGZ1ò0 "1]öT óCöT
aü[9Cö)ö'qþ8ÿ\GZ1ò0 "1RaüA ö&vö'aö?:
ôKòDWþ&Iaü[aôóDóCöMý5üCõ~ö
üGö)õûô&sþõ~ü²òý9þ~òvüDÿF-]@B1ö9þòD~òvüDÿ2þ)&(û'þ 312þ)?ÿ2ü
õ~öaô&D",þ
üCôK,òNM^öwõaûüCõ~ý9þ8ÿ wöJGòDM1_ '&vô$(~öwõ]aòN`)ö[&Yþ8õ~óCö)õ
1þ8ÿJ(GOü]12þ Cö
&ò01öT'þ?Ðû'þ8õOþ7GOöX9²ÿüGÐý5ü
aòI pþ~öôB~üªûô2õM1öwõWòÿC CöT(~òvóþaö*12òIý5ö'1üKU-
@B1öö3Köwõ~òvý5ö)ÿ?§þ)&²õ~öaô&D"aGòN1JZ,ùb'õaöGö)òvó?1?~öóCöwÿ
öwõ§þ)&òI`wö
ö'&òö*ûõ~ü2þCóDþ)aòüCÿ*+M1öc wüCôÿ/aö)õþ8õü8ûXùqûüDõ
12ö] *üCÿC Dö3 òD4öþ)õ~üDþ? "1$côóDóCöT(B1þWòÿed
ö)þ?E;fKõ~ü
&öwýA^GZ1ö)õaöO+,^ùgöwõaûüCõ~ýAGö&N&h:FM1ö5õaöGö)òvó?1/aö¯þ)
õ~ü òvý9þ~òvüDÿZ ü	ÿ2ü)õ~ü ²òIöÜþR *üDý[ö3~òvÿ2óÃþ)&Naö)õaÿ2þ)aòI Cö?-
iWüGOö' DöwõT:òÿjd
ö\GüDõM1/GZ12òN&ö
&öwýA:kòNý5òvó?1/
aüO wüCÿaòIöwõB,ùkGòN15&þCõaóDöwõ 3&ô(~öwõ"?þ?þ8ÿ¯þ)&Naöwõ~ÿ2þ)
ö
ý5üDõaöqõ~ü
aòI Cö?-l@B1öqý5ö312üCjaöwö)ýJ[~ü
ô9òvÿjaô "1
õ~ü
@B1ö)õaöòI:1üGö Cö)õ:þ8ÿ,òýJüDõ§þ8ÿ/Gü?ö)ÿ]õ~ü
&öwýV:pÿü(þK
ôOý5öwÿ/~òvüDÿöÃö)þ8õM&òvö)õòÿe8¯þCòvÿK
 õ~öMöT9òÿR12òIB2þö)õ:
Gõ~òvó?1?Üö'ªþ)&h-I:7<>>/<m:aGZ1òI "10ò0)øP1üGnaü42ÿeoÒüDõÜö' Döwÿ
ö3~öwõø	üaòýQòI`wö\1öp *üDôÿ/aòÿó[ÿ²ôý
ö)õMªòvÿbB,ù.-rqTÿ
12òIP2þ)öwõT:.Göp *üDý[2ôKaöT_1ö)ýsaô
üK~òvý9þ)&I&IEeòÿ wö
Eu12þCÿU:ZGZ1ò0 "1GþJü?Mò
GOþ?J~þ9Cö)ÿj wüCÿ~þCÿ/"
&ö
1þ8ÿ9K7~ü]M1ö*E²ýQý5ö'aõ~òvöTîòÿA1ö-ý5üCö'&h-.ÿþCôKaüDý5þ)aò0 
õ~üK *öôõaö?:v1üGOö' DöwõT:sòI\ *õ~ô *òYþ)&òvû*M1öZ,OùÄò0[aü
þ)&vòö]òvÿ]õ~ö)þ&aGOüCõM&IV2õaü
&vö)ýAXGòN1]óDõ~þ1ò0 wþ)&kýQüK ö&I
òNaõ§þ8õMEA(~õaô 3aôõ~ö
ü8ûsþ8õ
w\xTyFzr{C|A}~C=~Cz;
@B1ò0Üõ~öaö)þCõM "1uò0WaôüCõaö
ñüDôÿþ)aòüCÿe6@B8!-@B12þCÿ9KZ~ü2?öwöT&
1ò0X üDô
&ö3&vü²üpüCû(GOþCõaö?-
~C~/~/zrx~C

Ee12ö2-ôKM "1u@Gö "12ÿü&üCó?E
öwõ"WûüDõ*12þ8õ~òÿó

M§¸"mVKMD§MªY(¤T/²3©(§¤T$P¬hOÛc¯Ü.½
ÁTÀTß)

12þCõMFfaõ~ü

&öwýA-

°MÝ

ÖO'§)¼7(§²¹)©mé2?)¤TD))/XÖ_§DºXTà) ¡¡ £
ó?M¼«"DU¤'ªCÚ?/KMUK¤Ú//?;¤©(¹?r¤T²B/'©(§Ù©(§¤TXª0Ú?/«M¦
©(§¤T$a¬+b­K®c¯

?C'²T"ß¢Á3´ß3Þ¢)

°ô

ÖO'§)¼7(§²¹)©mé2?)¤TD))/XÖ_§DºXTà) ¡¡T¢T£
$("M¦Ê(M¼r"§²T¹©(mOK"§Mªc?(¤T/²T'©(§¤Te/O/(¤m¥?§¨]3©(
éJÔ\M©(§D¨]3©(§¤TW)º/"Ú/?¤¦¨^¤¨^"©F¨]'©(«¹/§/²¬+J®v¯½Cî
¾®¾;½

ÖO'§)¼7(§²¹)©m7é2.r'CóT¤?vé2a¬v ¡¡T¢£õ·c?¹/§«m
¨^¤)?""M¥K¤T?"©(§DZª'¨^§D§""S/LØT3(§D'©(§¤T/S§ª0M¦
"/«MTe"«¹//§«m'Yöc"K¤'©^Á'ÞÀ.ÒZÓk»r("Mº=áB"?©mF¤'ª
à)©3©(§D©(§«""

Öõ§"²M(§/«cÖjX ¡¡T¡T£!÷r3(§D'©(§¤T/X??(¤m¥§¨]'©(§¤T?[KM¦
©h¼r""¨^m2òC"DV©(¹/"¤'ºO'Cp©(¹/ZøhÚ//«©(§D¤O©("['²T¤¦
(§Ù©(¹/¨JU¬+b­K®c¯

/C²"vÁ 'Á3´)Á¢T¢)

°ù

ê=m?§D?§D)?àT¿?(""¨]'$'ÖjCÖV"§"Tê* ¡T¡)³3£K·"?¦
;C²"ÁTâÀ3´

°ú

M"")cKM("DC*X/KM$?C ¡T¡¢£$c??(¤m¥)¦
§¨]'©(§Dª0M(M/«"^'CA«"¤/©§©Z¤?©(§¨^§('©(§¤TX¬h­®v¯
°T±

?C'²T"c¢³"¢3´)¢T ¡)

M""?/[µK¤M©(Mm/¶* ¡¡T¢T£F·"?M§¸"m[KMD§Mª?(¤?¦

ê=Ú/§D7aÔFv ¡T¡T T£_Ó7Ó7Ó.Õk'D²¤(§Ù©(¹/¨^©(¤2¨^§/§¨^§¸"W©(¹?
»rM©(¹?2'C5Z§)Ú/«¹/§7ªN("R"/M(²§""çÓr¤ØTM(²T"©[Ù©(M¦
C3©(§DØT"[©(¤K"§Mª(¤TC'²3©(§D¤$ûÛXÎÈ)ÅÌTæXÉ(ÆïcüCÈ)ÄÌÄÃÊÆÂ?
³"ÞçD³"ÁTÀ)³´C³mèT  )

428e
Q
Q
Q
Q
Q
Q
Q
Q
Q
Q

Q
Q
Q
Q
Q
Q
Q
Q
Q
Q
t
Q
Q
Q
ö
Q
Q
Q
Q
Q

±


±

Recursive Autonomy Identification for Bayesian Network Structure 

Learning 

Raanan Yehezkel and Boaz Lerner 

Pattern Analysis and Machine Learning Lab 

Electrical and Computer Engineering 

Ben-Gurion University, Israel 
{raanany, boaz@ee.bgu.ac.il} 

 
 

 

to 

(due 

the  curse-of-dimensionality) 

between variables combined with causality inference rules 
[Pearl, 2000; Spirtes  et  al., 2000].  The  main  problem  of 
constraint-based  algorithms  is  their  inefficiency  and 
inaccuracy 
in 
performing  conditional  independence  (CI)  tests  for  large 
condition sets. Most constraint-based algorithms, such as 
Inductive Causation (IC) [Pearl, 2000], PC [Spirtes et al., 
2000]  and  Three  Phase  Dependency  Analysis  (TPDA), 
[Cheng  et  al.,  1997],  construct  a  directed  acyclic  graph 
(DAG)  in  two  consecutive  stages.  First  is  learning 
associations  between  variables  for  constructing  an 
undirected  structure.  This  requires  an  exponentially 
growing  number  of  CI  tests  with  the  number  of  nodes, 
which can be reduced to polynomial by fixing the number 
of parents (PC algorithm) or using the values computed in 
the  CI 
test  and  some  strong  assumptions  (TPDA 
algorithm). These assumptions however may not be valid 
in all situations. Another flaw of the TPDA algorithm is 
ignoring  the  curse-of-dimensionality  in  CI  tests  by  not 
limiting the size of the condition set. The second stage in 
most  constraint-based  algorithms  is  causality  inference 
performed in two consecutive steps: finding and directing 
V-structures  and  inductively  directing  additional  edges 
[Pearl,  2000].  Causality  inference,  and  especially  the 
induction step, is unstable, i.e., small errors in the input to 
the  stage  yield  large  errors  at  its  output  [Spirtes  et  al., 
2000].  Thus, 
increase  stability  by 
separating  the  two  stages  trying  in  the  first  stage  to 
minimize  erroneous  decisions  about  d-separation  caused 
by  invalid  threshold  selection  or  poor  estimation  due  to 
the curse-of-dimensionality. 
We propose a constraint-based algorithm that recursively 
tests  conditional  independencies  with  condition  sets  of 
increasing  orders,  directs  edges  for  each  order  and 
identifies autonomous sub-structures complying with the 
Markov property (i.e., the sub-structure includes all node 
parents).  By  considering  directed  rather  than  undirected 

the  algorithms 

Abstract 

We  propose  a  constraint-based  algorithm  for 
Bayesian  network  structure 
learning  called 
recursive  autonomy  identification  (RAI).  The 
RAI  algorithm  learns  the  structure  by  recursive 
application  of  conditional  independence  (CI) 
tests  of  increasing  orders,  edge  direction  and 
structure  decomposition  into  autonomous  sub-
structures.  In  comparison  to  other  constraint-
based algorithms d-separating structures and then 
directing the resulted undirected graph, the RAI 
algorithm  combines  the  two  processes  from  the 
outset  and  along  the  procedure.  Learning  using 
the RAI algorithm renders smaller condition sets 
thus requires a smaller number of high order CI 
tests.  This  reduces  complexity  and  run-time  as 
well as increases accuracy since diminishing the 
curse-of-dimensionality.  When  evaluated  on 
synthetic  and  "real-world"  databases  as  well  as 
the ALARM network, the RAI algorithm shows 
better  structural  correctness,  run-time  reduction 
along  with  accuracy  improvement  compared  to 
learning 
popular  constraint-based 
algorithms.  Accuracy 
is  also 
demonstrated  when  compared  to  a  common 
search-and-score structure learning algorithm. 
 

structure 
improvement 

1  INTRODUCTION 
Most  algorithms  for  Bayesian  network  (BN)  structure 
learning  are  either  search-and-score  based  [Heckerman, 
1995;  Friedman  et  al.,  1997]  in  which  the  structure 
achieving  the  highest  score  given  the  data  is  pursued  or 
constraint-based  in  which  the  structure  is  learned  from 
constraints derived from statistical tests of independence 

429edges, the RAI avoids unnecessary CI tests and performs 
tests  using  smaller  condition  sets.  Repeated 
for 
autonomies decomposed recursively from the graph both 
mechanisms reduce computational and time complexities, 
database  queries  and  errors  of  subsequent  iterations. 
Using  smaller  condition  sets,  the  RAI  algorithm  also 
improves  accuracy  since  diminishing 
the  curse-of-
dimensionality.  After  providing  some  preliminaries  in 
Section  2  we  introduce  the  RAI  algorithm  in  Section  3 
and  present  its  experimental  evaluation  in  Section  4 
before concluding the paper in Section 5. 

2  PRELIMINARIES 
A BN B(G,Θ) consists of a structure (graph) G and a set 
of probabilities Θ quantifying the graph. G(V,E) consists 
of V, a set of nodes representing domain variables, and E 
a set of edges connecting the nodes. Pap(X,G), Adj(X,G) 
and Ch(X,G) are respectively the sets of potential parents, 
adjacent  nodes  and  children  of  node  X  in  a  partially 
graph  G,  Pap(X,G)=Adj(X,G)\Ch(X,G). 
directed 
Similarly, Pa(X,G) and Desc(X,G) are the sets of parents 
and descendants of X in G. We indicate that X and Y are 
independent  given  a  set  of  nodes  S  using  X  ||  Y|S  and 
make use of the notion of d-separation [Pearl, 2000]. We 
also  define  d-separation 
resolution  evaluating  d-
separation for different values of the maximal number of 
nodes in the condition set, an exogenous cause to a graph 
and an autonomous sub-structure. 
Definition  1:  The  d-separation  resolution  between  any 
pair  of  non-adjacent  nodes  is  the  size  of  the  smallest 
condition set that d-separates the two nodes. 
Definition 2: The d-separation resolution of a graph is the 
highest d-separation resolution in the graph. 
Definition 3: Y is an exogenous cause to G(V,E) if Y∉V 
and ∀X∈V, Y∈Pa(X) or Y∉Adj(X) [Pearl, 2000].  
Definition  4:  A  sub-structure  GA(VA,EA)  in  G(V,E)  s.t 
VA⊂V,  EA⊂E  is  autonomous  given  a  set  of  exogenous 
nodes Vex to GA  if ∀X∈VA, Pa(X,G)⊂{VA∪Vex}. If Vex 
is empty, we say the sub-structure is autonomous. 
We  define  sub-structure  autonomy  in  the  sense  that  the 
sub-structure  holds  the  Markov  property  for  its  nodes. 
Given  a  structure  G,  any  two  non-adjacent  nodes  in  an 
autonomous sub-structure GA are d-separated given nodes 
either  included  in  the  sub-structure  or  exogenous  causes 
to it. This notion is elaborated in Section 3.3. 

3 RECURSIVE AUTONOMY 

IDENTIFICATION 

Starting from a complete graph and proceeding from low 
to high graph d-separation resolution, the RAI algorithm 
uncovers  the  correct  pattern  (i.e.,  a  family  of  structures 
Markov  equivalent  to  the  true  underlying  structure)  by 
recursive  (1)  test  of  CI  between  nodes  and  removal  of 
edges  related  to  independencies  (thinning),  (2)  edge 
direction  according  to  inferred  causality  rules  and  (3) 
graph decomposition into autonomous sub-structures. 
CI testing of order n between X and Y is performed by 
thresholding  a  criterion,  such  as  the  χ2  goodness  of  fit 
[Spirtes  et  al.,  2000]  or  conditional  mutual  information 
[Cheng et al., 1997]. The criterion measures dependence 
conditioned on a set of n nodes from the parents of X or Y 
determined by the Markov property [Pearl, 2000], e.g., if 
X is directed into Y only Y's parents are included in the 
set. 
Directing edges is conducted according to causality rules 
[Pearl, 2000] by identifying intransitive triplets of nodes 
(V-structures), 
i.e.,  non-adjacent  parents  having  a 
common child, directing the relevant edges, and applying 
additional  rules  to  further  direct  edges  until  no  more 
edges can be directed (the inductive step). 
Decomposition  into  autonomous  sub-structures  reveals 
the structure hierarchy and allows performing a fewer CI 
tests  conditioned  on  a  large  number  of  potential  parents 
thereby 
reducing  complexity.  The  RAI  algorithm 
identifies  ancestor  and  descendant  sub-structures,  the 
latter are autonomous given nodes of the former. 

3.1 THE RAI ALGORITHM 
Iteration  of  the  RAI  algorithm  starts  with  knowledge 
produced  in  the  previous  iteration  and  the  current  d-
separation  resolution,  n.  Previous  knowledge  includes 
Gstart, a structure having d-separation resolution of n-1 and 
Gex,  a  set  of  structures  having  each  possible  exogenous 
causes to Gstart. In the first iteration, n = 0, Gstart(V,E) is a 
complete graph and Gex=∅. 
Given a structure Gstart having d-separation resolution n-1, 
the RAI algorithm seeks independencies between adjacent 
nodes  conditioned  on  sets  of  size  n,  resulting  in  a 
structure  having  d-separation  resolution  of  n.  After 
directing  edges,  the  algorithm  decomposes  the  structure 
into  ancestor  and  descendent  autonomous  sub-structures 
in  order  to  reduce  complexity  of  successive  stages.  A 
descendant sub-structure is established by identifying the 
lowest topological order nodes (either a single node or a 

430Main function Gout = RAI(n,Gstart,Gex) 
Exit condition 

If  all  nodes  in  Gstart  have  less  than  n-1 
potential parents exit. 

A. Thinning the link between Gex and Gstart and 

directing Gstart 

1.  For every node Y in Gstart and its parent X in Gex, 
if ∃S⊂{Pap(Y,Gex)\X∪Pap(Y,Gstart)} and |S|=n s.t 
X || Y|S, then remove the edge between X and Y. 
2.  Direct the edges using causality inference rules. 
B. Thinning, directing and decomposing Gstart. 
1.  For every node Y and its potential parent X, both 
in  Gstart,  if  ∃S⊂{Pap(Y,Gex)∪Pap(Y,Gstart)\X}and 
|S|=n s.t X || Y|S, then remove the edge between 
X and Y. 

2.  Direct the edges using causality inference rules. 
3.  Group  the  nodes  having  the  lowest  topological 

order into a descendant sub-structure GD. 

4.  Remove  GD  from  Gstart  temporarily,  and  define 
the  resulting  unconnected  structures  as  ancestor 
sub-structures GA1,…, GAk. 

C. Ancestor sub-structure decomposition 

for i = 1 to k, call RAI(n+1,GAi,Gex) 

D. Descendant sub-structure decomposition 
1.  Define GD_ex={GA1,…,GAk,Gex} as the exogenous 

structure to GD. 

2.  Call RAI(n+1,GD,GD_ex) 
 

Figure 1: The RAI algorithm 

 
several  nodes  having  the  same  lowest  order).  This 
structure  is  autonomous  given  ancestor  sub-structures 
composed of nodes of higher order. In order to consider a 
smaller  number  of  parents  for  each  node  of 
the 
descendent sub-structure, the algorithm recursively learns 
ancestor  sub-structures  and  only  then  their  descendant 
sub-structure. Note that this latter structure may consist of 
a several non-connected sub-structures. Figures 1-3 show 
respectively  the  RAI  algorithm,  a  manifesting  example 
and  the  algorithm  execution  order  for  this  example. 
Figure  2a  shows  the  true  underlying  structure.  Initially, 
Gstart is the complete graph and Gex is empty so stage A is 
skipped. At stage B1, any pair of nodes is CI tested given 
an empty condition set (marginal independence) yielding 
the removal of the edges between node 1 and nodes 3, 4  

(a)                           (b)                           (c) 

    

    

    

    

(d)                           (e)                           (f) 

    

(g)                           (h)  

 

Figure 2: Learning an example structure. a) The true 
underlying structure and structures learned by the RAI 
algorithm in stages (see Figure 1) b) B1, c) B2, d) B4, e) 

C, f) D and A1, g) D and A2 and h) D and B1 (the 

resulting structure) 

 

 
 

RAI(0,G({X1…X7}),{}) 

RAI(1,G({X2,X6,X7}),G({X1,X3,X4,X5}))
8 

9 

10

11 

RAI(2,G({X2}),G({X1,X4}))

RAI(2,G({X6,X7}),G({X2})) 
 

Figure 3: The execution order of the RAI algorithm for 
the structure of Figure 2. Recursive calls of stages C and 

D are marked with a double and single arrow, 

respectively. 

 

 

 

 

12 

7

3 

2 

6 

1

RAI(1,G({X1}),{}) 

RAI(1,G({X3,X4,X5}),{})

5 

4 

RAI(2,G({X3,X4,X5}),{})

431and  5  (Figure  2b).  The  causal  relations  inferred  at  stage 
B2 are shown in Figure 2c. The nodes having the lowest 
topological order (2, 6, 7) are grouped into a descendant 
sub-structure  GD  (stage  B3)  while  the  remaining  nodes 
form  two  unconnected  ancestor  sub-structure,  GA1  and 
GA2  (stage  B4)  (Figure  2d).  At  stage  C  the  algorithm  is 
called recursively for each of the ancestor sub-structures 
with n=1, Gstart=GAi and Gex=∅. Since sub-structure GA1 
contains a single node, the exit condition for the structure 
is  satisfied.  While  calling  Gstart=GA2,  stage  A  is  skipped 
and stage B1 identifies that X4 || X5|X3 thus removes edge 
X4⎯X5.  No  causal  relations  are  identified  so  the  nodes 
have equal topological order and they are grouped to from 
a descendant sub-structure. The recursive call for this sub-
structure with n=2 is returned immediately since the exit 
condition is satisfied (Figure 2e). Moving to stage D, the 
RAI  is  called  with  n=1,  Gstart=GD  and  Gex={GA1,GA2}. 
Then,  in  stage  A1  relations  (X1  ||  {X6,X7}|X2),  (X4  || 
{X6,X7}|X2) and ({X3,X5} || {X2,X6,X7}|X4) are identified 
and the corresponding edges are removed (Figure 2f). At 
stage A2 node X2 is identified as a parent of X6 and X7 
(Figure 2g). Stage B1 identifies the relation (X2 || X7|X6) 
and stage B2 identifies X6 as a parent of X7 (Figure 2h). 
Further  recursive  calls  are  returned  and  the  resulting 
partially directed structure represents a family of Markov 
equivalent structures of the true structure. 

3.2 MINIMALITY, STABILITY & COMPLEXITY 
Minimality  A  structure  having  a  higher  d-separation 
resolution  entails  a  fewer  dependencies  and  thus  is 
simpler  and  preferred  to  a  structure  having  a  lower  d-
separation  resolution  [Pearl,  2000].  By  increasing  the 
resolution,  the  RAI  algorithm  moves  from  a  complete 
structure  having  maximal  dependency  relations  between 
variables to structures having less (or equal) dependencies 
than  previous  structures  ending  in  a  structure  having  no 
edges  between  conditionally  independent  nodes,  i.e.,  a 
minimal structure. 
Stability is measured by the number of errors in the output 
structure due to CI test errors, which are the only source 
of errors. CI test errors are the result of unnecessary large 
condition  set  leading  to  the  curse-of-dimensionality  or 
choosing  an  inaccurate  condition  set  due  to  partial 
information  (e.g.,  undirected  edges).  Although  as  a 
recursive algorithm the RAI might be unstable, errors are 
practically less likely to occur since the algorithm utilizes 
information  (e.g.,  edge  direction  and  graph 
more 
decomposition)  from  previous 
to  choose 
smaller,  informative  condition  sets  for  performing  the 
tests. 

iterations 

Complexity  CI  tests  are  the  major  contribution  to 
complexity (run-time) [Cheng and Greiner, 1999]. In the 
worst  case,  the  RAI  algorithm  will  not  direct  any  edges 
nor  decompose  the  structure  thus  identify  the  entire 
structure  as  a  descendant  sub-structure  calling  stage  D 
iteratively  while  skipping  most  other  stages.  Then,  the 
execution  of  the  algorithm  will  be  similar  to  that  of  the 
PC algorithm and the complexity will be bounded by that 
of  the  PC  algorithm.  Given  the  maximal  number  of 
possible parents k and the number of nodes n, the number 
of CI tests is bounded by [Spirtes et al., 2000] 

2

n
⎛ ⎞
⎜ ⎟
2
⎝ ⎠

⋅

k

∑

i

=

0

n

⎛
⎜
⎝

1

−
i

⎞
⎟
⎠

≤

(
n n
2
k
(

k

−

) 1
1
−
1)!
−

 

.

This  worst  case  scenario  rarely  occurs  in  “real-world” 
applications requiring structures having colliders. 

3.3 CORRECTNESS 
Proposition:  If  the  input  data  to  the  RAI  algorithm  is 
faithful to a DAG, G, having any d-separation resolution, 
then it yields the correct pattern, Gout. 
Proof:  (by  induction,  ignoring  notions  common  to  the 
RAI  and  PC  algorithms  which  are  proved  in  [Spirtes  et 
al., 2000])  
Base  case:  If  the  input  data  to  the  RAI  algorithm  is 
faithful to a DAG with d-separation resolution 0, then it 
yields the correct pattern Gout.  
Since  Gstart  is  a  complete  graph,  the  algorithm  tests  in 
stage  B  marginal  independence  between  pairs  of  nodes 
and  then  direct  edges.  Thus,  the  resulting  structure 
contains only edges between marginally dependent nodes, 
therefore  having  d-separation  resolution  of  0.  From  the 
decomposition  stages,  B3  and  B4,  based  on 
the 
topological  order  identified  from  the  partially  directed 
structure, it follows that every edge from a node X in an 
ancestor sub-structure to a node Z in the descendant sub-
structure  is  directed,  X→Z.  Also,  there  is  no  edge 
connecting one ancestor sub-structure to another ancestor 
sub-structure. Thus, every ancestor sub-structure contains 
all the potential parents of its nodes, i.e., it is autonomous.  
Lemma 1: If the given data entails X || Y|S and X,Y are 
members  of  an  autonomous  sub-structure  GA(VA,EA), 
then ∃S’ such that S’⊂VA and X || Y|S’. 
Lemma 2: In a DAG, if X and Y are non-adjacent and X 
is  not  a  descendant  of  Y  then  X  and  Y  are  d-separated 
given Pa(Y) (proved in [Spirtes et al., 2000]).  

432independently  by  recursive  calls  of 

An  autonomous  sub-structure  contains  all  potential 
parents  (either  sub-structure nodes or  exogenous  causes) 
of each of its nodes. Thus, from Lemma 2, if X and Y are 
independent given a set of nodes (i.e., d-separated in the 
true  underlying  graph),  then  they  are  d-separated  given 
PaP(X) or PaP(Y) which are contained in the autonomous 
sub-structure.  Thus,  every  ancestor  sub-structure  can  be 
processed 
the 
algorithm.  The  recursive  call  of  the  descendant  sub-
structure  regards  the  ancestor  sub-structure  nodes  as 
exogenous  causes.  The  data  does  not  entail  any  higher 
order conditional independencies and no more edges are 
removed. 
Inductive case: Suppose that the RAI algorithm yields the 
correct  pattern  given  data  faithful  to  a  DAG  having  d-
separation  resolution  n.  Then,  given  data  faithful  to  a 
DAG  having  d-separation  resolution  n+1 
the  RAI 
algorithm yields the correct pattern. 
After  achieving  d-separation  resolution  of  n  in  an 
autonomous sub-structure, G(n), a recursive call with n+1 
is made. The exit condition is not satisfied in case an edge 
exists  in G(n)  and does not  exist  in  the  true  structure Gt. 
Suppose an edge EXY=(X→Y) exists, such that EXY∈G(n) 
and  EXY∉Gt,  then  the  smallest  condition  set  required  to 
identify the independency between the nodes is SXY, such 
that  |SXY|  ≥  n+1.  Thus,  it  follows  from  Lemma  2  that 
either |Pa(X)| ≥ n+1 or |Pa(Y)|≥n+1 and the exit condition 
is not satisfied. Every pair of connected nodes is tested for 
independence in stage B1 using condition sets of size n+1 
and  the  corresponding  edges  are  removed  resulting  in  a 
sub-structure having d-separation resolution of n+1. 
The  correctness  of  edge  directing  is  discussed  in  [Pearl, 
2000; Spirtes et al., 2000]. 

4  EXPERIMENTS AND RESULTS 
The  RAI  algorithm  was  experimentally  compared  to  the 
PC  and  TPDA  algorithms,  two  popular  constraint-based 
structure 
learning  algorithms  reported  frequently  as 
having  good  performance  [Ramsey  et  al.,  2002].  For 
simplicity, no speeding-up heuristic techniques [Spirtes et 
al., 2000] were applied to either algorithm, and the RAI 
algorithm  employed  only  V-structure 
identification 
deferring the inductive step after forming the structure. 
The  complexity  and  prediction  accuracy  of  the  RAI 
algorithm were compared to those of the PC and TPDA 
algorithms  using  a  synthetic  problem  and  fifteen  “real-
world”  databases  of  the  UCI  Repository  [Murphy  and 
Aha, 1994]. Interested mainly in classification, the  

P C
R A I

3

 

1

2

C on d itio n   se t  siz e

2 5

2 0

1 5

1 0

5

0

5 0

4 0

3 0

2 0

1 0

s
t
s
e
t
 
I

C

 
f
o
 
r
e
b
n
u
n
 
e
g
a
r
e
v
A

)

%

(
 
n
o
i
t
c
u
d
e
r
 
s
t
s
e

t
 
I

C

0

0

0

1

2

3

 

C on d itio n   se t  siz e

 
Figure 4: (a) The number of CI tests required by the RAI 
and PC algorithms for increasing orders averaged over all 
possible structures having five nodes. (b) CI test reduction 

by the RAI algorithm compared to the PC algorithm 

 

prediction  accuracy  is  preferred  over  the  likelihood  in 
evaluating  performance,  as  the  likelihood  ignores  the 
importance of the class variable [Friedman et al., 1997]. 
Structural  correctness  was  evaluated  in  recovering  the 
ALARM  network  in  comparison  to  the  TPDA  and  PC 
algorithms.  BN  implementation  was  aided  by  the  Bayes 
net  toolbox  (BNT)  [Murphy,  2001]  and  BNT  structure 
learning package [Leray and Francois, 2004]. 

4.1 A SYNTHETIC PROBLEM 
All  29,281  possible  structures  having  five  nodes  were 
learned  by  the  PC  and  RAI  algorithms.  Since  the  true 
structure  is  known,  the  actual  CI  relationships  could  be 
inputted 
the 
complexity,  evaluated  using  the  averaged  number  of  CI 
tests  over  all  possible  structures,  of  the  algorithms  for 
increasing orders (condition sets). Figure 4b illustrates the 
percentage  of  CI  tests  reduced  by  the  RAI  algorithm  in 
comparison to the PC algorithm. 

the  algorithms.  Figure  4a  shows 

to 

4.2 “REAL-WORLD” DATA 
A  several  databases  of 
the  UCI  Repository  were 
employed in order to evaluate prediction accuracy. When 
needed, continuous variables were discretized using the  

433Table 1. The average number (percentage) of CI tests 
reduced by the RAI algorithm compared to the PC 

algorithm for different orders 

 
CI test order 
3 

Database 

shuttle (s) 

car 

corral 

mofn 
3,7,10 

tic-tac-toe 

led7 

breast 

vote 

flare C 

wine 

cmc 

crx 

zoo 

australian 

iris 

0 
0 
(0) 
0 
(0) 
0 
(0) 
0 
(0) 
0 
(0) 
0 
(0) 
0 
(0) 
0 
(0) 
0 
(0) 
0 
(0) 
0 
(0) 
0 
(0) 
0 
(0) 
0 
(0) 
0 
(0) 

1 
1.4 
(0.7) 
16 
(100) 
22.4 
(100) 
17 
(100) 
53.2 
(27.1) 
46.2 
(45.7) 
107.2 
(54.8) 
24.2 
(21.9) 

16 

(39.6) 
25.8 
(41.0) 
10.2 
(10.9) 
8.8 
(49.6) 

82 

(27.8) 
3.8 
(34.4) 

2 
(40) 

117.6 
(49.3) 
3.2 
(100) 
3.6 
(100) 

 

1.8 
(51.4) 
140 
(100) 

 

6.4 
(100) 

 

40.6 
(82.4) 

 

4 
83.6 
(56.0) 

 

 

 

 

105 
(100) 

 

1 

(100) 

19 

(96.7) 

 

 

2 
95.8 
(43.8) 
11.2 
(100) 
26 
(100) 

4 

(100) 
56.6 
(48.6) 
105 
(100) 
35 

(99.1) 
17.2 
(98.1) 

3 

(100) 
44.2 
(67.6) 

(32.5) 

8 

 

 

 

365.8 
(29.6) 

 

1033.4 
(27.7) 

 

1928.6 
(25.6) 

 

 

 

 

 

ignored  by 

(s)”  database  was 

MLC++ library [Kohavi et al., 1994]. Variable A14 of the 
“shuttle-small 
the 
discretization function of MLC++ and thus omitted from 
the  experiments.  “flare1”  and  “flare2”  were  merged  to 
form  the  “flare  C”  database  where  the  class  node  is  the 
number of “C-class” flares. All databases were analyzed 
using  a  CV5  experiment  except  the  large  “shuttle”  and 
“mofn  3-7-10”  databases  which  were  analyzed  using  a 
hold-out  experiment.  CI  tests  were  carried  out  using  the 
χ2  test  [Spirtes  et  al.,  2000]  with  thresholds  chosen  for 
each  algorithm  and  database  in  order  to  maximize  the 
prediction accuracy on a validation set selected from the 
training set. If a several thresholds were suitable, the  

Table 2. Mean (std) prediction accuracy of the RAI 

algorithm in comparison to the PC algorithm and “other” 

classifiers reported in [Friedman et al., 1997] (F) and 

[Cheng and Greiner, 1999] (TPDA algorithm) (C), as well 
as the cut (%) of CI test run-time using the RAI algorithm 

in comparison to the PC algorithm 

Database

shuttle (s) 

 
car 

corral 

mofn 
3,7,10 
tic-tac-
toe  
led7 

breast 

vote 

flare C 

wine 

cmc 

crx 

zoo 

run-
time 

cut (%) 
38.94 

91.10 

87.94 

67.70 

36.52 

91.74 

71.87 

46.06 

20.38 

29.11 

14.22 

25.25 

13.63 

australian 

6.05 

iris 

19.10 

accuracy 

accuracy

 
PC 

(%) 
98.40 

RAI 

(%) 
99.22 

85.07 
(1.83) 
84.53 
(15.45) 
81.45 

74.74 
(1.48) 
73.31 
(1.80) 
95.46 
(2.04) 
95.64 
(1.87) 
84.30 
(2.54) 
85.44 
(7.79) 
50.92 
(2.33) 
86.38 
(2.63) 
88.95 
(8.79) 
85.51 
(0.52) 
96.00 
(4.35) 

92.94 
(1.06) 
98.52 
(3.31) 
93.16 

75.57 
(1.93) 
73.59 
(1.56) 
96.49 
(1.61) 
95.87 
(1.71) 
84.30 
(2.54) 
87.07 
(5.88) 
51.12 
(3.16) 
86.38 
(2.63) 
88.95 
(8.79) 
85.51 
(0.52) 
93.33 
(2.36) 

other 

99.17(F) 

86.11(C) 

97.60(F) 

85.94(F) 

 

 

96.92(F) 

94.94(F) 
95.17(C) 
82.74(F) 
82.27(C) 

 

 

85.60(F) 

 

86.23(F) 

94.00(F) 

 
chosen threshold was that leading to the fewest CI tests. 
Parameter 
learning  was  performed  using  sequential 
Bayesian  updating  with  Dirichlet  priors  of  unit  hyper-
parameters [Heckerman, 1995]. 
Complexity  was  measured  by  the  number  of  CI  tests 
employed and the corresponding run-time. Table 1 shows 
the average number and percentage of CI tests reduced by 
the  RAI  algorithm  compared  to  the  PC  algorithm  for 

434different  orders.  A  100%  cut  in  CI  tests  for  a  specific 
order means that the RAI does not need any CI tests for 
this order. Empty cells mean that no CI tests of this order 
are required. Both Table 1 and Table 2, depicting the cut 
in run-time due to the RAI algorithm, demonstrate that the 
RAI algorithm outperforms the PC algorithm in all cases. 
Prediction Accuracies of the RAI and PC algorithms for 
the  experimented  databases  are  summarized  in  Table  2. 
On  ten  of  the  fifteen  databases  the  RAI  algorithm 
improves  accuracy  on  the  PC  algorithm,  on  four  keeps 
accuracy  intact  and  on  the  remaining  “iris”  database 
deteriorates accuracy. Examination of the “iris” database 
reveals  discrepancy  between  the  results  of  CI  tests  of 
orders  0  and  1  violating  the  Markov  property.  Three 
nodes  are  found  marginally  dependent  on  each  other 
whereas  nodes  of  each  pair  of  this  triplet  are  found 
independent given the third node. The prediction accuracy 
is also compared in Table 2 to that of the TPDA algorithm 
[Cheng and Greiner, 1999] and a BN learned by a search-
and-score  method using  the minimum  description  length 
criterion [Friedman et al., 1997]. 

4.3 LEARNING THE ALARM NETWORK 
Recovering the correct structure was evaluated using the 
ALARM network [Beinlich et al., 1989], which is widely 
accepted as a benchmark for evaluating structure learning 
algorithms. The RAI algorithm was compared to the PC 
and TPDA (PowerConstructor [Cheng, 1998]) algorithms 
using  ten  randomly  generated  databases  each  containing 
10,000  cases.  Since  the  TPDA  algorithm  had  used  the 
conditional mutual information CI test, we employed this 
test  also  here.  For  comparison,  we  selected  the  TPDA 
threshold of 0.003 [Cheng et al., 1997] for testing also the 
RAI  algorithm  and  a  threshold  of  0.002  for  the  PC 
algorithm  providing  better  accuracy  for  this  algorithm 
than using a threshold of 0.003. 
Structural  correctness  for  the  algorithms  was  evaluated 
using  two  types  of  errors  due  to  extra  edges  (EE; 
commission)  and  missing  edges  (ME;  omission)  (Table 
3).  The  PC  and  RAI  algorithms  achieved  the  smallest 
errors of extra and missing edges, respectively. The total 
structural error (Table 4) accounting for both errors was 
evaluated using 

Error
T

=

2

EE ME

+

2

. 

The  RAI  algorithm  yielded  structures  with  the  smallest 
total structural error of all algorithms which was validated 
using a t-test with 1% significance level. Others structural 
errors (e.g., edge reversal) were not recorded though we  

Table 3. Extra edge (EE) and missing edge (ME) errors 
(%) when learning the ALARM network in 10 trials using 

the TPDA, PC and RAI algorithms 

Trial 

1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
mean 
(std) 

TPDA 

EE  ME 
0.48 
8.70 
4.35 
0.32 
4.35 
0.32 
6.52 
0.32 
8.70 
0.48 
0.48 
8.70 
8.70 
0.48 
2.17 
0.16 
2.17 
0.16 
0.48 
8.70 
6.30 
0.37 
(0.13) 
(2.80) 

 

PC 

EE  ME 
0.16 
2.17 
6.52 
0 
4.35 
0 
4.35 
0.16 
2.17 
0 
0.16 
4.35 
0 
0.32 
2.17 
0.16 
4.35 
0.16 
0.32 
4.35 
0.15 
3.48 
(0.12) 
(1.83) 

RAI 

EE  ME 
0.97 
0 
2.17 
0.65 
2.17 
0.65 
0 
0.32 
0 
0.65 
0.48 
0 
0 
0.65 
2.17 
0.81 
2.17 
0.81 
0.65 
0 
0.87 
0.66 
(0.18) 
(1.12) 

 
 

 

 

Table 4. The total structural error (%) in 10 trials of the 
ALARM network learned using the TPDA, PC and RAI 

algorithms 

Trial 

1 
2 
3 
4 
5 
6 
7 
8 
9 
10 
mean 
(std) 

TPDA 
8.71 
4.36 
4.36 
6.53 
8.71 
8.71 
8.71 
2.18 
2.18 
8.71 
6.32 
(2.80) 

PC 
2.18 
6.52 
4.35 
4.35 
2.17 
4.35 
0.32 
2.17 
4.35 
4.36 
3.51 
(1.77) 

RAI 
0.97 
2.27 
2.27 
0.32 
0.65 
0.48 
0.65 
2.32 
2.32 
0.65 
1.29 
(0.88) 

expect  the  RAI  algorithm  to  dominate  both  algorithms 
due to its enhanced mechanism of directing edges. 
Complexity The average reduction in CI tests achieved by 
the RAI algorithm compared to the PC algorithm for the 
ALARM  network  is  presented  in  Figure  5.  The  RAI 
algorithm avoids completely the use of CI tests of order 4 
and  5  and  almost  completely  CI  tests  of  order  3,  and  it 
reduces the use of CI tests of order 2 by more than 83%. 
However, there is almost no reduction in CI tests of order 
1 which are most of the tests. The total CI test run-time  

435structures as well as higher prediction accuracy compared 
to other constraint-based algorithms. 

Acknowledgement 
This  work  was  supported  in  part  by  the  Paul  Ivanier 
Center  for  Robotics  and  Production  Management,  Ben-
Gurion University, Beer-Sheva, Israel. 

References 
 Beinlich,  I.  A.,  Suermondt,  H.  J.,  Chavez,  R.  M.  & 
Cooper,  G.  F.  The  ALARM  monitoring  system:  A 
case study with two probabilistic inference techniques 
for  belief  networks.  Second  European  Conf.  on 
Artificial  Intelligence  in  Medicine,  pages  246-256, 
1989. 

Cheng, 
 

system, 
http://www.cs.ualberta.ca/~jcheng/bnpc.htm. 

PowerConstructor 

J. 

1998. 

Cheng,  J.,  Bell,  D.  &  Liu,  W.  Learning  Bayesian 
networks  from  data:  an  efficient  approach  based  on 
Int.  Conf.  on 
information 
Information and Knowledge Management, pages 325-
331, 1997. 

theory.  Sixth  ACM 

Cheng,  J.  &  Greiner,  R.  Comparing  Bayesian  network 
classifiers, Fifteenth Conf. on Uncertainty in Artificial 
Intelligence, pages 101-107, 1999. 

Friedman,  N.,  Geiger,  D.  &  Goldszmidt,  M.  Bayesian 
network  classifiers.  Machine  Learning,  29:131-161, 
1997. 

Heckerman,  D.  A  tutorial  on  learning  with  Bayesian 

networks. MS TR-95-06, March 1995. 

Kohavi, R., John, G., Long, R., Manley D. & Pfleger, K. 
MLC++: A machine learning library in C++, Sixth Int. 
Conf. on Tools with AI, pages 740-743, 1994. 

Leray, P. & Francois, O. BNT structure learning package: 

documentation and experiments. PSI TR, 2004. 

Murphy,  K.  Bayes  net  toolbox  for  Matlab.  Computing 

Science & Statistics, 33, 2001. 

Murphy, P. M. & Aha, D. W. UCI Repository of machine 
1994. 

learning 
http://www.ics.uci.edu/~mlearn/MLRepository.html. 

databases, 

Pearl,  J.  Causality:  Models,  Reasoning,  and  Inference. 

Cambridge. 2000. 

Ramsey, J., Gazis, P., Roush, T., Spirtes, P. & Glymour, 
C.  Automated  remote  sensing  with  near  infrared 
reflectance  spectra:  Carbonate  recognition.  Data 
Mining  &  Knowledge  Discovery,  pages  277-293, 
2002. 

Spirtes,  P.,  Glymour,  C.  &  Scheines,  R.  Causation, 

Prediction and Search, 2nd edition, MIT Press, 2000. 

 

Figure 5: Average percentage (number) of CI tests 

reduced due to the RAI algorithm compared to the PC 
algorithm for increasing orders and the ALARM network 

 

 

reduced  by  the  RAI  algorithm  compared  to  the  PC 
algorithm is 38%. 

5  DISCUSSION 
The  performance  of  constraint-based  algorithms  of  BN 
structure learning depends on the size of the condition set 
used for testing conditional independence. The larger the 
condition  set  is,  the  more  CI  tests  (especially  of  high 
order) have to be performed and the less is their accuracy.  
We  propose  the  constraint-based  RAI  algorithm  that 
learns BN structures recursively by performing 1) CI tests 
of  increasing  orders,  along  with  2)  directing  edges 
employing  causality  inference  rules  and 3)  decomposing 
the  structure  into  autonomous  sub-structures.  These 
mechanisms  provide  smaller  condition  sets  enabling  the 
performance  of  fewer  CI  tests  of  higher  order  thus 
reducing 
its 
accuracy.  Other  constraint-based  algorithms  directing 
edges after accomplishing the undirected graph using all 
orders,  rather  than  continuously  through  learning,  are 
expensive and more sensitive to errors accumulated along 
the procedure. 
We  demonstrate  on  a  synthetic  problem,  fifteen  real-
world  databases  and  the  ALARM  network  that  the  RAI 
algorithm  significantly  reduces  the  number  of  CI  tests 
required  for  structure  learning  and  yields  more  accurate 

the  algorithm  run-time  and 

increasing 

436Dirichlet Enhanced Latent Semantic Analysis

Kai Yu

Siemens Corporate Technology

D-81730 Munich, Germany

Kai.Yu@siemens.com

spyu@dbs.informatik.uni-muenchen.de

Shipeng Yu

Volker Tresp

Institute for Computer Science

Siemens Corporate Technology

University of Munich

D-80538 Munich, Germany

D-81730 Munich, Germany
Volker.Tresp@siemens.com

Abstract

This paper describes nonparametric Bayesian
treatments for analyzing records containing
occurrences of items. The introduced model
retains the strength of previous approaches
that explore the latent factors of each record
(e.g. topics of documents), and further uncov-
ers the clustering structure of records, which
reﬂects the statistical dependencies of the la-
tent factors. The nonparametric model in-
duced by a Dirichlet process (DP) ﬂexibly
adapts model complexity to reveal the clus-
tering structure of the data. To avoid the
problems of dealing with inﬁnite dimensions,
we further replace the DP prior by a simpler
alternative, namely Dirichlet-multinomial al-
location (DMA), which maintains the main
modelling properties of the DP. Instead of re-
lying on Markov chain Monte Carlo (MCMC)
for inference, this paper applies eﬃcient vari-
ational inference based on DMA. The pro-
posed approach yields encouraging empirical
results on both a toy problem and text data.
The results show that the proposed algorithm
uncovers not only the latent factors, but also
the clustering structure.

1 Introduction

We consider the problem of modelling a large corpus of
high-dimensional discrete records. Our assumption is
that a record can be modelled by latent factors which
account for the co-occurrence of items in a record. To
ground the discussion, in the following we will iden-
tify records with documents, latent factors with (la-
tent) topics and items with words. Probabilistic la-
tent semantic indexing (PLSI) [7] was one of the ﬁrst
approaches that provided a probabilistic approach to-
wards modelling text documents as being composed

of latent topics. Latent Dirichlet allocation (LDA) [3]
generalizes PLSI by treating the topic mixture param-
eters (i.e. a multinomial over topics) as variables drawn
from a Dirichlet distribution. Its Bayesian treatment
avoids overﬁtting and the model is generalizable to
new data (the latter is problematic for PLSI). How-
ever, the parametric Dirichlet distribution can be a
limitation in applications which exhibit a richer struc-
ture. As an illustration, consider Fig. 1 (a) that shows
the empirical distribution of three topics. We see that
the probability that all three topics are present in a
document (corresponding to the center of the plot) is
near zero. In contrast, a Dirichlet distribution ﬁtted to
the data (Fig. 1 (b)) would predict the highest proba-
bility density for exactly that case. The reason is the
limiting expressiveness of a simple Dirichlet distribu-
tion.
This paper employs a more general nonparametric
Bayesian approach to explore not only latent topics
and their probabilities, but also complex dependen-
cies between latent topics which might, for example,
be expressed as a complex clustering structure. The
key innovation is to replace the parametric Dirichlet
prior distribution in LDA by a ﬂexible nonparamet-
ric distribution G(·) that is a sample generated from
a Dirichlet process (DP) or its ﬁnite approximation,
Dirichlet-multinomial allocation (DMA). The Dirich-
let distribution of LDA becomes the base distribution
for the Dirichlet process.
In this Dirichlet enhanced
model, the posterior distribution of the topic mixture
for a new document converges to a ﬂexible mixture
model in which both mixture weights and mixture pa-
rameters can be learned from the data. Thus the a
posteriori distribution is able to represent the distribu-
tion of topics more truthfully. After convergence of the
learning procedure, typically only a few components
with non-negligible weights remain; thus the model is
able to naturally output clusters of documents.
Nonparametric Bayesian modelling has attracted con-
siderable attentions from the learning community

437(a)

(b)

Figure 1: Consider a 2-dimensional simplex represent-
ing 3 topics (recall that the probabilities have to sum
to one):
(a) We see the probability distribution of
topics in documents which forms a ring-like distribu-
tion. Dark color indicates low density; (b) The 3-
dimensional Dirichlet distribution that maximizes the
likelihood of samples.

(e.g. [1, 13, 2, 15, 17, 16]). A potential problem with
this class of models is that inference typically relies on
MCMC approximations, which might be prohibitively
slow in dealing with the large collection of documents
in our setting.
Instead, we tackle the problem by a
less expensive variational mean-ﬁeld inference based
on the DMA model. The resultant updates turn out to
be quite interpretable. Finally we observed very good
empirical performance of the proposed algorithm in
both toy data and textual document, especially in the
latter case, where meaningful clusters are discovered.
This paper is organized as follows. The next section
introduces Dirichlet enhanced latent semantic analy-
sis.
In Section 3 we present inference and learning
algorithms based on a variational approximation. Sec-
tion 4 presents experimental results using a toy data
set and two document data sets.
In Section 5 we
present conclusions.

2 Dirichlet Enhanced Latent Semantic

Analysis

Following the notation in [3], we consider a corpus
D containing D documents. Each document d is
a sequence of Nd words that is denoted by wd =
{wd,1, . . . , wd,Nd}, where wd,n is a variable for the n-th
word in wd and denotes the index of the corresponding
word in a vocabulary V . Note that a same word may
occur several times in the sequence wd.

2.1 The Proposed Model

butions

wd,n|zd,n; β ∼ Mult(zd,n, β)

zd,n|θd ∼ Mult(θd).

(1)
(2)

wd,n is generated given its latent topic zd,n, which
takes value {1, . . . , k}. β is a k × |V | multinomial pa-
j βi,j = 1, where βz,wd,n speciﬁes
the probability of generating word wd,n given topic
z. θd denotes the parameters of a multinomial distri-
bution of document d over topics for wd, satisfying

rameter matrix, P
θd,i ≥ 0,Pk

i=1 θd,i = 1.

In the LDA model, θd is generated from a k-
dimensional Dirichlet distribution G0(θ) = Dir(θ|λ)
with parameter λ ∈ Rk×1. In our Dirichlet enhanced
model, we assume that θd is generated from distribu-
tion G(θ), which itself is a random sample generated
from a Dirichlet process (DP) [5]

G|G0, α0 ∼ DP(G0, α0),

(3)

where nonnegative scalar α0 is the precision parame-
ter, and G0(θ) is the base distribution, which is identi-
cal to the Dirichlet distribution. It turns out that the
distribution G(θ) sampled from a DP can be written
as

G(·) =

(·)

πlδθ∗

l

(4)

∞X

l=1

where πl ≥ 0,P∞

l πl = 1, δθ(·) are point mass distri-
butions concentrated at θ, and θ∗
l are countably inﬁ-
nite variables i.i.d. sampled from G0 [14]. The proba-
bility weights πl are solely depending on α0 via a stick-
breaking process, which is deﬁned in the next subsec-
tion. The generative model summarized by Fig. 2(a)
is conditioned on (k × |V | + k + 1) parameters, i.e. β,
λ and α0.
Finally the likelihood of the collection D is given by

(cid:20)
(cid:21)

p(θd|G)

(cid:27)

dθd

dG.

(5)

Z

(cid:26)

Z

DY

LDP(D|α0, λ, β) =

NdY

kX

n=1

zd,n=1

p(G; α0, λ)

G

d=1

θd

p(wd,n|zd,n; β)p(zd,n|θd)

In short, G is sampled once for the whole corpus D, θd
is sampled once for each document d, and topic zd,n
sampled once for the n-th word wd,n in d.

2.2 Stick Breaking and Dirichlet Enhancing

We assume that each document is a mixture of k latent
topics and words in each document are generated by
repeatedly sampling topics and words using the distri-

The representation of a sample from the DP-prior in
Eq. (4) is generated in the stick breaking process in
which inﬁnite number of pairs (πl, θ∗
l ) are generated.

438(a)

(b)

(c)

Figure 2: Plate models for latent semantic analysis. (a) Latent semantic analysis with DP prior; (b) An equivalent
representation, where cd is the indicator variable saying which cluster document d takes on out of the inﬁnite
clusters induced by DP; (c) Latent semantic analysis with a ﬁnite approximation of DP (see Sec. 2.3).

θ∗
l is sampled independently from G0 and πl is deﬁned
as

π1 = B1,

πl = Bl

(1 − Bj),

l−1Y

j=1

where Bl are i.i.d. sampled from Beta distribution
Beta(1, α0). Thus, with a small α0, the ﬁrst “sticks”
πl will be large with little left for the remaining sticks.
Conversely, if α0 is large, the ﬁrst sticks πl and all
subsequent sticks will be small and the πl will be more
evenly distributed.
In conclusion, the base distribu-
tion determines the locations of the point masses and
α0 determines the distribution of probability weights.
The distribution is nonzero at an inﬁnite number of
discrete points. If α0 is selected to be small the am-
plitudes of only a small number of discrete points will
be signiﬁcant. Note, that both locations and weights
are not ﬁxed but take on new values each time a new
sample of G is generated. Since E(G) = G0, initially,
the prior corresponds to the prior used in LDA. With
many documents in the training data set, locations θ∗
l
which agree with the data will obtain a large weight.
If a small α0 is chosen, parameters will form clusters
whereas if a large α0, many representative parameters
will result. Thus Dirichlet enhancement serves two
purposes:
it increases the ﬂexibility in representing
the posterior distribution of mixing weights and en-
courages a clustered solution leading to insights into
the document corpus.
The DP prior oﬀers two advantages against usual doc-
ument clustering methods. First, there is no need to
specify the number of clusters. The ﬁnally resulting
clustering structure is constrained by the DP prior,
but also adapted to the empirical observations. Sec-
ond, the number of clusters is not ﬁxed. Although
the parameter α0 is a control parameter to tune the
tendency for forming clusters, the DP prior allows the
creation of new clusters if the current model cannot

explain upcoming data very well, which is particularly
suitable for our setting where dictionary is ﬁxed while
documents can be growing.
By applying the stick breaking representation, our
representation in
model obtains
equivalent
Fig. 2(b). An inﬁnite number of θ∗
l are generated from
the base distribution and the new indicator variable cd
indicates which θ∗
is assigned to document d. If more
than one document is assigned to the same θ∗
l , cluster-
ing occurs. π = {π1, . . . , π∞} is a vector of probability
weights generated from the stick breaking process.

the

l

2.3 Dirichlet-Multinomial Allocation (DMA)
Since inﬁnite number of pairs (πl, θ∗
l ) are generated in
the stick breaking process, it is usually very diﬃcult to
deal with the unknown distribution G. For inference
there exist Markov chain Monte Carlo (MCMC) meth-
ods like Gibbs samplers which directly sample θd using
P´olya urn scheme and avoid the diﬃculty of sampling
the inﬁnite-dimensional G [4]; in practice, the sam-
pling procedure is very slow and thus impractical for
high dimensional data like text. In Bayesian statistics,
the Dirichlet-multinomial allocation DPN in [6] has of-
ten been applied as a ﬁnite approximation to DP (see
[6, 9]), which takes on the form

NX

GN =

πlδθ∗

l

,

l=1

where π = {π1, . . . , πN} is an N-vector of proba-
bility weights sampled once from a Dirichlet prior
Dir(α0/N, . . . , α0/N), and θ∗
l = 1, . . . , N, are
l ,
i.i.d. sampled from the base distribution G0.
It has
been shown that the limiting case of DPN is DP
[6, 9, 12], and more importantly DPN demonstrates
similar stick breaking properties and leads to a simi-
lar clustering eﬀect [6]. If N is suﬃciently large with

439respect to our sample size D, DPN gives a good ap-
proximation to DP.
Under the DPN model, the plate representation of our
model is illustrated in Fig. 2(c). The likelihood of the
whole collection D is

DY

(cid:20) NX

Z

Z

(cid:21)

π

θ∗
p(cd|π)

p(wd|θ

∗

, cd; β)

d=1

cd=1

dP (θ

∗; G0) dP (π; α0) (6)

LDPN (D|α0, λ, β) =

where cd is the indicator variable saying which unique
value θ∗
l document d takes on. The likelihood of doc-
ument d is therefore written as

p(wd|θ

∗

, cd; β) =

p(wd,n|zd,n; β)p(zd,n|θ∗

cd

).

NdY

kX

n=1

zd,n=1

derived, but it turns out to be very slow and inappli-
cable to high dimensional data like text, since for each
word we have to sample a latent variable z. Therefore
in this section we suggest eﬃcient variational
infer-
ence.

3.1 Variational Inference

∗

The idea of variational mean-ﬁeld inference is to
propose a joint distribution Q(π, θ
, c, z) condi-
tioned on some free parameters, and then en-
force Q to approximate the a posteriori distribu-
tions of interests by minimizing the KL-divergence
DKL(Qkp(π, θ
, c, z|D, α0, λ, β)) with respect to those
free parameters. We propose a variational distribution
Q over latent variables as the following

∗

2.4 Connections to PLSA and LDA

∗

Q(π, θ

From the application point of view, PLSA and LDA
both aim to discover the latent dimensions of data
with the emphasis on indexing. The proposed Dirich-
let enhanced semantic analysis retains the strengths
of PLSA and LDA, and further explores the cluster-
ing structure of data. The model is a generalization
of LDA. If we let α0 → ∞, the model becomes identi-
cal to LDA, since the sampled G becomes identical to
the ﬁnite Dirichlet base distribution G0. This extreme
case makes documents mutually independent given G0,
since θd are i.i.d. sampled from G0. If G0 itself is not
suﬃciently expressive, the model is not able to cap-
ture the dependency between documents. The Dirich-
let enhancement elegantly solves this problem. With
a moderate α0, the model allows G to deviate away
from G0, giving modelling ﬂexibilities to explore the
richer structure of data. The exchangeability may not
exist within the whole collection, but between groups
of documents with respective atoms θ∗
l sampled from
G0. On the other hand, the increased ﬂexibility does
not lead to overﬁtting, because inference and learn-
ing are done in a Bayesian setting, averaging over the
number of mixture components and the states of the
latent variables.

3 Inference and Learning

inference and
In this section we consider model
seen
learning based on the DPN model.
from Fig. 2(c), the inference needs to calculate the
a posteriori
latent variables
, c, z|D, α0, λ, β), which requires to compute
p(π, θ
Eq. (6). This integral is however analytically infeasi-
ble. A straightforward Gibbs sampling method can be

joint distribution of

As

∗

NY

, c, z|η, γ, ψ, φ) = Q(π|η)·
Q(cd|ψd)

DY

Q(θ∗

l |γl)

DY

NdY

l=1

d=1

d=1

n=1

Q(zd,n|φd,n)

(7)

where η, γ, ψ, φ are variational parameters, each tai-
loring the variational a posteriori distribution to each
latent variable.
In particular, η speciﬁes an N-
dimensional Dirichlet distribution for π, γl speciﬁes
a k-dimensional Dirichlet distribution for distinct θ∗
l ,
ψd speciﬁes an N-dimensional multinomial for the in-
dicator cd of document d, and φd,n speciﬁes a k-
dimensional multinomial over latent topics for word
wd,n. It turns out that the minimization of the KL-
divergence is equivalent to the maximization of a
lower bound of the ln p(D|α0, λ, β) derived by apply-
ing Jensen’s inequality [10]. Please see the Appendix
for details of the derivation. The lower bound is then
given as

DX

NdX

d=1

n=1

LQ(D) =

EQ[ln p(wd,n|zd,n, β)p(zd,n|θ

∗

, cd)]

DX

+ EQ[ln p(π|α0)] +

EQ[ln p(cd|π)]

(8)

d=1

EQ[ln p(θ∗

l |G0)] − EQ[ln Q(π, θ

∗

, c, z)].

NX

+

l=1

The optimum is found setting the partial derivatives
with respect to each variational parameter to be zero,

440which gives rise to the following updates

n NX
φd,n,i ∝ βi,wd,n exp
h(cid:16)

(cid:26) kX

ψd,l ∝ exp

l=1

i=1

ψd,l

γl,j)(cid:3)o
kX
(cid:2)Ψ(γl,i) − Ψ(
(cid:17) NdX
i
kX

j=1

(9)

γl,j)

φd,n,i

Ψ(γl,i) − Ψ(

NX

(cid:27)

+ Ψ(ηl) − Ψ(

ηj)

NdX

j=1

ψd,lφd,n,i + λi

DX
DX

d=1

d=1

γl,i =

ηl =

n=1

ψd,l + α0
N

j=1

n=1

(10)

(11)

(12)

where Ψ(·) is the digamma function, the ﬁrst deriva-
tive of the log Gamma function. Some details of the
derivation of these formula can be found in Appendix.
We ﬁnd that the updates are quite interpretable. For
example, in Eq. (9) φd,n,i is the a posteriori probability
of latent topic i given one word wd,n. It is determined
both by the corresponding entry in the β matrix that
can be seen as a likelihood term, and by the possi-
bility that document d selects topic i, i.e., the prior
term. Here the prior is itself a weighted average of
diﬀerent θ∗
In Eq. (12) ηl
is the a posteriori weight of πl, and turns out to be
the tradeoﬀ between empirical responses at θ∗
l and the
prior speciﬁed by α0. Finally since the parameters are
coupled, the variational inference is done by iteratively
performing Eq. (9) to Eq. (12) until convergence.

l s to which d is assigned.

3.2 Parameter Estimation

Following the empirical Bayesian framework, we can
estimate the hyper parameters α0, λ, and β by itera-
tively maximizing the lower bound LQ both with re-
spect to the variational parameters (as described by
Eq. (9)-Eq. (12)) and the model parameters, holding
the remaining parameters ﬁxed. This iterative proce-
dure is also referred to as variational EM [10]. It is
easy to derive the update for β:

βi,j ∝ DX

NdX

φd,n,iδj(wd,n)

(13)

d=1

n=1

where δj(wd,n) = 1 if wd,n = j, and 0 otherwise. For
the remaining parameters, let’s ﬁrst write down the

N

parts of L in Eq. (8) involving α0 and λ:

L[α0] = ln Γ(α0) − N ln Γ(cid:0) α0
(cid:1)
NX
NX
(cid:2)Ψ(ηl) − Ψ(
kX
λi) − kX
kX
kX
(λi − 1)(cid:2)Ψ(γl,i) − Ψ(

+ ( α0
N

NX

L[λ] =

ln Γ(λi)

− 1)

n

ln Γ(

j=1

+

l=1

l=1

i=1

i=1

ηj)(cid:3),

γl,j)(cid:3)o

.

i=1

j=1

Estimates for α0 and λ are found by maximization of
these objective functions using standard methods like
Newton-Raphson method as suggested in [3].

4 Empirical Study

4.1 Toy Data

We ﬁrst apply the model on a toy problem with
k = 5 latent topics and a dictionary containing 200
words. The assumed probabilities of generating words
from topics, i.e. the parameters β, are illustrated in
Fig. 3(d), in which each colored line corresponds to a
topic and assigns non-zero probabilities to a subset of
words. For each run we generate data with the follow-
ing steps: (1) one cluster number M is chosen between
5 and 12; (2) generate M document clusters, each of
which is deﬁned by a combination of topics; (3) gener-
ate each document d, d = 1, . . . , 100, by ﬁrst randomly
selecting a cluster and then generating 40 words ac-
cording to the corresponding topic combinations. For
DPN we select N = 100 and we aim to examine the
performance for discovering the latent topics and the
document clustering structure.
In Fig. 3(a)-(c) we illustrate the process of clustering
documents over EM iterations with a run containing
6 document clusters. In Fig. 3(a), we show the initial
random assignment ψd,l of each document d to a clus-
ter l. After one EM step documents begin to accumu-
late to a reduced number of clusters (Fig. 3(b)), and
converge to exactly 6 clusters after 5 steps (Fig. 3(c)).
The learned word distribution of topics β is shown in
Fig. 3(e) and is very similar to the true distribution.
By varying M, the true number of document clusters,
we examine if our model can ﬁnd the correct M. To de-
termine the number of clusters, we run the variational
inference and obtain for each document a weight vector
ψd,l of clusters. Then each document takes the cluster
with largest weight as its assignment, and we calculate
the cluster number as the number of non-empty clus-
ters. For each setting of M from 5 to 12, we randomize
the data for 20 trials and obtain the curve in Fig. 3(f)

441(a)

(d)

(b)

(e)

(c)

(f )

Figure 3: Experimental results for the toy problem. (a)-(c) show the document-cluster assignments ψd,l over the
variational inference for a run with 6 document clusters: (a) Initial random assignments; (b) Assignments after
one iteration; (c) Assignments after ﬁve iterations (ﬁnal). The multinomial parameter matrix β of true values
and estimated values are given in (d) and (e), respectively. Each line gives the probabilities of generating the
200 words, with wave mountains for high probabilities. (f) shows the learned number of clusters with respect to
the true number with mean and error bar.

which shows the average performance and the vari-
ance. In 37% of the runs we get perfect results, and
in another 43% runs the learned values only deviate
from the truth by one. However, we also ﬁnd that the
model tends to get slightly fewer than M clusters when
M is large. The reason might be that, only 100 doc-
uments are not suﬃcient for learning a large number
M of clusters.

4.2 Document Modelling

We compare the proposed model with PLSI and LDA
on two text data sets. The ﬁrst one is a subset of
the Reuters-21578 data set which contains 3000 docu-
ments and 20334 words. The second one is taken from
the 20-newsgroup data set and has 2000 documents
with 8014 words. The comparison metric is perplexity,
conventionally used in language modelling. For a test
document set, it is formally deﬁned as

Perplexity(Dtest) = exp

− ln p(Dtest)/

|wd|

.

d

We follow the formula in [3] to calculate the perplexity
for PLSI. In our algorithm N is set to be the number
of training documents. Fig. 4(a) and (b) show the

 

!

X

comparison results with diﬀerent number k of latent
topics. Our model outperforms LDA and PLSI in all
the runs, which indicates that the ﬂexibility introduced
by DP enhancement does not produce overﬁtting and
results in a better generalization performance.

4.3 Clustering

In our last experiment we demonstrate that our ap-
proach is suitable to ﬁnd relevant document clusters.
We select four categories, autos, motorcycles, baseball
and hockey from the 20-newsgroups data set with 446
documents in each topic. Fig. 4(c) illustrates one clus-
tering result, in which we set topic number k = 5 and
found 6 document clusters.
In the ﬁgure the docu-
ments are indexed according to their true category
labels, so we can clearly see that the result is quite
meaningful. Documents from one category show sim-
ilar membership to the learned clusters, and diﬀerent
categories can be distinguished very easily. The ﬁrst
two categories are not clearly separated because they
are both talking about vehicles and share many terms,
while the rest of the categories, baseball and hockey,
are ideally detected.

442(a)

(b)

(c)

Figure 4: (a) and (b): Perplexity results on Reuters-21578 and 20-newsgroups for DELSA, PLSI and LDA; (c):
Clustering result on 20-newsgroups dataset.

5 Conclusions and Future Work

This paper proposes a Dirichlet enhanced latent se-
mantic analysis model
for analyzing co-occurrence
data like text, which retains the strength of previous
approaches to ﬁnd latent topics, and further introduces
additional modelling ﬂexibilities to uncover the clus-
tering structure of data. For inference and learning, we
adopt a variational mean-ﬁeld approximation based on
a ﬁnite alternative of DP. Experiments are performed
on a toy data set and two text data sets. The ex-
periments show that our model can discover both the
latent semantics and meaningful clustering structures.
In addition to our approach, alternative methods for
approximate inference in DP have been proposed us-
ing expectation propagation (EP) [11] or variational
methods [16, 2]. Our approach is most similar to the
work of Blei and Jordan [2] who applied mean-ﬁeld ap-
proximation for the inference in DP based on a trun-
cated DP (TDP). Their approach was formulated in
context of general exponential-family mixture models
[2]. Conceptually, DPN appears to be simpler than
TDP in the sense that the a posteriori of G is a sym-
metric Dirichlet while TDP ends up with a generalized
Dirichlet (see [8]). In another sense, TDP seems to be
a tighter approximation to DP. Future work will in-
clude a comparison of the various DP approximations.

Acknowledgements

The authors thank the anonymous reviewers for their
valuable comments. Shipeng Yu gratefully acknowl-
edges the support through a Siemens scholarship.

References

[1] M. J. Beal, Z. Ghahramani, and C. E. Rasmussen.
The inﬁnite hidden Markov model. In Advances in
Neural Information Processing Systems (NIPS)
14, 2002.

[2] D. M. Blei and M. I. Jordan. Variational meth-
ods for the Dirichlet process. In Proceedings of the
21st International Conference on Machine Learn-
ing, 2004.

[3] D. M. Blei, A. Ng, and M. I. Jordan. Latent
Dirichlet Allocation. Journal of Machine Learn-
ing Research, 3:993–1022, 2003.

[4] M. D. Escobar and M. West. Bayesian density
estimation and inference using mixtures. Journal
of the American Statistical Association, 90(430),
June 1995.

[5] T. S. Ferguson. A Bayesian analysis of some non-
parametric problems. Annals of Statistics, 1:209–
230, 1973.

[6] P. J. Green and S. Richardson. Modelling hetero-
geneity with and without the Dirichlet process.
unpublished paper, 2000.

[7] T. Hofmann. Probabilistic Latent Semantic In-
dexing. In Proceedings of the 22nd Annual ACM
SIGIR Conference, pages 50–57, Berkeley, Cali-
fornia, August 1999.

[8] H. Ishwaran and L. F. James. Gibbs sampling
methods for stick-breaking priors. Journal of the
American Statistical Association, 96(453):161–
173, 2001.

[9] H. Ishwaran and M. Zarepour. Exact and ap-
proximate sum-representations for the Dirichlet
process. Can. J. Statist, 30:269–283, 2002.

[10] M. I. Jordan, Z. Ghahramani, T. Jaakkola, and
L. K. Saul. An introduction to variational meth-
ods for graphical models. Machine Learning,
37(2):183–233, 1999.

[11] T. Minka and Z. Ghahramani. Expectation prop-
agation for inﬁnite mixtures. In NIPS’03 Work-
shop on Nonparametric Bayesian Methods and
Inﬁnite Models, 2003.

[12] R. M. Neal. Markov chain sampling methods
Journal

for Dirichlet process mixture models.

443DX
NX

d=1

l=1

EQ[ln p(cd|π)] =

EQ[ln p(θ∗

The other terms can be derived as follows:

EQ[ln p(zd,n|θ

∗

, cd)] =

DX

d=1

NdX
DX

n=1

NdX

d=1

n=1

i=1

l=1

EQ[ln p(π|α0)] = ln Γ(α0) − N ln Γ( α0
N

)

ln Γ(λi)

N

l=1

l=1

+

j=1

j=1

d=1

l=1

j=1

ψd,l

ln Γ(

− 1

ψd,lφd,n,i

kX

NX

l |G0)] =
kX

kX
(cid:2)Ψ(γl,i) − Ψ(
γl,j)(cid:3),
(cid:16) α0
(cid:17) NX
NX
(cid:2)Ψ(ηl) − Ψ(
ηj)(cid:3),
DX
NX
NX
(cid:2)Ψ(ηl) − Ψ(
ηj)(cid:3),
(cid:26)
NX
kX
λi) − kX
γl,j)(cid:3)(cid:27)
kX
(λi − 1)(cid:2)Ψ(γl,i) − Ψ(
NX
ηl) − NX
NX
(ηl − 1)(cid:2)Ψ(ηl) − Ψ(
ηj)(cid:3)
(cid:26)
γl,i) − kX
kX
NX

kX
kX
(γl,i − 1)(cid:2)Ψ(γl,i) − Ψ(
kX
NdX

γl,j)(cid:3)(cid:27)

, c, z)] = ln Γ(

DX

ln Γ(γl,i)

ln Γ(ηl)

ln Γ(

j=1

j=1

j=1

+

i=1

i=1

i=1

i=1

i=1

i=1

l=1

l=1

,

φd,n,i ln φd,n,i.

ψd,l ln ψd,l +

EQ[ln Q(π, θ

∗

NX
NX

l=1

l=1

+

DX

+

+

+

d=1

l=1

d=1

n=1

i=1

Diﬀerentiating the lower bound with respect to dif-
ferent latent variables gives the variational E-step in
Eq. (9) to Eq. (12). M-step can also be obtained by
considering the lower bound with respect to β, λ and
α0.

of Computational and Graphical Statistics, 9:249–
265, 2000.

Inﬁnite
[13] C. E. Rasmussen and Z. Ghahramani.
mixtures of gaussian process experts.
In Ad-
vances in Neural Information Processing Systems
14, 2002.

[14] J. Sethuraman. A constructive deﬁnition of
Statistica Sinica, 4:639–650,

Dirichlet priors.
1994.

[15] Y. W. Teh, M. I. Jordan, M. J. Beal, and D. M.
Blei. Hierarchical Dirichlet processes. Technical
Report 653, Department of Statistics, University
of California, Berkeley, 2004.

[16] V. Tresp and K. Yu. An introduction to non-
parametric hierarchical bayesian modelling with
a focus on multi-agent learning. In Proceedings of
the Hamilton Summer School on Switching and
Learning in Feedback Systems. Lecture Notes in
Computing Science, 2004.

[17] K. Yu, V. Tresp, and S. Yu. A nonparametric
hierarchical Bayesian framework for information
ﬁltering. In Proceedings of 27th Annual Interna-
tional ACM SIGIR Conference, 2004.

Appendix

∗

To simplify the notation, we denote Ξ for all the la-
tent variables {π, θ
, c, z}. With the variational form
Eq. (7), we apply Jensen’s inequality to the likelihood
Eq. (6) and obtain
ln p(D|α0, λ, β)

Z
Z
Z
Z

π

π

Z

θ∗

Z
Z

θ∗

z

c

X
X
X
X
X
X
X
X

c

z

c

z

θ∗

= ln

= ln

Z

≥

π

p(D, Ξ|α0, λ, β)dθ∗dπ
Q(Ξ)p(D, Ξ|α0, λ, β)

Q(Ξ)

dθ∗dπ

Q(Ξ) ln p(D, Ξ|α0, λ, β)dθ∗dπ

−

Q(Ξ) ln Q(Ξ)dθ∗dπ
= EQ[ln p(D, Ξ|α0, λ, β)] − EQ[ln Q(Ξ)],

θ∗

π

c

z

DX

NdX

which results in Eq. (8).
To write out each term in Eq. (8) explicitly, we have,
for the ﬁrst term,

EQ[ln p(wd,n|zd,n, β)] =

φd,n,i ln βi,ν,

d=1

n=1

d=1

n=1

i=1

where ν is the index of word wd,n.

DX

NdX

kX

444 	


	 
!"$#%!"&'(!'

5.,7698/2:<;=/2:
>=?A@
BDCFEHGIAJKD@(LNM(OD@
M2P2QRO=LNSAM
TVUWLFEHGXIYJ	ZRL
`Ya

)+**	,-.,0/21(/43
bc`(d<efd(gYh.ikj(lmd<n=jkd<amgpoqamn=r

[]\^M
_YM(O
es`At"uvhwj<ikamgpoqamn=r

xzy|{4}2~D}

MDTVM
UVM
O2E?X_YM(ODM
TV?YCv?Y=DTWI2LF\^?YE]LFIYO\^M
EWDI2
JmIAT0?GYM
UVLF?YOLNODJmM(TWM(OD@
MwDTWIADCFM
\^U DM\^M
EWDI2
LFUXD?YUVM
IYOw27M
@(E]?YEWLNIAO.TWIAD?Y_A?YEWLNIAOmw]
.TWIc[]M
@
EWLNIAOUVE]M
=U	LFO'EWDMwLNEWM
TV?YE]LFIYO'E]D?AE	@(?YOD
ODIAE7MwDIAODM?AOD?YCFG2E]LF@
?YCFCFGR?YTVMDIAODMBDUVLFOD_ ?ABDUW
UVLN?AO¢¡2BD?YDTV?YEWBDTVM4£ GLFDM
O2E]LFJmG2LNO=_?z_YM(ODM
TV?YC
JmIATW\¤LNOEWDMDTVI[]M(@
E]LFIYO=UP2EWDMIAODCNG¡2BD?Y=TW?AE]BDTVM
TVBDCFM
UE]=?YE¥?ATWMTWM(¡2BDLNTVM
?YTVMJmIYT¥M(2¦IAODM
O2E]LF?YC
Jm?A\LFCFG¨§ M
LF_Y2EJmBDOD@(E]LFIYODU =MX@
IYTVTVM
UV¦IAODDLFOD_
@(BD\'BDCF?YO2E?YOD\^IY\^M
O2E^_YM(ODM
TV?YEWLNOD_JmBDOD@(E]LFIYODU
@(?YO©EWDM
O+¦MBDUVM
+E]I?YBDEWIY\^?YEWLN@(?YCFCNG^DM(TWLFSYM|E]DM
ODM(@
M(UWUV?YTVGª¡4B=?YDTV?YEWBDTWMTWB=CNM(U¬«HO­EWDLFU?YTVE]LF@
CFM
EWDM©?ADDTVIY?Y@pLFU"TVM
UVE]TVLF@
E]M(®E]I?YDDTVI2LN\^?AE]LFOD_
Jm?A\LFCFLNM(UE]D?AEXJm?Y@(E]IYTVLF¯
M°E]I®?DTVI2DBD@
EXIAJ|IAODM

DLF\^M
ODUVLFIYOD?ACJm?Y\^LNCFLFM
U
 DM¨±DOD?YCR?YCF_YIYTVLFE]D\=?YULFO2E]M
TVM
UVE]LFOD_®UVLN\^LFCN?ATW
LFE]LFM
U§ LNEW²D?ATWEWLN@(CNM¥±=CNEWM
TVLNOD_?YCF_YIATWLFE]D\^UM
DLFUV@
BDUVU³E]=M
UVM4P?YOD´?ACNUVIDLFUW@(BDUWU%E]DMTVM
CF?Y
EWLNIAODUW=LN§ LNEWS?ATWLF?YEWLNIAOD?YC	?GYM
U?YO=µ?YDCF?Y@(M
DTVIY=?Y_Y?AE]LFIYO w2¦M(TWLF\^M
O2E]?ACTVM
UVBDCFE]U|?YTVM'_YLFSYM(O
JmIAT?YOLFO4EWM
TVM
UVE]LFOD_\^I2DM
C.JmTWIA\£\^?YEWDM
\^?YEWLN@(?YC
±DO=?YOD@(M4

·Y¸¹º¼»ª½²¾¿¼¹·A»ª¸

«HELNUSYM(TWGOD?YEWBDTV?YC E]I¨EWTWGEWI¨@
IA\'DLFODM+w%§ LFE]?YO¼M(2
LFUWEWLNOD_©E]M
@p=ODLN¡2BDMEWI?Y=DTWI2LF\^?YE]MTVM
CF?YEWLNSAM
CFG©CFI§­DLF\^M
OD
UVLNIAOD?YCLNO2E]M(_YTV?YCFU «HOÀNÁÌËcÃ	w²LFU|@(IY\"DLNO=M
¥§ LFE]¥µ?YDCF?Y@(M
?Y=DTWI2LF\^?YE]LFIYO=UÎÍ|M
TVM'§ MM
2D?AOD¥BD7IYOªÀNÁÌÏcÃ?AODÀ
Â7ÁkÃ
?YO=©DM(±DODM?"_AM
ODM(TW?AC¦§ ?G^IYJ0@(IY\"DLNO=LNOD_w§ LNEW ?ABDUV
UVLN?AOÆ¡2BD?Y=TW?AE]BDTVM4KDM(@
E]LFIYOÐUVDI§ UDI§M
SAM
TVGDTWIc[]M
@(
E]LFIYO®@(?YO®7M©LFO2E]M
TVDTVM
EWM
®LFO¼?_YM(ODM
TV?YCJmIATW\¥KDM(@
EWLNIAO®Ë
DM(UW@(TWLF¦M(U'DI§'PBDUVLNO=_¥KDE]LFM
CFEm[]M(U"=TWI2@
M(DBDTVMXE]I@
IYO=UWEWTWBD@(E
IYTVE]=IY_YIAOD?YCq7IYCFG2ODIY\^LF?YCFUPcE]DMRTWM(¡4B=LNTVM
^¡2BD?Y=TW?AE]BDTVM TWB=CNM(U
@
?AOz¦MDM
TVLFSYM
ª?ABDE]IA\?AE]LF@
?ACNCFG4 DLFU©\^M(?YODU+E]D?AE©E]=M
M
O2EWLNTVM¡2BD?YDTV?YEWBDTVM.zTWIABDE]LFODM@(IYBDCF¦M'@
IY\^DB=E]M
TR_YM
O=
M
TV?YEWM
zJmIAT+\^?YO2G@pDIYUVM
Oz?ADDTVI2LN\^?YEWLNO=_®Jm?Y\^LNCFLFM
U¬Ê J
@
IABDTVUWM2Pv\^?YÈ2LNO=_BDUWMXIAJ.=TWIA¦M(TWEWLNM(UIYJ UW7M
@(LN±D@©M
2¦IAODM
O=
E]LF?YC7Jm?Y\^LFCNGXJmIATW\^U.@
?YO©TWM(UWBDCFEwLFO©M(É^@
LFM
OD@(G_A?YLFODU0Ñ|OD©?AU
LFERODI§ÒUVE]?YO=DUPDE]DM"@pDIYUVM
O?ADDTVI2LN\^?YEWLNO=_Jm?A\^LNCFG°LNU|TWM(
¡2BDLFTWM(E]I©Jm?A@
EWIYTVLN¯(MIYO2E]I?©DTWI2DB=@
ERIAJIYODM(sDLF\^M
ODUVLFIYOD?AC
Jm?Y\^LFCNLFM
U|ÍRI§ M
SAM
TPDEWDM"=TWI2@
M(DBDTVM?YUDM(UW@(TWLF¦M(¨LFO¨EWDLNU
?YTVE]LF@
CFM@
?YOJmIYTV\ÓE]DM^D?AUWLFUJmIYT?\M(E]DI2?YU_AM
ODM(TW?AC?AU
E]=MS<?ATWLF?YEWLNIAOD?YCÔ\M(?YODf±DM(CN	?GAM
U?YD=TWIA?Y@pÀFÁYP2ÂYÃÕ
	IJm?A@
LFCNLFE]?AE]M°E]=MDM
UV@
TVLN=E]LFIYOIYJREWDM\^M
EWDI2DUX§.M°±DTVUVE
LFO4EWTWI2DB=@
MIYBDT°TVBDODODLFOD_ªM
2?A\=CNM?YO=­DTVLFM
ÄDGzDM(UW@(TWLF7M
wwPDE]DM'M
2¦IAODM
O2EWLN?ACJm?Y\^LFCNG°?AODÆ ?YBDUVUVLN?AO¡4B=?YDTV?YEWBDTWM2
ÖM(?YDM(TWUJm?Y\^LFCNLF?YT§ LNEW¨EWDM
UVM"=?YUVLN@(U|\^?GDTVLNM(ÄDG°_YCF?YOD@(M
?YE>LF_YBDTVMÁ?YOD'[]BD\^E]I^KDM(@
E]LFIYO°Ð^TVLN_A4E?§ ?G4

ØR¹»¿ÆÙ

»ª½²ß°Ü'Ø

Ø|¹·A¿ÛÚ»Ü

¹·YÜ'·A¹Ý

w27M
@(E]?YEWLNIAOwTVIYD?A_Y?AE]LFIYOm.0ÀFÁpÂAÃALFU?R¦I§ M
TVJmBDC4DM
EWM
TV
\^LNO=LNUVE]LF@?YD=TWI2LF\?AE]MLNO=JmM
TVM
OD@(MEWM
@pDO=LN¡2BDM2	«HE LNU DTVLFM
ÄDG
LFO4EWTWI2DB=@
M
LNOKDM
@(E]LFIYOÅ7«HOw?AO¨LFODLFE]LF?YC?YD=TWI2LF\?A
E]LFIYOLNULFE]M
TV?YEWLNSAM
CFGTWM(±DODM
Æ4GLFO2E]TVI4=BD@
LFOD_¨LFO2E]M(TW?A@
E]LFIYO=U
JmTVIY\ÇE]DM|M
2?Y@(E\^I2DM
C7?YOD©UWBD=UWM(¡4B=M
O2E]CFG^DTWIc[]M
@(E]LFOD_E]=M
M
2EWM
ODDM(°?YDDTVI2LN\^?AE]LFIYO©=?Y@pÈXIYO2EWI?X@p=IYUVM
O©=?YTV?Y\^M
EW
TVLN@Jm?Y\^LFCNG2 DM
UVMDTWIc[]M
@(E]LFIYODU7IYLFCDI§ O©EWI?^\^?YEW@pDLFOD_
IYJ.M
27M
@
EWM
UWB=É@(LNM(O2EUWEW?YE]LFUVE]LF@
U+Ê ODMIYJ.E]DMX=TWIADCNM(\^U
E]=?YE@
?AO"UVE]?AOD^LNO^EWDM §.?GIAJ=?DLFTVM
@
E?ADDCFLN@(?YE]LFIYOIYJ7E]=M
wEWM
@pDODLF¡2BDM4PcLNUEWD?YEwE]DM TVM
¡2BDLFTWM("LFO2E]M(_YTV?YCFU	LF\^DCFLNM(2G
E]=M¨@
IA\^DBDE]?AE]LFIYOzIAJEWDM¨M(2¦M(@
E]M(²UVBDÉ^@
LFM
O2EUVE]?YEWLNUVE]LF@
U
@
?AODODIAE 7MDIAODM?YOD?ACNG2E]LF@
?ACNCFG4

à¥?AO4GIYJqEWDM4P<2GODI§@
CF?YUVUVLN@2P
TVM
UVBDCFE]ULNO"\?AE]DM(\^?YE]LF@
?ACY±D
OD?AOD@
M?YUVUVBD\^M EWD?YEUVE]I2@pÈ2UJmIYCFCFI§Æ?_YM(IY\^M
EWTWLF@ TVI§ ODLF?YO
\^IYEWLNIAO DLFU^\I2DM(CLN\^DCFLNM(UXE]D?AE"M(¡2BDLN=LNUVE]?AO4ECFIY_TWM(
E]B=TWODU ?ATWMLFODDM(¦M(ODDM
O2EWCNG2P2LN=M
O2E]LF@
?ACNCFG©?AOD+O=IYTV\?ACNCFGXDLFUW
E]TVLFDBDE]M(­ÑRCFE]DIABD_YzEWDM¥_AM
IY\^M(E]TVLN@°TWI§ O=LN?AO\^IYEWLNIAO
_YLFSYM(U©?TWIABD_Yz=M
UV@
TVLNDEWLNIAO²IYJ'UWEWI4@pÈª\^?YTVÈYM(E7M
D?S2LFIYTP
E]=M+CFIY_TWM(E]BDTVODUE]M(ODEWI=?SYMJm?AE]E]M(T^E]?YLFCFUEWD?YO?¨O=IYTV
\^?YCDLFUVE]TVLNDB=E]LFIYO?YODDI°ODIYEUVM
M(\áE]I°7M=IY\^IYUVÈYM(D?YUV
E]LF@4. DLFUR=?YUCFM
EWIE]DM'DM
SAM
CFIYD\^M
O2E IAJ	\^I2DM(CNU|§ DM
TVM
E]=MUVE]?AODD?ATWDM
S2LF?YE]LFIYOIYJ.E]DM^CFIY_TWM(E]BDTVODUP7TWM(JmM
TVTWM(¨EWI
?YUwSYIYCF?YEWLNCFLFEHG'LFOX±DOD?YO=@
M4PcLNU.E]TVM
?AE]M
X?AU?TV?YODDIA\%S?YTVLF?YDCFM
LFE]UVM
CFJ]	«HOEWDLFU ?YTVE]LF@
CFM|§ MUWEWBDDGEWDMUWEWI2@pD?YUVE]LF@|SAIYCF?YEWLNCFLNEHG

445¶
×
x
x
Þ




	




	


PE]DM+CNIA_TWM(E]BDTVO®?YE

>LN_ABDTVMÁv DM DG2OD?Y\^LF@.?GYM(UWLF?YOO=M
EH§ IYTVÈEWD?YE	M
O=@
I2DM
U
E]=Mw@
IAODDLFE]LFIYOD?ACALFODDM(¦M(ODDM(OD@
M(ULFOE]=MwUVE]I2@pD?YUVE]LF@SAIYCF?YE]LFCF
LFEHG©\^I2DM
CHKDD?ADLFOD_^M
\^DD?AUWLF¯
M(U E]DMJm?A@
E E]=?YE?^D?ATWEWLN@(
BDCF?YT S?YTVLF?YDCFM|LFUIADUWM(TWSAM

\^I2DM
C0JmTVIY\ÎÀÌÃÕ
 DM|\I2DM(CvLNU DM
±=ODM
+LNO+DLNUV@
TVM
EWMREWLN\^M4 DME]LF\^M
fLNO=DM

Á]Â

TV?YO=_YM
UISAM
TM(¡4B=LNDLFUVE]?YO2E7IYLFO2E]U"LNO®EWLN\^M4
	

CNIA_
IAJUWEWI4@pÈ
MDM
±=ODM

 "!
ÑRU.\^M
O2E]LFIYODM(X?Y7ISYM2PLFJ7EWDMRSAIYCF?YEWLNCFLNEHG"§.IABDCFX¦M|@
IYO=
UVE]?YO2EPwEWDM¥CFIY_®TVM
EWBDTWO=U?YTVM°LNOD=M
7M
ODDM(O2E]CFG4P LFDM
O2E]LF@
?ACNCFG4P
?YO=¥ODIYTV\^?YCFCNG+DLFUWEWTWLFDBDEWM
M"ÈYM
M(E]DM"\^M
?YOIAJE]DM(LNT
DLFUWEWTWLFDBDEWLNIAODU±D2M
¼?AE
P	DBDEE]TVM
?AE'EWDM©SAIYCF?YE]LFCFLNEHG?YU"?
TV?YODDIA\
S?ATWLF?YDCFMXLFE]UVM
CFJ]° DM©CFIY_¨IYJE]DM+SYIACN?AE]LFCNLFEHG?AE
LFUDM
O=IYE]M(2G
 DMCFIY_SYIACN?AE]LFCNLFEHG®JmIYCFCNI§ UX?\^M
?AO
TVM
SYM(TWEWLNO=_"Ñ|Ö"]ÁA	DTWI2@(M
UVU DM@(IY\^DCFM
E]M\^I2DM
CTWM(?YDU
/¤]ÁA
&('
)'
"%$
+*-,
43
ÔÏÁY
mÂv
+*-,
456870wDM
O=IYE]M(U|EWDM ?YBDUVUWLF?YO=TWIAD?YDLFCF
«HO¨EWDM'?A¦ISAM
LFEHG©DLFUWEWTWLFDBDEWLNIAO°§ LNEW\M(?YO95
?AOD°S<?ATWLF?YO=@
M:70ÑRCFC0DLFUW
E]B=TWD?AOD@
M(U;'
?ATWM'?YUVUWBD\^M(¨E]I+¦MLFODDM
7M
O=DM
O2E]CFG
DTV?§ O
M¼§ LNCFC@(IYODUVLN=M
TJm?Y@(E]IATWLF¯
M(UVBD2[]M(@
EWLNSAM®DTWLFIYTVU°IYJ^E]=M
JmIYTV\

"
0

ÔÏ

?AOD

"&

M21

8@BA8C"Aq
d<e?>
D5FEG7HE
>At"tJ>
D5FLG7HL
D5
G7

G@"K08C"KD

/

 DM|JmBDCNCv\^I2DM
C7LFUwDM(DLN@(E]M(©?YU.?DG2OD?A\LF@R?GAM
UVLN?AOO=M
E]
§ IYTVÈÀFÁNMcÃLNO>LF_YBDTVM+ÁY. DM'ODIYEW?YE]LFIYO=?YC0@(IYO2SYM(O4EWLNIAODUJmIAT
E]=MRS?YTVLNIABDUM(47IYO=M
O2E]LF?YCDJm?A\^LNCFLNM(U.?ATWM LFO2E]TVI2DBD@
M(XLNOXK=M
@

E]LFIYOPOv
 DM.LNO2E]M(TWM(UWELNULNOUV\^I2IYE]=M
7IYUVE]M
TVLFIYTVUQ
WP<§ LNEW
FW
Pw?YODLFOz¦IAUWEWM
TVLNIATWU^ISYM(T^E]DMCFIY_SYIACN?AE]LFCNLFEHG¼?AOD
[Z
DTVLNJmE"D?YTV?Y\^M(E]M
TVU
¥QROD
JmIYTVE]B=OD?YEWM
CFG4P?AULFO\IAUWE?GYM(UWLF?YO®LFODJmM
TVM
O=@
M°DTVIYDCFM
\^UP
E]=MTWM(¡4B=LNTVM
LNO2EWM
_YTV?YCFU@
?AODODIYE7MUWIACNSAM
+?YOD?ACNG2E]LF@
?ACNCFG4

]P	§ LFE]YX

VU
ò]\

SRT

VU

GX

RT

n



l

		

VU

Dm


ji

ÁoWÂ

BgU
8h

+k
+k

¹·Y»ª¸

8h
/
/

ß`_baß°¿¼¹

¹·A»ª¸ca¨ºÆ»da

x(ex
MÆ?YUVUVBD\^M®E]D?AE¥E]DM¥[]IYLFO2E¥ISYM(T¥?YCFC'S?YTVLF?YDCFM
ULFO³IYB=T
\^I2DM
C.Jm?Y@
EWIYTVLN¯(M
U?AU?¥DTVI2DBD@(EIYJJm?Y@(E]IATWUf
+>=IAT'E]=M
UVE]I2@pD?YUVE]LF@SYIACN?AE]LFCNLFEHGX\^I4=M
C0EWDLNUR¦M(@
IY\^M(UQ
8
§ LNEW
B

l
k

"
B
ji
Dm
Dm
ÁY0MDM(ODIYEWME]DM|DLFDDM
O©S<?ATWLF?Y=CNM(U
JmIYT
[]IALNO2E]CFG©?AUqh
LFOEWDMDIA\?ALNOIYJpf
 DMTVM
¡2BDLFTWM(©7IYUVE]M(TWLFIYTVU?YTVM=TWIA¦IATWEWLNIAOD?YCvE]I^EWDLNU[]IYLFO4E
sr
Gh
mÅv
BVU
§ M
	I=M
TVLNSAM?AOM
27M
@(E]?YEWLNIAO­=TWIAD?Y_A?YE]LFIYO?YCF_YIYTVLFE]D\
@pDI2IYUVM©?E]TV?Y@(E]?Y=CNM+?YDDTVI2LN\^?AE]LFOD_¨M(47IYO=M
O2E]LF?YC Jm?Y\^LFCNG
w>¦IYT|E]DMUVE]I2@pD?AUWEWLN@SAIYCF?YEWLNCFLNEHG\^I2DM
C§.MEW?YÈAM?JmBDCFCNG
Jm?Y@(E]IATWLF¯
M(¼?YD=TWI2LF\?AE]LFIYO®§ LFE]M
SYM(TWG\^?YTV_YLFOD?YC LFOÆE]=M
UV?Y\^MM
27IYODM(O4EWLN?ACcJm?Y\^LFCNG?YULNEWU@
IATWTVM
UV7IYODDLFOD_ DTVLNIATv«

M4
M
SAM
TVGXM
CFM
\^M
O2EquY8hv/v
ugAq

u

xOv
8ugE
uY8hv
Dw
§ LFE]yugAH
ugE
ugK
u
P?M
EW?7PcZRIYTV\^?YCHP= ?A\\^?vPZRIATW\^?AC
?YO=+Z|IYTV\?ACDLFUWEWTWLFDBDEWLNIAOTVM
UV7M
@
EWLNSAM
CFG4
 DMM
2?A@
E ¦IAUWEWM
TVLNIAT.LFOÔÅ7LNU?ADDTVI4LF\^?YEWM
2G?DTVI4=
BD@(E IYJ	?YDDTVI2LN\^?AE]MRJm?A@
EWIYTVU{z
s|}uY8hv

xMv
 DM"DTWI2DB=@
ELFU|TVM
UVE]TVLF@
E]M(°E]I©7M'LFO¥EWDM@pDIAUWM(O?YDDTVI2
LF\?AE]LFOD_¨Jm?A\^LNCFG~uYGh]KDLFOD@
M+E]DLFU^Jm?Y\^LNCFGLNUE]?AÈYM(O¼JmBDCFCNG
Jm?Y@(E]IATWLF¯
M(¼E]DM°LFODDLFS2LNDB=?YCE]M(TW\^U^@
?AOÆ7M§ TVLFE]E]M(OÆ§ LFE]D
IYB=ECNIAUWU'IYJ _YM(ODM
TV?YCFLFEHG¥?YU"?DTWI2DB=@
EIAJ EWM
TV\^U'ISYM(TE]=M
LFODDLFS4LFDBD?AC0S?YTVLN?ADCFM
ULNO°LFE]U=IY\^?YLFO%
D5

D5
+k
D5
Lv
Dm
"!
 DM+±DOD?YC?ACN_AIYTVLNEWD\
@(?YO¼7M©LFO2E]M(TWDTVM
EWM
¼?AU"?\^M
UVUW?A_YM
D?AUWUVLNO=_?ACN_AIYTVLNEWD\¥P4§.M§ LFCFCE]=M
TVM
JmIYTVMTWM(JmM
T EWIXE]DM5
D9
E]M(TW\^U ?AU E]DM\^M
UVUV?Y_YM(U_YIYLFOD_^IYB=E JmTVIY\¬Jm?Y@
EWIYTf
GXDM
±=ODLNEWLNIAO+EWDM?YD=TWI2LF\?AE]LFIYOXIAJ?\?ATW_ALNO=?YC7ISYM
Th0
E]DMDTVI2DBD@(EXIYJ?YCFCE]DM¨\M(UWUV?Y_AM
U^JmTVIY\
Jm?A@
EWIYTVU
LFUODI§
@
IA\^LNOD_^LFO2E]IPh

UV?YE]LFUV±DM
U
Gu
8ugK=

ji

l

"

Gh

BVU

Gh

D

D
D

D
D5

Gh

D
D

Gh

Dw

Gh

_7

	
uY

D

Dw

446â
ã
ä
å
å
å
å
å
å
å
å
å
æ
ç
è
è
è
è
è
è
è
è
è
è
è
è
è
è
è
è
è
é
ê
ë
ë
ë
ë
ë
ë
ë
ë
ë
ë
ë
ë
ë
ë
ë
ë
ë
ë
ë
ë
ë
ë
ë
ë
ë
ì
í
î
ã
ä
ï
ï
ï
ï
ï
ï
ï
ï
ï
ï
ð
ñ
è
è
è
è
è
è
è
è
è
è
è
è
è
è
è
è
ò
ó
ô
ó
ô
õ
ö
÷
ø
ù
ù
ù
ù
ù
ù
ù
ù
ù
ù
ù
ù
ù
ù
ù
ù
ú
û
ü
ý
ý
ý
ý
ý
ý
ý
ý
ý
ý
ý
ý
ý
ý
ý
ý
þ
ÿ
 
 
 
 
 
 
 
 
 
 
í
î


í
î


í
î











#
ò




â

ì
ì

ú
.



&
ò

3

,

3

<

â


=
<

ì


,

<

ú


I
<

ò


,
<



,
1
!
1
!


<




<

â

ì

ú

^
x

<

â

ì

ú

ò






f


f


<

â

<

ì

<

ú

<

ò

<

<

R

ò

<

R

ò
<

R

â

ì

ú
f


<



R



ò
<


R

â

ì

ú


$



<
R

f




t
t

â

ì
ú
L

ò



u


L

f


<
R



.


z
f




z
f


5
A

â
E

ì
K

ú
5
ò
1




1









â



.


5
A

â


		







>LN_ABDTVMwÂ DMwJm?A@
E]IAT_ATW?AD@
IATWTVM
UV7IYODDLFOD_ EWIRE]=M.@pDIALN@(M
IYJ.Jm?Y@(E]IYTVUJmIYTE]=MUVE]I2@pD?AUWEWLN@SYIACN?AE]LFCNLFEHG\^I2DM
CHK=D?YDM(
UV¡4B=?YTVM
UTWM(DTVM
UVM
O2E.Jm?A@
EWIYTVU

"

>LN_ABDTVMÂ_YLFSYM(UR?Jm?A@
EWIYTR_ATW?ADÆÀ
ËcÃLFO2E]M(TWDTVM
EW?YEWLNIAOIYJE]=M
@pDIAUWM(O+?ADDTVI4LF\^?YEWLNIAO
	I±DO=?AOÆ?ADDTVI4LF\^?YEWLNIAO¼LNOE]=MJm?Y\^LNCFGYuY8hv|E]=?YE^LNU
@
CFIYUVME]IE]=M M
2?Y@(E	7IYUVE]M(TWLFIYTÔÅ77wDTVI2@
M(M
DU?YUJmIACNCFI§ Uo
ÁY.«HODLFE]LF?YCFLF¯
M^E]DMX?ADDTVI2LN\^?YEWM"Jm?A@
EWIYTVU-z
m?AOD=M
OD@(M
EWDMIYBDEW_YIALNOD_\^M
UVUW?A_YM(UW
Â7	IA\=BDE]ME]=MLFODLFE]LF?YC0?ADDTVI2LN\^?YEWLNIAOuYGhJmTWIA\E]=M
DTVI2DBD@(E IYJEWDM?Y=DTWI2LF\^?YE]LFOD_Jm?Y@(E]IYTVUo

Dw

8h

uY8hv

mÐv
Í|M
TVMw§ M?YUVUWB=\M.§ LNEWDIYB=ECFIYUVUIYJq_AM
ODM(TW?ACNLFEHGREWD?YE	E]=M
?YTVMLFODLFE]LF?YCFLN¯(M
UVBD@pXE]=?YEwEWDMRLFODLFE]LF?YC7?YD=TWI2LF\?A
EWLNIAO®ÔÐ7LFUODIYTV\^?YCFLN¯(M

@
IAO2SYM
TV_YM
Å7.Q|O4EWLNC?YCFCJz

m?v`	=I4IAUWM?z
m	'ÖRM
\^ISYMz
2G=LNS2LFUWLFIYO%

Gh

EWIXTWM(±DODM4
JmTVIY\EWDM?YD=TWI2LF\?AE]LFIYO{uYGh
8h
2§ LFE]EWDMM(4?A@
E0Jm?A@
EWIYT]f

uYGh
8h

uN

Gh



m@2`	IA\'DLFODMnu

Gh

Gu

Gh

Gh
Gh
Gh
DLFUO=IYE	LNO"@pDIYUVM
OJm?A\LFCFG
uY8h
RDR

GHh
?ATW_A\LFO

0¡ 

µ©

 =M'ODIATW\^?YCFLF¯
LFOD_X@
IAODUWEW?YO2ELFURDM(±DODM(¥?YU;

m	'K=LNOD@(M

P<DTVI[]M(@
EQ
A
V
mM2'«HO=JmM
T¢E]=MODM
§Û?YDDTVI2LN\^?AE]LFOD_¤Jm?A@
EWIYTm?AOD

Gh

Gh
Gu
Gh
uN
G.Gh

=M
OD@(M\M(UWUV?Y_AM
U02G=LNS2LFUWLFIYO%
Gh

G
8h

f¢
G

Gh

O7.Q|UWM¥EWDMODIATW\^?YCFLF¯
LFOD_®@
IAODUWEW?YO2E^IYJ£uYGh?AU?YOª?Y=
DTVI2LN\^?AE]LFIYO©IAJ

gU
"VU

V
s|

Dw

·YÜ Ý

 DLFUR?ACN_AIYTVLNEWD\¤LFUR@(CNIAUWM(CNGTVM
CF?YE]M(E]ICFI2IY2G¦M(CNLFM
JDTVIY=
?Y_A?YEWLNIAOÀFÁpÅcÃHl¤AB=UWE?YUJmIAT CNI2IY2GX7M
CFLNM(J=TWIAD?Y_A?YE]LFIYO©@
IYO=
SYM(TW_AM
OD@(M|LFU ODIAE _YBD?ATW?AO4EWM
M(
Ü§¦

ß`_ba»ª¸­ß°¸¹·
»ª½²ß°Ü'Ø
 DM?Y=DTWI2LF\^?YE]LFOD_Jm?Y\^LFCNG
LFU TVM
UVE]TVLN@(E]M
E]I^7MLNO°E]=M
M
27IYODM(O2E]LF?YCJm?Y\^LFCNG2 DM"M(2¦IAODM
O2E]LF?YCJm?A\LFCFGD?YUUVIY\^M
DCFM
?AUW?AO4E©DTWIA¦M(TWEWLNM(UQ?AOzM
2¦IAODM
O2EWLN?AC|Jm?A\LFCFGLFU@
CFIYUVM

BDOD=M
TDTVI2DBD@
E?AOD"=LNS2LFUWLFIYOP?YODE]DM\^LFODLN\"BD\%IAJ	VY¦LNU
Gh]
DM(E]M
TV\^LNO=M
°2G©?^±DODLFE]MO2BD\"¦M(TIYJ	UWEW?YEWLNUVE]LF@
U JmTVIY\
«HOEWDLNUUVM
@(E]LFIYO§ MRLFO2E]TVI4=BD@
M|IYBDT.ODIYEW?YE]LFIYO©JmIYT M
2¦IAODM
O=
E]LF?YCJm?A\LFCFG\I2DM(CNU?AOD¨_ALNSAM'E]=M=?YUVLN@"TWM(UWBDCFE]UEWD?YE?YTVM
TVM
¡2BDLFTWM(+LFO+EWDMTVM
UVE IYJEWDME]M(2E<
w27IYODM(O2E]LF?YCJm?Y\^LFCNG©\I2DM(CNUR@
?YO7MTWM(DTWM(UWM(O2E]M
+?YU

MQ¨S©«ª¬ ­S®

mËv
M UW?GEWD?YE?@
CF?YUVUl°³IYJ7\^I4=M
CFULNU?AO"M(47IYO=M
O2E]LF?YCqJm?A\
ÔË7]
LFCNG¥LFJ ?YCFCLNEWU\^M
\'7M
TVU@
?AO7MX§ TVLNEWE]M
OLFOEWDMXJmIYTV\
MTWM(JmM
TEWIXX?YU'E]DMSAM
@(E]IYTIAJOD?YEWBDTW?ACD?ATW?A\M(E]M(TWUIAT
@
?AODIYO=LN@(?YCcD?ATW?A\^M
E]M(TWUP
E]Ip±w
2?AUEWDMwSAM
@
EWIYT0IAJqUWB=É@(LNM(O2E
UVE]?YEWLNUVE]LF@
UP(?YOD'E]I³²0GX4D?AUEWDMwCFIY_=?YTVE]LFE]LFIYOJmBDOD@(E]LFIYOM
?YUVUVBD\^ME]D?AEE]=M©Jm?Y\^LFCNGLFU'TVM
DTVM
UVM
O2EWM
\^LNODLF\^?YCFCNG2P	LÕ
M4
E]=?YE©O=I¼M
CFM
\^M
O2EWU©IYJ±w
?ATWM¨CNLFODM
?AT©@(IY\'=LNOD?AE]LFIYODU©IYJ
IYEWDM
TVUw>¦TWIA\¤EWDM'M(2¦IAODM
O2E]LF?YCJmIYTV\¤LFOÆmËv§ MLF\\^M(DLN
?YEWM
CFG°UWM(M'E]=?YEE]DM"Jm?Y\^LNCFGLFU|@(CNIAUWM(¥BDODDM(T|=TWI2DBD@(ER?AOD
DLFS2LNUVLNIAO
M(2¦M(@
E]M($S?YCFBDM
U
IYJE]=M9UVBDÉ^@
LFM
O2EUVE]?YEWLNUVE]LF@
U
 DM
µ?¶
±w
Pv§ LFCNC7M^LN\^7IYTVE]?AO4ELFOIABDTJmBDTVE]DM(TDM
UV@
TVLN=
¨V®
¬ ­·
E]LFIYO¤IYJ¥M(2¦IAODM
O2E]LF?YCJm?Y\^LFCNG\^I2DM(CNU
MÒ§ LFCNC°TVM
JmM(T
?AU
E]IÆE]DM(\
§ LNEW
n>Aesoqg>Yr
PEWDM¹¸
W0 =MUWIAs@(?YCFCNM('CFLNO=È4
sEW^\IA\^M
O2EIYJ
¨V®
¬ ­·
JmBDOD@(E]LFIYOº
\?ADU¥@(?YODIAODLN@(?YCD?ATW?A\M(E]M(TWU°E]IzO=?YE]B=TW?AC
\^IY\^M
O2EWU
ºGXA/i

\^IY\^M
O2E]U+E]I¼@(IYO2E]TV?YUVEXE]=M
\

±w

¬ ¨V®

.«¯

X4

¨V®
?ACNUVIÒ¦MzDM(TWLFSYM(

XAG
?AUE]DMz±DTVUVE

¬ ­·

±w
µ
 DMzCFLNO=È³JmBDOD@(E]LFIYOÇ@
?AO
»AÃ
DM(TWLFS?YE]LFSYMIAJ+²0GXARÀ
²0GXA

ºGXA
DTVI[]M(@
E]LFIYOUWEWM
¢A
µÒ\^LNODLF\^LN¯(?YEWLNIAOLFOEWDMw
 DM
»AÃÕ
7IYLFCNU|DI§ O°E]IX?X\^?YEW@pDLNO=_XIYJE]DM'OD?YEWBDTW?AC0\^IY\^M
O2EWU"À
8µoÀ
8h
P§ LFE]¿
M2½
M4]u
	G
©ª¬ ¾
]P
«

¬Á¾
E]=?YE \^?YEW@pDM
UEWDMOD?AE]BDTV?YC0\^IA
LFUE]DM'DLNUVE]TVLFDBDE]LFIYO°LFO
Gh
]
\^M
O2E]URIYJEWDMDLFUWEWTWLFDBDEWLNIAO

±wGh

447â




















































ì




































ò




































ú























































f










f




















f

.










.

f



.


z
f




z
f

f

f

f








z
f









z
<



f










i
f







z
<

t



z
<




z




u


u





<



<



.





¥
x
x
Þ
Þ
t
z
<
<


R




´



¶
<



´

¶



<


R


¼
¼
X


 




®

º
.


´

¶

®
t
z
<

e­x

¾²ØRØ|·

¸ÄÃª¾

½²º

¹¾²ºªß

8

A;Æ

		

GÇ

GÌ:Ë?ATWM@pDIAUWM(O+UVBD@pE]D?AE

 ?YB=UWUVLN?AO%¡2BD?ADTW?AE]BDTVMLNU®?Ò_YM(ODM
TV?YCE]M(@pDODLF¡2BDMzE]IÒ?Y=
P4§ DM
TVM
DTVI2LN\^?YEWM LNO2EWM
_YTV?YCFUIAJE]DM|JmIYTV\
Ç
wLNU?È2ODI§ O¥ODIAODsO=M
_Y?AE]LFSYMJmB=OD@
EWLNIAO«HO¨EWDMLNODJmM(TW
M
O=@
MR?ACN_AIYTVLNEWD\^UÈÇ
0§ LNCFCv¦M|?ÔODIYTV\^?YCFLN¯(M
0M
2¦IAODM
O=
E]LF?YCJm?Y\^LFCNGDLFUWEWTWLFDBDEWLNIAOPqODIAEODM(@
M
UVUV?YTVLNCFG ?YB=UWUVLN?AOÔE]DM
\^M
EWDI2LFUDB=MXE]I¼ ?YBDUVUP§ DLF@pM(2DCN?ALNO=UE]DMXO=?Y\^M^IYJ
E]=M¡4B=?YDTV?YEWBDTWMDTVI2@
M
=BDTWM2]
WP
É+7IYLFO2E]UpÊ
?YUVM
IAOÇ

Ê/Ë?AODqÉ+@(IYTVTWM(UW7IYO=D
LFOD_^§.M(LN_A4EWU¢Ì
		
Ç
LNU ?'7IYCFG2ODIY\^LF?YC=IAJ0DM(_YTVM
M?AEw\^IYUVEwÂÉ
LFU.M(4?A@
E.LNJ
 M
O=M
TV?YCDTWI2@(M
DBDTVM
U+E]IDM
EWM
TV\^LNODMdÊ/'?AOD~Ì:"?YTVM
ÁY
D?AUWM(IAOUVM
EWUIYJ+Éz¦IACNG2ODIA\LF?YCFU§ DLF@p?YTVMIATWEWDIY_AIYOD?AC
_70ÀFÁÎkÃJmIYT?AO
E<Ç
§'
T
LFO4EWTWI2DB=@
E]LFIYOE]I¨ ?ABDUVUWLF?YO+¡4B=?YDTV?YEWBDTWM2
	I?YDDTVI2LN\^?AE]M\'BDCFE]LFs=LN\^M
O=UWLFIYOD?ACLFO4EWM
_ATW?ACNUISYM(TJm?Y@(
E]IATWLFOD_§ M
LF_Y2EXJmBDOD@(E]LFIYODUP._YTVLNDUX@(?YOª7MBDUWM(z =MCNIA
@
?AE]LFIYOIYJEWDM"_ATWLF¨7IYLFO2E]U@
?AO¨7M"=M
E]M(TW\^LFODM
JmTVIY\ÓE]=M
7IYUVLNEWLNIAOzIYJE]DM¨¦IALNO2E]UDM(E]M
TV\^LNO=M
zJmIYT©E]DMLNOD=LNS2LFDBD?YC
\^?YTV_YLFOD?YC§ M
LF_Y2E©JmBDO=@
E]LFIYO=UÇ =M§ M
LF_Y2E]U?YTVM¨UVLF\=CNG
\'B=CNEWLNDCFLFM
%

?YO=E]DMLFO2E]M(TWS?YC À

	Í]ÃÕwKDM
M'M4

Ê

8

DÌ

8Ç

GÇ

G

Ê
ÌÈ

8Ç
8Ê/8Ò]V

G

 DTVIYBD_ADIYB=E0E]DLFU	D?Y7M
T	§.Mw§ LNCFCA?AUWUVBD\^MwEWD?YEM
CFM
\^M
O2EWULFO
Jm?Y@(E]IYTVLF¯
MR?AUDTWI2DB=@
E]UIAJ0BDODLFS?YTVLN?AE]MR\^?ATW_ALNOD?ACNUà¥IYTVM
?Y=S<?AOD@
M(¥TVBDCNM(U|=M
TVLNSAM
¥DLFTVM
@
EWCNGJmTVIY\EWDM"M(2?Y@
EWODM
UVUIYJ
LFO4EWM
_ATW?ACNUISYM(T.\"BDCFE]LFODIY\^LF?YCFU JmIYTV\?YOLNO2E]M(TWM(UWEWLNO=_"M(4EWM
OD
UVLNIAO

½²º

Ã¾

¹¾ºß

ßPa
	]P§ M@
?YOLFDM
OD
«HJ7§.M@
IA\'DLFODME]=M .UWEWM
DURÔÅ7
¦E]I©mÅv
E]LFJmG¥?_YM(ODM
TV?YC	§.?GIAJBDUVLNO=_ ?ABDUWUVLF?YO¨¡2BD?ADTV?YE]B=TWM"?YU?
O2BD\^M
TVLN@(?YC DTVI[]M(@
EWLNIAO\^M
EWDI2Ô	IA\'DLFODLFOD_E]DMUVE]M(DUP
?YOBD7D?YEWMJmTWIA\§u|E]I
x»v
Gh
§ LFE]
0?AUwE]=M
§ M
LF_Y2E"JmB=OD@
EWLNIAOP§ M°@
?AOÆ?Y=DTWI2LF\^?YE]ME]=MO=IYTV\?ACNLF¯
?A
E]LFIYOª@(IYODUVE]?AO4EBDUVLNO=_z ?ABDUVUWLF?YO¡2BD?YDTV?YEWBDTVM4ÆKDLNO=@
ME]=M

Gh
8h
«HJ§ MRLFDM
O2E]LFJmGPuYGh

LNURDM
±DO=M
°?YUo
uYGh

si
uYGh

GHh

s

¬ ¾
¬ ¾

§ M
LF_Y2E.JmB=OD@
EWLNIAOLFU 2GX@
IAODUWEWTWB=@
E]LFIYO+?^ODIYTV\^?YCFLN¯(M
©M(2¦IA
ODM(O4EWLN?AC Jm?Y\^LFCNGDLNUVE]TVLFDBDE]LFIYO	P§ M@
?AO\^?YÈAM°BDUWM°IAJ|EWDLNU
Jm?Y@(E LNO°DM(TWLFS2LNO=_"EWDM¡2BD?YDTV?YEWBDTVM|TVBDCFM
U
Gh@(?YO¥O=I§¢¦M?YD=TWI2LF\?AE]M(2G
«HO2E]M(_YTV?YCFURLFO4SAIYCFS2LNOD_
TVM
§ M
LF_Y2E]M(zJmBDOD@
EWLNIAOM(S<?ACNB=?YE]LFIYO=U%IDTVI[]M(@
E
D?Y@pÈ
IYO2EWIE]DM@pDIAUWM(OJm?Y\^LNCFG4P¦§ M'±DTVUVER?Y=DTWI2LF\^?YE]MEWDM'O=?YE]
8µQÀ
¶ªBDUVLNO=_EWDMzTVM
§ M
LF_Y2E]M(%7IYLFO4EWU
±w
BDTV?YCX\^IY\^M(O4EWU
 DM(OP(E]DM.LNO2SYM(TWUVMIYJ2EWDMCFLNODÈJmBDO=@
E]LFIYO'LNUBDUWM(E]I±=ODE]=M
D?ATW?A\M(E]M(TWUIYJ]u
	G
_YLFSYM(O+EWDM?Y=DTWI2LF\^?YE]M\^IY\^M
O2EWU
KDBD\^\^?YTVLF¯
LFOD_7P¦¡2BD?Y=TW?AE]BDTVM'.BD7D?YEWM
U?YO?YD=TWI2LF\?A
E]LFIYO°IAJJm?Y@(E]IATf
?YU JmIACNCFI§ UQ
ÁY	IA\=BDE]M+§.M(LN_A4EWUÌ:?AOD®7IYLFO4EWU9Ê/RJmIYTEWDMÔJm?Y@

EWIYTVLN¯(M
IYCF°¦IAUWEWM
TVLNIATuYGh
Â7.ÖM(§.M(LN_A2E M(SYM(TWGX7IYLFO2E2

W

ÌÈ

Öl× ®
Öl× ®
ÖØÙ®
ÖØÙ®

OD?AE]BDTV?YC\^IY\^M
O2E]U

WÁpÏv

BDUVLNO=_£E]=M

Ì:

Å7.Ñ|DDTVI4LF\^?YEWME]DM
TVM
§ M
LF_Y2E]M(©7IYLFO2E]U
±wGh

8µQÀ
¶|

±w8Ê

O7. DMD?ATW?A\M(E]M(TWU+JmIYTE]DMODM
§Ó?ADDTVI2LN\^?YEWLNIAOz?YTVM
JmIABDOD°2GLNO2SAM
TVE]LFOD_^E]DMCFLNO=ÈJmBDOD@(E]LFIYO%
§ LFE]	P
Ì:4±w8Ê/W]

MQÚ
©


G

ª¬ ¾

®N

Gh

Û


M7.«HODJmM(TODM(§\^M
UVUW?A_YM(U 2G=LNS2LFUWLFIYO

f¢	G

Gh

	G

Gh
Gh

Gh

	G
uYGh

Gh

¤4BDUWE?AUJmIYT.LFE]UVM
CFJ]PYE]DM LFE]M(TW?AE]LFSYMTWM(±DODM(\M(O2E	IAJ¦Jm?A@
EWIYTVU
LFU ODIYE _ABD?YTV?YO2E]M(M
+E]I^@
IAO4SAM
TV_YM2
 DM(TWMXLFU?¥UVE]TVIYOD_°TVM
UVM
\"DCN?AOD@
M^7M
EH§ M
M(O®E]DM?A¦ISAM^?YCF
OYÃH]
_YIATWLFE]=\?YOD+D?YTVE]LF@
CFM|±=CNEWM
TVLNOD_?YCF_YIATWLFE]=\UmUVM
MM2
_v7À
¤4BDUWE'?YU'LFO®E]=M©D?ATWEWLN@(CNM±=CNEWM
TVLNOD_¨?YCF_YIYTVLFE]D\¥P¦IALNO2E]U"?YTVM
BDUVM
EH§ LN@(MHIYO=@
ME]I^?Y=DTWI2LF\^?YE]M|?"O=IYTV\?ACNLF¯
?AE]LFIYO+@
IYO=
UVE]?YO2E0?AODIYO=@
MEWI?YD=TWI2LF\?AE]M?7IYUVE]M(TWLFIYT0=LNUVE]TVLN=BDE]LFIYO
D?YU|LNEWUR@
M(O2E]M
T|IYJ\^?YUVURLFO¥?SAM
TVG©DLDÜ¦M(TWM(O2E
ÑRCFUVI7P=LNJpu
?YTVM
? JmTVIY\ÝuYP(IYODCFG?JmM
§®7IYLFO2E]U]Ê
§ LNCFCA_AM
E0O=IYODfODM
_ACNLF_YLFDCFM
§ M
LF_Y2E<.ÑRU|?TVM
UVBDCNE EWDM'?ADDTVI2LN\^?YEWLNIAO+IAJ¹u
LFURSYM(TWG
7I4IATM¥@(IY\^D?YTVM¥EWDM¥?YCF_YIATWLFE]=\
LFOz\^IYTVM¥DM
EW?YLFCREWI
D?ATWEWLN@(CNM±DCFE]M(TWLFOD_^?YOD°IAE]DM(T ?YDDTVIY?A@pDM
U LFOK=M
@
EWLNIAOP»7


G

	G

448Â
x
x
x
Å











Å
A


Æ



|
Ë

w

Æ



Æ


$

â
Å
A
Ï
Ð
Æ




1


­





|
Å
A

Ì

Æ



­



|
Ñ

Ì
Ñ
Æ

t
Ó
x
x
z
<
z
<

f





z
f





i
Õ


®
À
Õ


®



z
<
z
<
´



z

Õ

¬
À
Õ

¬
Ñ
Ì
Ñ
Õ

¬
À
Õ

¬

´


z
Ì




u






º
.



z

z




u


u





u




z
f





·Y¸

5'8

¹ß
»ª½²ß°Ü
å9è9éêéëíì

aFa¨ºÆ»_z·
ØRÚ
¹Ùß
ä9å9æ9ç9è9æ
ç`é:ò

·Y¸ß¦Xß°ºß°¸¿¼ß
éïî%ð
àáãâ
 DM|UW7M
@(LN±D@|¡2BD?YDTV?YEWBDTVMw¼?ACN_AIYTVLNEWD\
JmIYT E]DMUWEWI2@pD?YUV
E]LF@ªSYIACN?AE]LFCNLFEHG¢\^I4=M
CXIYO=CNG¢DM(¦M(ODDU®IAO%IYB=T@p=IYLF@
MIYJ
E]=M®?YDDTVI2LN\^?AE]LFOD_ÆJm?A\LFCFG
¬M®§ LFCNC?AUWUVBD\^ME]D?AE
M
CFM
\^M(O4EWULFO
Jm?A@
E]IATWLF¯
MÆ?YU?­DTVI2DBD@(E¨IYJ©BDODLFS<?ATWLF?YEWM
\^?YTV_YLFOD?YCFU0>¦IYTE]DMUVE]I2@pD?AUWEWLN@SYIACN?AE]LFCNLFEHGX\^I4=M
CHP
@
IYO=
UVLNUVE]U IAJ?ACNCM(CNM(\M(O2E]UIAJE]=MJmIYTV\
	I@
IY\^DCFM
EWME]=M_YM(ODM
TV?YC=M
UV@
TVLNDEWLNIAOIYJKDM
@(E]LFIYOÐ7P§ M
ODM(M
zE]IÆDM
±DO=M¨DI§
E]DM¦IALNO2EWU©?YO=z§.M(LN_A4EWU?YTVM@pDIA
UVM
OJmIAT:uY8hvWP4?YOD=I§zODM
§zD?ATW?A\^M
E]M(TWU.?YTVMJmIYB=OD©_ALNSAM
O
?Y=DTWI2LF\^?YE]M\^IY\^M
O2EWU
>=IAT^E]DM¼ ?YB=UWUVLN?AOÆ@(IY\^¦IAODM
O2EWU`uSEH
]PwE]=M
7IYLFO4EWU©?AODz§.M(LN_A2E]U@(?YOz7M¨DM(E]M
TV\^LNO=M
zBDUVLNO=_­ ?YBDUVUV
_v0ÀFÁÎkÃJmIAT ?XDM
UV@
TVLN=E]LFIYO
ÍRM(TW\^LFE]M7IYCFG2ODIY\^LF?YCFUKDM(MM2
KDLFOD@
M

xOv]

8	u

G	u

"

7÷&P5
JmIYT

5ôG7G
@(?YO£=M
E]M(TW\^LFODM
5ôG7§ LFE]95ùø

Ï«<ÁY8
WÁYÁA
Ï«<ÁA]P?AOD
§ M
E]TV?YO=UWJmIATW\
E]DM(UWM§ DM
O³§ M¼M(OD@
IABDO2E]M
T?YO¢LFO2E]M
_ATW?AC'JmIAT
«HO¨M(2¦IAODM
O2E]LF?YC	JmIYTV\§.M"§ TWLFE]ME]=M'ODIATW\^?YC	DLFUWEWTWLFDBDEWLNIAO
?YU

öõ
¦IALNO2E]UÒIAOD@
M
Ï^IYT¢7ôø
ÁY

"ûýüG«þÿ 
 
¬Á¨
.«¯

5ôG7

X

¨N©

Âú"7
ª
hi

i

]§ LFE]

±'
8X

CNIA_

GX

 DMCFLNO=ÈJmBDOD@(E]LFIYOLFU
8X
X


§ DLF@p°§.M@
?AO+LFO2SYM(TWE?YO=?YCFG4EWLN@(?YCFCNG
1

±'4±µV

1

O






1

QRO=JmIYTVE]BDOD?AE]M(CNG2P4E]DM(TWMLFU ODI"TVM
UVBDCFE?YOD?ACNIA_YIYB=UwE]I¥WÁYÁYJmIAT
E]=MRM
EW?'?YO= ?Y\^\^?'DLFUVE]TVLNDB=E]LFIYODU0M@
?YO	PcDI§ M
SAM
TP
TVM
§ TVLNEWM|LFO2E]M
_ATW?ACNU LFO4SAIYCFS2LNOD_M
EW?"?AOD ?A\^\?DLFUWEWTWLFDBD
E]LFIYO=U|?AU|LFO2E]M
_ATW?ACNU|ISYM(TUWIA\^M'§ M
CFCNfUWEWBDDLFM
¥§ M
LF_Y2E|JmBDOD@

E]LFIYO=U

M§ TWLFE]ME]=M M(E]?XDLFUVE]TVLNDB=E]LFIYO?YU
G@P&PC
8@
DC 
¨N©
.«¯

@%8C

d<eÙ>



¬Á¨



WÁ

$y
]§ LFE]

X

±
GX

8@`&yC
8@
4C
8@%8C
8@%8C

CFIY_
CNIA_vWÁ
$y
8@
4C
G@y&PC 

CNIA_

$

]Á
&Á

ÑRO2GLFO2E]M(_YTV?YC4§ LNEW?M
EW?§ M
LF_Y2E	JmBDOD@(E]LFIYO@
?YO7M EWTW?AODUV
JmIYTV\^M
E]IX?¥ ?YB=UWUV?¤4?Y@(IYDL7JmIYTV\¬?AU JmIYCFCNI§ U



WÁ

 

$y

"!V"!$#

WÁp&
]¤4BDUVE?YUJmIATE]=M+ ?YBDUVUV
§ LFE]
ÍRM(TW\^LFE]M@
?AUWM2PEWDM@
I2M
É^@
LFM
O2EWU"IAJE]DM7IYCFG4O=IY\^LN?ACNU"?YTVM
È2ODI§ OXJmBDOD@(E]LFIYODU IYJEWDMR=?YTV?Y\^M
EWM
TVULNO©E]DM|§.M(LN_A4EwJmBDOD@

E]LFIYO	P?YODÆSYM
TVG_YI2I2¼?Y=DTWI2LF\^?YE]LFIYO=UIYJEWDMTWI2IYEWU"M(2
LFUWE'ÀFÁÎkÃH
 DMCFLNO=ÈJmBDOD@(E]LFIYOLFU _YLFSYM
O2G

²%|8X|
X

G@
DC 

8@`&yC
G@P&PC 
]P¬LNU£E]DM=LN_A?Y\^\^?

mLFO

Jm?Y@(E<P%DM
7M
O=DLNO=_

¡i
JmBDOD@

§ DM(TWM
E]LFIYO	
 DM(TWMM(2LNUVE]U³O=IÓ?YOD?ACNG2E]LF@
?AC®LNO2SAM
TVUWMÇIYJªEWDLNU
JmBDO=@
E]LFIYO
IYO9DM
±DO=LNEWLNIAODUP
CFLNODÈ
JmBDOD@(E]LFIYOLFE]UVM
CFJLFUODIAE¼?YO=?YCFG4EWLN@DBDM²EWI%E]=M
E]=MCFLNODÈ
DLF_Y?A\\^?JmB=OD@
EWLNIAO]|à¥LFODLF\LF¯
LFOD_E]DM"UW¡2BD?ATWM(DLFUWEW?YOD@(M
E<X
º(8X
±
_YLFSYM(U?XO4B=\M(TWLF@
?ACvLNO2SYM(TWUVM4
 DM© ?A\\^?^DLFUWEWTWLFDBDEWLNIAO°LNU _ALNSAM
O4G

º(RGX

±

8µoÀ

µQÀ

§'

T

GX

>Ytt;>

@%8C

X*

8@
M2¨N©

Î1
¬ ¨

.«¯

®NW§ LNEW

CNIA_

CNIA_

8@

GX

@(?YO

M
µ?A_YBDM(TWTVMJmIYTV\2GODIYEWLNO=_EWD?YE

TWM(§ TWLFE]M´ ?Y\^\^?ÎLNO2E]M(_YTV?YCFUÇLNO2E]I

 ?YBDUVUV



G@

1

8@

­H

449Þ
x
Þ
x
Þ
5
)
è
ñ
)
t
t
t
ì
L

ò


ó
.
ó
Æ



,


R


ó
.
ó
Æ
,


R


,


R
,


R


,


R

Á
õ
M

M

¬
1
®


®
i
	
$


	






²




Á
Â
$
ú


$
h


º




¼
²



¼

$
¾
$

$
¾
 



º
.



´



1
 

.

 
.




1
 

.

 



=


R




.

.


M

ª

¬
1
®


®
i
@
$
Á
C
$
Á





²










Æ








.



.






.

Æ

Â



.

.







¬

m

®
#
¬

®
#
¬

®
º




¼
¼

&
$
&
&
$
&


&


'
'
1



$
´

¶

$
´

¶
I


R

C




.

M
.

)
ª
)
¬
1
®
)
)
i
$
C
@
$
Á
±
*






²
*
*



C


?
ó

Æ



C


.

M
.



Á

ó

Æ

C


.

M
.

 DMCFLNO=ÈJmBDOD@(E]LFIYOLFU

GX

²%*8X*
X*

è9î

	G

G
u

Dm

CNIA_sC

D?YUVU

æì-,

ë+æîlî

è/.ßæè9ç

Å_YLFSYM
U TVM
UVBDCFE]U IAJM
27M
TVLN\^M(O4EWU

G@
zDLF@p°?YCFUWID?YU O=IX?YOD?ACNG2E]LF@LNO2SAM
TVUWM2
 DM(TWMLFU ?=G4O=?Y\^LN@(?YC?AUW7M
@(E LNOE]DM\^I2DM(CÕP2UVI^LNE UVM
M(\^U
\^IYUVECNIA_YLF@
?YCqEWIBD¦=?YE]M EWDM ?Y=DTWI2LF\^?YE]M Jm?Y@(E]IATWU9z
LFO?
JmIYTV§ ?YTVDs=?Y@pÈ2§.?ATWJm?YUVDLFIYO DM^ODM
2EUVM
@
EWLNIAO¨DTVM
UVM
O2EWU
?¨B=UWM(JmBDC.LFODLFE]LF?YCFLN¯(?YEWLNIAO¼IYJEWDM©?ADDTVI2LN\^?YEWLNIAO~uYGh?AOD
IYJvEWDMR\^M
UVUV?Y_YM(U DLFUw@(IY\^DCFM
E]M(UwEWDMRDM(UW@(TWLFDEWLNIAOXIYJE]=M
¡2BD?Y=TW?AE]BDTVM".­?ACN_AIYTVLNEWD\ÓJmIYTEWDMXUWEWI2@pD?YUVE]LF@"SAIYCF?YEWLNCFLNEHG
\^I2DM
CH	KDM
@(E]LFIYOY
àá+
«HO®DTVLNO=@
LFDCNM2P\?AO2G¨LFODLNEWLN?ACNLF¯
?AE]LFIYODU'IYJuYGh?YO=
§ LFCNC
DIvÑ|CNEWDIYBD_AP?AU\M(O2E]LFIYODM(LFOKDM
@(E]LFIYOÐ§ M^§.?AO2E|EWI
E]?AÈYM^@
?ATWM^EWD?YE÷uY8hv10
D?AU\^?YUVU32v§ =M
TVM
SYM(T£u
8hv=?YU
	G
Ê E]=M
TV§ LNUVM
P=?YO==M
OD@(MLNEWU|UVBDÉ^@
LFM
O2EUVE]?AE]LFUWEWLN@(UPD?YTVM
uY8hvW
7I4IATWCFG?ADDTVI4LF\^?YEWM
©2G7IYLFO2E]U@(IY\^DBDEWM
°JmTVIY\
M@(?YO³LFODLFE]LF?YCFLN¯(MuY8hv+DG2OD?A\LF@
?ACNCFG4G¢@(IYODUVE]TVBD@(E]LFOD_
uYGh
DB=TWLFOD_¢E]=M±DTVUWEÆJmIYTV§.?ATW
M²LFODLFE]LF?YCFLN¯(M
G
ugK=
G	uSE
ugAq
WP?AOD
°§ LFE]EWDM=TWLFIYTVU
JmTVIY\9EWDM®\^I2DM
CHÓÑ|CNC"\M(UWUV?Y_AM
U°?YTVM®LFODLNEWLN?ACNLF¯
M(Ò?YUÆÁY
?YTVMLNO=LNEWLN?ACNLF¯
M(¥2G+DTV?§ LFOD_
 DM"@
IYO=UWM(@
BDEWLNSAM
Dm
uY
7IYLFO4EWUJmTVIY\
D?YODDTVIY=?Y_Y?AE]LFOD_E]DM(UWM.E]DTVIYB=_Y
"
E]=M=M
E]M(TW\^LFODLFUWEWLN@zD?ATWEIYJ+E]DMªEWTW?AODUWLFE]LFIYO
\^I2DM
C¨WÁY]
 DM(UWM DTVIYD?A_Y?YEWM
7IYLFO2E]U?YTVMwB=UWM('E]I@
IAODUVE]TVBD@
E	?^ ?ABDUV
UVLN?AO?ADDTVI2LN\^?YEWLNIAOIAJ;u
W²	I®LNO2EWTWI2DBD@(M¥E]=M
UVE]I2@pD?YUVE]LF@^D?YTVEIYJ]ÁA §.MXUVLN\^DCFG¨?ADE]DMX@(IYTVTWM(UW7IYO=D
LFOD_ ?YB=UWUVLN?AODLFUWEWBDTW=?YOD@(ME]I+E]DM"DTWM(CNLF\^LNO=?YTVG©M
UVE]LF\^?YEWM
IYJ:u
W"ZRI§%?TVM
_YB=CN?AT.­B=¦D?AE]M^@
?AO7M^¦M(TW
Dm
JmIYTV\^M

àá4
KDM(@
E]LFIYOzÐ®?AODªE]DM¨LNODLFE]LF?YCFLF¯
?YEWLNIAO
 DM¥=TWI2@
M(DBDTVM°JmTWIA\
UV@pDM
\^MJmTVIY\
ÂX?YCFCNI§BDU|E]IX@
IA\^DBDE]M'?YDDTVI2
xO7W²>LF_YBDTVM¥Å®DTVM
UVM
O2EWU
LF\?AE]M¥7IYUVE]M(TWLFIYTVUXIYJEWDM¥JmIYTV\
P?AOD
?Y=DTWI2LF\^?YE]M®7IYUVE]M(TWLFIYTVU¥ISAM
T
JmIYT?¨SAM
TVGUV\^?YCFC.?ATWEWLN±=@
LF?YCFCNG_YM(ODM
TV?YEWM
¼±DSAM
fUWCFLF@
MDTVIY=
CFM
\¥ DM+UWIACNLF®@
B=TWSAM
UUVDI§Ç¦IAUWEWM
TVLNIATWU'@
IY\^DB=E]M
ÆBDUW
LFOD_¨¡2BD?ADTW?AE]BDTVM.w0 DM+DLFUWEWIY_YTV?Y\^U"DTWM(UWM(O2E'?Y=DTWI2LF
\^?YEWLNIAODU"=?YUVM
ÆIAO­ÁpÏAÏ7
ÏYÏAÏÆ LND=UXUW?A\=CNM(UKDLFOD@
ME]=M
DTVIYDCFM
\LFU|UVIUV\^?YCFCÕP¦§ M'M
27M
@(ERE]=M° LFDDU?YD=TWI2LF\?A
E]LFIYOE]I¦MODM(?YTM
2?Y@(E<9:|M(UW=LNEWM"EWDM"TVM
UVE]TVLF@
E]LFSYM"JmIYTV\IYJ
O7]PE]=MXwÒ?YD=TWI2LF\?AE]LFIYO
E]=MX?YDDTVI2LN\^?AE]LFOD_+Jm?A\^LNCFG
LFU TVM
?AUWIAOD?Y=CNM2+	I2DMJmIYTE]DMUVE]I2@pD?YUVE]LF@RSAIYCF?YEWLNCFLNEHG^\^I2DM
C
LFU ?S<?ALNCF?Y=CNMJmTVIY\<;=;=;?>@BA=A?>DC(E?>DA=F=GIHKJ(C=L=J=M=N(M=C
ODM
\^IYO=UWEWTW?AE]M
UEWDMTVLNUVÈ¨IAJ.?AOLNCFCNf\^?YEW@pDM
LFODLN
>LN_ABDTVM
E]LF?YC M(UWEWLN\^?AE]M°IYJJuYGh]ÑRUX\^M(O4EWLNIAODM
ªLFOK=M
@
EWLNIAOÐvPLFJ
E]=M¥LNO=LNEWLN?ACM
UVE]LF\^?YE]M¨IYJJuYGhD?YU©CNI§
§.M(LN_A2ELFOz?®UVLN_A
E]DMTWM(UWB=CNEWLNOD_+?YD=TWI2LF\?AE]LFIYO
ODLF±D@
?AO2ERD?ATWE|IYJ
LFU7I2IYT³ =MM(4?A\^DCNMLNU@
IAODUVE]TVBD@
EWM
²UVBD@pEWD?YEE]=M

Dm
é65ëqéè7,

é98
KDM
@(E]LFIYOY

P7§i

Dm

"Dm

Gh

gU

2

1.5

1

0.5

0
0

1.4

1.2

1

0.8

0.6

0.4

0.2

0.5

0.4

0.3

0.2

0.1

0
−15

120

100

80

60

40

20

−10
l

−5

0.2

0.4

0.6

0.8

1

a

4
v

0
0

2

6

8

0

−0.04

−0.02

0

0.02

0.04

>LN_ABDTVM¥ÅÑR=DTWI2LF\^?YE]M7IYUVE]M(TWLFIYTVUJmIAT©?ÆUV\^?YCFCRDTVIY=
CFM
\¬§ LFE]±=SYMIY=UWM(TWS?YEWLNIAODU	Ñ¬ LND=UR?Y=DTWI2LF\^?YE]LFIYO+LNU
DTVM
UVM
O2E]M(¨2G¥EWDMXDLFUWEWIY_YTV?Y\^UP¦E]DMXUVIYCFLN@
BDTVSYM(UUWDI§%?
¡2BD?Y=TW?AE]BDTVMw­?YD=TWI2LF\?AE]LFIYOP=E]=M"D?AUW=M
¨@(BDTVSYM
U|?YTVM
E]=MUWBDq[]M
@
EWLNSAMDTWLFIYTVU

47

gU

470 mTVM
=TWM(UWM(O4EWM
^2G^?DIYEWE]M(CNLFODM2?YO=¦IAUWEWM
TVLNIAT
DTVLNIAT
47
RÔ?YD=TWI2LF\?AE]M(2G LND=U|UV?Y\^DCFM
ULFO¥EWDMDLFUW
E]IA_YTV?Y\¥wD?SYM^E]=M
LFT\?AUWULFODLDÜ¦M(TWM(O4E?ATWM(?YU«HJuYD7 LNU
LFODLNEWLN?ACNLF¯
M(¼§ LFE]ÆEWDMDTWLFIYTPE]DM+¡2BD?YDTV?YEWBDTVM¦IALNO2EWU"?AOD
470©mDTVM
UVM
O2E]M(?AU@
LFTV
§ M
LF_Y2E]UXEWD?YE?ATWM°DTV?§ OJmTWIA\
@
CFM
U	TVM
UVBDCNELFO°?7I2IYT ?ADDTVI4LF\^?YEWLNIAO©IYJ
 mTVM
=
BgU
TVM
UVM
O2E]M(z4G?¼UVIYCFLNzCFLFODM4W¢Ñ£TVM
CF?YEWM
ªDTVIYDCFM
\
§ IYBDCF
§.IABDCN°D?SAM¦M(M
OSYM(TWG
D?SAMI2@(@
BDTVTWM(+LFJE]DM'DTWLFIYT JmIAT
ÄD?AELNOEWDMM
2?A\=CNMLFO>LN_ABDTWMXÅv =MXM
2?Y@(E¦IAUWEWM
TVLNIAT
LFU"SAM
TVG7M
?AÈYM
Æ@
CFIYUVM©E]I¯
M(TWIv DM+¡4B=?YDTV?YEWBDTWM©¦IALNO2E]U
JmTVIY\?®SAM
TVG®ÄD?YEXDLFUVE]TVLNDB=E]LFIYO@
M
O2EWM
TVM
?YEX¯
M(TWI§ IYBDCF
D?SAM"IAODM^¦IALNO2E?YE¯(M
TVI+§ =LN@pM	Ü7M
@(E]LFSYM(CNG¥EW?YÈAM
U?YCFCE]=M
§ M
LF_Y2EwLFO]ÁÌÏ7W =M|TVM
UVBDCFEw§ IYBDCF7M|?AO?YD=TWI2LF\?AE]LFIYO
IYJ
KDLF\^DCNM M(2¦M(TWLF\^M
O2E]UUVM
M(\³E]I7M M
OD@(IYBDTV?Y_ALNOD_vvÍRI§ M
SAM
TP
E]=MUWEWTWIAOD_ LFODÄDBDM(OD@
M.IYJ2E]DMwLNODLFE]LF?YC4M
UVE]LF\^?YEWMnuYGh2TVM
¡2BDLFTWM(U
M
2EWTW?¥@(?YTVM4°.LNEWDM
T"¦M(E]EWM
T§.?G2U'IAJLNODLFE]LF?YCFLF¯
LFOD_(uY8hvWP	?
DLDÜ¦M(TWM(O2EDTVIY7IYUV?YC4DLFUWEWTWLFDBDEWLNIAOPIATUV\^?YTVE?AD?YDEWLNSAM.§ ?G2U
E]I7IYUVLFE]LFIYOE]DMX¡2BD?ADTV?YE]B=TWM^7IYLFO4EWU?YTVM^ODM
M(DM
EWI@
IYO=
UVE]TVBD@
E?TVM
CFLF?YDCFM?ADDTVI2LN\^?YEWLNIAO
ZRIAE]ME]D?AE°D?YTVE]LF@
CFM
Ü7M
TJmTVIY\TVM
CF?YEWM
DTVIYDCFM
\^U
±DCFE]M(TWU UVB
ß¸ß°º

	2G?^DM
CFE]?As7M
?AÈ0

¹ß°½

gU

47

¿¼»
º¼¾²Ü'ß°Ø

a¨¾²¹ß°º

«HDM(?YCFCNG§.M©§.IABDCN®CFLFÈYMEWI¨D?SAMX?¥SYM(TWG_YM
O=M
TV?YCw@(CN?AUWU'IYJ
?Y=DTWI2LF\^?YE]LFIYOEWM
@pDODLF¡2BDM
U	§ DM(TWM.@
I2DMwJmIATUV7M
@
LF±D@.\I2D
»cÃLNU
M
CFU^@
?AO¼M
?AUWLFCNG7M°@
IY\^DB=E]M
T_YM(ODM
TV?YEWM
Q KÒÀNÁ
?²SAM
TVGUVBD@
@(M
UVUWJmBDC"M
2?Y\^DCFM®JmIYTª LN=DU¨UV?Y\^DCFLNO=_7P?AOD
PR«H.KÀ

ÂYÏcÃJmIYT \^M
?AODs±=M
CF=?YUVM
?YDDTVIY?A@pDM
U

450º
*
*


¼
¼



&
$


f

5
ì
)
z
f

u

â

ì
ú
L

ò
u




u



â

ì

ú








ñ
5
î
â
P
ì
ú
.

ò
<
R


m
<
<
R


<
<
R

ò
<
R


O
Þ
e
x
10

8

6

4

2

0

0

0.5

1

1.5

v

D7

>LN_ABDTVM]OBÑª¡2BD?YDTV?YEWBDTVM..?ADDTVI4LF\^?YEWLNIAOIYJ
VU
D?AUWM(­IAO­?AO­LFCNCFf\?AE]@pDM(­LFODLFE]LF?YC?ADDTVI4LF\^?YEWLNIAOÔuYGh]
KDM(ME]M
2E JmIAT DM
EW?YLFCNU
»7	IYJEWDM¡2BD?Y=TW?AE]BDTVMwª?YCF_YIATWLFE]D\
 DM_AM
ODM(TW?ACJmIYTV\Î
M
O=UWBDTVM
U©E]D?AE©E]=M¨§ M
LF_Y2EXJmBDOD@(E]LFIYODU?YTVM?YCF§.?G2U¨ÔDTWI2D
BD@(E]UIAJ(M
27IYODM(O2E]LF?YC0Jm?A\LFCFG+\^I2DM
CFU DM(TWM?ATWMUVM
SYM(TW?AC
E]M(@pDODLF¡2BDM
UIYJqTVM
@
B=TWUVLNSAM
CFG@
IAODUVE]TVBD@
EWLNOD_RIYTVE]DIA_YIYO=?YCc7IYCFG2
ODIA\LF?YCFUREWD?YEIYO=CNG°TVM
¡2BDLFTWMEWDMM
S?YCFBD?YEWLNIAOIYJ\^IY\^M(O4EWU
KDEWLNM(CNEÔ[]M
UR=TWI2@
M(DBDTVM©ÀNÁkÃLFUR?A\^IYOD_^E]=M¦M(UWERÈ4O=I§ OP2DBDE
7M
TVD?YDU O=IYE E]=M\IAUWEUVE]?ADCNM2
«HJ	E]DM\^IY\^M(O4E _AM
ODM(TW?AE]LFOD_JmBDOD@
EWLNIAO

IYJR?YOÆM(2¦IAODM
O2E]LF?YCDLFUVE]TVLNDB=E]LFIYOÆLFU^È2ODI§ OPEWDM+@(IY\^DBD
E]?AE]LFIYOIYJE]DM\^IY\^M
O2EWU JmIYCFCNI§ UJmTVIY\DLDÜ¦M(TWM(O2E]LF?YE]LFOD_^E]=M
\^IY\^M
O2E _AM
ODM(TW?AE]LFOD_"JmB=OD@
EWLNIAO%

Q%

G

Q%

 DLFU.LFU \M(@pD?YO=LN@(?YC=?AOD@(?YO7M|?ABDE]IA\^?YE]M(w2E]M(ODUWLFIYO=U
E]I\'BDCFE]LFfDLN\^M(ODUWLFIYO=?YCR¡2BD?ADTV?YE]B=TWM¥TVBDCFM
U+LNU?ÆEWIYDLF@¨JmIAT
JmBDEWBDTWMTVM
UVM
?ATW@p	
¹ß°½

ß°¹Ù»ª½²Ø

ºß°Ü

«HOE]DLFUUWM(@
E]LFIYO+§.M_YLFSYM?7PA2GXODI\^M
?YO=U @(IY\^DCFM
EWM4P4@
IA\^
D?ATWLFUWIAO©EWIXTWM(CN?AE]M
\^M
EWDI2DU
M
TVD?ADUE]DMw\M(E]DI2@(CNIAUWM(UWEEWI E]DMIAODMDTVM
UVM
O2E]M(DM
TVMLNU
OYÃH«HO=UWEWM
?Y+IYJDM(E]M(TW\^LFODLNO=_"7IYLFO2E]U BDUW
D?ATWEWLN@(CNM|±DCNEWM
TVLNO=_À
LFOD_ ?ABDUWUVLF?YO¡2BD?Y=TW?AE]BDTVM4PDD?YTVE]LF@
CFM±DCFE]M(TWLFOD_?ACN_AIYTVLNEWD\^U
DTV?§7IYLFO2E]U0JmTVIY\? DTVIY7IYUV?YCDLFUVE]TVLNDB=E]LFIYO0ÑRODP(LFODUVE]M
?A
IYJqB=UWLFOD_TVM
§ M
LF_Y2E]M(¦IALNO2E]U	E]I|DTVI[]M
@(E0E]=Mw7IYUVE]M
TVLFIYT0IAO4EWI
?'@p=IYUVM
OD?ATW?A\^M
E]TVLF@RJmIYTV\¥PcEWDMTWM(§.M(LN_A2E]M
X7IYLFO2E]Um=?YTV
E]LF@
CFM
U?ATWMÈAM
DE?AU?XODIAODs=?YTV?Y\^M
EWTWLF@?YDDTVI2LN\^?AE]LFIYOIYJ
E]=M7IYUVE]M(TWLFIYTTS BD?ADTW?AE]BDTVM¥D?AUWM(z±DCFE]M
TVULNO­E]DMJmBDCFCNG
 ?YB=UWUVLN?AO@
?AUWM|?YTVMR?v
ÅAÃÕÒ	?YO=
_YM(O2E+EWIIABDT+?ADDTVIY?A@pz?YTVM¨CF?YE]EWLN@(M=?YTVE]LF@
CFM±DCFE]M(TWU¼ÀFÁNOcÃ

IvY=M
UV@
TVLN7M
+LNOÀNÁÌÐcÃv?YODÀ

"

"



CNIA_

"VU

V&

?YOD

?YO=





\^LFO

VU

µ©8uY8hv

RR

Â7ÁkÃ0JmIAT \^IYTVM=M
E]?ALNCFU

E]=?YERUVE]?G§ LFE]DLFO¨EWDM"=?YTVE]LF@
CFM±DCFE]M
T@
CF?YUVUPDDB=ER_YM(ODM
TV?YEWM
DTVIY7IYUV?YCv7IYLFO4EWULFO+?X@(CNM(SYM
T§ ?G4
µDTVI[]M(@
EWLNIAO¥LNOE]=M
«HO¨µ?YDCF?Y@(M'DTVIY=?Y_Y?AE]LFIYOÀFÁpËYÃ	EWDM
wÆ?YCF_YIYTVLFE]D\
LNU.TWM(DCF?Y@
M(X2G?'µ?Y=CN?A@
M?ADDTVI4LF\^?YEWLNIAO
 DLFUX\^?G®JmIYTV\´?_AI2I4?YCFE]M(TWOD?AE]LFSYM+LNO\^?YO2G®UWM(E]EWLNOD_AUP
M
UV7M
@
LF?YCFCFGLNJ7E]=M
TVM LNU?TVM
CF?YE]LFSYM(CNGCF?YTV_YMO2BD\"¦M(TIYJ7IYDUVM
TV
S?YEWLNIAODU?YOD"¦IAUWEWM
TVLNIATWU?ATWM §.M(CNCq?ADDTVI2LN\^?YEWM
2G+ ?ABDUV
UVLN?AODU
ZRIAE]M^E]=?YE<P0JmIYTEWDM^@
BDTVTWM(O2E\^I2DM(CÕPv?AO2G¥?YD=TWI2LF\?AE]LFIYO
\^M
EWDI2"EWD?YE?Y=DTWI2LF\^?YE]M(U
[]IYLFO4EWCNG?AU?X ?ABDUV
UVLN?AOP§ LFCNCTVM
UVBDCNE+LNOSYM
TVG¦I2IYTTVM
UVBDCNEWU%KDLFOD@
M
?AOD
?ATWMBDOD@(IYTVTWM(CN?AE]M
¨LNOzmÂv]P7?® ?YBDUVUWLF?YO?YD=TWI2LF\?AE]LFIYO

?YULFODDM(¦M(ODDM
O2E¢ÍRM(OD@
M¨?¼DTVLNIAT
§ LFCNCE]TVM
?AE
?YO=
§ LNCFCODIAEX¦M¥B=¦D?AE]M(zLNOªE]=M¥CNLF_Y2EXIAJ|IADUWM(TWS2LFOD_
JmIYT
"
 =MBDODUV@
M(O4EWM

?YCF\^?YO°±DCFE]M(T"À
ÐAÃ0§ LFCNCE]DM(TWM(JmIYTVM4P2JmIAT
E]=LNU\^I2DM
CHP¦IYODCFGDTVIYD?A_Y?YEWME]DMDTVLNIATP=LH
M2==TWM(?YÈ°DI§ O
@
IA\^DCNM(E]M(CNG2	KDM
MÀ
\^M
?AODs±=M
CF¬?Y=DTWIA?Y@pDM(UÆ?ATWM­@
CFIYUVM
CFGTWM(CN?AE]M
	
w
ÍRI§ M
SAM
TE]=M
G'?ATWM O=IYE?YU@(CNIAUWM(CNG'TWM(CN?AE]M
^?AUE]DMJm?A@
EWIYTVM

JmIYTV\xOvIAJ
\^?G°CNM(?Y¥B=UEWI©?AUWUVBD\^M4RIYE]¨\M(E]DI2DU
@
?AO¦M'DM
TVLNSAM
°UVE]?YTVE]LFOD_XJmTVIY\
E]DM'JmIYCFCNI§ LFOD_XS?YTVLN?AE]LFIYOD?AC
IYq[]M
@
EWLNSAM
8h
CNIA_
]
BVU
BgU
WÁpÂv
LFU'EWDMUVM
EIAJ.?ACNCwS<?ACNLF®DLFUWEWTWLFDBDEWLNIAODU'IAO~h¨E]=M
«HJXW
E]M(TW\¬LNO]ÁpÂvS<?AODLFUWDM(U?YE E]DM\^LNO=LN\"BD\¥P2?YOD+E]DMM(¡4B=?YCF
LFEHGLNU LFODDM(M
°?YOM
¡2BD?ACNLFEHG4IYEW+\^M(?YODf±DM
CF?YODwª?Y=
DTVIY?A@pDM
U^?YTVTVLNSAM©?YE^?AO?ADDTVI2LN\^?YEWLNIAO¼2G¼TVM
DCF?Y@(LNOD_YW
LNU
§ LFE]?E]TV?Y@(E]?Y=CNM^UVM
E<X>=IYT\^M(?YODf±DM
CF?YD=TWIA?Y@pDM(U9W
§ LNEWJm?Y@(E]IATWM(XM
CFM
\^M
O2E]UxOv]M
TV
TVM
DCF?Y@(M
^2G"EWDMRUVM
E
D?ADUw@(IYODJmBDUVLFOD_YCFG4PYE]DMRw¼?ADDTVIY?Y@pLFUwODIAEwD?AUWM(XIYOXE]=M
UV?Y\^M UWM(E
«HODUVE]M(?Y^IYJ7TWM(DCF?Y@
LFOD_6WÒ4G'?UWM(EIYJ7UWLF\^DCNM(TP
DBDE©DTWIA¦M(TXDLFUWEWTWLFDBDEWLNIAODUuYP.E]DM¨\LFODLF\^LN¯(?YE]LFIYOªLFUISYM(T
UVM
E]U.IYJ7ISYM(TWCF?YD=LNOD_DUVM
B=DI\^?YTV_YLFOD?YCFU§ LNEW@
M(TWEW?YLFO^@
IYO=
_7vÀFÁYÁcPMAÃ7JmIAT\IATWM|DM
EW?YLFCNU]
UVE]LFUWEWM
OD@(GX@
IYO=UWEWTW?ALNO2E]UmUVM
MM4
 DM.@pDIYLF@
MIAJ
LNU	DTVI[]M(@
E]M(P(DM

E]M(TW\^LFODM
UEWDMISYM(TWCF?YDUIYJ¦E]DM(UWMDUVM
BD=I\^?ATW_ALNOD?ACNUvKDLFOD@(M
E]=M?ADDTVI2LN\^?YEWLNIAOXTWM(E]?ALNODU \^IYTVMRUVE]TVBD@
EWBDTVM|IAJ0E]DMIATWLF_YLF
OD?ACA\^I2DM
CHP<E]=M.DIA¦M.LNU	E]=?YE	E]DM.?YDDTVI2LN\^?AE]LFIYOLFU7M
EWE]M
T
E]=?YO°?^JmBDCNCFG©Jm?A@
EWIYTVLN¯(M
?YDDTVI2LN\^?AE]LFIYOIAJW+
¶IZ
M¥D?SYMUVDI§ OªDI§
_YM(ODM
TV?YC ¡2BD?ADTW?AE]BDTVM°?YD=TWI2LF\?A
E]LFIYO=U@
?AO¦M.LN=M
O2E]LF±DM
'LNOEWDMwUVE]?AODD?ATW.UW@pDM(\^M4 =M
?Y=DTWIA?Y@p?Y=¦M(?YTVU0E]I|¦M.TW?AE]DM(TÄDM(4LFDCFMw?AODLNU	@
CFIYUVM
CFGTWM(
CF?YE]M(¥E]I+D?YTVE]LF@
CFM±DCFE]M(TWLFOD_?ACN_AIYTVLNEWD\^U  =M'DTVI[]M(@
E]LFIYO=U
IYO2EWI?^@pDIAUWM(O+Jm?A\^LNCFG©?ACNCFI§ U LNEWM
TV?YEWLNSAMLF\^DTVISYM
\^M(O4EWUIYJ
?Y=DTWI2LF\^?YE]LFIYO=U7 DLFULNULFO'@(IYO2E]TV?YUVE0E]ID?ATWEWLN@(CNM.±DCNEWM
TVLNO=_
?YCF_YIATWLFE]=\UEWD?YE@
?AO+UVM
CFM
@(EE]DM7IYUVLNEWLNIAO+IAJ7IYLFO2E]U'm=?YTV
E]LF@
CFM
UIAODCNG+IYOD@(M?YOD@(?YO°IYODCFG©TVM
§ M
LF_Y2ELFOEWDMCFLN_A2E IYJ
M
2EWTW?^LFODJmIYTV\^?YE]LFIYO	

?AU?RJm?Y\^LNCFGIYO§ =LN@p

½²·YØ|¿¼¾²Ø|ØR·Y»ª¸

451<
R






M

1
<






¶
¬
1
®










R
x
Þ
 


 
t
$
<




$
<


 
<
R


 
µ
t
t
t
z
<
?YD=TWIA?Y@pLNU
 DM+TWBDO=ODLNO=_¨E]LF\^M+IAJE]=M©¡2BD?Y=TW?AE]BDTVMw
M
27IYODM(O2E]LF?YCLNOE]=MO2BD\"¦M(TIYJwS?ATWLF?YDCFM
ULFO-h
 DLFULNU
7M
@
?ABDUVM"§ M"=?SYM'?ADDTVI2LN\^?YEWM
LFO2E]M
_ATW?ACNUISYM(Th
2G°?
_YTVLF¥ISYM(TR?YCFC	S<?ATWLF?Y=CNM(URLFO(h
| DLFU@
IA\=CNM(4LFEHG°LNULFDM
OD
LNÈ2BD@p=L	?AOD©[]BDOD@
EWLNIAOEWTWM(M"?ACN_AIYTVLNEWD\^ULNOJmBDCFCNG
E]LF@
?ACE]I
DLFUW@(TWM(E]MODM
EH§ IYTVÈ2UÒà¨IYTVM¥?YDS?AOD@
M(²¡2BD?YDTV?YEWBDTVM¥TWB=CNM(U
\^?GTWM(UWBDCFE'LFOÆ?TWB=ODODLFOD_EWLN\^MUWB=DsM(2¦IAODM
O2E]LF?YC LFOÆE]=M
CF?YTV_YM
UVE@
CFLF¡4B=M©UVLN¯(M4° DM©@
IYUVE'IAJDM
EWM
TV\LFODLFOD_¨EWDM©_ATWLF
7IYLFO4EWU|=M
7M
ODDUIAO¨E]=M'D?ATWEWLN@(BDCN?AT|@p=IYLF@
MIAJ
P¦EWDM"M(2
7IYODM(O4EWLN?ACJm?Y\^LFCNGIYO§ DLF@pE]DM©¦IAUWEWM
TVLNIATLNU"DTWIc[]M
@(E]M
	
>=IAT' ?YBDUVUVLN?AODUPA_ATWLF©7IYLFO2E]U@(?YO©7M@
IA\^DBDE]M(+IAOD@
M?AOD
TVM
UV@
?YCFM
®§ =M
ODM(SYM
T"ODM
M(DM
]ÁYÁA]°«HOÆE]DM§.IATWUVE@(?YUVM4P?
UVM
EIAJ.IATWEWDIY_AIYOD?AC¦IACNG2ODIA\LF?YCFUD?AUE]I7M©@(IYODUVE]TVBD@(E]M
	P
IYJ	§ DLF@p+EWDMTVI4IAE]U \"BDUWE7MJmIYBDO=O2BD\^M(TWLF@
?ACNCFG4
zDM(O®E]DM¡2BD?ADTV?YE]B=TWMXD?AUWM(\M(E]DI2®LFU'@(IY\^DBDEW?YE]LFIYO=
?YCFCFG'E]I2ILFO2E]M
O=UWLFSYM2PTVM
DCF?Y@(LNOD_UVE]M(DU|Á EWIÅJmTWIA\%EWDM?YCF_YIA
TVLNEWD\¤LFO¥KDM(@
EWLNIAOÐX4GLF\7IYTVE]?AOD@
M'UW?A\=CNLFOD_X\^?G©JmIATW\
?YOLFO4EWM
TVM
UVE]LFOD_^?YCFE]M(TWOD?AE]LFSYM2
 DM M(E]?¼?AOD% ?Y\^\^?¼@(IY\^¦IAODM
O2EWU+LFOzE]DM@pDIYLF@
M¨IYJ
LNOKDM
@(E]LFIYO~LF\^DCNGM(2E]TV?©@
IA\^DBDE]?AE]LFIYOD?ACM	Ü7IYTVE<ÑRJm
E]M(T.UVM
M(LNO=_'\^?YO2G^IYDUVM
TVS?YEWLNIAODUPYE]=M|7IYUVE]M(TWLFIYT.ISYM
T:XR§ LFCNC
E]M(OD¨EWI©7M° ?ABDUVUWLF?YOR«HELNULNO2EWM
TVM
UVE]LFOD_©EWI©M
UVE]?ADCFLNUV¨JmIAT
§ D?AE IYDUVM
TVS?YE]LFIYO+UWLF¯
M(U E]DMM(2E]TV?"M
Ü¦IATWE LFU §.IATWEW2§ DLNCFM4
 DM=TWI2@
M(DBDTVME]I_AM
ODM(TW?AE]MIATWEWDIY_AIYOD?AC¦IACNG2ODIA\LF?YCFU0?AOD
¡2BD?Y=TW?AE]BDTVM TWB=CNM(U.DM(UW@(TWLF7M
XLFOE]DLFU ?YTVE]LF@
CFMLNU ?Y\^IAOD_E]=M
7M
UVEUWEWBDDLFM
LFOXE]=MCNLFE]M(TW?AE]BDTVM4BDEwLFELFUwBDO=CNLFÈYM(CNG"E]D?AEwLFE
LFUE]=MwIY=E]LF\?ACYIAODMJmIYTE]DM.wJmTV?Y\^M
§ IYTVÈ0M§ IYB=CN?AE
CFM
?YUVETWM(¡2BDLNTVMTWBDCFM
UJmIAT\'BDCFE]LFfDLN\^M(ODUWLFIYO=?YC§ M
LF_Y2EJmBDOD@

E]LFIYO=UP=E]?AÈ4LFOD_EWDM'7IYUVE]M(TWLFIYTRIYJD?ATW?A\M(E]M(TWU Jm?A@
E]IATWLF¯
M(LNU
DTVIYD?ADCFGTWM(CN?AE]LFSYM(CNG+@
IY?ATWUVM4ÑRCFUWIvP2E]TV?YDLFE]LFIYO=?YC. ?ABDUWUVLF?YO
¡2BD?Y=TW?AE]BDTVM LNU.DM
UVLF_YODM(XE]I?A@pDLNM(SYM ¯(M
TVIM
TVTWIATJmIYTw?'@
CF?YUVU
IYJ	7IYCFG4O=IY\^LN?ACNU	>=IAT E]DM'@
BDTVTWM(O2E ?ADDCFLN@(?YEWLNIAO+LFE \^?G©7M
LFO4EWM
TVM
UVE]LFOD_E]ITWM(¡2BDLNTVM©_AI2I4¦M(TWJmIATW\^?AOD@
MJmIYT^DLDÜ¦M(TWM(O2E
@
CF?YUVUVM
UIYJ	JmBDOD@(E]LFIYODU
æ7[
;*	,\^]
/=_a`76®/2*1
:
M¬§ IYBDCF
ÑRCFM
2?AODDM
TcbRD\^?7PzLF\
[]È2UWEWTW??YOD"ÑRCFL2?G2CF?YO9	M(\_ALNC2JmIAT
zLFM
_YM(TWLFOD@pÈ0P(	[]M
M(TWd:|L
DM(CNDJmB=C DLNUV@
B=UWUVLNIAODU¨ =M® LFDDU^?ADDTVI4LF\^?YEWLNIAODU'§ M
TVM
DTVI2DBD@
M(ÇBDUWLFOD_¢zLFODQ K§ =LN@pÇLFU¼?S?YLFCN?ADCNMªJmTVIY\
;=;=;e>Df=CgBhi@BE?>gBj=f?>DjIg>kE(l(G=i=Enm@A
/=oÕ/23/4*
prqDsutwvyx{zkzk|~}vV~(ykk|n?I}}Duzkke}D(kzkk(zknkVn~}zkKz
}k|~}zk|rB}X}3vX~DDD 3¡£¢n¤¥
}Dk|~}(r9u (r-K
qVªBªVªVv
¦§e¨k©
Vº¡£·6±3²³
´µ¤3¡²³¶3·6¥®¸D3
§¹3¹
(|
ykk|z~ÄÃÅVrrV
±3¼¥D¡£±3¢
B((B
Àazkku|rn|kzk|rÑ}n
prÈDsuÉÊvËV
kzk ¿I}kzk|r7}kzk|rr7Ò(rzkk1|rÓkz}zk­k}DÔ6 (rvÕ
Ù
xwvÀaB(yz
©%Ø

¢¸k¢(Dv¾½¿ÀÁzk¿nk|r
«ÇBÇÈVv
|rÌv
|rÌ3Í}nÏÎ-vËÐzkV
}D(
©VÖ

pr«Ds­¬®v$K}~v°¯±V¡£±V²³¡£3¢(±V´

CNLFÈYMEWIáE]=?YODÈ

vV(e×=k|rz}D

vÎBk(V

(|rzkVk

©Â

/2:

ÚÛ

ÚÛ

©BÖ
«ÇBÇqVv

v-ó3v×(k

´µº

©

Ðz}D(Bk

n|

v=ÎVknV

(|rzkVkv

v(ÀÊv×=ky|z}D

}(

§e¨kØñn§?ñÅØn©

«DÇVÇÈBv

âBsuxwv=ÀV(yz

}n÷Ð(v7ÃÅ¿(|rIv

prªDs­Ð(v
prqÇBs

¼¥D²³·6¥Dv½¿ÀÔzk¿nk|r

p Dsu×ev-û?vô-k¿n|k¿}D(

 V¡£¥
}(ïtuv
xuv
¶3D3¼
âök«
çìKVk

}D(k|rzkêIva±
qVªBªVòBv
yk(v	?¼
¡ 
²eÝÅ3·
«ÇBÇ«Vv

¢(²³¡£±3´Ü^3¢n²³ÞÝÅ±3´µ­Ü^²³¶3 3¥6¡£¢ß±3²³¡£DvaÐ(k|rnVkà
yk}Dv
Ù
¢(²³¡£±3´ÅÜ^3¢(²³^ÝÅ±3´µãÜ^²³¶3 V¥-¡£¢­a~±3²³¡£DvÊÐnk|r(Vykä
yk}D
pråDsuævÅtXkÌV®}D(Äç-vè  zkvéÎy(}D|rêyér|re(kVI}à
}Dzk|BYëV^}(nkìí|r­}Dzkd|rnkn1|î¿KK(k|rï}3yk|}D
(z~ðBkÌívÅ~ÞDDD 3¡£¢(¤¥
pròDs­Ð(v"ó(r|r6}nÞó3vKô1v
¿(r­}nvÅxõnðïìKzk(k|rB^VIzk¿n
Ì=}Dr­}­Ò(rzkXzk1nVn|rnK}ÊkKkzk6v?YDD V¡£¢(¤¥9¸
qVªVªBöVv
¢n¥
~
v7Ð¿n(¿I}k
Ðzk ¿I}kzk|r
pröDs­Ð(vwô-|r
©ÔÖ
|rÌ3r|r¿(  é|nky(î}D(ùV6}k|rkBðú|rzk¿
V~}Dzk|rz~Åø
qVªBª Bv
xwûúÃÅtùu (yv"üý¡£þß¸aÿV¢(3·9¡£
òVå
 r|rVyv
×}yzkVeV}n¿(9}n^zk¿(Xk(uà
(k n(z}DrVVk|rzk¿n­v
ÿÿaÿ
«DÇVÇ=qVv
±V¢(¥D±3²³¡£3¢n¥/3¢
¢¸D3·6±V²³¡£3¢
¶3¡£D±3´?Ü^ 3´µ¥Dv
kk|rz
n|
½%kyk
±3¼B¥D¡£±V¢?²³þ3¥?¸D36üaD±3¥D3¢n¡£¢(¤
±
D
kà
k|rz
prqVqDsuæv¬6|rnÌ=}BvÅæú¿(-ÉX½7nkV1n(zk|rVß}n^u|r(|ru|rêK}Dzk|B
k¿nuvIæIy¿n(|rK}"kBkz
«DÇVÇqBv
prqV«Dsuæv¬6|nÌ=}BvÉìKz}zk|rBÔnkV}D}Dzk|BßBd}(nkìí|r­}Dzk
}3k|~}ã|nky(Kvßa~DD 3¡¢(¤¥
«ÇBÇqVv
¦§?¨k©
}D(
vË|rk
 BíÔr|r
prqVÈDsuô1v¬6nk(¿K
¬®vóBk}Dv
(kB}=}zk|rV7B$}n(kìK|r­}zk9|nky(Køx?7yu(|rk|rK}
kzk(nívßa~DD 3¡£¢n¤¥
qVªVªBªVv
¦§e¨k©
}zkzk|r
6|y(ì
}(ÄÀÊvó3vÅ×rzv
prqâBs­ÀÊvçkuB(|rz
}Dkzk|y-ÒnrzkkvIÞDDD 3¡£¢n¤¥
¦§e¨k©
prqVåDs­ó3ve½(K}k~võ
D±
¡´µ¡£¥D²³¡£ÔüD±3¥D3¢(¡¢(¤Ë¡¢
¼¥DÙ
²³·6¥Dv{¬6Vk=}(à
qBª  Bv
prqVòDsuxwv½(Vr7}D(Ó¬®vÔkzv9Éu|rKz1}3k|~}Ë }k(|rn^|r
r|nK}wnK}6|du (yv 
(B(à
¢n±3´?¸=3~D±3¥D²³¡£¢n¤
ªk«
qBªVªÇ=v
zkzkyk|rn
}n
¾v(æv
prqVöDs¾v(twv½kk
Ð(v(xuv(æI(ÌVVrkÌK
v½"v=×~}n(kív
¥6¡£¢ÓÝ
²e¸
¶3
 ¤±V·6·6¡¢(¤vÃú}D9nk|nV
kk|rz~7½%kk
¡£¢n²³¡
(|
«nãn|zk|rB
qBªVªB«Vv
}(ËÉÊv%ÉakÌK|rv
|rk¿Kð-}D}zk¿I}
prq DsuxwvaÐuB}
}n}D
©Åá
v"«ÇVÇBâv
(kB}=}zk|rVIv~ÞDDD 3¡£¢(¤¥!
}(
vKÎ-vKkzvÃÅVuà
prqVªDs­ÀÊvKó3víÐ(|rBr¿}Dzky
xwvæú¿(B­}
(nz}zk|rV7Vé}3k|~}ËV}n¿(|rK}D6 (rv-
±3¼¥¡±3¢
I}B?âBÇöDäVâ«Bå
qBªVªVòBv
²³±3²³¡¥²³¡¥!"
}k|~}zk|rB}%n|kzkk|rà
pr«ÇBs­ó3v|r(Ô}nßÃúv%|rk¿nVvaÐzkknzk(k
ÉXÐ(vÅ~ÞDD V¡£¢(¤¥
(nzk|B(ú|r
«ÇBÇÈBv
§e¨kØñn§?ñÅØ(©
Þn(à
}D(îævÅtXkÌVvÔ6(k
xuv
pr«VqDs­ç-vè  zk
kKzkÓô1}D®}ïku Vzk¿n|r(ùVãkzk Ì
V~}zk|rr|rzkzk|rà
­}zk|rBvIßa~DD 3¡£¢n¤¥/Ü$#
«ÇBÇVâv

«DÇVÇ=qVv
¢(²³´´µ¡£¤¢(²

·9¡±V´aüD¡

Ãúv

ô1}D(®}(

n­}

452


 
t
t
è
[


§
»
¨

Æ
©


©
Ö
©
á
p
©
Ö
©
Ø
á
©
Â
§
Ø
©
©

Æ
Ø
²
Û
©
©
©
©
à
Æ
¨
ñ
¨
ñ
©
©
Æ
¹
Â

©
Â
v
Æ
»
Û
¹
Ø
©
Â

©
©
©
Æ
©
Æ
©
Æ
¨
Ø
©
Û
©
©
©
©
á
©
Û
¹
ñ
§
Ø
Â

©
©
v
á
©
Æ
¨

Ø
©
©
Ö
»
Ø
©
©

á
©

©


Ø

©
