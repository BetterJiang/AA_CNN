Abstract

We develop the distance dependent Chinese restaurant process, a exible class of distributions over
partitions that allows for dependencies between the elements. This class can be used to model many
kinds of dependencies between data in innite clustering models, including dependencies arising
from time, space, and network connectivity. We examine the properties of the distance depen-
dent CRP, discuss its connections to Bayesian nonparametric mixture models, and derive a Gibbs
sampler for both fully observed and latent mixture settings. We study its empirical performance
with three text corpora. We show that relaxing the assumption of exchangeability with distance
dependent CRPs can provide a better t to sequential data and network data. We also show that
the distance dependent CRP representation of the traditional CRP mixture leads to a faster-mixing
Gibbs sampling algorithm than the one based on the original formulation.
Keywords: Chinese restaurant processes, Bayesian nonparametrics

1. Introduction

Dirichlet process (DP) mixture models provide a valuable suite of exible clustering algorithms for
high dimensional data analysis. Such models have been adapted to text modeling (Teh et al., 2006;
Goldwater et al., 2006), computer vision (Sudderth et al., 2005), sequential models (Dunson, 2006;
Fox et al., 2007), and computational biology (Xing et al., 2007). Moreover, recent years have seen
signicant advances in scalable approximate posterior inference methods for this class of models
(Liang et al., 2007; Daume, 2007; Blei and Jordan, 2005). DP mixtures have become a valuable tool
in modern machine learning.

DP mixtures can be described via the Chinese restaurant process (CRP), a distribution over
partitions that embodies the assumed prior distribution over cluster structures (Pitman, 2002). The
CRP is fancifully described by a sequence of customers sitting down at the tables of a Chinese
restaurant. Each customer sits at a previously occupied table with probability proportional to the
number of customers already sitting there, and at a new table with probability proportional to a
concentration parameter. In a CRP mixture, customers are identied with data points, and data
sitting at the same table belong to the same cluster. Since the number of occupied tables is random,
this provides a exible model in which the number of clusters is determined by the data.

c(cid:13)2011 David M. Blei and Peter I. Frazier.

BLEI AND FRAZIER

The customers of a CRP are exchangeableunder any permutation of their ordering, the prob-
ability of a particular conguration is the sameand this property is essential to connect the CRP
mixture to the DP mixture. The reason is as follows. The Dirichlet process is a distribution over
distributions, and the DP mixture assumes that the random parameters governing the observations
are drawn from a distribution drawn from a Dirichlet process. The observations are conditionally
independent given the random distribution, and thus they must be marginally exchangeable.1 If the
CRP mixture did not yield an exchangeable distribution, it could not be equivalent to a DP mixture.
Exchangeability is a reasonable assumption in some clustering applications, but in many it is not.
Consider data ordered in time, such as a time-stamped collection of news articles. In this setting,
each article should tend to cluster with other articles that are nearby in time. Or, consider spatial data,
such as pixels in an image or measurements at geographic locations. Here again, each datum should
tend to cluster with other data that are nearby in space. While the traditional CRP mixture provides
a exible prior over partitions of the data, it cannot accommodate such non-exchangeability.

In this paper, we develop the distance dependent Chinese restaurant process, a new CRP in
which the random seating assignment of the customers depends on the distances between them.2
These distances can be based on time, space, or other characteristics. Distance dependent CRPs
can recover a number of existing dependent distributions (Ahmed and Xing, 2008; Zhu et al., 2005).
They can also be arranged to recover the traditional CRP distribution. The distance dependent
CRP expands the palette of innite clustering models, allowing for many useful non-exchangeable
distributions as priors on partitions.3

The key to the distance dependent CRP is that it represents the partition with customer assign-
ments, rather than table assignments. While the traditional CRP connects customers to tables, the
distance dependent CRP connects customers to other customers. The partition of the data, that
is, the table assignment representation, arises from these customer connections. When used in a
Bayesian model, the customer assignment representation allows for a straightforward Gibbs sam-
pling algorithm for approximate posterior inference (see Section 3). This provides a new tool for
exible clustering of non-exchangeable data, such as time-series or spatial data, as well as a new
algorithm for inference with traditional CRP mixtures.

1.1 Related Work

Several other non-exchangeable priors on partitions have appeared in recent research literature.
Some can be formulated as distance dependent CRPs, while others represent a different class of
models. The most similar to the distance dependent CRP is the probability distribution on partitions
presented in Dahl (2008). Like the distance dependent CRP, this distribution may be constructed
through a collection of independent priors on customer assignments to other customers, which then
implies a prior on partitions. Unlike the distance dependent CRP, however, the distribution pre-

1. That these parameters will exhibit a clustering structure is due to the discreteness of distributions drawn from a

Dirichlet process (Ferguson, 1973; Antoniak, 1974; Blackwell, 1973).

2. This is an expanded version of our shorter conference paper on this subject (Blei and Frazier, 2010). This version

contains new perspectives on inference and new results.

3. We avoid calling these clustering models Bayesian nonparametric (BNP) because they cannot necessarily be cast as
a mixture model originating from a random measure, such as the DP mixture model. The DP mixture is BNP because
it includes a prior over the innite space of probability densities, and the CRP mixture is only BNP in its connection
to the DP mixture. That said, most applications of this machinery are based around letting the data determine their
number of clusters. The fact that it actually places a distribution on the innite-dimensional space of probability
measures is usually not exploited.

2462

DISTANCE DEPENDENT CHINESE RESTAURANT PROCESSES

sented in Dahl (2008) requires normalization of these customer assignment probabilities. The model
in Dahl (2008) may always be written as a distance dependent CRP, although the normalization re-
quirement prevents the reverse from being true (see Section 2). We note that Dahl (2008) does not
present an algorithm for sampling from the posterior, but the Gibbs sampler presented here for the
distance dependent CRP can also be employed for posterior inference in that model.

There are a number of Bayesian nonparametric models that allow for dependence between
(marginal) partition membership probabilities. These include the dependent Dirichlet process
(MacEachern, 1999) and other similar processes (Duan et al., 2007; Grifn and Steel, 2006; Xue
et al., 2007). Such models place a prior on collections of sampling distributions drawn from Dirich-
let processes, with one sampling distribution drawn per possible value of covariate and sampling
distributions from similar covariates more likely to be similar. Marginalizing out the sampling dis-
tributions, these models induce a prior on partitions by considering two customers to be clustered to-
gether if their sampled values are equal. (Recall, these sampled values are drawn from the sampling
distributions corresponding to their respective covariates.) This prior need not be exchangeable if
we do not condition on the covariate values.

Distance dependent CRPs represent an alternative strategy for modeling non-exchangeability.
The difference hinges on marginal invariance, the property that a missing observation does not af-
fect the joint distribution. In general, dependent DPs exhibit marginal invariance while distance
dependent CRPs do not. For the practitioner, this property is a modeling choice, which we discuss
in Section 2. Section 4 shows that distance dependent CRPs and dependent DPs represent nearly
distinct classes of models, intersecting only in the original DP or CRP.

Still other prior distributions on partitions include those presented in Ahmed and Xing (2008)
and Zhu et al. (2005), both of which are special cases of the distance dependent CRP. Rasmussen
and Ghahramani (2002) use a gating network similar to the distance dependent CRP to partition
datapoints among experts in way that is more likely to assign nearby points to the same cluster. Also
included are the product partition models of Hartigan (1990), their recent extension to dependence
on covariates (Muller et al., 2008), and the dependent Pitman-Yor process (Sudderth and Jordan,
2008). A review of prior probability distributions on partitions is presented in Mueller and Quintana
(2008). The Indian Buffet Process, a Bayesian non-parametric prior on sparse binary matrices, has
also been generalized to model non-exchangeable data by Miller et al. (2008). We further discuss
these priors in relation to the distance dependent CRP in Section 2.

The rest of this paper is organized as follows. In Section 2 we develop the distance dependent
CRP and discuss its properties. We show how the distance dependent CRP may be used to model
discrete data, both fully-observed and as part of a mixture model. In Section 3 we show how the
customer assignment representation allows for an efcient Gibbs sampling algorithm. In Section 4
we show that distance dependent CRPs and dependent DPs represent distinct classes of models. Fi-
nally, in Section 5 we describe an empirical study of three text corpora using the distance dependent
CRP. We show that relaxing the assumption of exchangeability with distance dependent CRPs can
provide a better t to sequential data. We also show its alternative formulation of the traditional CRP
leads to a faster-mixing Gibbs sampling algorithm than the one based on the original formulation.

2463

BLEI AND FRAZIER

Figure 1: An illustration of the distance dependent CRP. The process operates at the level of cus-
tomer assignments, where each customer chooses either another customer or no customer
according to Equation (2). Customers that chose not to connect to another are indicated
with a self link The table assignments, a representation of the partition that is familiar to
the CRP, are derived from the customer assignments.

2. Distance-dependent CRPs

The Chinese restaurant process (CRP) is a probability distribution over partitions (Pitman, 2002). It
is described by considering a Chinese restaurant with an innite number of tables and a sequential
process by which customers enter the restaurant and each sit down at a randomly chosen table.
After N customers have sat down, their conguration at the tables represents a random partition.
Customers sitting at the same table are in the same cycle.

In the traditional CRP, the probability of a customer sitting at a table is computed from the
number of other customers already sitting at that table. Let zi denote the table assignment of the
ith customer, assume that the customers z1:(i1) occupy K tables, and let nk denote the number of
customers sitting at table k. The traditional CRP draws each zi sequentially,

p(zi = k| z1:(i1),a ) (cid:181) (cid:26) nk

for
for

k  K
k = K + 1,

(1)

where a
is a given scaling parameter. When all N customers have been seated, their table assign-
ments provide a random partition. Though the process is described sequentially, the CRP is ex-
changeable. The probability of a particular partition of N customers is invariant to the order in
which they sat down.

We now introduce the distance dependent CRP. In this distribution, the seating plan probability
is described in terms of the probability of a customer sitting with each of the other customers.
The allocation of customers to tables is a by-product of this representation. If two customers are

2464

a
DISTANCE DEPENDENT CHINESE RESTAURANT PROCESSES

Figure 2: Draws from sequential CRPs. Illustrated are draws for different decay functions, which
are inset: (1) The traditional CRP; (2) The window decay function; (3) The exponential
decay function; (4) The logistic decay function. The table assignments are illustrated,
which are derived from the customer assignments drawn from the distance dependent
CRP. The decay functions (inset) are functions of the distance between the current cus-
tomer and each previous customer.

2465

BLEI AND FRAZIER

reachable by a sequence of interim customer assignments, then they at the same table. This is
illustrated in Figure 1.

Let ci denote the ith customer assignment, the index of the customer with whom the ith customer
is sitting. Let di j denote the distance measurement between customers i and j, let D denote the
set of all distance measurements between customers, and let f be a decay function (described in
more detail below). The distance dependent CRP independently draws the customer assignments
conditioned on the distance measurements,

p(ci = j| D,a ) (cid:181) (cid:26) f (di j)

if
if

j 6= i
i = j.

(2)

Notice the customer assignments do not depend on other customer assignments, only the distances
between customers. Also notice that j ranges over the entire set of customers, and so any customer
may sit with any other. (If desirable, restrictions are possible through the distances di j. See the
discussion below of sequential CRPs.)

As we mentioned above, customers are assigned to tables by considering sets of customers that
are reachable from each other through the customer assignments. (Again, see Figure 1.) We denote
the induced table assignments z(c), and notice that many congurations of customer assignments
c might lead to the same table assignment. Finally, customer assignments can produce a cycle,
for example, customer 1 sits with 2 and customer 2 sits with 1. This still determines a valid table
assignment: All customers sitting in a cycle are assigned to the same table.

By being dened over customer assignments, the distance dependent CRP provides a more
expressive distribution over partitions than models based on table assignments. This distribution
is determined by the nature of the distance measurements and the decay function. For example, if
each customer is time-stamped, then di j might be the time difference between customers i and j;
the decay function can encourage customers to sit with those that are contemporaneous. If each
customer is associated with a location in space, then di j might be the Euclidean distance between
them; the decay function can encourage customers to sit with those that are in proximity.4 For many
sets of distance measurements, the resulting distribution over partitions is no longer exchangeable;
this is an appropriate distribution to use when exchangeability is not a reasonable assumption.

2.1 Decay Functions

In general, the decay function mediates how distances between customers affect the resulting distri-
bution over partitions. We assume that the decay function f is non-increasing, takes non-negative
nite values, and satises f ( ) = 0. We consider several types of decay as examples, all of which
satisfy these nonrestrictive assumptions.

The window decay f (d) = 1[d < a] only considers customers that are at most distance a from
the current customer. The exponential decay f (d) = ed/a decays the probability of linking to
an earlier customer exponentially with the distance to the current customer. The logistic decay
f (d) = exp (d + a)/(1 + exp (d + a)) is a smooth version of the window decay. Each of these
affects the distribution over partitions in a different way.

4. The probability distribution over partitions dened by Equation (2) is similar to the distribution over partitions pre-
sented in Dahl (2008). That probability distribution may be specied by Equation (2) if f (di j) is replaced by a
non-negative value hi j that satises a normalization requirement (cid:229)
i6= j hi j = N  1 for each j. Thus, the model pre-
sented in Dahl (2008) may be understood as a normalized version of the distance dependent CRP. To write this model
as a distance dependent CRP, take di j = 1/hi j and f (d) = 1/d (with 1/0 = 

and 1/ = 0), so that f (di j) = hi j.

2466

a
DISTANCE DEPENDENT CHINESE RESTAURANT PROCESSES

2.2 Sequential CRPs and the Traditional CRP

With certain types of distance measurements and decay functions, we obtain the special case of
sequential CRPs.5 A sequential CRP is constructed by assuming that di j = 
for those j > i. With
our previous requirement that f ( ) = 0, this guarantees that no customer can be assigned to a later
customer, that is, p(ci  i| D) = 1. The sequential CRP lets us dene alternative formulations of
some previous time-series models. For example, with a window decay function and a = 1, we
recover the model studied in Ahmed and Xing (2008). With a logistic decay function, we recover
the model studied in Zhu et al. (2005). In our empirical study we will examine sequential models in
detail.

and di j < 

ered when f (d) = 1 for d 6= 

The sequential CRP can re-express the traditional CRP. Specically, the traditional CRP is recov-
for j < i. To see this, consider the marginal distribution
of a customer sitting at a particular table, given the previous customers assignments. The probabil-
ity of being assigned to each of the other customers at that table is proportional to one. Thus, the
probability of sitting at that table is proportional to the number of customers already sitting there.
Moreover, the probability of not being assigned to a previous customer is proportional to the scaling
parameter a
. This is precisely the traditional CRP distribution of Equation (1). Although these
models are the same, the corresponding Gibbs samplers are different (see Section 5.4).

settings to the sequential case, the distances are di j = i j for j < i and di j = 

Figure 2 illustrates seating assignments (at the table level) derived from draws from sequential
CRPs with each of the decay functions described above, including the original CRP. (To adapt these
for j > i.) Com-
pared to the traditional CRP, customers tend to sit at the same table with other nearby customers. We
emphasize that sequential CRPs are only one type of distance dependent CRP. Other distances, com-
bined with the formulation of Equation (2), lead to a variety of other non-exchangeable distributions
over partitions.

2.3 Marginal Invariance

The traditional CRP is marginally invariant: Marginalizing over a particular customer gives the
same probability distribution as if that customer were not included in the model at all. The distance
dependent CRP does not generally have this property, allowing it to capture the way in which inu-
ence might be transmitted from one point to another. See Section 4 for a precise characterization of
the class of distance dependent CRPs that are marginally invariant.

