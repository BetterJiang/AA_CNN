Jonathan Chang, Jordan Boyd-Graber, and David M. Blei. Connections between the Lines: Augmenting Social

Networks with Text. Refereed Conference on Knowledge Discovery and Data Mining, 2009.

@inproceedings{Chang:Boyd-Graber:Blei-2009,

Title = {Connections between the Lines: Augmenting Social Networks with Text},
Booktitle = {Refereed Conference on Knowledge Discovery and Data Mining},
Author = {Jonathan Chang and Jordan Boyd-Graber and David M. Blei},
Year = {2009},
Location = {Paris, France},
}

1

ConnectionsbetweentheLines:AugmentingSocialNetworkswithTextJonathanChangElectricalEngineeringEngineeringQuadranglePrinceton,NJ08544jcone@princeton.eduJordanBoyd-GraberComputerScience35OldenSt.Princeton,NJ08544jbg@cs.princeton.eduDavidM.BleiComputerScience35OldenSt.Princeton,NJ08544blei@cs.princeton.eduABSTRACTNetworkdataisubiquitous,encodingcollectionsofrelation-shipsbetweenentitiessuchaspeople,places,genes,orcor-porations.Whilemanyresourcesfornetworksofinterest-ingentitiesareemerging,mostofthesecanonlyannotateconnectionsinalimitedfashion.Althoughrelationshipsbe-tweenentitiesarerich,itisimpracticaltomanuallydevisecompletecharacterizationsoftheserelationshipsforeverypairofentitiesonlarge,real-worldcorpora.Inthispaperwepresentanovelprobabilistictopicmodeltoanalyzetextcorporaandinferdescriptionsofitsenti-tiesandofrelationshipsbetweenthoseentities.Wedevelopvariationalmethodsforperformingapproximateinferenceonourmodelanddemonstratethatourmodelcanbeprac-ticallydeployedonlargecorporasuchasWikipedia.Weshowqualitativelyandquantitativelythatourmodelcanconstructandannotategraphsofrelationshipsandmakeusefulpredictions.CategoriesandSubjectDescriptorsH.2.8[DatabaseApplications]:DataminingGeneralTermsAlgorithmsKeywordsstatisticaltopicmodels,socialnetworklearning,graphicalmodels1.INTRODUCTIONNetworkdata—datawhichexpressrelationshipsbetweenensemblesofentities—arebecomingincreasinglypervasive.Peopleareconnectedtoeachotherthroughavarietyofkin-ship,social,andprofessionalrelationships;proteinsbindtoandinteractwithotherproteins;corporationsconductbusinesswithothercorporations.Understandingthena-tureoftheserelationshipscanprovideusefulmechanismsPermissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalorclassroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributedforproﬁtorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitationontheﬁrstpage.Tocopyotherwise,torepublish,topostonserversortoredistributetolists,requirespriorspeciﬁcpermissionand/orafee.KDD’09,June28–July1,2009,Paris,France.Copyright2009ACM978-1-60558-495-9/09/06...$5.00.forsuggestingnewrelationshipsbetweenentities,character-izingnewrelationships,andquantifyingglobalpropertiesofnaturallyoccurringnetworkstructures[2,6,31,33,34].Manycorporaofnetworkdatahaveemergedinrecentyears.Examplesofsuchdataincludesocialnetworks,suchasLinkedInorFacebook,andcitationnetworks,suchasCiteSeer,Rexa,orJSTOR.Othernetworkscanbecon-structedmanuallyorautomaticallyusingtextswithpeoplesuchastheBible,scientiﬁcabstractswithgenes,ordecisionsinlegaljournals.Characterizingthenetworksofconnectionsbetweentheseentitiesisofhistorical,scientiﬁc,andpracti-calinterest.However,describingeveryrelationshipforlarge,real-worldcorporaisinfeasible.Thusmostdatasetslabeledgesasmerelyonoroﬀ,orwithasmallsetofﬁxed,pre-deﬁnedconnectiontypes.Theselabellingscannotcapturethecomplexitiesunderlyingtherelationshipsandlimittheapplicabilityofthesedatasets.Inthispaperwedevelopamethodforaugmentingsuchdatasetsbyanalyzingdocumentcollectionstouncovertherelationshipsencodedintheirtexts.Textcorporaarere-pletewithinformationaboutrelationships,butthisinfor-mationisoutofreachfortraditionalnetworkanalysistech-niques.WedevelopNetworksUncoveredByBayesianInfer-ence(Nubbi),aprobabilistictopicmodeloftext[5,12,29]withhiddenvariablesthatrepresentthepatternsofwordusewhichdescribestherelationshipsinthetext.Givenacollectionofdocuments,Nubbirevealsthehiddennetworkofrelationshipsthatisencodedinthetextsbyassociatingrichdescriptionswitheachentityanditsconnections.Forexample,Figure1illustratesasubsetofthenetworkun-coveredfromthetextsofWikipedia.Connectionsbetweenpeoplearedepictedbyedges,eachofwhichisassociatedwithwordsthatdescribetherelationship.First,wedescribetheintuitionsandstatisticalassump-tionsbehindNubbi.Second,wederiveeﬃcientalgorithmsforusingNubbitoanalyzelargedocumentcollections.Fi-nally,weapplyNubbitotheBible,Wikipedia,andscientiﬁcabstracts.WedemonstratethatNubbicandiscoversensi-bledescriptionsofthenetworkandcanmakepredictionscompetitivewiththosemadebystateoftheartmodels.2.MODELThegoalofNubbiistoanalyzeacorpustodescribetherelationshipsbetweenpairsofentities.Nubbitakesasin-putverylightlyannotateddata,requiringonlythatentitieswithintheinputtextbeidentiﬁed.Nubbialsotakesasin-putthenetworkofentitiesdesiredtobeannotated.ForsomecorporathisnetworkisalreadyexplicitlyencodedasJoseph StalinWinston ChurchillLyndon B. JohnsonMao ZedongJimmy CarterMargaret ThatcherRonald ReaganRichard NixonNikita KhrushchevJohn F. KennedyHubert HumphreyGeorge H. W. BushRoss PerotLeon TrotskyLev KamenevZhou EnlaiMikhail GorbachevlabourgovernleaderbritishworldsovietcommunistcentralunionfullsovietrussiangovernunionnuclearrepublicanstatefederalistvoteviceFigure1:AsmallsubgraphofthesocialnetworkNubbilearnedtakingonlytherawtextofWikipediawithtaggedentitiesasinput.Thefullmodeluses25relationshipandentitytopics.Anedgeexistsbetweentwoentitiesiftheirco-occurrencecountishigh.Forsomeoftheedges,weshowthetopwordsfromthemostprobablerelationshiptopicassociatedwiththatpairofentities.Thesearethewordsthatbestexplainthecontextswherethesetwoentitiesappeartogether.Acompletebrowserforthisdataisavailableathttp://topics.cs.princeton.edu/nubbi.1 When Jesus had spoken these words, he went forth with his disciples over the brook Cedron, where was a garden, into the which he entered, and his disciples.2 And Judas also, which betrayed him, knew the place: for Jesus ofttimes resorted thither with his disciples.3 Judas then, having received a band of men and ofﬁcers from the chief priests and Pharisees, cometh thither with lanterns and torches and weapons.4 Jesus therefore, knowing all things that should come upon him, went forth, and said unto them, Whom seek ye?5 They answered him, Jesus of Nazareth. Jesus saith unto them, I am he. And Judas also, which betrayed him, stood with them.6 As soon then as he had said unto them, I am he, they went backward, and fell to the ground.7 Then asked he them again, Whom seek ye? And they said, Jesus of Nazareth.received band ofﬁcers chief priests Pharisees lanterns  torches weaponsspoken words disciples brook Cedron garden enter disciples knowing things seek asked seek NazarethJesusJudas1 When Jesus had spoken these words, he went forth with his disciples over the brook Cedron, where was a garden, into the which he entered, and his disciples.2 And Judas also, which betrayed him, knew the place: for Jesus ofttimes resorted thither with his disciples.3 Judas then, having received a band of men and ofﬁcers from the chief priests and Pharisees, cometh thither with lanterns and torches and weapons.4 Jesus therefore, knowing all things that should come upon him, went forth, and said unto them, Whom seek ye?5 They answered him, Jesus of Nazareth. Jesus saith unto them, I am he. And Judas also, which betrayed him, stood with them.6 As soon then as he had said unto them, I am he, they went backward, and fell to the ground.7 Then asked he them again, Whom seek ye? And they said, Jesus of Nazareth.betrayed knew place disciples answered Nazareth saith betrayedJesusand JudasFigure2:Ahigh-leveloverviewofNubbi’sviewoftextdata.Acorpuswithidentiﬁedentitiesisturnedintoacollectionofbags-of-words(inrectangles),eachassociatedwithindividualentities(left)orpairsofentities(right).Theprocedureintheleftpanelisrepeatedforeveryentityinthetextwhiletheprocedureintherightpanelisrepeatedforeverypairofentities.agraph.Forothertextcorporathisgraphmustbecon-structed.Onesimplewayofconstructingthisgraphistouseafully-connectednetworkofentities.Onecanprunetheedgesinthisgraphusingsimplestatisticssuchasentity-entityco-occurrencecounts.Fromtheentitiesinthisnetwork,thetextisdividedintotwodiﬀerentclassesofbagsofwords.First,eachentityisassociatedwithanentitycontext,abagofwordsco-locatedwiththeentity.Second,eachpairofentitiesisassociatedwithapaircontext,abagofwordsco-locatedwiththepair.Figure2showsanexampleoftheinputtothealgorithmturnedintoentitycontextsandpaircontexts.Nubbilearnstwodescriptionsofhowentitiesappearinthecorpus:entitytopicsandrelationshiptopics.Following[5],atopicisdeﬁnedtobeadistributionoverwords.Toaidintuitions,wewillforthemomentassumethatthesetopicsaregivenandhavedescriptivenames.Wewilldescribehowthetopicsandcontextsinterplaytorevealthenetworkofrelationshipshiddeninthetexts.Weemphasize,however,thatthegoalofNubbiistoanalyzethetextstolearnboththetopicsandrelationshipsbetweenentities.Anentitytopicisadistributionoverwords,andeachentityisassociatedwithadistributionoverentitytopics.Forexample,supposetherearethreeentitytopics:poli-tics,movies,andsports.RonaldReaganwouldhaveadistributionthatfavorspoliticsandmovies,athleteac-torslikeJohnnyWeissmullerandGeenaDaviswouldhavedistributionsthatfavormoviesandsports,andspecial-izedathletes,likePel´e,wouldhavedistributionsthatfavorsportsmorethanotherentitytopics.Nubbiusesentitytopicstomodelentitycontexts.Becausethesportsentitytopicwouldcontainwordslike“cup,”“win,”and“goal,”asso-ciatingPel´eexclusivelywiththesportsentitytopicwouldbeconsistentwiththewordsobservedinhiscontext.Relationshiptopicsaredistributionsoverwordsassoci-atedwithpairsofentities,ratherthanindividualentities,andeachpairofentitiesisassociatedwithadistributionoverrelationshiptopics.Justastheentitytopicsclustersimilarpeopletogether(e.g.,RonaldReagan,GeorgeBush,andBillClintonallexpressthepoliticstopic),therelation-shiptopicscanclustersimilarpairsofpeople.Thus,RomeoandJuliet,AbelardandHeloise,RuslanandLudmilla,andIzanamiandIzanagimightallsharealoversrelationshiptopic.Relationshiptopicsareusedtoexplainpaircontexts.Eachwordinapaircontextisassumedtoexpresssomethingabouteitheroneoftheparticipatingentitiesorsomethingparticulartotheirrelationship.Forexample,considerJaneWymanandRonaldReagan.(JaneWyman,anactress,wasactor/presidentRonaldReagan’sﬁrstwife.)Individu-ally,WymanisassociatedwiththemoviesentitytopicandReaganisassociatedwiththemoviesandpoliticsentitytopics.Inaddition,thispairofentitiesisassociatedwithrelationshiptopicsfordivorceandcostars.Nubbihypothesizesthateachworddescribeseitheroneoftheentitiesortheirrelationship.ConsiderthepaircontextforReaganandWyman:In1938,Wymanco-starredwithRonaldReagan.Rea-ganandactressJaneWymanwereengagedattheChicagoTheaterandmarriedinGlendale,California.FollowingargumentsaboutReagan’spoliticalambitions,Wymanﬁledfordivorcein1948.SinceReaganistheonlyU.S.presidenttohavebeendivorced,Wymanistheonlyex-wifeofanAmericanPresident.Wehavemarkedthewordsthatarenotassociatedwiththerelationshiptopic.Functionalwordsaregray;wordsthatcomefromapoliticstopic(associatedwithRonaldReagan)areunderlined;andwordsthatcomefromamoviestopic(associatedwithJaneWyman)areitalicized.Theremainingwords,“1938,”“co-starred,”“engaged,”“Glen-dale,”“ﬁled,”“divorce,”“1948,”“divorced,”and“ex-wife,”describetherelationshipbetweenReaganandWyman.In-deed,itisbydeducingwhichcaseeachwordfallsintothatNubbiisabletocapturetherelationshipsbetweenentities.Examiningtherelationshiptopicsassociatedwitheachpairofentitiesprovidesadescriptionofthatrelationship.TheabovediscussiongivesanintuitivepictureofhowNubbiexplainstheobservedentityandpaircontextsusingentityandrelationshiptopics.Indataanalysis,however,wedonotobservetheentitytopics,pairtopics,ortheassign-mentsofwordstotopics.Ourgoalistodiscoverthem.Todothis,weformalizethesenotionsinagenerativeprob-abilisticmodelofthetextsthatuseshiddenrandomvari-ablestoencodethehiddenstructuredescribedabove.Inposteriorinference,we“reverse”theprocesstodiscoverthelatentstructurethatbestexplainsthedocuments.(Poste-riorinferenceisdescribedinthenextsection.)Morefor-mally,Nubbiassumesthefollowingstatisticalmodel.1.Foreachentitytopicjandrelationshiptopick,(a)Drawtopicmultinomialsβθj∼Dir(ηθ+1),βψk∼Dir(ηψ+1)2.Foreachentitye,(a)Drawentitytopicproportionsθe∼Dir(αθ);(b)Foreachwordassociatedwiththisentity’scon-text,i.Drawtopicassignmentze,n∼Mult(θe);ii.Drawwordwe,n∼Mult(βθze,n).3.Foreachpairofentitiese,e0,(a)Drawrelationshiptopicproportionsψe,e0∼Dir(αψ);(b)Drawselectorproportionsπe,e0∼Dir(απ);(c)Foreachwordassociatedwiththisentitypair’scontext,i.Drawselectorce,e0,n∼Mult(πe,e0);ii.Ifce,e0,n=1,A.Drawtopicassignmentze,e0,n∼Mult(θe);B.Drawwordwe,e0,n∼Mult(βθze,e0,n).iii.Ifce,e0,n=2,A.Drawtopicassignmentze,e0,n∼Mult(θe0);B.Drawwordwe,e0,n∼Mult(βθze,e0,n).iv.Ifce,e0,n=3,A.Drawtopicassignmentze,e0,n∼Mult(ψe,e0);B.Drawwordwe,e0,n∼Mult(βψze,e0,n).ThisisdepictedinagraphicalmodelinFigure3.ThehyperparametersoftheNubbimodelareDirichletpa-rametersαθ,αψ,andαπ,whichgoverntheentitytopicdis-tributions,therelationshipdistributions,andtheentity/pairmixingproportions.TheDirichletparametersηθandηψarepriorsforeachtopic’smultinomialdistributionoverterms.ThereareKθper-topictermdistributionsforentitytopics,βθ1:Kθ,andKψper-topictermdistributionsβψ1:Kψforrela-tionshiptopics.ThewordsofeachentitycontextareessentiallydrawnfromanLDAmodelusingtheentitytopics.Thewordsofeachpaircontextaredrawninamoresophisticatedway.Thetopicassignmentsforthewordsinthepaircontextforentityeandentitye0arehypothesizedtocomefromtheentitytopicproportionsθe,entitytopicproportionsθe0,orrelationshiptopicproportionsψe,e0.Theswitchingvariablece,e0,nselectswhichofthesethreeassignmentsisusedforeachword.Thisselectorce,e0,nisdrawnfromπe,e0,whichdescribesthetendencyofwordsassociatedwiththispairofentitiestobeascribedtoeitheroftheentitiesorthepair.Itisψe,e0thatdescribeswhattherelationshipbetweenentitieseande0is.Byallowingsomeofeachpair’scontextwordstocomefromarelationshiptopicdistribution,themodelisabletocharacterizeeachpair’sinteractionintermsofthelatentrelationshiptopics.3.COMPUTATIONWITHNUBBIWiththemodelformallydeﬁnedintermsofhiddenandobservedrandomvariables,wenowturntoderivingtheal-gorithmsneededtoanalyzedata.Dataanalysisinvolvesinferringthehiddenstructurefromobserveddataandmak-ingpredictionsonfuturedata.Inthissection,wedevelopavariationalinferenceprocedureforapproximatingthepos-terior.Wethenusethisproceduretodevelopavariationalexpectation-maximization(EM)algorithmforparameteres-timationandforapproximatingthevariouspredictivedis-tributionsofinterest.3.1InferenceInposteriorinference,weapproximatetheposteriordis-tributionofthelatentvariablesconditionedontheobser-vations.AsforLDA,exactposteriorinferenceforNubbiisintractable[5].Weappealtovariationalmethods.Variationalmethodspositafamilyofdistributionsoverthelatentvariablesindexedbyfreevariationalparameters.Thoseparametersarethenﬁttobeclosetothetrueposte-rior,whereclosenessismeasuredbyrelativeentropy.See[13]MNeNe,e'Kθβθψe,e'αθwzθeαψcπe,e'ηθzwαπKψβψηψNe'zwθe'...Ne''zwθe''N entity contextsM pair contextsKψ relationship topicsKθ entity topicsFigure3:AdepictionoftheNubbimodelusingthegraphicalmodelformalism.Nodesarerandomvariables;edgesdenotedependence;plates(i.e.,rectangles)denotereplication;shadednodesareobservedandunshadednodesarehidden.Thelefthalfoftheﬁgureareentitycontexts,whiletherighthalfoftheﬁgurearepaircontexts.Initsentirety,themodelgeneratesboththeentitycontextsandthepaircontextsshowninFigure2.forareview.Weusethefactorizedfamilyq(Θ,Z,C,Π,Ψ|γθ,γψ,Φθ,Φψ,γπ,Ξ)=Qeˆq(θe|γθe)Qnq(ze,n|φθe,n)˜·Qe,e0q(ψe,e0|γψe,e0)q(πe,e0|γπe,e0)·Qe,e0hQnq(ze,e0,n,ce,e0,n|φψe,e0,n,ξe,e0,n)i,whereγθisasetofDirichletparameters,oneforeachen-tity;γπandγψaresetsofDirichletparameters,oneforeachpairofentities;Φθisasetofmultinomialparameters,oneforeachwordineachentity;Ξisasetofmultinomialparameters,oneforeachpairofentities;andΦψisasetofmatrices,oneforeachwordineachentitypair.Eachφψe,e0,ncontainsthreerows—onewhichdeﬁnesamultinomialovertopicsgiventhatthewordcomesfromθe,onewhichdeﬁnesamultinomialgiventhatthewordcomesfromθe0,andonewhichdeﬁnesamultinomialgiventhatthewordcomesfromψe,e0.Notethatthevariationalfamilyweuseisnotthefully-factorizedfamily;thisfamilyfullycapturesthejointdistributionofze,e0,nandce,e0,n.Weparameterizethispairbyφψe,e0,nandξe,e0,nwhichdeﬁneamultinomialdistributionoverall3Kpossiblevaluesofthispairofvariables.Minimizingtherelativeentropyisequivalenttomaximiz-ingtheJensen’slowerboundonthemarginalprobabilityoftheobservations,i.e.,theevidencelowerbound(ELBO),L=Xe,e0Le,e0+XeLe+H(q),(1)wheresumsovere,e0iterateoverallpairsofentitiesandLe,e0=XnEqhlogp(we,e0,n|βψ1:K,βθ1:K,ze,e0,n,ce,e0,n)i+XnEq[logp(ze,e0,n|ce,e0,n,θe,θe0,ψe,e0)]+XnEq[logp(ce,e0,n|πe,e0)]+Eq[logp(ψe,e0|αψ)]+Eq[logp(πe,e0|απ)]andLe=XnEqhlogp(we,n|βθ1:K,ze,n)i+Eq[logp(θe|αθ)]+XnEq[logp(ze,n|θe)].TheLe,e0termoftheELBOdiﬀerentiatesthismodelfrompreviousmodels[5].Theconnectionsbetweenentitiesaﬀecttheobjectiveinposteriorinference(and,below,inparame-terestimation).OuraimnowistocomputeeachtermoftheobjectivefunctiongiveninEquation1.Afterexpandingthisexpres-sionintermsofthevariationalparameters,wecanderiveasetofcoordinateascentupdatestooptimizetheELBOwithrespecttothevariationalparameters,γθ,γψ,Φθ,Φψ,γπ,Ξ.Becauseofspacelimitations,wemustreferthereadertothelongerversionofthispaperforafullderivationofthefol-lowingupdates.Theupdatesforφθe,nassigntopicproportionstoeachwordassociatedwithanindividualentity,φθe,n∝exp“logβθwn+Ψ“γθe””,wherelogβθwnrepresentsthelogarithmofcolumnwnofβθandΨ(·)isthedigammafunction.(Adigammaofavectoristhevectorofdigammas.)Thetopicassignmentsforeachwordassociatedwithapairofentitiesaresimilar,φψe,e0,n,1=exp“logβθwn+Ψ“γθe”−Ψ“1Tγθe”−λe,e0,n,1”φψe,e0,n,2=exp“logβθwn+Ψ“γθe0”−Ψ“1Tγθe0”−λe,e0,n,2”φψe,e0,n,3=exp“logβψwn+Ψ“γψe,e0”−Ψ“1Tγψe,e0”−λe,e0,n,3”,whereλe,e0,nisavectorofnormalizingconstants.Thesenormalizingconstantsarethenusedtoestimatetheprob-abilitythateachwordassociatedwithapairofentitiesisassignedtoeitheranindividualorrelationship,ξe,e0,n∝exp`λe,e0,n+Ψ`γπe,e0´´.ThetopicandentityassignmentsarethenusedtoestimatethevariationalDirichletparameterswhichparameterizethelatenttopicandentityproportions,γπe,e0=απ+Xnξe,e0,nγψe,e0=αψ+Xnξe,e0,n,3φe,e0,n,3.Finally,thetopicandentityassignmentsforeachpairofentitiesalongwiththetopicassignmentsforeachindividualentityareusedtoupdatethevariationalDirichletparame-terswhichgovernthelatenttopicassignmentsforeachindi-vidualentity.Theseupdatesallowustocombineevidenceassociatedwithindividualentitiesandevidenceassociatedwithentitypairs.γθe=Xe0Xn“ξe,e0,n,1φψe,e0,n,1+ξe0,e,2φψe0,e,n,2”+αθ+Xnφθe,n.3.2ParameterestimationWeﬁtthemodelbyﬁndingmaximumlikelihoodestimatesforeachoftheparameters:πe,e0,βθ1:Kandβψ1:K.Onceagain,thisisintractablesoweturntoanapproximation.Weem-ployvariationalexpectation-maximization,whereweiteratebetweenoptimizingtheELBOofEquation1withrespecttothevariationaldistributionandwithrespecttothemodelparameters.OptimizingwithrespecttothevariationaldistributionisdescribedinSection3.1.Optimizingwithrespecttothemodelparametersisequivalenttomaximumlikelihoodesti-mationwithexpectedsuﬃcientstatistics,wheretheexpec-tationistakenwithrespecttothevariationaldistribution.Thesuﬃcientstatisticsforthetopicvectorsβθandβψcon-sistofalltopic-wordpairsinthecorpus,alongwiththeirentityorrelationshipassignments.Collectingthesestatis-ticsleadstothefollowingupdates,βθw∝ηθ+XeXn1(we,n=w)φθe,n+Xe,e0Xn1(we,e0,n=w)ξe,e0,n,1φψe,e0,n,1+Xe,e0Xn1(we0,e,n=w)ξe0,e,n,2φψe0,e,n,2βψw∝ηψ+Xe,e0Xn1(we,e0,n=w)ξe,e0,n,3φψe,e0,n,3.Thesuﬃcientstatisticsforπe,e0arethenumberofwordsascribedtotheﬁrstentity,thesecondentity,andtherela-tionshiptopic.Thisresultsintheupdateπe,e0∝exp`Ψ`απ+Pnξe,e0,n´´.3.3PredictionWithaﬁttedmodel,wecanmakejudgmentsabouthowwellthemodeldescribesthejointdistributionofwordsas-sociatedwithpreviouslyunseendata.InthissectionwedescribetwopredictiontasksthatweusetocompareNubbitoothermodels:wordpredictionandentityprediction.Inwordprediction,themodelpredictsanunseenwordas-sociatedwithanentitypairgiventheotherwordsassociatedwiththatpair,p(we,e0,i|we,e0,−i).Thisquantitycannotbecomputedtractably.Weinsteadturntoavariationalap-proximationofthisposterior,p(we,e0,i|we,e0,−i)≈Eq[p(we,e0,i|ze,e0,i)].Herewehavereplacedtheexpectationoverthetrueposte-riorprobabilityp(ze,e0,i|we,e0,−i)withthevariationaldis-tributionq(ze,e0,i)whoseparametersaretrainedbymaxi-mizingtheevidenceboundgivenwe,e0,−i.Inentityprediction,themodelmustpredictwhichentitypairasetofwordsismostlikelytoappearin.ByBayes’rule,theposteriorprobabilityofanentitypairgivenasetofwordsisproportionaltotheprobabilityofthesetofwordsbelongingtothatentitypair,p((e,e0)|w)∝p(w|we,e0),wheretheproportionalityconstantischosensuchthatthesumofthisprobabilityoverallentitypairsisequaltoone.Afteraqualitativeexaminationofthetopicslearnedfromcorpora,weusethesetwopredictionmethodstocompareNubbiagainstothermodelsthatoﬀerprobabilisticframe-worksforassociatingentitieswithtextinSection4.2.4.EXPERIMENTSInthissection,wedescribeaqualitativeandquantitativestudyofNubbionthreedatasets:thebible(charactersinthebible),biological(genes,diseases,andproteinsinsci-entiﬁcabstracts),andwikipedia.Forthesethreecorpora,theentitiesofinterestarealreadyannotated.ExpertshavemarkedallmentionsofpeopleintheBible[23]andbiolog-icalentitiesincorporaofscientiﬁcabstracts[26,30],andWikipedia’slinkstructureoﬀersdisambiguatedmentions.Notethatitisalsopossibletousenamedentityrecogniz-erstopreprocessdataforwhichentitiesarenotpreviouslyidentiﬁed.Theﬁrststepinouranalysisistodeterminetheentityandpaircontexts.Forbible,versesoﬀeranatomiccontext;anyterminaversewithanentity(pair)isassociatedwiththatentity(pair).Forbiological,weusetokenswithinaﬁxeddistancefrommentionsofanentity(pair)tobuildthedatausedbyourmodel.Forwikipedia,weusedthesameapproachasbiologicalforassociatingwordswithentitypairs.Weassociatedwithindividualentities,however,allthetermsinhis/herWikipediaentry.ForallcorporaweremovedtokensbasedonastoplistandstemmedalltokensusingthePorterstemmer.Infrequenttokens,entities,andpairswereprunedfromthecorpora.14.1LearningNetworksWeﬁrstdemonstratethattheNubbimodelproducesin-terpretableentitytopicsthatdescribeentitycontextsandre-lationshiptopicsthatdescribepaircontexts.WealsoshowthatbycombiningNubbi’smodeloflanguagewithanet-workautomaticallyestimatedthroughco-occurrencecounts,wecanconstructrichsocialnetworkswithlabeledrelation-ships.Table1showssomeoftherelationshiptopicslearnedfromtheBibledata.(Thismodelhasﬁveentitytopicsandﬁve1Afterpreprocessing,thebibledatasetcontainsalexiconofsize2411,523entities,and475entitypairs.Thebiologicaldatasetcontainsalexiconofsize2425,1566entities,and577entitypairs.Thewikipediadatasetcontainsalexiconofsize9144,1918entities,and429entitypairs.Topic1Topic2EntitiesJesus,MaryAbraham,ChedorlaomerTerah,AbrahamAhaz,RezinfatherkingbegatcityTopTermsjamessmotedaughterlordmotherthousandTable1:ExamplesofrelationshiptopicslearnedbyasixtopicNubbimodeltrainedontheBible.Theupperpartofthetableshowssomeoftheentitypairshighlyassociatedwiththattopic.Thelowerpartofthetableshowsthetoptermsinthattopic’smultinomial.relationshiptopics.)Eachcolumnshowsthewordswiththehighestweightinthattopic’smultinomialparametervector,andaboveeachcolumnareexamplesofentitypairsassoci-atedwiththattopic.Inthisexample,RelationshipTopic1correspondstobloodrelations,andRelationshipTopic2referstoantagonists.Weemphasizethatthisstructureisuncoveredbyanalyzingtheoriginaltexts.Nopriorknowl-edgeoftherelationshipsbetweencharactersisusedintheanalysis.Inamorediversecorpus,Nubbilearnsbroadertopics.Inatwenty-ﬁvetopicmodeltrainedontheWikipediadata,theentitytopicsbroadlyapplytoentitiesacrossmanytimeperiodsandcultures.Artists,monarchs,worldpoliticians,peoplefromAmericanhistory,andscientistseachhavearepresentativetopic(seeTable2).Therelationshiptopicsfurtherrestrictentitiesthatarespeciﬁctoanindividualcountryorperiod(Table3).Insomecases,relationshiptopicsnarrowthefocusofbroaderentitytopics.Forinstance,RelationshipTopics1,5,6,9,and10inTable3helpexplainthespeciﬁchistoricalcontextofpairsbetterthantheverybroadworldleaderentityTopic7.Insomecases,thesedistinctionsareveryspeciﬁc.Forex-ample,RelationshipTopic6containspairsofpost-HanoverianmonarchsofGreatBritainandNorthernIreland,whileRela-tionshipTopic5containsrelationshipswithpre-HanoverianmonarchsofEnglandeventhoughbothsharewordslike“queen”and“throne.”Notealsothatthesetopicsfavorwordslike“father”and“daughter,”whichdescribethere-lationshipspresentinthesepairs.Themodelsometimesgroupstogetherpairsofpeoplefromradicallydiﬀerentcontexts.Forexample,RelationshipTopic8groupscomposerswithreligiousscholars(bothsharetermslike“mass”and“patron”),revealingadrawbackofusingaunigram-basedmethod.Asanotherexample,RelationshipTopic3civilwargeneralsandearlyMuslimleaders.4.2EvaluatingthepredictivedistributionThequalitativeresultsoftheprevioussectionillustratethatNubbiisaneﬀectivemodelforexploringandunder-standinglatentstructureindata.Inthissection,weprovideaquantitativeevaluationofthepredictivemechanismsthatNubbiprovides.Aswithanyprobabilisticmodel,Nubbideﬁnesaproba-bilitydistributionoverunseendata.Afterﬁttingthelatentvariablesofourmodeltodata(asdescribedinSection3.1),wetakeunseenpaircontextsandaskhowwellthemodelpre-dictsthoseheld-outwords.Modelsthatgivehigherprob-abilitytotheheld-outwordsbettercapturehowthetwoentitiesparticipatinginthatcontextinteract.Inacompli-mentaryproblem,wecanasktheﬁttedmodeltopredictentitiesgiventhewordsinthepaircontext.(ThedetailsofthesemetricsaredeﬁnedmorepreciselyinSection3.3.)WecompareNubbitothreealternativeapproaches:aun-igrammodel,LDA[5],andtheAuthor-Topicmodel[27].Alloftheseapproachesaremodelsoflanguagewhichtreatin-dividualentitiesandpairsofentitiesalikeasbagsofwords.IntheAuthor-Topicmodel[27],entitiesareassociatedwithindividualcontextsandpaircontexts,buttherearenodis-tinguishedpairtopics;allwordsareexplainedbythetopicsassociatedwithindividuals.Inaddition,wealsocomparethemodelagainsttwobaselines:aunigrammodel(equiv-alenttousingnorelationshiptopicsandoneentitytopic)andamutualinformationmodel(equivalenttousingonerelationshiptopicandoneentitytopic).Weusethebootstrapmethodtocreateheld-outdatasetsandcomputepredictiveprobability[10].Figure4showstheaveragepredictiveloglikelihoodforthethreeapproaches.TheresultsforNubbiareplottedasafunctionofthetotalnumberoftopicsK=Kθ+Kψ.TheresultsforLDAandauthor-topicwerealsocomputedwithKtopics.Allmodelsweretrainedwiththesamehyperparameters.NubbioutperformsbothLDAandunigramonallcorporaforallnumbersoftopicsK.ForwordpredictionNubbiperformscomparablytoAuthor-Topiconbible,worseonbi-ological,andbetteronwikipedia.Wepositthatbecausethewikipediacorpuscontainsmoretokensperentityandpairofentities,theNubbimodelisabletoleveragemoredatatomakebetterwordpredictions.Conversely,forbiological,individualentitiesexplainpaircontextsbetterthanrela-tionshiptopics,givingtheadvantagetoAuthor-Topic.Forwikipedia,thisyieldsa19%improvementinaveragewordloglikelihoodovertheunigrammodelatK=24.Incontrast,theLDAmodelisunabletomakeimprovedpredictionsovertheunigrammodel.Therearetworea-sonsforthis.First,LDAcannotuseinformationabouttheparticipatingentitiestomakepredictionsaboutthepair,becauseittreatsentitycontextsandpaircontextsasin-dependentbagsofwords.Second,LDAdoesnotallocatetopicstodescriberelationshipsalone,whereasNubbidoeslearntopicswhichexpressrelationships.ThisallowsNubbitomakemoreaccuratepredictionsaboutthewordsusedtodescriberelationships.WhenrelationshipwordsdoﬁndtheirwayintoLDAtopics,LDA’sperformanceimproves,suchasonthebibledataset.Here,LDAisabletoobtaina6%improvementoverunigram;Nubbiobtainsa10%im-provement.WiththeexceptionofAuthor-Topiconbiological,Nubbioutperformstheotheralltheotherapproachesontheen-titypredictiontask.Forexample,onwikipedia,theNubbimodelshowsa32%improvementovertheunigrambase-line,LDAshowsa7%improvement,andAuthor-Topicac-tuallyperformsworsethantheunigrambaseline.WhileLDA,Author-Topic,andNubbiimprovemonotonicallywiththenumberoftopicsonthewordtask,theycanpeakanddecreasefortheentitypredictiontask.Recallthatanim-provedwordlikelihoodneednotimplyanimprovedentitylikelihood;ifamodelassignsahigherwordlikelihoodtootherentitypairsinadditiontothecorrectentitypair,thepredictiveentitylikelihoodmaystilldecrease.Thus,whileeachheld-outcontextisassociatedwithaparticularpairofentities,itdoesnotfollowthatthatsamecontextcouldnotTopic1Topic2Topic3Topic4Topic5EntitiesGeorgeWestinghouseCharlesPeirceLindsayDavenportLeeHarveyOswaldPierre-JosephProudhonGeorgeStephensonFrancisCrickMartinaHingisTimothyMcVeighBenjaminTuckerGuglielmoMarconiEdmundHusserlMichaelSchumacherYuriGagarinMurrayRothbardJamesWattIbnal-HaythamAndreAgassiBobbySealeKarlMarxRobertFultonLinusPaulingAlainProstPattyHearseAmartyaSenTopTermselectricityworkalignstatesocialengineuniversebgcoloramericanworkpatenttheoryraceyearpoliticscompanysciencewintimesocietyinventtimegrandpresidenteconomicsTopic6Topic7Topic8Topic9Topic10EntitiesBettyDavisFranklinD.RooseveltJackKirbyBabeRuthXenophonHumphreyBogartJimmyCarterTerryPratchettBarryBondsCaligulaKateWinsletBrianMulroneyCarlBarksSatchelPageHorusMartinScorseseNevilleChamberlainGregoryBenfordPedroMartinezNebuchadrezzarIIAudreyHepburnMargaretThatcherSteveDitkoRogerClemensNeroTopTermsﬁlmstatestorygamegreekawardpartybookbaseballromestarelectionworkseasonhistoryrolepresidentﬁctionleaguesenateplaygovernmentpublishrundeathTable2:TentopicsfromamodeltrainedonWikipediacarveoutfairlybroadcategorieslikemonarchs,athletes,entertainers,andﬁguresfrommythandreligion.AnexceptionisthemorefocusedTopic9,whichismostlyaboutbaseball.Notethatnotalloftheinformationislinguistic;Topic3showswewereunsuccessfulinﬁlteringoutallWikipedia’smarkup,andthealgorithmlearnedtoassociatescoretableswithasportscategory.Topic1Topic2Topic3Topic4Topic5PairsReagan-GorbachevMuhammad-MosesGrant-LeePaulVI-JohnPaulIIPhilipV-LouisXIVKennedy-KhrushchevRabin-ArafatMuhammad-AbuBakrPiuxXII-PaulIILouisXVI-FrancisIAlexandra-AlexanderIIIE.Bront¨e-C.Bront¨eSherman-GrantJohnXXIII-JohnPaulIIMariaTheresa-CharlemagneNajibullah-KamalSolomon-MosesJackson-LeePiusIX-JohnPaulIIPhilipV-LouisXVINicholasI-AlexanderIIIArafat-SharonSherman-LeeLeoXIII-JohnPaulIIPhilipV-MariaTheresaTermssovietisraelunionvaticanfrenchrussiangodcorpcatholdauphingovernmentpalestiniangenpapalspanishunionchilecampaigncouncildeathnuclearbookrichmondtimethroneTopic6Topic7Topic8Topic9Topic10PairsHenryVIII-C.ofAragonJeﬀerson-BurrMozart-SalieriGeorgeVI-EdwardVIITrotsky-StalinMaryI(Eng)-ElizabethIJeﬀerson-MadisonMalory-ArthurGeorgeVI-EdwardVIIIKamenev-StalinHenryVIII-AnneBoleynPerot-BushMozart-BeethovenVictoria-EdwardVIIKhrushchev-StalinMaryI(Scot)-ElizabethIJeﬀerson-JayBede-AugustineGeorgeV-EdwardVIIKamenev-TrotskyHenryVIII-ElizabethIJ.Q.Adams-ClayLeoX-JuliusIIVictoria-GeorgeVIZhouEnlai-MaoZedongTermsqueenrepublicanmusicroyalsovietenglishstateplayqueencommunistdaughterfederalistﬁlmbritishcentraldeathvotepianothroneunionthroneviceworkfatherfullTable3:IncontrasttoTable2,therelationshiptopicsshownherearemorespeciﬁctotimeandplace.Forexample,Englishmonarchpairs(Topic6)aredistinctfromBritishmonarchpairs(Topic9).Whilethereissomenoise(theBront¨esistersbeinglumpedinwithmideastleadersorAbuBakrandMuhammadwithcivilwargenerals),theserelationshiptopicsgroupsimilarpairsofentitieswell.AsocialnetworklabeledwiththeserelationshipsisshowninFigure1.llll101520−5.9−5.8−5.7−5.6−5.5−5.4biologicalWord Prediction Log Likelihoodllll101520−6.5−6.3−6.1−5.9biblellll101520−7.5−7.0−6.5wikipediallll101520−6.0−5.5−5.0−4.5−4.0Number of topicsEntity Prediction Log Likelihoodllll101520−6.5−6.0−5.5Number of topicsllll101520−7.0−6.0−5.0−4.0Number of topicslNubbi      Author−Topic           LDAUnigramMutualFigure4:PredictiveloglikelihoodasafunctionofthenumberofNubbitopicsontwotasks:entityprediction(giventhecontext,predictwhatentitiesarebeingdiscussed)andrelationprediction(giventheentities,predictwhatwordsoccur).Higherisbetter.alsobeaptlyassociatedwithsomeotherentitypair.5.DISCUSSIONANDRELATEDWORKWepresentedNubbi,anovelmachinelearningapproachforanalyzingfreetexttoextractdescriptionsofrelationshipsbetweenentities.WeappliedNubbitothreecorpora—theBible,Wikipedia,andscientiﬁcabstracts.WeshowedthatNubbiprovidesastate-of-the-artpredictivemodelofentitiesandrelationshipsand,moreover,isausefulexploratorytoolfordiscoveringandunderstandingnetworkdatahiddeninplaintext.Analyzingnetworksofentitieshasasubstantialhistory[33];recentworkhasfocusedinparticularonclusteringandcom-munitystructure[2,6,11,18,25],derivingmodelsforso-cialnetworks[15,16,19,31],andapplyingtheseanalysestopredictiveapplications[34].Latentvariableapproachestomodelingsocialnetworkswithassociatedtexthavealsobeenexplored[17,20,22,32].Whilethespaceofpotentialapplicationsforthesemodelsisrich,itistemperedbytheneedforobservednetworkdataasinput.Nubbiallowsthesetechniquestoaugmenttheirnetworkdatabyleveragingthelargebodyofrelationshipinformationencodedincollectionsoffreetext.Previousworkinthisveinhasusedeitherpattern-basedapproachesorco-occurrencemethods.Thepattern-basedapproaches[1,9,21,28]andsyntaxbasedapproaches[3,14]requirepatternsorparserswhicharemeticulouslyhand-crafted,oftenfragile,andtypicallyneedseveralexamplesofdesiredrelationshipslimitingthetypeofrelationshipsthatcanbediscovered.Incontrast,Nubbimakesminimalas-sumptionsabouttheinputtext,andisthuspracticalforlanguagesandnon-linguisticdatawhereparsingisnotavail-ableorapplicable.Co-occurrencemethods[7,8]alsomakeminimalassumptions.However,becauseNubbidrawsontopicmodeling[5],itisabletouncoverhiddenandseman-ticallymeaningfulgroupingsofrelationships.Throughthedistinctionbetweenrelationshiptopicsandentitytopics,itcanbettermodelthelanguageusedtodescriberelationships.Finally,whileothermodelshavealsoleveragedthema-chineryofLDAtounderstandensemblesofentitiesandthewordsassociatedwiththem[4,24,27]thesemodelsonlylearnhiddentopicsforindividualentities.Nubbimodelsindividualentitiesandpairsofentitiesdistinctly.Bycon-trollingforfeaturesofindividualentitiesandexplicitlyre-lationships,Nubbiyieldsmorepowerfulpredictivemodelsandcandiscoverricherdescriptionsofrelationships.6.ACKNOWLEDGEMENTSWewouldliketothankDavidPetrou,BillSchillit,CaseyWhitelaw,andRyanMacDonaldfortheiradviceandsup-portduringthedevelopmentofthiswork.WealsothanktheOﬃceofNavalResearchandGoogleforsupportingthiswork.7.REFERENCES[1]E.AgichteinandL.Gravano.Queryingtextdatabasesforeﬃcientinformationextraction.DataEngineering,InternationalConferenceon,0:113,2003.[2]A.Anagnostopoulos,R.Kumar,andM.Mahdian.Inﬂuenceandcorrelationinsocialnetworks.KDD2008,2008.[3]M.Banko,M.J.Cafarella,S.Soderland,M.Broadhead,andO.Etzioni.Openinformationextractionfromtheweb.InIJCAI2007,2007.[4]I.Bhattacharya,S.Godbole,andS.Joshi.Structuredentityidentiﬁcationanddocumentcategorization:Twotaskswithonejointmodel.KDD2008,2008.[5]D.Blei,A.Ng,andM.Jordan.LatentDirichletallocation.JournalofMachineLearningResearch,3:993–1022,2003.[6]D.Cai,Z.Shao,X.He,X.Yan,andJ.Han.Mininghiddencommunityinheterogeneoussocialnetworks.LinkKDD2005,Aug2005.[7]A.Culotta,R.Bekkerman,andA.McCallum.Extractingsocialnetworksandcontactinformationfromemailandtheweb.AAAI2005,2005.[8]D.Davidov,A.Rappoport,andM.Koppel.Fullyunsuperviseddiscoveryofconcept-speciﬁcrelationshipsbywebmining.InACL,2007.[9]C.Diehl,G.M.Namata,andL.Getoor.Relationshipidentiﬁcationforsocialnetworkdiscovery.InAAAI2007,July2007.[10]B.Efron.Estimatingtheerrorrateofapredictionrule:Improvementoncross-validation.JournaloftheAmericanStatisticalAssociation,78(382),1983.[11]D.Gibson,J.Kleinberg,andP.Raghavan.Inferringwebcommunitiesfromlinktopology.HYPERTEXT1998,May1998.[12]T.Hofmann.Probabilisticlatentsemanticindexing.SIGIR1999,1999.[13]M.I.Jordan,Z.Ghahramani,T.S.Jaakkola,andL.K.Saul.Anintroductiontovariationalmethodsforgraphicalmodels.Oct1999.[14]S.KatrenkoandP.Adriaans.Learningrelationsfrombiomedicalcorporausingdependencytrees.LectureNotesinComputerScience,2007.[15]J.Leskovec,L.Backstrom,R.Kumar,andA.Tomkins.Microscopicevolutionofsocialnetworks.KDD2008,2008.[16]J.Leskovec,K.Lang,A.Dasgupta,andM.Mahoney.Statisticalpropertiesofcommunitystructureinlargesocialandinformationnetworks.WWW2008,2008.[17]A.McCallum,A.Corrada-Emmanuel,andX.Wang.Topicandrolediscoveryinsocialnetworks.IJCAI2005,2005.[18]A.McGovern,L.Friedland,M.Hay,B.Gallagher,A.Fast,J.Neville,andD.Jensen.Exploitingrelationalstructuretounderstandpublicationpatternsinhigh-energyphysics.ACMSIGKDDExplorationsNewsletter,5(2),Dec2003.[19]E.Meeds,Z.Ghahramani,R.Neal,andS.Roweis.Modelingdyadicdatawithbinarylatentfactors.NIPS2007,2007.[20]Q.Mei,D.Cai,D.Zhang,andC.Zhai.Topicmodelingwithnetworkregularization.WWW2008,Apr2008.[21]Q.Mei,D.Xin,H.Cheng,J.Han,andC.Zhai.Semanticannotationoffrequentpatterns.KDD2007,1(3),2007.[22]R.Nallapati,A.Ahmed,E.P.Xing,andW.W.Cohen.Jointlatenttopicmodelsfortextandcitations.KDD2008,2008.[23]O.J.Nave.Nave’sTopicalBible.ThomasNelson,2003.[24]D.Newman,C.Chemudugunta,andP.Smyth.Statisticalentity-topicmodels.InKDD2006,pages680–686,NewYork,NY,USA,2006.ACM.[25]M.E.J.Newman.Modularityandcommunitystructureinnetworks.ProceedingsoftheNationalAcademyofSciences,103(23),2006.[26]T.Ohta,Y.Tateisi,andJ.-D.Kim.Geniacorpus:anannotatedresearchabstractcorpusinmolecularbiologydomain.InHLT2008,SanDiego,USA,2002.[27]M.Rosen-Zvi,T.Griﬃths,T.Griﬃths,M.Steyvers,andP.Smyth.Theauthor-topicmodelforauthorsanddocuments.InAUAI2004,pages487–494,Arlington,Virginia,UnitedStates,2004.AUAIPress.[28]S.Sahay,S.Mukherjea,E.Agichtein,E.Garcia,S.Navathe,andA.Ram.Discoveringsemanticbiomedicalrelationsutilizingtheweb.KDD2008,2(1),Mar2008.[29]M.SteyversandT.Griﬃths.Probabilistictopicmodels.HandbookofLatentSemanticAnalysis,2007.[30]L.Tanabe,N.Xie,L.H.Thom,W.Matten,andW.J.Wilbur.Genetag:ataggedcorpusforgene/proteinnamedentityrecognition.BMCBioinformatics,6Suppl1,2005.[31]B.Taskar,M.-F.Wong,P.Abbeel,andD.Koller.Linkpredictioninrelationaldata.NIPS2003,2003.[32]X.Wang,N.Mohanty,andA.McCallum.Groupandtopicdiscoveryfromrelationsandtext.Proceedingsofthe3rdinternationalworkshoponLinkdiscovery,2005.[33]S.WassermanandP.Pattison.Logitmodelsandlogisticregressionsforsocialnetworks:I.anintroductiontomarkovgraphsandp*.Psychometrika,1996.[34]D.Zhou,S.Zhu,K.Yu,X.Song,B.Tseng,H.Zha,andC.Giles.Learningmultiplegraphsfordocumentrecommendations.WWW2008,Apr2008.