how to grow a mind : statistics , structure , and abstraction joshua b .
tenenbaum
, 123 ( 123 ) ;
, et al .
this copy is for your personal , non - commercial use only .
if you wish to distribute this article to others colleagues , clients , or customers by
, you can order high - quality copies for your
permission to republish or repurpose articles or portions of articles following the guidelines
can be obtained by
the following resources related to this article are available online at www . sciencemag . org ( this infomation is current as of
march 123 , 123
updated information and services , version of this article at :
including high - resolution figures , can be found in the online
supporting online material
can be found at :
, 123 of which can be accessed free :
cites 123 articles
this article appears in the following
( print issn 123 - 123; online issn 123 - 123 ) is published weekly , except the last week in december , by the
american association for the advancement of science , 123 new york avenue nw , washington , dc 123
123 by the american association for the advancement of science; all rights reserved .
the title registered trademark of aaas .
how to grow a mind : statistics , structure , and abstraction
joshua b .
tenenbaum , 123* charles kemp , 123 thomas l .
griffiths , 123 noah d .
goodman123
in coming to understand the worldin learning concepts , acquiring language , and grasping causal relationsour minds make inferences that appear to go far beyond the data available .
how do we do it ? this review describes recent approaches to reverse - engineering human learning and cognitive development and , in parallel , engineering more humanlike machine learning systems .
computational models that perform probabilistic inference over hierarchies of flexibly structured representations can address some of the deepest questions about the nature and origins of human thought : how does abstract knowledge guide learning and reasoning from sparse data ? what forms does our knowledge take , across different domains and tasks ? and how is that abstract knowledge itself acquired ?
the challenge : how does the mind get so much from so little ?
for scientists studying how humans come
to understand their world , the central chal - lenge is this : how do our minds get so much from so little ? we build rich causal models , make strong generalizations , and construct pow - erful abstractions , whereas the input data are sparse , noisy , and ambiguousin every way far too limited .
a massive mismatch looms between the information coming in through our senses and the ouputs of cognition .
consider the situation of a child learning the meanings of words .
any parent knows , and sci - entists have confirmed ( 123 , 123 ) , that typical 123 - year - olds can learn how to use a new word such as horse or hairbrush from seeing just a few examples .
we know they grasp the meaning , not just the sound , because they generalize : they use the word appropriately ( if not always per - fectly ) in new situations .
viewed as a compu - tation on sensory input data , this is a remarkable feat .
within the infinite landscape of all possible objects , there is an infinite but still highly con - strained subset that can be called horses and another for hairbrushes .
how does a child grasp the boundaries of these subsets from seeing just one or a few examples of each ? adults face the challenge of learning entirely novel object concepts less often , but they can be just as good at it ( fig .
generalization from sparse data is central in learning many aspects of language , such as syn - tactic constructions or morphological rules ( 123 ) .
it presents most starkly in causal learning : every statistics class teaches that correlation does
123department of brain and cognitive sciences , computer sci - ence and artificial intelligence laboratory ( csail ) , massa - chusetts institute of technology , 123 massachusetts avenue , cambridge , ma 123 , usa .
123department of psychology , carnegie mellon university , pittsburgh , pa 123 , usa .
123de - partment of psychology , university of california , berkeley , berkeley , ca 123 , usa .
123department of psychology , stan - ford university , stanford , ca 123 , usa .
*to whom correspondence should be addressed .
e - mail :
not imply causation , yet children routinely in - fer causal links from just a handful of events ( 123 ) , far too small a sample to compute even a reli - able correlation ! perhaps the deepest accomplish - ment of cognitive development is the construction of larger - scale systems of knowledge : intuitive theories of physics , psychology , or biology or rule systems for social structure or moral judgment .
building these systems takes years , much longer than learning a single new word or concept , but on this scale too the final product of learning far outstrips the data observed ( 123 ) .
philosophers have inquired into these puz - zles for over two thousand years , most famously as the problem of induction , from plato and aristotle through hume , whewell , and mill to carnap , quine , goodman , and others in the 123th century ( 123 ) .
only recently have these questions become accessible to science and engineering by viewing inductive learning as a species of compu - tational problems and the human mind as a nat - ural computer evolved for solving them .
the proposed solutions are , in broad strokes , just what philosophers since plato have sug - gested .
if the mind goes beyond the data given , another source of information must make up the difference .
some more abstract background knowledge must generate and delimit the hypothe - ses learners consider , or meaningful generaliza - tion would be impossible ( 123 , 123 ) .
psychologists and linguists speak of constraints; machine learn - ing and artificial intelligence researchers , induc - tive bias; statisticians , priors .
this article reviews recent models of human learning and cognitive development arising at the intersection of these fields .
what has come to be known as the bayesian or probabilistic approach to reverse - engineering the mind has been heavily influenced by the engineering successes of intelligence and machine learning over the past two decades ( 123 , 123 ) and , in return , has begun to inspire more powerful and more humanlike approaches to machine learning .
as with connectionist or neural network models of cognition ( 123 ) in the 123s ( the last
moment when all these fields converged on a common paradigm for understanding the mind ) , the labels bayesian or probabilistic are mere - ly placeholders for a set of interrelated principles and theoretical claims .
the key ideas can be thought of as proposals for how to answer three
123 ) how does abstract knowledge guide learn -
ing and inference from sparse data ?
123 ) what forms does abstract knowledge take ,
across different domains and tasks ?
123 ) how is abstract knowledge itself acquired ?
we will illustrate the approach with a focus on two archetypal inductive problems : learning concepts and learning causal relations .
we then briefly discuss open challenges for a theory of hu - man cognitive development and conclude with a summary of the approachs contributions .
we will also draw contrasts with two earlier approaches to the origins of knowledge : nativism and associationism ( or connectionism .
these ap - proaches differ in whether they propose stronger or weaker capacities as the basis for answering the questions above .
bayesian models typically combine richly structured , expressive knowledge representations ( question 123 ) with powerful statis - tical inference engines ( questions 123 and 123 ) , arguing that only a synthesis of sophisticated approaches to both knowledge representation and inductive inference can account for human intelligence .
until recently it was not understood how this fusion could work computationally .
cognitive modelers were forced to choose between two alternatives ( 123 ) : powerful statistical learning operating over the simplest , unstructured forms of knowledge , such as matrices of associative weights in connec - tionist accounts of semantic cognition ( 123 , 123 ) , or richly structured symbolic knowledge equipped with only the simplest , nonstatistical forms of learning , checks for logical inconsistency between hypotheses and observed data , as in nativist ac - counts of language acquisition ( 123 ) .
it appeared necessary to accept either that peoples abstract knowledge is not learned or induced in a nontrivial sense from experience ( hence essentially innate ) or that human knowledge is not nearly as ab - stract or structured ( as knowledge - like ) as it seems ( hence simply associations ) .
many devel - opmental researchers rejected this choice alto - gether and pursued less formal approaches to describing the growing minds of children , under the headings of constructivism or the theory theory ( 123 ) .
the potential to explain how peo - ple can genuinely learn with abstract structured knowledge may be the most distinctive feature of bayesian models : the biggest reason for their recent popularity ( 123 ) and the biggest target of skepticism from their critics ( 123 ) .
the role of abstract knowledge over the past decade , many aspects of higher - level cognition have been illuminated by the
www . sciencemag . org science vol 123
123 march 123
mathematics of bayesian statistics : our sense of similarity ( 123 ) , representativeness ( 123 ) , and ran - domness ( 123 ) ; coincidences as a cue to hidden causes ( 123 ) ; judgments of causal strength ( 123 ) and evidential support ( 123 ) ; diagnostic and condi - tional reasoning ( 123 , 123 ) ; and predictions about the future of everyday events ( 123 ) .
the claim that human minds learn and rea - son according to bayesian principles is not a claim that the mind can implement any bayesian inference .
only those inductive computations that the mind is designed to perform well , where biology has had time and cause to engineer ef - fective and efficient mechanisms , are likely to
human children learning names for object concepts routinely make strong generalizations from just a few examples .
the same processes of rapid generalization can be studied in adults learning names for novel objects created with computer graphics .
( a ) given these alien objects and three examples ( boxed in red ) of tufas ( a word in the alien language ) , which other objects are tufas ? almost everyone selects just the objects boxed in gray ( 123 ) .
( b ) learning names for categories can be modeled as bayesian inference over a tree - structured domain representation ( 123 ) .
objects are placed at the leaves of the tree , and hypotheses about categories that words could label correspond to different branches .
branches at different depths pick out hypotheses at different levels of generality ( e . g . , clydesdales , draft horses , horses , animals , or living things ) .
priors are defined on the basis of branch length , reflecting the distinctiveness of categories .
likelihoods assume that examples are drawn randomly from the branch that the word labels , favoring lower branches that cover the examples tightly; this captures the sense of suspicious coincidence when all examples of a word cluster in the same part of the tree .
combining priors and likelihoods yields posterior probabilities that favor generalizing across the lowest distinctive branch that spans all the observed examples ( boxed in gray ) .
be understood in bayesian terms .
in addition to the general cognitive abilities just mentioned , bayesian analyses have shed light on many spe - cific cognitive capacities and modules that result from rapid , reliable , unconscious processing , in - cluding perception ( 123 ) , language ( 123 ) , memory ( 123 , 123 ) , and sensorimotor systems ( 123 ) .
in contrast , in tasks that require explicit conscious manipu - lations of probabilities as numerical quantitiesa recent cultural invention that few people become fluent with , and only then after sophisticated trainingjudgments can be notoriously biased away from bayesian norms ( 123 ) .
at heart , bayess rule is simply a tool for answering question 123 : how does abstract knowl - edge guide inference from incomplete data ? abstract knowledge is encoded in a probabilistic generative model , a kind of mental model that describes the causal processes in the world giv - ing rise to the learners observations as well as unobserved or latent variables that support ef - fective prediction and action if the learner can infer their hidden state .
generative models must be probabilistic to handle the learners uncertain - ty about the true states of latent variables and the true causal processes at work .
a generative model is abstract in two senses : it describes not only the specific situation at hand , but also a broader class of situations over which learning should generalize , and it captures in parsimonious form the essential world structure that causes learners observations and makes generalization possible .
bayesian inference gives a rational framework for updating beliefs about latent variables in gen - erative models given observed data ( 123 , 123 ) .
background knowledge is encoded through a constrained space of hypotheses h about pos - sible values for the latent variables , candidate world structures that could explain the observed data .
finer - grained knowledge comes in the prior probability p ( h ) , the learners degree of belief in a specific hypothesis h prior to ( or independent of ) the observations .
bayess rule updates priors to posterior probabilities p ( h|d ) conditional on the observed data d :
the posterior probability is proportional to the product of the prior probability and the likelihood p ( d|h ) , measuring how expected the data are under hypothesis h , relative to all other hypotheses h in h .
to illustrate bayess rule in action , suppose we observe john coughing ( d ) , and we consider three hypotheses as explanations : john has h123 , a cold; h123 , lung disease; or h123 , heartburn .
intuitively only h123 seems compelling .
bayess rule explains why .
the likelihood favors h123 and h123 over h123 : only colds and lung disease cause coughing and thus elevate the probability of the data above baseline .
the prior , in contrast , favors h123 and h123 over h123 : colds and heartburn are much more common than lung disease .
bayess rule weighs
123 march 123 vol 123 science www . sciencemag . org
hypotheses according to the product of priors and likelihoods and so yields only explanations like h123 that score highly on both terms .
the same principles can explain how people learn from sparse data .
in concept learning , the data might correspond to several example ob - jects ( fig .
123 ) and the hypotheses to possible ex - tensions of the concept .
why , given three examples of different kinds of horses , would a child gen - eralize the word horse to all and only horses ( h123 ) ? why not h123 , all horses except clydesdales; h123 , all animals; or any other rule consistent with the data ? likelihoods favor the more specific patterns , h123 and h123; it would be a highly suspi - cious coincidence to draw three random exam - ples that all fall within the smaller sets h123 or h123 if they were actually drawn from the much larger h123 ( 123 ) .
the prior favors h123 and h123 , because as more coherent and distinctive categories , they are more likely to be the referents of common words in language ( 123 ) .
only h123 scores highly on both terms .
likewise , in causal learning , the data could be co - occurences between events; the hypotheses , possible causal relations linking the events .
likelihoods favor causal links that make the co - occurence more probable , whereas priors favor links that fit with our background knowledge of what kinds of events are likely to cause which others; for example , a disease ( e . g . , cold ) is more likely to cause a symptom ( e . g . , coughing ) than the other way around .
the form of abstract knowledge abstract knowledge provides essential con - straints for learning , but in what form ? this is just question 123
for complex cognitive tasks such as concept learning or causal reasoning , it is im - possible to simply list every logically possible hy - pothesis along with its prior and likelihood .
some more sophisticated forms of knowledge repre - sentation must underlie the probabilistic gener - ative models needed for bayesian cognition .
in traditional associative or connectionist ap - proaches , statistical models of learning were de - fined over large numerical vectors .
learning was seen as estimating strengths in an associative mem - ory , weights in a neural network , or parameters of a high - dimensional nonlinear function ( 123 , 123 ) .
bayesian cognitive models , in contrast , have had most success defining probabilities over more structured symbolic forms of knowledge repre - sentations used in computer science and artificial intelligence , such as graphs , grammars , predicate logic , relational schemas , and functional programs .
different forms of representation are used to cap - ture peoples knowledge in different domains and tasks and at different levels of abstraction .
in learning words and concepts from exam - ples , the knowledge that guides both childrens and adults generalizations has been well de - scribed using probabilistic models defined over tree - structured representations ( fig .
123b ) ( 123 , 123 ) .
reasoning about other biological concepts for natural kinds ( e . g . , given that cows and rhinos have protein x in their muscles , how likely is it
that horses or squirrels do ? ) is also well described by bayesian models that assume nearby objects in the tree are likely to share properties ( 123 ) .
how - ever , trees are by no means a universal represen - tation .
inferences about other kinds of categories or properties are best captured by using proba - bilistic models with different forms ( fig .
123 ) : two - dimensional spaces or grids for reasoning about geographic properties of cities , one - dimensional orders for reasoning about values or abilities , or directed networks for causally transmitted proper - ties of species ( e . g . , diseases ) ( 123 ) .
knowledge about causes and effects more generally can be expressed in a directed graph - ical model ( 123 , 123 ) : a graph structure where nodes represent variables and directed edges between nodes represent probabilistic causal links .
in a medical setting , for instance ( fig .
123a ) , nodes might represent whether a patient has a cold , a cough , a fever or other conditions , and the pres - ence or absence of edges indicates that colds tend to cause coughing and fever but not chest pain; lung disease tends to cause coughing and chest pain but not fever; and so on .
such a causal map represents a simple kind of intuitive theory ( 123 ) , but learning causal net - works from limited data depends on the con - straints of more abstract knowledge .
for example , learning causal dependencies between medical conditions is enabled by a higher - level framework theory ( 123 ) specifying two classes of variables ( or nodes ) , diseases and symptoms , and the tendency for causal relations ( or graph edges ) to run from diseases to symptoms , rather than within these classes or from symptoms to diseases ( fig .
123 , a to c ) .
this abstract framework can be repre - sented by using probabilistic models defined over relational data structures such as graph schemas ( 123 , 123 ) , templates for graphs based on types of nodes , or probabilistic graph grammars ( 123 ) , similar in spirit to the probabilistic grammars for strings that have become standard for representing lin - guistic knowledge ( 123 ) .
at the most abstract lev - el , the very concept of causality itself , in the sense of a directed relationship that supports interven - tion or manipulation by an external agent ( 123 ) , can be formulated as a set of logical laws express - ing constraints on the structure of directed graphs relating actions and observable events ( fig .
each of these forms of knowledge makes different kinds of prior distributions natural to define and therefore imposes different constraints on induction .
successful generalization depends on getting these constraints right .
although in - ductive constraints are often graded , it is easiest to appreciate the effects of qualitative constraints that simply restrict the hypotheses learners can consider ( i . e . , setting priors for many logical possible hypotheses to zero ) .
for instance , in learning concepts over a domain of n objects , there are 123n subsets and hence 123n logically pos - sible hypotheses for the extension of a novel concept .
assuming concepts correspond to the branches of a specific binary tree over the ob - jects , as in fig .
123b , restricts this space to only
n 123 hypotheses .
in learning a causal network over 123 variables , there are roughly 123 logical - ly possible hypotheses ( directed acyclic graphs ) , but a framework theory restricting hypotheses to bipartite disease - symptom graphs reduces this to roughly 123 hypotheses .
knowing which var - iables belong to the disease and symptom classes further restricts this to roughly 123 networks .
the smaller the hypothesis space , the more ac - curately a learner can be expected to generalize , but only as long as the true structure to be learned remains within or near ( in a probabilistic sense ) the learners hypothesis space ( 123 ) .
it is no coin - cidence then that our best accounts of peoples mental representations often resemble simpler ver - sions of how scientists represent the same do - mains , such as tree structures for biological species .
a compact description that approximates how the grain of the world actually runs offers the most useful form of constraint on inductive learning .
the origins of abstract knowledge the need for abstract knowledge and the need to get it right bring us to question 123 : how do learners learn what they need to know to make learning possible ? how does a child know which tree structure is the right way to organize hypothe - ses for word learning ? at a deeper level , how can a learner know that a given domain of entities and concepts should be represented by using a tree at all , as opposed to a low - dimensional space or some other form ? or , in causal learning , how do people come to correct framework theories such as knowledge of abstract disease and symp - tom classes of variables with causal links from diseases to symptoms ?
the acquisition of abstract knowledge or new inductive constraints is primarily the province of cognitive development ( 123 , 123 ) .
for instance , children learning words initially assume a flat , mutually exclusive division of objects into name - able clusters; only later do they discover that cat - egories should be organized into tree - structured hierarchies ( fig .
123b ) ( 123 ) .
such discoveries are also pivotal in scientific progress : mendeleev launched modern chemistry with his proposal of a periodic structure for the elements .
linnaeus famously proposed that relationships between biological species are best explained by a tree structure , rather than a simpler linear order ( premodern europes great chain of being ) or some other form .
insights have long been viewed by psychologists and philosophers of science as deeply mysterious in their mecha - nisms , more magical than computational .
con - ventional algorithms for unsupervised structure discovery in statistics and machine learning hierarchical clustering , principal components anal - ysis , multidimensional scaling , clique detection assume a single fixed form of structure ( 123 ) .
un - like human children or scientists , they cannot learn multiple forms of structure or discover new forms in novel data .
neither traditional ap - proach to cognitive development has a fully satisfying response : nativists have assumed that ,
www . sciencemag . org science vol 123
123 march 123
salmon trout alligator
chain x chain
ring x chain
kemp and tenenbaum ( 123 ) showed how the form of structure in a domain can be discovered by using a hbm defined over graph gram - mars .
at the bottom level of the model is a data matrix d of objects and their properties , or similarities between pairs of objects .
each square of the matrix represents whether a given feature ( column ) is observed for a given object ( row ) .
one level up is the structure s , a graph of rela - tions between objects that describes how the features in d are distributed .
intuitively , objects nearby in the graph are expected to share similar feature values; technically , the graph laplacian parameterizes the inverse covariance of a gaussian distribution with one dimension per object , and each feature is drawn independently from that dis - tribution .
the highest level of abstract principles specifies the form f of structure in the domain , in terms of grammatical rules for growing a graph s of a constrained form out of an initial seed node .
red arrows repre - sent p ( s|f ) and p ( d|s ) , the condi - tional probabilities that each level specifies for the level below .
a search algorithm attempts to find both the form f and the structure s of that form that jointly maximize the posterior probability p ( s , f|d ) , a function of the product of p ( d|s ) and p ( s|f ) .
( a ) given as data the features of animals , the algorithm finds a tree structure with intuitively sensible categories at mul - tiple scales .
( b ) the same algorithm discovers that the voting patterns of u . s .
supreme court judges are best explained by a linear left - right spec - trum .
( c ) subjective similarities among colors are best explained by a circu - lar ring .
( d ) given proximities between cities on the globe , the algorithm dis - covers a cylindrical representation analogous to latitude and longitude : the cross product of a ring and a ring .
( e ) given images of realistically synthesized faces varying in two di - mensions , race and masculinity , the algorithm successfully recovers the un - derlying two - dimensional grid struc - ture : a cross product of two chains .
if different domains of cognition are represented in qualitatively different ways , those forms must be innate ( 123 , 123 ) ; connectionists have suggested these representations may be learned but in a generic system of associative weights that at best only approximates trees , causal networks , and other forms of structure people appear to know explicitly ( 123 ) .
recently cognitive modelers have begun to answer these challenges by combining the struc - tured knowledge representations described above with state - of - the - art tools from bayesian statis -
hierarchical bayesian models ( hbms ) ( 123 ) address the origins of hypothesis spaces and priors by positing not just a single level of hypotheses to explain the data but multiple levels : hypoth - esis spaces of hypothesis spaces , with priors on priors .
each level of a hbm generates a proba - bility distribution on variables at the level below .
bayesian inference across all levels allows hypothe - ses and priors needed for a specific learning task to themselves be learned at larger or longer time scales , at the same time as they constrain lower - level learn -
in machine learning and artificial intelligence ( ai ) , hbms have primarily been used for transfer learning : the acquisition of inductive constraints from experience in previous related tasks ( 123 ) .
transfer learning is critical for humans as well ( som text and figs .
s123 and s123 ) , but here we focus on the role of hbms in explaining how people acquire the right forms of abstract knowledge .
kemp and tenenbaum ( 123 , 123 ) showed how hbms defined over graph - and grammar - based representations can discover the form of structure
123 march 123 vol 123 science www . sciencemag . org
' dis e a s e s ' ' s y m
123 123 123 123 123 123 123
123 123 123 123 123 123
123 123 123 123 123 123 123 123 123 123
n = 123
n = 123
n = 123
n = 123
hbms defined over graph schemas can explain how intuitive theories are acquired and used to learn about specific causal relations from limited data ( 123 ) .
( a ) a simple medical reasoning domain might be described by relations among 123 variables : the first six encode presence or absence of diseases ( top row ) , with causal links to the next 123 symptoms ( bottom row ) .
this network can also be visualized as a matrix ( top right , links shown in black ) .
the causal learning task is to reconstruct this network based on observing data d on the states of these 123 variables in a set of patients .
( b ) a two - level hbm formalizes bottom - up causal learning or learning with an uninformative prior on networks .
the bottom level is the data matrix d .
the second level ( structure ) encodes hypothesized causal networks : a grayscale matrix visualizes the posterior probability that each pairwise causal link exists , conditioned on observing n patients; compare this matrix with the black - and - white ground truth matrix shown in ( a ) .
the true causal network can be recovered perfectly only from observing very many patients ( n = 123; not shown ) .
with n = 123 , spurious links ( gray squares ) are inferred , and with n = 123 almost none of the true structure is detected .
( c ) a three - level nonparametric hbm ( 123 ) adds a level of abstract principles , represented by a graph schema .
the schema encodes a prior on the level below ( causal network structure ) that constrains and thereby accelerates causal learning .
both schema and network structure are learned from the same data observed in ( b )
schema discovers the disease - symptom framework theory by assigning var - iables 123 to 123 to class c123 , variables 123 to 123 to class c123 , and a prior favoring only c123 c123 links .
these assignments , along with the effective number of classes ( here , two ) , are inferred automatically via the bayesian occam ' s razor .
although this three - level model has many more degrees of freedom than the model in ( b ) , learning is faster and more accurate .
with n = 123 patients , the causal network is identified near perfectly .
even n = 123 patients are sufficient to learn the high - level c123 c123 schema and thereby to limit uncertainty at the network level to just the question of which diseases cause which symptoms .
( d ) a hbm for learning an abstract theory of causality ( 123 ) .
at the highest level are laws expressed in first - order logic representing the abstract properties of causal relationships , the role of exogenous interventions in defining the direction of causality , and features that may mark an event as an exogenous intervention .
these laws place constraints on possible directed graphical models at the level below , which in turn are used to explain patterns of observed events over variables .
given observed events from several different causal systems , each encoded in a distinct data matrix , and a hypothesis space of possible laws at the highest level , the model converges quickly on a correct theory of intervention - based causality and uses that theory to constrain inferences about the specific causal networks underlying the different systems at the level below .
governing similarity in a domain .
structures of different formstrees , clusters , spaces , rings , orders , and so oncan all be represented as graphs , whereas the abstract principles under - lying each form are expressed as simple gram - matical rules for growing graphs of that form .
embedded in a hierarchical bayesian frame - work , this approach can discover the correct forms of structure ( the grammars ) for many real - world domains , along with the best struc -
ture ( the graph ) of the appropriate form ( fig .
in particular , it can infer that a hierarchical organization for the novel objects in fig .
123a ( such as fig .
123b ) better fits the similarities peo - ple see in these objects , compared to alternative representations such as a two - dimensional space .
hierarchical bayesian models can also be used to learn abstract causal knowledge , such as the framework theory of diseases and symp - toms ( fig .
123 ) , and other simple forms of intui -
tive theories ( 123 ) .
mansinghka et al .
( 123 ) showed how a graph schema representing two classes of variables , diseases and symptoms , and a pref - erence for causal links running from disease to symptom variables can be learned from the same data that support learning causal links be - tween specific diseases and symptoms and be learned just as fast or faster ( fig .
123 , b and c ) .
the learned schema in turn dramatically accel - erates learning of specific causal relations ( the
www . sciencemag . org science vol 123
123 march 123
directed graph structure ) at the level below .
getting the big picture firstdiscovering that diseases cause symptoms before pinning down any specific disease - symptom linksand then us - ing that framework to fill in the gaps of specific knowledge is a distinctively human mode of learn - ing .
it figures prominently in childrens develop - ment and scientific progress but has not previously fit into the landscape of rational or statistical lear -
although this hbm imposes strong and valuable constraints on the hypothesis space of causal networks , it is also extremely flexible : it can discover framework theories defined by any number of variable classes and any pattern of pairwise regularities on how variables in these classes tend to be connected .
not even the number of variable classes ( two for the disease - symptom theory ) need be known in advance .
this is enabled by another state - of - the - art bayesian tool , known as infinite or nonparametric hier - archical modeling .
these models posit an un - bounded amount of structure , but only finitely many degrees of freedom are actively engaged for a given data set ( 123 ) .
an automatic occams razor embodied in bayesian inference trades off model complexity and fit to ensure that new structure ( in this case , a new class of variables ) is introduced only when the data truly require it .
the specific nonparametric distribution on node classes in fig .
123c is a chinese restaurant process ( crp ) , which has been particularly in - fluential in recent machine learning and cogni - tive modeling .
crp models have given the first principled account of how people form new categories without direct supervision ( 123 , 123 ) : as each stimulus is observed , crp models ( guided by the bayesian occams razor ) infer whether that object is best explained by assimilation to an existing category or by positing a previously unseen category ( fig .
the crosscat mod - el extends crps to carve domains of objects and their properties into different subdomains or views , subsets of properties that can all be explained by a distinct way of organizing the objects ( 123 ) ( fig .
crps can be embedded in probabilistic models for language to explain how children discover words in unsegmented speech ( 123 ) , learn morphological rules ( 123 ) , and organize word meanings into hierarchical semantic networks ( 123 , 123 ) ( fig .
a related but novel nonparametric construction , the indian buffet process ( ibp ) , explains how new percep - tual features can be constructed during object categorization ( 123 , 123 ) .
more generally , nonparametric hierarchical models address the principal challenge human learners face as knowledge grows over a life - time : balancing constraint and flexibility , or the need to restrict hypotheses available for gener - alization at any moment with the capacity to expand ones hypothesis spaces , to learn new ways that the world could work .
placing non - parametric distributions at higher levels of the hbm yields flexible inductive biases for lower
levels , whereas the bayesian occams razor en - sures the proper balance of constraint and flex - ibility as knowledge grows .
across several case studies of learning abstract knowledgediscovering structural forms , caus - al framework theories , and other inductive con - straints acquired through transfer learningit has been found that abstractions in hbms can be learned remarkably fast from relatively little data compared with what is needed for learning at lower levels .
this is because each degree of freedom at a higher level of the hbm influences and pools evidence from many variables at lev - els below .
we call this property of hbms the blessing of abstraction .
it offers a top - down route to the origins of knowledge that contrasts sharply with the two classic approaches : nativ - ism ( 123 , 123 ) , in which abstract concepts are as - sumed to be present from birth , and empiricism or associationism ( 123 ) , in which abstractions are constructed but only approximately , and only slowly in a bottom - up fashion , by layering many experiences on top of each other and filtering out their common elements .
only hbms thus seem suited to explaining the two most striking features of abstract knowledge in humans : that it can be learned from experience , and that it can be engaged remarkably early in life , serving to constrain more specific learning tasks .
hbms may answer some questions about the origins of knowledge , but they still leave us wondering : how does it all start ? developmen - talists have argued that not everything can be learned , that learning can only get off the ground with some innate stock of abstract concepts such as agent , object , and cause to provide the basic ontology for carving up experience ( 123 , 123 ) .
surely some aspects of mental representation are innate , but without disputing this bayesian modelers have recently argued that even the most abstract concepts may in principle be learned .
for instance , an abstract concept of causality expressed as logical constraints on the structure of directed graphs can be learned from experience in a hbm that generalizes across the network structures of many specific causal systems ( fig .
following the blessing of abstraction , these constraints can be induced from only small samples of each networks behavior and in turn enable more ef - ficient causal learning for new systems ( 123 ) .
how this analysis extends to other abstract concepts such as agent or object and whether children ac - tually acquire these concepts in such a manner re - main open questions .
although hbms have addressed the acqui - sition of simple forms of abstract knowledge , they have only touched on the hardest subjects of cognitive development : framework theories for core common - sense domains such as intui - tive physics , psychology , and biology ( 123 , 123 , 123 ) .
first steps have come in explaining develop - ing theories of mind , how children come to understand explicit false beliefs ( 123 ) and in -
