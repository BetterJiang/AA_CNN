pedestrian detection is a problem of considerable prac - tical interest .
adding to the list of successful applications of deep learning methods to vision , we report state - of - the - art and competitive results on all major pedestrian datasets with a convolutional network model .
the model uses a few new twists , such as multi - stage features , connections that skip layers to integrate global shape information with local distinctive motif information , and an unsupervised method based on convolutional sparse coding to pre - train the lters at each stage .
pedestrian detection is a key problem for surveillance , automotive safety and robotics applications .
the wide vari - ety of appearances of pedestrians due to body pose , occlu - sions , clothing , lighting and backgrounds makes this task
all existing state - of - the - art methods use a combination of hand - crafted features such as integral channel fea - tures ( 123 ) , hog ( 123 ) and their variations ( 123 , 123 ) and com - binations ( 123 ) , followed by a trainable classier such as svm ( 123 , 123 ) , boosted classiers ( 123 ) or random forests ( 123 ) .
while low - level features can be designed by hand with good success , mid - level features that combine low - level features are difcult to engineer without the help of some sort of learning procedure .
multi - stage recognizers that learn hier - archies of features tuned to the task at hand can be trained end - to - end with little prior knowledge .
convolutional net - works ( convnets ) ( 123 ) are examples of such hierarchical systems with end - to - end feature learning that are trained in a supervised fashion .
recent works have demonstrated the usefulness of unsupervised pre - training for end - to - end training of deep multi - stage architectures using a variety of techniques such as stacked restricted boltzmann ma - chines ( 123 ) , stacked auto - encoders ( 123 ) and stacked sparse auto - encoders ( 123 ) , and using new types of non - linear trans - forms at each layer ( 123 , 123 ) .
123 - 123 / 123 $123 123 ieee 123 - 123 / 123 $123 123 ieee 123 - 123 / 123 $123 123 ieee
figure 123 : 123 123 123 lters trained on grayscale inria im - ages using algorithm 123
it can be seen that in addition to edge detectors at multiple orientations , our systems also learns more complicated features such as corner and junction detectors .
supervised convnets have been used by a number of au - thors for such applications as face , hand detection ( 123 , 123 , 123 , 123 , 123 , 123 ) .
more recently , a large convnet by ( 123 ) achieved a breakthrough on a 123 - class imagenet detec - tion task .
the main contribution of this paper is to show that the convnet model , with a few important twists , con - sistently yields state of the art and competitive results on all major pedestrian detection benchmarks .
the system uses unsupervised convolutional sparse auto - encoders to pre - train features at all levels from the relatively small in - ria dataset ( 123 ) , and end - to - end supervised training to train the classier and ne - tune the features in an integrated fash - ion .
additionally , multi - stage features with layer - skipping connections enable output stages to combine global shape detectors with local motif detectors .
processing speed in pedestrian detection has recently seen great progress , enabling real - time operation with - out sacricing quality .
( 123 ) manage to entirely avoid image rescaling for detection while observing quality improve - ments .
while processing speed is not the focus of this pa - per , features and classier approximations introduced by ( 123 ) and ( 123 ) may be applicable to deep learning models for faster detection , in addition to gpu optimizations .
learning feature hierarchies
much of the work on pedestrian detection have focused on designing representative and powerful features ( 123 , 123 , 123 , 123 ) .
in this work , we show that generic feature learning al - gorithms can produce successful feature extractors that can achieve state - of - the - art results .
supervised learning of end - to - end systems on images have been shown to work well when there is abundant la - beled samples ( 123 ) , including for detection tasks ( 123 , 123 , 123 , 123 , 123 , 123 ) .
however , for many input domains , it is hard to nd adequate number of labeled data .
in this case , one can resort to designing useful features by using domain knowledge , or an alternative way is to use unsupervised learning algorithms .
recently unsupervised learning algo - rithms have been demonstrated to produce good features for generic object recognition problems ( 123 , 123 , 123 , 123 ) .
in ( 123 ) , it was shown that unsupervised learning can be used to train deep hierarchical models and the nal repre - sentation achieved is actually useful for a variety of differ - ent tasks ( 123 , 123 , 123 ) .
in this work , we also follow a similar approach and train a generic unsupervised model at each layer using the output representation from the layer before .
this process is then followed by supervised updates to the whole hierarchical system using label information .
figure 123 : a subset of 123 123 second layer lters trained on grayscale inria images using algorithm 123
each row in the g - ure shows lters that connect to a common output feature map .
it can be seen that they extract features at similar locations and shapes , e . g .
the bottom row tends to aggregate horizontal features towards the bottom of the lters .
hierarchical model
a hierarchical feature extraction system consists of mul - tiple levels of feature extractors that perform the same l - tering and non - linear transformation functions in successive layers .
using a particular generic parametrized function one can then map the inputs into gradually more higher level ( or abstract ) representations ( 123 , 123 , 123 , 123 , 123 ) .
in this work we use sparse convolutional feature hierarchies as proposed in ( 123 ) .
each layer of the unsupervised model contains a convolutional sparse coding algorithm and a predictor func - tion that can be used for fast inference .
after the last layer
a classier is used to map the feature representations into class labels .
both the sparse coding dictionary and the pre - dictor function do not contain any hard - coded parameter and are trained from the input data .
the training procedure for this model is similar to ( 123 ) .
each layer is trained in an unsupervised manner using the representation from previous layer ( or the input image for the initial layer ) separately .
after the whole multi - stage sys - tem is trained in a layer - wise fashion , the complete architec - ture followed by a classier is ne - tuned using labeled data .
unsupervised learning
recently sparse coding has seen much interest in many elds due to its ability to extract useful feature representa - tions from data , the general formulation of sparse coding is a linear reconstruction model using an overcomplete dictio - nary d rmn where m > n and a regularization penalty on the mixing coefcients z rn .
= arg min
123 + s ( z )
the aim is to minimize equation 123 with respect to z to obtain the optimal sparse representation z that correspond to input x rm .
the exact form of s ( z ) depends on the particular sparse coding algorithm that is used , here , we use the ( cid : 123 ) . ( cid : 123 ) 123 norm penalty , which is the sum of the absolute values of all elements of z .
it is immediately clear that the solution of this system requires an optimization process .
many efcient algorithms for solving the above convex system has been proposed in recent years ( 123 , 123 , 123 , 123 ) .
however , our aim is to also learn generic feature extractors .
for that reason we minimize equation 123 wrt d too .
, d = arg min
123 + ( cid : 123 ) z ( cid : 123 ) 123
this resulting equation is non - convex in d and z at the same time , however keeping one xed , the problem is still convex wrt to the other variable .
all sparse modeling algorithms that adopt the dictionary matrix d exploit this property and perform a coordinate descent like minimization pro - cess where each variable is updated in succession .
follow - ing ( 123 ) many authors have used sparse dictionary learning to represent images ( 123 , 123 , 123 ) .
however , most of the sparse coding models use small image patches as input x to learn the dictionary d and then apply the resulting model to every overlapping patch location on the full image .
this approach assumes that the sparse representation for two neighboring patches with a single pixel shift is completely independent , thus produces very redundant representations .
( 123 , 123 ) have introduced convolutional sparse modeling formulations for feature learning and object recognition and we use the con - volutional predictive sparse decomposition ( cpsd ) model proposed in ( 123 ) since it is the only convolutional sparse coding model providing a fast predictor function that is suit - able for building multi - stage feature representations
particular predictor function we use is similar to a single layer convnet of the following form :
f ( x; g , k , b ) = z = ( zj ) j=123 . n
zj = gj tanh ( x kj + bj )
where operator represents convolution operator that ap - plies on a single input and single lter .
in this formulation x is a p p grayscale input image , k rnmm is a set of 123d lters where each lter is kj rmm , g rn and b rn are vectors with n elements , the predictor output npm+123pm+123 is a set of feature maps where each of zj is of size p m + 123 p m + 123
considering this gen - eral predictor function , the nal form of the convolutional unsupervised energy for grayscale inputs is as follows :
ecp sd = econvsc + ep red
ep red = ( cid : 123 ) z
f ( x; g , k , b ) ( cid : 123 ) 123
where d is a dictionary of lters the same size as k and is a hyper - parameter .
the unsupervised learning proce - dure is a two step coordinate descent process .
at each it - eration , ( 123 ) inference : the parameters w = ( d , g , k , b ) are kept xed and equation 123 is minimized to obtain the optimal sparse representation z , ( 123 ) update : keeping z xed , the parameters w updated using a stochastic gradi - ent step : w w w where is the learning rate parameter .
the inference procedure requires us to carry out the sparse coding problem solution .
for this step we use the fista method proposed in ( 123 ) .
this method is an ex - tension of the original iterative shrinkage and thresholding algorithm ( 123 ) using an improved step size calculation with a momentum - like term .
we apply the fista algorithm in the image domain adopting the convolutional formulation .
for color images or other multi - modal feature represen - tations , the input x is a set of feature maps indexed by i and the representation z is a set of feature maps indexed by j for each input map i .
we dene a map of connections p th output feature map is con - from input x to features z .
a j nected to a set pj of input feature maps .
thus , the predictor function in algorithm 123 is dened as :
zj = gj tanh
( xi kj , i ) + bj
and the reconstruction is computed using the inverse map
123 + ( cid : 123 ) z ( cid : 123 ) 123
for a fully connected layer , all the input features are con - nected to all the output features , however it is also common
to use sparse connection maps to reduce the number of pa - rameters .
the online training algorithm for unsupervised training of a single layer is :
algorithm 123 single layer unsupervised training .
function unsup ( x , d , p , ( , ) , ( g , k , b ) , )
set : f ( x; g , k , b ) from eqn 123 , w initialize : z = , d and w
p = ( g , k , b ) .
perform inference , minimize equation 123 wrt z using do a stochastic update on d and w
return : ( d , g , k , b )
non - linear transformations
once the unsupervised learning for a single stage is com - pleted , the next stage is trained on the feature representation from the previous one .
in order to obtain the feature repre - sentation for the next stage , we use the predictor function f ( x ) followed by non - linear transformations and pooling .
following the multi - stage framework used in ( 123 ) , we ap - ply absolute value rectication , local contrast normalization and average down - sampling operations .
absolute value rectication is applied component - wise to the whole feature output from f ( x ) in order to avoid cancel - lation problems in contrast normalization and pooling steps .
local contrast normalization is a non - linear process that enhances the most active feature and suppresses the other ones .
the exact form of the operation is as follows :
vi = xi xi w , =
where i is the feature map index and w is a 123 123 gaus - sian weighting function with normalized weights so that ipq wpq = 123
for each sample , the constant c is set to
mean ( ) in the experiments .
average down - sampling operation is performed using a xed size boxcar kernel with a certain step size .
the size of the kernel and the stride are given for each experiment in the following sections .
once a single layer of the network is trained , the features for training a successive layer is extracted using the predic - tor function followed by non - linear transformations .
de - tailed procedure of training an n layer hierarchical model is explained in algorithm 123
the rst layer features can be easily displayed in the pa - rameter space since the parameter space and the input space is same , however visualizing the second and higher level features in the input space can only be possible when only
algorithm 123 multi - layer unsupervised training .
function hierarunsup ( x , ni , mi , pi , ( i , i ) , ( wi , si ) , i = ( 123 . n ) , i )
set : i = 123 , x123 = x , lcn ( x ) using equations 123 - 123 , ds ( x , w , s ) as the down - sampling operator using box - car kernel of size w w and stride of size s in both
set : di , ki rnimimi , gi , bi rni .
( di , ki , gi , ki , bi ) =
u nsup ( xi , di , pi , ( i , i ) , ( gi , ki , bi ) , i )
z = f ( xi; gi , ki , bi ) using equation 123
z = |z| z = lcn ( z ) xi+123 = ds ( z , wi , si ) i = i + 123 until i = n
figure 123 : a multi - scale convolutional network .
the top row of maps constitute a regular convnet ( 123 ) .
the bottom row in which the 123st stage output is branched , subsampled again and merged into the classier input provides a multi - stage component to the classier stage .
the multi - stage fea - tures coming out of the 123nd stage extracts a global structure as well as local details .
invertible operations are used in between layers .
however , since we use absolute value rectication and local contrast normalization operations mapping the second layer features onto input space is not possible .
in figure 123 we show a sub - set of 123 second layer features in the parameter space .
supervised training
after the unsupervised learning of the hierarchical fea - ture extraction system is completed using algorithm 123 , we append a classier function , usually in the form of a linear logistic regression , and perform stochastic online training using labeled data .
multi - stage features
convnets are usually organized in a strictly feed - forward manner where one layer only takes the output of the previous layer as input .
features extracted this way tend to be high level features after a few stages of convolutions
and subsampling .
by branching lower levels outputs into the top classier ( fig .
123 ) , one produces features that extract both global shapes and structures and local details , such as a global silhouette and face components in the case of hu - man detection .
contrary to ( 123 ) , the output of the rst stage is branched after the non - linear transformations and pool - ing / subsampling operations rather than before .
we also use color information on the training data .
for this purpose we convert all images into yuv image space and subsample the uv features by 123 since color information is in much lower resolution .
then at the rst stage , we keep feature extraction systems for y and uv channels separate .
on the y channel , we use 123 123 123 features followed by ab - solute value rectication , contrast normalization and 123 123 subsampling .
on the subsampled uv channels , we extract 123 123 123 features followed by absolute value rectication and contrast normalization , skipping the usual subsampling step since it was performed beforehand .
these features are then concatanated to produce 123 feature maps that are input to the rst layer .
the second layer feature extraction takes 123 feature maps and produces 123 output features using 123 123 123 features .
a randomly selected 123% of the connec - tions in mapping from input features to output features is removed to limit the computational requirements and break the symmetry ( 123 ) .
the output of the second layer features are then transformed using absolute value rectication and contrast normalization followed by 123 123 subsampling .
this results in 123 dimensional feature vector for each sample which is then fed into a linear classier .
in table 123 , we show that multi - stage features improve ac - curacy for different tasks , with different magnitudes .
great - est improvements are obtained for pedestrian detection and trafc - sign classication while only minimal gains are ob - tained for house numbers classication , a less complex task .
bootstrapping is typically used in detection settings by multiple phases of extracting the most offending negative answers and adding these samples to the existing dataset while training .
for this purpose , we extract 123 nega - tive samples per bootstrapping pass and limit the number of most offending answers to 123 for each image .
we perform 123 bootstrapping passes in addition to the original training phase ( i . e .
123 training passes in total ) .
non - maximum suppression
non - maximum suppression ( nms ) is used to resolve conicts when several bounding boxes overlap .
for both inria and caltech experiments we use the widely accepted pascal overlap criteria to determine a matching score be - tween two bounding boxes ( intersection ) and if two boxes overlap by more than 123% , only the one with the highest score is kept .
in ( 123 ) s addendum , the matching criteria is modied by replacing the union of the two boxes with the minimum of the two .
therefore , if a box is fully contained in another one the small box is selected .
the goal for this
single - stage features multi - stage features
pedestrians detection ( inria ) ( fig
trafc signs classication ( gtsrb ) ( 123 ) house numbers classication ( svhn ) ( 123 )
table 123 : error rates improvements of multi - stage features over single - stage features for different types of objects detection and classication .
improvements are signicant for multi - scale and textured objects such as trafc signs and pedestrians but minimal for house
modication is to avoid false positives that are due to pedes - trian body parts .
however , a drawback to this approach is that it always disregards one of the overlapping pedes - trians from detection .
instead of changing the criteria , we actively modify our training set before each bootstrapping phase .
we include body part images that cause false posi - tive detection into our bootstrapping image set .
our model can then learn to suppress such responses within a positive window and still detect pedestrians within bigger windows
we evaluate our system on 123 standard pedestrian de - tection datasets .
however , like most other systems , we only train on the inria dataset .
we also demonstrate im - provements brought by unsupervised training and multi - stage features .
in the following we name our model con - vnet with variants of unsupervised ( convnet - u ) and fully - supervised training ( convnet - f ) and multi - stage features ( convnet - u - ms and convnet - f - ms ) .
data preparation
is trained on the inria pedestrian dataset ( 123 ) .
pedestrians are extracted into windows of 123 pixels in height and 123 pixels in width .
the context ratio is 123 , i . e .
pedestrians are 123 pixels high and the remaining 123 pixels correspond to the background .
each pedestrian image is mirrored along the horizontal axis to expand the dataset .
similarly , we add 123 variations of each original sam - ple using 123 random deformations such as translations and scale .
translations range from - 123 to 123 pixels and scale ratios from 123 to 123 .
these deformations enforce invariance to small deformations in the input .
the range of each de - formation determines the trade - off between recognition and localization accuracy during detection .
an equal amount of background samples are extracted at random from the negative images and taking approximately 123% of the ex - tracted samples for validation yields a validation set with 123 samples and training set with 123 samples .
note that the unsupervised training phase is performed on this initial data before the bootstrapping phase .
evaluation protocol
sampled .
the up - sampling ratio is 123 while the sub - sampling ratio is limited by 123 times the networks mini - mum input ( 123 ) .
we use a scale stride of 123 between each scale , while other methods typically use either 123 or 123 ( 123 ) .
a higher scale stride is desirable as it implies less
for evaluation we use the bounding boxes les published on the caltech pedestrian website 123 and the evaluation soft - ware provided by piotr dollar ( version 123 . 123 ) .
in an ef - fort to provide a more accurate evaluation , we improved on both the evaluation formula and the inria annotations as follows .
the evaluation software was slightly modied to compute the continuous area under curve ( auc ) in the entire ( 123 , 123 ) range rather than from 123 discrete points only ( 123 , 123 , 123 , 123 , 123 , 123 , 123 , 123 and 123 in version 123 . 123 ) .
instead , we compute the entire area under the curve by summing the areas under the piece - wise linear interpolation of the curve , between each pair of points .
in addition , we also report a xed version of the annotations for inria dataset , which has missing positive labels .
the added labels are only used to avoid counting false errors and wrongly penalizing algorithms .
the modi - ed code and extra inria labels are available at 123
table 123 reports results for both original and xed inria datasets .
notice that the continuous auc and xed inria annota - tions both yield a reordering of the results ( see supplemen - tary material for further evidence that the impact of these modications is signicant enough to be used ) .
to avoid ambiguity , all results with the original discrete auc are re - ported in the supplementary paper .
to ensure a fair comparison , we separated systems trained on inria ( the majority ) from systems trained on tud - motionpairs and the only system trained on caltech in table 123
for clarity , only systems trained on inria were represented in figure 123 , however all results for all systems are still reported in table 123
in figure 123 , we plot det curves , i . e .
miss rate ver - sus false positives per image ( fppi ) , on the xed inria dataset and rank algorithms along two measures : ror rate at 123 fppi and the area under curve ( auc ) rate in the ( 123 , 123 ) fppi range .
this graph shows the indi -
during testing and bootstrapping phases using the in - the images are both up - sampled and sub -
false positives per image
false positives per image
figure 123 : det curves on the xed - inria dataset for large pedestrians measure report false positives per image ( fppi ) against miss rate .
algorithms are sorted from top to bottom using the proposed continuous area under curve measure between 123 and 123 fppi .
on the right , only the convnet variants are displayed to highlight the individual contributions of unsupervised learning ( convnet - u ) and multi - stage features learning ( convnet - f - ms ) and their combination ( convnet - u - ms ) compared to the fully - supervised system without multi - stage features ( convnet - f ) .
vidual contributions of unsupervised learning ( convnet - u ) and multi - stage features learning ( convnet - f - ms ) and their combination ( convnet - u - ms ) compared to the fully - supervised system without multi - stage features ( convnet - f ) .
with 123% error rate , unsupervised learning exhibits the most improvements compared to the baseline convnet - f ( 123% ) .
multi - stage features without unsupervised learning reach 123% error while their combination yields the competitive error rate of 123% .
extensive results comparison of all major pedestrian datasets and published systems is provided in table 123
mul - tiple types of measures proposed by ( 123 ) are reported .
for clarity , we also plot in figure 123 two of these measures , reasonable and large , for inria - trained systems .
the large plot shows that the convnet results in state - of - the - art performance with some margin on the eth , caltech and tudbrussels datasets and is closely behind latsvm - v123 and veryfast for inria and daimler datasets .
in the reason - able plot , the convnet yields competitive results for in - ria , daimler and eth datasets but performs poorly on the caltech dataset .
we suspect the convnet with multi - stage features trained at high - resolution is more sensitive to reso - lution loss than other methods .
in future work , a convnet trained at multiple resolution will likely learn to use appro - priate cues for each resolution regime .
