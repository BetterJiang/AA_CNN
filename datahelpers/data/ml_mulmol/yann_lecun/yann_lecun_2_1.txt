performance object recognition are composed of two main stages : a feature extraction stage that extracts locally - feature vectors from regularly spaced image patches , and a somewhat generic supervised classier .
the rst stage is often composed of three main modules : ( 123 ) a bank of lters ( often oriented edge detectors ) ; ( 123 ) a non - linear transform , such as a point - wise squashing functions , quantization , or normalization; ( 123 ) a spatial pooling operation which combines the outputs of similar lters over neighboring regions .
we propose a method that automatically learns such feature extractors in an unsupervised fashion by simultaneously learning the lters and the pooling units that combine multiple lter outputs together .
the method automatically generates topographic maps of similar lters that extract features of orientations , scales , and positions .
these similar lters are pooled together , producing locally - invariant outputs .
the learned feature descriptors give comparable results as sift on image recognition tasks for which sift is well suited , and better results than sift on tasks for which sift is less well
a crucially important component of every recognition system is the feature extractor .
much of the recent propos - als for object recognition systems are based on feature de - scriptors extracted from local patches placed at regularly - spaced grid - points on the image ( 123 , 123 , 123 , 123 , 123 ) .
the most successful and most commonly - used descriptors such as sift and hog ( 123 , 123 ) are designed to be invariant ( or ro - bust ) to minor transformations of the input , such as transla - tions , rotations , and other afne transforms and distortions .
the present paper proposes a new method to automatically learn locally - invariant feature descriptors from data in an unsupervised manner .
while good descriptors have been devised for grayscale image recognition , the design of good
descriptors for other types of input data is a complex task .
the ability to learn the features would allow us to auto - matically construct good descriptors for new image types ( e . g .
multispectral images , range images ) , and for other in - put modalities ( e . g .
audio , sonar ) .
most existing local descriptors are based on a simple ar - chitecture : the patch is convolved with a lter bank ( often consisting of oriented edge detectors ) , the outputs of which are rectied and often normalized and quantized .
then , the outputs of each lter are spatially pooled using a simple ad - dition or a max operator , so as to build local bags of fea - tures .
the pooling operation makes the descriptor robust to minor changes in the position of individual features .
this architecture is somewhat similar ( and inspired by ) the most commonly accepted model of early areas of the mammalian primary visual cortex : simple cells detect oriented edges at various locations and scales ( playing the same role as the lter bank ) .
highly - active simple cells inhibit other cells at neighboring locations and orientations ( similarly to lo - cal normalization and / or quantization ) , while complex cells spatially pool the rectied outputs of complex cells , so as to create a local invariance to small shifts ( like the pooling operation ) ( 123 , 123 , 123 ) .
the method proposed here simulta - neously learns the lters and the pooling function , so that lters that re on similar image patches end up in the same pool .
as a result , similar patches will produce similar de -
the problem of learning low - level image features has become a topic of growing interest in recent years .
sev - eral authors have proposed unsupervised methods to learn image descriptors based on sparse / overcomplete decompo - sition ( 123 , 123 , 123 ) , but none had explicit provision for local invariance .
supervised learning methods have long been used in conjunction with convolutional networks to learn low - level , locally invariant features that are tuned to the task at hand ( 123 , 123 ) , but these methods require large numbers of labeled samples .
a number of different proposals have appeared for unsupervised learning of locally - invariant de - scriptors , which also use sparsity criteria ( 123 , 123 , 123 , 123 ) .
our aim is to learn the lter bank stage and the pooling
123 - 123 - 123 - 123 - 123 / 123 / $123 123 ieee
stage simultaneously , in such a way the lters that belong to the same pool extract similar features .
rather than learning descriptors that are merely invariant to small shift ( a prop - erty that can easily be built by hand ) , our goal is to learn descriptors that are also invariant to other types of transfor - mations , such as rotations and certain distortions .
our solu - tion is to pre - wire ( before learning ) which lters outputs are pooled together , and to let the underlying lters learn their coefcients .
the main idea , inspired by ( 123 ) , is to minimize a sparsity criterion on the pooling units .
as a result , lters that are pooled together end up extracting similar features .
several authors have proposed methods to learn pooled features in the context of computational models of the mam - malian primary visual cortex .
the idea relies on impos - ing sparsication criteria on small groups of lter out - puts ( 123 , 123 , 123 ) , which can be related to the group lasso method for regularization ( 123 ) .
when the lters that are pooled together are organized in a regular array ( 123d or 123d ) , the lters form topographic maps in which nearby lters ex - tract similar features ( 123 , 123 ) , with patterns similar to what is found in the visual cortex .
to the best of our knowledge , the present work is the rst time a trainable topographically - organized feature map is used for extracting locally invariant image descriptors for image recognition .
the following sections describe the training procedure , and compare the descriptors thereby ob - tained with a number of standard descriptors such as sift .
the experiments compare recognition accuracies on cal - tech 123 , mnist and tiny images datasets using various recognition architectures fed with various descriptors .
it is well established that sparse coding algorithms ap - plied to natural images learn basis functions that are lo - calized oriented edges and resemble the receptive elds of simple cells in area v123 of the mammalian visual cor - tex ( 123 ) .
these methods produce feature representation that are sparse , but not invariant .
if the input pattern is slightly distorted , the representation may change drastically .
more - over , these features represent information about local tex - ture , and hence , are rather inefcient when used to pre - process whole images because they do not exploit the re - dundancy in adjacent image patches .
finally , most sparse coding algorithms ( 123 , 123 , 123 , 123 , 123 ) have found limited ap - plications in vision due to the high computational cost of the iterative optimization required to compute the feature
in this paper , we introduce an algorithm , named in - variant predictive sparse decomposition ( ipsd ) , that : ( 123 ) learns features that are invariant to small variations inherent in the data , and ( 123 ) produces more efcient representations because they can be compact and directly computed using a feed - forward function , without requiring the use of any
iterative optimization procedure .
learning an over ( cid : 123 ) complete dictionary of basis
sparse coding algorithms represent an input signal x rm using a linear combination of basis functions that are columns of the dictionary matrix d rmn , using co - efcients z rn , with n > m .
since the linear system is under - determined , a sparsity constraint is added that prefers most of the coefcients to be zero for any given input .
many sparse coding algorithms have been proposed in the liter - ature and in this work we focus on the following convex
l = min
123 + xi
this particular formulation has been extensively stud - ied ( 123 , 123 , 123 , 123 , 123 , 123 , 123 , 123 ) , and it has also been extended to the case when the dictionary d is learned , thus adapting to the statistics of the input .
the basic idea is to minimize the same objective of eqn .
123 alternatively over coefcients z for a given dictionary d , and then over d for a given set of z .
note that each column of d is required to be unit 123 norm ( or bounded norm ) in order to avoid trivial solutions that are due to the ambiguity of the linear reconstruction ( for instance , the objective can be decreased by respectively dividing and multiplying z and d by a constant factor ) .
modeling invariant representations
although the sparse coding algorithm outlined above can learn representations that are sparse , they are not invariant : a small change in the input signal x may result in a large change in the coefcients z ( 123 ) .
we now describe how the sparsity term in eqn .
123 can be modied to create coefcients that are invariant to perturbations in the input signal .
the overall idea ( 123 ) is to arrange the zs into a 123d map ( or some other topology ) and then pool the squared coef - cients of z across overlapping windows .
then , the square of the the lter outputs within each sub - window are summed , and its square root is computed .
more formally , let the map of z contain k overlapping neighborhoods pi .
within each neighborhood i , we sum the squared coefcients zj ( weighted by a xed gaussian weighting function centered in the neighborhood ) and then take the square root .
this j , where wj are the gaussian weights .
the overall sparsity penalty is the sum i=123 vi .
figure 123 ( a ) il - lustrates this scheme .
thus , the overall objective function is
gives the activation vi = qpjpi of each neighborhoods activation : pk
wj z 123
j p i
figure 123
( a ) : the structure of the block - sparsity term which en - courages the basis functions in d to form a topographic map .
see text for details .
( b ) : overall architecture of the loss function , as dened in eqn .
in the generative model , we seek a feature vec - tor z that simultaneously approximate the input x via a dictionary of basis functions d and also minimize a sparsity term .
since per - forming the inference at run - time is slow , we train a prediction function f ( x; w ) ( dashed lines ) that directly predicts the optimal z from the input x .
at run - time we use only the prediction function to quickly compute z from x , from which the invariant features vi
the modied sparsity term has a number of subtle effects on the nature of z that are not immediately obvious :
the square root in the sum over i encourages sparse activations across neighborhoods since a few large ac - tivations will have lower overall cost than many small
within each neighborhood i , the coefcients zj are en - couraged to be similar to one another due to the z 123 ( which prefers many small coefcients to a few large ones ) .
this has the effect of encouraging similar basis functions in d to be spatially close in the 123d map .
as the neighborhoods overlap , these basis functions will smoothly vary across the map , so that the coef - cients zj in any given neighborhood i will be similar .
if the size of the pooling regions is reduced to a single z element , then the sparsity term is equivalent to that of eqn
the modied sparsity term means that by minimizing the loss function li in eqn .
123 with respect to both the co - efcients z and the dictionary d , the system learns a set of basis functions in d that are laid out in a topographic map on the 123d grid .
since the nearby basis functions in the topographic map are similar , the coefcients zj will be similar for a given in - put x .
this also means that if this input is perturbed slightly then the pooled response within a given neighborhood will be minimally affected , since a decrease in the response of one lter will be offset by an increased response in a nearby one .
hence , we can obtain a locally robust representation
by taking the pooled activations vi as features , rather than z as is traditionally done .
since invariant representations encode similar patterns with the same representation , they can be made more com - pact .
put another way , this means that the dimensionality of v can be made lower than the dimensionality of z with - out loss of useful information .
this has the triple benet of requiring less computation to extract the features from an image , requiring less memory to store them , and requiring less computation to exploit them .
the 123d map over z uses circular boundary conditions to ensure that the pooling wraps smoothly around at the edges of the map .
code prediction
the model proposed above is generative , thus at test - time for each input region x , we will have to perform infer - ence by minimizing the energy function li of eqn .
123 with respect to z .
however , this will be impractically slow for real - time applications where we wish to extract thousands of descriptors per image .
we therefore propose to train a non - linear regressor that directly maps input patches x into sparse representations z , from which the invariant features vi can easily be computed .
at test - time we only need to present x to the regression function which operates in feed - forward fashion to produce z .
no iterative optimization is
f ( x; w ) = f ( x; g , m , b ) = g tanh ( m x + b )
where m rmn is a lter matrix , b rm is a vector of biases , tanh is the hyperbolic tangent non - linearity , and g rmm is a diagonal matrix of gain coefcients allow - ing the outputs of f to compensate for the scaling of the input and the limited range of the hyperbolic tangent non - linearity .
for convenience , w is used to collectively denote the parameters of the predictor , w = ( g , m , b ) .
during training , the goal is to make the prediction of the regressor , f ( x; w ) as close as possible to the optimal set of coefcients : z = arg minz li in eqn .
this opti - mization can be carried out separately after the problem in eqn .
( 123 ) has been solved .
however , training becomes much faster by jointly optimizing the w and the set of basis func - tions d all together .
this is achieved by adding another term to the loss function in eqn .
( 123 ) , which forces the rep - resentation z to be as close as possible to the feed - forward prediction f ( x; w ) :
lip = kx dzk123
j + kz f ( x; w ) k123
the overall structure of this loss function is depicted in
the goal of learning is to nd the optimal value of the ba - sis functions d , as well as the value of the parameters in the regressor w , thus minimizing lip in eqn .
learning pro - ceeds by an on - line block coordinate gradient descent algo - rithm , alternating the following two steps for each training
keeping the parameters w and d constant , minimize lip of eqn .
( 123 ) with respect to z , starting from the initial value provided by the regressor f ( x; w ) .
using the optimal value of the coefcients z provided by the previous step , update the parameters w and d by one step of stochastic gradient descent .
the update is : u u lip u , where u collectively denotes ( w , d ) and is the step size .
the columns of d are then re - scaled to unit norm .
we set = 123 for all experiments .
we found that training the set of basis functions d rst , then subsequently training the regressor , yields similar performance in terms of recogni - tion accuracy .
however , when the regressor is trained after - wards , the approximate representation is usually less sparse and the overall training time is considerably longer .
once the parameters are learned , computing the invariant representation v can be performed by a simple feed - forward propagation through the regressor f ( x; w ) , and then prop -
agating z into v through vi = qpjpi
note that no reconstruction of x using the set of basis functions d is necessary any longer .
an example of this feed forward recognition architecture is given in fig
the addition of this feed - forward module for predicting z , and hence , v is crucial to speeding up the run - time per - formance , since no optimization needs to be run after train - ing .
experiments reported in a technical report on the non - invariant version of predictive sparse decomposition ( 123 ) show that the z produced by this approximate representa - tion gives a slightly superior recognition accuracy to the z produced by optimizing of li .
finally , other families of regressor functions were tested ( using different kinds of thresholding non - linearities ) , but the one chosen here achieves similar performance while having the advantage of being very simple .
in fact the l - ters m learned by the prediction function closely match the basis functions d used for reconstruction during training , having the same topographic layout .
figure 123
topographic map of feature detectors learned from nat - ural image patches of size 123x123 pixels by optimizing lip a in eqn .
there are 123 lters that are organized in 123x123 neighbor - hoods .
adjacent neighborhoods overlap by 123 pixels both horizon - tally and vertically .
notice the smooth variation within a given neighborhood and also the circular boundary conditions .
figure 123
analysis of learned lters by tting gabor functions , each dot corresponding to a feature .
left : center location of tted gabor .
right : polar map showing the joint distribution of orienta - tion ( azimuthally ) and frequency ( radially ) of gabor t .
in the following section , before exploring the properties of the invariant features obtained , we rst study the topo - graphic map produced by our training scheme .
first , we make an empirical evaluation of the invariance achieved by these representations under translations and rotations of the input image .
second , we assess the discriminative power of these invariant representations on recognition tasks in three different domains : ( i ) generic object categories using the caltech 123 dataset; ( ii ) generic object categories from a dataset of very low resolution images and ( iii ) classication
figure 123
examples from the tiny images .
we use grayscale images in our experiments .
of handwriting digits using the mnist dataset .
in these ex - periments we compare ipsd s learned representations with the sift descriptor ( 123 ) that is considered a state - of - the - art descriptor in computer vision .
finally , we examine the computational cost of computing ipsd features on an im -
learning the topographic map
123 shows a typical topographic map learned by the proposed method from natural image patches .
each tile shows a lter in d corresponding to a particular zi .
in the example shown , the input images are patches of size 123x123 pixels , and there are 123 basis functions , and hence , 123 units zi arranged in a 123x123 lattice .
the neighborhoods over which the squared activities of zis are pooled are 123x123 windows , and they overlap by 123 in both the vertical and the horizontal direction .
the properties of these lters are ana - lyzed by tting gabor functions and are shown in fig
by varying the way in which the neighborhoods are pooled , we can change the properties of the map .
larger neighborhoods make the lters in each pool increasingly similar .
a larger overlap between windows makes the lters vary more smoothly across different pools .
a large sparsity value makes the feature detectors learn less localized pat - terns that look like those produced by k - means clustering because the input has to be reconstructed using a small num - ber of basis functions .
on the other hand , a small sparsity value makes the feature detectors look like non - localized random lters because any random overcomplete basis set can produce good reconstructions ( effectively , the rst term in the loss of eqn .
123 dominates ) .
the map in fig .
123 has been produced with an intermedi - ate sparsity level of = 123
the chosen parameter setting in - duces the learning algorithm to produce a smooth map with mostly localized edge detectors in different positions , ori - entations , and scales .
these feature detectors are nicely or - ganized in such a way that neighboring units encode similar patterns .
a unit vi , that connects to the sum of the squares of units zj in a pool is invariant because these units represent similar features , and small distortions applied to the input , while slightly changing the zjs within a pool , are likely to leave the corresponding vi unaffected .
while the sparsity level , the size of the pooling windows and their overlap should be set by cross - validation , in prac - tice we found that their exact values do not signicantly
rotation 123 degrees
rotation 123 degrees
sift non rot .
our alg .
non inv .
our alg
figure 123
mean squared error ( mse ) between the representation of a patch and its transformed version .
on the left panel , the trans - formed patch is horizontally shifted .
on the right panel , the trans - formed patch is rst rotated by 123 degrees and then horizontally shifted .
the curves are an average over 123 patches randomly picked from natural images .
since the patches are 123x123 pixels in size , a shift of 123 pixels generates a transformed patch that is quite uncorrelated to the original patch .
hence , the mse has been normalized so that the mse at 123 pixels is the same for all methods .
this allows us to directly compare different feature ex - traction algorithms : non - orientation invariant sift , sift , ipsd trained to produce non - invariant representations ( i . e .
pools have size 123x123 ) ( 123 ) , and ipsd trained to produce invariant representa - tions .
all algorithms produce a feature vector with 123 dimen - sions .
ipsd produces representations that are more invariant to transformations than the other approaches .
affect the kind of features learned .
in other words , the al - gorithm is quite robust to the choice of these parameters , probably because of the many constraints enforced during
analyzing invariance to transformations
in this experiment we study the invariance properties of the learned representation under simple transformations .
we have generated a dataset of 123x123 natural image patches under different translations and rotations .
each patch is pre - sented to the predictor function that produces a 123 dimen - sional descriptor ( chosen to be the same size as sift ) com - posed of vs .
a representation can be considered locally in - variant if it does not change signicantly under small trans - formations of the input .
indeed , this is what we observe in fig .
we compare the mean squared difference be - tween the descriptor of the reference patch and the descrip - tor of the transformed version , averaged over many different image patches .
the gure compares proposed descriptor against sift with a varying horizontal shift for 123 and 123 degrees initial rotation .
very similar results are found for vertical shifts and other rotation angles .
on the left panel , we can see that the mean squared error ( mse ) between the representation of the original patch and its transformation increases linearly as we increase the hor - izontal shift .
the mse of ipsd representation is generally
figure 123
diagram of the recognition system , which is composed of an invariant feature extractor that has been trained unsuper - vised , followed by a supervised linear svm classier .
the fea - ture extractor process the input image through a set of lter banks , where the lters are organized in a two dimensional topographic map .
the map denes pools of similar feature detectors whose ac - tivations are rst non - linearly transformed by a hyperbolic tangent non - linearity , and then , multiplied by a gain .
invariant representa - tions are found by taking the square root of the sum of the squares of those units that belong to the same pool .
the output of the fea - ture extractor is a set of feature maps that can be fed as input to the classier .
the lter banks and the set of gains is learned by the algorithm .
recognition is very fast , because it consists of a direct forward propagation through the system .
lower than the mse produced by features that are computed using sift , a non - rotation invariant version of sift , and a non - invariant representation produced by the proposed method ( that was trained with pools of size 123x123 ) ( 123 ) .
a sim - ilar behavior is found when the patch is not only shifted , but also rotated .
when the shift is small , sift has lower mse , but as soon as the translation becomes large enough that the input pattern falls in a different internal sub - window , the mse increases considerably .
instead learned represen - tations using ipsd seem to be quite robust to shifts , with an overall lower area under the curve .
note also that traditional sparse coding algorithms are prone to produce unstable rep - resentations under small distortions of the input .
because each input has to be encoded with a small number of basis functions , and because the basis functions are highly tuned in orientation and location , a small change in the input can produce drastic changes in the representation .
this problem is partly alleviated by our approximate inference procedure that uses a smooth predictor function .
however , this experi - ment shows that this representations is fairly unstable under small distortions , when compared to the invariant represen - tations produced by ipsd and sift .
generic object recognition
we now use ipsd invariant features for object classi - cation on the caltech 123 dataset ( 123 ) of 123 generic object categories including background class .
we use 123 training images per class and up to 123 test images per class .
the images are randomly picked , and pre - processed in the fol -
lowing way : converted to gray - scale and down - sampled in such a way that the longest side is 123 pixels and then lo - cally normalized and zero padded to 123x123 pixels .
the local normalization takes a 123x123 neighborhood around each pixel , subtracts the local mean , then divides the by the local standard deviation if it is greater than the standard deviation of the image .
the latter step is a form of divisive normal - ization , proposed to model the contrast normalization in the
we have trained ipsd on 123 , 123 123x123 patches ran - domly extracted from the pre - processed images .
the topo - graphic map used has size 123x123 , with the pooling neigh - borhoods being 123x123 and an overlap of 123 coefcients be - tween neighborhoods .
hence , there are a total of 123 units that are used in 123 pools to produce a 123 - dimensional representation that can be compared to sift .
after training ipsd in an unsupervised way , we use the predictor function to infer the representation of one whole image by : ( i ) run - ning the predictor function on 123x123 patches spaced by 123 pixels to produce 123 maps of features of size 123x123; ( ii ) the feature maps are locally normalized ( neighborhood of 123x123 ) and low - pass ltered with a boxcar lter ( 123x123 ) to avoid aliasing; ( iii ) the maps are then projected along the leading 123 principal components ( equal to the number of train - ing samples ) , and ( iv ) a supervised linear svm123 is trained to recognize the object in each corresponding image .
the overall scheme is shown in fig
table 123 reports the recognition results for this experi - ment .
with a linear classier similar to ( 123 ) , ipsd features outperform sift and the model proposed by serre and pog - gio ( 123 ) .
however , if rotation invariance is removed from sift its performance becomes comparable to ipsd .
we have also experimented with the more sophisticated spatial pyramid matching ( spm ) kernel svm classier of lazebnik et al .
in this experiment , we again used the same ipsd architecture on 123x123 patches spaced by 123 pixels to produce 123x123x123 dimensional feature maps , followed by local normalization over a 123x123 neighborhood , yielding 123 dimensional features over a uniform 123x123 grid .
using spm , ipsd features achieve 123% average accuracy per class .
by decreasing the stepping stride to 123 pixel , thereby producing 123x123 feature maps , ipsd fea - tures achieve 123% accuracy as shown in table 123
this is comparable to lazebniks 123% accuracy on caltech - 123 ( without background class ) ( 123 ) .
for comparison , our re - implementation of lazebniks sift feature extractor , stepped by 123 pixels to produce 123x123 maps , yielded 123% average recognition rate .
with 123 invariant features , each descriptor takes around 123ms to compute from a 123x123 patch .
note that the evalua - tion time of each region is a linear function of the number
accuracy / class ( % )
performance on tiny images dataset
local norm123 + boxcar123 + pca123 + linear svm sift ( 123x123 ) ( non rot .
inv . ) sift ( 123x123 ) ( rot .
inv . ) serre et al .
features ( 123 )
local norm123 + spatial pyramid match kernel svm
table 123
recognition accuracy on caltech 123 dataset using a va - riety of different feature representations and two different classi - ers .
the pca + linear svm classier is similar to ( 123 ) , while the spatial pyramid matching kernel svm classier is that of ( 123 ) .
ipsd is used to extract features with three different sampling step sizes over an input image to produce 123x123 , 123x123 and 123x123 feature maps , where each feature is 123 dimensional to be compa - rable to sift .
local normalization is not applied on sift features when used with spatial pyramid match kernel svm .
number of invariant units
figure 123
the gure shows the recognition accuracy on caltech 123 dataset as a function of the number of invariant units .
note that the performance improvement between 123 and 123 units is below 123% , suggesting that for certain applications the more com - pact descriptor might be preferable .
of features , thus this time can be further reduced if the num - ber of features is reduced .
123 shows how the recognition performance varies as the number of features is decreased .
tiny images classication
ipsd was compared to sift on another recognition task using the tiny images dataset ( 123 ) .
this dataset was chosen as its extreme low - resolution provides a different setting to the caltech 123 images .
for simplicity , we selected 123 ani - mal nouns ( abyssinian cat , angel shark , apatura iris ( a type of buttery ) , bilby ( a type of marsupial ) , may beetle ) and manually labeled 123 examples of each .
123 images of each class were used for training , with the remaining 123 held out for testing .
all images are converted to grayscale .
both ipsd with 123 pooled units and sift were used to extract features over 123x123 regions , spaced every 123 pixels over the 123x123 images .
the resulting 123 by 123 by 123 dimensional feature maps are used with a linear svm .
ipsd features achieve 123% and sift features achieve a comparable 123% .
sift ( 123x123 ) ( non rot
performance on mnist dataset
sift ( 123x123 ) ( non rot
error rate ( % )
table 123
results of recognition error rate on tiny images and mnist datasets .
in both setups , a 123 dimensional feature vector is obtained using either ipsd or sift over a regularly spaced 123x123 grid and afterwards a linear svm is used for classication .
for comparison purposes it is worth mentioning that a gaussian svm trained on mnist images without any preprocessing achieves 123% error rate .
handwriting recognition
we use a very similar architecture to that used in the ex - periments above to train on the handwritten digits of the mnist dataset ( 123 ) .
this is a dataset of quasi - binary hand - written digits with 123 , 123 images in the training set , and 123 , 123 images in the test set .
the algorithm was trained us - ing 123x123 windows extracted from the original 123x123 pixel images .
for recognition , 123 - dimensional feature vectors were extracted at 123 locations regularly spaced over a 123x123 grid .
a linear svm trained on these features yields an er - ror rate of 123% .
when 123 sift feature vectors are used instead of ipsd features , the error rate increases to 123% .
this demonstrates that , while sift seems well suited to natural images , ipsd produces features that can adept to the task at hand .
in a similar experiment , a single 123 - dimensional feature vector was extracted using ipsd and sift , and fed to a linear svm .
the error rate was 123% for ipsd , and 123% for sift .
summary and future work
we presented an architecture and a learning algorithm that can learn locally - invariant feature descriptors .
the ar - chitecture uses a bank of non - linear lters whose outputs are organized in a topographic fashion , followed by a pool - ing layer that imposes a sparsity criterion on blocks of l - ter outputs located within small regions of the topographic map .
as a result of learning , lters that are pooled together extract similar features , which results in spontaneous invari - ance of the pooled outputs to small distortions of the input .
during training , the output of the non - linear lter bank is fed to a linear decoder that reconstructs the input patch .
the lters and the linear decoder are simultaneously trained to minimize the reconstruction error , together with a sparsity criterion computed as the sum of the pooling units .
after training , the linear decoder is discarded , and the pooling unit outputs are used as the invariant feature descriptor of the input patch .
computing the descriptor for a patch is very
fast and simple : it merely involves multiplying the patch by a ltering matrix , applying a scaled tanh function to the re - sults , and computing the square root of gaussian - weighted sum - of - squares of lter outputs within each pool window .
image classication experiments show that the descrip - tors thereby obtained give comparable performance to sift descriptors on tasks for which sift was specically de - signed ( such as caltech 123 ) , and better performance on tasks for which sift is not particularly well suited ( mnist , and tiny images ) .
while other models have learned locally invariant de - scriptors by explicitly building shift invariance using spa - tial pooling , our proposal is more general : it can learn local invariances to other transformations than just translations .
our results also show spontaneous local invariance to rota - tion .
to our knowledge , this is the rst time such invariant feature descriptors have been learned and tested in an image recognition context with competitive recognition rates .
a long - term goal of this work is to provide a general tool for learning feature descriptors in an unsupervised manner .
future work will involve stacking multiple stage of such feature extractors so as to learn multi - level hierarchies of increasingly global and invariant features .
we thank karol gregor , y - lan boureau , eero simon - celli , and members of the cifar program neural computa - tion and adaptive perception for helpful discussions .
this work was supported in part by onr grant n123 - 123 - 123 - 123 , nsf grant efri - 123 , and nsf iis - 123
