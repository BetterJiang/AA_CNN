we develop the syntactic topic model ( stm ) , a nonparametric bayesian model of parsed documents .
the stm generates words that are both thematically and syntactically constrained , which combines the semantic insights of topic models with the syntactic information available from parse trees .
each word of a sentence is generated by a distribution that combines document - specic topic weights and parse - tree - specic syntactic transitions .
words are assumed to be generated in an order that respects the parse tree .
we derive an approximate posterior inference method based on variational methods for hierarchical dirichlet processes , and we report qualitative and quantitative results on both synthetic data and hand - parsed
