consider data consisting of pairwise measurements , such as presence or absence of links between pairs of objects .
these data arise , for instance , in the analysis of protein interactions and gene regulatory networks , collections of author - recipient email , and social networks .
analyzing pair - wise measurements with probabilistic models requires special assumptions , since the usual inde - pendence or exchangeability assumptions no longer hold .
here we introduce a class of variance allocation models for pairwise measurements : mixed membership stochastic blockmodels .
these models combine global parameters that instantiate dense patches of connectivity ( blockmodel ) with local parameters that instantiate node - specic variability in the connections ( mixed membership ) .
we develop a general variational inference algorithm for fast approximate posterior inference .
we demonstrate the advantages of mixed membership stochastic blockmodels with applications to so - cial networks and protein interaction networks .
analysis , social networks , protein interaction networks
hierarchical bayes , latent variables , mean - eld approximation , statistical network
the problem of modeling relational information among objects , such as pairwise relations repre - sented as graphs , arises in a number of settings in machine learning .
for example , scientic litera - ture connects papers by citations , the web connects pages by links , and protein - protein interaction data connects proteins by physical binding records .
in these settings , we often wish to infer hidden attributes of the objects from the observed measurements on pairwise properties .
for example , we might want to compute a clustering of the web - pages , predict the functions of a protein , or assess
( cid : 123 ) .
also in the lewis - sigler institute for integrative genomics .
address correspondence to 123 carl icahn laboratory ,
also in the school of computer science .
c ( cid : 123 ) 123 edoardo m .
airoldi , david m .
blei , stephen e .
fienberg and eric p
airoldi , blei , fienberg and xing
the degree of relevance of a scientic abstract to a scholars query .
unlike traditional data collected from individual objects , relational data violate the classical independence or exchangeability as - sumptions made in machine learning and statistics .
the observations are dependent because of the way they are connected .
this interdependence suggests that a different set of assumptions is more
there is a history of research devoted to analyzing relational data .
one well - studied problem is clustering , grouping the objects to uncover a structure based on the observed patterns of interactions .
standard model - based clustering methods , for example , mixture models , are not immediately ap - plicable to relational data because they assume that the objects are conditionally independent given their cluster assignments .
rather , the latent stochastic blockmodel ( wang and wong , 123; snijders and nowicki , 123 ) is an adaptation of mixture modeling to relational data .
in that model , each ob - ject belongs to a cluster and the relationships between objects are governed by the corresponding pair of clusters .
with posterior inference , one identies a set of latent roles which govern the ob - jects relationships with each other .
a recent extension of this model relaxed the nite - cardinality assumption on the latent clusters with a nonparametric hierarchical bayesian model based on the dirichlet process prior ( kemp et al . , 123 , 123; xu et al . , 123 ) .
the latent stochastic blockmodel suffers from a limitation that each object can only belong to one cluster , or in other words , play a single latent role .
however , many relational data sets are multi - facet .
for example , when a protein or a social actor interacts with different partners , different functional or social contexts may apply and thus the protein or the actor may be acting according to different latent roles they can possible play .
in this paper , we relax the assumption of single - latent - role for actors , and develop a mixed membership model for relational data .
mixed membership models , such as latent dirichlet allocation ( blei et al . , 123 ) , have re - emerged in recent years as a exible modeling tool for data where the single cluster assumption is violated by the heterogeneity within of a data point .
for almost two decades , these models have been successfully applied in many domains , such as surveys ( berkman et al . , 123; erosheva , 123 ) , population genetics ( pritchard et al . , 123 ) , document analysis ( minka and lafferty , 123; blei et al . , 123; buntine and jakulin , 123 ) , image processing ( li and perona , 123 ) , and transcriptional regulation ( airoldi et al . , 123 ) .
the mixed membership model associates each unit of observation with multiple clusters rather than a single cluster , via a membership probability - like vector .
the concurrent membership of a data in different clusters can capture its different aspects , such as different underlying topics for words constituting each document .
this is also a natural idea for relational data , where the objects can bear multiple latent roles or cluster - memberships that inuence their relationships to others .
as we will demonstrate , a mixed membership approach to relational data lets us describe the interaction between objects playing multiple roles .
for example , some of a proteins interactions may be governed by one function; other interactions may be governed by another function .
existing mixed membership models are not appropriate for relational data because they assume that the data are conditionally independent given their latent membership vectors .
in relational data , where each object is described by its relationships to others , we would like to assume that the en - semble of mixed membership vectors help govern the relationships of each object .
the conditional independence assumptions of modern mixed membership models do not apply .
mixed membership stochastic blockmodels
figure 123 : two graphical model representations of the mixed membership stochastic blockmodel ( mmb ) .
intuitively , the mmb summarized the variability of a graph with the blockmodel b and node - specic mixed membership vectors ( left ) .
in detail , a mixed membership , p n ( k ) , quanties the expected proportion of times node n instantiates the connectivity pattern of group k , according to the blockmodel .
in any given interaction , y ( n; m ) , how - ever , node n instantiates the connectivity pattern of a single group , zn ! m ( k ) .
( right ) .
we did not draw all the arrows out of the block model b for clarity; all interactions depend
in this paper , we develop mixed membership models for relational data . 123 models in this family include parameters to reduce bias due to sparsity , and can be used to analyze multiple collections of paired measurements , and collections of non - binary and multivariate paired measurements .
we develop a fast nested variational inference algorithm that performs well in the relational setting and is parallelizable .
we demonstrate the application of our technique to large - scale protein interaction networks and social networks .
our model captures the multiple roles that objects exhibit in interac - tion with others , and the relationships between those roles in determining the observed interaction
mixed membership and the latent block structure can be recovered from relational data ( section 123 ) .
the application to a friendship network among students tests the model on a real data set where a well - dened latent block structure exists ( section 123 ) .
the application to a protein interaction network tests to what extent our model can reduce the dimensionality of the data , while revealing substantive information about the functionality of proteins that can be used to inform subsequent analyses ( section 123 ) .
airoldi , blei , fienberg and xing
the mixed membership stochastic blockmodel
in this section , we describe the modeling assumptions if the mixed membership model of relational data .
we represent observed relational data as a graph g = ( n ;y ) , where y ( p; q ) maps pairs of nodes to values , that is , edge weights .
we consider binary matrices , where y ( p; q ) 123 f123;123g .
the data can be thought of as a directed graph .
as a running example , we consider the monk data of sampson ( 123 ) .
sampson measured a collection of sociometric relations among a group of monks by repeatedly asking questions such as whom do you like ? and whom do you dislike ? to determine asymmetric social relationships within the group .
the questionnaire was repeated at four subsequent epochs .
information about these repeated , asymmetric relations was collapsed into a square binary table that encodes the di - rected connections between monks by breiger et al .
( 123 ) .
in analyzing this data , the goal is to determine the social structure within the monastery .
in the context of the monastery example , we assume k factions , that is , latent groups , exist in the monastery , and the observed network is generated according to distributions of group - membership for each monk and a matrix of group - group interaction strength .
the per - monk distributions are specied by latent simplicial vectors .
each monk is associated with a randomly drawn vector ~ p for monk i , where p i;g denotes the probability of monk i belonging to group g .
that is , each monk can simultaneously belong to multiple groups with different degrees of afliation strength .
the probabilities of interactions between different groups are dened by a matrix of bernoulli rates b ( k ( cid : 123 ) k ) , where b ( g; h ) represents the probability of having a link between a monk from group g and a monk from group h .
for each monk , the indicator vector ~ zp ! q denotes the group membership of monk p when he responds to survey questions about monk q and ~ z p q denotes the group membership of monk q when he responds to survey questions about node p . 123 n denotes the number of monks in the monastery , and recall that k denotes the number of distinct groups a monk can belong to .
more in general , monks can be represented by nodes in a graph , where directed ( binary ) edges represent positive responses to survey questions about a specic sociometric relation .
in this abstract setting , the mixed membership stochastic blockmodel ( mmb ) posits that a graph g = ( n ;y ) is drawn from the following procedure .
( cid : 123 ) for each node p 123 n :
draw a k dimensional mixed membership vector ~ p p ( cid : 123 ) dirichlet ( ~ a
( cid : 123 ) for each pair of nodes ( p; q ) 123 n ( cid : 123 ) n :
draw membership indicator for the initiator , ~ zp ! q ( cid : 123 ) multinomial ( ~ p p ) .
draw membership indicator for the receiver , ~ zq ! p ( cid : 123 ) multinomial ( ~ p q ) .
sample the value of their interaction , y ( p; q ) ( cid : 123 ) bernoulli ( ~ z > p ! qb ~ zp q ) .
in previous work we combined mixed membership and blockmodels to perform analyses of a single collection of bi - nary , paired measurements; namely , hypothesis testing , predicting and de - noising interactions within an unsupervised learning setting ( airoldi et al . , 123 ) .
an indicator vector is used to denote membership in one of the k groups .
such a membership - indicator vector is specied as a k - dimensional vector of which only one element equals to one , whose index corresponds to the group to be indicated , and all other elements equal to zero .
mixed membership stochastic blockmodels
this process is illustrated as a graphical model in figure 123
note that the group membership of each node is context dependent .
that is , each node may assume different membership when interacting to or being interacted by different peers .
statistically , each node is an admixture of group - specic interactions .
the two sets of latent group indicators are denoted by f ~ z p ! q : p; q 123 n g = : z ! and f ~ zp q : p; q 123 n g = : z .
also note that the pairs of group memberships that underlie interactions need not be equal; this fact is useful for characterizing asymmetric interaction networks .
equality may be enforced when modeling symmetric interactions .
under the mmb , the joint probability of the data y and the latent variables f ~ p 123 : n; z ! ; z g can
be written in the following factored form ,
p ( y; ~ p 123 : n; z ! ; z j ~ a
p ( y ( p; q ) j ~ zp ! q; ~ zp q; b ) p ( ~ zp ! qj ~ p p ) p ( ~ zp qj ~ p q ) ( cid : 123 )
p ( ~ p pj ~ a ) :
this model generalizes to two important cases .
first , multiple networks among the same actors can be generated by the same latent vectors .
this may be useful , for instance , to analyze multivariate sociometric relations .
second , in the mmb the data generating distribution is a bernoulli , but b can be a matrix that parameterizes any kind of distribution .
this may be useful , for instance , to analyze collections of paired measurements , y , that take values in an arbitrary metric space .
we elaborate on this in section 123
123 modeling sparsity
adjacency matrices encoding binary pairwise measurements are often sparse , that is , they contain many zeros or non - interactions .
it is useful to distinguish two sources of non - interaction : they may be the result of the rarity of interactions in general , or they may be an indication that the pair of relevant blocks rarely interact .
in applications to social sciences , for instance , nodes may represent people and blocks may represent social communities .
it is reasonable to expect that a large portion of the non - interactions is due to limited opportunities of contact between people rather than due to deliberate choices , the structure of which the blockmodel is trying to estimate .
it is useful to account for these two sources of sparsity at the model level .
a good estimate of the portion of zeros that should not be explained by the blockmodel b reduces the bias of the estimates of its elements .
thus , we introduce a sparsity parameter r 123 ( 123;123 ) in the mmb to characterize the source of non - interaction .
instead of sampling a relation y ( p : q ) directly the bernoulli with parameter specied as above , we down - weight the probability of successful interaction to ( 123 ( cid : 123 ) r ) ( cid : 123 ) ~ z > p ! qb ~ zp q .
this is the result of assuming that the probability of a non - interaction comes from a mixture , 123 ( cid : 123 ) s pq = ( 123 ( cid : 123 ) r ) ( cid : 123 ) ~ z > capture the portion zeros that should not be explained by the blockmodel b .
a large value of r will cause the interactions in the matrix to be weighted more than non - interactions , in determining plausible values for f ~ a
p ! q ( 123 ( cid : 123 ) b ) ~ zp q + r
, where the weight r
; b; ~ p 123 : ng .
the sparsity parameter r can be estimated .
its maximum likelihood estimate provides the best data - driven guess about the proportion of zeros that the blockmodel can explain .
introducing r provides a strategy to rescale b , by separating zeros in the adjacency matrix into those that are likely to be due to the blockmodel and those that are not .
airoldi , blei , fienberg and xing
123 summarizing and de - noising pairwise measurements
it is useful to distinguish two types of data analysis that can be performed with the mixed - membership blockmodel .
first , mmb can be used to summarize the data , y , in terms of the global blockmodel , b , and the node - specic mixed memberships , p s .
second , mmb can be used to de - noise the data , y , in terms of the global blockmodel , b , and interaction - specic single memberships , zs .
in both cases the model depends on a small set of unknown constants to be estimated : a , and b .
the like - lihood is the same in both cases , although , the rationale for including the set of latent variables zs differs .
when summarizing data , we could integrate out the zs analytically; this leads to numerical optimization of a smaller set of variational parameters , g s .
we choose to keep the zs to simplify inference .
when de - noising , the zs are instrumental in estimating posterior expectations of each interactions individuallya network analog to the kalman filter .
the posterior expectations of an interaction is computed as follows , in the two cases ,
e ( y ( p; q ) = 123 ) ( cid : 123 ) b ~ p p
123 an illustration : crisis in a cloister
e ( y ( p; q ) = 123 ) ( cid : 123 ) b ~ f
to illustrate the mmb , we return to an analysis of the monk data described above .
sampson ( 123 ) surveyed 123 novice monks in a monastery and asked them to rank the other novices in terms of four like / dislike , esteem , personal inuence , and alignment with the monastic credo .
we consider breigers collation of sampsons data ( breiger et al . , 123 ) .
the original graph of monk - monk interaction is illustrated in figure 123 ( left ) .
sampson spent several months in a monastery in new england , where novice monks were preparing to join a monastic order .
sampsons original analysis was rooted in direct anthropological observations .
he suggested the existence of tight factions among the novices : the loyal opposition ( whose members joined the monastery rst ) , the young turks ( who joined later on ) , the outcasts ( who were not accepted in the two main factions ) , and the waverers ( who did not take sides ) .
the events that took place during sampsons stay at the monastery supported his observationsmembers of the young turks resigned or were expelled over religious differences ( john and gregory ) .
we shall
figure 123 : original adjacency matrix of whom - do - like sociometric relations ( left ) , relations pre - dicted using approximate mles for ~ p 123 : n and b ( center ) , and relations de - noised using the model including zs indicators ( right ) .
mixed membership stochastic blockmodels
refer to the labels assigned by sampson to the novices in the analysis below .
for more analyses , we refer to fienberg et al .
( 123 ) , davis and carley ( 123 ) and handcock et al .
( 123 ) .
using the algorithms presented in section 123 , we t the monks to mmb models for different numbers of groups , providing model estimates f a ; bg and posterior mixed membership vectors ~ p n for each monk .
here , we use the following approximation to bic to choose the number of groups in the mmb :
; bj ( cid : 123 ) log jy j;
bic = 123 ( cid : 123 ) log p ( y ) ( cid : 123 ) 123 ( cid : 123 ) log p ( y jb ~ p ;bz;b ~ a
;bb ) ( cid : 123 ) j ~ a
which selects three groups , where j ~ a ; bj is the number of hyper - parameters in the model , and jy j is the number of positive relations observed ( volinsky and raftery , 123; handcock et al . , 123 ) .
note that this is the same number of groups that sampson identied .
we illustrate the t of model t via the predicted network in figure 123 ( right ) .
the three panels contrast the different resolution of the original adjacency matrix of whom - do - like sociometric relations ( left panel ) obtained in different uses of mmb .
if the goal of the analysis if to nd a parsimonious summary of the data , the amount of relational information that is captured by in a ; b , and e ( ~ p jy ) leads to a coarse reconstruction of the original sociomatrix ( central panel ) .
if the goal of the analysis if to de - noising a collection of pairwise measurements , the amount of relational information that is revealed by a ; b; e ( ~ p jy ) and e ( z ! ; z jy ) leads to a ner reconstruction of the original sociomatrix , y relations in y are re - weighted according to how much they make sense to the model ( right panel ) .
123 m ark 123 w infrid 123 john bosco
figure 123 : posterior mixed membership vectors , ~ p 123 : 123 , projected in the simplex .
numbered points can be mapped to monks names using the legend on the right .
the colors identify the four factions dened by sampsons anthropological observations .
airoldi , blei , fienberg and xing
figure 123 : estimated blockmodel in the monk data , b .
the mmb provides interesting descriptive statistics about the actors in the observed graph .
in figure 123 we illustrate the the posterior means of the mixed membership scores , e ( ~ p jy ) , for the 123 monks in the monastery .
note that the monks cluster according to sampsons classication , with young turks , loyal opposition , and outcasts dominating each corner respectively .
we can see the central role played by john bosco and gregory , who exhibit relations in all three groups , as well as the uncertain afliations of ramuald and victor .
( amands uncertain afliation , however , is not captured . ) the estimated blockmodel is shown in figure 123
parameter estimation and posterior inference
two computational problems are central to the mmb : posterior inference of the per - node mixed membership vectors and per - pair roles , and parameter estimation of the dirichlet parameters and bernoulli rate matrix .
we derive empirical bayes estimates of the parameters ( ~ a ; b ) , and employ a mean - eld approximation scheme for posterior inference .
123 posterior inference
the posterior inference problem is to compute the posterior distribution of the latent variables given a collection of observations .
the normalizing constant of the posterior distribution is the marginal probability of the data , which requires an integral over the simplicial vectors ~ p p ,
; b ) = zp
p ( y ( p; q ) j ~ zp ! q; ~ zp q; b ) p ( ~ zp ! qj ~ p p ) p ( ~ zp qj ~ p q ) ( cid : 123 )
p ( ~ p pj ~ a ) ! d ~ p ;
which is not solvable in closed form ( blei et al . , 123 ) .
a number of approximate inference al - gorithms for mixed membership models have appeared in recent years , including mean - eld vari - ational methods ( blei et al . , 123; teh et al . , 123 ) , expectation propagation ( minka and lafferty , 123 ) , and monte carlo markov chain sampling ( mcmc ) ( erosheva and fienberg , 123; grifths and steyvers , 123 ) .
mixed membership stochastic blockmodels
we appeal to variational methods ( jordan et al . , 123; wainwright and jordan , 123 ) .
the main idea behind variational methods is to rst posit a distribution of the latent variables with free parameters , and then t those parameters such that the distribution is close in kullback - leibler divergence to the true posterior .
the variational distribution is simpler than the true posterior so that the optimization problem can be approximately solved .
good reviews of variational methods can be found in wainwright and jordan ( 123 ) , xing et al .
( 123 ) , bishop et al .
( 123 ) and airoldi ( 123 ) .
in the mmb , we begin by bounding the log of the marginal probability of the data with jensens
log p ( y ja
; b ) ( cid : 123 ) eq ( log p ( y; ~ p 123 : n; z ! ; z ja
; b ) ) ( cid : 123 ) eq ( logq ( ~ p 123 : n; z ! ; z ) ) :
we have introduced a distribution of the latent variables q that depends on a set of free parameters .
we specify q as the mean - eld fully - factorized family , q123 ( ~ p pj ~ g p ) ( cid : 123 )
q ( ~ p 123 : n; z ! ; z j ~ g 123 : n;f ! ;f ) = ( cid : 123 )
p;q ( cid : 123 ) q123 ( ~ zp ! qj ~ f p ! q ) q123 ( ~ zp qj ~ f p q ) ( cid : 123 ) ;
where q123 is a dirichlet , q123 is a multinomial , and f ~ g 123 : n;f ! ;f g are the set of free variational parameters that are optimized to tighten the bound .
tightening the bound with respect to the variational parameters is equivalent to minimizing the kl divergence between q and the true posterior .
when all the nodes in the graphical model are conjugate pairs or mixtures of conjugate pairs , we can directly write down a coordinate ascent algo - rithm for this optimization to reach a local maximum of the bound .
the updates for the variational multinomial parameters are
f p q;h
e eq ( logp p;g ) ( cid : 123 ) ( cid : 123 )
e eq ( logp q;h ) ( cid : 123 ) ( cid : 123 )
h ( cid : 123 ) b ( g; h ) y ( p;q ) ( cid : 123 ) ( 123 ( cid : 123 ) b ( g; h ) ) 123 ( cid : 123 ) y ( p;q ) ( cid : 123 ) f p q;h g ( cid : 123 ) b ( g; h ) y ( p;q ) ( cid : 123 ) ( 123 ( cid : 123 ) b ( g; h ) ) 123 ( cid : 123 ) y ( p;q ) ( cid : 123 ) f p ! q;g
for g; h = 123; : : : ; k .
the update for the variational dirichlet parameters g p;k is
g p;k = a k + ( cid : 123 )
f p ! q;k + ( cid : 123 )
f p q;k;
for all nodes p = 123; : : : ; n and k = 123; : : : ; k .
the complete coordinate ascent algorithm is described in figure 123
to improve convergence , we employed a nested variational inference scheme based on an al - ternative schedule of updates to the traditional ordering .
in a typical schedule for coordinate ascent ( which we call nave variational inference ) , one initializes the variational dirichlet parameters ~ g 123 : n and the variational multinomial parameters ( ~ f p ! q; ~ f p q ) to non - informative values , and then iterates the following two steps until convergence : ( i ) update ~ f p ! q and f p q for all edges ( p; q ) , and ( ii ) update ~ g p for all nodes p 123 n .
in such algorithm , at each variational inference cycle we need to allocate nk + 123n123k scalars .
in our experiments , the nave variational algorithm often converged only after many iterations .
we attribute this behavior to the dependence between ~ g 123 : n and b , which is not satised by the nave algorithm .
some intuition about why this may happen follows .
from a purely algorithmic
airoldi , blei , fienberg and xing
k for all p; k
pk = 123n
for p = 123 to n
until convergence
for q = 123 to n
partially update ~ g t+123
, ~ g t+123
p q = f ( y ( p; q ) ; ~ g t
q; bt )
p q;h = 123
p ! q;g = f 123
initialize f 123
for g = 123 to k update f s+123 f123 ( ~ f s p ! q to sum to 123 for h = 123 to k update f s+123 f123 ( ~ f s p q to sum to 123 123 .
until convergence
k for all g; h
p q; ~ g p; b )
p ! q; ~ g q; b )
figure 123 : top : the two - layered variational inference for ( ~ g ;f p ! q;g;f p q;h ) and m = 123
the in - ner algorithm consists of step 123
the function f is described in details in the bottom panel .
the partial updates in step 123 for ~ g and b refer to equation 123 of section b . 123 and equation 123 of section b . 123 , respectively .
bottom : inference for the variational parame - ters ( ~ f p ! q; ~ f p q ) corresponding to the basic observation y ( p; q ) .
this nested algorithm details step 123 in the top panel .
the functions f123 and f123 are the updates for f p ! q;g and f p q;h described in equations 123 and 123 of section b . 123
perspective , the nave variational em algorithm instantiates a large coordinate ascent algorithm , where the parameters can be divided into blocks .
blocks are processed in a specic order , and the parameters within each block get all updated each time . 123 at every new iteration the nave algorithm sets all the elements of ~ g t+123 123 : n equal to the same constant .
this dampens the likelihood by suddenly 123 : n and in bt that was being
breaking the dependence between the estimates of parameters inb ~ g t
instead , the nested variational inference algorithm maintains some of this dependence that is being inferred from the data across the various iterations .
this is achieved mainly through a different
inferred from the data during the previous iteration .
within a block , the order according to which ( scalar ) parameters get updated is not expected to affect convergence .
mixed membership stochastic blockmodels
scheduling of the parameter updates in the various blocks .
to a minor extent , the dependence is maintained by always keeping the block of free parameters , ( ~ f p ! q; ~ f p q ) , optimized given the other variational parameters .
note that these parameters are involved in the updates of parameters in ~ g 123 : n and in b , thus providing us with a channel to maintain some of the dependence among them , that is , by keeping them at their optimal value given the data .
furthermore , the nested algorithm has the advantage that it trades time for space thus allowing us to deal with large graphs; at each variational cycle we need to allocate nk + 123k scalars only .
the increased running time is partially offset by the fact that the algorithm can be parallelized and leads to empirically observed faster convergence rates .
an alternative strategy to perform inference is given by monte carlo markov chain ( e . g . , see grifths and steyvers , 123; kemp et al . , 123 ) .
while powerful in some settings , mcmc is impractical here .
there are too many variables to sample .
the proposed nested variational em algorithm outperforms mcmc variations ( i . e . , blocked and collapsed gibbs samplers ) in terms of memory requirements and convergence rates .
123 parameter estimation we compute the empirical bayes estimates of the model hyper - parameters f ~ a ; bg with a variational expectation - maximization ( em ) algorithm .
alternatives to empirical bayes have been proposed to x the hyper - parameters and reduce the computation .
the results , however , are not always sat - isfactory and often times cause of concern , since the inference is sensitive to the choice of the hyper - parameters ( joutard et al . , 123 ) .
empirical bayes , on the other hand , guides the posterior inference towards a region of the hyper - parameter space that is supported by the data .
variational em uses the lower bound in equation 123 as a surrogate for the likelihood .
to nd a local optimum of the bound , we iterate between tting the variational distribution q to approximate the posterior and maximizing the corresponding bound with respect to the parameters .
the latter m - step is equivalent to nding the mle using expected sufcient statistics under the variational distribution .
we consider the maximization step for each parameter in turn .
a closed form solution for the approximate maximum likelihood estimate of ~ a does not exist ( minka , 123 ) .
we use a linear - time newton - raphson method , where the gradient and hessian are
= n ( cid : 123 ) y = n ( cid : 123 ) i ( k123=k123 ) ( cid : 123 ) y
a k ) ( cid : 123 ) y ( a k ) ( cid : 123 ) + ( cid : 123 ) 123 ( ( cid : 123 )
123 ( a k123 ) ( cid : 123 ) y
g p;k ) ( cid : 123 ) ;
p ( cid : 123 ) y ( g p;k ) ( cid : 123 ) y a k ) ( cid : 123 ) :
the approximate mle of b is
b ( g; h ) =
p;qy ( p; q ) ( cid : 123 ) f p ! qg f p qh ( 123 ( cid : 123 ) r ) ( cid : 123 ) ( cid : 123 ) p;q f p ! qg f p qh
for every index pair ( g; h ) 123 ( 123; k ) ( cid : 123 ) ( 123; k ) .
finally , the approximate mle of the sparsity parameter
p;q ( 123 ( cid : 123 ) y ( p; q ) ) ( cid : 123 ) ( ( cid : 123 ) g;h f p ! qg f p qh )
p;q ( cid : 123 ) g;h f p ! qg f p qh
airoldi , blei , fienberg and xing
alternatively , we can x r prior to the analysis; the density of the interaction matrix is estimated p;qy ( p; q ) =n123 , and the sparsity parameter is set to r = ( 123 ( cid : 123 ) d ) .
this latter estimator with d = ( cid : 123 ) attributes all the information in the non - interactions to the point mass , that is , to latent sources other than the block model b or the mixed membership vectors ~ p 123 : n .
it does however provide a quick recipe to reduce the computational burden during exploratory analyses . 123
several model selection strategies are available for complex hierarchical models ( joutard et al . , 123 ) .
in our setting , model selection translates into the determination of a plausible value of the number of groups k .
in the various analyses presented , we selected the optimal value of k according to two strategies .
on large networks , we selected k corresponding to the highest averaged held - out likelihood in a cross - validation experiment .
on small networkswhere cross - validation cannot be expected to work well , as we discuss in section 123we selected k using an approximation to bic .
experiments and results
we present a study of simulated data and applications to social and protein interaction networks .
simulations are performed in section 123 to show that both mixed membership , ~ p 123 : n , and the latent block structure , b , can be recovered from data , when they exist , and that the nested variational inference algorithm is faster than the nave implementation while reaching the same peak in the likelihoodall other things being equal .
the application to a friendship network among students in section 123 tests the model on a real data set where we expect a well - dened latent block structure to inform the observed connectivity patterns in the network .
in this application , the blocks are interpretable in terms of grades .
we compare our results with those that were recently obtained with a simple mixture of blocks ( doreian et al . , 123 ) and with a latent space model ( handcock et al . , 123 ) on the same data .
the application to a protein interaction network in section 123 tests the model on a real data set where we expect a noisy , vague latent block structure to inform the observed connectivity patterns in the network to some degree .
in this application , the blocks are interpretable in terms functional biological contexts .
this application tests to what extent our model can reduce the dimensionality of the data , while revealing substantive information about the functionality of proteins that can be used to inform subsequent analyses .
123 exploring expected model behavior with simulations
in developing the mmb and the corresponding computation , our hope is the the model can recover both the mixed membership of nodes to clusters and the latent block structure among clusters in situations where a block structure exists and the relations are measured with some error .
to sub - stantiate this claim , we sampled graphs of 123;123; and 123 nodes from blockmodels with 123;123; and 123 clusters , respectively , using the mmb .
we used different values of a to simulate a range of settings in terms of membership of nodes to clustersfrom unique ( a = 123 : 123 ) to mixed ( a = 123 : 123 ) .
recovering the truth .
the variational em algorithm successfully recovers both the latent block model b and the latent mixed membership vectors ~ p 123 : n .
in figure 123 we show the adjacency matri - ces of binary interactions where rows , that is , nodes , are reordered according to their most likely membership .
the estimated reordering reveals the block model that was originally used to simulate 123
note that r = r any ( p; q ) pair .
in the case of single membership .
in fact , that implies f m
p ! qg = f m
p qh = 123 for some ( g; h ) pair , for
mixed membership stochastic blockmodels
the interactions .
as a increases , each node is likely to belong to more clusters .
as a consequence , they express interaction patterns of clusters .
this phenomenon reects in the reordered interaction matrices as the block structure is less evident .
nested variational inference .
the nested variational algorithm drives the log - likelihood to con - verge faster to its peak than the nave algorithm .
in figure 123 ( left panel ) we compare the running times of the nested variational - em algorithm versus the nave implementation .
the nested algo - rithm , which is more efcient in terms of space , converged faster .
furthermore , the nested varia - tional algorithm can be parallelized given that the updates for each interaction ( i; j ) are independent of one another .
choosing the number of blocks .
the right panel of figure 123 shows an example where cross - validation is sufcient to perform model selection for the mmb .
the example shown corresponds to a network among 123 nodes with k = 123 clusters .
we measure the number of latent clusters
figure 123 : adjacency matrices of corresponding to simulated interaction graphs with 123 nodes and 123 clusters , 123 nodes and 123 clusters , 123 nodes and 123 clusters ( top to bottom ) and equal to 123 : 123;123 : 123 and 123 : 123 ( left to right ) .
rows , which corresponds to nodes , are reordered according to their most likely membership .
the estimated reordering accurately reveals the original blockmodel .
airoldi , blei , fienberg and xing
on the x axis and the average held - out log - likelihood , corresponding to ve - fold cross - validation experiments , on the y axis .
the nested variational em algorithm was xrun until convergence , for each value of k we tested , with a tolerance of e = 123 ( cid : 123 ) 123
our estimate for k occurs at the peak in the average held - out log - likelihood , and equals the correct number of clusters , k ( cid : 123 ) = 123
123 application to social network analysis
we considered a friendship network among a group of 123 students in grades 123
the analysis here directly compares clustering results obtained by mmb to published clustering results obtained by competing models , in a setting where a fair amount of social segregation is expected ( doreian et al . , 123; handcock et al . , 123 ) .
the national longitudinal study of adolescent health is nationally representative study that explores the how social contexts such as families , friends , peers , schools , neighborhoods , and com - munities inuence health and risk behaviors of adolescents , and their outcomes in young adulthood ( harris et al . , 123; udry , 123 ) .
as part of the survey , a questionnaire was administered to a sam - ple of students in each school , who were allowed to nominate up to 123 friends .
we analyzed a friendship network among the students , at the same school that was considered by handcock et al .
( 123 ) and discussants .
friendship nominations were collected among 123 students in grades 123 to 123; two students did not nominate any friends .
the network of binary , asymmetric friendship relations among the remaining 123 students that constitutes our data is shown in figure 123 ( left ) .
time ( in seconds )
number of latent groups
figure 123 : left : the running time of the nave variational inference ( dashed , red line ) against the running time of our enhanced ( nested ) variational inference algorithm ( solid , black line ) , on a graph with 123 nodes and 123 clusters .
we measure the number of seconds on the x axis and the log - likelihood on the y axis .
the two curves are averages over 123 ex - periments , and the error bars are at three standard deviations .
each of the 123 pairs of experiments was initialized with the same values for the parameters .
right : the held - out log - likelihood is indicative of the true number of latent clusters , on simulated data .
we measure the number of latent clusters on the x axis and the log - likelihood on a test set on the y axis .
in the example shown , the peak identies the correct number of clusters , k ( cid : 123 ) = 123
mixed membership stochastic blockmodels
figure 123 : the posterior mixed membership scores , ~ p
, for the 123 students .
each panel correspond to a student; we order the clusters 123 to 123 on the x axis , and we measure the students grade of membership to these clusters on the y axis .
given the size of the network we used bic to perform model selection , as in the monks example of section 123 .
the results suggest a model with k ( cid : 123 ) = 123 groups .
( we x k ( cid : 123 ) = 123 in the analyses that follow . ) the hyper - parameters estimated with the nested variational em .
they are a = 123 : 123 , r = 123 : 123 , and a fairly diagonal blockmodel ,
figure 123 shows the expected posterior mixed membership scores for the 123 students in the sam - ple; few students display mixed membership .
the rarity of mixed membership in this context is expected , while mixed membership may signal unexpected social situations for further investiga - tion .
for instance , it may signal a family bond such as brotherhood , or a student that is repeating a grade and is thus part of a broader social clique .
in figure 123 , we contrast the friendship relation data ( left ) to the estimates obtained by thresholding the estimated probabilities of a relation , using the blockmodel and the node - specic latent variables ( center ) and the interactions - specic latent variables ( right ) .
the model provides a good summary of the social structure in the school; students
airoldi , blei , fienberg and xing
tend to befriend other students in the same grade , with a few exceptions .
the low degree of mixed membership explains the absence of obvious differences between the model - based reconstructions of the friendship relations with the two model variants ( center and right ) .
figure 123 : original matrix of friensdhip relations among 123 students in grades 123 to 123 ( left ) , and friendship estimated relations obtained by thresholding the posterior expectations
123b ~ p qjy ( center ) , and ~ f p
123b ~ f qjy ( right ) .
next , we attempted a quantitative evaluation of the goodness of t .
in this data , the blocks are clearly interpretable a - posteriori in terms of grades .
the mixed membership vectors provide a mapping between grades and blocks .
conditionally on such a mapping , we assign students to the grade they are most associated with , according to their posterior - mean mixed membership vectors , e ( ~ p njy ) .
to be fair in the comparison with competing models , we assign students to a unique gradedespite mmb allows for mixed membership .
table 123 computes the correspondence of grades to blocks by quoting the number of students in each grade - block pair , for mmb versus the mixture blockmodel ( mb ) in doreian et al .
( 123 ) , and the latent space cluster model ( lscm ) in handcock et al .
( 123 ) .
the higher the sum of counts on diagonal elements is the better is the correspondence , while the higher the sum of counts off diagonal elements is the worse is the cor - respondence .
mmb performs best by allocating 123 students to their grades , versus 123 of mb , and 123 of lscm .
correspondence only partially captures goodness of t , however , it is a good metric in the setting we consider , where a fair amount of clustering is present .
the results suggest that the extra - exibility mmb offers over mb and lscm reduces bias in the prediction of the membership of students to blocks .
in other words , mixed membership does not absorb noise in this example; rather it accommodates variability in the friendship relation that is instrumental in producing better
concluding this example , we note how the model decouples the observed friendship patterns into two complementary sources of variability .
on the one hand , the connectivity matrix b is a global , unconstrained set of hyper - parameters .
on the other hand , the mixed membership vectors ~ p 123 : n provide a collection of node - specic latent vectors , which inform the directed connections in the graph in a symmetric fashion .
123 application to protein interactions in saccharomyces cerevisiae
we considered physical interactions among 123 proteins in yeast .
the analysis allows us to evalu - ate the utility of mmb in summarizing and de - noising complex connectivity patterns quantitatively , using an independent set of functional annotations .
for instance , between two models that sug -
mixed membership stochastic blockmodels
table 123 : grade levels versus ( highest ) expected posterior membership for the 123 students , accord - ing to three alternative models .
mmb is the proposed mixed membership stochastic block - model , msb is a simpler stochastic block mixture model ( doreian et al . , 123 ) , and lscm is the latent space cluster model ( handcock et al . , 123 ) .
gest different sets of interactions as reliable , we prefer the model that reveals functionally relevant interactionsas measured using the annotations .
protein interactions ( ppi ) form the physical basis for the formation of stable protein complexes ( i . e . , protein clusters ) and signaling pathways ( i . e . , cascades of protein interaction events ) that carry out all major biological processes in the cell .
a number of high - throughput experimental tech - nologies have been devised to determine the set of interacting proteins on a global scale in yeast .
these include two - hybrid ( y123h ) screens and mass spectrometry methods ( gavin et al . , 123; ho et al . , 123; krogan et al . , 123 ) .
high - throughput technologies , however , often miss to identify interactions that are not present under the given conditions .
specic wet - lab methods employed by a certain technology , such as tagging , may disturb the formation of a stable protein complex , and weakly associated components may dissociate and escape detection .
statistical models that encode information about functional processes with high precision are an essential tool for carrying out probabilistic de - noising of biological signals from high - throughput experiments .
the goal of the analysis of protein interactions with mmb is to reveal the proteins diverse functional roles by analyzing their local and global patterns of interaction .
the biochemical compo - sition of individual proteins make them suitable for carrying out a specic set of cellular operations , or functions .
the main intuition behind our methodology is that pairs of protein interact because they participate in the same cellular process , as part of the same stable protein complex , that is , co - location , or because they are part of interacting protein complexes , as they carry out compatible cellular operations ( alberts et al . , 123 ) .
below , we describe the mips protein interactions data and the possible interpretations of the blocks in mmb in terms of biological functions , and we report results of two experiments .
123 . 123 protein interaction data and functional annotation data
the munich institute for protein sequencing ( mips ) database was created in 123 based on ev - idence derived from a variety of experimental techniques ( mewes et al . , 123 ) .
it includes a hand - curated collection of protein interactions that does not include interactions obtained with high - throughput technologies .
the collection covers about 123 protein complex associations in yeast .
airoldi , blei , fienberg and xing
we analyzed a subset of this collection containing 123 proteins , the interactions amongst which
the mips institute also provides a set of functional annotations for each protein .
these anno - tations are organized in a tree , with 123 nodes ( i . e . , high - level functions ) at the rst level , 123 nodes ( i . e . , the mid - level functions ) at the second level , and 123 nodes ( i . e . , the low - level functions ) at the the leaf level .
we mapped the 123 proteins in our collections to the high - level functions of the mips annotation tree .
table 123 quotes the number of proteins annotated to each of these 123 functions .
most proteins participate in more than one functional category , with an average of ( cid : 123 ) 123 : 123 functional anno - tations for each protein . .
the relative importance of functional categories in our collection , in terms of the number of proteins involved , is similar to the relative importance of functional categories over the entire mips collection .
we can also represent each protein in terms of its mips functional annotations .
this leads to a 123 - dimensional , binary representation for each protein , ~ bp , where a component ~ bp ( k ) = 123 indicates that protein p is annotated with function k in table 123
figure 123 shows the binary representations , ~ b123 : 123 , of the proteins in our collections; each panel corresponds to a protein; the 123 functional categories are ordered as in table 123 on the x axis , whereas the pres - ence or absence of the corresponding functional annotation is displayed on the y axis .
in section 123 . 123 , we t a mixed membership blockmodel with k = 123 , and we explore the direct correspon - dence between protein - specic mixed memberships to blocks , ~ p 123 : 123 , and mips - derived functional
an alternative source of functional annotations is the gene ontology ( go ) , distributed as part of the saccharomyces genome database ( ashburner et al . , 123 ) .
go provides vocabularies for describing the molecular function , biological process , and cellular component of gene products such as proteins .
terms are organized in a directed acyclic graph .
terms at the top represent broader , more general concepts , terms lower down represent more specic concepts .
there are two different relationship types between ( parent - child ) terms : is a and part of .
proteins are annotated to terms , and , most importantly , a protein is typically annotated to multiple terms , in different portions of the go annotation graph .
we restrict our evaluations to a collection of go terms that is specic enough for a co - annotation ( i . e . , two proteins annotated to the same term ) to be functionally relevant to molecular biologists ( myers et al . , 123 ) .
in section 123 . 123 , we select the mixed membership blockmodel best for predicting out - of - sample interactions , corresponding to
123 cell cycle & dna processing 123 transcription ( trna ) 123 protein synthesis 123 protein fate 123 cellular transportation 123 cell rescue , defence & virulence
interaction w / cell .
environment
123 cellular regulation 123 cellular other 123 control of cell organization 123 sub - cellular activities 123 protein regulators 123 transport facilitation
table 123 : the 123 high - level functional categories obtained by cutting the mips annotation tree at
the rst level and how many proteins ( out of 123 ) participate in each .
mixed membership stochastic blockmodels
k ( cid : 123 ) = 123 , and we explore its goodness - of - t indirectlyrather than attempting a direct interpretation of the models parameters , in terms of the number of predicted interactions that are functionally relevant according to go functional annotations .
123 . 123 direct evaluation : the model captures substantive biology
in the rst experiment , we t a model with k = 123 blocks , and we attempt a direct interpretation of the blocks in terms of the 123 high - level functional categories in the mips annotation tree separate from the mips protein interaction data , and independently conceived .
we discuss results
figure 123 : by mapping individual proteins to the 123 general functions in table 123 , we obtain a 123 - dimensional representation for each protein .
here , each panel corresponds to a protein; the 123 functional categories are displayed on the x axis , whereas the presence or absence of the corresponding functional annotation is displayed on the y axis .
the plots at the bottom zoom into three example panels ( proteins ) .
airoldi , blei , fienberg and xing
functional category given estimated identification
figure 123 : the mapping of blocks to functions is estimated by maximizing the accuracy of the pre - dicted annotations of 123 proteins .
we plot marginal frequencies of proteins membership to true functions ( left ) and to predicted functions ( right ) .
that portray the relevance of mixed membership , the resolution of the identication of blocks with functional categories , and selected predictions .
we want to compute the correspondence between protein - specic mixed memberships to blocks , ~ p 123 : 123 , and mips - derived functional annotations , ~ b123 : 123
the k = 123 blocks in the blockmodel b are not directly identiable in terms of functional categories .
in other words , we need to estimate a permutation of the components of ~ p n in order to be able to interpret e ( p n ( k ) jy ) as the expected degree of membership of protein n in function k of table 123rather than simply the expected degree of membership of protein n in block k , out of 123
to estimate the permutation that best identies blocks to functions , we proceeded as follows .
we sampled 123 proteins and their corresponding mips annotations , ~ b123 : 123
we predicted membership of the 123 proteins by thresholding their mixed
bn ( k ) = ( cid : 123 ) 123 if p n ( k ) > t
is the 123th percentile of the ensemble of elements of ~ p 123 : 123 , corresponding to the 123 proteins in the training set .
we then greedily identied the mapping that maximizing the accuracy of the predicted annotations of 123 proteins .
we used this mapping to compare predicted versus known functional annotations for all proteins; in figure 123 we plot marginal frequencies of proteins mem - bership to true functions ( left panel ) and to predicted functions ( right panel ) .
the accuracy on the 123% testing set is about 123% .
an algorithm that randomly guesses annotations , knowing the right proportions of annotations in each category , leads to a baseline accuracy of about 123% .
figure 123 shows predicted mixed memberships ( dashed , red lines ) versus the true annotations ( solid , black lines ) , given the estimated mapping of blocks to functions , for six example proteins .
123 . 123 indirect evaluation : functional content of predicted interactions
in the second experiment , we selected the mixed membership blockmodel best for predicting out - of - sample interactions , and we explored its goodness - of - t indirectly , in terms of the number of
mixed membership stochastic blockmodels
predicted interactions that are functionally relevant according to go present in estimated protein interaction networks obtained with the two types of analyses that mmb supports; summarization
we t models with k ranging between 123 and 123
we selected the best model ( k = 123 ) using cross - validated held - out log likelihood , as in figure 123
this nding supports the hypothesis that proteins derived from the mips data are interpretable in terms functional biological contexts .
al - ternatively , the blocks might encode signal at a ner resolution , such as that of protein complexes .
123 123 123
123 123 123
123 123 123
123 123 123
123 123 123
123 123 123
figure 123 : predicted mixed - memberships ( dashed , red lines ) versus binary manually curated func - tional annotations ( solid , black lines ) for six example proteins , given the estimated map - ping of blocks to functions in figure 123
airoldi , blei , fienberg and xing
gavin et al .
( 123 , aff .
precipitation ) ho et al .
( 123 , aff .
precipitation ) tong et al .
( 123 , synthetic lethality ) uetz et al .
( 123 , two hybrid ) ito et al .
( 123 , two hybrid ) ito et al .
( 123 , two hybrid ) tong et al .
( 123 , two hybrid ) fromont - racine et al .
( two hybrid ) drees et al .
( 123 , two hybrid ) gasch et al .
( 123 , expression m icroarray ) gasch et al .
( 123 , expression m icroarray ) spellman et al .
( 123 , expression m icroarray ) m ewes et al .
( 123 , m ips database ) m m b ( m ips data de - noised with zs & b , 123 blocks ) m m b ( m ips data summarized with ( cid : 123 ) s & b , 123 blocks )
figure 123 : in the top panel we measure the functional content of the the mips collection of pro - tein interactions ( yellow diamond ) , and compare it against other published collections of interactions and microarray data , and to the posterior estimates of the mmb models computed as described in section 123 . 123
a breakdown of three estimated interaction networks ( the points annotated 123 , 123 , and 123 ) into most represented gene ontology cate - gories is detailed in table 123
if that was the case , however , we would expect the optimal number of blocks to be signicantly higher; 123=123 ( cid : 123 ) 123 , given an average size of ve proteins in a complex ( krogan et al . , 123 ) .
using this model , we computed posterior model - based expectations of each interaction as fol -
e ( y ( p; q ) ) ( cid : 123 ) b ~ p p
e ( y ( p; q ) ) ( cid : 123 ) b ~ f
these computations lead to two estimated protein interaction networks with expected probabilities of interactions taking values in ( 123;123 ) .
we obtained binary protein interaction networks by thresh - olding these expected probabilities at ten different values .
in terms of the two analyses described in section 123 , this amount to either ( i ) predicting physical interactions by thresholding the posterior expectations computed using blockmodel b and mixed membership map ~ p s , essentially a predic - tion task , or ( ii ) we de - noise the observed interactions y using the blockmodel b and interaction - specic membership indicators zs , essentially a de - noising task .
we use the independent set of functional annotations from the gene ontology to decide which interactions are functionally mean - ingful; namely those between pairs of proteins that share at least one functional annotation ( myers et al . , 123 ) .
in this sense , between two models that suggest different sets of interactions as reliable , our evaluation assigns a higher score to the model that reveals functionally relevant interactions .
figure 123 shows the functional content of the original mips collection of physical interactions ( point no . 123 ) , and of the collections of interactions computed using ( b;p s ) , the light blue ( ( cid : 123 ) ( cid : 123 ) ) line , and using ( b; zs ) , the dark blue ( ( cid : 123 ) + ) line , thresholded at ten different levelsprecision - recall curves .
the posterior means of p s provide a parsimonious representation for the mips collection , and lead to precise interaction estimates , in moderate amount ( ( cid : 123 ) ( cid : 123 ) line ) .
the posterior means of zs provide a richer representation for the data , and describe most of the functional content of the mips collection with high precision ( ( cid : 123 ) + line ) .
figure 123 also shows the functional content of the original mips collection ( the yellow diamond ) .
most importantly , notice the estimated protein interaction
mixed membership stochastic blockmodels
networks , that is , ex - es and crosses , corresponding to lower levels of recall feature a more precise functional content than the original .
this means that the proposed latent block structure is helpful in summarizing the collection of interactionsby ranking them properly .
on closer inspection , dense blocks of predicted interactions contain known functional predictions that were not in the mips collection , thus effectively improving the quality of the data that instantiate activity specic to few biological contexts , such as biopolymer catabolism and homeostasis .
in conclusion , results suggest that mmb successfully reduces the dimensionality of the data , while revealing substantive informa - tion about the multiple functionality of proteins that can be used to inform subsequent analyses .
table 123 provides more information about three instances of predicted interaction networks dis - played in figure 123; those corresponding the points annotated 123 , 123 , and 123
specically , the table shows a breakdown of the predicted ( posterior ) collections of interactions in each example network into the gene ontology categories .
a count in the table corresponds to the fact that both proteins are annotated with the same go functional category . 123
in this application , the mmb learned information about ( i ) the mixed membership of objects to latent groups , and ( ii ) the connectivity patterns among latent groups .
these estimates were useful in describing and summarizing the functional content of the mips collection of protein interac - tions .
this suggests the use of mmb as a dimensionality reduction approach that may be useful for performing model - driven de - noising of new collections of interactions , such as those measured via
modern probabilistic models for relational data analysis are rooted in the stochastic blockmodels for psychometric and sociological analysis , pioneered by lorrain and white ( 123 ) and by holland and leinhardt ( 123 ) .
in statistics , this line of research has been extended in various contexts over the years ( fienberg et al . , 123; wasserman and pattison , 123; snijders , 123; hoff et al . , 123; doreian et al . , 123 ) .
in machine learning , the related technique of markov random networks ( frank and strauss , 123 ) have been used for link prediction ( taskar et al . , 123 ) and the traditional blockmodels have been extended to include nonparametric bayesian priors ( kemp et al . , 123 , 123; xu et al . , 123 ) and to integrate relations and text ( mccallum et al . , 123 ) .
there is a close relationship between the mmb and the latent space models ( hoff et al . , 123; handcock et al . , 123 ) .
in the latent space models , the latent vectors are drawn from gaussian distributions and the interaction data is drawn from a gaussian with mean ~ p p 123i ~ p q .
in the mmb , the marginal probability of an interaction takes a similar form , ~ p p 123b ~ p q , where b is the matrix of probabilities of interactions for each pair of latent groups .
two major differences exist between these approaches .
in mmb , the distribution over the latent vectors is a dirichlet and the underlying data distribution is arbitrarywe have chosen bernoulli .
the posterior inference in latent space models ( hoff et al . , 123; handcock et al . , 123 ) is carried out via mcmc sampling , while we have developed a scalable variational inference algorithm to analyze large network structures .
( it would be interesting to develop a variational algorithm for the latent space models as well . ) a number of well - designed numerical investigations and comparisons between variational em and variants of mcmc have been performed in existing literature; for instance , see buntine and jakulin ( 123 ) , 123
note that , in go , proteins are typically annotated to multiple functional categories .
see corresponding slides with additional results .
( http : / / www . hiit . fi / buntine / dpca\_slides . pdf )
airoldi , blei , fienberg and xing
# go term 123 go : 123 biopolymer catabolism 123 go : 123 transcription from rna polymerase ii promoter 123 go : 123 protein biosynthesis 123 go : 123 dna replication 123 go : 123 protein complex assembly 123 go : 123 chromatin modication 123 go : 123 protein amino acid acetylation 123 go : 123 transcription from rna polymerase i promoter 123 go : 123 homeostasis 123 go : 123 biopolymer catabolism 123 go : 123 transcription from rna polymerase ii promoter 123 go : 123 chromatin modication 123 go : 123 dna replication 123 go : 123 protein biosynthesis 123 go : 123 secretory pathway 123 go : 123 phosphorus metabolism 123 go : 123 golgi vesicle transport 123 go : 123 transcription initiation 123 go : 123 protein biosynthesis 123 go : 123 protein complex assembly 123 go : 123 regulation of biosynthesis 123 go : 123 regulation of protein metabolism 123 go : 123 ribosome biogenesis 123 go : 123 ubiquitin cycle
table 123 : breakdown of three example interaction networks into most represented gene ontology categoriessee text for more details .
the digit in the rst column indicates the example network in figure 123 that any given line refers to .
the last two columns quote the number of predicted , and possible pairs for each go term .
and braun and mcauliffe ( 123 ) .
we refer readers interested in the comparison between variational vs .
mcmc to these resources .
the model decouples the observed connectivity patterns into two sources of variability , b;p s , that are apparently in competition for explaining the data , possibly raising an identiability issue .
this is not the case , however , as the blockmodel b captures global / asymmetric relations , while the mixed membership vectors p s capture local / symmetric relations .
this difference practically eliminates the issue , unless there is no signal in the data to begin with .
a recurring question , which bears relevance to mixed membership models in general , is why we do not integrate out the single membership indicators ( ~ z p ! q; ~ zp q ) .
while this may lead to computational efciencies we would often lose interpretable quantities that are useful for making predictions , for de - noising new measurements , or for performing other tasks .
in fact , the posterior distributions of such quantities typically carry substantive information about elements of the appli -
mixed membership stochastic blockmodels
cation at hand .
in the application to protein interaction networks of section 123 , for example , they encode the interaction - specic memberships of individual proteins to protein complexes .
in the relational setting , cross - validation is feasible if the blockmodel estimated on training data can be expected to hold on test data; for this to happen the network must be of reasonable size , so that we can expect members of each block to be in both training and test sets .
in this setting , scheduling of variational updates is important; nested variational scheduling leads to efcient and
a limitation of our model can be best appreciated in a simulation setting .
if we consider struc - tural properties of the network mmb is capable of generating , we count a wide array of local and global connectivity patterns .
but the model does not readily generate hubs , that is , nodes con - nected with a large number of directed or undirected connections , or networks with skewed degree
from a data analysis perspective , we speculate that the value of mmb in capturing substan - tive information about a problem will increase in semi - supervised settingwhere , for example , information about the membership of genes to functional contexts is included in the form of prior distributions .
in such a setting we may be interested in looking at the change between prior and posterior membership; a sharp change may signal biological phenomena worth investigating .
we need not assume that the number of groups / blocks , k , is nite .
it is possible , for example , to posit that the mixed - membership vectors are sampled form a stochastic process , in the nonparametric set - ting .
to maintain mixed membership of nodes to groups / blocks in such setting , we need to sample them from a hierarchical dirichlet process ( teh et al . , 123 ) , rather than from a dirichlet process ( escobar and west , 123 ) .
mmb generalizes to two important cases .
first , multiple data collections y123 : m on the same objects can be generated by the same latent vectors .
this might be useful , for example , for simul - taneously analyzing the relational measurements about esteem and disesteem , liking and disliking , positive inuence and negative inuence , praise and blame , for example , see sampson ( 123 ) , or those about the collection of 123 relations measured by bradley ( 123 ) .
second , in the mmb the data generating distribution is a bernoulli , but b can be a matrix that parameterizes any kind of distribution .
for example , technologies for measuring interactions between pairs of proteins such as mass spectrometry ( ho et al . , 123 ) and tandem afnity purication ( gavin et al . , 123 ) return a probabilistic assessment about the presence of interactions , thus setting the range of y ( p; q ) to ( 123;123 ) .
this is not the case for the manually curated collection of interactions we analyze in section 123 .
in this paper we introduced mixed membership stochastic blockmodels , a novel class of latent vari - able models for relational data .
these models provide exploratory tools for scientic analyses in applications where the observations can be represented as a collection of unipartite graphs .
the nested variational inference algorithm is parallelizable and allows fast approximate inference on
airoldi , blei , fienberg and xing
this work was partially supported by national institutes of health under grant no .
r123 ag123 - 123 , by the ofce of naval research under contracts n123 - 123 - 123 - 123 and 123 - 123 , by the na - tional science foundation under grants no .
dms - 123 , iis - 123 , iis - 123and dbi - 123 , by the pennsylvania department of healths health research program under grant no .
123nf - cancer health research grant me - 123 - 123 , and by the department of defense , all to carnegie mellon university .
the authors would like to thank david banks and jim berger at duke university , alan karr at the national institute of statistical sciences for insight and advice , and acknowledge generous support from the statistical and applied mathematical sciences institute .
appendix a .
general model formulation
in general , mixed membership stochastic blockmodels can be specied in terms of assumptions at four levels : population , node , latent variable , and sampling scheme level .
a . 123 population level
assume that there are k classes or sub - populations in the population of interest .
we denote by f ( y ( p; q ) j b ( g; h ) ) the probability distribution of the relation measured on the pair of nodes ( p; q ) , where the p - th node is in the h - th sub - population , the q - th node is in the h - th sub - population , and b ( g; h ) contains the relevant parameters .
the indices i; j run in 123; : : : ; n , and the indices g; h run in 123; : : : ; k .
a . 123 node level the components of the membership vector ~ p p = ( ~ p p ( 123 ) ; : : : ; ~ p p ( k ) ) 123 encodes the mixed membership of the n - th node to the various sub - populations .
the distribution of the observed response y ( p; q ) given the relevant , node - specic memberships , ( ~ p p; ~ p q ) , is then
pr ( y ( p; q ) j ~ p p; ~ p q; b ) =
~ p p ( g ) f ( y ( p; q ) j b ( g; h ) ) ~ p q ( h ) :
conditional on the mixed memberships , the response edges y jnm are independent of one another , both across distinct graphs and pairs of nodes .
a . 123 latent variable level assume that the mixed membership vectors ~ p 123 : n are realizations of a latent variable with distribution
the probability of observing y ( p; q ) , given the parameters , is then
, with parameter vector ~ a
pr ( y ( p; q ) j ~ a
; b ) = z pr ( y ( p; q ) j ~ p p; ~ p q; b ) d ~ a ( d ~ p ) :
a . 123 sampling scheme level
assume that the m independent replications of the relations measured on the population of nodes are independent of one another .
the probability of observing the whole collection of graphs , y123 : m , given the parameters , is then given by the following equation .
pr ( y123 : m j ~ a
; b ) =
pr ( ym ( p; q ) j ~ a
; b ) :
mixed membership stochastic blockmodels
full model specications immediately adapt to the different kinds of data , for example , multiple data types through the choice of f , or parametric or semi - parametric specications of the prior on the number of clusters through the choice of a distribution for the p s , da
appendix b .
details of the variational approximation
here we present more details about the derivation of the variational em algorithm presented in section 123
furthermore , we address a setting where m replicates are available about the paired measurements , g123 : m = ( n;y123 : m ) , and relations ym ( p; q ) take values into an arbitrary metric space according to f ( ym ( p; q ) j : : ) .
an extension of the inference algorithm to address the case or multivariate relations , say j - dimensional , and multiple blockmodels b123 : j each corresponding to a distinct relational response , can be derived with minor modications of the derivations that follow .
b . 123 variational expectation - maximization
we begin by briey summarizing the general strategy we intend to use .
the approximate variant of em we describe here is often referred to as variational em ( beal and ghahramani , 123 ) .
recall that y denotes the data .
rewrite x = ( ~ p 123 : n; z ! ; z ) for the latent variables , and q = ( ~ a ; b ) for the models parameters .
briey , it is possible to lower bound the likelihood , p ( y jq ) , making use of jensens inequality and of any distribution on the latent variables q ( x ) ,
p ( y; xjq )
p ( y; xjq ) dx
p ( y jq ) = logzx = eq ( log p ( y; xjq ) ( cid : 123 ) logq ( x ) ) = : l ( q;q ) in em , the lower bound l ( q;q ) is then iteratively maximized with respect to q q in the e step ( dempster et al . , 123 ) .
in particular , at the t - th iteration of the e step we set
( for any q )
p ( y; xjq )
, in the m step , and
q ( t ) = p ( xjy;q
that is , equal to the posterior distribution of the latent variables given the data and the estimates of the parameters at the previous iteration .
unfortunately , we cannot compute the posterior in equation 123 for the admixture of latent blocks model .
rather , we dene a direct parametric approximation to it , q = qd ( x ) , which involves an extra set of variational parameters , d , and entails an approximate lower bound for the likelihood ld ( q;q ) .
at the t - th iteration of the e step , we then minimize the kullback - leibler divergence between q ( t ) and q ( t ) , using the data . 123 the optimal parametric approximation is , in fact , a proper posterior as it depends on the data y , although indirectly , q ( t ) ( cid : 123 ) q ( t ) d ( cid : 123 ) ( y ) ( x ) = p ( xjy ) .
, with respect to d
b . 123 lower bound for the likelihood
according to the mean - eld theory ( jordan et al . , 123 ) , one can approximate an intractable distri - bution such as the one dened by equation ( 123 ) by a fully factored distribution q ( ~ p 123 : n; z ! 123
this is equivalent to maximizing the approximate lower bound for the likelihood , ld ( q;q ) , with respect to d
airoldi , blei , fienberg and xing
dened as follows :
q ( ~ p 123 : n; z !
q123 ( ~ p pj ~ g p ) ( cid : 123 )
123 : mj ~ g 123 : n;f !
p qj ~ f m
minimizing the kulback - leibler divergence between this q ( ~ p 123 : n; z !
where q123 is a dirichlet , q123 is a multinomial , and d = ( ~ g 123 : n;f ! variational parameters need to be estimated in the approximate distribution .
p ( ~ p 123 : n; z !
123 : m ) represent the set of free 123 : mjd ) and the original 123 : m dened by equation ( 123 ) leads to the following approximate lower bound for the
ld ( q;q ) = eq ( cid : 123 ) log ( cid : 123 ) + eq ( cid : 123 ) log ( cid : 123 ) + eq ( cid : 123 ) log ( cid : 123 ) ( cid : 123 ) eq ( cid : 123 ) log ( cid : 123 )
p123 ( ~ p pj ~ a ) ( cid : 123 ) ( cid : 123 ) eq ( cid : 123 ) ( cid : 123 )
p q; b ) ( cid : 123 ) p ! qj ~ p p;123 ) ( cid : 123 ) +eq ( cid : 123 ) log ( cid : 123 ) q123 ( ~ p pj ~ g p ) ( cid : 123 ) p ! q;123 ) ( cid : 123 ) ( cid : 123 ) eq ( cid : 123 ) log ( cid : 123 ) p q;h ( cid : 123 ) f ( cid : 123 ) ym ( p; q ) ; b ( g; h ) ( cid : 123 )
working on the single expectations leads to
p qj ~ p q;123 ) ( cid : 123 )
p qj ~ f m
p q;123 ) ( cid : 123 ) :
ld ( q;q ) = ( cid : 123 )
p ! q;g ( cid : 123 ) y ( g p;g ) ( cid : 123 ) y ( ( cid : 123 ) p q;h ( cid : 123 ) y ( g p;h ) ( cid : 123 ) y ( ( cid : 123 ) ( a k ( cid : 123 ) 123 ) ( cid : 123 ) y ( g p;k ) ( cid : 123 ) y ( ( cid : 123 ) logg ( a k ) + ( cid : 123 ) a k ) ( cid : 123 ) ( cid : 123 ) g p;k ) + ( cid : 123 ) logg ( g p;k ) ( cid : 123 ) ( cid : 123 ) ( g p;k ( cid : 123 ) 123 ) ( cid : 123 ) y ( g p;k ) ( cid : 123 ) y ( ( cid : 123 ) p ! q;g logf m
p q;h logf m
f ( ym ( p; q ) ; b ( g; h ) ) = ym ( p; q ) logb ( g; h ) + ( 123 ( cid : 123 ) ym ( p; q ) ) log ( 123 ( cid : 123 ) b ( g; h ) ) ;
m runs over 123; : : : ; m; p; q run over 123; : : : ; n; g; h; k run over 123; : : : ; k; and y ( x ) is the derivative of the log - gamma function , d logg ( x )
b . 123 the expected value of the log of a dirichlet random vector the computation of the lower bound for the likelihood requires us to evaluate eq ( log ~ p p ) for p = 123; : : : ; n .
recall that the density of an exponential family distribution with natural parameter ~ q can be written as
p ( xja ) = h ( x ) ( cid : 123 ) c ( a ) ( cid : 123 ) exp f ( cid : 123 )
q k ( a ) ( cid : 123 ) tk ( x ) g
= h ( x ) ( cid : 123 ) exp f ( cid : 123 )
q k ( a ) ( cid : 123 ) tk ( x ) ( cid : 123 ) logc ( a ) g :
mixed membership stochastic blockmodels
omitting the node index p for convenience , we can rewrite the density of the dirichlet distribution p123 as an exponential family distribution ,
p123 ( ~ p j ~ a ) = exp ( cid : 123 ) ( cid : 123 )
( a k ( cid : 123 ) 123 ) log ( p k ) ( cid : 123 ) log
k g ( a k )
k a k ) ( cid : 123 ) ;
with natural parameters q k ( ~ a ) = ( a k ( cid : 123 ) 123 ) and natural sufcient statistics tk ( ~ p ) = log ( p k ) .
let c123 ( ~ q ) = c ( a 123 ( ~ q ) ; : : : ;a k ( ~ q ) ) ; using a well known property of the exponential family distributions ( schervish , 123 ) we nd that
eq ( logp k ) = e ~ q
( logtk ( x ) ) = y
( a k ) ( cid : 123 ) y
a k ) ;
where y ( x ) is the derivative of the log - gamma function , d logg ( x )
b . 123 variational e step the approximate lower bound for the likelihood ld ( q;q ) can be maximized using exponential family arguments and coordinate ascent ( wainwright and jordan , 123 ) .
p ! q;g ( q;q )
p ! q;g and f m p q corresponding to the natural sufcient statistics log ( ~ zm
isolating terms containing f m p ! q and ~ gm
p ! q;g ( q;q ) and lf m
p q;h we obtain lf m
p q ) are functions of the other latent variables and the observations .
we nd that
natural parameters ~ gm
p ! q;g = logp p;g + ( cid : 123 ) p q;h = logp q;h + ( cid : 123 )
p q;h ( cid : 123 ) f ( ym ( p; q ) ; b ( g; h ) ) ;
p ! q;g ( cid : 123 ) f ( ym ( p; q ) ; b ( g; h ) ) ;
for all pairs of nodes ( p; q ) in the m - th network; where g; h = 123; : : : ; k , and
f ( ym ( p; q ) ; b ( g; h ) ) = ym ( p; q ) logb ( g; h ) + ( 123 ( cid : 123 ) ym ( p; q ) ) log ( 123 ( cid : 123 ) b ( g; h ) ) :
this leads to the following updates for the variational parameters ( ~ f m ( p; q ) in the m - th network :
p q ) , for a pair of nodes
= e eq ( logp p;g ) ( cid : 123 ) e ( cid : 123 ) h f m = e eq ( logp p;g ) ( cid : 123 ) ( cid : 123 )
p q;h ( cid : 123 ) eq ( f ( ym ( p;q ) ;b ( g;h ) ) )
h ( cid : 123 ) b ( g; h ) ym ( p;q ) ( cid : 123 ) ( 123 ( cid : 123 ) b ( g; h ) ) 123 ( cid : 123 ) ym ( p;q ) ( cid : 123 ) f m
= e eq ( logp q;h ) ( cid : 123 ) e ( cid : 123 ) g f m = e eq ( logp q;h ) ( cid : 123 ) ( cid : 123 )
p ! q;g ( cid : 123 ) eq ( f ( ym ( p;q ) ;b ( g;h ) ) )
g ( cid : 123 ) b ( g; h ) ym ( p;q ) ( cid : 123 ) ( 123 ( cid : 123 ) b ( g; h ) ) 123 ( cid : 123 ) ym ( p;q ) ( cid : 123 ) f m
for g; h = 123; : : : ; k .
these estimates of the parameters underlying the distribution of the nodes group
p q need be normalized , to make sure ( cid : 123 )
p ! q and ~ f m
p ! q;k = ( cid : 123 )
p q;k = 123
airoldi , blei , fienberg and xing
isolating terms containing g p;k we obtain lg p;k ( q;q ) .
setting
g p;k yields :
equal to zero and solving for
g p;k = a k + ( cid : 123 )
for all nodes p 123 p and k = 123; : : : ; k .
the t - th iteration of the variational e step is carried out for xed values of q ( t ( cid : 123 ) 123 ) ; b ( t ( cid : 123 ) 123 ) ) , and nds the optimal approximate lower bound for the likelihood ld ( cid : 123 ) ( q;q
b . 123 variational m step the optimal lower bound ld ( cid : 123 ) ( q ( t ( cid : 123 ) 123 ) ;q ) provides a tractable surrogate for the likelihood at the t - th iteration of the variational m step .
we derive empirical bayes estimates for the hyper - parameters , given expected
that are based upon it . 123 that is , we maximize ld ( cid : 123 ) ( q ( t ( cid : 123 ) 123 ) ;q ) with respect to q
sufcient statistics computed using ld ( cid : 123 ) ( q ( t ( cid : 123 ) 123 ) ;q
isolating terms containing ~ a we obtain l ~ a ( q;q ) .
unfortunately , a closed form solution for the approximate maximum likelihood estimate of ~ a does not exist ( blei et al . , 123 ) .
we can produce a newton - raphson method that is linear in time , where the gradient and hessian for the bound l ~ a
= n ( cid : 123 ) y = n ( cid : 123 ) i ( k123=k123 ) ( cid : 123 ) y m ( cid : 123 ) ( cid : 123 )
b ( g; h ) =
a k ) ( cid : 123 ) y ( a k ) ( cid : 123 ) + ( cid : 123 ) 123 ( ( cid : 123 )
123 ( a k123 ) ( cid : 123 ) y
g p;k ) ( cid : 123 ) ;
p ( cid : 123 ) y ( g p;k ) ( cid : 123 ) y a k ) ( cid : 123 ) :
p;qym ( p; q ) ( cid : 123 ) f m ( 123 ( cid : 123 ) r ) ( cid : 123 ) ( cid : 123 ) p;q f m
p qh ( cid : 123 ) ;
isolating terms containing b we obtain lb , whose approximate maximum is
for every index pair ( g; h ) 123 ( 123; k ) ( cid : 123 ) ( 123; k ) .
in section 123 we introduced an extra parameter , r
, to control the relative importance of presence and absence of interactions in likelihood , that is , the score that informs inference and estimation .
isolating terms containing r we obtain lr .
we may then estimate the sparsity parameter r by
m ( cid : 123 ) ( cid : 123 )
p;q ( 123 ( cid : 123 ) ym ( p; q ) ) ( cid : 123 ) ( ( cid : 123 ) g;h f m
p;q ( cid : 123 ) g;h f m
p qh )
alternatively , we can x r prior to the analysis; the density of the interaction matrix is estimated with d = ( cid : 123 ) m;p;qym ( p; q ) = ( n123m ) , and the sparsity parameter is set to r = ( 123 ( cid : 123 ) d ) .
this latter estima - tor attributes all the information in the non - interactions to the point mass , that is , to latent sources other than the block model b or the mixed membership vectors ~ p 123 : n .
it does , however , provide a quick recipe to reduce the computational burden during exploratory analyses . 123
we could term these estimates pseudo empirical bayes estimates , since they maximize an approximate lower bound
for the likelihood , ld ( cid : 123 ) .
note that r = r any ( p; q ) pair .
in the case of single membership .
in fact , that implies f m
p ! qg = f m
p qh = 123 for some ( g; h ) pair , for
mixed membership stochastic blockmodels
