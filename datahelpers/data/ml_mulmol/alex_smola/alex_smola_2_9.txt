targeting interest to match a user with services ( e . g .
news , products , games , advertisements ) and predicting friendship to build connections among users are two fundamental tasks for social network systems .
in this paper , we show that the information contained in interest networks ( i . e .
user - service interactions ) and friendship networks ( i . e .
user - user connec - tions ) is highly correlated and mutually helpful .
we propose a framework that exploits homophily to establish an inte - grated network linking a user to interested services and con - necting dierent users with common interests , upon which both friendship and interests could be eciently propagated .
the proposed friendship - interest propagation ( fip ) frame - work devises a factor - based random walk model to explain friendship connections , and simultaneously it uses a coupled latent factor model to uncover interest interactions .
we dis - cuss the exibility of the framework in the choices of loss ob - jectives and regularization penalties and benchmark dier - ent variants on the yahoo ! pulse social networking system .
experiments demonstrate that by coupling friendship with interest , fip achieves much higher performance on both in - terest targeting and friendship prediction than systems using only one source of information .
categories and subject descriptors h . 123 ( information systems ) : web - based interaction; h . 123 ( information search and retrieval ) : information ltering
algorithms , performance , experimentation
social network , link prediction , interest targeting
online social networking services have brought to the pub - lic a new style of social lives parallel to our day - to - day oine activities .
popular social network sites , such as facebook , linkedin and twitter have already gathered billions of ex - tensively acting users and are still attracting thousands of
copyright is held by the international world wide web conference com - mittee ( iw123c123 ) .
distribution of these papers is limited to classroom use , and personal use by others .
www 123 , march 123april 123 , 123 , hyderabad , india .
enthusiastic newbies each day .
doubtlessly , social networks have become one of todays major platforms for building friendship and sharing interests .
figure 123 : a social network graph .
the connections consist of both ( unipartite ) edges within the user - user friendship network and bipartite user - item in - teractions in the interest network .
fundamental to all social network services is the goal to eectively model the interests of a user and the friendship between users ( 123 ) .
on the one hand , by capturing a users interests and accordingly exploiting the opportunity to serve her / him with potentially interesting service items ( e . g .
news , games , advertisements , products ) , one can improve the sat - isfaction of a users participation and boost the revenue of a social network site as well ( e . g .
via product purchases , vir - tual transactions , advertisement clicks ) .
on the other hand , connecting people with common interests is not only impor - tant for improving existing users loyalty , but also helps to attract new costumers to boost the sites trac .
friendship prediction ( a . k . a .
link prediction ) and interest targeting ( a . k . a .
service recommendation ) are two important tools available in almost all the major social network sites .
both activities which occur routinely in a social network have accrued a tremendous wealth of interaction traces , both among users ( i . e .
friendship network ) and between users and service items ( i . e .
interest network ) .
figure 123 depicts a typi - cal topology of a heterogeneous graph in the context of social 123 interests and friendship
modeling user interests and friendship in social networks raises unique challenges to both research and engineering communities .
the information about a users behaviors is often scattered in both friendship and interest networks , in - volving other users that are closely connected to the user
www 123 session : temporal dynamicsmarch 123april 123 , 123 , hyderabad , india123 and dierent activities that the user has engaged in .
a fun - damental mechanism that drives the dynamics of networks is the underlying social phenomenon of homophily ( 123 ) : peo - ple with similar interest tend to connect to each other and people of similar interest are more likely to be friends .
traditional user proling approaches often do not take full advantage of this fact .
instead they either employ fea - ture engineering to generate hand - crafted meta - descriptors as ngerprint for a user ( 123 , 123 ) or they extract a set of latent features by factorizing a users registered prole data; for example , by means of sparse coding ( 123 ) or latent dirichlet allocation ( 123 ) .
these approaches could be inaccurate be - cause neither user friendship nor user behavior information is taken into account .
recent approaches resort to collaborative ltering ( cf ) techniques ( 123 , 123 , 123 , 123 ) to prole user interests by collabo - ratively uncovering user behaviors , where users are assumed to be unrelated to each other .
while cf performs well in recommendation systems where decisions are mainly made individually and independently , it could fail in the context of social networks where user interactions substantially in - uence decision making ( 123 , 123 ) .
modeling friendship is equally challenging .
a typical so - cial network is a graph both large and sparse , involving hun - dreds of millions of users with each being connected to only a tiny proportion of the whole virtual world .
this property rules out traditional spectral algorithms for graph mining ( 123 , 123 ) and calls for algorithms that are both ecient to handle large scale connections and capable of reliably learn - ing from rare , noisy and largely missing observations .
un - fortunately , progress on this topic to date is limited ( 123 ) .
123 friendship interest propagation
this paper exploits the important role homophily plays in social networks .
we show that friendship and interest in - formation is highly correlated ( i . e .
closely - connected friends tend to have similar interests ) and mutually helpful ( i . e .
much higher performance for both friendship prediction and interest targeting could be achieved if coupling the two pro - cesses to exploit both sources of evidence simultaneously ) .
we present a friendship - interest propagation ( fip ) model that integrates the learning for interest targeting and friend - ship prediction into one single process .
the key idea in fip is to associate latent factors with both users and items , and to dene coupled models to encode both interest and friendship information .
in particular , fip de - nes a shared latent factor to assure dynamical interaction between friendship network and interest network during the learning process .
in doing so , fip integrates both interest and friendship networks to connect a user to both items of potential interest and other users with similar interests .
fip hereby provides a single unied framework to address both link prediction and interest targeting while enjoying the re - sources of both sources of evidence .
experiments on yahoo ! pulse demonstrate that , by coupling friendship with inter - est , fip achieves much higher performance on both tasks .
the contributions of this work are three - fold :
we present the friendship - interest propagation model that propagates two dierent types of evidence through
we formulate the fip model in a computational frame - work , discuss the exibility in the choices of loss objec - tives ( e . g .
( cid : 123 ) 123 , logistic regression , hubers loss ) and reg -
ularization penalties ( e . g .
sparse coding , ( cid : 123 ) 123 penalties ) and we benchmark dierent variants in a real - world social networking system;
for the implementation of fip , we present a built - in scheme for bias correction based on pseudo - negative sampling to avoid overtting , and we also deliver an optimization package that allows distributed optimiza - tion on streaming data .
outline : 123 describes the background .
123 presents the de - tailed fip model and our distributed implementation .
123 reports experiments and results .
123 reviews related work and 123 summarizes the results .
problem definition we begin by briey reviewing the state - of - the - art .
this will come in handy as we will link them to our model in 123
modeling dyadic interactions is the heart of many web ap - plications , including link prediction and interest targeting .
typically , a pair of instances from two parties ( such as users and items ) , i i and j j , interact with each other with a response yij y .
the mapping
( ( i , j ) yij where i i , j j )
constitutes a large matrix y y|i||j | , of which only a tiny proportion of entries are observable; the goal is to infer the value of a missing entry yij , given an incoming pair ( i , j ) .
essentially , the observed interactions dene a graph , either unipartite ( when i = j ) or bipartite .
the task amounts to propagating the sparse observations to the remainder ( un - observed ) part of the matrix .
for convenience we will hence - forth refer to i as user and j as item unless stated otherwise .
123 interest targeting
interest targeting , or ( service ) recommendation , works with
a bipartite graph between two dierent parties , e . g .
user i and item j .
it aims at matching the best item j to a given user i .
we consider collaborative ltering ( cf ) approaches , which tackle the problem by learning from past interactions .
neighborhood models .
a popular approach to cf is based on the principle of locality of dependencies , which assumes that the interaction between user i and item j can be restored solely upon the observations of neighboring users or items ( 123 , 123 ) .
such neighborhood - based models therefore propagate similar items to a particular user ( item - oriented ) or recommend a particular item to similar users ( user - oriented ) .
basically , it predicts the interest of user i to item j by averaging the neighboring observations .
for instance , the user - oriented model uses : i ( cid : 123 ) i ii ( cid : 123 ) yi ( cid : 123 ) j
where ii ( cid : 123 ) measures the similarity , e . g .
pearson correlation coecient , between user i and its neighbor i
latent factor models .
this class of methods attempt to learn informative latent factors to uncover the dyadic in - teractions .
the basic idea is to associate latent factors , 123
123throughout this paper , we assume each latent factor contains a constant component so as to absorb user / item - specic oset into latent factors .
www 123 session : temporal dynamicsmarch 123april 123 , 123 , hyderabad , india123 k for each user i and j r
k for each item j , and assume a multiplicative model for the interaction response
p ( yij|i , j ) = p ( yij|
i j ; ) .
this way the factors could explain past interactions and in turn make prediction for future ones .
this model implicitly encodes the aldous - hoover theorem ( 123 ) for exchangeable ma - trices yij are independent from each other given i and j .
parameter estimation for the model reduces to a low - rank approximation of the matrix y that naturally embeds both users and items into a vector space in which the inner
i j directly reect the semantic relatedness .
latent factor models have gained tremendous successes in recommendation systems and have even become the cur - rent state - of - the - art for cf ( 123 , 123 ) .
a known drawback for such models is that , because it is learned only upon past interactions , the generalization performance is usually poor for completely new entities , i . e .
unseen users or items , for which the observations are missing at the training stage .
this scenario is well - known as the cold - start problem in recommendation systems .
the recently proposed regression based latent factor model ( rlfm ) ( 123 ) addresses this problem by incorporating entity features into latent factor learning .
the key idea is to use observable features to explain the learned latent variables ( e . g .
by regression or factorization ) .
suppose for each user and each item , there are observable features , xi for i ( e . g .
users demographic information , self - crafted registration proles ) and xj for j ( e . g .
content of a document , description of a product ) , as shown in figure 123 , rlfm ( 123 ) assumes the following dependencies :
i p ( i|xi ) j p ( j|xj )
i j ; ) .
neighborhood based latent factor models .
it is nat - ural to combine the neighborhood models and latent factor models .
a recent example is discussed ( 123 ) , where the basic idea is to apply the locality of dependencies directly to the latent factors , for example : i ( cid : 123 ) i ii ( cid : 123 ) i ( cid : 123 )
i j; ) .
this model123 which is quite similar to ( 123 ) was deployed on the netix data yielding signicantly better performances over both pure - neighborhood and pure latent factor models .
123 friendship prediction
friendship ( link ) prediction recommends users to other users in the hope of acquainting people who were previously not connected in the network ( or even unfamiliar with each other ) .
unlike interest targeting , the user network is unipar - tite .
for a pair of users ( i , i ) the observation whether they are connected is a binary value sii ( cid : 123 ) .
link prediction cru - cially inuences both the trac and the revenue of a social network and it is hence recognized as one of the key tasks in social network analysis .
ideally , our goal is to learn a distribution over jointly ex - changeable matrices ( e . g .
by applying the aldous - hoover factorization theorem ) .
for reasons of practicality we pick a nite - dimensional factorization instead , which we shall dis - cuss in the next section .
before we do so , let us briey review existing approaches .
some of them employ random walk methods ( 123 , 123 ) or spectral graph algorithms ( 123 , 123 ) .
123in this case the set of neighbors i contains i with ii = 123
figure 123 : graphical representations of ( a ) regres - sion based latent factor model ( rlfm ) and ( b ) friendship - interest propagation model ( fip ) .
random walk .
a random walk on the graph s is a reversible markov chain on the vertexes i .
the transi - tion probability from the vertex i to vertex i ( cid : 123 ) |i ) = sii ( cid : 123 ) / di .
here di denotes the degree of vertex i; sii ( cid : 123 ) the connection weight between nodes i and i are considered close whenever the hitting time is small or whenever the diusion probability is large .
spectral algorithms .
for the given network s , the un - normalized laplacian is dened by l = d s , where d is a diagonal matrix with dii = di .
spectral algorithms diuse the connections by maximizing the spectral smoothness to obtain the intrinsic kinship dened by the dominant eigen - vectors of the laplacian
sii ( cid : 123 ) ( cid : 123 ) ui ui ( cid : 123 ) ( cid : 123 ) 123 = 123u lu ( cid : 123 ) , where u = ( u123 , .
, u|i| ) .
we now consider interest targeting and link prediction in the context of social network , where evidence for both in - terest and friendship are available , allowing us to solve both tasks in a single framework .
the rationale is that friendship and interest information are to some degree correlated , 123 i . e .
the network exhibits homophily ( 123 ) and the propagation of friendship and interest would be mutually reinforcing if
in this section we present our model of friendship - interest propagation ( fip ) .
we start with a probabilistic formula - tion , discuss dierent variants of the model and its imple - mentation within an optimization framework , and then dis - tinguish our model from existing works .
123 probabilistic model
the nontrivial correlation between interest and friendship motivates joint modeling of both sources of evidence .
as shown in figure 123 , the friendship - interest propagation ( fip ) model simultaneously encodes the two heterogeneous types of dyadic relationships : the user - item interactions ( yij|i i , j j ) , and user - user connections ( sii ( cid : 123 ) |i , i ( cid : 123 ) i ) .
our model is built on latent factor models .
123empirical analysis on yahoo ! pulse illustrates that the interest correlation ( pearson score , max 123 ) between two directly - linked friends is 123 , much higher than average .
www 123 session : temporal dynamicsmarch 123april 123 , 123 , hyderabad , india123 modeling interest evidence .
to characterize the user - item dyads , yij , we assume that for each user i and item j there exist observable properties xi ( e . g .
a users self - crafted registration les ) and xj ( e . g .
a textual description of a service item ) 123
moreover , we also assume that there exist some subtle properties which cannot be observed directly , such as a users interests , a service items semantic topics .
we denote these latent features by i for i and j for j respectively .
we assume the response yij depends on both types of features ( i . e .
observable and latent ) : yij p ( yij|i , j , xi , xj , ) , i p ( i|xi ) j p ( j|xj ) where denotes the set of hyper - parameters .
to design a concrete model , one needs to specify distributions for the dependencies , i|xi , j|xj , and yij|xi , xj , i , j .
this model is essentially an integration of collaborative ltering ( 123 ) and content ltering ( 123 ) .
on the one hand , if the user i or item j has no or merely non - informative observable features such that we have access to only their identity and past interactions , the model degrades to a factorization - style collaborative ltering algorithms ( 123 ) .
on the other hand , if we assume that i and j are irrelevant , for instance , if i or j is totally new to the system such that there is no interac - tion involving either of them as in a cold - start setting , this model becomes the classical feature - based recommendation algorithms ( 123 , 123 , 123 ) , which predict the interaction response yij purely based on the observed properties of i and j , and are commonly used in , e . g .
webpage ranking ( 123 ) , advertise - ment targeting ( 123 ) , and content recommendation ( 123 ) .
modeling friendship evidence .
we now extend the in - terest model to incorporate the social friendship - connection information among users .
for this purpose , we dene a ran - dom walk process for user - user networking .
but unlike tra - ditional random walk models ( 123 , 123 ) , we assume a user i is fully characterized by her observable features xi and la - tent factor i , and devise the following model for user - user
i p ( i|xi , ) and sii ( cid : 123 ) p ( sii ( cid : 123 ) |i , i ( cid : 123 ) , xi , xi ( cid : 123 ) , ) ,
where sii ( cid : 123 ) reects an observed state transition from i to i unlike in random walk models where proximity in a graph is simply used to smooth secondary estimators of parameters ( e . g .
reachability , hitting times ) , we make direct use of it to model the latent variables i .
note that whenever we restrict the norm of i ( e . g .
by ( cid : 123 ) 123 regularization ) and when i i ( cid : 123 ) to assess similarity , we we use an inner product model approximately recover the graph laplacian of eqn . ( 123 ) .
in this way our model integrates two dierent methodolo - gies collaborative ltering and random walks .
it is dier - ent from traditional random walk models in which transition probability is dened solely based on graph topologies .
it is also dierent from traditional cf models in that it is de - ned on unipartite dyadic relationships .
by doing so , this integrated model not only allows learning of latent factors to capture graph topologies , but it also alleviates certain crit - ical issues in random walks : for example , it naturally han - dles heterogeneous graphs ( e . g .
a compound graph consist - ing of both unipartite and bipartite connections such as fig - ure 123 ) , and it also makes applicable computationally - ecient
123whenever we do not have access to these properties we simply default to the expected value of the latent variables , which is easily achieved in a probabilistic model .
sequential learning algorithms ( e . g .
stochastic gradient de - scent ) , avoiding directly manipulating large matrices .
friendship - interest propagation model .
based on the above descriptions , we nally summarize the overall fip model in figure 123 and the table below .
note that the tu - ples ( i , xi , i ) now play double duty in encoding interest , sii ( cid : 123 ) ) interactions ( i , j , yij ) and friendship connections ( i , i simultaneously .
learning shared factors from coupled rela - tionships gives us both more evidence and more constraints to work with , and in turn leads to better generalization .
the friendship - interest propagation ( fip ) model .
i i , j j
i p ( i|xi , ) j p ( j|xj , ) yij p ( yij|i , j , xi , xj , ) sii ( cid : 123 ) p ( sii ( cid : 123 ) |i , i ( cid : 123 ) , xi , xi ( cid : 123 ) , )
123 model specication
so far we deliberately described the fip model in terms of general dependencies between random variables to make it explicit that the model is quite a bit more general than what can be achieved by an inner product model .
here , we specify the model within an optimization framework .
for computational convenience we assume linear depen - dencies between xi and i plus a noise term123 .
this means
i = axi + i where e ( i ) = 123
j = bxj + j where e ( j ) = 123
is typically assumed to be gaussian or laplace .
whenever nonlinearity in x is desired we can achieve this simply by using a feature map of x and an associated kernel expan - sion .
finally , we assume that the dyadic response ( e . g .
yij ) depends on latent features only through the inner product i j ) and on observable features through a bilinear product ( e . g
i w xj ) ( 123 ) .
that is : yij p ( yij|fij ) where fij = i j + x sii ( cid : 123 ) p ( sii ( cid : 123 ) |hii ( cid : 123 ) ) where hii ( cid : 123 ) =
i w xj .
m and xj r
here , assume xi r and m r mm provide a bilinear form which captures the anity between the observed features for the corresponding dyads .
we also impose laplace or gaussian priors on w and m .
one advantage of using an ( cid : 123 ) 123 ( i . e .
laplace ) prior is that it introduces sparsity , which makes ( 123 ) equivalent to sparse - coding ( 123 ) and thus improves both compactness and predictiveness of the learned latent factors .
given observed responses for the dyads ( ( i , j ) oy ) and ) os ) , the problem of minimizing the negative log - posterior of fip boils down to the following objective :
i i ( cid : 123 ) + x
i m xi ( cid : 123 ) .
n , the matrices w r
( cid : 123 ) ( yij , fij ) + s
( cid : 123 ) ( sii ( cid : 123 ) , hii ( cid : 123 ) )
( i|xi ) + j
+ w ( w ) + m ( m ) + a ( a ) + b ( b ) ,
where s are trade - o parameters , ( cid : 123 ) ( , ) denotes a loss function for dyadic responses .
the term ( |x ) = ( ) + 123note that the latent noise term is actually meaningful .
it indicates the deviation of the user / item proles from its cold - start estimates axi and bxj respectively .
www 123 session : temporal dynamicsmarch 123april 123 , 123 , hyderabad , india123 x ( x , ) .
here ( ) is used to penalize the complexity ( i . e .
( cid : 123 ) 123 , ( cid : 123 ) 123 norm ) .
the term x ( x , ) regularizes by tting the observed feature x , as dened by ( 123 ) .
this type of regular - ization are equivalent to applying content factorization ( e . g .
lsi , nmf , lda ) to the feature x in terms of a factor and
123 or b
the motivations for a computational framework instead of direct probabilistic inference are mainly two - fold : first , the two formulations are somewhat equivalent the dis - tribution of the dyadic response ( e . g .
yij ) and its depen - dence on the prediction ( e . g .
p ( yij|fij ) ) can be encoded pre - cisely through the choice of loss functions; likewise , the prior over the observations or parameters could also be readily translated into the regularization penalties .
secondly , com - putational models allow more scalable algorithms , e . g .
via stochastic gradient descent , whereas probabilistic reasoning often requires monte carlo sampling or quite nontrivial vari -
in our case , both y and s are binary , i . e .
yij , sii ( cid : 123 ) ( 123 ) .
we performed an extensive study in our experiments com - paring a large variety of dierent loss functions .
for the convenience of optimization , we limit ourselves to dieren - tiable ( in many cases , also convex ) loss functions ( see also figure 123 for details ) :
least mean squares : this is the most popularly - used loss in matrix factorization .
it minimizes the frobenius norm of the prediction residue matrix and leads to a svd - style algorithm .
we have the loss
( cid : 123 ) 123 ( y , f ) =
( 123 yf )
lazy least mean squares : this is a slight modication of ( cid : 123 ) 123 loss for the purpose of classication ( 123 ) .
basi - cally , it is an iteratively truncated version of the ( cid : 123 ) 123 loss
ll123 ( y , f ) = min ( 123 , max ( 123 , 123 yf )
it has been shown that this loss approximates the clas - sication error rate in the example space ( 123 ) .
logistic regression : this is the loss used in a binary ex -
ponential families model .
it is given by
log ( y , f ) = log ( 123 + exp ( yf ) ) .
huber loss : this is the one - sided variant of hubers robust loss function .
it is convex and continuously dieren -
( y , f ) =
123 max ( 123 , 123 yf ) 123 ,
if yf > 123
loss : unlike other loss functions , which are all convex upper bound of the 123 - 123 loss , the loss ( 123 ) is non - convex .
both theoretical and empirical studies have shown appealing advantages of using non - convex loss over convex ones , such as higher generalization accu - racy , better scalability , faster convergence to the bayes limit ( 123 , 123 ) .
we implement the following version :
( y , f ) =
123 max ( 123 , 123 yf ) 123 ,
123 max ( 123 , 123 + yf ) 123 ,
if yf > 123
figure 123 : least mean squares ( ( cid : 123 ) 123 ) , logistic ( log ) , hu - ber and - loss ( psi ) .
we use these four and the lazy ( cid : 123 ) 123 ( omitted since its shape in parameter space is es - sentially identical to ( cid : 123 ) 123 ) loss for binary classication .
123 bias correction
a key challenge for learning latent factors from dyadic in - teractions is that the observations are extremely sparse with almost exclusively positive interactions observable .
that is , we typically do not observe explicit information that user i does not like item j .
rather , the fact that we have not observed ( i , j ) suggests that i might not even know about j .
in other words , absence of a preference statement or a social link should not be interpreted absolutely as negative
