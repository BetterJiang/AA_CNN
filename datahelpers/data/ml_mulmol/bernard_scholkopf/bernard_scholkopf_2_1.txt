we usually endow the investigated objects with pairwise relationships , which can be illustrated as graphs .
in many real - world problems , however , relationships among the objects of our interest are more complex than pair - wise .
naively squeezing the complex relationships into pairwise ones will inevitably lead to loss of information which can be expected valuable for our learning tasks however .
therefore we consider using hypergraphs in - stead to completely represent complex relationships among the objects of our interest , and thus the problem of learning with hypergraphs arises .
our main contribution in this paper is to generalize the powerful methodology of spectral clustering which originally operates on undirected graphs to hy - pergraphs , and further develop algorithms for hypergraph embedding and transductive classication on the basis of the spectral hypergraph cluster - ing approach .
our experiments on a number of benchmarks showed the advantages of hypergraphs over usual graphs .
in machine learning problem settings , we generally assume pairwise relationships among the objects of our interest .
an object set endowed with pairwise relationships can be naturally illustrated as a graph , in which the vertices represent the objects , and any two vertices that have some kind of relationship are joined together by an edge .
the graph can be undirected or directed .
it depends on whether the pairwise relationships among objects are symmetric or not .
a nite set of points in euclidean space associated with a kernel matrix is a typical example of undirected graphs .
as to directed graphs , a well - known instance is the world wide web .
a hyperlink can be thought of as a directed edge because given an arbitrary hyperlink we cannot expect that there certainly exists an inverse one , that is , the hyperlink based relationships are asymmetric ( 123 ) .
however , in many real - world problems , representing a set of complex relational objects as undirected or directed graphs is not complete .
for illustrating this point of view , let us consider a problem of grouping a collection of articles into dierent topics .
given an article , assume the only information that we have is who wrote this article .
one may construct an undirected graph in which two vertices are joined together by an edge if there is at least one common author of their corresponding articles ( figure 123 ) , and then an undirected graph based clustering approach is applied , e . g .
spectral graph techniques ( 123 , 123 , 123 ) .
the undirected graph may be further embellished by assigning to each edge a weight equal to the
figure 123 : hypergraph vs .
simple graph .
left : an author set e = ( e123 , e123 , e123 ) and an article set v = ( v123 , v123 , v123 , v123 , v123 , v123 , v123 ) .
the entry ( vi , ej ) is set to 123 if ej is an author of article vi , and 123 otherwise .
middle : an undirected graph in which two articles are joined together by an edge if there is at least one author in common .
this graph cannot tell us whether the same person is the author of three or more articles or not .
right : a hypergraph which completely illustrates the complex relationships among authors and articles .
number of authors in common .
the above method may sound natural , but within its graph representation we obviously miss the information on whether the same person joined writing three or more articles or not .
such information loss is unexpected because the articles by the same person likely belong to the same topic and hence the information is useful for our a natural way of remedying the information loss issue occurring in the above methodology is to represent the data as a hypergraph instead .
a hypergraph is a graph in which an edge can connect more than two vertices ( 123 ) .
in other words , an edge is a subset of vertices .
in what follows , we shall uniedly refer to the usual undirected or directed graphs as simple graphs .
moreover , without special mentioning , the referred simple graphs are undirected .
it is obvious that a simple graph is a special kind of hypergraph with each edge containing two vertices only .
in the problem of clustering articles stated before , it is quite straightforward to construct a hypergraph with the vertices representing the articles , and the edges the authors ( figure 123 ) .
each edge contains all articles by its corresponding author .
even more than that , we can consider putting positive weights on the edges to encode our prior knowledge on authors work if we have .
for instance , for a person working on a broad range of elds , we may assign a relatively small value to his corresponding edge .
now we can completely represent the complex relationships among objects by using hy - pergraphs .
however , a new problem arises .
how to partition a hypergraph ? this is the main problem that we want to solve in this paper .
a powerful technique for partitioning simple graphs is spectral clustering .
therefore , we generalize spectral clustering techniques to hypergraphs , more specically , the normalized cut approach of ( 123 ) .
moreover , as in the case of simple graphs , a real - valued relaxation of the hypergraph normalized cut criterion leads to the eigendecomposition of a positive semidenite matrix , which can be regarded as an analogue of the so - called laplacian for simple graphs ( cf .
( 123 ) ) , and hence we sugges - tively call it the hypergraph laplacian .
consequently , we develop algorithms for hypergraph embedding and transductive inference based on the hypergraph laplacian .
there have actually existed a large amount of literature on hypergraph partitioning , which arises from a variety of practical problems , such as partitioning circuit netlists ( 123 ) , clustering categorial data ( 123 ) , and image segmentation ( 123 ) .
unlike the present work however , they generally transformed hypergraphs to simple ones by using the heuristics we discussed in the beginning or other domain - specic heuristics , and then applied simple graph based spectral ( 123 ) proposed an iterative approach which was indeed designed for hypergraphs .
nevertheless it is not a spectral method .
in addition , ( 123 ) and ( 123 ) considered propagating label distributions on hypergraphs .
the structure of the paper is as follows .
we rst introduce some basic notions on hy - pergraphs in section 123
in section 123 , we generalize the simple graph normalized cut to
hypergraphs .
as shown in section 123 , the hypergraph normalized cut has an elegant prob - abilistic interpretation based on a random walk naturally associated with a hypergraph .
in section 123 , we introduce the real - valued relaxation to approximately obtain hypergraph normalized cuts , and also the hypergraph laplacian derived from this relaxation .
in section 123 , we develop a spectral hypergraph embedding technique based on the hypergraph lapla - cian .
in section 123 , we address transductive inference on hypergraphs , this is , classifying the vertices of a hypergraph provided that some of its vertices have been labeled .
experimental results are shown in section 123 , and we conclude this paper in section 123
let v denote a nite set of objects , and let e be a family of subsets e of v such that ee = v .
then we call g = ( v , e ) a hypergraph with the vertex set v and the hyperedge set e .
a hyperedge containing just two vertices is a simple graph edge .
a weighted hypergraph is a hypergraph that has a positive number w ( e ) associated with each hyperedge e , called the weight of hyperedge e .
denote a weighted hypergraph by g = ( v , e , w ) .
a hyperedge e is said to be incident with a vertex v when v e .
for a vertex v v , its degree is ( ee|ve ) w ( e ) .
given an arbitrary set s , let |s| denote the cardinality dened by d ( v ) = of s .
for a hyperedge e e , its degree is dened to be ( e ) = |e| .
we say that there is a hyperpath between vertices v123 and vk when there is an alternative sequence of distinct vertices and hyperedges v123 , e123 , v123 , e123 , .
, ek123 , vk such that ( vi , vi+123 ) ei for 123 i k 123
a hypergraph is connected if there is a path for every pair of vertices .
in what follows , the hypergraphs we mention are always assumed to be connected .
a hypergraph g can be represented by a |v | |e| matrix h with entries h ( v , e ) = 123 if v e and 123 otherwise , vv h ( v , e ) .
called the incidence matrix of g .
then d ( v ) = let dv and de denote the diagonal matrices containing the vertex and hyperedge degrees respectively , and let w denote the diagonal matrix containing the weights of hyperedges .
then the adjacency matrix a of hypergraph g is dened as a = hw h t dv , where h t is the transpose of h .
ee w ( e ) h ( v , e ) and ( e ) =
123 normalized hypergraph cut for a vertex subset s v , let sc denote the compliment of s .
a cut of a hypergraph g = ( v , e , w ) is a partition of v into two parts s and sc .
we say that a hyperedge e is cut if it is incident with the vertices in s and sc simultaneously .
given a vertex subset s v , dene the hyperedge boundary s of s to be a hyperedge set which consists of hyperedges which are cut , i . e .
s : = ( e e|e s ( cid : 123 ) = , e sc ( cid : 123 ) = ) , and dene the volume vol s of s to be the sum of the degrees of the vertices in s , that is , vol s : =
vs d ( v ) .
moreover , dene the volume of s by |e s||e sc|
vol s : =
clearly , we have vol s = vol sc .
the denition given by equation ( 123 ) can be understood as follows .
let us imagine each hyperedge e as a clique , i . e .
a fully connected subgraph .
for avoiding unnecessary confusion , we call the edges in such an imaginary subgraph the subedges .
moreover , we assign the same weight w ( e ) / ( e ) to all subedges .
then , when a hyperedge e is cut , there are |e s||e sc| subedges are cut , and hence a single sum term in equation ( 123 ) is the sum of the weights over the subedges which are cut .
naturally , we try to obtain a partition in which the connection among the vertices in the same cluster is dense while the connection between two clusters is sparse .
using the above introduced denitions , we may formalize this natural partition as
for a simple graph , |e s| = |e sc| = 123 , and ( e ) = 123
thus the right - hand side of equation ( 123 ) reduces to the simple graph normalized cut ( 123 ) up to a factor 123 / 123
in what follows , we explain the hypergraph normalized cut in terms of random walks .
c ( s ) : = vol s
123 random walk explanation
we associate each hypergraph with a natural random walk which has the transition rule as follows .
given the current position u v , rst choose a hyperedge e over all hyperedges incident with u with the probability proportional to w ( e ) , and then choose a vertex v e uniformly at random .
obviously , it generalizes the natural random walk dened on simple graphs .
let p denote the transition probability matrix of this hypergraph random walk .
then each entry of p is
in matrix notation , p = d123
v hw d123
which follows from that
( u ) p ( u , v ) =
we written c ( s ) =
p ( u , v ) =
w ( e ) h ( u , e )
e h t .
the stationary distribution of the random ( v ) = d ( v )
w ( e ) h ( u , e ) h ( v , e )
w ( e ) h ( v , e ) = d ( v )
w ( e ) h ( u , e ) h ( v , e )
h ( u , e ) h ( v , e )
vol s / vol v
vol sc / vol v
from equation ( 123 ) , we have
that is , the ratio vol s / vol v is the probability with which the random walk occupies some vertex in s .
moreover , from equations ( 123 ) and ( 123 ) , we have
|e s||e sc|
w ( e ) h ( u , e )
h ( u , e ) h ( v , e )
that is , the ratio vol s / vol v is the probability with which one sees a jump of the random walk from s to sc under the stationary distribution .
from equations ( 123 ) and ( 123 ) , we can understand the hypergraph normalized cut criterion as follows : looking for a cut such that the probability with which the random walk crosses dierent clusters is as small as possible while the probability with which the random walk stays in the same cluster is as large as possible .
it is worth pointing out that the random walk view is consistent with that for the simple graph normalized cut ( 123 ) .
the consistency means that our generalization of the normalized cut approach from simple graphs to hypergraphs is reasonable .
123 spectral hypergraph partitioning
as in ( 123 ) , the combinatorial optimization problem given by equation ( 123 ) is np - complete , and it can be relaxed ( 123 ) into a real - valued optimization problem
f 123 ( v ) = 123 ,
d ( v ) = 123
v hw d123 we dene the matrices = d identity matrix .
then it can be veried that
e h t d
and = i , where i denotes the
= 123f t f .
v hw h t d123 / 123
note that this also shows that is positive semi - denite .
we can check that the smallest eigenvalue of is 123 , and its corresponding eigenvector is just d .
therefore , from standard results in linear algebra , we know that the solution to the optimization problem is an eigenvector of associated with its smallest nonzero eigenvalue .
hence , the vertex set is clustered into the two parts s = ( v v | ( v ) 123 ) and sc = ( v v | ( v ) < 123 ) .
for a simple graph , the edge degree matrix de reduces to 123i .
thus = i 123 ( dv + a ) d123 / 123 which coincides with the simple graph laplacian up to a factor of 123 / 123
so we suggestively call the hypergraph laplacian .
as in ( 123 ) where the spectral clustering methodology is generalized from undirected to directed simple graphs , we may consider generalizing the present approach to directed hy - pergraphs ( 123 ) .
a directed hypergraph is a hypergraph in which each hyperedge e is an ordered pair ( x , y ) where x v is the tail of e and y v \ x is the head .
directed hypergraphs have been used to model various practical problems from biochemical networks ( 123 ) to natural language parsing ( 123 ) .
= i 123
123 spectral hypergraph embedding
as in the simple graph case ( 123 , 123 ) , it is straightforward to extend the spectral hypergraph clustering approach to k - way partitioning .
denote a k - way partition by ( v123 , , vk ) , where v123 v123 vk = v , and vi vj = for all 123 i , j k .
we may obtain a k - way partition by minimizing c ( v123 , , vk ) = over all k - way partitions .
similarly , the combinatorial optimization problem can be relaxed into a real - valued one , of which the solution can be any orthogonal basis of the linear space spanned by the eigenvectors of associated with the k smallest eigenvalues .
theorem 123
assume a hypergraph g = ( v , e , w ) with |v | = n .
denote the eigenvalues of the laplacian of g by 123 123 n .
dene ck ( g ) = min c ( v123 , , vk ) , where the minimization is over all k - way partitions .
then proof .
let ri be a n - dimensional vector dened by ri ( v ) = 123 if v vi , and 123 otherwise .
i=123 i ck ( g ) .
c ( v123 , , vk ) =
i ( dv hw d123
e h t ) ri
dene si = d
ri , and fi = si / ( cid : 123 ) si ( cid : 123 ) , where ( cid : 123 ) ( cid : 123 ) denotes the usual euclidean norm
c ( v123 , , vk ) =
i fi = tr f t f ,
where f = ( f123 fk ) .
clearly , f t f = i .
if allowing the elements of ri to take arbitrary continuous values rather than boolean ones only , we have
ck ( g ) = min c ( v123 , , vk ) min
f t f =i
tr f t f =
the last equality is from standard results in linear algebra .
this completes the proof .
the above result also shows that the real - valued optimization problem derived from the relaxation is actually a lower bound of the original combinatorial optimization problem .
unlike 123 - way partitioning however , it is unclear how to utilize multiple eigenvectors simul - taneously to obtain a k - way partition .
many heuristics have been proposed in the situation of simple graphs , and they can be applied here as well .
perhaps the most popular one among them is as follows ( 123 ) .
first form a matrix x = ( 123 k ) , where is are the eigenvectors of associated with the k smallest eigenvalues .
and then the row vectors of x are regarded as the representations of the graph vertices in k - dimensional euclidian space .
those vectors corresponding to the vertices are generally expected to be well separated , and consequently we can obtain a good partition simply by running k - means on them once .
( 123 ) has resorted to a semidenite relaxation model for the k - way normalized cut instead of the relatively loose spectral relaxation , and then obtained a more accurate solution .
it sounds reasonable to expect that the improved solution will lead to improved clustering .
as reported in ( 123 ) , however , the expected improvement does not occur in practice .
123 transductive inference
we have established algorithms for spectral hypergraph clustering and embedding .
now we consider transductive inference on hypergraphs .
specically , given a hypergraph g = ( v , e , w ) , the vertices in a subset s v have labels in l = ( 123 , 123 ) , our task is to predict the labels of the remaining unlabeled vertices .
basically , we should try to assign the same label to all vertices contained in the same hyperedge .
it is actually straightforward to derive a transductive inference approach from a clustering scheme .
let f : v ( cid : 123 ) r denote a classication function , which assigns a label sign f ( v ) to a vertex v v .
given an objective functional ( ) from some clustering approach , one may choose a classication function by
( remp ( f ) + ( f ) ) ,
where remp ( f ) denotes a chosen empirical loss , such as the least square loss or the hinge loss , and the number > 123 the regularization parameter .
since in general normalized cuts are thought to be superior to mincuts , the transductive inference approach that we used in the later experiments is built on the above spectral hypergraph clustering method .
consequently , as shown in ( 123 ) , with the least square loss function , the classication function is nally given by f = ( i ) 123y , where the elements of y denote the initial labels , and is a parameter in ( 123 , 123 ) .
for a survey on transductive inference , we refer the readers to ( 123 ) .
all datasets except a particular version of the 123 - newsgroup one are from the uci ma - chine learning depository .
they are usually referred to as the so - called categorical data .
specically , each instance in those datasets is described by one or more attributes .
each attribute takes only a small number of values , each corresponding to a specic category .
attribute values cannot be naturally ordered linearly as numerical values can ( 123 ) .
in our experiments , we constructed a hypergraph for each dataset , where attribute values were regarded as hyperedges .
the weights for all hyperedges were simply set to 123
how to choose suitable weights is denitely an important problem requiring additional exploration how - ever .
we also constructed a simple graph for each dataset , and the simple graph spectral clustering based approach ( 123 ) was then used as the baseline .
those simple graphs were constructed in the way discussed in the beginning of section 123 , which is essentially to dene pairwise relationships among the objects by the adjacency matrices of hypergraphs .
the rst task we addressed is to embed the animals in the zoo dataset into euclidean space .
this dataset contains 123 animals with 123 attributes .
the attributes include hair , feathers , eggs , milk , legs , tail , etc .
the animals have been manually classied into 123 dierent categories .
we embedded those animals into euclidean space by using the eigenvectors of the hypergraph laplacian associated with the smallest eigenvalues ( figure 123 ) .
for the an - imals having the same attributes , we randomly chose one as their representative to put in the gures .
it is apparent that those animals are well separated in their euclidean repre - sentations .
moreover , it deserves a further look that seal and dolphin are signicantly
figure 123 : embedding the zoo dataset .
left panel : the eigenvectors with the 123nd and 123rd smallest eigenvalues; right panel : the eigenvectors with the 123rd and 123th smallest eigenvalues .
note that dolphin is between class 123 ( denoted by ) containing the animals having milk and living on land , and class 123 ( denoted by ( cid : 123 ) ) containing the animals living in sea .
figure 123 : classication on complex relational data .
( a ) - ( c ) results from both the hyper - graph based approach and the simple graph based approach .
( d ) the inuence of the in letter recognition with 123 labeled instances .
mapped to the positions between class 123 consisting of the animals having milk and living on land , and class 123 consisting of the animals living in sea .
a similar observation also holds for seasnake .
the second task is classication on the mushroom dataset that contains 123 instances described by 123 categorical attributes , such as shape , color , etc .
we remove the 123th attribute that has missing values .
each instance is labeled as edible or poisonous .
they contain 123 and 123 instances separately .
the third task is text categorization on a modied 123 - newsgroup dataset with binary occurrence values for 123 words across 123 articles ( see http : / / www . cs . toronto . edu / ~ roweis ) .
the articles belong to 123 dierent top - ics corresponding to the highest level of the original 123 newsgroups , with the sizes being 123 , 123 , 123 and 123 respectively .
the nal task is to guess the letter categories with the letter dataset , in which each instance is described by 123 primitive numerical attributes ( statistical moments and edge counts ) .
we used a subset containing the instances of the letters from a to e with the sizes being 123 , 123 , 123 , 123 and 123 respectively .
the exper - imental results of the above three tasks are shown in figures 123 ( a ) - 123 ( c ) .
the regularization parameter is xed at 123 .
each testing error is averaged over 123 trials .
the results show that the hypergraph based method is consistently better than the baseline .
the inuence of the used in the letter recognition task is shown in figure 123 ( d ) .
it is interesting that the inuences the baseline much more than the hypergraph based approach .
we generalized spectral clustering techniques to hypergraphs , and developed algorithms for hypergraph embedding and transductive inference .
it is interesting to consider applying the present methodology to a broader range of practical problems .
we are particularly interested in the following problems .
one is biological network analysis ( 123 ) .
biological networks are
123 . 123 . 123 . 123 . 123 . 123 . 123 . 123 . 123bearcarpcavyclamcrabdeerdogfishdolphindoveflamingofleafroggirlgnatgorillagullhawkhoneybeehouseflykiwiladybirdlionlobsterminknewtoctopusostrichpenguinpitviperplatypusponypussycatscorpionseahorsesealsealionseasnakeseawaspslowwormsquirrelstarfishstingrayswantoadtortoisetuataravampirewaspworm123 . 123 . 123 . 123 . 123 . 123 . 123 . 123 . 123bearpussycatcarpcavyclamcrabdeerdogfishdolphinflamingofleafroggirlgnatgorillagullhawkhoneybeehouseflykiwiladybirdlionlobsterminknewtoctopusostrichpenguinpitviperplatypusponyscorpionseahorsesealsealionseasnakeseawaspslowwormsquirrelstingrayswantoadtortoisetuataravampirewaspwormstarfishdove123 . 123 . 123# labeled pointstest errorhypergraphsimple graph123 . 123 . 123# labeled pointstest errorhypergraphsimple graph123 . 123 . 123 . 123# labeled pointstest errorhypergraphsimple graph123 . 123 . 123 . 123 . 123 . 123 . 123 . 123 . 123different valuetest errorhypergraphsimple graph mainly modeled as simple graphs so far .
it might be more sensible to model them as hypergraphs instead such that complex interactions will be completely taken into account .
the other is social network analysis .
as recently pointed out by ( 123 ) , many social transactions are supra - dyadic; they either involve more than two actors or they involve numerous aspects of the setting of interaction .
so standard network techniques are not adequate in analyzing these networks .
consequently , they resorted to the concept of a hypergraph , and showed how the concept of network centrality can be adapted to hypergraphs .
