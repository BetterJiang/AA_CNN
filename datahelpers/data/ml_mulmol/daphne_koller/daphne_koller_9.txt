we address the problem of segmenting 123d scan data into objects or object classes .
our segmentation framework is based on a subclass of markov random fields ( mrfs ) which support efcient graph - cut inference .
the mrf mod - els incorporate a large set of diverse features and enforce the preference that adjacent scan points have the same clas - sication label .
we use a recently proposed maximum - margin framework to discriminatively train the model from a set of labeled scans; as a result we automatically learn the relative importance of the features for the segmentation task .
performing graph - cut inference in the trained mrf can then be used to segment new scenes very efciently .
we test our approach on three large - scale datasets produced by different kinds of 123d sensors , showing its applicability to both outdoor and indoor environments containing diverse
range scanners have become standard equipment in mo - bile robotics , making the task of 123d scan segmentation one of increasing practical relevance .
given the set of points ( or surfaces ) in 123d acquired by a range scanner , the goal of segmentation is to attribute the acquired points to a set of candidate objects or object classes .
the segmentation capability is essential for scene understanding , and can be utilized for scan registration and robot localization .
much work in vision has been devoted to the problem of segmenting and identifying objects in 123d image data .
the 123d problem is easier in some ways , as it circumvents the ambiguities induced by the 123d - to - 123d projection , but is also harder because it lacks color cues , and deals with data which is often noisy and sparse .
the 123d scan segmentation prob - lem has been addressed primarily in the context of detect -
ing known rigid objects for which reliable features can be extracted ( e . g . , ( 123 , 123 ) ) .
the more difcult task of segment - ing out object classes or deformable objects from 123d scans requires the ability to handle previously unseen object in - stances or congurations .
this is still an open problem in computer vision , where many approaches assume that the scans have been already segmented into objects ( 123 , 123 ) .
an object segmentation algorithm should possess sev - eral important properties .
first , it should be able to take ad - vantage of several qualitatively different kinds of features .
for example , trees may require very different features from cars , and ground can be detected simply based on a height feature .
as the number of features grows , it becomes impor - tant to learn how to trade them off automatically .
second , some points can lie in generic - looking or sparsely sampled regions , but we should be able to infer their label by enforc - ing spatial contiguity , exploiting the fact that adjacent points in the scans tend to have similar labels .
third , the algorithm should adapt to the particular 123d scanner used , since differ - ent scanners produce qualitatively different inputs .
this is particularly relevant , because real - world scans can violate standard assumptions made in synthetic data used to evalu - ate segmentation algorithms ( e . g . , ( 123 , 123 ) ) .
in this paper we present a learning - based approach for scene segmentation , which satises all of the properties de - scribed above .
our approach utilizes a markov random eld ( mrf ) over scan points in a scene to label each point with one of some set of class labels; these labels can include dif - ferent object types as well as background .
we also assume that , in our dataset , adjacent points in space are connected by links .
these links can be provided either by the scanner ( when it produces 123d meshes ) , or introduced by connect - ing neighboring points in the scan .
the mrf uses a set of pre - specied features of scan points ( e . g . , spin images ( 123 ) or height of the point ) to provide evidence on their likely la - bels .
the links are used to relate the labels of nearby points ,
thereby imposing a preference for spatial contiguity of the labels; the strength of these links can also depend on fea - tures ( e . g . , distance between the linked points ) .
we use a subclass of mrfs that allow effective inference using graph cuts ( 123 ) , yet can enforce our spatial contiguity preference .
our algorithm consists of a learning phase and a seg - mentation phase .
in the learning phase , we are provided a set of scenes acquired by a 123d scanner .
the scene points are labeled with an appropriate class or object label .
the goal of the learning algorithm is to nd a good set of fea - ture weights .
we use a maximum - margin learning approach which nds the optimal tradeoff between the node and edge features , which induce the mrf - based segmentation algo - rithm to match the training set labels ( 123 ) .
this learning procedure nds the globally optimal ( or nearly optimal ) weights and can be implemented efciently .
in the segmentation phase , we need to classify the points of a new scene .
we compute the relevant point and edge features , and run the graph - cut algorithm with the weights provided by the learning phase .
the inference procedure performs joint classication of the scan points while en - forcing spatial contiguity .
the algorithm is very efcient , scaling to scenes involving millions of points .
it produces the optimal solution for binary classication problems and a solution within a fraction of the optimal for multi - class
we demonstrate the approach on two real - world datasets and one computer - simulated dataset .
these data sets span both indoor and outdoor scenes , and a diverse set of object classes .
they were acquired using different scanners , and have very different properties .
we show that our algorithm performs well for all three data sets , illustrating its applica - bility in a broad range of settings , requiring different feature sets .
our results demonstrate the ability of our algorithm to del with signicant occlusion and scanner noise .
previous work
the problem of segmenting and classifying objects in 123d scenes is arguably the core problem in machine vision , and has received considerable attention .
the existing work on the problem in the context of 123d scan data can largely be classied into three groups .
the rst class of methods detects known objects in the scene .
such approaches center on computing ef - cient descriptors of the object shape at selected surface points ( 123 , 123 , 123 ) .
however , they usually require that the descriptor parameters are specied by hand .
detection often involves inefcient nearest - neighbor search in high - dimensional space .
while most approaches address detec - tion of rigid objects , detection of nonrigid objects has also been demonstrated ( 123 ) .
another line of work performs classication of 123d
shapes .
some methods ( particularly those used for retrieval of 123d models from large databases ) use global shape de - scriptors ( 123 , 123 ) , which require that a complete surface model of the query object is available .
objects can also be classied by looking at salient parts of the object surface ( 123 , 123 ) .
all mentioned approaches assume that the surface has already been pre - segmented from the scene .
another set of approaches segment 123d scans into a set of predened parametric shapes .
han et al .
( 123 ) present a method based for segmenting 123d images into 123 parametric models such as planar , conic and b - spline surfaces .
unlike their approach , ours is aimed at learning to segment the data directly into objects or classes of objects .
the parameters of our model are trained on examples containing the objects , while han et al .
assume a pre - specied generative model .
our segmentation approach is most closely related to work in vision applying conditional random elds ( crfs ) to 123d images .
discriminative models such as crfs ( 123 ) are a natural way to model correlations between classi - cation labels y given a scan x as input .
crfs directly model the conditional distribution p ( y j x ) .
cation tasks , crfs have been shown to produce results superior to generative approaches which expend efforts to model the potentially more complicated joint distribution p ( x; y ) ( 123 ) .
very recently , crfs have been applied for image segmentation .
kumar et al .
( 123 ) train crfs us - ing a pseudo - likelihood approximation to the distribution p ( y j x ) since estimating the true conditional distribu - tion is intractable .
unlike their work , we optimize a dif - ferent objective called the margin , based on support vec - tor machines ( 123 ) .
our learning formulation provides an ex - act and tractable optimization algorithm , as well as formal guarantees for binary classication problems .
unlike their work , our approach can also handle multi - class problems in a straightforward manner .
in a very recent work , torralba et al .
( 123 ) propose boosting random elds for image segmen - tation , combining ideas from boosting and crfs .
similar to our approach , they optimize the classication margin .
however , their implementation is specic to 123d image data , which poses very different challenges than 123d scans .
markov random fields
we restrict our attention to markov networks ( or random elds ) over discrete variables y = fy123; : : : ; yn g , where each variable corresponds to the label of a point in the 123d scan and has k possible values : yi 123 f123; : : : ; kg .
an assignment of values to y is denoted by y .
a markov net - work for y denes a joint distribution over f123; : : : ; kgn , dened by an undirected graph ( v; e ) over the nodes cor - responding to the variables .
in our task , the variables cor - respond to the scan points in the scene , and their values to their label , which can include different object types as well
a ) robot and campus map
b ) segmentation results
figure 123
a ) the robot and a portion of a 123d scan range map of stanford university .
b ) scan seg - mentation results obtained with svm , voted - svm and amn predictions .
( color legend : buildings / red , trees / green , shrubs / blue , ground / gray ) .
as background .
for simplicity of exposition , we focus our discussion to pairwise markov networks , where nodes and edges are associated with potentials ( cid : 123 ) i ( yi ) and ( cid : 123 ) ij ( yi; yj ) , ij 123 e ( i < j ) .
in our task , edges are associated with links between points in the scan , corresponding to physical prox - imity; these edges serve to correlate the labels of nearby points .
a node potential ( cid : 123 ) i ( yi ) species a non - negative number for each value of the variable yi .
similarly , an edge potential species non - negative number for each pair of values of yi; yj .
intuitively , a node potentials encodes a points individual preference for different labels , whereas the edge potentials encode the interactions between labels of related points .
the joint distribution specied by the net -
where z is the partition function given by z = the maximum a - posteriori ( map ) inference problem in a markov network is to nd arg maxy p ( cid : 123 ) ( y ) .
i ) qij123e ( cid : 123 ) ij ( y123
we further restrict our attention to an important sub - class of networks , called associative markov networks ( amns ) ( 123 ) that allow effective inference using graph - cuts ( 123 , 123 ) .
these associative potentials generalize the potts model ( 123 ) , rewarding instantiations where adjacent nodes have the same label .
specically , we require that ij ( cid : 123 ) 123 , and ( cid : 123 ) ij ( k; l ) = 123; 123k 123= l .
( cid : 123 ) ij ( k; k ) = ( cid : 123 ) k we formulate the node and edge potentials in terms of
ij , where ( cid : 123 ) k
the features of the objects xi 123 irdn and features of the re - lationships between them xij 123 irde .
in 123d range data , the xi might be the spin image or spatial occupancy histograms of a point i , while the xij might include the distance be - tween points i and j , the dot - product of their normals , etc .
the simplest model of dependence of the potentials on the features is log - linear combination : n ( cid : 123 ) xi and log ( cid : 123 ) ij ( k; k ) = wk e are label - specic row vectors of node and edge parameters , of size dn and de , respectively .
note that this formulation assumes that all of the nodes in the network share the same set of weights , and similarly all of the edges share the same weights .
stat - ing the amn restrictions in terms of the parameters w , we e ( cid : 123 ) xij ( cid : 123 ) 123
to ensure that wk require that wk e ( cid : 123 ) xij ( cid : 123 ) 123 , we e ( cid : 123 ) 123
simply assume that xij ( cid : 123 ) 123 , and constrain wk
e ( cid : 123 ) xij , where wk
log ( cid : 123 ) i ( k ) = wk
n and wk
the map problem for amns can be solved efciently using a min - cut algorithm .
in the case of binary labels ( k = 123 ) , the min - cut procedure is guaranteed to return the optimal map .
for k > 123 , the map problem is np - hard , but a procedure proposed by boykov et al .
( 123 ) , which augments the min - cut algorithm with an iterative procedure called alpha - expansion , guarantees a factor 123 approxima - tion of the optimal solution .
an alternative approach to solving the map inference problem is based on formulating the problem as an inte - ger program , and then using a linear programming relax - ation ( 123 , 123 ) .
this approach is slower in practice than the iterated min - cut approach , but has the same performance guarantees ( 123 ) .
importantly for our purposes , it forms the
basis for our learning procedure .
we represent an assignment y as a set of k ( cid : 123 ) n indicators i g , where yk i = i ( yi = k ) .
with these denitions , the
log of conditional probability log pw ( y j x ) is given by :
n ( cid : 123 ) xi ) yk
e ( cid : 123 ) xij ) yk
j ( cid : 123 ) log zw ( x ) :
note that the partition function zw ( x ) above depends on the parameters w and input features x , but not on the labels yis .
hence the map objective is quadratic in y .
e; : : : ; wk
n; : : : ; wk
for compactness of notation , we dene the node and n ) and we = edge weight vectors wn = ( w123 e ) , and let w = ( wn; we ) be a vector of all the weights , of size d = k ( dn + de ) .
also , we dene the node i ; : : : ) > and and edge labels vectors , yn = ( : : : ; y123 j , and the ij ; : : : ) > , where yk ye = ( : : : ; y123 vector of all labels y = ( yn; ye ) of size l = k ( n + jej ) .
finally , we dene an appropriate d ( cid : 123 ) l matrix x such that
i ; : : : ; yk ij = yk
ij ; : : : ; yk
log pw ( y j x ) = wxy ( cid : 123 ) log zw ( x ) :
the matrix x contains the node feature vectors xi and edge feature vectors xij repeated multiple times ( for each label k ) , and padded with zeros appropriately .
the linear programming formulation of the map prob -
lem for these networks can be written as :
n ( cid : 123 ) xi ) yk
e ( cid : 123 ) xij ) yk
i ( cid : 123 ) 123; 123i; k; x
i = 123; 123i;
ij ( cid : 123 ) yk
ij ( cid : 123 ) yk
123ij 123 e; k :
ij ( cid : 123 ) yk
i by vari - note that we substitute the quadratic terms yk ij by using two linear constraints yk i .
this works because the coefcient wk e ( cid : 123 ) xij is ij ( cid : 123 ) yk non - negative and we are maximizing the objective function .
i ) at the optimum , which is equiv - alent to yk j 123 f123; 123g .
in the binary case , i ; yk the linear program eq .
( 123 ) is guaranteed to produce an in - teger solution ( optimal assignment ) when a unique solution exists ( 123 ) .
for k > 123 , the lp may produce fractional so - lutions which are guaranteed to be within at most a factor of 123 of the optimal .
ij = min ( yk ij = yk
i ; yk j if yk
maximum margin estimation
we now consider the problem of training the weights w of a markov network given a labeled training instance ( x; ^y ) .
for simplicity of exposition , we assume that we have only a single training instance; the extension to the case of multiple instances is entirely straightforward .
note that , in our setting , a single training instance is not a single point , but an entire scene that contains tens of thousands of
the standard approach of learning a conditional model w given ( x; ^y ) is to maximize the log pw ( ^y j x ) , with an additional regularization term , which is usually taken to be the squared - norm of the weights w ( 123 ) .
an alterna - tive method , recently proposed by taskar et al .
( 123 ) , is to maximize the margin of condence in the true label assign - ment ^y over any other assignment y 123= ^y .
they show that the margin - maximization criterion provides signicant im - provements in accuracy over a range of problems .
it also al - lows high - dimensional feature spaces to be utilized by using the kernel trick , as in support vector machines .
the maxi - mum margin markov network ( m123n ) framework forms the basis for our work , so we begin by reviewing this approach .
as in support vector machines , the goal in an m123n is to maximize our condence in the true labels ^y relative to any other possible joint labeling y .
specically , we dene the gain of the true labels ^y over another joint labeling y as :
log pw ( ^y j x ) ( cid : 123 ) log pw ( y j x ) = wx ( ^y ( cid : 123 ) y ) :
in m123ns , the desired gain depends on the number of mis - classied labels in y , ( ^y; y ) , by scaling linearly with it :
max ( cid : 123 ) s : t : wx ( ^y ( cid : 123 ) y ) ( cid : 123 ) ( cid : 123 ) ( ^y; y ) ;
jjwjj123 ( cid : 123 ) 123 :
note that the number of incorrect node labels ( ^y; y ) can n yn .
( whenever ^yi and yi agree also be written as n ( cid : 123 ) ^y> i = 123 , adding on some label k , we have that ^yk 123 to ^y> n yn . ) by dividing through by ( cid : 123 ) and adding a slack variable for non - separable data , we obtain a quadratic pro - gram ( qp ) with exponentially many constraints :
i = 123 and yk
jjwjj123 + c ( cid : 123 )
wx ( ^y ( cid : 123 ) y ) ( cid : 123 ) n ( cid : 123 ) ^y>
n yn ( cid : 123 ) ( cid : 123 ) ; 123y 123 y :
this qp has a constraint for every possible joint assign - ment y to the markov network variables , resulting in an
as our rst step , we replace the exponential set of linear constraints in the max - margin qp of eq .
( 123 ) with the single equivalent non - linear constraint :
wx^y ( cid : 123 ) n + ( cid : 123 ) ( cid : 123 ) max
wxy ( cid : 123 ) ^y>
this non - linear constraint essentially requires that we nd the assignment y to the network variables which has the highest probability relative to the parameterization wx ( cid : 123 ) n .
thus , optimizing the max - margin qp contains the map inference task as a component .
the lp relaxation of eq .
( 123 ) provides us with precisely the necessary building block to provide an effective solu - tion for eq .
the map problem is precisely the max subproblem in this qp .
in the case of amns , this max sub - problem can be replaced with the lp of eq .
in effect , we are replacing the exponential constraint set one which includes a constraint for every discrete y , with an innite
constraint set one which includes a constraint for every continuous vector y in y 123 = fy : yk
ij ( cid : 123 ) yk after substituting the ( dual of the ) map lp into eq
i g; as dened in eq
i ( cid : 123 ) 123; pk yk
ij ( cid : 123 ) yk
i ; yk
and some algebraic manipulation ( see ( 123 ) ) , we obtain :
jjwjj123 + c ( cid : 123 )
wx^y ( cid : 123 ) n + ( cid : 123 ) ( cid : 123 )
( cid : 123 ) i; we ( cid : 123 ) 123;
( cid : 123 ) i ( cid : 123 ) x
ij ( cid : 123 ) wk
n ( cid : 123 ) xi ( cid : 123 ) ^yk
i ; 123i; k;
ji ( cid : 123 ) wk
ij + ( cid : 123 ) k
ji ( cid : 123 ) 123; 123ij 123 e; k : above , we also added the constraint we ( cid : 123 ) 123 to ensure pos - itivity of the edge log - potentials .
e ( cid : 123 ) xij ;
ij ; ( cid : 123 ) k
for k = 123 , the map lp is exact , so that eq .
( 123 ) learns exact max - margin weights for markov networks of arbi - trary topology .
for k > 123 , the linear relaxation leads to a strengthening of the constraints on w by potentially adding constraints corresponding to fractional assignments y .
thus , the optimal choice w; ( cid : 123 ) for the original qp may no longer be feasible , leading to a different choice of weights .
however , as our experiments show , these weights tend to do well in practice .
the dual of eq .
( 123 ) is given by :
( 123 ( cid : 123 ) ^yk
i ( cid : 123 ) ( cid : 123 ) k
( cid : 123 ) k + x
xij ( c ^yk
ij ( cid : 123 ) ( cid : 123 ) k
i ( cid : 123 ) 123; 123i; k; x
i = c; 123i;
ij ( cid : 123 ) 123;
( cid : 123 ) k ( cid : 123 ) 123; 123k :
ij ( cid : 123 ) ( cid : 123 ) k
i ; ( cid : 123 ) k
ij ( cid : 123 ) ( cid : 123 ) k
123ij 123 e; k;
the primal and dual solution are related by :
i ( cid : 123 ) ( cid : 123 ) k
e = ( cid : 123 ) k + x
xij ( c ^yk
ij ( cid : 123 ) ( cid : 123 ) k
experimental results
we validated our scan segmentation algorithm by ex - perimenting on two real - world and one synthetic datasets , which differed in both the type of 123d scanner used , and the types of objects present in the scene .
we describe each set of experiments separately below .
we compare the per - formance of our method to that of support vector machines ( svms ) , a state - of - the - art classication method known to work well in high - dimensional spaces .
the webpage contains additional results , including a y - through movie .
terrain classication .
terrain classication is useful for autonomous mobile robots in tasks such as path plan - target detection , and as a pre - processing step for the stanford segbot project ( http : / / robots . stanford . edu / ) has provided us with a laser range campus map collected by a robot equipped with a sick123 laser scanner ( see fig .
the robot drove around a campus environment and acquired around 123 million scan readings .
each reading was a point in 123d space , represented by its coordinates in an absolute frame of reference , which was fairly noisy due to sensor noise and localization errors .
our task is to classify the laser range points into four classes : ground , building , tree , and shrubbery .
classifying ground points is trivial given their absolute z - coordinate; we do it by thresholding the z coordinate at a value close to 123
after this , we are left with approximately 123 million non - ground points .
each point is represented simply as a location in an absolute 123d coordinate system .
the features we use require pre - processing to infer properties of the lo - cal neighborhood of a point , such as how planar the neigh - borhood is , or how much of the neighbors are close to the ground .
we use features that are invariant to rotation in the x - y plane , as well as the density of the range scan , since scans tend to be sparser in regions farther from the robot .
our rst type of feature is based on the principal plane around each point .
to compute it , we sample 123 points in a cube of radius 123 : 123 meters .
we run pca on these points to get the plane , spanned by the rst two principal compo - nents .
we then partition the cube into 123 ( cid : 123 ) 123 ( cid : 123 ) 123 bins around the point , oriented with respect to the principal plane , and compute the percentage of points lying in the various sub - cubes .
these percentages capture the local distribution well and are especially useful in nding planes .
our second type of feature is based on a column around each point .
we take a cylinder of radius 123 : 123 meters , which extends vertically to include all the points in a column .
we then compute what percentage of the points lie in various segments of this column ( e . g . , between 123m and 123m ) .
finally , we also use an indicator feature of whether a point lies within 123m of the ground .
this feature is especially useful in classifying
one important consequence of these relationships is that the node parameters are all support vector expansions .
thus , the terms in the constraints of the form wnx can all be ex - panded in terms of dot products x> i xi; similarly , the objec - tive ( jjwjj123 ) can be expanded similarly .
therefore , we can use kernels k ( xi; xj ) to dene node parameters .
unfortu - nately , the positivity constraint on the edge potentials , and the resulting ( cid : 123 ) k dual variable in the expansion of the edge weight , prevent the edge parameters from being kernelized in a similar way .
a ) training instance
d ) amn with edges ignored
figure 123
segmentation results on the puppet dataset .
a ) training set instance b ) amn segmentation result c ) svm segmentation result d ) result obtained by using the node weights learned by the amn , and ignoring the mrf edges e ) - h ) segmentation results on other testing set instances .
legend : head / green , torso / dark blue , limbs / red , background / gray ) .
for training we select roughly 123 thousand points that represent the classes well : a segment of a wall , a tree , some bushes .
we considered three different models : svm , voted - svm and amns .
all methods use the same set of features , augmented with a quadratic kernel .
the rst model
is a multi - class svm .
this model ( fig .
123 ( b ) , right panel ) achieves reasonable performance in many places , but fails to enforce local consistency of the classication predictions .
for example arches on buildings and other less planar regions are consistently confused for trees , even though they are surrounded entirely by build - ings .
we improved upon the svm by smoothing its predic - tions using voting .
for each point we took its local neigh - borhood and assigned the point the label of the majority of its 123 neighbors .
the voted - svm model ( fig .
123 ( b ) , mid - dle panel ) performs slightly better than svm , yet it still fails in areas like arches of buildings where the svm classier has a locally consistent wrong prediction .
the nal model is a pairwise amn .
each point is con - nected to 123 of its neighbors : 123 of them are sampled ran - domly from the local neighborhood in a sphere of radius 123 : 123m , and the other 123 are sampled at random from the ver - tical cylinder column of radius 123 : 123m .
it is important to en - sure vertical consistency since the svm classier is wrong in areas that are higher off the ground ( due to the decrease in point density ) or because objects tend to look different as we vary their z - coordinate ( for example , tree trunks and tree crowns look different ) .
while we experimented with a variety of edge features , we found that even using only a constant feature performs well .
we trained the amn model using cplex to solve the quadratic program; the training took about an hour on a pen - tium 123 desktop .
for inference , we used min - cut combined with the alpha - expansion algorithm of boykov et al .
de - scribed above ( 123 ) .
we split up the dataset into 123 square ( in the xy - plane ) regions , the largest of which contains around 123 : 123 million points .
the implementation is largely domi - nated by i / o time , with the actual min - cut taking less than a minute even for the largest segment .
we can see that the predictions of the amn ( fig .
123 b ) , left panel ) are much smoother : for example building arches and tree trunks are predicted correctly .
we hand - labeled around 123 thousand points of the test set and computed accuracies of the predictions ( excluding ground , which was classied by pre - processing ) .
the differences are dramatic : svm : 123% , voted - svm : 123% and amn : 123% .
segmentation of articulated objects .
we also tested our scan segmentation algorithm on a challenging dataset of cluttered scenes containing articulated wooden puppets .
the dataset was acquired by a scanning system based on temporal stereo ( 123 ) .
the system consists of two cameras and a projector , and outputs a triangulated surface only in the ar - eas that are visible to all three devices simultaneously .
the dataset contains eleven different single - view scans of three puppets of different sizes and in different positions .
it also contains clutter and occluding objects such as rope , sticks and rings .
each scan has around 123; 123 points , which we subsampled to around 123; 123 with standard software .
our goal was to segment the scenes into 123 classes puppet
figure 123
segmentation of vehicles ( cars , trucks , suvs ) from the background in synthetic range scans from the princeton dataset .
the amn performs reasonably well on most of the testing scenes , as demonstrated in scenes a ) , b ) , and c ) .
however , it sometimes fails to detect the vehicles in challenging scenes such as d ) .
( color legend : vehicles / green , background / pink ) .
head , limbs , torso and background .
five of the scenes comprise our training set , and the rest are kept for testing .
a sample scan from the training set is shown in fig
to segment articulated objects , it is desirable to have an approach which is independent of global orientation alto - gether , and which discriminates based on shape alone .
we used spin - images ( 123 ) as local point features .
we computed spin - images of size 123 ( cid : 123 ) 123 bins at two different resolutions .
we scaled the spin - image values , and performed pca to obtain 123 principal components , which comprised our point features .
we use the surface links output by the scanner as edges in the mrf .
again , we experimented with several different edge features , but we got the best performance by using a constant feature for each edge .
because of clutter and occlusion in the scenes , our amn framework achieves the best generalization performance when we keep the scope of the spin - images rather small ( comparable to the size of the puppets head ) .
our scan segmentation algorithm performed very well by classify - ing 123% of the testing set points accurately , translating into 123% recall and 123% precision on the task of de - tecting puppet parts versus background .
overall , our results ( see fig .
123eh ) show that amns can detect puppet parts with a fairly high degree of accuracy , even under occlusion and clutter .
the main source of classication error was the small puppet , which appears only in the testing set .
by comparison , the svm method applied to the same point features performs remarkably poorly ( see fig .
the classication accuracy on the testing set is 123% , but that is because that the majority of points are classied as
background; indeed , overall the svm approach achieves 123% precision but only 123% recall on the task of seg - menting puppet parts against background .
the poor per - formance is caused by the relatively small spin - image size which makes the algorithm more robust under clutter and occlusion , but at the same time makes it hard to discrimi - nate between locally similar shapes .
the dataset has signif - icant shape ambiguity , as it is very easy to confuse sticks for limbs , and the torso for parts of the computer mouse appear - ing in the testing set .
we tried to obtain a fairer comparison by changing the spin - image size to accommodate the svm algorithm .
the results were still signicantly worse .
to understand the reason underlying the superior per - formance of the amn , we ran a at classier with node weights trained for the amn model .
the result , shown in fig .
123d , suggests that our algorithm has an additional de - gree of exibility it can commit a lot of errors locally , but rely on the edge structure to eliminate the errors in the nal result .
this result demonstrates that our approach would be superior to a strategy which trains the edge and the node
princeton benchmark .
the nal test of our system was performed using a set of articially generated scenes , which contain different types of vehicles , trees , houses , and the ground .
models of the objects in these scenes were ob - tained from the princeton shape benchmark ( 123 ) , and were combined in various ways to construct the training and test scenes .
from these , a set of synthetic range scans were gen - erated by placing a virtual sensor inside the scene .
we cor -
rupted the sensor readings with additive white noise .
we then triangulated the resulting point cloud , and subsampled it down to our desired resolution .
we trained both the svm and the amn approaches to distinguish vehicles from other objects and background .
we used exactly the same node and edge features as in the pup - pet dataset , with the spin image size appropriately adjusted .
the results , shown in fig .
123 , demonstrate again that our method outperforms the svm method .
in general , the amn method labels most of the points on the vehicles correctly .
occasionally , the amn method labels a at part of a vehi - cle as background , because in this area , the features are in - distinguishable from a wall , and the edge potentials are not strong enough to overcome this ( see fig .
there are also cases in which the amn method fails , as in fig .
123d where we fail to detect the two cars under dense foliage .
by com - parison , the svm method is only able to label vehicle parts with signicant curvature , as at areas are locally to similar to background .
the amn method thus provides a signi - cant gain , producing a 123% overall accuracy , compared to only 123% for the svm approach .
we present an mrf - based method for detection and seg - mentation of complex objects and object classes from 123d range data .
our approach has a number of attractive the - oretical and practical properties .
by constraining the class of mrfs to be solvable by graph - cuts , our models are ef - ciently learned using a compact quadratic program , and at run - time , scale up to tens of millions of points and multiple object classes .
the proposed learning formulation effec - tively and directly learns to exploit a large set of complex surface and volumetric features , while balancing the spatial coherence modeled by the mrf .
there are several interesting directions in which our work can be extended , that address the main limitation of our work : its reliance on local features to distinguish ob - jects .
first , as our formulation is based on the max - margin framework underlying svms , we can easily incorporate kernels in order to further boost the expressive power of the models .
we are currently developing appropriate spa - tial kernels .
more importantly , our method relies heavily on the existence of distinguishing local surface features of objects .
since we do not model object parts and spatial relations between them , our method is effective at differ - entiating between mostly homogeneous objects ( for exam - ple , trees , buildings , limbs ) , which do not have many parts that look similar locally .
for example , it would be dif - cult to differentiate between car types , such as sedan vs .
coup , which look alike except for the rear door / trunk .
the challenge of incorporating the object / part hierarchy into the learning framework is a subject of our future work .
