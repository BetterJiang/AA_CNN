game theory provides a theoretical basis for defining ratio - nal behavior in multi - agent scenarios .
however , the compu - tational complexity of finding equilibria in large games has limited game theorys practical applications .
in this paper , we explore the application of structured probabilistic models to multi - agent scenarios .
we define multi - agent influence di - agrams ( maids ) , which represent games in a way that allows us to take advantage of independence relationships among variables .
this representation allows us to define a notion of strategic relevance : d is strategically relevant to d if , to optimize the decision rule at d , the decision maker needs to know the decision rule at d .
we provide a sound and com - plete graphical criterion for determining strategic relevance .
we then show how strategic relevance , which is made explicit by the maid structure , can be exploited in algorithms for computing equilibria to obtain exponential savings in certain classes of games .
game theory ( fudenberg & tirole 123 ) provides a math - ematical framework for determining what behavior is ra - tional for agents interacting with each other in a partially observable environment .
however , the computational com - plexity of finding equilibria in games has hindered the ap - plication of game theory to real - world problems .
most algo - rithms for finding equilibria operate on the strategic form of a game , whose size is typically exponential in the size of the game tree ( mckelvey & mclennan 123 ) .
even algorithms that operate directly on the game tree ( romanovskii 123; koller , megiddo , &von stengel 123 ) are not a solution , as for games involving many decisions , the game tree can be prohibitively large .
as an extreme case , if the game tree is symmetric ( i . e . , all paths to leaves have the same sequence of decisions ) , the number of leaf nodes is exponential in the number of decisions .
this problem of state space explosion also occurs in deci - sion trees , the single - agent versions of game trees .
influence diagrams ( ids ) ( howard & matheson 123 ) allow single - agent decision problems to be represented and solved with - out this exponential blow - up .
like bayesian networks ( pearl
*now at google inc .
copyright 123 , american association for artificial intelli - gence ( www . aaai . org ) .
all rights reserved .
123 ) , influence diagrams represent the conditional inde - pendencies among variables .
these formalisms allow us to take advantage of the structure in real - world problems to solve them more efficiently .
in this paper , we present an ex - tension of influence diagrams to the multi - agent setting , with the goal of providing compact representations and more ef - ficient solution algorithms for game - theoretic problems .
multi - agent influence diagrams ( maids ) represent deci - sion problems involving multiple agents in a structured way .
we show that maids allow us to exploit not only the depen - dencies between the probabilistic attributes in the domain ( as in bayesian networks ) , but also the dependencies be - tween strategic variables .
we define a notion of strategic relevance : a decision variable d strategically relies on an - other decision variable dt when , to optimize the decision rule in d , the decision - making agent needs to know the de - cision rule in dt .
we provide a graph - based criterion , which we call s - reachability , for strategic relevance , and show that it is sound and complete in the same sense that d - separation is sound and complete for probabilistic dependence .
we also provide a polynomial time algorithm for computing s -
the notion of strategic relevance allows us to define a data structure we call the relevance graph - - a directed graph that indicates when one decision variable in the maid relies on another .
we then show that this data structure can be exploited to provide more efficient algorithms for computing equilibria : it allows a large game to be broken up into several smaller games , whose equilibria can be combined to obtain a global equilibrium .
we will introduce maids using a simple two - agent sce -
example i alice is considering building a patio behind her house , and the patio would be more valuable to her if she could get a clear view of the ocean .
unfortunately , there is a tree in her neighbor bobs yard that blocks her view .
being somewhat unscrupulous , alice considers poisoning bob s tree , which might cause it to become sick .
bob cannot tell whether alice has poisoned his tree , but he can tell if the tree is getting sick , and he has the option of calling in a tree doctor ( at some cost ) .
the attention of a tree doctor reduces
the chance that the tree will die during the coming winter .
meanwhile , alice must make a decision about building her patio before the weather gets too cold .
when she makes this decision , she knows whether a tree doctor has come , but she cannot observe the health of the tree directly .
a maid for this scenario is shown in figure 123
figure l : maid for the tree killer example .
alices deci - sion and utility variables are in dark gray and bobs in light
to define a maid more formally , we begin with a set . a of agents .
the world in which the agents act is represented by the set c of chance variables , and a set 123a of decision vari - ables for each agent a e a .
chance variables correspond to moves by nature , and are represented in the diagram as ovals .
the decision variables for agent a are variables whose values a gets to choose , and are represented as rectangles in the diagram .
we use d to denote ua123at 123a , and 123 ) to de - note c to 123
each variable v e 123 has a finite set dom ( v ) of possible values , called its domain .
the agents utility func - tions are specified using utility variables : for each agent a 123 . a , we have a set / . / a of utility variables , represented as diamonds in the diagram , that take on real numbers as
a maid defines a directed acyclic graph with its vari - ables as the nodes , where each variable x is associated with a set of parents pa ( x ) c 123
note that utility variables cannot be parents of other variables .
for each chance vari - able x 123 c , the maid specifies a conditional probability distribution ( cpd ) : a distribution pr ( x i pa ) for each in - stantiation pa of pa ( x ) .
for a decision variable d 123 123a , pa ( d ) is the set of variables whose values agent a knows when he chooses a value for d .
thus , the choice agent a makes for d can be contingent only on these variables .
the value of a utility variable u is a deterministic function of the values of pa ( u ) ; we use u ( pa ) to denote the util - ity value for node u when pa ( u ) = pa .
for each utility variable u e h , f specifies , for each instantiation pa of pa ( u ) , the corresponding utility value f ( u ) ( pa ) , which abbreviate using u ( pa ) .
the total utility that an agent a de - rives from an instantiation of 123 is the sum of the utilities specified by the utility variables in ha for this instantiation .
thus , by breaking an agents utility function into several
variables , we are simply defining an additive decomposition of the agents utility function ( howard & matheson 123; keeney & raiffa 123 ) .
the behavior of the agents is defined by a set of decision
definition 123 a decision rule for a decision variable d is a function that maps each instantiation pa of pa ( d ) to a prob - ability distribution over dom ( d ) .
an assignment of decision rules to every decision d e 123a for a particular agent a e . a is called a strategy .
an assignment a of decision rules to every decision d 123 123 is called a strategy profile .
a partial strategy profile ac is an assignment of decision rules to a subset e of 123
we will also use ( re to denote the restriction of a to e , and cr - e to denote the restriction of a to variables not in e .
note that a decision rule has exactly the same form as a cpd .
thus , if we have a maid . at , then a partial strategy profile a that assigns decision rules to a set e of decision variables induces a new maid . a123 ( tr ) where the elements of e have become chance variables .
that is , each d e g corresponds to a chance variable in . a123 ( or ) with tr ( d ) as its cpd .
when a assigns a decision rule to every decision vari - able in . a123 , the induced maid is simply a bn : it has no more decision variables .
this bn defines a joint probability distribution p ~ over all the variables in . a123
with this probability distribution , we can now write an that agent a expects to receive in a
equation for the utility
. a123 if the agents play a given strategy profile tr :
eua ( a ) = ~ ~ u ( pa ) p ~ - m ( pa )
pa123 x pa ( u )
where x pa ( u ) is the joint domain of pa ( u ) .
in the game - theoretic framework , we typically consider a strategy profile to represent rational behavior if it is a nash equilibrium ( nash 123 ) .
intuitively , a strategy profile is nash equilibrium if no agent has an incentive to deviate from the strategy specified for him by the profile , as long as the other agents do not deviate from their specified strategies .
definition 123 a strategy profile cr is a nash equilibrium for a maid . a123 if for all agents a e , 123 and all strategies a " ella ( o ) eua ( ( 123_123 o " ) ) .
maids and games
a maid provides a compact representation of a scenario that can also be represented as a game in strategic or ex - tensive form .
in this section , we discuss how to convert a maid into an extensive - form game .
we also show how , once we have found an equilibrium strategy profile for a maid , we can convert it into a behavior strategy profile for the extensive form game .
the word " node " in this section refers solely to a node in the tree , as distinguished from the nodes in the maid .
we use a straightforward extension of a construction of ( pearl 123 ) for converting an influence diagram into decision tree .
the basic idea is to construct a tree with splits for decision and chance nodes in the maid .
we need to split on a chance variable before its value is observed by
some decision node; we need only split on chance vari - ables that are observed at some point in the process .
more precisely , the set of variables included in our game tree is g = 123 : ) u ud ~ v pa ( d ) .
we begin by defining a total ordering - ~ over g that is consistent with the topological order of the maid : if there is a directed path from x to y , then x - g y .
our tree 123 " is a symmetric tree , with each path containing splits over all the variables in g in the order defined by - - ~ .
each node is labeled with a partial instantiation inst ( n ) of g , in the obvious way .
for each agent a , the nodes corresponding to variables d e d , are decision nodes for a; the other nodes are all chance nodes .
to define the information sets , consider two decision nodes m and m ~ that correspond to a variable d .
we place m and m into the same information set if and only if inst ( m ) and inst ( m ) assign the same values to pa ( d ) .
to determine the probabilities for the chance nodes , we must do probabilistic inference .
it turns out that we can choose an arbitrary fully mixed strategy profile a for our maid . hi ( one where no decision has probability zero ) , and do inference in the bn 123 ( a ) induced by this strat - egy profile .
consider a chance node n corresponding to a chance variable c .
for each value e e dom ( c ) , let nc be the child of n corresponding to the choice c = c .
then we define the probability of going from n to nc as p ~ a ( inst ( nc ) ) inst ( n ) ) .
note that if we split on a deci - sion variable d before g , then the decision rule ad does not affect this computation because inst ( n ) includes values for d and all its parents .
if we split on d after c , then d can - not be an ancestor of c in the maid , and inst ( n ) cannot specify evidence on d or any of its descendants .
therefore , ad cannot affect the computation .
hence , the probabilities of the chance nodes are well - defined .
we define the payoffs at the leaves by computing a distri - bution over the parents of the utility nodes , given an instan - tiation of g .
for a leaf n , the payoff for agent a is :
ued / , , pae x pa ( u )
the mapping between maids and trees also induces an obvious mapping between strategy profiles in the different representations .
a maid strategy profile specifies a proba - bility distribution over dom ( d ) for each pair ( d , pa ) , where pa is an instantiation of pa ( d ) .
the information sets in the game tree correspond one - to - one with these pairs , and a behavior strategy in the game tree is a mapping from infor - mation sets to probability distributions .
clearly the two are
based on this construction , we can now state the follow -
ing equivalence lemma : lemma 123 let 123 be a maid and 123 " be its corresponding game tree .
then for any strategy profile a , the payoff vector for a in 123 is the same as the payoff vector for a in t .
the number of nodes in 123 " is exponential in the number of decision variables , and in the number of chance variables that are observed during the course of the game .
while this blowup is unavoidable in a tree representation , it can be quite
significant in certain games .
thus , a maid can be exponen - tially smaller than the extensive game it corresponds to .
example 123 suppose a road is being built from north to south through undeveloped land , and n agents have pur - chased plots of land along the road .
as the road reaches each agents plot , the agent needs to choose what to build on his land .
his utility depends on what he builds , on some private information about the suitability of his land for var - ious purposes , and on what is built north , south , and across the road from his land .
the agent can observe what has already been built immediately to the north of his land ( on both sides of the road ) , but he cannot observe further north; nor can he observe what will be built across from his land or south of it .
the maid representation
is very compact .
there are n chance nodes , corresponding to the private information about each agents land , and n decision variables .
each de - cision variable has at most three parents : the agents private inform , ation , and the two decisions regarding the two plots to the north of the agents land .
thus , the size of the maid is linear in n .
conversely , any game tree for this situation must split on each of the n chance nodes and each of the n decisions , leading to a representation that is exponential in
a maid representation
is not always more compact .
if the game tree is naturally asymmetric , a naive maid repre - sentation can be exponentially larger than the tree .
we return to this problem in section .
to take advantage of the independence structure in a maid , we would like to find a global equilibrium through a series of relatively simple local computations .
the difficulty is that in order to determine the optimal decision rule for a sin - gle decision variable , we usually need to know the decision rules for some other variables .
in example 123 , when alice is deciding whether to poison the tree , she needs to compare the expected utilities of her two alternatives .
however , the probability of the tree dying depends on the probability of bob calling a tree doctor if he observes that the tree is sick .
thus , we need to know the decision rule for calltreedoctor to determine the optimal decision rule for poisontree .
in such situations , we will say that poisontree ( strategically ) relies on calltreedoctor , or that calltreedoctor is rel - evant to poisontree .
on the other hand , calltreedoctor does not rely on poisontree .
bob gets to observe whether the tree is sick , and treedead is conditionally indepen - dent of poisontree given treesick , so the decision rule for poisontree is not relevant to bobs decision .
we will now formalize this intuitive discussion of strate -
gic relevance .
suppose we have a strategy profile , and we would like to find a decision rule for a single decision vari - able d e 123 ~ that maximizes as expected utility , assuming the rest of the strategy profile remains fixed .
definition 123 let ~ be a decision rule for a variable d in a maid 123
then ~ is optimal for a strategy profile a if , in the induced maid ad ( a - d ) ( where the only remaining decision node is d ) , the strategy profile ( ~ ) is a nash equilibrium .
given this definition of optimality for a strategy profile ,
we can now define strategic relevance .
definition 123 a decision variable d strategically relies on a decision variable d in a maid 123 if there are two strategy profiles a and a ~ such that a and tr ~ differ only at d ~ , but some decision rule for d is optimal for cr and not for a
if d does not rely on d ~ , then a decision rule for d that is optimal for a strategy profile a is also optimal for any strategy profile a that differs from a only at d
it turns out that strategic relevance corresponds to a sim - ple graph - theoretic property in a maid .
to begin with , sup - pose we have a strategy profile a for a maid 123 , and con - sider finding an optimal decision rule for d in 123 ( a - o ) , where d is the only decision node .
the optimality of the decision rule at d depends only on the utility nodes / 123o that are descendants of d in the maid .
the other utility nodes are irrelevant , because the decision at d cannot influence them .
now , based on the independence properties implied by the graph structure , we can prove the following lemma :
lemma 123 let 123 be a decision rule for a decision variable d e 123a in a maid 123 , and let a be a strategy profile for 123
then ~ is optimal for a if and only if for every instanti - ation pad of pa ( d ) where pm ( pad ) > o , the probability distribution ~ ( d ( pa ) is :
ueud pa u e x pa ( u )
so to be optimal for a strategy profile a , a decision rule
just has to satisfy equation 123
if the expression being maxi - mized in equation 123 is independent of the decision rule that a assigns to another decision variable d ~ , then d does not rely on d .
thus , we would like a graphical criterion for de - tecting when this expression is independent of the decision rule for some node .
the appropriate formal notion turns out to be that of a requisite probability node .
definition 123 let 123 ( and y be sets of variables in the di - rected acyclic graph defined by a bn or maid .
then a node z is a requisite probability node for the query p ( x i y ) there exist two functions p123 and pz that assign cpds to all the nodes in the graph , such that p123 and p123 differ only at z , butpl ( xly ) p123 ( x i y ) intuitively , the decision rule at d ~ is only relevant to d if d ( viewed as a chance node ) is a relevant probability node for p ( ud i d , pa ( d ) ) .
geiger et al .
( 123 ) provide a graphical criterion for test - ing whether a node z is a requisite probability node for a query p ( x i y ) .
we add to z a new " dummy " parent 123 whose values correspond to cpds for z , selected from some set of possible cpds .
then z is a requisite probability node for p ( x i y ) if and only if z can influence x given y .
this condition can easily be checked using the standard notion of active paths in the bn .
thus , z is a requisite probability
node for p ( x i 123; ) if and only if there would be an active path from a new parent of z to x , given y .
based on this analysis , we can define s - reachability , a graphical criterion for detecting strategic relevance .
note that unlike d - separation in bayesian networks , s - reachability is not necessarily a symmetric relation .
definition 123 a node d ~ is s - reachable from a node d in a maid if there is some utility node u e ud such that if a new parent d ~ were added to d ~ , there would be an active path from d ~ to pa ( u ) given pa ( d ) u ( d ) .
as we now show , s - reachability
is sound and complete for strategic relevance in the same sense that d - separation is sound and complete for independence in bayesian networks .
theorem 123 ( soundness ) if d and d ~ are two decision nodes in a maid and d is not s - reachable from d in the maid , then d does not rely on d .
theorem 123 ( completeness ) if a node d is s - reachable from a node d in a maid , then there is some maid with the same graph structure in which d relies on d
as for bns , the completeness result is somewhat weaker : s - reachability does not imply relevance in every maid .
we can choose the probabilities and utilities in the maid in such a way that the influence of one decision rule on an - other does not manifest itself .
however , s - reachability is the most precise graphical criterion we can use " it will not iden - tify a strategic relevance unless that relevance actually exists in some maid that has the given graph structure .
our proof of this theorem involves constructing an appropriate assign - ment of cpds and utility functions to the maid , and de - pends on the completeness proof in ( geiger , verma , & pearl
since strategic relevance is a binary relation , we can rep - resent it as a directed graph .
as we show below , this graph turns out to be extremely useful .
definition 123 the relevance graph for a maid 123 is a graph whose nodes are the decision nodes of . m , and whose edges are the pairs of nodes ( d , d ~ ) such that d relies on d
the graph for a given maid , we need to determine , for each decision node d , the set of nodes d that are s - reachable from d .
using an algorithm such as shachters bayes - ball ( shachter 123 ) , we can find this set for any given d in time linear in the number of nodes in the maid .
by repeating the algorithm for each d , we can de - rive the relevance graph in time quadratic in the number of
it is interesting to consider the relevance graphs of various simple games .
in the examples in figure 123 , the decision node d belongs to agent a , and d belongs to agent b .
example ( a ) represents a perfect - information game .
since agent b can observe the value of d , he does not need to know the deci - sion rule for d in order to evaluate his options .
thus , d does not rely on d .
on the other hand , agent a cannot ob - serve d ~ when she makes decision d , and d ~ is relevant to as utility , so d relies on dq example ( b ) represents a game where the agents do not have perfect information : agent b cannot observe d when making decision d .
however , the
the algorithm is a generalization of existing backward in - duction algorithms for decision trees and perfect information games ( zermelo 123 ) and for influence diagrams ( jensen , jensen , & dittmer 123 ) .
the basic idea is as follows : in order to optimize the decision rule for d , we need to know the decision rule for all decisions d ~ that are relevant for d .
for example , the relevance graph for the troo killor ex - ample ( figure 123 ( a ) ) shows that to optimize poisontree , we must first decide on the decision rules for buildpatio and treedoctor .
however , we can optimize treedoctor with - out knowing the decision rules for either of the other de - cision variables .
having decided on the decision rule for treedoctor , we can now optimize buildpatio and then fi -
figure 123 : relevance graphs for ( a ) the tree killor example; ( b ) the road example with n =
in this simple case , the relevance graph is acyclic , allow - ing us to process the variables one at a time .
in general , however , we might have cycles in the relevance graph; e . g . , figure 123 ( b ) contains the relevance graph for the road exam - ple with n = 123
here , we cannot sequentially optimize in - dividual decisions , because at various points in the process , there is no decision node that only relies on decisions for which we have already obtained a decision rule .
however , we can perform a backward induction process over subsets definition 123 a set s of nodes in a directed graph is a strongly connected component ( scc ) if for every pair nodes d ~ d e s , there exists a directed path from d to d ~ .
a maximal scc is an scc that is not a strict subset of any other scc .
the maximal sccs are outlined in figure 123 ( b ) .
we can find the maximal sccs of a graph in linear time , construct - ing a component graph whose nodes are the maximal sccs of the relevance graph .
there is an edge from component c to component c ~ in the component graph if and only if there is an edge from some element of c to some element of c ~ in the relevance graph .
the component graph is always acyclic ( cormen , leiserson , & rivest 123 ) .
thus , we can define an ordering c123 , . . .
, cm over the maximal sccs of the relevance graph , such that whenever i < j , no element of cj relies on any element of ci .
figure 123 : five simple maids ( top ) , and their relevance graphs ( bottom ) .
a two - color diamond represents a pair utility nodes , one for each agent , with the same parents .
information is " perfect enough " : the utility for b does not depend on d directly , but only on the chance node , which b can observe .
hence d ~ does not rely on d .
examples ( c ) and ( d ) represent scenarios where the agents move simultaneously , and thus neither can observe the others move .
in ( c ) , each agents utility node is influenced by both decisions , so d relies on d ~ and d ~ relies on d .
thus , the relevance graph is cyclic .
in ( d ) , however , the rel - evance graph is acyclic despite the fact that the agents move simultaneously .
the difference here is that agent a no longer cares what agent b does , because her utility is not influenced by bs decision .
in graphical terms , there is no active path from d ~ to as utility node given d .
one might conclude that a decision node d ~ never relies on a decision node d when d is observed by d ~ , but the situation is more subtle .
consider example ( e ) , which rep - resents a simple card game : agent a observes a card , and decides whether to bet ( d ) ; agent b observes only agent as bet , and decides whether to bet ( d ~ ) ; the utility of both de - pends on their bets and the value of the card .
even though agent b observes the actual decision in d , he needs to know the decision rule for d in order to know what the value of d tells him about the chance node .
thus , d ~ relies on d; indeed , when d is observed , there is an active path from d that runs through the chance node to the utility node .
using divide &
the computation of a nash equilibrium for a game is ar - guably the key computational task in game theory .
in this section , we show how the structure of the maid can be ex - ploited to provide substantially faster algorithms for finding
the key insight behind our algorithm is the use of the relevance graph to break up the task of finding an equilib - rium into a series of subtasks , each over a much smaller game .
since algorithms for finding equilibria games have complexity that is superlinear in the number of levels in the game tree , breaking the game into smaller games will significantly improve the complexity of finding a global equilibrium .
based on this definition , we can now provide a divide -
and - conquer algorithm for computing nash equilibria 123 let ~ r be an arbitrary fully mixed strategy profile
let 123 - be a partial strategy profile for c ( m - 123 that is
fori = 123 throughm - 123 :
nash equilibrium in . hall / cri - - c ( m - i )
123 output ~ rr ~ as an equilibrium of . m
= ( o " ( 123n_i ) )
the algorithm iterates backwards over the sccs , finding
an equilibrium strategy profile for each scc in the maid induced by the previously selected decision rules ( with ar - bitrary decision rules for some decisions that are not rele - vant for this scc ) .
finding the equilibrium in this induced maid requires the use of a subroutine for finding equilib - ria in games .
we simply convert the induced maid into a game tree , as described in section , and use a standard game - solving algorithm ( mckelvey & mclennan 123 ) .
if the relevance graph is acyclic , each scc consists of a single node , so each decision is optimized by itself .
in this case , the algorithm is very similar to the standard backward induction algorithm in perfect information games .
however , we obtain acyclic relevance graphs in a wider range of situ - ations .
for example , the relevance graph of the treo killer example is acyclic , although the game does not have perfect
the proof that this algorithm is correct requires a se - quence of lemmas .
so far we have considered strategic rel - evance only as a binary relation between nodes .
suppose 123 is a decision rule for d123 that is optimal for a strategy profile a , and d123 relies on neither d123 nor d123
then changing ~ z at either d123 or d123 does not affect the optimality of 123
but one might worry that changing ( r at both d123 and d123 might cause 123 to lose optimality .
the following lemma shows that such a thing cannot happen : if we have a set of decisions none of which are individually relevant , then the entire set is not lemma 123 let ~ r be a strategy profile , d be a decbion node , and 123 be a decision rule for d that is optimal for ~ r .
if ~ rr is another strategy profile such that cr ( d ) - - or ( d ) whenever d relies on dr , then 123 is also optimal for ~ r
proof : we proceed by induction on the number k of nodes where ~ r and cr ~ differ .
for the base case , k = 123 and cr = cr so it is obvious that 123 is also optimal for crr .
now as an induc - tive hypothesis , assume the lemma holds whenever ~ z and a differ on exactly k nodes .
then suppose cr and ar differ on k + 123 nodes .
select any node d such that ~ r ( d ) ~ cr ( d ) .
by the conditions of the lemma , this means d does not rely on dr .
now construct a strategy profile 123
that agrees with ~ r on all nodes but dr , and agrees with ~ rr on dr .
because ~ r and # differ only on d , 123 must also be optimal for 123; oth - erwise d would rely on dr .
but 123 " and crr differ on only k nodes , so by the inductive hypothesis , 123 is optimal for ar as
thus , we can change the decision rules for a whole set of nodes that are irrelevant for d without affecting the optimal -
ity of a decision rule for d .
but in our divide and conquer algorithm , we are concerned with the optimality of a par - tial strategy profile 123 - for an entire set c of decision nodes .
clearly , if none of the decision nodes in c rely on a node d ~ ~ c , then changing the decision rule for d would not give . any agent an incentive to deviate at a single decision node in c .
but might an agent want to deviate at several decision nodes simultaneously ?
we can answer this question in the negative if we make the standard assumption of perfect recall : agents never forget their previous actions or observations .
more formally :
definition 123 an agent a has perfect recall with respect to a total order - 123 over 123a if for all d ) dr e 123 , , d - - 123 d
that d e pa ( d ) and pa ( d ) c pa ( d ) .
note that if d and its parents are parents of d ~ , then there cannot be an active path from a new parent / 123 of d to any descendant of d , given dr and pa ( dr ) .
thus , by theo - rem 123 , dr does not rely on d .
this observation leads to the
lemma 123 if an agent has perfect recall with respect to a total order - ~ , and 123 - . < d ~ , then d ~ does not rely on d .
we can now show that if a single agent has no incentive to deviate at a single decision node , then he has no incentive to deviate at any group of nodes .
lemma 123 let . a123 be a maid with a single agent a , who has perfect recall let ~ r be a strategy for a in . hd such that for every d e 123 , ~ r ( d ) is optimal for cr .
then crb a nash equillbrium in . h123
proof : to show that cr is a nash equilibrium , we must show that for all other strategies ~ # :
we proceed by induction on the number k of decisions where a and ar differ .
if k = 123 , then cr = a , so obvi - ously eua ( ~ r ) = eu ~ ( cry ) .
as an inductive hypothesis , suppose that whenever ~ rr differs from cr on k or fewer nodes ,
now suppose ( 123 differs from er on k + 123 nodes .
since has perfect recall , lemma 123 tells us there is a total order - . < over 123 such that whenever d - 123 dr , d does not rely on d .
let d* be the last decision in this ordering such that ( rr ( d* ) 123 ~ ( r ( d* ) .
that is , if crr ( d ) ~ r ( d ) , then d = d* or d - 123 d* .
in either case , d* does not rely on d .
let 123 = a ( d ) , and 123 = at ( d ) .
we are given that is optimal for cr .
but since ar differs from cr only at nodes that d* does not rely on , we know by lemma 123 that 123 is also optimal for ~ rr .
in particular , 123 yields at least as much expected utility as 123r in . m ( 123 " % . )
eua ( c / _d , , 123 ) >_ eua ( a )
tthe notion of nash equilibrium in the single agent case re - duces to the simpler notion of the agent acting optimally under
but the strategy ( fit_d . , 123 ) differs from a at only k decision nodes , so by the inductive hypothesis :
eua ( ( 123 ) > eua ( a_o . , 123 )
so by transitivity :
eua ( a ) _> eua t )
given this result , we can show that changing the decision rules for nodes that are not relevant to any node in a set c does not affect the optimality of a partial strategy profile over lemma 123 let a be a strategy profile for a maid . all where every agent has perfect recall , and let r be a partial strategy profile for a set 123 of decision nodes in . m .
suppose t is a nash equilibrium in . m ( a - c ) , and e is a set of decision nodes in m ( disjoint from c ) such that no node in c relies on any node in 123
then if a is another strategy profile that differs from a only on 123 , t is also a nash equilibrium in
proof : for each agent a , let ca = c fq 123a .
if ca # 123 , let ta be the restriction of r to ca , and 123 - _a be the restriction of t to t123 \ ca .
by the definition of a nash equilibrium , it suffices to show that in the induced maid . m ( a ~ _c ) , no agent a has an incentive to deviate from ra to another strategy ra , assuming the other agents adhere to t .
in other words , we must show that ta is a nash equilibrium in the induced single - agent in - fluence diagram . m ( al_c , t - a ) .
consider an arbitrary decision d e ca .
we are given that r is an equilibrium in . m ( a - c ) , so the decision rule ra ( d ) is optimal for ( a - c , r ) .
we are also given that ( r differs from a only at nodes that are irrelevant for d .
so by lemma 123 , ~ - a ( d ) is also optimal for ( a ~ _c , t ) .
this is equivalent to saying that ta ( d ) is optimal for the strategy ta in . m ( a ~ _c , ~ - _a ) .
since every ta ( d ) is optimal for ta , lemma 123 implies that ta is a nash equilibrium .
recall that our algorithm produces a strategy profile atm .
lemma 123 implies that for each scc c in the relevance graph , the partial strategy profile that am specifies for c is a nash equilibrium in . m jam_c ) .
thus , no agent has an incentive to deviate from am on the nodes within any single scc .
we now prove a lemma that generalizes lemma 123 , showing that in fact , no agent has an incentive to deviate from am on any group of nodes .
lemma 123 let . h123 be a maid where every agent has perfect recall , and let c123 , . . .
, cm be sets of decision nodes in . m such that whenever i < j , no element of cd relies on any element of ci .
lf a is a strategy profile for jt123 such that for each i e ( 123 , m ) , ac , is a nash equilibrium in . aa ( a - c , ) , then a is a nash equilibrium for m .
proof : we must show that for any agent a and any alter - native strategy tr ~ for i ) a , eua ( a ) _> eua ( a - a , a ~ ) .
proceed by induction on the number of sets ci where aa and differ .
the base case is where they differ on zero sets; then aa = aa and eua ( a ) eua ( a , a ~ a ) .
as an inductive
hypothesis , suppose that whenever a or fewer sets , eua ( a ) _> eua ( a - a , a ) .
differs from aa on k
now suppose aa
differs from aa on k + 123 sets .
for each set ci , let ci , a = cifqt ) a .
let cj be the last set in the ordering where the partial strategy profiles aa ( cj , a ) and er ~ ( cj , a ) are different .
let " ca = aa ( cj , a ) , and r ~ = a ~ ( cj , a ) .
since a ( cj ) is an equilibrium in . m ( a_cj ) , we know that ra is an equilibrium in . m ( a - a , ( aa ) - cj ) .
but a ~ differs from aa only on sets ci where i < j , and no node in cj relies on any node in these sets .
so by lemma 123 , " ca is also an equilibrium in . m ( a - a , ( a ) - cj ) .
in particular , ra yields at least as much expected utility as q - ~ in . m ( a - a , ( a ~ ) - c ~ ) .
eux ~ ( a - a , ( a ~ ) - c ~ , ~ - a ) > eua123 ( a - a ,
but ( ( aa ) _sooj , dif fers fro m aa on only k s ets .
so by the inductive hypothesis :
eum ( a ) > eum ( a - a ,
so by transitivity :
eua123 ( a ) > eu ~ ( a - a , cr ~ ) .
using this lemma , we can finally prove the correctness of
theorem 123 if . m is a maid where every agent has perfect recall , then the strategy profile crm derived by the algorithm above is a nash equilibrium for . &t .
proof : consider any scc c ( m - i ) , where < i < m . by construction , ai+ ~ assigns to c ( m - i ) a partial strategy pro - file t that is a nash equilibrium in a / / ( _c ( ~ _o ) .
because ( m - i ) decreases as i increases from one iteration of the algorithm to the next , am differs from ai only on sccs cj where j < ( m - i ) .
because the ordering of sccs a topological ordering in the relevance graph , no node in c ( m - i ) relies on any node in cj where j < ( m - i ) .
there - fore am agrees with ai on all nodes that are relevant for any node in c ( m - i ) .
so by lemma 123 , t is a nash equilibrium in . m ( . _c ( m_ , ) ) .
since this is true for every scc , lemma 123 implies that am is a nash equilibrium in . m .
to demonstrate the potential savings resulting from our al - gorithm , we tried it on the road example .
as shown in the relevance graph in figure 123 ( b ) , the decision for a given plot relies on the decisions about the plot across from it and the plot directly to the south .
however , it does not rely on the decision about the land directly north of it , because this de - cision is observed .
none of the other decisions affect this agents utility directly .
the sccs in the relevance graph all have size 123 : they correspond to pairs of decisions about plots that are across from each other .
even for small values of n , it is infeasible
the road example with standard game - solving algorithms .
suppose the chance and decision variables each have three possible values , corresponding to three types of buildings .
then the game tree corresponding to the road maid has 123n terminal nodes .
since each agent ( except the first can observe three ternary variables , he has 123 information sets .
so the number of possible pure ( deterministic ) strate - gies for each agent is 123r , and the number of pure strategy profiles for all n players is ( 123 ) ( n - 123 ) ( 123 ) 123
in the sim - plest interesting case , where n = 123 , we obtain a game tree with 123 terminal nodes , and standard solution algorithms would need to operate on a strategic - form game matrix with about 123 x 123 entries ( one for each pure strategy profile ) .
number of plots of land
divide end conquer algorithm
figure 123 : performance results for the road example .
figure 123 shows how our divide - and - conquer algorithm performs on the road example .
we converted each of the induced maids constructed during the algorithm into a small game tree , and used the game solver gambit ( mck - elvey , mclennan , & turocy 123 ) to solve it .
as expected , the time required by our algorithm grows polynomially with n .
thus , we can solve a road maid with 123 agents ( corre - sponding to a game tree with 123 terminal nodes ) in about hour and 123 minutes .
and future work
we have introduced a new formalism , multi - agent influence diagrams ( maids ) , for modeling multi - agent scenarios with imperfect information .
maids allow the conditional inde - pendence structure of a scenario to be represented explic - limiting the state space explosion which plagues both strategic - form and extensive - form games .
we have also shown that maids allow us to define a qualitative graph - based notion that represents strategic relevance , and to ex - ploit it as the basis for algorithms that find equilibria effi -
although the possibility of extending influence diagrams to multi - agent scenarios was recognized at least fifteen years ago ( shachter 123 ) , the idea seems to have been dormant for some time .
suryadi and gmytrasiewicz ( 123 ) have used influence diagrams as a framework for learning in multi - agent systems .
the focus of their work is very differ -
ent , and they do not consider the computational benefits derived from the influence diagram representation .
milch and koller ( 123 ) use multi - agent influence diagrams as representational framework for reasoning about agents be - liefs and decisions .
however , they do not deal explicitly with the conversion of a maid into a game tree , and leave open the question of how to find equilibria .
nilsson and lauritzen ( 123 ) have done related work on limited mem - ory influence diagrams , or limids .
although they mention that limids could be applied to multi - agent scenarios , they only consider the use of limids to speed up inference in
maids are also related to la muras ( 123 ) game net - works , which incorporate both probabilistic and utility dependence .
la mura defines a notion of strategic dence , and also uses it to break up the game into separate components .
however , his notion of strategic is an undirected one , and thus does not allow as fine - grained a decomposition as the directed relevance graph used in this paper , nor the use of a backward induction process for deci - sions that are not strategically independent .
this work leaves many interesting open questions .
first , there is a great deal of work to be done in relating maids to existing concepts in game theory , particularly equilibrium refinements .
on the algorithmic front , the most pressing question is whether we can take advantage of independence structure within sccs in the relevance graph .
on the rep - resentational front , it is important to extend maids to deal with asymmetric situations , where the decisions to be made and the information available depend on previous decisions or chance moves .
game trees represent such asymmetry in a natural way , whereas in maids ( as in influence dia - grams and bns ) , a naive representation of an asymmetric leads to unnecessary blowup .
we may be able to avoid these difficulties representing context - specificity , as in ( boutilier et al .
123; smith , holtzman , & matheson 123 ) , integrating the best of the game tree and maid representations .
in maids by explicitly
