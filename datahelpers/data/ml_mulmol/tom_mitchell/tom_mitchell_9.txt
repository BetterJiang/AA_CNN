abstract .
the problem of formulating general concepts from specific training examples has long been a major focus of machine learning research .
while most previous research has focused on empirical methods for generalizing from a large number of training examples using no domain - specific knowledge , in the past few years new methods have been developed for applying domain - specific knowledge to for - mulate valid generalizations from single training examples .
the characteristic common to these methods is that their ability to generalize from a single example follows from their ability to explain why the training example is a member of the concept being learned .
this paper proposes a general , domain - independent mechanism , called ebg , that unifies previous approaches to explanation - based generalization .
the ebg method is illustrated in the context of several example problems , and used to contrast several existing systems for explanation - based generalization .
the perspective on explanation - based generalization af - forded by this general method is also used to identify open research problems in this area .
introduction and motivation
the ability to generalize from examples is widely recognized as an essential capability of any learning system .
generalization involves observing a set of training examples of some general concept , identifying the essential features common to these ex - amples , then formulating a concept definition based on these common features .
the generalization process can thus be viewed as a search through a vast space of possible concept definitions , in search of a correct definition of the concept to be learned .
because this space of possible concept definitions is vast , the heart of the generaliza - tion problem lies in utilizing whatever training data , assumptions and knowledge are available to constrain this search .
most research on the generalization problem has focused on empirical , data - intensive methods that rely on large numbers of training examples to constrain the search for the correct generalization ( see mitchell , 123; michalski , 123; dietterich ,
mitchell , r . m .
keller and s . t .
kedar - cabell123
123 for overviews of these methods ) .
these methods all employ some kind of induc - tive bias to guide the inductive leap that they must make in order to define a concept from only a subset of its examples ( mitchell , 123 ) .
this bias is typically built into the generalizer by providing it with knowledge only of those example features that are presumed relevant to describing the concept to be learned .
through various algorithms it is then possible to search through the restricted space of concepts definable in terms of these allowed features , to determine concept definitions consis - tent with the training examples .
because these methods are based on searching for features that are common to the training examples , we shall refer to them as similarity - based generalization methods . 123
in recent years , a number of researchers have proposed generalization methods that contrast sharply with these data - intensive , similarity - based methods ( e . g . , borgida et al . , 123; dejong , 123; kedar - cabelli , 123; keller , 123; lebowitz , 123; mahadevan , 123; minton , 123; mitchell , 123; mitchell et al . , 123; o ' rorke , 123; salzberg & atkinson , 123; schank , 123; silver , 123; utgoff , 123; winston et al . , 123 ) .
rather than relying on many training examples and an inductive bias to constrain the search for a correct generalization , these more recent methods constrain the search by relying on knowledge of the task domain and of the concept under study .
after analyzing a single training example in terms of this knowledge , these methods are able to produce a valid generalization of the example along with a deductive justification of the generalization in terms of the system ' s knowledge .
more precisely , these explanation - based methods123 analyze the training example by first constructing an explanation of how the example satisfies the defini - tion of the concept under study .
the features of the example identified by this ex - planation are then used as the basis for formulating the general concept definition .
the justification for this concept definition follows from the explanation constructed for the training example .
thus , by relying on knowledge of the domain and of the concept under study , explanation - based methods overcome the fundamental difficulty associated with in - ductive , similarity - based methods : their inability to justify the generalizations that they produce .
the basic difference between the two classes of methods is that similarity - based methods must rely on some form of inductive bias to guide generalization , whereas explanation - based methods rely instead on their domain knowledge .
while explanation - based methods provide a more reliable means of
' the term similarity - based generalization was suggested by lebowitz ( 123 ) .
we use this term to cover both methods that search for similarities among positive examples , and for differences between positive and negative examples .
123 the term explanation - based generalization was first introduced by dejong ( 123 ) to describe his par - ticular generalization method .
the authors have previously used the term goal - directed generalization ( mitchell , 123 ) to refer to their own explanation - based generalization method .
in this paper , we use the term explanation - based generalization to refer to the entire class of methods that formulate generaliza - tions by constructing explanations .
generalization , and are able to extract more information from individual training examples , they also require that the learner possess knowledge of the domain and of the concept under study .
it seems clear that for a large number of generalization problems encountered by intelligent agents , this required knowledge is available to the learner .
in this paper we present and analyze a number of such generalization
the purpose of this paper is to consider in detail the capabilities and requirements of explanation - based approaches to generalization , and to introduce a single mechanism that unifies previously described approaches .
in particular , we present a domain - independent method ( called ebg ) for utilizing domain - specific knowledge to guide generalization , and illustrate its use in a number of generalization tasks that have previously been approached using differing explanation - based methods .
ebg constitutes a more general mechanism for explanation - based generalization than these previous approaches .
because it requires a larger number of explicit inputs ( i . e . , the training example , a domain theory , a definition of the concept under study , and a description of the form in which the learned concept must be expressed ) ebg can be instantiated for a wider variety of learning tasks .
finally , ebg provides a perspec - tive for identifying the present limitations of explanation - based generalization , and for identifying open research problems in this area .
the remainder of this paper is organized as follows .
section 123 introduces the general ebg method for explanation - based generalization , and illustrates the method with an example .
section 123 then illustrates the ebg method in the context of two additional examples : ( 123 ) learning a structural definition of a cup from a train - ing example plus knowledge about the function of a cup ( based on winston et al . ' s ( 123 ) work ) , and ( 123 ) learning a search heuristic from an example search tree plus knowledge about search and the search space ( based on mitchell et al . ' s ( 123 ) work on the lex system ) .
section 123 concludes with a general perspective on explanation - based generalization and a discussion of significant open research issues in this area .
the appendix relates dejong ' s ( 123 , 123 ) research on explanation - based generalization and explanatory schema acquisition to the other work discussed here .
explanation - based generalization : discussion and an example
the key insight behind explanation - based generalization is that it is possible to form a justified generalization of a single positive training example provided the learning system is endowed with some explanatory capabilities .
in particular , the system must be able to explain to itself why the training example is an example of the concept under study .
thus , the generalizer is presumed to possess a definition of the concept under study as well as domain knowledge for constructing the required explanation .
in this section , we define more precisely the class of generalization problems covered by explanation - based methods , define the general ebg method , and illustrate it in terms of a specific example problem .
mitchell , r . m .
keller and s . t .
kedar - cabelli
123 the explanation - based generalization problem
in order to define the generalization problem considered here , we first introduce some terminology .
a concept is defined as a predicate over some universe of in - stances , and thus characterizes some subset of the instances .
each instance in this universe is described by a collection of ground literals that represent its features and their values .
a concept definition describes the necessary and sufficient conditions for being an example of the concept , while a sufficient concept definition describes sufficient conditions for being an example of the concept .
an instance that satisfies the concept definition is called an example , or positive example of that concept , whereas an instance that does not satisfy the concept definition is called a negative example of that concept .
a generalization of an example is a concept definition which describes a set containing that example . 123 an explanation of how an instance is an ex - ample of a concept is a proof that the example satisfies the concept definition .
an explanation structure is the proof tree , modified by replacing each instantiated rule by the associated general rule .
the generic problem definition shown in table 123 summarizes the class of generalization problems considered in this paper .
table 123 illustrates a particular in - stance of an explanation - based generalization problem from this class .
as indicated by these tables , defining an explanation - based learning problem involves specifying four kinds of information :
the goal concept defines the concept to be acquired .
for instance , in the problem defined in table 123 the task is to learn to recognize pairs of objects <x , y> such that it is safe to stack x on top of y .
notice that the goal concept
table 123
the explanation - based generalization problem
goal concept : a concept definition describing the concept to be learned .
( it is assumed that this
concept definition fails to satisfy the operationality criterion . )
training example : an example of the goal concept .
domain theory : a set of rules and facts to be used in explaining how the training example is an
example of the goal concept .
operationality criterion : a predicate over concept definitions , specifying the form in which the
learned concept definition must be expressed .
a generalization of the training example that is a sufficient concept definition for the goal concept
and that satisfies the operationality criterion .
123 in fact , we use the term generalization in this paper both as a noun ( to refer to a general concept defini -
tion ) , and as a verb ( to refer to the process of deriving this generalization ) .
table 123
the safe - to - stack generalization problem after borgida et al .
( 123 )
goal concept : pairs of objects <x , y> such that safe - to - stack ( x , y ) , where
safe - to - stack ( x , y ) not ( fragile ( y ) ) v lighter ( x , y ) .
on ( obj 123 , obj123 ) isa ( obj 123 , box ) isa ( obj123 , endtable ) color ( obj123 , red ) color ( obj123 , blue ) volume ( obj 123 , 123 ) density ( obj 123 , . 123 )
volume ( p123 , vl ) a density ( p123 , dl ) - > weight ( p123 , vl*dl ) weight ( p123 , wl ) a weight ( p123 , w123 ) a less ( wl , w123 ) - > lighter ( p123 , p123 ) isa ( p123 , endtable ) - weight ( p123 , 123 ) ( default )
operationality criterion : the concept definition must be expressed in terms of the predicates used to describe examples ( e . g . , volume , color , density ) or other selected , easily evaluated , predicates from the domain theory ( e . g . , less ) .
a generalization of training example that is a sufficient concept definition for the goal concept and
that satisfies the operationality criterion .
here , safe - to - stack , is defined in terms of the predicates fragile and lighter , whereas the training example is defined in terms of other pred - icates ( i . e . , color , density , volume , etc . ) .
the training example is a positive example of the goal concept .
for instance , the training example of table 123 describes a pair of objects , a box and an end - table , where one is safely stacked on the other .
the domain theory includes a set of rules and facts that allow explaining how training examples are members of the goal concept .
for instance , the domain theory for this problem includes definitions of fragile and lighter , rules for inferring features like the weight of an object from its density and volume , rules that suggest default values such as the weight of an endtable , and facts such as ' . 123 is less than 123 ' .
the operationality criterion defines the terms in which the output concept definition must be expressed .
our use of this term is based on mostow ' s ( 123 ) definition that a procedure is operational relative to a given agent and task , provided that the procedure can be applied by the agent to solve the task .
similarly , we assume that the learned concept definition will be used by some agent to perform some task , and must be defined in terms operational for
mitchell , r . m .
keller and s . t .
kedar - cabelli
that agent and task .
for this problem , the operationality criterion requires that the final concept definition be described in terms of the predicates used to describe the training example ( e . g . , color , volume , density ) or in terms of a selected set of easily evaluated predicates from the domain theory ( e . g . , less ) .
reexpressing the goal concept in these terms will make it opera - tional with respect to the task of efficiently recognizing examples of the
given these four inputs , the task is to determine a generalization of the training example that is a sufficient concept definition for the goal concept and that satisfies the operationality criterion .
note that the notion of operationality is crucial for explanation - based generalization : if the operationality criterion were not specified , the input goal concept definition could always be a correct output concept definition and there would be nothing to learn ! the operationality criterion imposes a require - ment that learned concept definitions must be not only correct , but also in a usable form before learning is complete .
this additional requirement is based on the view - point that concept definitions are not learned as theoretical entities , but rather as practical entities to be used by a particular agent for a particular task .
123 the ebg method
the ebg method , which is designed to address the above class of problems , is de - fined as follows :
the ebg method 123
explain : construct an explanation in terms of the domain theory that proves how
the training example satisfies the goal concept definition .
this explanation must be constructed so that each branch of the explana - tion structure terminates in an expression that satisfies the operationality
generalize : determine a set of sufficient conditions under which the explanation
structure holds , stated in terms that satisfy the operationality criterion .
this is accomplished by regressing the goal concept through the explanation structure .
the conjunction of the resulting regressed expressions constitutes the desired concept definition .
to see more concretely how the ebg method works , consider again the problem of learning the concept safe - to - stack ( x , y ) .
the bottom of figure 123 shows a training example for this problem , described in terms of a semantic network of ob - jects and relations .
in particular , the example consists of two physical objects , obj 123
figure 123
explanation of safe - to - stack ( obj123 , obj123 ) .
and obj123 , in which obj123 is on obj123 , and for which several features of the objects are described ( e . g . , their owners , colors ) .
given this training example , the task is to determine which of its features are rele - vant to characterizing the goal concept , and which are irrelevant .
to this end , the first step of the ebg method is to construct an explanation of how the training exam - ple satisfies the goal concept .
notice that the explanation constitutes a proof , and constructing such an explanation therefore may involve in general the complexities of theorem proving .
the explanation for the training example depicted in the lower
mitchell , r . m .
keller and s . t .
kedar - cabelli
portion of figure 123 is given in the top portion of the figure .
as shown there , the pair of objects <obj123 , obj123> satisfies the goal concept safe - to - stack because obj123 is lighter than obj123
furthermore , this is known because the weights of obj123 and obj123 can be inferred .
for obj123 , the weight is inferred from its density and volume , whereas for obj123 the weight is inferred based on a rule that specifies the default weight of endtables in general .
through this chain of inferences , the explanation structure demonstrates how obj123 and obj123 satisfy the goal concept definition .
note that the explanation struc - ture has been constructed so that each of its branches terminates in an expression that satisfies the operationality criterion ( e . g . , volume ( obj123 , 123 ) , less ( . l , 123 ) ) .
in this way , the explanation structure singles out those features of the training example that are relevant to satisfying the goal concept , and that provide the basis for constructing a justified generalization of the training example .
for the current example , these rele - vant training example features are shown shaded over in the figure , and correspond to the conjunction volume ( obj123 , 123 ) a density ( obj123 , 123 ) a isa ( obj123 ,
whereas the first step of the ebg method isolates the relevant features of the train - ing example , it does not determine the desired generalized constraints on feature values .
for instance , while the feature volume ( obj123 , 123 ) is relevant to explaining how the present training example satisfies the goal concept , the general constraint on acceptable values for volume is yet to be determined .
the second step of the ebg method therefore generalizes on those feature values selected by the first step , by determining sufficient conditions on these feature values that allow each step in the explanation structure to carry through .
in order to determine general sufficient conditions under which the explanation holds , the second step of the ebg method involves regressing ( back propagating ) the goal concept step by step back through the explanation structure .
in general , regress - ing a given formula f through a rule r is a mechanism for determining the necessary and sufficient ( weakest ) conditions under which that rule r can be used to infer f .
we employ a slightly modified version of the goal - regression algorithm described by waldinger ( 123 ) and nilsson ( 123 ) . 123 our modified goal regression algorithm computes an expression that represents only a sufficient condition ( rather than necessary and sufficient conditions ) under which rule r can be used to infer formula f , but that corresponds closely to the training example under consideration .
in par - ticular , whereas the general goal regression algorithm considers all possible variable bindings ( unifications ) under which r can infer f , our modified algorithm considers only the specific variable bindings used in the explanation of the training example .
furthermore , if the rule r contains a disjunctive antecedent ( left - hand side ) , then our
123 dijkstra ( 123 ) introduces the related notion of weakest preconditions in the context of proving program correctness .
the weakest preconditions of a program characterize the set of all initial states of that program such that activation guarantees a final state satisfying some postcondition .
figure 123
generalizing from the explanation of safe - to - stack ( obj123 , obj123 ) .
( underlined expres - sions are the results of regressing the goal concept . )
algorithm considers only the particular disjuncts satisfied by the training example .
figure 123 illustrates the second step of the ebg method in the context of the safe - to - stack example .
in the first ( topmost ) step of this figure , the goal concept ex - pression safe - to - stack ( x , y ) is regressed through the rule lighter ( pi , p123 ) - safe - to - stack ( p123 , p123 ) , 123 to determine that lighter ( x , y ) is a sufficient condition for inferring safe - to - stack ( x , y ) .
similarly , regressing lighter ( x , y ) through the next step in the explanation structure yields the expression weight ( x , wl ) a weight ( y , w123 ) a less ( wl , w123 ) .
this expression is in turn regressed through the final steps of the explanation structure to yield the operational definition for safe - to - stack ( x , y ) .
to illustrate the goal regression process in greater detail , consider the final step of figure 123 in which the expression weight ( x , wl ) a weight ( y , w123 ) a less ( wl , w123 ) is regressed through the final steps of the explanation structure .
each conjunct of the expression is regressed separately through the appropriate rule , in the follow - ing way .
the conjunct is unified ( matched ) with the consequent ( right - hand side ) of
123 notice that the definition of safe - to - stack given in table 123 is a disjunctive definition .
as noted above , the procedure considers only the disjunct that is satisfied by the current training example ( e . g . , the disjunct involving the lighter predicate ) .
mitchell , r . m .
keller and s . t .
kedar - cabelli
the rule to yield some set of substitutions ( particular variable bindings ) .
the substitu - tion consistent with the example is then applied to the antecedent ( left - hand side ) of the rule to yield the resulting regressed expression . 123 any conjuncts of the original expression which cannot be unified with the consequent of any rule are simply added to the resulting regressed expression ( with the substitutions applied to them ) .
as il - lustrated in the figure , regressing the conjunct weight ( x , wl ) through the rule volume ( p123 , vl ) a density ( p123 , dl ) - weight ( p123 , vl*dl ) therefore yields volume ( x , vl ) a density ( x , dl ) .
regressing the conjunct weight ( y , w123 ) through the rule isa ( p123 , endtable ) - > weight ( p123 , 123 ) yields isa ( y , end - table ) .
finally , since no rule consequent can be unified with the conjunct less ( wl , w123 ) , this conjunct is simply added to the resulting regressed expression after applying the substitutions produced by regressing the other conjuncts .
in this case these substitutions are ( x / pl , vl*dl / wl , y / p123 , 123 / w123 ) , which yield the third conjunct less ( vl*dl , 123 ) .
the final , operational definition for safe - to - stack ( x , y ) is
volume ( x , vl ) a density ( x , dl ) a less ( vl*dl , 123 ) a isa ( y , endtable )
- safe - to - stack ( x , y )
this expression characterizes in operational terms the features of the training ex - ample that are sufficient for the explanation structure to carry through in general .
as such , it represents a justified generalization of the training example , for which the explanation structure serves as a justification .
several general points regarding the ebg method are illustrated in the above exam - ple .
the main point of the above example is that the ebg method produces a justified generalization from a single training example in a two - step process .
the first step creates an explanation that separates the relevant feature values in the examples from the irrelevant ones .
the second step analyzes this explanation to determine the par - ticular constraints on these feature values that are sufficient for the explanation structure to apply in general .
thus , explanation - based methods such as ebg over - come the main limitation of similarity - based methods : their inability to produce justified generalizations .
this is accomplished by assuming that the learner has available knowledge of the domain , the goal concept , and the operationality
123 it is correctly observed in dejong ( 123 ) that the substitution list used to regress expressions through previous steps in the explanation must be applied to the current expression before the next regression step .
criterion , whereas similarity - based generalization does not rely on any of these
a second point illustrated by the above example is that the language in which the final concept definition is stated can be quite rich .
notice in the above example that the final generalization includes a constraint that the product of the density and volume of x must be less than 123
there are very many such relations among the parts of the training example that might be considered during generalization ( e . g . , why not consider the fact that the owners of the two objects are of different sex ? ) .
the interesting point here is that the appropriate constraint was derived directly by analyzing the explanation , without considering the universe of possible relations among parts of the training example .
this is in marked contrast with similarity - based generalization methods ( e . g .
michalski , 123; quinlan , 123 ) .
such methods are typically based on a heuristic focusing criterion , such as the heuristic that ' less complex features are preferred over more complex features for character - izing concepts ' .
therefore , before such methods will consider the feature less ( vl*dl , 123 ) as a plausible basis for generalization , they must first consider vast numbers of syntactically simpler , irrelevant features .
a final point illustrated by this example is that the final concept definition pro - duced by ebg is typically a specialization of the goal concept rather than a direct reexpression of the concept .
this is largely due to the fact that the explanation struc - ture is created for the given training example , and does not explain every possible example of the goal concept .
thus , the generalization produced from analyzing this explanation will only cover examples for which the explanation holds .
furthermore , because the modified goal regression algorithm computes only sufficient ( not necessary and sufficient ) conditions under which the explanation holds , it leads to a further specialization of the concept .
this limitation of explanation - based generalization suggests an interesting problem for further research : developing explanation - based methods that can utilize multiple training examples ( see the discus - sion in section 123 ) .
other examples and variations
this section discusses two additional examples of explanation - based generalization that have previously been reported in the literature .
the first is winston , binford , katz , and lowry ' s ( 123 ) research on learning structural definitions of concepts such as ' cup ' from their functional definitions .
the second is mitchell , keller , and utgoff ' s ( 123 ) research on learning search heuristics from examples ( see also utgoff , 123; keller , 123 ) .
a common perspective on these two systems is provided by instantiating the ebg method for both problems .
differences among the two original approaches and the ebg method are also considered , in order to underscore some subtleties of the ebg method , and to suggest some possible variations .
mitchell , r . m .
keller and s . t .
kedar - cabelli
123 an example : learning the concept cup
in this subsection we first summarize the application of the ebg method to a second example of an explanation - based generalization problem : the cup generalization problem , patterned after the work of winston et al .
( 123 ) .
we then discuss the rela - tionship between the ebg method and the analogy program of winston et al . , which addresses this same problem .
the cup generalization problem , defined in table 123 , involves learning a structural definition of a cup from its functional definition .
in particular , the goal concept here is the concept cup , defined as the class of objects that are open - vessels , lift - able , and stable .
the domain theory includes rules that relate these properties to the more primitive structural properties of physical objects , such as flat , han - dle , etc .
the operationality criterion requires that the output concept definition be useful for the task of visually recognizing examples of cups .
it thus requires that the output concept definition be expressed in terms of its structural features .
figure 123 illustrates a training example describing a particular cup , obj123 , along with the explanation that shows how obj123 satisfies the goal concept cup .
in par - ticular , the explanation indicates how obj123 is liftable , stable , and an open - vessel .
as in the safe - to - stack example , this explanation distinguishes the relevant features of the training example ( e . g . , its lightness ) from irrelevant features ( e . g . , its color ) .
the second step of the ebg method , regressing the goal concept through the explanation structure , results in the following general definition of the cup concept :
( part - of ( x , xc ) a isa ( xc , concavity ) a is ( xc , upward - pointing ) a part - of ( x , xb ) a isa ( xb , bottom ) a is ( xb , flat ) a part - of ( x , xh ) a isa ( xh , handle ) a is ( x , light ) ) - cup ( x )
table 123the cup generalization problem after winston et al .
( 123 )
goal concept : class of objects , x , such that cup ( x ) , where
cup ( x ) * liftable ( x )
part - of ( obj123 , concavity - 123 )
is ( x , light ) a part - of ( x , y ) a isa ( y , handle ) - > liftable ( x ) part - of ( x , y ) a isa ( y , bottom ) a is ( y , flat ) - stable ( x ) part - of ( x , y ) a isa ( y , concavity ) a is ( y , upward - pointing - open - vessel ( x )
operationality criterion : concept definition must be expressed in terms of structural features used
in describing examples ( e . g . , light , handle , flat , etc . ) .
a generalization of training example that is a sufficient concept definition for the goal concept and
that satisfies the operationality criterion .
figure 123
explanation of cup ( obj123 ) .
mitchell , r . m .
keller and s . t .
kedar - cabelli
as in the first example , the ebg method is able to produce a valid generalization from a single training example , by explaining and analyzing how the training example satisfies the definition of the goal concept .
notice that the regression step in this example is quite straightforward , and leads to generalizing the training example features effectively by replacing constants with variables ( i . e . , replacing obj123 by x ) .
it is interesting that several earlier attempts at explanation - based generalization ( e . g . , mitchell , 123 ) involved the assumption that the explanation could always be generalized simply by replacing constants by variables in the explanation , without the need to regress the goal concept through the explanation structure . 123 as the earlier safe - to - stack example illustrates , this is not the case .
in general , one must regress the goal concept through the explanation structure to ensure a valid general - ization of the training example ( which may involve composing terms from different parts of the explanation , requiring constants where no generalization is possible , and
several interesting features of this example come to light when the ebg method is compared to the method used in winston et al . ' s ( 123 ) analogy program , upon which this example problem is based .
the most striking difference between the two methods is that although analogy does construct an explanation , and also uses this explanation to generalize from a single example , the system has no domain theory of the kind used in the above example .
instead , winston ' s program constructs its explanations by drawing analogies between the training example and a library of precedent cases ( e . g . , annotated descriptions of example suitcases , bricks , bowls , etc . ) .
for example , analogy explains that the flat bottom of obj123 allows obj 123 to be stable , by drawing an analogy to a stored description of a brick which has been annotated with the assertion that its flat bottom ' causes ' it to be stable .
similarly , it relies on an annotated example of a suitcase to explain by analogy why a handle allows obj123 to be liftable .
in general , the precedents used by analogy are assumed to be annotated by links that indicate which features of the precedent account for which of its properties .
thus , for the analogy program , the causal links distributed over the library of precedents constitute its domain theory .
however , this theory is qualitatively dif - ferent than the domain theory used in the cup example above : it is described by ex - tension rather than intention ( i . e . , by examples rather than by general rules ) , and is therefore a weaker domain theory .
because analogy ' s knowledge about causality is summarized by a collection of instances of causal relations rather than by general rules of causality , its theory cannot lead deductively to assertions about new causal
this observation is due in part to sridhar mahadevan .
because its domain theory is weak , the analogy system raises some interesting questions about explanation - based generalization .
whereas the safe - to - stack and cup examples above show how a sufficient set of domain theory rules can pro - vide powerful guidance for generalization , analogy suggests how a weaker , ex - tensional theory might be used to focus the generalization process in a weaker fashion .
in particular , the causal links are used by analogy to construct a plausi - ble explanation , but not a proof , that the training example satisfies the goal concept definition .
as discussed above , such plausible explanations can guide generalization by focusing on plausibly relevant features of the training example .
but since analogy lacks general inference rules to characterize the links in this explanation , it cannot perform the second ( goal regression ) step in the ebg method , and therefore has no valid basis for generalizing the explanation .
in fact , the analogy program generalizes anyway , implicitly , assuming that each causal link of the form ( feature ( obj123 ) - > property ( obj123 ) ) is supported by a general rule of the form ( ( vx ) feature ( x ) - property ( x ) ) . 123 thus , analogy represents an important step in considering the use of a weak domain theory to guide generalization , and helps to illuminate a number of open research issues ( see the discussion in section 123 ) .
123 an example : learning a search heuristic
this section presents a third example of an explanation - based generalization problem - this one involving the learning of search heuristics .
this example is based on the problem addressed by the lex program ( mitchell et al . , 123 ) which learns search control heuristics for solving problems in the integral calculus .
in particular , lex begins with a set of legal operators ( transformations ) for solving integrals ( e . g . , in - tegration by parts , moving constants outside the integrand ) .
for each such operator , the system learns a heuristic that summarizes the class of integrals ( problem states ) for which it is useful to apply that operator .
for example , one typical heuristic learned by the lex system is :
if the integral is of the form j <polynomial ' - / / ? >< then apply integration - by - parts
thus , for each of its given operators , lex faces a generalization problem : learning the class of integrals for which that operator is useful in reaching a solution .
table 123 defines the generalization problem that corresponds to learning when it is useful to apply op123 ( moving constants outside the integrand ) .
here the goal concept useful - op123 ( x ) describes the class of problem states ( integrals ) for which op123 will
123 winston ' s ( 123 ) own work on building rule censors can be viewed as an attempt to address difficulties
that arise from this implicit assumption .
mitchell , r . m .
keller and s . t .
kedar - cabelli
table 123
the search heuristic generalization problem after mitchell et at .
( 123 )
goal concept : the class of integral expressions that can be solved by first applying operator op123 ( removing a constant from the integrand ) ; that is , the class of integrals , x , such that useful - op123
useful - op123 ( x ) not ( solved ( x ) ) a solvable ( op123 ( x ) )
op123 : f r <any - fn>dx
- > r f <any - fn>dx .
training example : f 123x 123dx
solvable ( x ) ( 123op ) ( solved ( op ( x ) ) v solvable ( op ( x ) ) ) matches ( x , ' f <any - fn>dx ' ) - not ( solved ( x ) ) matches ( x , ' <any - fn> ' ) - solved ( x ) matches ( op ( x ) , y ) matches ( x , regress ( y , op ) )
operationality criterion : concept definition must be expressed in a form that uses easily - com - features such as <polynomial - fn> ,
the problem state , x , ( e . g . ,
putable features of < transcendental - fn > , <any - fn> , r , k ) .
a generalization of training example that is a sufficient concept definition of the goal concept and
that satisfies the operationality criterion .
be useful .
this is defined to be the class of problem states that are not already solved ( i . e . , algebraic expressions that contain an integral sign ) , and for which applying op123 leads to a solvable problem state .
the domain theory in this case contains rules that relate solved and solvable to observable features of prob - lem states ( e . g . , one rule states that if problem state x matches the expression | < any ~ fn > dx , then x is not a solved state . ) .
notice that some of the domain theory rules constitute knowledge about search and problem solving in general ( e . g . , the definition of solvable ) , while other rules represent knowledge specific to in - tegral calculus ( e . g . , that the absence of an integral sign denotes a solved state ) .
the operationality condition in this problem requires that the final concept definition be stated in terms of easily - computable features of the given problem state .
this re - quirement assures that the final concept definition will be in a form that permits its effective use as a search control heuristic . 123 for the lex program , the set of easily - computable features is described by a well - defined generalization language over problem states that includes features ( e . g . , < trigonometric - fn > , < real - constant > ) which lex can efficiently recognize using its matches predicate .
123 if the concept definition were permitted to include features that are difficult to compute ( e . g . , solvable ) , then the resulting heuristic would be so expensive to evaluate that its use would degrade , rather than improve , the problem solver ' s performance .
figure 123 , explanation of useful - op123 ( j 123x 123dx ) .
a training example for the goal concept useful - op123 is shown in the bottom por - tion of figure 123
in particular , the problem state j 123x123 dx constitutes a training exam - ple of a problem state for which application of op123 is useful .
the training example described in the figure is shown along with the other problem states involved in its
the explanation of useful - op123 ( j 123x 123dx ) is shown in the top portion of figure 123
the left - hand branch of this explanation structure leads to a node which asserts that useful - op123 is satisfied in part because the training example state is not already a solved state .
the right - hand branch of the explanation structure ex - plains that applying op123 to the example state leads to a solvable problem state .
mitchell , r . m .
keller and s . t .
kedar - cabelli
this is in turn explained by indicating that applying op123 to the resulting state pro - duces a solved problem , as evidenced by the fact that the resulting state matches the expression ' <any - fn> ' ( i . e . , that it contains no integral sign ) .
thus , up to this point ( marked as ( a ) in the figure ) , each step in the right - hand branch of the explanation structure corresponds to some step along the solution path of the
by point ( a ) , the explanation has indicated that one relevant feature of the training example state is that the result of applying op123 followed by op123 , is a state that matches ' <any - fn> ' .
the operationality criterion requires , however , that the explanation be in terms of features of the single given training example state , rather than features of its resulting solution state .
thus , the remainder of the explanation consists of reexpressing this constraint in terms of the training example state .
this is accomplished by applying the last rule in the domain theory of table 123
this rule " allows back propagating the expression ' <any - fn> ' through the general defini - tions of op123 and op123 , to determine the equivalent constraint on the training example state .
the resulting constraint is that the training example state must match the expression ' <any - fn> f r123 - x r123 - 123 d x ' ( here r123 and r123 stand for two distinct real numbers , where r123 must not be equal to - 123 ) .
this together with the left - hand branch of the explanation structure , explains which features of f 123x123dx guarantee that it satisfies the goal concept useful - op123
given this explanation structure , the second step of the ebg method is straight - forward .
as in the cup example , regressing the goal concept expression useful - op123 ( x ) through the explanation structure effectively results in replacing the training example state by a variable , so that the resulting generalization ( taken from the leaves of the explanation tree ) is :
which simplifies to :
123 the domain theory rule matches ( op ( x ) , y ) matches ( x , regress ( y , op ) ) indicates that if the result of applying operator op to state x matches some expression y , then the state x matches some expression which can be computed by regressing the expression y through operator op .
notice that the regression here involves propagating constraints on problem states through problem solving operators .
this is a different regression step from the second step of the ebg process , in which the goal concept is regressed through the domain theory rules used in the explanation structure .
to summarize , this example demonstrates again the general ebg method of con - structing an explanation in terms that satisfy the operationality condition , then regressing the goal concept through the explanation structure to determine a justified generalization of the training example .
as in the previous examples , this process results in a generalization of the training example which is a sufficient condition for satisfying the goal concept , and which is justified in terms of the goal concept , domain theory , and operationality criterion .
in the above example , the goal concept corresponds to the precondition for a search heuristic that is to be learned .
the domain theory therefore involves both domain - independent knowledge about search ( e . g . , the definition of solvable ) and domain - dependent knowledge ( e . g . , how to recognize a solved integral ) .
to use this method to learn heuristics in a new domain , one would have to replace only the domain - dependent portion of the theory .
to learn a different type of heuristic in the same domain , one could leave the domain theory intact , changing only the definition of the useful - op123 goal concept accordingly .
for example , as suggested in mitchell ( 123 ) , the system could be modified to learn heuristics that suggest only steps along the minimum cost solution path , by changing the goal concept to
useful - op123 ( s ) not ( solved ( s ) > a
min - cost - soln ( solution - path ( op123 , s ) )
note that the explanation structure in this example , like the domain theory , separates into a domain - independent and a domain - dependent portion .
domain - independent knowledge about search is applied above point ( a ) in figure 123 , and domain - dependent knowledge about calculus problem solving operators is applied below point ( a ) .
in the implementation of the lex123 program ( mitchell , 123 ) , these two phases of the explanation were considered to be two unrelated subprocesses and were implemented as separate procedures .
from the perspective afforded by the ebg method , however , these two subprocesses are better seen as different portions of the same explanation - generation step .
one final point regarding the current example has to do with the ability of explanation - based methods to augment their description language of concepts .
in lex123 , as in the safe - to - stack problem , this method is able to isolate fairly com - plex features of the training example that are directly related to the explanation of how it satisfies the goal concept .
in the context of the lex project , utgoff ( 123 ) studied this issue and developed the stabb subsystem .
stabb is able to extend the initial vocabulary of terms used by lex , by naming and assimilating terms that cor - respond to the constraints derived during the regression step .
for example , in one instance stabb derived the definition of odd integers through this regression step , defining it as ' the set of real numbers , x , such that subtracting 123 then dividing by 123 produces an integer ' .
mitchell , r . m .
keller and s . t .
kedar - cabelli
123 . 123 related methods for strategy learning
there are a number of additional systems that learn problem solving strategies by analyzing single examples of successful solutions . 123 these systems ( e . g .
fikes et al . , 123; utgoff , 123; minton , 123; mahadevan , 123 ) , which we might call strips - like systems , can all be viewed as systems that learn a goal concept of the following form : ' the set of problem states such that applying a given operator sequence , os , yields a final state matching a given solution property , p . ' since these systems are tuned to this single goal concept , and are not intended to learn other forms of con - cepts , they typically do not represent the goal concept and explanation declaratively .
however , they do represent the solution property , p , explicitly , and regress this prop - erty through the operator sequence os to determine an operational definition of the ( implicit ) goal concept .
from the perspective of the above lex example , the steps that they perform correspond to constructing the portion of the explanation below point ( a ) in figure 123
it is in constructing these steps of the explanation that lex regresses its solution property ' matches ( x , <any - fn> ) ' through the operator sequence < op123 , op123 > to determine the equivalent constraint on the initial problem state .
these strips - like systems do not construct the portion of the explanation cor - responding to the section above point ( a ) in figure 123
because they are tuned to a fixed goal concept , they do not need to generate this portion of the explanation explicitly for each training example .
to illustrate this point , consider minton ' s ( 123 ) program for learning search heuristics in two - person games such as go - moku , tic - tac - toe , and chess .
this program analyzes one positive instance of a sequence of moves that leads to a winning board position , in order to determine an operational definition of the goal concept ' the class of board positions for which the given sequence of moves leads to a forced win ' .
but minton ' s system has no explicit definition of this goal concept .
it has only a definition of the solution property p that characterizes a winning posi - tion .
for example , in the game of go - moku , ( a variant of tic - tac - toe ) this solution property characterizes a winning board position as ' a board position with five x ' s in a row ' .
this solution property is regressed by minton ' s program through the operator sequence for the given training example .
in this way , the program deter - mines that an effective definition of its implicit goal concept is ' board positions that contain three x ' s , with a blank space on one side , and two blank spaces on the other ' .
123 see kibler and porter ( 123 ) for a thoughtful critique of analytic goal regression methods for learning search control heuristics .
they discuss certain requirements for regression to succeed : that the operators be invertible , and that the representation language be able to express goal regression products .
perspective and research issues
the previous sections presented a general method for explanation - based generaliza - tion , and illustrated its application to several generalization tasks .
this section sum - marizes some general points regarding explanation - based generalization , and con - siders a number of outstanding research issues .
to summarize , explanation - based generalization utilizes a domain theory and knowledge of the goal concept to guide the generalization process .
by doing so , the method is able to produce a valid generalization of the training example , along with an explanation that serves as a justification for the generalization .
the ebg method introduced here unifies mechanisms for explanation - based generalization that have been previously reported for a variety of task domains .
the generality of the ebg method stems from the fact that the goal concept , domain theory , and operationality criterion are made explicit inputs to the method , rather than instantiated implicitly within the method .
123 perspectives on explanation - based generalization
several perspectives on explanation - based generalization , and on the ebg method in particular , are useful in understanding their strengths and weaknesses :
ebg as theory - guided generalization of training examples .
ebg can be seen as the process of interpreting or perceiving a given training example as a member of the goal concept , based on a theory of the domain .
soloway ' s ( 123 ) early work on learning action sequences in the game of baseball shares this viewpoint on generalization .
this is the perspective stressed in the above sections , and it highlights the centrality of the goal concept and domain theory .
it also highlights an important feature of ebg : that learning depends strongly on what the learner already knows .
one consequence of this is that the degree of generalization produced for a particular training example will depend strongly on the generality with which the rules in the domain theory are expressed .
a second consequence is that the learning system can improve its learning performance to the degree that it can learn new rules for its domain theory .
ebg as example - guided operationalization of the goal concept .
one can also view ebg as the process of reformulating the goal concept in terms that satisfy the opera - tionality criterion , with the domain theory providing the means for reexpressing the goal concept .
given this perspective , one wonders why training examples are re - quired at all .
in principle , they are not .
mostow ' s ( 123 ) foo system operationalizes general advice about how to play the card game of hearts , without considering specific examples that apply that advice .
similarly , keller ( 123 ) describes a process of concept operationalization , by which a sequence of transformations is applied to
mitchell , r . m .
keller and s . t .
kedar - cabell123
the goal concept in search of a reformulation that satisfies the operationality criterion , without the guidance of specific training examples .
however , training examples can be critical in guiding the learner to consider rele - vant transformations of the goal concept .
for instance , consider the cup learning task as described in section 123 , where a functional definition of cup is reexpressed in structural terms for use by a vision system recognizing cups .
a system that refor - mulates the functional definition of cup in structural terms , without the guidance of training examples , amounts to a system for producing all possible structural definitions for classes of cups ( i . e . , for designing all possible classes of cups ) .
since there are so many possible designs for cups , and since so few of these are actually encountered in the world , the learning system could easily waste its effort learning structural definitions corresponding to cups that will never be seen by the vision system ! 123 training examples thus provide a means of focusing the learner on for - mulating only concept descriptions that are relevant to the environment in which it
ebg as reformulating / operationalizing / deducing from what is already known .
the above paragraph suggests that explanation - based generalization does not lead to acquiring truly ' new ' knowledge , but only enables the learner to reformulate / operationalize / deduce what the learner already knows implicitly .
while this state - ment is true , it is somewhat misleading .
consider , for example , the task of learning to play chess .
once one is told the rules of the game ( e . g . , the legal moves , and how to recognize a checkmate ) , one knows in principle everything there is to know about chess - even the optimal strategy for playing chess follows deductively from the rules of the game .
thus , although the ebg method is restricted to compiling the deductive consequences of its existing domain theory , this kind of learning is often nontrivial ( as is the case for learning chess strategies ) .
nevertheless , it is a significant limitation that ebg is highly dependent upon its domain theory .
as discussed below , further research is needed to extend the method to generalization tasks in which the domain theory is not sufficient to deductively infer the desired concept .
123 , 123 research issues
123 . 123 imperfect theory problems
as the above discussion points out , one important assumption of ebg is that the
123 of course information about what types of cups are to be encountered by the vision system also could be presented in the operationality criterion , since this information relates to the use of the concept defini - tion for the recognition task .
this information , however , may not be easily described in the declarative form required by the operationality criterion .
domain theory is sufficient to prove that the training example is a member of the goal concept; that is , that the inferred generalizations follow deductively ( even if remote - ly ) from what the learner already knows .
although this assumption is satisfied in each of the example problems presented above , and although there are interesting do - mains in which this assumption is satisfied ( e . g . , chess , circuit design ( mitchell et al . , 123 ) ) , for the majority of real - world learning tasks it is unrealistic to assume that the learner begins with such a strong theory .
for both the safe - to - stack domain and the cup domain , it is easy to imagine more realistic examples for which the re - quired domain theory is extremely complex , difficult to describe , or simply unknown .
for generalization problems such as inferring general rules for predicting the stock market or the weather , it is clear that available theories of economics and meteorology are insufficient to produce absolutely predictive rules .
thus , a major research issue for explanation - based generalization is to develop methods that utilize imperfect domain theories to guide generalization , as well as methods for improving imperfect theories as learning proceeds .
the problem of dealing with imperfect theories can be broken down into several classes of problems :
the incomplete theory problem .
the stock market and weather prediction examples above both illustrate the incomplete theory problem .
the issue here is that such theories are not complete enough to prove that the training example is a member of the goal concept ( e . g . , to prove why a particular training example stock has doubled over a twelve month period ) .
however , even an incomplete theory might allow con - structing plausible explanations summarizing likely links between features of the training example and the goal concept .
for example , even a weak theory of economics allows one to suggest that the ' cash on hand ' of the company may be rele - vant to the goal concept ' stocks that double over a twelve month period ' , whereas the ' middle initial of the company president ' is probably an irrelevant feature .
thus , incomplete theories that contain only information about plausible cause - effect rela - tions , with only qualitative rather than quantitative associations , can still provide im - portant guidance in generalizing .
methods for utilizing and refining such incomplete theories would constitute a major step forward in understanding explanation - based
the intractable theory problem .
a second class of imperfect theories includes those which are complete , but for which it is computationally prohibitive to construct ex - planations in terms of the theory .
for instance , quantum physics constitutes a fairly complete theory that would be inappropriate for generating explanations in the safe - to - stack problem - generating the necessary explanations in terms of quantum physics is clearly intractable .
similarly , although the rules of chess con - stitute a domain theory sufficient to explain why any given move is good or bad , one would never use this theory to explain why the opening move ' pawn to king four ' is a member of the goal concept ' moves that lead to a win or draw for white ' .
in fact ,
mitchell , r . m .
keller and s . t .
kedar - cabelli
this theory of chess is intractable for explaining why nearly any move is good or bad .
humans tend to respond to this problem by constructing more abstract , tractable theories that are approximations to the underlying intractable theory .
in chess , for example , the learner might formulate a more abstract theory that includes approx - imate assertions such as ' there is no threat to the king if it is surrounded by many friendly pieces ' ( tadepalli , 123 ) .
such approximate , abstracted theories can be trac - table enough and accurate enough to serve as a useful basis for creating and learning from explanations .
developing computer methods that can construct such abstracted theories , and that can judge when they can safely be applied , is a problem for further
the inconsistent theory problem .
a third difficulty arises in theories from which inconsistent statements can be derived .
the domain theory in the safe - to - stack problem provides one example of such a theory .
while this theory has a default rule for inferring the weight of an end table , it also has a rule for computing weights from the known density and volume .
thus , the theory will conclude two different weights for a given end table provided that its density and volume are known , and provided that these are inconsistent with the default assumption about its weight .
in such cases , it is possible to construct inconsistent explanations for a single training exam - ple .
furthermore , if two different training examples of the same concept are explained in inconsistent terms ( e . g . , by utilizing one default assumption for one example , and some other assumptions for the second example ) , difficulties will cer - tainly arise in merging the resulting generalizations .
because of this , and because default assumptions are commonplace in theories of many domains , the problem of dealing with inconsistent theories and inconsistent explanations is also an important one for future research .
123 . 123 combining explanation - based and similarity - based methods
while ebg infers concept definitions deductively from a single example , similarity - based methods infer concept definitions inductively from a number of training ex - amples .
it seems clearly desirable to develop combined methods that would utilize both a domain theory and multiple training examples to infer concept definitions .
this kind of combined approach to generalization will probably be essential in do - mains where only imperfect theories are available .
although few results have been achieved in combining explanation - based and similarity - based methods , a number of researchers have begun to consider this issue .
lebowitz ( lebowitz , 123 ) is exploring methods for combining similarity - based methods and explanation - based methods in his unimem system .
unimem ex - amines a database of the voting records of congresspersons , searching for empirical , similarity - based generalizations ( e . g . , mid western congresspersons vote in favor of farm subsidies ) .
the system then attempts to verify these empirical generalizations
by explaining them in terms of a domain theory ( e . g .
explaining how midwestern con - gresspersons satisfy the goal concept ' people who favor farm subsidies ' ) .
this ap - proach has the advantage that the similarity - based techniques can be used to generate a candidate set of possible generalizations from a large number of potentially noisy training examples .
once such empirical generalizations are formulated , explanation - based methods can help prune and refine them by using other knowledge in the
whereas lebowitz ' s approach involves applying similarity - based generalization followed by explanation - based methods , an alternative approach is to first apply explanation - based methods to each training example , then to combine the resulting generalized examples using a similarity - based generalization technique .
consider , for example , using the version space method123 to combine the results of explanation - based generalizations of a number of training examples ( mitchell , 123 ) .
since the explanation - based generalization of a positive training example constitutes a suffi - cient condition for the goal concept , this can be used as a generalized positive exam - ple to refine ( generalize ) the specific boundary set of the version space .
similarly , one could imagine generalizing negative training examples using explanation - based generalization , by explaining why they are not members of the goal concept .
the resulting generalized negative example could then be used to refine ( specialize ) the general boundary set of the version space .
thus , while this combined method still suf - fers the main disadvantage of similarity - based methods ( i . e . , it makes inductive leaps based on its generalization language , which it cannot justify ) , it converges more rapidly on a final concept definition because it employs ebg to generalize each train -
kedar - cabelli ( 123 , 123 ) proposes an alternative method for combining the results of explanation - based generalizations from multiple training examples .
this method , purpose - directed analogy , involves constructing an explanation of one ex - ample by analogy with an explanation of a familiar example , then combining the two explanations to produce a general concept definition based on both .
given explana - tions for two different examples , the proposed system combines the explanations as follows : common portions of the two explanations remain unaltered in the com - bined explanation .
differing portions either become disjunctive subexpressions in the combined explanation , or are generalized to the next more specific common subexpression in the explanation .
for example , given an explanation that a blue , ceramic mug is a cup , and a second example of a white styrofoam cup , the explana - tion of the first example is used to construct by analogy an explanation for the
123 the version space method ( mitchell , 123 ) is a similarity - based generalization method based on sum - marizing the alternative plausible concept definitions by maintaining two sets : the ' specific ' set contains the set of most specific concept definitions consistent with the observed data , and the ' general ' set contains the most general concept definitions consistent with the data .
all other plausible concept definitions lie between these two sets in the general - to - specific ordering over concept definitions .
mitchell , r . m .
keller and s . t .
kedar - cabelli
second example .
the two resulting explanations may differ in how they explain that the two example cups are graspable ( assume the first example cup is graspable because it has a handle , whereas the second is graspable because it is conical ) .
in this case , a generalization of the two explanations would include a disjunction , that either the conical shape , or a handle , makes it graspable .
that , along with the common features of the two objects in the combined explanation structure leads to the generalization that cups include objects which are concave up - ward , have a flat bottom , are light , and have either a conical shape or a handle .
alter - natively , the combined explanation would retain only the next most - specific common subexpression , graspable , which would lead to a slightly more general , yet less operational , definition of a cup .
thus , this method of combining explanations of multiple examples provides a principled method for introducing disjunctions where needed into the common generalization of the two examples .
three methods discussed above for combining similarity - based and explanation - based generalization offer differing advantages .
the first method uses similarity - based generalization to determine empirical generalizations which may then be validated and refined by explanation - based methods .
the second method in - volves employing a similarity - based method to combine the results of explanation - based generalizations from multiple examples .
it suffers the disadvantage that this combination of methods still produces unjustified generalizations .
the third method merges the explanations of multiple examples in order to produce a combined generalization that is justified in terms of the merged explanations .
more research is required on these and other possible methods for employing explanation - based methods when multiple training examples are available .
123 . 123 formulating generalization tasks
the above discussion focuses on research issues within the framework of explanation - based generalization .
an equally important set of research issues has to do with how such methods for generalization will be used as subcomponents of larger systems that improve their performance at some given task .
as our understanding of generalization methods advances , questions about how to construct performance systems that incorporate generalization mechanisms will become increasingly
one key issue to consider in this regard is how generalization tasks are initially for - mulated .
in other words , where do the inputs to the ebg method ( the goal concept , the domain theory , the operationality criterion ) come from ? is it possible to build a system that automatically formulates its own generalization tasks and these inputs ? is it possible to build learning systems that automatically shift their focus of attention from one learning problem to the next as required ? what kind of knowledge must be transmitted between the performance system and the learning system to enable the automatic formulation of generalization tasks ?
again , little work has been devoted to these issues .
the soar system ( laird et al . , 123 , laird et al . , 123 ) is one example of a learning system that formulates its own generalization tasks .
each time that soar encounters and solves a subgoal , it formulates the generalization problem of inferring the general conditions under which it can reuse the solution to this subgoal .
soar then utilizes a technique closely related to explanation - based generalization , called implicit generalization ( laird et al . , 123 ) , to infer these subgoal preconditions .
a second research effort which confronts the problem of formulating learning tasks is keller ' s research on contextual learning ( keller , 123 , 123 , 123 ) .
in this work , keller suggests how a problem solving system could generalization problems such as those addressed by the lex123 system .
in particular , he shows how the task of learning the goal concept useful - op123 arises as a subgoal in the process of planning to improve performance at solving calculus problems .
by reasoning from a top - level goal of improving the efficiency of the problem solver , as well as a declarative description of the problem solving search schema , the method derives the subgoal of introducing a filter to prune the search moves that it considers .
the definition of this filter includes the specification that it is to allow only problem solving steps that are ' useful ' ( i . e . , that lead toward solutions ) .
the subgoal of introducing this filter leads , in turn , to the problem of operationalizing the definition of ' useful ' ( i . e . , to the subgoal corresponding to the lex123 generalization task ) .
recent work by kedar - cabelli ( 123 ) also addresses the problem of formulating learning tasks .
in this work , kedar - cabelli proposes a system to automatically for - mulate definitions of goal concepts in the domain of artifacts .
in particular , the proposed system derives functional definitions of artifacts ( e . g . , cup ) from infor - mation about the purpose for which agents use them ( e . g . , to satisfy their thirst ) .
given two different purposes for which an agent might use a cup ( e . g . , as an orna - ment , versus to satisfy thirst ) , two different functional definitions can be derived . 123 to derive the functional definition of the artifact , the proposed system first computes a plan of actions that leads to satisfying the agent ' s goal .
for example , if the agent ' s goal is to satisfy thirst , then this plan might be to pour the liquids into the cup , grasp the cup with the liquid in order to lift , and finally drink the liquids .
in order to be used as part of this plan , the artifact must satisfy the preconditions of those plan actions in which it is involved .
these preconditions form the functional definition of a cup : an open - vessel , which is stable , graspable , liftable .
thus , for - mulating functional definitions of artifacts is accomplished by analyzing the role that the artifact plays in facilitating the goal of some agent .
123 this extends winston ' s work ( see section 123 ) , in that it can derive its own goal concept from a given
mitchell , r . m .
keller and s . t .
kedar - cabelli
123 . 123 using contextual knowledge to solve the generalization task
above we have discussed some approaches to automatically formulating learning tasks , given knowledge of the performance task for which the learning takes place .
in cases where the learner formulates its own learning task , information about how and why the task was formulated can provide important guidance in solving the learning task .
keller ' s ( 123 ) metalex system provides an example of how such information can be used in guiding learning .
like lex123 , metalex addresses the learning task of operationalizing the goal concept useful - op123
it takes as input a procedural representation of the performance task to be improved ( the calculus problem solver ) , a specification of the performance objectives to be achieved ( ' minimize problem solving time ' ) and knowledge of the performance plan ( search space pruning via filtering ) , which is a record of how the operationaliza - tion task was originally formulated .
metalex uses this additional knowledge about the context in which its learning task was formulated to guide its search for an operational transformation of the goal concept .
specifically , it executes the calculus problem solver using the initial ( and subsequent intermediary ) definitions of the goal concept to collect diagnostic information which aids in operationalizing the goal concept if performance objectives are not satisfied .
in effect , the performance task and performance objective inputs required by metalex elaborate on the operationality criterion required by the ebg method .
instead of evaluating operationality in terms of a binary - valued predicate over con - cept definitions ( as in ebg ) , metalex evaluates the degree of operationality of the concept definition in relation to the performance task and objective .
this ability to make a more sophisticated analysis of operationality enables metalex to make important distinctions among alternative concept definitions .
for example , because metalex uses approximating ( non truth - preserving ) transforms to modify the goal concept , it can generate concept definitions that only approximate the goal con - cept .
in such cases , metalex is able to determine whether such an approximate concept definition is desirable based on the degree to which it helps improve the per -
as the first sections of this paper demonstrate , explanation - based generalization methods offer significant promise in attempts to build computer models of learning systems .
significant progress has been made in understanding explanation - based generalization , especially for problems in which the learner possesses a complete and correct theory .
as the final section illustrates , much more remains to be discovered about how a learner can use what it already knows to guide the acquisition of new
the perspective on explanation - based generalization reported here has arisen from discussions over a period of time with a number of people in the machine learning group at rutgers and elsewhere .
discussions with the following people have been particularly useful in formulating the ideas presented here : alex borgida , gerry dejong , thomas dietterich , thome mccarty , sridhar mahadevan , jack mostow , michael sims , prasad tadepalli , paul utgoff , and keith williamson .
we also thank the following people for providing useful comments on an earlier draft of this paper : pat langley , sridhar mahadevan , jack mostow , louis steinberg , prasad tadepalli , and keith williamson .
this material is based on work supported by the defense advanced research pro - jects agency under research contract n123 - 123 - k - 123 , by the national science foundation under grants dcs123 - 123 and mcs123 - 123 , by the national institutes of health under grant rr - 123 , by gte under grant gte123 , and by a rutgers university graduate fellowship .
the views and conclusions contained in this docu - ment are those of the authors and should not be interpreted as necessarily represent - ing the official views or policies of these sponsors .
the appendix describes dejong ' s research on explanation - based generalization .
in particular , it casts the work on learning schemata for story understanding in terms of the ebg method .
in addition to this project , there has been a great deal of recent research on explanation - based generalization , including ( dejong , 123; ellman , 123; mooney , 123; o ' rorke , 123; rajamoney , 123; schooley , 123; segre , 123; shavlik , 123; sims , 123; watanabe , 123; williamson , 123 ) .
dejong ( 123 , 123 ) developed one of the earliest successful explanation - based generalization systems as part of his research on explanatory schema acquisition .
dejong is interested in the problem of learning schemata for use in natural language story understanding .
dejong ' s system takes as input an example story and produces as output a generalized schema representing the stereotypical action sequence that is instantiated in the story .
for example , the system can process the following story ( adapted from g .
dejong , personal communication , november 123 , 123 ) :
fred is mary ' s father .
fred is rich .
mary wears blue jeans .
john approached mary .
he pointed a gun at her .
he told her to get into his car .
john drove mary to the hotel .
he locked her in his room .
john called fred .
he told fred he had mary .
he promised not to harm her if fred gave him $123 , 123 at treno ' s restaurant .
fred delivered the money .
mary arrived home in a taxi .
mitchell , r . m .
keller and s . t .
kedar - cabelli
it then produces as output a generalized schema for kidnapping .
the kidnapping schema contains only the relevant details of the kidnapping ( e . g . , that three people are involved : person a who wants money , person b who has money and person c who is valued by person b ) , but none of the irrelevant details ( e . g . , that person c wears blue jeans ) .
dejong ' s system uses a generalization method that closely parallels the ebg method .
although there is no direct counterpart to the goal concept in dejong ' s system , the goal concept can be thought of as ' the class of action sequences that achieve personal goal x for actor y . ' for the kidnapping story , the actor ' s personal goal is ' attainment of wealth . ' the system constructs an explanation for how the actions in the story lead to the kidnapper ' s ' attainment of wealth ' as a by - product of the story - understanding process .
during the story parse , data dependency links are created to connect actions in the story with the inference rules that are used by the parser in interpreting the actions .
the set of inference rules constitutes a domain theory for dejong ' s system , and includes knowledge about the goals and plans of human actors , as well as causal knowledge used to set up and verify expectations for future actions .
the network of all the data dependency links created during the story parse is called an inference justification network , and corresponds to an explanation for the action sequence .
generalization of the inference justification network is carried out by replacing general entities for the specific objects and events referenced in the network .
as with the ebg method , the entities in the inference justification network are generalized as far as possible while maintaining the correctness of the data dependency links . 123 then a new schema is constructed from the network .
the issue of operationality enters into the process of determining an appropriate level of generalization for the schema constructed from the network .
should , for example , a generalized schema be created to describe the kidnapping action sequence or the more general action sequences representing bargaining - for - money or bargaining - for - wealth ? all of these schemata explain the actions in the example story .
dejong cites several criteria to use in determining the level of generalization at which to repre - sent the new schema ( dejong , 123 ) .
the criteria include such considerations as : 123 ) will the generalized schema be useful in processing stories in the future , or does the schema summarize an event that is unlikely to recur ? 123 ) are the preconditions for schema activation commonly achievable ? 123 ) will the new schema represent a more efficient method of achieving personal goals than existing schemata ? note that these schema generalization criteria roughly correspond to the operationalization criteria used in the ebg method .
because the generalized schemata are subsequently used for a story - understanding task , the operationality criteria pertain to that task .
123 it is unclear whether the system regresses its equivalent of the goal concept through the inference
table 123
the wealth acquisition schema generalization problem : learning about ways to achieve wealth
* goal concept : the class of action sequences ( i . e . , a general schema ) by which actor x can achieve
wealth - acquisition - action - sequence al , a123 , .
. , an> , x )
not ( wealthy ( x , s123 ) ) a wealthy ( x , execute ( x , <al , a123 , .
. , an> , s123 ) )
<al , a123 , .
, an> is an action sequence; x is the actor; s123 is the actor ' s current state; and exe - cute ( a , b , c ) returns the state resulting from the execution of action sequence b by actor a in state
training example : the kidnapping story :
father - of ( fred , mary ) a wealthy ( fred )
a desperate ( john ) a wears ( mary , blue - jeans ) a approaches ( john , mary , s123 ) a points - gun - at ( john , mary , s123 )
a exchanges ( fred , john , $123 , mary , s123 )
domain theory : rules about human interaction , and knowledge about human goals , intentions ,
father - of ( person 123 , person123 ) - loves ( person 123 , person 123 ) a values ( person 123 , person123 )
wealthy ( person ) - > has ( person , $123 ) exchanges ( person 123 , person123 , object 123 , object123 )
not ( has ( person123 , objectl ) ) a values ( personl , object123 ) a not ( has ( person123 , object123 ) ) a values ( person123 , object123 ) a has ( personl , object123 ) a has ( person123 , objectl )
operationality criterion : acquired generalization ( i . e . , the generalized schema ) must satisfy the re -
quirements for future usefulness in story - understanding ( see text ) .
a generalization of training example ( i . e . , a generalized schema ) that is a sufficient concept defini - tion for the goal concept ( i . e . , that is a specialization of the wealth acquisition schema ) and that satisfies the operationality criterion .
table 123 summarizes the explanation - based generalization problem addressed by
the explanatory schema acquisition research .
