it is often useful to classify email accord - ing to the intent of the sender ( e . g . , " pro - pose a meeting " , " deliver information " ) .
we present experimental results in learn - ing to classify email in this fashion , where each class corresponds to a verb - noun pair taken from a predefined ontol - ogy describing typical email speech acts .
we demonstrate that , although this categorization problem is quite dif - ferent from topical text classification , certain categories of messages can none - theless be detected with high precision ( above 123% ) and reasonable recall ( above 123% ) using existing text - classification learning methods .
this result suggests that useful task - tracking tools could be constructed based on automatic classifi - cation into this taxonomy .
methods which could be used to partially auto - mate this sort of activity tracking .
a hypothetical example of an email assistant that works along these lines is shown in figure 123
do you have any sample scheduling - related email we could use as data ? - steve
sure , ill put some together
fred , can you collect the msgs from the cspace corpora tagged w / the meeting noun , asap ? - bill
assistant announces : new email request , priority
assistant : should i add this new commitment to your to -
assistant : notices outgoing request , may take action if no answer is received promptly .
yes , i can get to that in the next few days .
is next monday ok ? - fred
assistant : notices incoming commitment .
should i send fred a reminder on monday ?
figure 123 - dialog with a hypothetical email assistant that automatically detects email speech acts .
dashed boxes indicate outgoing messages .
( messages have been edited for space and anonymity . )
in this paper we discuss using machine learn - ing methods to classify email according to the intent of the sender .
in particular , we classify emails according to an ontology of verbs ( e . g . , propose , commit , deliver ) and nouns ( e . g . , infor - mation , meeting , task ) , which jointly describe the email speech act intended by the email sender .
a method for accurate classification of email into such categories would have many potential benefits .
for instance , it could be used to help an email user track the status of ongoing joint activi - ties .
delegation and coordination of joint tasks is a time - consuming and error - prone activity , and the cost of errors is high : it is not uncommon that commitments are forgotten , deadlines are missed , and opportunities are wasted because of a failure to properly track , delegate , and prioritize sub - tasks .
the classification methods we consider
123 related work
our research builds on earlier work defining il - locutionary points of speech acts ( searle , 123 ) , and relating such speech acts to email and work - flow tracking ( winograd , 123 , flores & lud - low , 123 , weigant et al , 123 ) .
winograd suggested that research explicating the speech - act based language - action perspective on human communication could be used to build more use - ful tools for coordinating joint activities .
the coordinator ( winograd , 123 ) was one such sys - tem , in which users augmented email messages with additional annotations indicating intent .
while such systems have been useful in lim - ited contexts , they have also been criticized as cumbersome : by forcing users to conform to a particular formal system , they constrain commu - nication and make it less natural ( schoop , 123 ) ; in short , users often prefer unstructured email interactions ( camino et al .
123 ) .
we note that
these difficulties are avoided if messages can be automatically annotated by intent , rather than soliciting a statement of intent from the user .
murakoshi et al .
( 123 ) proposed an email an - notation scheme broadly similar to ours , called a deliberation tree , and an algorithm for con - structing deliberation trees automatically , but their approach was not quantitatively evaluated .
the approach is based on recognizing a set of hand - coded linguistic clues .
a limitation of their approach is that these hand - coded linguistic clues are language - specific ( and in fact limited to japanese text . )
prior research on machine learning for text classification has primarily considered classifica - tion of documents by topic ( lewis , 123; yang , 123 ) , but also has addressed sentiment detection ( pang et al . , 123; weibe et al . , 123 ) and au - thorship attribution ( e . g . , argamon et al , 123 ) .
there has been some previous use of machine learning to classify email messages ( cohen 123; sahami et al . , 123; rennie , 123; segal & kephart , 123 ) .
however , to our knowledge , none of these systems has investigated learning methods for assigning email speech acts .
instead , email is generally classified into folders ( i . e . , ac - cording to topic ) or according to whether or not it is spam .
learning systems have been previ - to automatically detect acts conversational speech ( e . g .
finke et al . , 123 ) .
123 an ontology of email acts
our ontology of nouns and verbs covering some of the possible speech acts associated with emails is summarized in figure 123
we assume that a single email message may contain multiple acts , and that each act is described by a verb - noun pair drawn from this ontology ( e . g . , " deliver data " ) .
the underlined nodes in the figure indicate the nouns and verbs for which we have trained clas - sifiers ( as discussed in subsequent sections ) .
to define the noun and verb ontology of figure 123 , we first examined email from several corpora ( including our own inboxes ) to find regu - larities , and then performed a more detailed analysis of one corpus .
the ontology was further refined in the process of labeling the corpora de -
in refining this ontology , we adopted several principles .
first , we believe that it is more impor -
tant for the ontology to reflect observed linguistic behavior than to reflect any abstract view of the space of possible speech acts .
as a consequence , the taxonomy of verbs contains concepts that are atomic linguistically , but combine several illocu - tionary points .
( for example , the linguistic unit " let ' s do lunch " is both directive , as it requests the receiver , and commissive , as it implicitly com - mits the sender .
in our taxonomy this is a single ' propose ' act . ) also , acts which are abstractly possible but not observed in our data are not rep - resented ( for instance , declarations ) .
figure 123 taxonomy
second , we believe that the taxonomy must re - flect common non - linguistic uses of email , such as the use of email as a mechanism to deliver files .
we have grouped this with the linguistically similar speech act of delivering information .
the verbs in figure 123 are defined as follows .
a request asks ( or orders ) the recipient to per - form some activity .
a question is also considered a request ( for delivery of information ) .
a propose message proposes a joint activity , i . e . , asks the recipient to perform some activity and commits the sender as well , provided the re - cipient agrees to the request .
a typical example is an email suggesting a joint meeting .
an amend message amends an earlier proposal .
like a proposal , the message involves both a commitment and a request .
however , while a proposal is associated with a new task , an amendment is a suggested modification of an
a commit message commits the sender to some future course of action , or confirms the senders ' intent to comply with some previously described course of action .
a deliver message delivers something , e . g . , some information , a powerpoint presentation , the url of a website , the answer to a question , a message sent " fyi , or an opinion .
the refuse , greet , and remind verbs occurred very infrequently in our data , and hence we did not attempt to learn classifiers for them ( in this initial study ) .
the primary reason for restricting ourselves in this way was our expectation that human annotators would be slower and less reli - able if given a more complex taxonomy .
the nouns in figure 123 constitute possible ob - jects for the email speech act verbs .
the nouns fall into two broad categories .
information nouns are associated with email speech acts described by the verbs deliver , re - mind and amend , in which the email explicitly contains information .
we also associate informa - tion nouns with the verb request , where the email contains instead a description of the needed information ( e . g . , " please send your birthdate . " versus " my birthdate is " .
the request act is actually for a ' deliver information ' activity ) .
in - formation includes data believed to be fact as well as opinions , and also attached data files .
activity nouns are generally associated with email speech acts described by the verbs pro - pose , request , commit , and refuse .
activities include meetings , as well as longer term activities such as committee memberships .
notice every email speech act is itself an ac - tivity .
the <verb><noun> node in figure 123 indi - cates that any email speech act can also serve as
the noun associated with some other email speech act .
for example , just as ( deliver infor - mation ) is a legitimate speech act , so is ( commit ( deliver information ) ) .
automatically construct - ing such nested speech acts is an interesting and difficult topic; however , in the current paper we consider only the problem of determining top - level the verb for such compositional speech acts .
for instance , for a message containing a ( commit ( deliver information ) ) our goal would be to automatically detect the commit verb but not the inner ( deliver information ) compound noun .
123 categorization results
although email is ubiquitous , large and realis - tic email corpora are rarely available for research purposes .
the limited availability is largely due to privacy issues : for instance , in most us aca - demic institutions , a users email can only be dis - tributed to researchers if all senders of the email also provided explicit written consent .
the email corpora used in our experiments consist of four different email datasets collected from working groups who signed agreements to make their email accessible to researchers .
the first three datasets , n123f123 , n123f123 , and n123f123 are annotated subsets of a larger corpus , the cspace email corpus , which contains approxi - mately 123 , 123 email messages collected from a management course at carnegie mellon univer - sity .
in this course , 123 mba students , organized in approximately 123 teams of four to six mem - bers , ran simulated companies in different market scenarios over a 123 - week period ( kraut et al . ) .
n123f123 , n123f123 and n123f123 are collections of all email messages written by participants from three different teams , and contain 123 , 123 and 123 different email messages respectively .
the fourth dataset , the pw calo corpus , was generated during a four - day exercise conducted at sri specifically to generate an email corpus .
during this time a group of six people assumed different work roles ( e . g .
project leader , finance manager , researcher , administrative assistant , etc ) and performed a number of group activities .
there are 123 email messages in this corpus .
these email corpora are all task - related , and associated with a small working group , so it is not surprising that they contain many instances of the email acts described abovefor instance , the cspace corpora contain an average of about 123 email verbs per message .
informal analysis of other personal inboxes suggests that this sort of email is common for many university users .
we believe that negotiation of shared tasks is a cen - tral use of email in many work environments .
all messages were preprocessed by removing quoted material , attachments , and non - subject header information .
this preprocessing was per - formed manually , but was limited to operations which can be reliably automated .
the most diffi - cult step is removal of quoted material , which we address elsewhere ( carvalho & cohen , 123 ) .
each message may be annotated with several labels , as it may contain several speech acts .
to evaluate inter - annotator agreement , we double - labeled n123f123 for the verbs deliver , commit , request , amend , and propose , and the noun , meeting , and computed the kappa statistic ( car - letta , 123 ) for each of these , defined as
where a is the empirical probability of agreement on a category , and r is the probability of agree - ment for two annotators that label documents at random ( with the empirically observed frequency of each label ) .
hence kappa ranges from - 123 to +123
the results in table 123 show that agreement is good , but not perfect .
table 123 - inter - annotator agreement on n123f123
took doubly - annotated messages which had only a single verb label and con - structed the 123 - class confusion matrix for the two annotators shown in table 123
note kappa values
are somewhat higher for the shorter one - act mes -
table 123 - inter - annotator agreement on documents with only one category .
123 learnability of categories
representation of documents .
to assess the types of message features that are most important for prediction , we adopted support vector ma - chines ( joachims , 123 ) as our baseline learning method , and a tfidf - weighted bag - of - words as a baseline representation for messages .
we then conducted a series of experiments with the n123f123 corpus only to explore the effect of dif -
nf123f123 and nf123f123 all useful features
table 123 f123 for different feature sets .
we noted that the most discriminating words for most of these categories were common words , not the low - to - intermediate frequency words that are most discriminative in topical classification .
this suggested that the tfidf weighting was inappropriate , but that a bigram representation might be more informative .
experiments showed that adding bigrams to an unweighted bag of words representation slightly improved perform - ance , especially on deliver .
these results are shown in table 123 on the rows marked no tfidf and bigrams .
( the tfidf - weighted svm is shown in the row marked baseline , and the ma -
jority classifier in the row marked default; all numbers are f123 measures on 123 - fold cross - validation . ) examination of messages suggested other possible improvements .
since much nego - tiation involves timing , we ran a hand - coded ex - tractor for time and date expressions on the data , and extracted as features the number of time ex - pressions in a message , and the words that oc - curred near a time ( for instance , one such feature is the word before appears near a time ) .
these results appear in the row marked times .
similarly , we ran a part of speech ( pos ) tagger and added features for words appearing near a pronoun or proper noun ( personphrases in the table ) , and also added pos counts .
to derive a final representation for each cate - gory , we pooled all features that improved per - formance over no tfidf for that category .
we then compared performance of these document representations to the original tfidf bag of words baseline on the ( unexamined ) n123f123 and n123f123 corpora .
as table 123 shows , substantial improvement with respect to f123 and kappa was obtained by adding these additional features over the baseline representation .
this result contrasts with previous experiments with bigrams for topi - cal text classification ( scott & matwin , 123 ) and sentiment detection ( pang et al . , 123 ) .
the difference is probably that in this task , more in - formative words are potentially ambiguous : for instance , will you and i will are correlated with requests and commitments , respectively , but the individual words in these bigrams are less
learning methods .
in another experiment , we fixed the document representation to be un - weighted word frequency counts and varied the learning algorithm .
in these experiments , we pooled all the data from the four corpora , a total of 123 features in the 123 messages , and since the nouns and verbs are not mutually exclusive , we formulated the task as a set of several binary classification problems , one for each verb .
the following learners were used from the based on the minorthird toolkit ( cohen , 123 ) .
vp is an implementation of the voted perceptron algorithm ( freund & schapire , 123 ) .
dt is a simple decision tree learning system , which learns trees of depth at most five , and chooses suggested by schapire and
singer ( 123 ) as an appropriate objective for weak learners .
ab is an implementation of the confidence - rated boosting method described by singer and schapire ( 123 ) , used to boost the dt algorithm 123 times .
svm is a support vector ma - chine with a linear kernel ( as used above ) .
table 123 learning on the entire corpus .
table 123 reports the results on the most common verbs , using 123 - fold cross - validation to assess ac - curacy .
one surprise was that dt ( which we had intended merely as a base learner for ab ) works surprisingly well for several verbs , while ab sel - dom improves much over dt .
we conjecture that the bias towards large - margin classifiers that is followed by svm , ab , and vp ( and which has been so successful in topic - oriented text classifi - cation ) may be less appropriate for this task , per - haps because positive and negative classes are not clearly separated ( as suggested by substantial
( total : 123 msgs )
figure 123 - precision / recall for commissive act
further results are shown in figure 123 - 123 , which provide precision - recall curves for many of these classes .
the lowest recall level in these graphs
corresponds to the precision of random guessing .
these graphs indicate that high - precision predic - tions can be made for the top - level of the verb hierarchy , as well as verbs request and deliver , if one is willing to slightly reduce recall .
( total : 123 msgs )
figure 123 - precision / recall for directive act
( total : 123 messages )
figure 123 - precision / recall of 123 different classes
transferability .
one important question in - volves the generality of these classifiers : to what range of corpora can they be accurately applied ? is it possible to train a single set of email - act classifiers that work for many users , or is it nec - essary to train individual classifiers for each user ? to explore this issue we trained a dt clas - sifier for directive emails on the nf123f123 corpus , and tested it on the nf123f123 corpus; trained the same classifier on nf123f123 and tested it on nf123f123; and also performed a 123 - fold cross - validation experiment within each corpus .
( nf123f123 and nf123f123 are for disjoint sets of us - ers , but are approximately the same size . ) we then performed the same experiment with vp for deliver verbs and svm for commit verbs ( in
each case picking the top - performing learner with respect to f123 ) .
the results are shown in table 123
table 123 - transferability of classifiers
if learned classifiers were highly specific to a particular set of users , one would expect that the diagonal entries of these tables ( the ones based on cross - validation within a corpus ) would ex - hibit much better performance than the off - diagonal entries .
in fact , no such pattern is shown .
for directive verbs , performance is simi - lar across all table entries , and for deliver and commit , it seems to be somewhat better to train on nf123f123 regardless of the test set .
123 future directions
none of the algorithms or representations dis - cussed above take into account the context of an email message , which intuitively is important in detecting implicit speech acts .
a plausible notion of context is simply the preceding message in an
exploiting this context is non - trivial for sev - eral reasons .
detecting threads is difficult; al - though email headers contain a reply - to field , users often use the reply mechanism to start what is intuitively a new thread .
also , since email is asynchronous , two or more users may reply simultaneously to a message , leading to a thread structure which is a tree , rather than a se - quence .
finally , most sequential learning models assume a single category is assigned to each in - stancee . g . , ( ratnaparkhi , 123 ) whereas our scheme allows multiple categories .
classification of emails according to our verb - noun ontology constitutes a special case of a gen - eral family of learning problems we might call factored classification problems , as the classes
( email speech acts ) are factored into two features ( verbs and nouns ) which jointly determine this class .
a variety of real - world text classification problems can be naturally expressed as factored problems , and from a theoretical viewpoint , the additional structure may allow construction of new , more effective algorithms .
for example , the factored classes provide a more elaborate structure for generative probabil - istic models , such as those assumed by nave bayes .
for instance , in learning email acts , one might assume words were drawn from a mixture distribution with one mixture component pro - duces words conditioned on the verb class factor , and a second mixture component generates words conditioned on the noun ( see blei et al ( 123 ) for a related mixture model ) .
alternatively , models of the dependencies between the different factors ( nouns and verbs ) might also be used to improve classification accuracy , for instance by building into a classifier the knowledge that some nouns and verbs are incompatible .
the fact that an email can contain multiple email speech acts almost certainly makes learn - ing more difficult : in fact , disagreement between human annotators is generally higher for longer messages .
this problem could be addressed by more detailed annotation : rather than annotating each message with all the acts it contains , human annotators could label smaller message segments ( say , sentences or paragraphs ) .
an alternative to more detailed ( and expensive ) annotation would be to use learning algorithms that implicitly seg - ment a message .
as an example , another mixture model formulation might be used , in which each mixture component corresponds to a single verb
123 concluding remarks
we have presented an ontology of email speech acts that is designed to capture some im - portant properties of a central use of email : nego - tiating and coordinating joint activities .
unlike previous attempts to combine speech act theory with email ( winograd , 123; flores and ludlow , 123 ) , we propose a system which passively ob - serves email and automatically classifies it by intention .
this reduces the burden on the users of the system , and avoids sacrificing the flexibility
and socially desirable aspects of informal , natural
this problem also raises a number of interest - ing research issues .
we showed that entity ex - traction and part of speech tagging improves classifier performance , but leave open the ques - tion of whether other types of linguistic analysis would be useful .
predicting speech acts requires context , which makes classification an inherently sequential task , and the labels assigned to mes - sages have non - trivial structure; we also leave open the question of whether these properties can be effectively exploited .
our experiments show that many categories of messages can be detected , with high precision classification learning methods .
this suggests that useful task - tracking tools could be con - structed based on automatic classifiersa poten - tially important practical application .
recall , using existing
